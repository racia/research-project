Using the model: meta-llama/Meta-Llama-3-70B-Instruct
Prompt: init_prompt_reasoning, path: /home/hd/hd_hd/hd_ip303/research-project/inference/prompts/init_prompt_reasoning.txt
- THE SYSTEM SPROMPT -
______________________________
You are a helpful, logical, and highly attentive student.

You will be given a sequence of context sentences and with questions about them in parts.
You should read the context sentences and the question, understand the situation, and answer the questions correctly.
Please reason to your best abilities and answer questions in one word. In your reasoning, be very concise and avoid duplication.
As a basis for your reasoning and answer, use only the information provided to you in the conversation.

Follow each actor and object in the sentences separately paying attention to their relations.
The questions might refer to previous parts of the conversation history.
If so, inspect all the previous parts to find the correct answer.

Aim to give a specific and objective answer rather than a subjective one.
For example, 'kitchen' as a specific location is better than 'there'.

If information you need to answer the question is not specified directly,
infer it logically employing the information about the connected entities.
If you need to make an assumption, please make it as logical as possible.

Please provide the reasoning and the answer separately, first the reasoning and then the answer.
Here is a template for your answer:
Reasoning: <REASONING>
Answer: <ANSWER>

Always use it to fill in your answer.
______________________________

Starting to query the model with TEST data...


-* TASK 10/20 | SAMPLE 1/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 1/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentences only mention Bill being in the kitchen, with no information about him being in the bedroom. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' being', ' in', ' the', ' kitchen', ',', ' with', ' no', ' information', ' about', ' him', ' being', ' in', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02813006 0.04298579 0.05189936 0.07291258 0.08273926 0.0700423
  0.05150617 0.06052095 0.05188767 0.06495348 0.04395387 0.05597342
  0.06477298 0.10507298 0.07436867 0.03247471 0.0318436  0.03335727
  0.0289178  0.03237732 0.02576762 0.03798472 0.04200315 0.02213615
  0.01860136 0.02333465]
 [0.02798236 0.06264175 0.04943635 0.04365812 0.0341766  0.0413911
  0.10285293 0.06347379 0.05097058 0.03799732 0.06285024 0.0380284
  0.06554407 0.01968818 0.02095225 0.04392769 0.04132107 0.05392405
  0.04150452 0.0489832  0.04219754 0.0414388  0.0410061  0.04966858
  0.04693985 0.04366403]
 [0.03054524 0.05953544 0.03833761 0.05535875 0.0415693  0.03553768
  0.03054466 0.02187007 0.02232572 0.03474616 0.02643298 0.01544267
  0.01755075 0.03232522 0.04257973 0.02539045 0.01469095 0.0138645
  0.01676312 0.01775978 0.01622165 0.04403048 0.05360876 0.0102339
  0.00762972 0.01230991]
 [0.02871547 0.0287841  0.03083823 0.02360464 0.01731338 0.02532106
  0.02716399 0.02390999 0.02621769 0.02402836 0.027513   0.02349079
  0.02269497 0.0127355  0.01427467 0.0346244  0.03610497 0.03475365
  0.03661771 0.03865836 0.03605799 0.03316167 0.05592253 0.05864217
  0.06203281 0.06093869]
 [0.0290003  0.04312865 0.04863191 0.07029321 0.06430287 0.04828423
  0.03340823 0.02931317 0.03468377 0.04695989 0.03262209 0.0246116
  0.0248357  0.10881947 0.11334331 0.03943846 0.02824952 0.02196356
  0.02185654 0.0243098  0.02281627 0.03947601 0.06331461 0.01810157
  0.01133964 0.02711315]
 [0.02962507 0.02767173 0.02945931 0.05343461 0.04765144 0.04313315
  0.02475587 0.02261771 0.02904396 0.04333728 0.02876761 0.02755696
  0.0264674  0.11792663 0.14186305 0.03897522 0.03182951 0.0263992
  0.02461112 0.02586859 0.02181776 0.03371134 0.03770876 0.012797
  0.00905577 0.01729379]
 [0.03009351 0.03089422 0.03697555 0.05614052 0.05299176 0.05375843
  0.03201155 0.030611   0.03739541 0.05088111 0.03349841 0.04282254
  0.0395609  0.09324333 0.08831703 0.03246931 0.02876573 0.02601753
  0.02359234 0.02543387 0.02061496 0.03036846 0.03476663 0.01688291
  0.01194195 0.01628535]
 [0.02910008 0.03739884 0.0446392  0.04303501 0.0454865  0.04934865
  0.03685058 0.03963701 0.04076939 0.04515805 0.03462879 0.04870635
  0.04207046 0.05572852 0.05018264 0.04119539 0.03534755 0.03293122
  0.02890203 0.03168853 0.02910695 0.03427805 0.04899224 0.03769229
  0.03488992 0.03045581]
 [0.02926117 0.05197733 0.06124096 0.03473408 0.02898633 0.04304666
  0.04687779 0.04805625 0.0452968  0.03442279 0.03296008 0.04137755
  0.04129397 0.0241073  0.0178047  0.0392867  0.03191702 0.03020706
  0.02808883 0.0306849  0.02991812 0.03240734 0.06221958 0.04248196
  0.04084096 0.04393656]
 [0.03016604 0.06657545 0.07506131 0.03121611 0.02252543 0.03927364
  0.04507596 0.04090489 0.04839339 0.02998156 0.02584093 0.03432103
  0.03197721 0.01708016 0.01432501 0.04350111 0.03155715 0.02804855
  0.02763796 0.03214619 0.02789718 0.03128158 0.06867096 0.03610471
  0.02874218 0.02906517]
 [0.03018514 0.04162379 0.05068217 0.02799237 0.02017535 0.03642059
  0.04155676 0.04130977 0.04274651 0.02818264 0.0243871  0.03540953
  0.02968334 0.01542845 0.01325237 0.03841989 0.03097769 0.02867472
  0.0285509  0.03162144 0.02893688 0.03228017 0.04927518 0.04521123
  0.04005675 0.03636367]
 [0.03077455 0.03150104 0.03298031 0.0255908  0.01925202 0.03588552
  0.03558484 0.03938188 0.03527818 0.0279758  0.02677098 0.03856255
  0.03184133 0.01362597 0.01137978 0.02717721 0.02619521 0.02670825
  0.02513018 0.02650977 0.02554174 0.03075865 0.02664821 0.03112069
  0.03049702 0.03013755]
 [0.03036732 0.02195841 0.02112852 0.01609414 0.0135898  0.02073546
  0.02693532 0.02656    0.02419387 0.01840873 0.02594166 0.02320872
  0.02502551 0.00890162 0.00858652 0.03007549 0.02979289 0.02850486
  0.03017322 0.03085982 0.03677084 0.02806777 0.02189695 0.05842175
  0.06353439 0.04311804]
 [0.0303567  0.01857107 0.01610984 0.01355698 0.01163665 0.01431372
  0.02163043 0.02149403 0.01837715 0.01460405 0.02008495 0.0164435
  0.01992982 0.00710283 0.00732228 0.0313578  0.02479277 0.02798278
  0.02874376 0.03015268 0.04395971 0.02619411 0.01764727 0.04744075
  0.07991552 0.050634  ]
 [0.03082056 0.01994327 0.01741463 0.01486667 0.01343732 0.01627531
  0.0209283  0.02181239 0.01941312 0.01651076 0.0232724  0.01962998
  0.02153132 0.00770407 0.00772855 0.03142345 0.02583141 0.02805177
  0.02876463 0.02867877 0.03485387 0.02588001 0.01617499 0.04248785
  0.06736034 0.04562118]
 [0.03062294 0.01754035 0.01542164 0.011754   0.01177097 0.01348689
  0.02078976 0.02047574 0.01792285 0.013867   0.03015316 0.01725396
  0.02092523 0.00636006 0.00678899 0.03319032 0.03296843 0.0302236
  0.0344     0.03106169 0.03838586 0.02471776 0.0177961  0.04664485
  0.05520884 0.06139321]
 [0.03016779 0.01972426 0.01619997 0.01252279 0.01196822 0.0145057
  0.0195117  0.01760609 0.01898996 0.01399809 0.02786554 0.01593472
  0.01836174 0.00668991 0.00736074 0.03314172 0.02951496 0.02761402
  0.03271153 0.03063213 0.03690636 0.02627559 0.01997452 0.04895682
  0.05911707 0.09080651]
 [0.03097354 0.0194024  0.0171476  0.01391758 0.01216426 0.01606148
  0.01974321 0.02016071 0.01927442 0.01589461 0.02773012 0.01865338
  0.01947794 0.00765546 0.00774976 0.02399872 0.02622142 0.02660698
  0.02743034 0.02698922 0.02952649 0.02541528 0.01835035 0.03573116
  0.03817463 0.05171291]
 [0.03146411 0.02039466 0.02167184 0.01834714 0.01480841 0.02453415
  0.02408884 0.02881068 0.02708383 0.02392931 0.02495565 0.03062231
  0.02591739 0.01126718 0.00879933 0.01956832 0.02304588 0.02206725
  0.02386561 0.02418305 0.02295412 0.02768731 0.01629135 0.02272676
  0.02208791 0.02057764]
 [0.03131207 0.02468947 0.02154717 0.01629751 0.01451555 0.02127053
  0.02636508 0.02841578 0.02622901 0.01961335 0.02537423 0.02410686
  0.02569199 0.01025671 0.00851194 0.0222327  0.02919409 0.0251751
  0.02851222 0.02872981 0.02991845 0.0277125  0.01940435 0.03318026
  0.03109354 0.02339811]
 [0.03118917 0.02892305 0.02692132 0.02072708 0.01733275 0.02780536
  0.03101813 0.04165696 0.03487908 0.02811854 0.03323428 0.04139832
  0.03980894 0.0127232  0.00963073 0.02555301 0.02627845 0.0290459
  0.02873969 0.02933085 0.02750322 0.0283162  0.01868657 0.02056876
  0.01718077 0.0166092 ]
 [0.03159007 0.02555063 0.0281343  0.02343011 0.01743319 0.03971272
  0.03164341 0.03902137 0.03815965 0.03271563 0.02862323 0.05981462
  0.048745   0.01459644 0.00958412 0.02106435 0.02315961 0.02540669
  0.02574237 0.02618402 0.02310327 0.02717446 0.01731595 0.01599362
  0.01253332 0.01196412]
 [0.03099724 0.01775623 0.01866972 0.01408057 0.0112615  0.01595123
  0.02157065 0.02497599 0.02217995 0.01729151 0.02655945 0.02142166
  0.02753075 0.00779392 0.00739547 0.02580225 0.02643381 0.02758457
  0.02859975 0.02929816 0.03572316 0.02540295 0.01326409 0.02860344
  0.02747715 0.01921688]
 [0.03121826 0.01948012 0.01842881 0.01473829 0.011368   0.01504457
  0.02439721 0.02690609 0.02210636 0.01647726 0.02680231 0.02085
  0.02597347 0.00762099 0.00734116 0.03240962 0.02659866 0.03206136
  0.02869644 0.03009476 0.0403201  0.02434407 0.01303626 0.02994367
  0.02798624 0.0198366 ]
 [0.03149992 0.0181974  0.01692354 0.0152013  0.01238935 0.01641217
  0.0202774  0.02374693 0.0226852  0.01947643 0.02738989 0.02527901
  0.02407215 0.00849485 0.00778262 0.02542057 0.02551579 0.02588519
  0.02748937 0.02661186 0.03120396 0.02347803 0.01135207 0.02144963
  0.01811283 0.01389934]
 [0.03115272 0.01633692 0.01562043 0.01183333 0.0106286  0.01319132
  0.01967015 0.02042693 0.02091188 0.01473369 0.02972339 0.01968363
  0.01971951 0.00686837 0.00645149 0.02599949 0.0306896  0.02435567
  0.03138538 0.02988199 0.03531592 0.0232131  0.01137718 0.02761235
  0.02340436 0.02112456]
 [0.03013724 0.01936629 0.01786275 0.01312859 0.0118339  0.01510159
  0.02103741 0.02167373 0.02452787 0.01657194 0.02781742 0.02112227
  0.02245124 0.00779884 0.00739874 0.02891652 0.03848442 0.02937512
  0.03757594 0.03886826 0.03933587 0.02496446 0.01662328 0.04164569
  0.03129538 0.03331548]
 [0.03129726 0.02028476 0.01966116 0.01718891 0.01372655 0.01834525
  0.02139227 0.02425941 0.02549874 0.02120835 0.02772564 0.02517748
  0.0239794  0.01083949 0.00951    0.02140482 0.02950807 0.02656341
  0.02996763 0.03296917 0.02985766 0.02663295 0.01464451 0.02118125
  0.01796884 0.0167884 ]
 [0.03081996 0.02737186 0.02848893 0.03433887 0.02806058 0.03681405
  0.03094697 0.03463538 0.03467811 0.04075324 0.03232662 0.04832217
  0.04541906 0.02480823 0.01527972 0.02111551 0.02794439 0.03059559
  0.02579326 0.02524805 0.02308965 0.03215752 0.02257369 0.0225055
  0.01954242 0.01865036]
 [0.03036675 0.03233393 0.03044654 0.04811653 0.0503936  0.04266461
  0.02595329 0.02555723 0.03136782 0.04635102 0.03108433 0.02835416
  0.02865558 0.07999951 0.0924878  0.02930729 0.02699786 0.02420357
  0.02371142 0.02452486 0.02116836 0.03311441 0.03400109 0.01186439
  0.00923319 0.01660547]
 [0.03001949 0.03069718 0.02926725 0.05210329 0.10685965 0.03833751
  0.02218929 0.02374693 0.03005446 0.05451973 0.03575022 0.03263837
  0.02514845 0.07642778 0.09432962 0.0322067  0.0420136  0.0431783
  0.03454758 0.02982693 0.02711292 0.02817357 0.0316322  0.01080474
  0.00822238 0.01579723]
 [0.029867   0.02569428 0.02448274 0.038454   0.06900787 0.02709543
  0.01838069 0.02271089 0.02597143 0.0450459  0.03548497 0.03518226
  0.02740349 0.02843411 0.03252385 0.02647865 0.0515812  0.0696715
  0.06968953 0.04324527 0.03613472 0.02529176 0.0253866  0.01749287
  0.01507688 0.01970967]
 [0.03018094 0.03106535 0.02826908 0.04133155 0.05864308 0.03089791
  0.02334116 0.02374027 0.03048611 0.04128636 0.03187447 0.02859932
  0.02593896 0.03187476 0.03479338 0.0224521  0.03463273 0.03899724
  0.04128723 0.03658685 0.02996097 0.044609   0.03843388 0.01367072
  0.01290615 0.01832277]]

-* TASK 10/20 | SAMPLE 1/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 2/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 explicitly states that Bill journeyed to the bedroom, which implies that Bill is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' explicitly', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02917604 0.03930278 0.03966948 ... 0.03705021 0.0097202  0.00938441]
 [0.02993434 0.04042608 0.03730627 ... 0.04658488 0.01225569 0.01305433]
 [0.03054938 0.03926533 0.0424062  ... 0.05605194 0.01703978 0.01593744]
 ...
 [0.03073201 0.0338257  0.03221339 ... 0.01563874 0.00677256 0.00772029]
 [0.03070704 0.02895288 0.025778   ... 0.01419524 0.01126226 0.01360939]
 [0.03084339 0.03206198 0.02774655 ... 0.01070676 0.00960083 0.0114872 ]]

-* TASK 10/20 | SAMPLE 1/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 3/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 mentions that Bill is either in the school or the office, but there is no information about him being in the park. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' mentions', ' that', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' him', ' being', ' in', ' the', ' park', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 38), x_tokens=38, y_tokens=37, max_supp_attn=0.027, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 38)
DEBUG result.interpretability.attn_scores 1406 
 [[0.02517265 0.03971587 0.03876834 ... 0.02053462 0.02224848 0.03685235]
 [0.02527696 0.04681161 0.04179187 ... 0.02607974 0.03571852 0.03554656]
 [0.02624091 0.04241014 0.0435758  ... 0.01789408 0.01805392 0.03331412]
 ...
 [0.02635981 0.03388294 0.03297818 ... 0.01744616 0.01542849 0.04520176]
 [0.02690005 0.02497587 0.02218455 ... 0.01864413 0.01709841 0.03514415]
 [0.02681327 0.02792974 0.02486773 ... 0.01887821 0.01980585 0.03418876]]

-* TASK 10/20 | SAMPLE 1/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 4/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 previously mentioned that Fred went back to the park, and there is no information that suggests he left the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' previously', ' mentioned', ' that', ' Fred', ' went', ' back', ' to', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' left', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02724596 0.03141021 0.03785156 ... 0.01117412 0.00857261 0.04495324]
 [0.02765532 0.03673219 0.04156514 ... 0.01948334 0.01374938 0.02056351]
 [0.02848279 0.03674964 0.0438313  ... 0.02051098 0.01270738 0.04432622]
 ...
 [0.02871374 0.04239793 0.03778762 ... 0.0082418  0.00787517 0.10070593]
 [0.02928682 0.03120256 0.02572158 ... 0.01198916 0.01789661 0.08307458]
 [0.02897255 0.03797458 0.0319766  ... 0.00761325 0.01109416 0.09108261]]

-* TASK 10/20 | SAMPLE 1/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 5/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 14 explicitly states that Bill went back to the office, which implies that Bill is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' explicitly', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02943647 0.04513121 0.04255885 ... 0.01463553 0.0282428  0.02205762]
 [0.02954888 0.0395533  0.03984436 ... 0.04087496 0.07244962 0.04015   ]
 [0.03063998 0.0469346  0.05002517 ... 0.01285098 0.02307335 0.02279419]
 ...
 [0.03086976 0.05121939 0.04061337 ... 0.01206211 0.02344773 0.0253238 ]
 [0.0313531  0.03587664 0.02519335 ... 0.02610197 0.02492796 0.03234394]
 [0.0310169  0.04350257 0.02945982 ... 0.01668881 0.02739677 0.02988343]]
Model's predictions for the sample 1:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Bill   |
|          |                 |       being in the kitchen, with no        |
|          |                 |     information about him being in the     |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 4 explicitly states  |
|          |                 |    that Bill journeyed to the bedroom,     |
|          |                 |  which implies that Bill is currently in   |
|          |                 |                the bedroom.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentence 8 mentions that    |
|          |                 |    Bill is either in the school or the     |
|          |                 |    office, but there is no information     |
|          |                 |        about him being in the park.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 7 previously      |
|          |                 |    mentioned that Fred went back to the    |
|          |                 |   park, and there is no information that   |
|          |                 |         suggests he left the park.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 14 explicitly     |
|          |                 |     states that Bill went back to the      |
|          |                 |     office, which implies that Bill is     |
|          |                 |          currently in the office.          |
+----------+-----------------+--------------------------------------------+

Metrics for sample 1:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 2/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 6/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 1, Fred journeyed to the office, but then sentence 2 states that Fred went back to the cinema, implying that Fred left the office and is now in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '1', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' office', ',', ' but', ' then', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' went', ' back', ' to', ' the', ' cinema', ',', ' implying', ' that', ' Fred', ' left', ' the', ' office', ' and', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 26), x_tokens=26, y_tokens=51, max_supp_attn=0.1765, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 26)
DEBUG result.interpretability.attn_scores 1326 
 [[0.01786196 0.03744632 0.04463782 ... 0.01296127 0.0076567  0.01739541]
 [0.01777175 0.06162743 0.04465519 ... 0.02693424 0.01644939 0.02547079]
 [0.01946535 0.04704935 0.02955855 ... 0.00445165 0.00273748 0.00862518]
 ...
 [0.01920781 0.02226099 0.02307258 ... 0.00468154 0.00293307 0.01082091]
 [0.0192688  0.0171133  0.01843672 ... 0.00862483 0.00635349 0.01386287]
 [0.01941075 0.02058051 0.02085272 ... 0.00719507 0.00454091 0.01180935]]

-* TASK 10/20 | SAMPLE 2/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 7/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 4 indicates that Julie is either in the school or the office, but sentence 5 states that Julie moved to the cinema, which means Julie left her previous location (school or office) and is now in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' indicates', ' that', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' office', ',', ' but', ' sentence', ' ', '5', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' Julie', ' left', ' her', ' previous', ' location', ' (', 'school', ' or', ' office', ')', ' and', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 32), x_tokens=32, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 32)
DEBUG result.interpretability.attn_scores 1696 
 [[0.01733492 0.02952139 0.03334729 ... 0.00999679 0.00711364 0.00588913]
 [0.01779928 0.02840501 0.03275482 ... 0.01384339 0.00946139 0.00836589]
 [0.01809748 0.02704381 0.03552734 ... 0.02499647 0.01595786 0.01158532]
 ...
 [0.01812989 0.02965849 0.02944876 ... 0.00725324 0.00625827 0.00596344]
 [0.01837809 0.02422838 0.02258388 ... 0.00859884 0.00756839 0.00881961]
 [0.01827653 0.02717013 0.02506567 ... 0.00668826 0.00690385 0.00647716]]

-* TASK 10/20 | SAMPLE 2/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 8/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 indicates that Julie is either in the kitchen or the bedroom, but sentence 8 states that Julie journeyed to the school, which means Julie left her previous location (kitchen or bedroom) and is now in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' indicates', ' that', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' sentence', ' ', '8', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' school', ',', ' which', ' means', ' Julie', ' left', ' her', ' previous', ' location', ' (', 'k', 'itchen', ' or', ' bedroom', ')', ' and', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 38), x_tokens=38, y_tokens=55, max_supp_attn=0.0182, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 38)
DEBUG result.interpretability.attn_scores 2090 
 [[0.0168156  0.03105258 0.02769487 ... 0.05049053 0.02505869 0.00790519]
 [0.01711794 0.02460161 0.02318769 ... 0.02818532 0.0201341  0.014533  ]
 [0.01754956 0.03157525 0.03271073 ... 0.03773488 0.0212738  0.00681021]
 ...
 [0.0176733  0.02885946 0.0271477  ... 0.04529132 0.02123803 0.0078082 ]
 [0.01804705 0.01993264 0.0175946  ... 0.02192811 0.02201354 0.01484289]
 [0.01785745 0.02406468 0.02037972 ... 0.04931878 0.02128518 0.00966691]]

-* TASK 10/20 | SAMPLE 2/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 9/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 indicates that Bill is either in the bedroom or the school, and sentence 11 states that Bill went to the bedroom, which means Bill is now in the bedroom. There is no mention of Bill being in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' indicates', ' that', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' and', ' sentence', ' ', '11', ' states', ' that', ' Bill', ' went', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Bill', ' is', ' now', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 44), x_tokens=44, y_tokens=54, max_supp_attn=0.0185, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 44)
DEBUG result.interpretability.attn_scores 2376 
 [[0.01704015 0.03307087 0.03027778 ... 0.10039978 0.02475832 0.00498017]
 [0.01750118 0.02194926 0.02182342 ... 0.04425809 0.05040872 0.00889268]
 [0.01786163 0.03069739 0.0313941  ... 0.06056915 0.04252972 0.00587901]
 ...
 [0.01795574 0.02926226 0.0235531  ... 0.03848332 0.01025144 0.00387542]
 [0.01833509 0.02446009 0.01829603 ... 0.02020647 0.00755466 0.00540861]
 [0.01825081 0.02703383 0.01952945 ... 0.02882295 0.00635294 0.00484354]]

-* TASK 10/20 | SAMPLE 2/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 10/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Julie journeyed to the park, which means Julie is now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' means', ' Julie', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.1071, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03345963 0.04702476 0.05185059 ... 0.0082137  0.01495694 0.06684126]
 [0.03414974 0.05088642 0.05246755 ... 0.02186147 0.01452519 0.02502529]
 [0.03505531 0.04817843 0.05822932 ... 0.01106147 0.01260344 0.05812545]
 ...
 [0.03534547 0.05123594 0.04334299 ... 0.00896592 0.01004417 0.1295195 ]
 [0.03534409 0.04126494 0.03236227 ... 0.01173562 0.01668577 0.12921412]
 [0.03534243 0.04556989 0.03615138 ... 0.01050877 0.01217352 0.10510803]]
Model's predictions for the sample 2:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 1, Fred journeyed   |
|          |                 |     to the office, but then sentence 2     |
|          |                 |     states that Fred went back to the      |
|          |                 |    cinema, implying that Fred left the     |
|          |                 |      office and is now in the cinema.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     Sentence 4 indicates that Julie is     |
|          |                 |  either in the school or the office, but   |
|          |                 |   sentence 5 states that Julie moved to    |
|          |                 |   the cinema, which means Julie left her   |
|          |                 |  previous location (school or office) and  |
|          |                 |           is now in the cinema.            |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     Sentence 7 indicates that Julie is     |
|          |                 |   either in the kitchen or the bedroom,    |
|          |                 |      but sentence 8 states that Julie      |
|          |                 |    journeyed to the school, which means    |
|          |                 |      Julie left her previous location      |
|          |                 |   (kitchen or bedroom) and is now in the   |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |     Sentence 10 indicates that Bill is     |
|          |                 |  either in the bedroom or the school, and  |
|          |                 |  sentence 11 states that Bill went to the  |
|          |                 |  bedroom, which means Bill is now in the   |
|          |                 |    bedroom. There is no mention of Bill    |
|          |                 |            being in the office.            |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 13 states that Julie journeyed   |
|          |                 |  to the park, which means Julie is now in  |
|          |                 |                 the park.                  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 2:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.08 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 3/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 11/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the bedroom. In fact, sentence 1 explicitly states that Bill is in the kitchen, which is a different location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 26), x_tokens=26, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 26)
DEBUG result.interpretability.attn_scores 1040 
 [[0.02328781 0.04101321 0.04377789 ... 0.0106338  0.00758044 0.03221114]
 [0.02401908 0.0251241  0.02567212 ... 0.00768255 0.00662179 0.02136848]
 [0.02441618 0.02813352 0.03249107 ... 0.01019986 0.01006307 0.02003761]
 ...
 [0.02448611 0.02641591 0.0255546  ... 0.006754   0.00682801 0.01951428]
 [0.02444428 0.0227726  0.0220276  ... 0.01068272 0.01390323 0.0215538 ]
 [0.02452544 0.02716037 0.024608   ... 0.00870919 0.01126956 0.02053431]]

-* TASK 10/20 | SAMPLE 3/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 12/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Julie's location in relation to the bedroom. Sentence 2 mentioned that Julie is either in the school or the cinema, but it does not mention the bedroom.

Answer: unknown


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', ' in', ' relation', ' to', ' the', ' bedroom', '.', ' Sentence', ' ', '2', ' mentioned', ' that', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' mention', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 32), x_tokens=32, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 32)
DEBUG result.interpretability.attn_scores 1536 
 [[0.01918969 0.03039032 0.03376421 ... 0.00980454 0.01492763 0.00804958]
 [0.01978221 0.03109428 0.03162191 ... 0.01184911 0.01903265 0.01164911]
 [0.02014826 0.02794035 0.03206291 ... 0.01567679 0.02521903 0.01449118]
 ...
 [0.02013773 0.03075309 0.02660819 ... 0.00600363 0.00733587 0.00591202]
 [0.02066171 0.02409686 0.01965406 ... 0.00829563 0.00855905 0.00747588]
 [0.02067515 0.03319073 0.02889455 ... 0.0080017  0.00879463 0.00649014]]

-* TASK 10/20 | SAMPLE 3/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 13/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 states that Julie is either in the bedroom or the office, which means it is possible that Julie is in the bedroom, but it is not certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' which', ' means', ' it', ' is', ' possible', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' but', ' it', ' is', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 38), x_tokens=38, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 38)
DEBUG result.interpretability.attn_scores 1520 
 [[0.02300451 0.03514301 0.04114106 ... 0.03595562 0.01738092 0.01570299]
 [0.02301429 0.03096868 0.03570428 ... 0.04088295 0.03267886 0.02867001]
 [0.02401602 0.03737306 0.04704846 ... 0.02976546 0.01646272 0.01355829]
 ...
 [0.02404005 0.03722696 0.03619801 ... 0.02630065 0.01331399 0.0144642 ]
 [0.02458259 0.03171846 0.02898844 ... 0.02928768 0.0193205  0.02331661]
 [0.02469109 0.03046295 0.02745384 ... 0.02745862 0.01847452 0.01940264]]

-* TASK 10/20 | SAMPLE 3/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 14/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 5 mentioned that Bill is in the school, and there is no information that suggests Bill has moved or changed locations.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' mentioned', ' that', ' Bill', ' is', ' in', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' has', ' moved', ' or', ' changed', ' locations', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 44), x_tokens=44, y_tokens=32, max_supp_attn=0.0312, attn_on_target=0.0313)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 44)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02887376 0.03864352 0.03902883 ... 0.01967161 0.008572   0.01922798]
 [0.0294739  0.0284954  0.02624444 ... 0.02209046 0.01356201 0.02526615]
 [0.03012889 0.04023813 0.0406391  ... 0.02897201 0.01194572 0.02983439]
 ...
 [0.03039846 0.04567161 0.04385278 ... 0.01012451 0.00761067 0.01129591]
 [0.03093639 0.0345296  0.03022467 ... 0.01255253 0.01118922 0.01266928]
 [0.03081305 0.04038493 0.03624045 ... 0.00961813 0.00930785 0.01178105]]

-* TASK 10/20 | SAMPLE 3/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 15/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 explicitly states that Julie is in the school, which contradicts the uncertainty in sentence 13.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' school', ',', ' which', ' contrad', 'icts', ' the', ' uncertainty', ' in', ' sentence', ' ', '13', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03217511 0.04352169 0.04647733 ... 0.03842098 0.04058497 0.01932503]
 [0.0328606  0.03841342 0.03518924 ... 0.02775261 0.03722871 0.03057886]
 [0.03364407 0.04682254 0.04820963 ... 0.03868543 0.03372581 0.01769253]
 ...
 [0.03399174 0.04540577 0.04630878 ... 0.05483295 0.0377325  0.01921145]
 [0.03450345 0.03617824 0.03337266 ... 0.04662272 0.03681953 0.02682164]
 [0.03468384 0.03832441 0.03664298 ... 0.06027068 0.03591837 0.01880388]]
Model's predictions for the sample 3:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Bill being in the bedroom. In fact,     |
|          |                 |   sentence 1 explicitly states that Bill   |
|          |                 |  is in the kitchen, which is a different   |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|    no    |     unknown     |  The context sentences do not provide any  |
|          |                 |   information about Julie's location in    |
|          |                 |    relation to the bedroom. Sentence 2     |
|          |                 |   mentioned that Julie is either in the    |
|          |                 |   school or the cinema, but it does not    |
|          |                 |            mention the bedroom.            |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 7 states that Julie is either   |
|          |                 |    in the bedroom or the office, which     |
|          |                 |   means it is possible that Julie is in    |
|          |                 |    the bedroom, but it is not certain.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 5 mentioned that Bill is in the  |
|          |                 |  school, and there is no information that  |
|          |                 |     suggests Bill has moved or changed     |
|          |                 |                 locations.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 14 explicitly states that Julie  |
|          |                 |  is in the school, which contradicts the   |
|          |                 |        uncertainty in sentence 13.         |
+----------+-----------------+--------------------------------------------+

Metrics for sample 3:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.95    |
| Max attention distribution | 0.04 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 4/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 16/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Julie journeying to the bedroom and travelling to the park, but there is no mention of Julie being in or going to the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' journey', 'ing', ' to', ' the', ' bedroom', ' and', ' travelling', ' to', ' the', ' park', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' or', ' going', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 26), x_tokens=26, y_tokens=39, max_supp_attn=0.1538, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 26)
DEBUG result.interpretability.attn_scores 1014 
 [[0.0239123  0.04486864 0.04810484 ... 0.00969373 0.00929465 0.02442493]
 [0.02466505 0.02809963 0.02851108 ... 0.0075409  0.00767155 0.01615146]
 [0.02505766 0.03181544 0.03644226 ... 0.01081866 0.01025108 0.01537185]
 ...
 [0.02507617 0.03055428 0.02818661 ... 0.00719668 0.00692617 0.01503893]
 [0.02486877 0.02518431 0.0241403  ... 0.01190195 0.01122439 0.01733956]
 [0.02515395 0.02936307 0.02647599 ... 0.00928153 0.00941979 0.0152396 ]]

-* TASK 10/20 | SAMPLE 4/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 17/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, Julie travelled to the bedroom, which implies that Julie is in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03220669 0.04539812 0.04975011 0.07035767 0.06129682 0.05571562
  0.03906463 0.04085444 0.05129736 0.05623198 0.03325864 0.03883229
  0.03963513 0.10799545 0.10368071 0.03034438 0.02567744 0.02226551
  0.02443085 0.02539437 0.02102035 0.03560874 0.05599569 0.01193792
  0.0142051  0.03770857 0.04541076 0.03501804 0.10910879 0.00873828
  0.02297625 0.01091449]
 [0.03315693 0.04379606 0.04311211 0.07819617 0.0804243  0.08370585
  0.04338507 0.04193457 0.05299138 0.07548223 0.04569514 0.05917137
  0.05738353 0.14820006 0.12005424 0.03283442 0.02525847 0.02647831
  0.02615382 0.02635228 0.0218321  0.03791052 0.04286916 0.01075293
  0.01275951 0.03248203 0.04632964 0.02852369 0.09823485 0.01126501
  0.03037197 0.01474454]
 [0.03379336 0.04292127 0.04915909 0.06929342 0.06157616 0.06478781
  0.0419288  0.04129064 0.0486479  0.05871797 0.03558369 0.0498313
  0.04691477 0.1084104  0.07956742 0.02939072 0.02421129 0.02193636
  0.02355256 0.02311643 0.01922164 0.03577229 0.04097933 0.01322624
  0.014452   0.03016264 0.04523291 0.02519123 0.08212987 0.01423816
  0.03751453 0.0187999 ]
 [0.03233324 0.04731125 0.05141477 0.0372751  0.03397418 0.04095444
  0.04049671 0.04144549 0.04047836 0.03613729 0.02931988 0.03913903
  0.03880371 0.02896903 0.02828582 0.03787694 0.03257955 0.02691479
  0.02927366 0.02971303 0.02664282 0.03839937 0.06162494 0.04384226
  0.04356322 0.04328284 0.05720807 0.03268537 0.07107336 0.03923257
  0.05958738 0.03913694]
 [0.03409143 0.05324779 0.06109302 0.05291211 0.04631589 0.06744304
  0.06215861 0.0654313  0.09107578 0.06449563 0.03825566 0.05613848
  0.060658   0.05076368 0.03774732 0.0363725  0.02868418 0.02574487
  0.03061421 0.0314015  0.02428859 0.04150576 0.04913227 0.02039651
  0.02047254 0.0342207  0.06049827 0.02498406 0.05277109 0.02543083
  0.05251594 0.03276984]
 [0.03338505 0.05945305 0.05801147 0.03048306 0.026559   0.03707766
  0.04646696 0.04117734 0.04275209 0.0310059  0.02771144 0.03403157
  0.03709989 0.02210255 0.02278949 0.0482057  0.03621771 0.02853313
  0.03313226 0.03224169 0.02862249 0.03987594 0.08110009 0.04623597
  0.04642535 0.04177482 0.06052791 0.0283967  0.05065659 0.0384115
  0.0425404  0.03825082]
 [0.03430232 0.0796446  0.06869239 0.02999649 0.02756026 0.03657295
  0.05007781 0.04113769 0.05014439 0.03051042 0.02671449 0.03032894
  0.03337641 0.02047918 0.02314327 0.05675579 0.039885   0.02872275
  0.03443332 0.03482875 0.02812327 0.03597885 0.09626067 0.03909537
  0.03532056 0.0374264  0.06408489 0.02457833 0.03716926 0.02887862
  0.03003838 0.02595667]
 [0.03442368 0.05056357 0.04940943 0.02497301 0.02414652 0.02904262
  0.04220296 0.03347854 0.04008116 0.024778   0.02403375 0.02530043
  0.02697599 0.01789127 0.02065468 0.0468069  0.03587153 0.02581821
  0.03199847 0.03105374 0.02664454 0.03469596 0.06472547 0.04079994
  0.04474641 0.03704237 0.05673381 0.02294681 0.02839071 0.0305084
  0.03044225 0.0240488 ]
 [0.03466044 0.01940585 0.02074244 0.01346409 0.01377832 0.01692974
  0.01976696 0.01697815 0.01986667 0.01512273 0.01705683 0.01567267
  0.0168521  0.00922043 0.01160103 0.02371758 0.02096406 0.01819344
  0.02499397 0.02454789 0.02311205 0.02383532 0.03396163 0.04480034
  0.05360003 0.03301358 0.02534347 0.01788542 0.01720681 0.02327228
  0.02093068 0.01561559]
 [0.03440082 0.02703938 0.02880249 0.01836094 0.0187901  0.0234063
  0.02751602 0.02206725 0.02455368 0.01936657 0.02334517 0.02204701
  0.02242622 0.0127541  0.01539876 0.0346591  0.03203709 0.02712648
  0.03121683 0.03318701 0.03202229 0.03356684 0.03651718 0.05719011
  0.06181073 0.04062508 0.03325775 0.02489796 0.0251627  0.03956429
  0.03331671 0.02651727]
 [0.0344253  0.02752716 0.02846311 0.0218736  0.02023033 0.02667301
  0.02916744 0.02553426 0.02582474 0.02349193 0.02741533 0.02954485
  0.02956245 0.01515991 0.01512738 0.03503333 0.03553883 0.03529269
  0.03400467 0.03459152 0.03680658 0.03405903 0.02618263 0.06084446
  0.05695209 0.03148567 0.0283669  0.03052758 0.02504063 0.04770795
  0.03757888 0.04089411]
 [0.03392342 0.02584477 0.02276068 0.01888084 0.01495735 0.02149425
  0.02630811 0.02161216 0.02161222 0.01832823 0.02528301 0.02143535
  0.02502292 0.01100382 0.01190653 0.03553623 0.03131291 0.04915347
  0.03542423 0.04721412 0.05262212 0.03138533 0.01972836 0.07659789
  0.10201608 0.04205113 0.02535829 0.03211875 0.01595    0.09024244
  0.03262752 0.04647606]
 [0.03499077 0.02378998 0.02224321 0.01914523 0.01531105 0.02247593
  0.02585977 0.02256389 0.02221984 0.01969832 0.02989282 0.02444283
  0.02646553 0.01153243 0.01197739 0.03417359 0.02922071 0.04827872
  0.03631514 0.0551802  0.04862716 0.02655589 0.01732625 0.05881163
  0.07597517 0.04633165 0.02433566 0.03255676 0.01457431 0.08289751
  0.03933319 0.04953678]
 [0.03493881 0.02041207 0.01968557 0.01543483 0.01213493 0.01875444
  0.02321009 0.01924417 0.01957467 0.01605335 0.03376149 0.02062858
  0.02274889 0.00941908 0.0107995  0.03392566 0.03721582 0.04077797
  0.0403805  0.04677831 0.05560254 0.02784084 0.0170546  0.06966789
  0.05084731 0.05499688 0.01941517 0.03212467 0.01311263 0.06883345
  0.04085128 0.03695178]
 [0.03412731 0.02400466 0.02468472 0.01988731 0.01468345 0.02384306
  0.02910454 0.02716013 0.02599865 0.01977587 0.02807938 0.02153336
  0.02622823 0.01169576 0.01298784 0.02647949 0.03025279 0.02741449
  0.0352242  0.03473889 0.03783491 0.03033862 0.02007799 0.03814916
  0.02907151 0.03518897 0.02223112 0.02962465 0.01880542 0.03902083
  0.041394   0.02492135]
 [0.03530996 0.025449   0.0271288  0.02232684 0.01604205 0.02587158
  0.02912873 0.0282025  0.02472115 0.02185902 0.02944778 0.02633862
  0.02746426 0.01414351 0.01410905 0.02917567 0.02891011 0.02776272
  0.03173792 0.03169893 0.03416109 0.03384525 0.0187214  0.03430596
  0.03315266 0.03115549 0.02086761 0.03109151 0.02122987 0.04276388
  0.05116634 0.03913543]
 [0.03541244 0.02571918 0.03189953 0.02974321 0.02184288 0.03408687
  0.03267024 0.04145304 0.02986549 0.03446344 0.03596039 0.04454324
  0.03994755 0.02091509 0.01649109 0.02639873 0.02704708 0.02994634
  0.02948377 0.02639901 0.02539562 0.03652101 0.01809174 0.02005639
  0.02374327 0.02485649 0.02187542 0.0321957  0.02717848 0.03090424
  0.05852395 0.05384833]
 [0.03569709 0.03287662 0.03768068 0.03937914 0.02559945 0.04169209
  0.04049026 0.05304184 0.0336078  0.04476068 0.04431798 0.05800704
  0.05131602 0.02630168 0.01882222 0.03079468 0.02844853 0.03319314
  0.0311     0.02734703 0.02506644 0.03772225 0.02072275 0.01852682
  0.02014334 0.02207111 0.02572881 0.02873194 0.02617006 0.02664714
  0.04433535 0.05383024]
 [0.03550309 0.03054873 0.03302608 0.035471   0.0247052  0.03697367
  0.03727775 0.04388335 0.03190733 0.03859957 0.04186502 0.0460615
  0.04740134 0.02365529 0.01932666 0.03688384 0.03225709 0.03922284
  0.03537801 0.03275389 0.03120767 0.03809107 0.01898048 0.02533522
  0.02563522 0.02317285 0.02286841 0.04031673 0.02402691 0.03213702
  0.03780748 0.05886063]
 [0.03549027 0.02452018 0.02401885 0.02374435 0.01475963 0.02365172
  0.0287562  0.03104257 0.0251205  0.02350701 0.03141366 0.02911287
  0.03243743 0.01446686 0.013402   0.03841364 0.0354752  0.03900937
  0.03455519 0.03231987 0.03543874 0.03545447 0.01592774 0.03652862
  0.03106029 0.02568894 0.01860003 0.04647692 0.01796896 0.0386997
  0.03197727 0.05641024]
 [0.03535452 0.02781339 0.02615323 0.02667046 0.01598038 0.02400668
  0.03415232 0.03536312 0.02688753 0.02463152 0.03241412 0.02838778
  0.03408492 0.01484208 0.01456467 0.04322468 0.03772108 0.04484586
  0.03823813 0.0364633  0.04159031 0.03324592 0.01707136 0.03745457
  0.0370876  0.02797321 0.02083796 0.05008435 0.01593036 0.04441778
  0.02808086 0.06161242]
 [0.03556605 0.0245085  0.02310651 0.02342441 0.01665333 0.02263538
  0.0288449  0.03120497 0.02468036 0.02437947 0.03330069 0.03023092
  0.03049631 0.01493368 0.01442977 0.03764734 0.0424927  0.04140586
  0.04383736 0.03600052 0.04017363 0.03211782 0.01625892 0.02903998
  0.02730641 0.03028675 0.02309072 0.05080594 0.01598238 0.03583772
  0.02927129 0.06096441]
 [0.03573865 0.02224633 0.02122764 0.01833427 0.01429165 0.0187475
  0.02872878 0.02763033 0.02366051 0.01825067 0.03785969 0.02505268
  0.02672674 0.01244951 0.01204458 0.0366547  0.04326487 0.03754249
  0.04564186 0.03829195 0.04288692 0.0307283  0.01551272 0.04023537
  0.02853511 0.0361104  0.02169757 0.04227541 0.01346345 0.0435379
  0.02978946 0.05177318]
 [0.03488334 0.02613101 0.02365753 0.01832761 0.01516957 0.01986229
  0.03584889 0.03502322 0.0275617  0.01908006 0.06921027 0.03023909
  0.03414638 0.0129086  0.01342089 0.03521693 0.04654337 0.03895809
  0.04320112 0.03876191 0.04233656 0.03169491 0.01870547 0.04781794
  0.02593634 0.04487515 0.0259363  0.03924268 0.01524039 0.04372375
  0.03257502 0.03199072]
 [0.03557829 0.02871154 0.02836632 0.02655937 0.01896605 0.02635133
  0.03281861 0.03939097 0.03134695 0.02621488 0.03464981 0.03116566
  0.03112799 0.01825766 0.01645173 0.0285042  0.03095702 0.02868339
  0.03229516 0.03575341 0.03173562 0.0356005  0.01878512 0.02309376
  0.02137011 0.02873658 0.02406889 0.03257775 0.01887442 0.02901507
  0.03593124 0.03238254]
 [0.03426071 0.03174188 0.03177694 0.05094137 0.04680927 0.0424117
  0.03114139 0.03344644 0.03668237 0.04999332 0.03508258 0.03863354
  0.03793814 0.06882711 0.0904341  0.02445525 0.02655477 0.02835484
  0.02775072 0.02800839 0.02473209 0.03577796 0.03415782 0.01060215
  0.01422931 0.02964162 0.03435448 0.03826064 0.04739144 0.01047982
  0.02373233 0.01472721]
 [0.0339103  0.04061676 0.03541338 0.07295717 0.15974213 0.05317963
  0.03402975 0.03526304 0.03993516 0.07329998 0.05233566 0.05362377
  0.03635554 0.09726091 0.13163008 0.03398717 0.04618748 0.04836398
  0.03854239 0.03501207 0.03787225 0.03466866 0.04414861 0.01107427
  0.01241288 0.03283796 0.05074622 0.03914582 0.04385136 0.00857301
  0.01342998 0.00999371]
 [0.03397524 0.03350605 0.02889153 0.04585568 0.08503158 0.02893724
  0.027437   0.0302608  0.03048384 0.04816222 0.04179494 0.03747194
  0.02937637 0.03632882 0.05485938 0.03266162 0.06629741 0.06725151
  0.05775306 0.04732914 0.06367    0.03327863 0.03640902 0.01934401
  0.01994679 0.03194697 0.04007529 0.05021134 0.0250263  0.01370705
  0.01622824 0.01566231]
 [0.03416047 0.03525123 0.02962837 0.04573126 0.05266814 0.03271558
  0.03196065 0.03288371 0.03642043 0.04360171 0.03494066 0.03305328
  0.03102726 0.03911206 0.04429242 0.02386925 0.04291599 0.04280834
  0.03933663 0.04352089 0.04070962 0.04392396 0.04297061 0.01423623
  0.01722312 0.03285318 0.03491767 0.05652327 0.02827872 0.01131383
  0.0151318  0.01327371]]

-* TASK 10/20 | SAMPLE 4/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 18/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Julie moved to the office, which implies that Julie is in the office, not in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Julie', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Julie', ' is', ' in', ' the', ' office', ',', ' not', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 38), x_tokens=38, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 38)
DEBUG result.interpretability.attn_scores 1292 
 [[0.02748465 0.0446277  0.04100626 ... 0.03020342 0.01853195 0.02535773]
 [0.02812995 0.03519451 0.0324765  ... 0.03098481 0.02627842 0.02897426]
 [0.02866894 0.04824416 0.04713007 ... 0.02626718 0.01247278 0.01857912]
 ...
 [0.02886312 0.04113461 0.03794064 ... 0.02447546 0.00955872 0.01929859]
 [0.02932883 0.03247034 0.02645794 ... 0.02631688 0.01696097 0.02137666]
 [0.02932577 0.0339541  0.02815826 ... 0.02399147 0.01467719 0.02541169]]

-* TASK 10/20 | SAMPLE 4/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 19/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary in the context sentences. The sentences only talk about Bill's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Bill', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 44), x_tokens=44, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 44)
DEBUG result.interpretability.attn_scores 1232 
 [[0.03342709 0.0332488  0.03615828 ... 0.05288735 0.01804999 0.04718997]
 [0.03437067 0.0251165  0.02732025 ... 0.0491385  0.0257806  0.02677158]
 [0.03486563 0.03473763 0.04076097 ... 0.07234809 0.03207029 0.05702242]
 ...
 [0.03547283 0.03844977 0.03153731 ... 0.01366436 0.01749393 0.02587456]
 [0.03602785 0.04235049 0.03711572 ... 0.01361368 0.01728094 0.02859107]
 [0.03606017 0.03728683 0.03296848 ... 0.01429251 0.01805142 0.03064205]]

-* TASK 10/20 | SAMPLE 4/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 20/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary in the context sentences. The sentences only talk about Fred and Julie's locations, but not Mary's.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Fred', ' and', ' Julie', "'s", ' locations', ',', ' but', ' not', ' Mary', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02670879 0.04008549 0.03663057 ... 0.02128159 0.01714764 0.04205875]
 [0.02729265 0.03051377 0.02963811 ... 0.02684332 0.02315407 0.02963351]
 [0.02786099 0.03936918 0.03896912 ... 0.01803166 0.01378405 0.03606969]
 ...
 [0.02834762 0.03282011 0.02432218 ... 0.02562879 0.02623271 0.03428121]
 [0.02804419 0.04171881 0.02829093 ... 0.024186   0.02655119 0.04262648]
 [0.02838653 0.03422124 0.0254476  ... 0.01620986 0.01662523 0.03628737]]
Model's predictions for the sample 4:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Julie  |
|          |                 |  journeying to the bedroom and travelling  |
|          |                 |  to the park, but there is no mention of   |
|          |                 |  Julie being in or going to the kitchen.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 5, Julie   |
|          |                 |  travelled to the bedroom, which implies   |
|          |                 |       that Julie is in the bedroom.        |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 7, Julie   |
|          |                 |  moved to the office, which implies that   |
|          |                 |     Julie is in the office, not in the     |
|          |                 |                  kitchen.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     There is no mention of Mary in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |        talk about Bill's locations.        |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     There is no mention of Mary in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |   talk about Fred and Julie's locations,   |
|          |                 |              but not Mary's.               |
+----------+-----------------+--------------------------------------------+

Metrics for sample 4:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.09 ± 0.08 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 5/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 21/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 2 states that Fred is either in the office or the park, but it does not provide a definitive location for Fred. Therefore, we cannot conclude that Fred is definitely in the park.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' park', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Fred', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 26), x_tokens=26, y_tokens=48, max_supp_attn=0.1042, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 26)
DEBUG result.interpretability.attn_scores 1248 
 [[0.01927557 0.03848303 0.03981974 ... 0.01901279 0.00324447 0.02232714]
 [0.01988041 0.02366769 0.02342238 ... 0.01375155 0.00301811 0.01485183]
 [0.02022291 0.02697015 0.0304461  ... 0.01739628 0.00408222 0.01474601]
 ...
 [0.02029658 0.02373858 0.02340676 ... 0.01111994 0.00290795 0.01397306]
 [0.02031245 0.0189937  0.01905787 ... 0.01539584 0.00917036 0.01677773]
 [0.02059755 0.01905171 0.0189016  ... 0.0137218  0.00670804 0.01514525]]

-* TASK 10/20 | SAMPLE 5/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 22/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Fred went to the bedroom, which means Fred is in the bedroom. There is no information that suggests Fred is in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Fred', ' went', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Fred', ' is', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.025, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02325175 0.03846295 0.04378364 ... 0.01103407 0.01876383 0.00728962]
 [0.02390967 0.03757727 0.04039098 ... 0.01308348 0.02486665 0.01088092]
 [0.02429642 0.03583387 0.04256993 ... 0.02130472 0.02712798 0.01301125]
 ...
 [0.02430986 0.03888483 0.03293013 ... 0.00724977 0.01469599 0.00659229]
 [0.02463641 0.02855146 0.02355631 ... 0.00768169 0.0135776  0.00832164]
 [0.02476874 0.02955786 0.02404205 ... 0.0066567  0.01272934 0.00759555]]

-* TASK 10/20 | SAMPLE 5/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 23/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences 7 and 8 do not provide any information about Fred's location. However, we can refer back to the previous context sentence 4, which states that Fred went to the bedroom. Therefore, we can conclude that Fred is still in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' back', ' to', ' the', ' previous', ' context', ' sentence', ' ', '4', ',', ' which', ' states', ' that', ' Fred', ' went', ' to', ' the', ' bedroom', '.', ' Therefore', ',', ' we', ' can', ' conclude', ' that', ' Fred', ' is', ' still', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 38), x_tokens=38, y_tokens=61, max_supp_attn=0.0492, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 38)
DEBUG result.interpretability.attn_scores 2318 
 [[0.01516876 0.02051899 0.0208745  ... 0.02218505 0.0053183  0.0073541 ]
 [0.01538968 0.01466083 0.01444275 ... 0.02114303 0.02996999 0.01561491]
 [0.01584952 0.02134914 0.0221589  ... 0.01521806 0.00415732 0.00614294]
 ...
 [0.01608026 0.02014889 0.01718785 ... 0.01735065 0.00358769 0.00589464]
 [0.01627815 0.01500094 0.01242912 ... 0.01434771 0.00785993 0.01202107]
 [0.01628967 0.01758648 0.01377429 ... 0.01980796 0.00555941 0.008451  ]]

-* TASK 10/20 | SAMPLE 5/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 24/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that Mary went back to the office, which means Mary is currently in the office. There is no information that suggests Mary is in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' means', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 44), x_tokens=44, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 44)
DEBUG result.interpretability.attn_scores 1848 
 [[0.02214223 0.03627423 0.03657023 ... 0.11842432 0.01191053 0.00777618]
 [0.02267152 0.02471365 0.02491274 ... 0.04999874 0.0356558  0.01183961]
 [0.02307    0.03742489 0.0399067  ... 0.07895434 0.02160766 0.01194382]
 ...
 [0.02324351 0.0323868  0.03497103 ... 0.04261063 0.00776327 0.00552845]
 [0.02378775 0.02291774 0.0243303  ... 0.01949409 0.00746523 0.00666867]
 [0.02366172 0.02556869 0.02681251 ... 0.02980413 0.00642631 0.00596658]]

-* TASK 10/20 | SAMPLE 5/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 25/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that Mary went back to the office, and there is no information that suggests Mary has moved from the office. Therefore, we can conclude that Mary is still in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', ' from', ' the', ' office', '.', ' Therefore', ',', ' we', ' can', ' conclude', ' that', ' Mary', ' is', ' still', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0625, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01933847 0.02860801 0.02976204 ... 0.02828333 0.03589754 0.02279508]
 [0.01967775 0.02341858 0.02457491 ... 0.01641513 0.02849937 0.0280365 ]
 [0.02005563 0.0308415  0.03489865 ... 0.03235341 0.03099519 0.02102633]
 ...
 [0.02035989 0.03496515 0.02789611 ... 0.08380666 0.03117595 0.02185635]
 [0.02084116 0.02331666 0.01809548 ... 0.05750173 0.02353387 0.0254482 ]
 [0.02056537 0.02929826 0.02209786 ... 0.06409159 0.03337994 0.02105142]]
Model's predictions for the sample 5:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 2 states that Fred   |
|          |                 |  is either in the office or the park, but  |
|          |                 |      it does not provide a definitive      |
|          |                 |  location for Fred. Therefore, we cannot   |
|          |                 |  conclude that Fred is definitely in the   |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 4 states that Fred   |
|          |                 |  went to the bedroom, which means Fred is  |
|          |                 |  in the bedroom. There is no information   |
|          |                 |    that suggests Fred is in the school.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    The context sentences 7 and 8 do not    |
|          |                 |    provide any information about Fred's    |
|          |                 |  location. However, we can refer back to   |
|          |                 |   the previous context sentence 4, which   |
|          |                 |   states that Fred went to the bedroom.    |
|          |                 |  Therefore, we can conclude that Fred is   |
|          |                 |           still in the bedroom.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 11 states that Mary  |
|          |                 |    went back to the office, which means    |
|          |                 |   Mary is currently in the office. There   |
|          |                 |  is no information that suggests Mary is   |
|          |                 |              in the kitchen.               |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 11 states that Mary  |
|          |                 |  went back to the office, and there is no  |
|          |                 |  information that suggests Mary has moved  |
|          |                 |     from the office. Therefore, we can     |
|          |                 |     conclude that Mary is still in the     |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 5:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.06 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 6/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 26/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Julie being in the school. The context sentences only mention Julie journeying to the cinema and Fred being in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' journey', 'ing', ' to', ' the', ' cinema', ' and', ' Fred', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0541, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.0253573  0.04307062 0.04607582 0.07537495 0.07316425 0.04515558
  0.03345532 0.02939703 0.03086794 0.0473138  0.03577838 0.02248084
  0.02433091 0.12091399 0.12629661 0.03490787 0.02627145 0.01836183
  0.01800434 0.01917383 0.01922094 0.03844126 0.0590967  0.0091094
  0.00776671 0.02539136]
 [0.02615632 0.02695579 0.02717005 0.05593749 0.05191761 0.03893299
  0.02354683 0.02134186 0.02476325 0.04087419 0.03080649 0.02414319
  0.02416766 0.12391212 0.15177499 0.03345517 0.02835294 0.02171213
  0.01980513 0.01980926 0.01796574 0.03241095 0.03527799 0.00709314
  0.00651058 0.01662502]
 [0.02658726 0.03026942 0.03484231 0.05913851 0.05870908 0.049979
  0.03131576 0.029769   0.03262788 0.04842609 0.03534326 0.03863901
  0.03780242 0.09842744 0.09351937 0.02765602 0.02600488 0.02215473
  0.01919247 0.01995345 0.01713056 0.02921692 0.03265091 0.00980291
  0.0086597  0.01606348]
 [0.0256959  0.03580651 0.04294424 0.04601833 0.04794269 0.04698905
  0.03525597 0.03746678 0.03699607 0.04406472 0.03587998 0.04570227
  0.03920546 0.05815035 0.05394042 0.03484959 0.03250537 0.02844938
  0.02430612 0.02606276 0.02371379 0.03250768 0.04705011 0.02694429
  0.02277193 0.02747997]
 [0.02665464 0.03142173 0.03818835 0.03483342 0.03035108 0.04168947
  0.03551667 0.03902134 0.03463738 0.0348803  0.03074354 0.04270677
  0.03648773 0.02242306 0.01736633 0.02613219 0.02545973 0.02497564
  0.02288067 0.02476459 0.02199233 0.0269994  0.03416888 0.02166597
  0.02301637 0.027695  ]
 [0.02700889 0.02860529 0.03250967 0.02802478 0.02288483 0.0391422
  0.03436508 0.03567258 0.03485064 0.03192793 0.02942602 0.04506961
  0.03595474 0.01887649 0.01434003 0.02392044 0.02506883 0.02332276
  0.02357639 0.02446546 0.02138379 0.02658932 0.03148646 0.02000345
  0.0225968  0.02656861]
 [0.02645101 0.04387344 0.04049682 0.03078473 0.02543773 0.04401834
  0.04132944 0.04675246 0.0415576  0.0381347  0.03733554 0.06123124
  0.05077263 0.02086498 0.01576562 0.0318733  0.02930219 0.02900551
  0.02681963 0.02710165 0.02374327 0.0282994  0.03595565 0.0223394
  0.02110396 0.02319192]
 [0.02709368 0.03601563 0.04063879 0.03166831 0.02259743 0.05291958
  0.04315256 0.04354957 0.04211182 0.03609638 0.03161931 0.06616928
  0.05166766 0.02042174 0.01464036 0.02882922 0.02781776 0.02641563
  0.02449557 0.02657459 0.02269525 0.02692963 0.02962402 0.0173485
  0.01687268 0.01809338]
 [0.02723521 0.04299897 0.05231934 0.03696121 0.02446805 0.07459402
  0.06570692 0.04692021 0.05706656 0.03876003 0.03067617 0.05582538
  0.04287488 0.02064432 0.01537474 0.02583961 0.02285654 0.02069988
  0.02063413 0.02362763 0.02017755 0.0275024  0.0351176  0.01514325
  0.01419418 0.01831254]
 [0.0266683  0.02274429 0.02257425 0.01841308 0.01450764 0.02052716
  0.02670852 0.02753718 0.02312284 0.02057879 0.02843761 0.02516001
  0.03164094 0.01010728 0.01017574 0.03244182 0.03060833 0.03008278
  0.02861686 0.02883866 0.03310275 0.02599403 0.01969626 0.03451647
  0.02959181 0.02200846]
 [0.0265888  0.02079793 0.01802149 0.01653528 0.01260328 0.0149824
  0.02335625 0.02360702 0.01889876 0.01616687 0.02268714 0.01881852
  0.02200596 0.00849276 0.00882373 0.0352466  0.0305573  0.03961982
  0.03083254 0.03420866 0.04100555 0.02451135 0.01711042 0.04618736
  0.03775936 0.02670424]
 [0.02722182 0.02016767 0.01729052 0.01683268 0.01422524 0.0165506
  0.02159965 0.0231767  0.01883666 0.0187161  0.02691578 0.02438477
  0.02319004 0.00910277 0.00911134 0.03303651 0.03024881 0.03090691
  0.03076847 0.02951484 0.03255102 0.02256309 0.01380512 0.02567386
  0.02531745 0.01747064]
 [0.02721722 0.01743897 0.01515422 0.01262451 0.01221591 0.01266441
  0.01932525 0.01886415 0.01704509 0.01426159 0.02707702 0.018372
  0.01888008 0.0070681  0.00771967 0.02969318 0.03324289 0.02941213
  0.03644177 0.03266197 0.03724672 0.02287643 0.01369274 0.02661422
  0.02523597 0.01914741]
 [0.02658993 0.02039214 0.01729882 0.01356557 0.0131231  0.01404517
  0.02138929 0.01963622 0.01995918 0.01461684 0.02571533 0.01651311
  0.01889641 0.00750557 0.00862567 0.03015013 0.03138603 0.02930651
  0.04017111 0.03587044 0.03767269 0.02518038 0.02238433 0.04014645
  0.03576453 0.03520675]
 [0.02734654 0.02417517 0.02145362 0.01683125 0.01450139 0.01803679
  0.02335894 0.02482712 0.02273265 0.01876001 0.02578932 0.02268232
  0.02296725 0.00954729 0.009491   0.02320753 0.0252653  0.02354521
  0.03484863 0.03305737 0.02964386 0.0250226  0.02059134 0.01973541
  0.01919529 0.01995251]
 [0.02690194 0.02936643 0.02968242 0.02962673 0.02523904 0.0325012
  0.02735039 0.03058587 0.03052931 0.03529675 0.02802237 0.0421944
  0.03614681 0.02156031 0.01564115 0.02517427 0.02709636 0.02809755
  0.02350875 0.02404319 0.0214625  0.02909625 0.03299426 0.02946576
  0.02612662 0.01913376]
 [0.0267548  0.04571451 0.04446888 0.02391718 0.01971215 0.02796146
  0.03674737 0.03638421 0.03461395 0.02294974 0.02429952 0.02742631
  0.03035026 0.01532031 0.01385011 0.03129193 0.02595503 0.02370694
  0.0224812  0.02570586 0.02471909 0.02849302 0.05235734 0.034841
  0.03470999 0.02982042]
 [0.02716082 0.06504353 0.06824532 0.02775898 0.02136659 0.03053217
  0.04426009 0.03939956 0.04136778 0.02445719 0.02352536 0.02573673
  0.0278342  0.01532096 0.01406563 0.03706063 0.02779166 0.02200885
  0.02063888 0.02498088 0.02093186 0.02873009 0.06195869 0.02111659
  0.02020395 0.0217802 ]
 [0.02730077 0.03605365 0.03926216 0.02348185 0.01847256 0.0258259
  0.03472737 0.03377105 0.03144443 0.0215434  0.02104052 0.02403725
  0.02396695 0.01354479 0.01228832 0.02869601 0.02434098 0.02118505
  0.02024297 0.02393169 0.02209618 0.02942561 0.04310273 0.02684959
  0.03081774 0.03033152]
 [0.02790266 0.02814612 0.02828767 0.02062276 0.01605462 0.02422004
  0.02832847 0.03266348 0.02572758 0.02013175 0.02191629 0.02449863
  0.025394   0.01170897 0.01001036 0.02280076 0.01930674 0.02027874
  0.01819933 0.02075724 0.02011778 0.02714799 0.02247807 0.02423452
  0.02400723 0.02238641]
 [0.02737844 0.01985254 0.01821859 0.01426382 0.01217467 0.01518324
  0.02123467 0.02126372 0.01896204 0.01468868 0.02161258 0.01508244
  0.01967716 0.00845876 0.00803622 0.02676803 0.02347237 0.02323926
  0.02156676 0.02483132 0.02921005 0.02464788 0.01906434 0.05567183
  0.04326433 0.02650576]
 [0.0270896  0.01838948 0.01575304 0.01297076 0.0107439  0.01193052
  0.01827435 0.01740128 0.01646743 0.01280869 0.01845518 0.01211665
  0.01677888 0.00740935 0.00739215 0.03374894 0.02413834 0.03263339
  0.02307289 0.02817368 0.03660735 0.0238244  0.01649544 0.07270578
  0.04409598 0.02446552]
 [0.02773239 0.01737536 0.01654972 0.01386153 0.01191351 0.01324015
  0.01797768 0.01740858 0.01801528 0.01367352 0.01676659 0.01259733
  0.01567354 0.00814637 0.00767103 0.02810988 0.0169493  0.02080814
  0.01735332 0.02247097 0.02216488 0.02057487 0.01700255 0.05800667
  0.04060363 0.02449942]
 [0.02749884 0.01663542 0.01498431 0.01226246 0.01042401 0.01164433
  0.01655011 0.01622807 0.01607491 0.01239092 0.01904712 0.01297752
  0.01615371 0.00716945 0.00678449 0.03598187 0.02011318 0.03088513
  0.02281106 0.03262032 0.03147892 0.02189802 0.01425068 0.06474648
  0.03124105 0.01535928]
 [0.02739982 0.01578289 0.01374285 0.01060735 0.00919942 0.01043095
  0.01483847 0.0139056  0.01530274 0.01114424 0.01980251 0.01158844
  0.01453651 0.0063856  0.00617384 0.03395375 0.02145656 0.02934678
  0.0278804  0.0314959  0.0342971  0.02224245 0.01423882 0.06290231
  0.03207644 0.01992067]
 [0.02670489 0.03308001 0.02593993 0.0399769  0.04937846 0.03917065
  0.03177694 0.028129   0.02942906 0.04653546 0.04702421 0.03697567
  0.03243802 0.0388473  0.02862094 0.03206074 0.02791981 0.0306399
  0.03123281 0.02806621 0.02688871 0.0340216  0.02590591 0.03253828
  0.01575164 0.01817112]
 [0.02787792 0.01648407 0.01478495 0.01264032 0.01038027 0.01227446
  0.0151567  0.01557061 0.01695136 0.01313999 0.01869704 0.0128097
  0.01564377 0.00775445 0.00666451 0.02098482 0.01873549 0.02177979
  0.02443664 0.02309252 0.02738013 0.02196605 0.01455789 0.0329492
  0.03522321 0.03097865]
 [0.0276662  0.01861322 0.01738415 0.01308283 0.0107614  0.01371127
  0.02159426 0.02237337 0.01957602 0.01404206 0.01773071 0.01530125
  0.02160934 0.00884876 0.0069374  0.01693168 0.02326621 0.02188541
  0.02357955 0.02522583 0.02627747 0.02702541 0.01648245 0.02241028
  0.05799234 0.05168581]
 [0.02739182 0.01678092 0.01473209 0.01260152 0.01009162 0.01250793
  0.0191913  0.01918819 0.01675685 0.01345931 0.01778483 0.0129503
  0.01827892 0.00805208 0.00660938 0.01725067 0.02492689 0.02498785
  0.03248778 0.03181205 0.03525182 0.02391954 0.01413774 0.02139295
  0.07780387 0.05889157]
 [0.02775073 0.01701709 0.01520481 0.01231705 0.01067018 0.01274726
  0.02109892 0.02203162 0.01740364 0.01354446 0.02239779 0.01504135
  0.02051456 0.00838371 0.00672338 0.0179367  0.03048604 0.02219598
  0.03048331 0.02669684 0.03234818 0.02220978 0.01279201 0.01738173
  0.05882867 0.05343452]
 [0.02756045 0.01326549 0.01224616 0.00939906 0.00838344 0.009964
  0.01755247 0.01621452 0.01468641 0.01056681 0.0224508  0.01133299
  0.01694886 0.00668259 0.00536588 0.01792528 0.03785221 0.02448354
  0.03421778 0.03386251 0.03941607 0.02066446 0.01222503 0.02020115
  0.04117585 0.0754678 ]
 [0.02710246 0.02246937 0.02408983 0.02176209 0.02181894 0.02536147
  0.02994393 0.03190599 0.04942222 0.03114427 0.02609192 0.02747681
  0.03270595 0.01909715 0.01511831 0.01748569 0.02616294 0.02546774
  0.02647513 0.02841594 0.02815337 0.02831891 0.02480584 0.01695641
  0.02325893 0.04339666]
 [0.02834462 0.01821912 0.0186762  0.01620196 0.01243084 0.01728365
  0.02254807 0.02522097 0.02334195 0.01875335 0.02343259 0.01903832
  0.02380273 0.01118876 0.00840216 0.01490832 0.02160172 0.01727531
  0.02120052 0.02297116 0.0218479  0.02415408 0.01465897 0.01045086
  0.01452384 0.02906371]
 [0.02677423 0.02863234 0.02811247 0.05019346 0.05411312 0.03823341
  0.02553806 0.026315   0.03096988 0.0487188  0.03247741 0.027707
  0.03175234 0.08462864 0.09780265 0.02344397 0.02511838 0.02337722
  0.02038219 0.020086   0.01835709 0.03143127 0.032896   0.00688906
  0.00750401 0.01833652]
 [0.02662532 0.02890215 0.02681287 0.05305973 0.10532597 0.03421333
  0.02020175 0.02237858 0.02558932 0.05138645 0.03616712 0.02650603
  0.02393622 0.07914106 0.1010325  0.02772952 0.03645047 0.03592296
  0.02860302 0.02398363 0.02272364 0.02805646 0.03220987 0.00646097
  0.00607298 0.01561772]
 [0.02649244 0.02324441 0.02231146 0.03805887 0.060451   0.0245305
  0.01649797 0.02171696 0.02397468 0.04476456 0.0344443  0.03110299
  0.02776697 0.02808446 0.02993154 0.02082545 0.03982725 0.05954739
  0.06201275 0.03785956 0.03184188 0.02452752 0.02548576 0.01047107
  0.00999755 0.01618298]
 [0.02671595 0.0261983  0.02353177 0.03778876 0.052245   0.0263054
  0.01922816 0.02240463 0.02731879 0.04128132 0.03258232 0.02760353
  0.02724551 0.027808   0.0279125  0.01769193 0.03208368 0.04227604
  0.04573919 0.03323156 0.02718215 0.04257945 0.03219123 0.00903339
  0.00836282 0.0146588 ]]

-* TASK 10/20 | SAMPLE 6/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 27/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Julie moved to the kitchen, which implies that Julie is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03115795 0.04138919 0.04288848 0.06632598 0.05769083 0.05047772
  0.03294522 0.03611535 0.04402315 0.0492604  0.03089094 0.03395955
  0.03373329 0.1013651  0.09943587 0.02589724 0.02457503 0.02027349
  0.0229993  0.02558145 0.02186404 0.03567171 0.04955602 0.01530813
  0.01611737 0.03703516 0.04062712 0.03747258 0.10835768 0.01585431
  0.01931711 0.01372696]
 [0.03190472 0.04024851 0.04006024 0.07744183 0.07561127 0.07690769
  0.03753028 0.03896745 0.05111821 0.06904589 0.04149022 0.05249096
  0.05116127 0.14282978 0.11230814 0.02728131 0.0241091  0.02443678
  0.0246378  0.02727614 0.02291744 0.03794002 0.0391431  0.01333449
  0.01406775 0.03193877 0.03962325 0.03179684 0.10161892 0.02240187
  0.02588045 0.01820387]
 [0.03253865 0.03811042 0.04351563 0.0671145  0.05739476 0.05808938
  0.03469943 0.03684143 0.04457773 0.05348612 0.03199387 0.04487567
  0.03942715 0.10506941 0.07644916 0.02480237 0.02275834 0.01980444
  0.02182622 0.02380354 0.01985892 0.03461714 0.03677279 0.01659464
  0.01697863 0.03030002 0.03726121 0.02686445 0.08520715 0.03264666
  0.03794249 0.02092755]
 [0.03142207 0.04587229 0.04995907 0.04040382 0.03322889 0.03921247
  0.03744271 0.04077507 0.03958447 0.03642651 0.02883134 0.03922208
  0.03675651 0.03182173 0.02888616 0.03622765 0.03168729 0.02666137
  0.0275044  0.03007587 0.02638153 0.03632986 0.05545712 0.04528388
  0.03926069 0.04378992 0.0492781  0.03445928 0.05928994 0.06422387
  0.09195405 0.04340888]
 [0.0328888  0.04750903 0.05617127 0.05326407 0.04285938 0.06324365
  0.05164002 0.05670505 0.07903832 0.06164394 0.03432992 0.05621036
  0.05800257 0.0536037  0.03619847 0.03111157 0.02774297 0.02453951
  0.02839319 0.03240227 0.02461172 0.03877207 0.04733221 0.02323581
  0.02310031 0.03915894 0.05497653 0.02643992 0.05381374 0.049583
  0.06613356 0.03334336]
 [0.03230809 0.060709   0.06033493 0.03349272 0.02648179 0.03797804
  0.04600703 0.04302913 0.04713164 0.03269478 0.02683465 0.03573909
  0.03772147 0.02435447 0.02386987 0.04768489 0.03838809 0.02936316
  0.03253834 0.03455688 0.02921229 0.03731477 0.07583524 0.04840661
  0.04462522 0.04494247 0.05606897 0.02853388 0.03711617 0.05299474
  0.08405796 0.04102329]
 [0.03307618 0.07664526 0.0698875  0.03187334 0.02566595 0.0352302
  0.04658842 0.03960256 0.05036671 0.03036369 0.02387107 0.02873749
  0.03126368 0.02075276 0.02374707 0.05125829 0.03943285 0.02693204
  0.03221431 0.03618804 0.02862197 0.0332936  0.09763061 0.0463342
  0.03709676 0.04234635 0.06525141 0.0243274  0.02810164 0.0341194
  0.07835257 0.03165095]
 [0.03307709 0.04796928 0.04895902 0.0256237  0.02200785 0.02780453
  0.0386184  0.03197113 0.03874053 0.02482065 0.02141214 0.02390568
  0.02534558 0.01783265 0.02161092 0.04375757 0.03752604 0.02526238
  0.03204541 0.03377305 0.02860686 0.03252831 0.06843459 0.04997227
  0.04825137 0.04453827 0.05846054 0.02419358 0.02748072 0.02918205
  0.05528728 0.03436089]
 [0.03339832 0.02175635 0.02358479 0.01461071 0.01420806 0.01802721
  0.01947429 0.0177915  0.02159061 0.01646246 0.01626316 0.0159471
  0.01691767 0.00998113 0.0138214  0.02616001 0.02622931 0.02002891
  0.0271177  0.02756246 0.02436013 0.0253185  0.03371772 0.03881143
  0.04378432 0.03432586 0.02986507 0.01873545 0.01777801 0.0183386
  0.02571324 0.02523836]
 [0.03312484 0.02754858 0.02931633 0.0189546  0.01804545 0.02486815
  0.02727778 0.02290776 0.02642514 0.02124962 0.02230736 0.02233987
  0.02294402 0.01353573 0.0167627  0.03698755 0.03341139 0.02612873
  0.03078827 0.03252933 0.0288445  0.03178793 0.03439754 0.05096614
  0.04872219 0.03587683 0.03569636 0.02167734 0.02418671 0.03253236
  0.03287813 0.04116715]
 [0.03332315 0.02993868 0.03001734 0.02256241 0.02055546 0.02702744
  0.03002681 0.02695933 0.02771315 0.0255428  0.02659915 0.02954226
  0.03053223 0.01642861 0.01620892 0.04053176 0.03233742 0.03075781
  0.02938897 0.03007945 0.03019074 0.03311728 0.02649155 0.05879199
  0.04593353 0.03098485 0.03144468 0.03000708 0.02429206 0.04526596
  0.03455308 0.04801789]
 [0.03291865 0.02750083 0.02542145 0.01840607 0.01646806 0.0221547
  0.02711126 0.02274435 0.0225953  0.02007912 0.02407878 0.02238764
  0.02534249 0.01163331 0.01258912 0.03935916 0.02856243 0.03633369
  0.03053454 0.03373458 0.03600333 0.03117284 0.02032709 0.05839812
  0.04394051 0.02903083 0.02734064 0.02866883 0.01597634 0.04206569
  0.02490989 0.06918478]
 [0.03383349 0.02449264 0.02377608 0.01763571 0.01773458 0.02255471
  0.02708399 0.02373324 0.02370447 0.02110678 0.03175397 0.0268867
  0.02753529 0.01193799 0.01236135 0.04374928 0.02971315 0.04532227
  0.03451997 0.04527441 0.03913042 0.02712652 0.0184687  0.04687653
  0.04041395 0.02683429 0.02215891 0.02467715 0.01385804 0.03283144
  0.02030424 0.05680691]
 [0.03378799 0.02098971 0.02013424 0.01394118 0.01441695 0.01829856
  0.02542165 0.02024771 0.02019009 0.01693066 0.04335819 0.02309363
  0.02389196 0.00961573 0.01115844 0.03864307 0.03492851 0.03955942
  0.03756234 0.03784694 0.03933029 0.02822632 0.01813949 0.04545075
  0.0403517  0.03344354 0.01829106 0.02796934 0.0126955  0.03119203
  0.02168769 0.05037209]
 [0.03274137 0.02779396 0.02636702 0.0183012  0.01893695 0.02492548
  0.03536838 0.0332801  0.03434806 0.02343192 0.0341266  0.02899414
  0.03221781 0.01244893 0.01342268 0.03040217 0.0375815  0.03669784
  0.04374873 0.04510978 0.03784344 0.03292861 0.02213939 0.03748503
  0.03855447 0.03941647 0.02214414 0.03519812 0.01935105 0.0328687
  0.03388135 0.04071463]
 [0.03421817 0.02435071 0.0253137  0.01989638 0.0182675  0.0247535
  0.0281233  0.02820764 0.02438162 0.02226935 0.03036287 0.02837478
  0.02727704 0.01413357 0.01339475 0.0275208  0.02689429 0.02823484
  0.03123992 0.02958733 0.0314353  0.03176858 0.01867939 0.02588124
  0.02865498 0.02960942 0.02167173 0.02732215 0.02003753 0.03286467
  0.03155708 0.03477419]
 [0.03435986 0.02659094 0.0301481  0.02854988 0.02385006 0.03336645
  0.03404196 0.04275284 0.03147266 0.03499413 0.03166182 0.04366771
  0.03927406 0.02188667 0.0167627  0.02447451 0.02510088 0.02835767
  0.02800267 0.02642521 0.02620547 0.03369487 0.01896827 0.02137935
  0.02448106 0.02636773 0.02669107 0.03161522 0.02595924 0.04023697
  0.03315111 0.02915811]
 [0.03453305 0.03319093 0.03632276 0.0352089  0.02641929 0.03970802
  0.03981419 0.04859012 0.03232263 0.0417652  0.04018689 0.05253954
  0.04766794 0.02406759 0.01791649 0.03002183 0.0263016  0.03086271
  0.02899693 0.02720008 0.02647856 0.03457626 0.02158796 0.02236525
  0.02325763 0.02209244 0.0310018  0.02755887 0.02456778 0.04436167
  0.03065915 0.03081651]
 [0.03432685 0.03194017 0.0323625  0.03187132 0.02545213 0.03487732
  0.03619955 0.0406841  0.03038761 0.0367598  0.03768261 0.04335682
  0.0443942  0.02182385 0.01821168 0.03494419 0.02819107 0.03583203
  0.03259107 0.03193252 0.03172465 0.03576242 0.02008594 0.0311181
  0.03094453 0.02223911 0.02800496 0.03725047 0.02307376 0.04420558
  0.02684028 0.03443675]
 [0.03435252 0.0246266  0.02389837 0.0210479  0.01475085 0.02328976
  0.02802856 0.02932793 0.02426909 0.02205707 0.02773134 0.0270041
  0.03119718 0.01309284 0.01292957 0.03883402 0.03006965 0.03541353
  0.03189944 0.03055457 0.03462223 0.03333351 0.01684898 0.04285686
  0.0420301  0.02307407 0.02062358 0.04285143 0.01829694 0.04134669
  0.02323103 0.03843367]
 [0.03422218 0.02821707 0.02633796 0.02467184 0.01606507 0.02465413
  0.03434629 0.03471373 0.02560331 0.02421159 0.03130198 0.02795135
  0.03432401 0.01400583 0.01464437 0.03788948 0.03285732 0.03972465
  0.03516803 0.03291139 0.03853951 0.03177511 0.01741769 0.03637337
  0.04102736 0.0247671  0.02007736 0.04166275 0.01680405 0.04006074
  0.01993864 0.03929426]
 [0.03436837 0.02440907 0.02293221 0.02193321 0.01586605 0.02280822
  0.02822523 0.02933973 0.02310969 0.02271176 0.03122591 0.02742105
  0.02977603 0.01382784 0.01410985 0.0349797  0.03627481 0.03670219
  0.03773659 0.03261881 0.03908335 0.03157242 0.01694939 0.03180154
  0.04893382 0.02682505 0.02139124 0.04259109 0.01764296 0.03871639
  0.02212739 0.03419349]
 [0.0346378  0.02708568 0.02546625 0.02296776 0.01528871 0.0242452
  0.03309451 0.03253381 0.02797838 0.02333471 0.03638659 0.02803636
  0.03272348 0.01404143 0.01420808 0.03834242 0.03437692 0.03754246
  0.03764488 0.03596166 0.04074683 0.03219791 0.01717737 0.03540035
  0.04356137 0.02605707 0.02273465 0.0335703  0.01573929 0.03721998
  0.02042903 0.03588851]
 [0.0346691  0.02054936 0.01990179 0.01685727 0.01255994 0.01882723
  0.02959471 0.02607489 0.0213937  0.01665688 0.05063405 0.02172294
  0.02645745 0.01104175 0.01118589 0.0332508  0.03597574 0.03269325
  0.03611796 0.03212847 0.03732226 0.02992718 0.01477496 0.0341758
  0.04060295 0.0321501  0.01668192 0.03117551 0.01379696 0.03214567
  0.02201917 0.03788435]
 [0.0328332  0.02719709 0.02492142 0.02040055 0.01539234 0.02506943
  0.04639031 0.0416275  0.03139229 0.02284667 0.06809522 0.03462587
  0.04169882 0.01351793 0.01447534 0.03348318 0.05577559 0.05340699
  0.06131364 0.05794166 0.05118556 0.03519595 0.02385211 0.03950837
  0.04568681 0.06021201 0.02026927 0.0490366  0.02019612 0.03054856
  0.03215374 0.03988019]
 [0.03458164 0.02216885 0.02347825 0.02494207 0.01646147 0.02656501
  0.03055221 0.03707223 0.02672655 0.0245072  0.02955249 0.02860714
  0.03035903 0.01759393 0.01509413 0.02056692 0.02464039 0.02664561
  0.02884026 0.02738262 0.02841396 0.03155984 0.01647121 0.01666888
  0.02243258 0.02794873 0.01837964 0.02920975 0.0221732  0.02770477
  0.03078394 0.02683006]
 [0.03302626 0.02973973 0.03083457 0.05195929 0.04777249 0.04330046
  0.02929469 0.02999336 0.03520004 0.04972463 0.03134147 0.03651957
  0.03493794 0.07157979 0.09350946 0.02173556 0.02541579 0.02816201
  0.02685557 0.02787921 0.02673479 0.03422579 0.03428807 0.01320565
  0.01522554 0.03269289 0.03634592 0.03863595 0.04972173 0.01542281
  0.02062792 0.01367399]
 [0.03272383 0.03577071 0.03287826 0.06879438 0.1523295  0.0512357
  0.03019907 0.03033366 0.03533466 0.06736553 0.04482828 0.04743083
  0.03179873 0.09159545 0.12600964 0.02899482 0.04340143 0.04585165
  0.03649625 0.03377574 0.04050687 0.03329626 0.04188954 0.01363694
  0.01280924 0.03219514 0.05081343 0.03789598 0.04608475 0.01086913
  0.01005463 0.0109477 ]
 [0.03268473 0.03203832 0.02706803 0.04565319 0.08638985 0.02777396
  0.02478141 0.02727772 0.02725903 0.04640358 0.03809072 0.03641108
  0.02669869 0.03594695 0.05570551 0.03016229 0.06854092 0.06612296
  0.05463891 0.0419244  0.06558689 0.03182324 0.03535636 0.02331986
  0.02200138 0.03257625 0.04154241 0.0509332  0.02635824 0.01544195
  0.01194358 0.01377209]
 [0.03296114 0.03365118 0.0277424  0.04529422 0.05182865 0.03272567
  0.03007849 0.02979963 0.03202122 0.04184654 0.03277646 0.03199865
  0.02862241 0.03863357 0.04301238 0.02094568 0.03720023 0.04234546
  0.03663839 0.03598224 0.04363628 0.04314517 0.04180971 0.01705845
  0.01715179 0.03723033 0.035283   0.05766941 0.03042392 0.01275374
  0.01163014 0.01186845]]

-* TASK 10/20 | SAMPLE 6/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 28/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Mary is in the bedroom, but there is no information provided about Mary being in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.02834944 0.0405099  0.03941036 ... 0.04244306 0.02238703 0.0341207 ]
 [0.02879674 0.03378262 0.03159329 ... 0.0275021  0.02809692 0.02768078]
 [0.02948263 0.04313588 0.0428054  ... 0.03171465 0.01890442 0.02616879]
 ...
 [0.02959408 0.03734232 0.03656568 ... 0.03415747 0.01590837 0.03092649]
 [0.03019296 0.03001239 0.0280453  ... 0.02880125 0.01838866 0.02536201]
 [0.03024004 0.03071309 0.02798521 ... 0.03077601 0.01850908 0.02953609]]

-* TASK 10/20 | SAMPLE 6/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 29/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary's location in the context sentences. The context sentences only mention Julie's possible locations and Bill's possible locations, but do not provide any information about Mary.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', "'s", ' possible', ' locations', ' and', ' Bill', "'s", ' possible', ' locations', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 44), x_tokens=44, y_tokens=46, max_supp_attn=0.0435, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 44)
DEBUG result.interpretability.attn_scores 2024 
 [[0.01999621 0.02082614 0.02253337 ... 0.0103457  0.00696212 0.03516847]
 [0.02038848 0.02283474 0.02437132 ... 0.02082388 0.01112238 0.02090882]
 [0.02089802 0.02255347 0.0257302  ... 0.01628553 0.00971002 0.0368064 ]
 ...
 [0.02135891 0.02406461 0.02244494 ... 0.00949553 0.01315129 0.03557248]
 [0.02167607 0.02770899 0.0282017  ... 0.0082598  0.012017   0.03734837]
 [0.0217337  0.02423999 0.02514031 ... 0.00908382 0.01253383 0.05205473]]

-* TASK 10/20 | SAMPLE 6/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 30/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred's location in the context sentences. The context sentences only mention Bill's possible locations and Julie's possible locations, but do not provide any information about Fred.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', "'s", ' possible', ' locations', ' and', ' Julie', "'s", ' possible', ' locations', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.02028561 0.02350857 0.02841805 ... 0.01349037 0.03224659 0.04683847]
 [0.02058884 0.02866898 0.03094855 ... 0.01931225 0.02974196 0.0262882 ]
 [0.0211275  0.02741401 0.03293754 ... 0.01074955 0.02974196 0.03393914]
 ...
 [0.02155195 0.02385098 0.02170175 ... 0.02494947 0.0361362  0.02850153]
 [0.02172515 0.03025345 0.02869466 ... 0.01696478 0.02588853 0.02578107]
 [0.02160007 0.02586831 0.02440056 ... 0.01288074 0.02487542 0.0349787 ]]
Model's predictions for the sample 6:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Julie being in the school. The context   |
|          |                 |  sentences only mention Julie journeying   |
|          |                 |    to the cinema and Fred being in the     |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 4, Julie   |
|          |                 |  moved to the kitchen, which implies that  |
|          |                 |     Julie is currently in the kitchen.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to context sentence 7, Mary is  |
|          |                 |      in the bedroom, but there is no       |
|          |                 |  information provided about Mary being in  |
|          |                 |                the office.                 |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |       Mary's location in the context       |
|          |                 |   sentences. The context sentences only    |
|          |                 |   mention Julie's possible locations and   |
|          |                 |   Bill's possible locations, but do not    |
|          |                 |    provide any information about Mary.     |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |       Fred's location in the context       |
|          |                 |   sentences. The context sentences only    |
|          |                 |   mention Bill's possible locations and    |
|          |                 |   Julie's possible locations, but do not   |
|          |                 |    provide any information about Fred.     |
+----------+-----------------+--------------------------------------------+

Metrics for sample 6:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.04 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 7/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 31/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Fred is in the kitchen, and there is no information that suggests he has moved or left the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', ' or', ' left', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 26), x_tokens=26, y_tokens=38, max_supp_attn=0.1053, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 26)
DEBUG result.interpretability.attn_scores 988 
 [[0.02407048 0.04394586 0.05503007 0.07259744 0.08569447 0.06965838
  0.05226025 0.0583395  0.04797415 0.06144589 0.0440901  0.05138619
  0.05402077 0.09172228 0.05781221 0.02845983 0.0276716  0.02766917
  0.02526003 0.02611461 0.02294156 0.03546875 0.03666633 0.01869649
  0.01962092 0.02960365]
 [0.02628063 0.05035923 0.03207099 0.05011844 0.03982083 0.03148088
  0.02696165 0.01876525 0.01855143 0.03086055 0.02552624 0.01334249
  0.01520088 0.03182163 0.04068272 0.0209356  0.01301278 0.01152434
  0.01514434 0.01479955 0.01439633 0.03791836 0.04540835 0.00733547
  0.00706775 0.0141283 ]
 [0.02456355 0.0400406  0.04490842 0.02770059 0.02118056 0.03332997
  0.03426319 0.03237363 0.03666522 0.02877792 0.02672237 0.02866119
  0.02802542 0.01648556 0.01555345 0.03405334 0.03107824 0.03033537
  0.03002957 0.03032256 0.02816001 0.03171612 0.05493209 0.04538644
  0.05244656 0.04594117]
 [0.02501242 0.03640103 0.03981668 0.06172108 0.05732431 0.04153618
  0.02932177 0.02443188 0.02799953 0.04069255 0.03124473 0.02081864
  0.02085548 0.09918267 0.10510604 0.03234689 0.02451908 0.01811982
  0.01951804 0.01982254 0.02000814 0.03468081 0.05224311 0.0124415
  0.01054087 0.03028576]
 [0.02552348 0.02337866 0.02432253 0.04807976 0.04277087 0.03781647
  0.02168678 0.01878876 0.0235535  0.03797247 0.02774337 0.02359299
  0.02233638 0.10695862 0.13192138 0.03206573 0.02755092 0.02195874
  0.02185785 0.02122826 0.01929921 0.02989928 0.03230838 0.00888039
  0.00841997 0.01994486]
 [0.02591169 0.02599517 0.03113353 0.04992731 0.04675769 0.04774259
  0.02852836 0.02572322 0.03068108 0.04405139 0.03173613 0.03682289
  0.03354041 0.0852829  0.08250922 0.02655708 0.02468365 0.02134893
  0.02073708 0.02078586 0.0179799  0.02697207 0.03032379 0.0124843
  0.0110634  0.01918587]
 [0.025057   0.03582605 0.04326561 0.04019643 0.04132435 0.04562106
  0.03399426 0.03554036 0.03492048 0.04066823 0.03271044 0.04197001
  0.03642961 0.05223009 0.04817371 0.03468806 0.03159494 0.0271818
  0.02556827 0.02620328 0.0241056  0.03107685 0.04555257 0.02956612
  0.02853369 0.03355875]
 [0.02604946 0.03534624 0.04453664 0.04479238 0.03988536 0.0520701
  0.03839026 0.03952628 0.04196331 0.04550168 0.03353085 0.04222583
  0.0385844  0.03983141 0.02644834 0.0254837  0.02408264 0.02249336
  0.02249564 0.02373491 0.01991047 0.03106291 0.03271178 0.01671381
  0.0180965  0.02584419]
 [0.02547534 0.04477265 0.04882505 0.02793758 0.02223991 0.03481222
  0.03885022 0.03623164 0.03912737 0.02907617 0.02700256 0.03209897
  0.03199528 0.01825994 0.01566022 0.03900931 0.03147514 0.02588698
  0.02691199 0.02827479 0.02737864 0.03000675 0.06083778 0.03881023
  0.04011471 0.03537128]
 [0.0258907  0.05920471 0.05824134 0.02630791 0.02107946 0.02945127
  0.03962603 0.03359725 0.0404101  0.02530132 0.02428766 0.02534354
  0.0253289  0.01524084 0.01476607 0.04484825 0.03227534 0.0253741
  0.02780981 0.03092439 0.02743148 0.02765377 0.06273563 0.0317947
  0.03010982 0.03121299]
 [0.02597436 0.03217325 0.03583473 0.02036006 0.01695069 0.02204498
  0.0306983  0.02582761 0.03066831 0.02074693 0.01988947 0.02037987
  0.01937644 0.01290919 0.01325183 0.03696646 0.02918505 0.02240092
  0.02656435 0.02828497 0.02680538 0.02692468 0.05257545 0.04707985
  0.04781539 0.03641839]
 [0.02618943 0.01421199 0.01534752 0.01139878 0.01008588 0.01309433
  0.01503958 0.01437208 0.01741496 0.01275691 0.01312769 0.01287708
  0.01227165 0.00690256 0.00786188 0.01884455 0.01916196 0.01710266
  0.02208775 0.02441282 0.02591832 0.0210046  0.03744595 0.05975984
  0.06967434 0.0432213 ]
 [0.02617317 0.0202427  0.02140383 0.01561375 0.01404903 0.01928998
  0.0217337  0.01929006 0.02045173 0.01728314 0.01967402 0.01922892
  0.01801189 0.00984671 0.01079958 0.02979602 0.02361537 0.02087605
  0.02247988 0.022916   0.02396132 0.02511295 0.02778531 0.05152561
  0.05316223 0.03929092]
 [0.02634759 0.02324582 0.02373045 0.01989753 0.01699263 0.02344194
  0.02831891 0.02741803 0.02249714 0.0232763  0.0256069  0.02814251
  0.02824323 0.01297737 0.01133451 0.02808393 0.02569524 0.0242169
  0.02404841 0.02367144 0.02528419 0.02766539 0.02032455 0.0422541
  0.03290114 0.02394566]
 [0.02595852 0.01882705 0.01561645 0.01375346 0.01147863 0.01462047
  0.0255868  0.02508836 0.01621233 0.01512626 0.0222934  0.01767539
  0.02212788 0.00751054 0.00782384 0.02873276 0.0262195  0.0323683
  0.03371125 0.03189255 0.04028377 0.02443403 0.01542473 0.06304738
  0.04930258 0.03341577]
 [0.02643443 0.01924672 0.01703759 0.01499578 0.01345537 0.01695812
  0.02285889 0.02337568 0.01713636 0.01757627 0.02626918 0.02317131
  0.02388057 0.00869947 0.00841302 0.02477282 0.02713047 0.02596908
  0.02877994 0.02440022 0.03182522 0.02426786 0.01556216 0.05221712
  0.03479787 0.02248682]
 [0.02641727 0.01567918 0.01339129 0.01099232 0.01068062 0.01283928
  0.02168008 0.01980358 0.01448848 0.01325868 0.03390869 0.01851172
  0.02020764 0.00628668 0.00686593 0.02558925 0.0310922  0.02903814
  0.03253856 0.02616403 0.03339331 0.02153377 0.01352688 0.05530952
  0.03437901 0.02967728]
 [0.02522417 0.0287954  0.02089236 0.01772889 0.02142792 0.01918812
  0.03784065 0.03206796 0.02553854 0.02054212 0.03365397 0.02306275
  0.02695128 0.0110948  0.01332489 0.02722777 0.04726302 0.04236363
  0.04843936 0.04490503 0.04516972 0.02839835 0.02855448 0.05602386
  0.04862001 0.05436956]
 [0.02690383 0.01749203 0.01713488 0.01554749 0.01225298 0.01669893
  0.01844864 0.01942267 0.01749855 0.01665719 0.02177441 0.0198235
  0.01850986 0.00924266 0.00856561 0.01813907 0.01937276 0.02087191
  0.02241175 0.02098889 0.02330849 0.02223173 0.01428142 0.02465479
  0.02843958 0.02845656]
 [0.02700958 0.02021163 0.02359216 0.0241673  0.01818319 0.02526204
  0.02124023 0.02575049 0.02413508 0.02720603 0.02213314 0.02952968
  0.02387592 0.01554681 0.01084432 0.01616745 0.01998978 0.01872584
  0.02015213 0.01862809 0.01889872 0.02444921 0.0149696  0.01426785
  0.0193996  0.02197187]
 [0.02681598 0.02437596 0.02500356 0.01904893 0.01462441 0.02273145
  0.0263023  0.03034775 0.02869023 0.02023619 0.01945539 0.02756453
  0.02663667 0.01143852 0.00908455 0.0194607  0.02129533 0.02275756
  0.02485353 0.02537322 0.025796   0.02637353 0.01897118 0.01652496
  0.02633704 0.03060989]
 [0.02701771 0.02351084 0.02370682 0.01843095 0.01513419 0.0243669
  0.02787152 0.03268776 0.03041176 0.02168008 0.02568332 0.03859405
  0.03072753 0.01070713 0.00888138 0.02333036 0.0254853  0.02670547
  0.02724294 0.02521429 0.0254163  0.02200672 0.01678175 0.01445727
  0.01886595 0.02252122]
 [0.02723418 0.02212295 0.02251571 0.01925662 0.01494276 0.02697036
  0.02543432 0.02815446 0.03166431 0.02249675 0.02000516 0.03111639
  0.02852154 0.01170504 0.00865725 0.01705864 0.02064837 0.02003962
  0.02456708 0.02288644 0.02199661 0.02289361 0.01826367 0.01299038
  0.02024662 0.02401124]
 [0.02666337 0.03335627 0.0296311  0.02186613 0.01611933 0.02784812
  0.03449443 0.03745714 0.03761131 0.02581206 0.0251155  0.03723402
  0.03832285 0.01301681 0.00963245 0.0268058  0.02394161 0.03095001
  0.02849349 0.03115746 0.02659252 0.02535825 0.02168732 0.01602173
  0.02331924 0.02403489]
 [0.02723449 0.02642872 0.02800774 0.02267014 0.01561601 0.04036528
  0.03340025 0.0348566  0.04017561 0.02760156 0.02372621 0.05396503
  0.04253192 0.01402092 0.00945198 0.02144031 0.0212837  0.02228848
  0.02346207 0.02351104 0.02008088 0.02407692 0.01717418 0.01103623
  0.01425133 0.01636226]
 [0.02735688 0.01926588 0.01865886 0.01706631 0.01179912 0.01896206
  0.02314458 0.02594706 0.02408981 0.02063429 0.02179351 0.02855012
  0.03085784 0.01044061 0.00741102 0.02267543 0.01975745 0.02433969
  0.02322428 0.0241967  0.02328326 0.02364346 0.01116659 0.01602401
  0.01770661 0.01497168]
 [0.02734309 0.01961352 0.01823981 0.01792256 0.01283266 0.01947795
  0.02252879 0.02486264 0.02372415 0.02184009 0.02333139 0.0257999
  0.02978929 0.01105536 0.00803479 0.02110932 0.02009387 0.02460493
  0.02454251 0.02549533 0.02383366 0.02529987 0.01070832 0.01691522
  0.01644488 0.01364937]
 [0.02687176 0.01896385 0.01637254 0.0139586  0.01032033 0.01346034
  0.02097213 0.02168933 0.01927347 0.01517107 0.02185401 0.01888766
  0.02442789 0.00785483 0.00676392 0.02996881 0.02198503 0.03528975
  0.02754886 0.0340193  0.03479961 0.02265621 0.01182812 0.0245287
  0.03071276 0.02235888]
 [0.02691301 0.02017991 0.01768387 0.01462754 0.01105596 0.01514464
  0.02376372 0.02578717 0.02182152 0.01695544 0.0251813  0.0221832
  0.0284992  0.00843464 0.00660052 0.03373763 0.02504624 0.04115642
  0.03027385 0.03872635 0.03444247 0.02171449 0.0113432  0.02143344
  0.02815414 0.0206474 ]
 [0.02720408 0.01712061 0.01588887 0.01322722 0.01018805 0.01436708
  0.02025413 0.02170814 0.02065836 0.0155666  0.02391407 0.01910428
  0.02239502 0.00802781 0.00638828 0.02803363 0.02337723 0.03256456
  0.0274784  0.03023098 0.02846817 0.01946047 0.01031956 0.01839296
  0.03293423 0.02661662]
 [0.02733534 0.01793682 0.01686733 0.0143485  0.01062577 0.01562658
  0.02247517 0.02489462 0.02151506 0.01748922 0.02565148 0.02304516
  0.02768847 0.00886908 0.00631717 0.02579048 0.0254507  0.03675701
  0.03101222 0.03731094 0.03112193 0.02018647 0.00954359 0.01678998
  0.0183442  0.01578926]
 [0.027512   0.01484381 0.01407649 0.01103946 0.00853396 0.01224887
  0.01684423 0.01690302 0.01813353 0.01307692 0.0243853  0.01525186
  0.0180938  0.00736968 0.00561495 0.02170807 0.02145351 0.02299555
  0.02602714 0.02618051 0.0278477  0.02068419 0.00973275 0.02423486
  0.0169232  0.01836024]
 [0.02691061 0.01806437 0.01598616 0.01067505 0.00846728 0.01237473
  0.02187613 0.01913581 0.01944992 0.01271082 0.03421435 0.0146593
  0.02139627 0.00705807 0.00578872 0.02539813 0.02645211 0.02707074
  0.0295795  0.02771997 0.03019093 0.02220634 0.0120643  0.04219191
  0.02332337 0.02628873]
 [0.02743594 0.0182025  0.01847609 0.01432301 0.01037948 0.01511069
  0.01864888 0.02043561 0.02291968 0.01572532 0.0189884  0.01654404
  0.01980833 0.00956272 0.00699259 0.01844538 0.01831582 0.02030797
  0.02297306 0.02402032 0.02344773 0.02254177 0.01403217 0.01690324
  0.02159522 0.02546793]
 [0.02614926 0.02432177 0.02351085 0.0393937  0.03966381 0.03262279
  0.0205926  0.02100087 0.02515431 0.03996549 0.02741118 0.02397697
  0.02583897 0.06790987 0.08583293 0.02207197 0.0236427  0.02105195
  0.02190976 0.02108047 0.01968574 0.0284541  0.0275972  0.00917708
  0.01037565 0.02051464]
 [0.02591867 0.02536929 0.02385762 0.04436298 0.08478891 0.03243813
  0.01825175 0.01927407 0.02342813 0.04566424 0.03267223 0.02511787
  0.02151914 0.0697406  0.09080748 0.02668285 0.03422785 0.02971176
  0.02593722 0.02299402 0.02332007 0.02586759 0.02791438 0.00815864
  0.00827803 0.01856235]
 [0.02563903 0.02350423 0.02156158 0.03804562 0.08865635 0.02346512
  0.01574334 0.01877278 0.02026135 0.04258446 0.03253001 0.0268247
  0.02131622 0.03402932 0.04496909 0.02315852 0.05410451 0.04558514
  0.03556298 0.02643781 0.03593099 0.02347342 0.02419967 0.01408869
  0.01476999 0.02126018]
 [0.02597757 0.02742271 0.02382288 0.03590246 0.05261692 0.02546161
  0.02007316 0.02035096 0.02312979 0.03601144 0.03116195 0.02291549
  0.02185516 0.03072623 0.03505221 0.02035612 0.03676917 0.02999735
  0.02876511 0.02497007 0.02728572 0.04062443 0.03250172 0.01188122
  0.01291152 0.01964223]]

-* TASK 10/20 | SAMPLE 7/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 32/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, Bill went to the cinema, and there is no information that suggests he is in the school. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' is', ' in', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.1471, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02746751 0.04706796 0.0467159  ... 0.03611412 0.01358336 0.00849566]
 [0.02825453 0.04628997 0.04449687 ... 0.04487119 0.01528638 0.01071511]
 [0.02874436 0.04300892 0.04690211 ... 0.06174678 0.02601065 0.01830236]
 ...
 [0.02881877 0.04248616 0.03819677 ... 0.01491519 0.00843659 0.00502731]
 [0.02920325 0.02989084 0.02558959 ... 0.01159441 0.01276473 0.00700785]
 [0.02921067 0.03124231 0.02753141 ... 0.00984623 0.01121106 0.00684226]]

-* TASK 10/20 | SAMPLE 7/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 33/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill in the given context sentences. The previous information about Bill was in context sentence 5, where Bill went to the cinema, and there is no update about his location.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Bill', ' was', ' in', ' context', ' sentence', ' ', '5', ',', ' where', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' update', ' about', ' his', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0638, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01960845 0.02593393 0.02503433 ... 0.02084785 0.01228993 0.00726052]
 [0.01999803 0.02035922 0.02042134 ... 0.01437488 0.01233121 0.00889917]
 [0.02054685 0.02559299 0.02656022 ... 0.01432985 0.00924341 0.00540638]
 ...
 [0.02069454 0.02310418 0.01960665 ... 0.01705338 0.01002435 0.00449935]
 [0.02123912 0.01694804 0.0144812  ... 0.01269824 0.01223201 0.0071804 ]
 [0.02112039 0.01883423 0.0161738  ... 0.01697056 0.01209952 0.00675197]]

-* TASK 10/20 | SAMPLE 7/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 34/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, Julie journeyed to the kitchen, and there is no information that suggests she has left the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' has', ' left', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02751448 0.03616585 0.04045787 ... 0.08074544 0.01039641 0.01165734]
 [0.02773779 0.03249635 0.03782983 ... 0.05739862 0.02298822 0.01656679]
 [0.0287692  0.03930616 0.04916397 ... 0.06696612 0.01473959 0.01796043]
 ...
 [0.02881873 0.04563454 0.04348505 ... 0.02439452 0.00832047 0.00721521]
 [0.02928135 0.03298512 0.02933517 ... 0.01275052 0.01016083 0.00819494]
 [0.02915965 0.03788209 0.03465051 ... 0.01278886 0.00781088 0.00720186]]

-* TASK 10/20 | SAMPLE 7/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 35/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 11, Fred went to the kitchen, but then according to context sentence 14, Fred moved to the cinema, which means he is no longer in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '14', ',', ' Fred', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' he', ' is', ' no', ' longer', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 50), x_tokens=50, y_tokens=45, max_supp_attn=0.0, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 50)
DEBUG result.interpretability.attn_scores 2250 
 [[0.02059584 0.02980495 0.03152261 ... 0.03243875 0.02089941 0.01746756]
 [0.02089598 0.02291635 0.02564652 ... 0.02051645 0.02591823 0.02640015]
 [0.02146551 0.03101761 0.03845    ... 0.03077829 0.01922483 0.01397334]
 ...
 [0.0216849  0.03408442 0.03274858 ... 0.03025253 0.01801487 0.01446598]
 [0.02224008 0.02557773 0.02346811 ... 0.02205994 0.01761428 0.01865869]
 [0.02191325 0.02798685 0.02557896 ... 0.02902015 0.01731384 0.01784055]]
Model's predictions for the sample 7:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 1, Fred is  |
|          |                 |      in the kitchen, and there is no       |
|          |                 |   information that suggests he has moved   |
|          |                 |            or left the kitchen.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 5, Bill    |
|          |                 |    went to the cinema, and there is no     |
|          |                 |   information that suggests he is in the   |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   There is no information about Bill in    |
|          |                 |      the given context sentences. The      |
|          |                 |   previous information about Bill was in   |
|          |                 |   context sentence 5, where Bill went to   |
|          |                 |  the cinema, and there is no update about  |
|          |                 |               his location.                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 10, Julie   |
|          |                 |   journeyed to the kitchen, and there is   |
|          |                 |    no information that suggests she has    |
|          |                 |             left the kitchen.              |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 11, Fred   |
|          |                 |  went to the kitchen, but then according   |
|          |                 |   to context sentence 14, Fred moved to    |
|          |                 |  the cinema, which means he is no longer   |
|          |                 |              in the kitchen.               |
+----------+-----------------+--------------------------------------------+

Metrics for sample 7:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.11 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 8/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 36/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary going to the school in the context sentences. In fact, sentence 1 states that Mary went to the office, which implies that she is not in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' going', ' to', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' In', ' fact', ',', ' sentence', ' ', '1', ' states', ' that', ' Mary', ' went', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' she', ' is', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 26), x_tokens=26, y_tokens=46, max_supp_attn=0.1087, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 26)
DEBUG result.interpretability.attn_scores 1196 
 [[0.02016181 0.03646023 0.03874355 ... 0.0092292  0.00885297 0.02779652]
 [0.02081037 0.02287365 0.02285282 ... 0.00634305 0.00709021 0.01815523]
 [0.02116581 0.02580069 0.02933067 ... 0.00845238 0.00862231 0.01708017]
 ...
 [0.02122429 0.02379235 0.02280805 ... 0.00602086 0.00634698 0.01760081]
 [0.02123144 0.01881347 0.01825073 ... 0.00816763 0.00915859 0.01779148]
 [0.02128124 0.02472038 0.02202559 ... 0.00692049 0.00877265 0.01702417]]

-* TASK 10/20 | SAMPLE 8/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 37/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 5 explicitly states that Mary is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 32), x_tokens=32, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 32)
DEBUG result.interpretability.attn_scores 608 
 [[0.04963483 0.07677312 0.0767559  0.09576838 0.08084435 0.08079841
  0.06558693 0.06637745 0.08032308 0.0804002  0.05657119 0.0605229
  0.06418431 0.13222569 0.1253006  0.0571492  0.04268651 0.0421971
  0.03883888 0.04660799 0.0387887  0.05611531 0.09802746 0.03607552
  0.03336628 0.07209169 0.08045719 0.06185223 0.15435344 0.02709672
  0.03736909 0.02156211]
 [0.05121981 0.07117868 0.07039605 0.10939647 0.10400743 0.114306
  0.07093188 0.06914814 0.08454106 0.10431904 0.07284572 0.08516845
  0.08729254 0.20048267 0.16064708 0.06133316 0.04202465 0.04707511
  0.0411064  0.0476584  0.03939466 0.05842764 0.06854028 0.02997487
  0.02883879 0.06076195 0.09093858 0.0498173  0.13932723 0.0336117
  0.04164734 0.02659898]
 [0.05210969 0.06773997 0.07411152 0.09061582 0.07864523 0.0884899
  0.06882613 0.06964859 0.07489373 0.08184291 0.05775775 0.07764477
  0.0766903  0.12717535 0.09313859 0.05118757 0.03847495 0.0392652
  0.0368796  0.04194005 0.0346334  0.05514007 0.06596565 0.03615936
  0.03238058 0.0540424  0.07611489 0.04399957 0.1136757  0.04873481
  0.0651119  0.0437769 ]
 [0.05031291 0.07350598 0.07458484 0.05163223 0.04647091 0.05862191
  0.06263451 0.06960551 0.06441586 0.05230974 0.04888178 0.06201944
  0.06170417 0.03735009 0.03539708 0.05896824 0.04698002 0.04350159
  0.04404597 0.04870217 0.04205797 0.06036495 0.08079147 0.05969422
  0.054899   0.06510025 0.07252128 0.0534215  0.07473668 0.08680537
  0.13093059 0.11602074]
 [0.05189777 0.06532069 0.06976274 0.03827244 0.03195954 0.04490607
  0.06042497 0.05621932 0.06115898 0.03890292 0.04092192 0.04443688
  0.04559297 0.02514784 0.0260008  0.05997725 0.04622347 0.03994931
  0.04701994 0.0515713  0.04381233 0.0506015  0.0754598  0.06499769
  0.06194118 0.05428615 0.0638866  0.03879648 0.03708382 0.05934453
  0.0847851  0.15319699]
 [0.05295038 0.02802442 0.02960594 0.01855114 0.0164887  0.02292582
  0.02804665 0.02615923 0.02999013 0.02131821 0.02651156 0.02366481
  0.02556898 0.0114185  0.01317556 0.03229896 0.02807348 0.02658365
  0.0353516  0.03873572 0.0349572  0.0342968  0.03530029 0.05171973
  0.05958947 0.04157594 0.0317187  0.02916536 0.01985302 0.03418359
  0.0375794  0.07351672]
 [0.05213735 0.05575544 0.05589863 0.03155213 0.02578241 0.04291182
  0.04964767 0.04891475 0.04697451 0.03390197 0.03967428 0.04534554
  0.04220114 0.01911455 0.02039629 0.05392846 0.04853501 0.03894333
  0.04838521 0.051105   0.04715136 0.05677967 0.06412065 0.07368419
  0.06951114 0.0544924  0.06044272 0.04087154 0.03688666 0.08053313
  0.07744054 0.1101407 ]
 [0.05344342 0.06993797 0.07353598 0.05419235 0.0387063  0.06203154
  0.06938329 0.07552473 0.06292524 0.06065613 0.06312346 0.08443642
  0.07293269 0.03294925 0.02826771 0.0608991  0.05423055 0.05164612
  0.05517719 0.05599364 0.05010619 0.05927813 0.05567908 0.06261678
  0.05664273 0.05241114 0.06832872 0.04927537 0.04120018 0.09787486
  0.07783619 0.08757889]
 [0.05420797 0.05025797 0.05578752 0.03779403 0.0302857  0.04439264
  0.05674605 0.0529548  0.04654292 0.04027364 0.04948961 0.05132039
  0.05200254 0.0224776  0.02185674 0.0545844  0.04812805 0.04141101
  0.04893688 0.04925807 0.04517835 0.05400424 0.04301074 0.06261412
  0.05705408 0.0418947  0.05415388 0.0426348  0.03394414 0.07588809
  0.06564391 0.09086741]
 [0.05352955 0.03882542 0.03726353 0.02562379 0.01923409 0.03042107
  0.04109084 0.03854121 0.03482468 0.02722985 0.0422219  0.03429179
  0.03992052 0.01408585 0.01585327 0.05251091 0.05490153 0.04124211
  0.05316632 0.0495103  0.05044457 0.05036078 0.03055771 0.07133655
  0.06592019 0.0376853  0.03661002 0.04526971 0.02440198 0.06363985
  0.04535803 0.04921985]
 [0.05323542 0.03954648 0.03542358 0.02606017 0.01703731 0.02959047
  0.04435188 0.0407982  0.03575315 0.02622841 0.04237022 0.03148808
  0.04291055 0.01337138 0.01406221 0.0581406  0.06325183 0.0506582
  0.06447349 0.05963439 0.06691585 0.04683489 0.0276048  0.09300688
  0.08648015 0.04730878 0.02879888 0.05943448 0.01940129 0.07628924
  0.03948085 0.03234316]
 [0.05413409 0.03645586 0.03506359 0.02592764 0.01882555 0.0311367
  0.04180914 0.04143122 0.03524539 0.02799032 0.04704959 0.03742618
  0.04150837 0.01412915 0.01454991 0.05148781 0.06994063 0.04699969
  0.06955358 0.05483537 0.05844907 0.04662207 0.02448145 0.05370937
  0.05566221 0.03525248 0.02894862 0.05001853 0.01873409 0.05844762
  0.03761206 0.0298993 ]
 [0.05389057 0.032311   0.03210366 0.02247536 0.01555956 0.0273187
  0.04238269 0.03878977 0.03399414 0.0238406  0.05149048 0.03229499
  0.04066872 0.01234948 0.0131473  0.06011108 0.07500161 0.05191169
  0.07361501 0.06095197 0.06765196 0.04668743 0.02405384 0.07461179
  0.06842195 0.050358   0.02475606 0.06282052 0.01755483 0.05926019
  0.04020685 0.02604523]
 [0.05318492 0.03485212 0.03509914 0.02573692 0.01752055 0.03324591
  0.04499645 0.04322753 0.03955404 0.02538657 0.03744366 0.03218194
  0.0401727  0.01474547 0.01396362 0.0394862  0.03785405 0.03926945
  0.04930466 0.05248398 0.04822585 0.04564525 0.03443162 0.05587333
  0.06841678 0.06288072 0.03012154 0.04536833 0.0273603  0.05349813
  0.05242217 0.0350794 ]
 [0.05453281 0.03300968 0.0344236  0.02972256 0.01798979 0.03335494
  0.04047905 0.04230617 0.03623551 0.02976475 0.04020649 0.03532057
  0.04051354 0.01778376 0.0159834  0.03758351 0.03282857 0.03537299
  0.0439957  0.04183385 0.04468275 0.04783642 0.02553552 0.03938403
  0.04463066 0.04078141 0.02854932 0.04075997 0.02951914 0.04732874
  0.05547984 0.03231658]
 [0.05272834 0.05031018 0.05294537 0.07199679 0.05878782 0.06759004
  0.05298247 0.05519191 0.06332056 0.07837854 0.06033736 0.06595227
  0.0661518  0.0918171  0.10124466 0.04540908 0.04059803 0.05394065
  0.04463997 0.04859597 0.04497532 0.055105   0.05351561 0.02963683
  0.03554982 0.05418302 0.04986149 0.06111206 0.06731676 0.02814998
  0.04498542 0.02302326]
 [0.05211354 0.06679264 0.06168738 0.10710142 0.21312279 0.08548071
  0.05821544 0.06057753 0.0638537  0.10757686 0.08979788 0.0827053
  0.05983922 0.12116515 0.167459   0.06578127 0.07584193 0.09962204
  0.06197578 0.06169871 0.06960935 0.05514247 0.06980068 0.03001347
  0.03358877 0.05907914 0.07197225 0.06129536 0.06554393 0.01820677
  0.0191527  0.01591612]
 [0.05223773 0.0521551  0.0457411  0.06452656 0.09532303 0.04555231
  0.04448025 0.04899098 0.04620925 0.06865828 0.06858224 0.05704369
  0.0468178  0.04100037 0.06366939 0.05365023 0.09059881 0.12863302
  0.08068744 0.07188088 0.09810611 0.05017347 0.05310743 0.04082401
  0.04441334 0.05495177 0.05395423 0.07340501 0.03426526 0.02726746
  0.02295559 0.01781584]
 [0.05249894 0.05724728 0.04980989 0.07305381 0.07340891 0.05692503
  0.05698367 0.05559293 0.05924403 0.07102107 0.064723   0.05673563
  0.05332712 0.05121077 0.0558867  0.04551297 0.0638263  0.0817778
  0.06284627 0.06700219 0.07485891 0.07058392 0.07001599 0.03406725
  0.0426929  0.06086274 0.04786504 0.09068187 0.04484151 0.02383923
  0.02400234 0.01508181]]

-* TASK 10/20 | SAMPLE 8/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 38/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no new information about Mary's location in the given context sentences. The previous information about Mary's location is not provided in this task, so we cannot determine Mary's current location.

Answer: unknown


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Mary', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Mary', "'s", ' location', ' is', ' not', ' provided', ' in', ' this', ' task', ',', ' so', ' we', ' cannot', ' determine', ' Mary', "'s", ' current', ' location', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.1333, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02040026 0.02394142 0.02098856 ... 0.04017443 0.02505071 0.0154048 ]
 [0.020867   0.01834089 0.01679495 ... 0.02784622 0.02792828 0.04779586]
 [0.02131601 0.02386343 0.02260448 ... 0.03001042 0.01746346 0.01086682]
 ...
 [0.02146494 0.02589529 0.02194326 ... 0.06103708 0.01785862 0.0103427 ]
 [0.02204451 0.02418278 0.01917605 ... 0.04303301 0.01807094 0.01429966]
 [0.02220088 0.02479439 0.02126931 ... 0.06267367 0.0185992  0.01111133]]

-* TASK 10/20 | SAMPLE 8/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 39/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie's location in the context sentences. Sentence 11 only provides information about Mary's possible locations, which does not imply anything about Julie's location.

Answer: unknown


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '11', ' only', ' provides', ' information', ' about', ' Mary', "'s", ' possible', ' locations', ',', ' which', ' does', ' not', ' imply', ' anything', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 44), x_tokens=44, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 44)
DEBUG result.interpretability.attn_scores 1848 
 [[0.02195089 0.02558047 0.0300696  ... 0.0493775  0.03654079 0.02836886]
 [0.02234517 0.02208443 0.02319293 ... 0.02171054 0.05586008 0.02526764]
 [0.02291635 0.02789895 0.03247142 ... 0.03235625 0.05794552 0.03964578]
 ...
 [0.02303874 0.0325961  0.02997717 ... 0.03845998 0.01293895 0.0149387 ]
 [0.02352656 0.02669392 0.02404327 ... 0.02901629 0.01044115 0.01408465]
 [0.02362975 0.02936043 0.02818538 ... 0.03067651 0.00865908 0.01314352]]

-* TASK 10/20 | SAMPLE 8/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 40/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Mary's location in the context sentences. Sentence 14 only provides information about Bill's location, which does not imply anything about Mary's location.

Answer: unknown


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Mary', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '14', ' only', ' provides', ' information', ' about', ' Bill', "'s", ' location', ',', ' which', ' does', ' not', ' imply', ' anything', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02261987 0.02690669 0.03301097 ... 0.02094042 0.0341834  0.03257465]
 [0.02327996 0.02211531 0.0262448  ... 0.02431297 0.02424034 0.01996866]
 [0.02364058 0.03173772 0.03981822 ... 0.01974411 0.02773638 0.02628999]
 ...
 [0.0239511  0.03547052 0.03240333 ... 0.01589741 0.03259348 0.03189605]
 [0.02411857 0.02801483 0.02560806 ... 0.0239069  0.03290664 0.04929909]
 [0.0241776  0.03274279 0.03388049 ... 0.01779401 0.03208157 0.02954848]]
Model's predictions for the sample 8:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Mary going to the  |
|          |                 |    school in the context sentences. In     |
|          |                 |   fact, sentence 1 states that Mary went   |
|          |                 |  to the office, which implies that she is  |
|          |                 |             not in the school.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 5 explicitly states that Mary   |
|          |                 |             is in the office.              |
+----------+-----------------+--------------------------------------------+
|   yes    |     unknown     |  There is no new information about Mary's  |
|          |                 |  location in the given context sentences.  |
|          |                 |   The previous information about Mary's    |
|          |                 |   location is not provided in this task,   |
|          |                 |   so we cannot determine Mary's current    |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|    no    |     unknown     |   There is no information about Julie's    |
|          |                 |     location in the context sentences.     |
|          |                 |   Sentence 11 only provides information    |
|          |                 |   about Mary's possible locations, which   |
|          |                 |   does not imply anything about Julie's    |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |     unknown     |    There is no information about Mary's    |
|          |                 |     location in the context sentences.     |
|          |                 |   Sentence 14 only provides information    |
|          |                 |   about Bill's location, which does not    |
|          |                 |   imply anything about Mary's location.    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 8:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.4     |
|    Soft-match accuracy     |     0.55    |
| Max attention distribution | 0.09 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 9/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 41/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Bill being in the school or the school, but there is no mention of the cinema. Therefore, we cannot conclude that Bill is in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' being', ' in', ' the', ' school', ' or', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' cinema', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0714, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02219089 0.04275034 0.04352462 ... 0.00472668 0.00637587 0.03375433]
 [0.02292521 0.02687658 0.02508168 ... 0.00407821 0.00584859 0.02196139]
 [0.02330208 0.03002599 0.03155075 ... 0.00583284 0.00723565 0.02065852]
 ...
 [0.02338127 0.02682345 0.0253631  ... 0.0040646  0.00525345 0.02071363]
 [0.02318836 0.02241509 0.02213098 ... 0.00939104 0.00962263 0.02216083]
 [0.02337914 0.02595213 0.02403052 ... 0.00737569 0.00824642 0.02103125]]

-* TASK 10/20 | SAMPLE 9/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 42/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Mary's movements, but there is no new information about Bill's location. From the previous context (sentence 1), we know that Bill is either in the school or the school.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', "'s", ' movements', ',', ' but', ' there', ' is', ' no', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' From', ' the', ' previous', ' context', ' (', 'sentence', ' ', '1', '),', ' we', ' know', ' that', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 32), x_tokens=32, y_tokens=49, max_supp_attn=0.102, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 32)
DEBUG result.interpretability.attn_scores 1568 
 [[0.01891534 0.02561055 0.0281285  ... 0.00570643 0.00649096 0.01349833]
 [0.01955811 0.0251076  0.02622401 ... 0.00645737 0.00724878 0.01791641]
 [0.01995573 0.0237236  0.02799104 ... 0.00899853 0.00889603 0.02170175]
 ...
 [0.02003573 0.02517658 0.02257815 ... 0.0036872  0.00388414 0.00730757]
 [0.02044732 0.02098791 0.01740953 ... 0.00721834 0.0078774  0.00880456]
 [0.0205712  0.02004836 0.01759087 ... 0.0052168  0.00652543 0.00980489]]

-* TASK 10/20 | SAMPLE 9/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 43/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Julie journeying to the office, but there is no mention of the park. Therefore, we cannot conclude that Julie is in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' journey', 'ing', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' park', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Julie', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 38), x_tokens=38, y_tokens=40, max_supp_attn=0.075, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 38)
DEBUG result.interpretability.attn_scores 1520 
 [[0.02336485 0.02983771 0.03609838 ... 0.04495813 0.02848381 0.01971195]
 [0.02350582 0.03197874 0.0342425  ... 0.0371284  0.0375051  0.03275478]
 [0.02435539 0.03293126 0.03966581 ... 0.03336463 0.02339778 0.01512868]
 ...
 [0.0244912  0.03217155 0.03023952 ... 0.03847721 0.01900577 0.01457292]
 [0.02482788 0.02385492 0.02235106 ... 0.02555018 0.01712724 0.0177723 ]
 [0.02480971 0.0255758  0.0231634  ... 0.03816823 0.01800132 0.01851431]]

-* TASK 10/20 | SAMPLE 9/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 44/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 mentions Julie going back to the park, which implies that Julie is no longer in the office (sentence 7). 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' mentions', ' Julie', ' going', ' back', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' office', ' (', 'sentence', ' ', '7', ').', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02583883 0.03632206 0.03361178 ... 0.09869548 0.0116286  0.01537498]
 [0.02613902 0.02849485 0.02721    ... 0.06745684 0.02640119 0.03066314]
 [0.02700703 0.03897574 0.03950233 ... 0.07881459 0.0176999  0.02252379]
 ...
 [0.02737087 0.03720606 0.0368175  ... 0.02481754 0.00824826 0.01056043]
 [0.02784002 0.02894595 0.02579524 ... 0.01196773 0.00888794 0.01210937]
 [0.0276898  0.02994066 0.0272309  ... 0.01238315 0.00788997 0.01112673]]

-* TASK 10/20 | SAMPLE 9/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 45/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Mary moving to the office, but there is no mention of the park. Therefore, we cannot conclude that Mary is in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' moving', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' park', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Mary', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02390118 0.03460986 0.03110823 ... 0.02470794 0.03243056 0.03911088]
 [0.02436498 0.02914045 0.02402402 ... 0.01905028 0.01756479 0.03231109]
 [0.02504623 0.03602125 0.03577598 ... 0.02926183 0.02974778 0.0300043 ]
 ...
 [0.02524712 0.03319648 0.03240662 ... 0.05027437 0.06417452 0.03039011]
 [0.02568338 0.02405112 0.02213149 ... 0.03343163 0.05918097 0.02339942]
 [0.02555688 0.02523685 0.02281105 ... 0.02009891 0.064574   0.02973303]]
Model's predictions for the sample 9:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Bill   |
|          |                 |   being in the school or the school, but   |
|          |                 |     there is no mention of the cinema.     |
|          |                 |  Therefore, we cannot conclude that Bill   |
|          |                 |             is in the cinema.              |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |     The context sentences only mention     |
|          |                 |   Mary's movements, but there is no new    |
|          |                 |  information about Bill's location. From   |
|          |                 |   the previous context (sentence 1), we    |
|          |                 |   know that Bill is either in the school   |
|          |                 |               or the school.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Julie  |
|          |                 |   journeying to the office, but there is   |
|          |                 |   no mention of the park. Therefore, we    |
|          |                 |    cannot conclude that Julie is in the    |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   The context sentence 11 mentions Julie   |
|          |                 |   going back to the park, which implies    |
|          |                 |   that Julie is no longer in the office    |
|          |                 |               (sentence 7).                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Mary   |
|          |                 |   moving to the office, but there is no    |
|          |                 |     mention of the park. Therefore, we     |
|          |                 |    cannot conclude that Mary is in the     |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 9:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.08 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 10/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 46/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the park. The context sentences only mention the bedroom and the office as possible locations for Fred.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' the', ' bedroom', ' and', ' the', ' office', ' as', ' possible', ' locations', ' for', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02683533 0.04616231 0.04998027 0.08285873 0.07808547 0.04915122
  0.03438164 0.02981797 0.03280873 0.05084255 0.03540346 0.02386264
  0.02377084 0.12638985 0.13379015 0.04225614 0.02753909 0.0206562
  0.01671877 0.01963329 0.02048654 0.04015179 0.06549647 0.01942581
  0.00440804 0.02483806]
 [0.0276932  0.02827091 0.02946858 0.06002355 0.0555901  0.0417776
  0.02428311 0.02160216 0.02618859 0.04409618 0.03004126 0.02570609
  0.0238021  0.13222593 0.15906657 0.03977982 0.02967769 0.02422611
  0.01856823 0.02059884 0.01946408 0.03324955 0.03888266 0.01413358
  0.00389307 0.01654279]
 [0.02815191 0.0318622  0.03704412 0.06365313 0.0619219  0.05292498
  0.0321113  0.02984772 0.03462284 0.05234824 0.03525233 0.04116388
  0.03683864 0.10410447 0.09758639 0.03308031 0.02703594 0.02437546
  0.01821793 0.02065208 0.01830886 0.03026126 0.03497464 0.01728842
  0.00520004 0.01653947]
 [0.02716429 0.03752692 0.043123   0.04723435 0.05212833 0.04817864
  0.03642238 0.03915384 0.03958607 0.04672508 0.03593068 0.04865674
  0.04029579 0.06224503 0.05581023 0.03942398 0.03307248 0.03129642
  0.0242226  0.0275531  0.02573813 0.03450294 0.04848891 0.03307042
  0.01391648 0.03227179]
 [0.02815763 0.03187228 0.03702682 0.03495766 0.03295021 0.04258882
  0.0348765  0.03816097 0.03675137 0.03659767 0.03004587 0.0449867
  0.03564584 0.02266147 0.01732718 0.02733533 0.02504813 0.02666638
  0.02314997 0.02610206 0.02348197 0.02748594 0.03589735 0.02858242
  0.01999201 0.03180428]
 [0.02854794 0.03090298 0.03259615 0.02948214 0.02584261 0.0410094
  0.03388677 0.03592085 0.03527537 0.03339646 0.02912756 0.04882902
  0.03596606 0.01924998 0.01446789 0.02523668 0.02426696 0.02442144
  0.02174458 0.02354334 0.02239903 0.02761062 0.03207767 0.02857323
  0.02152757 0.03037599]
 [0.02794388 0.04638701 0.04015027 0.0323562  0.02822453 0.04672292
  0.04327181 0.0476148  0.0451931  0.0404611  0.0366944  0.0625793
  0.04967527 0.02164723 0.01618425 0.03296761 0.02941557 0.03211303
  0.02866483 0.02996113 0.02641987 0.02979793 0.03740903 0.02723317
  0.02399449 0.02691323]
 [0.02866711 0.03707598 0.03984716 0.03226429 0.02458143 0.05487371
  0.04315016 0.04396332 0.0437483  0.03735409 0.03102417 0.06865441
  0.05043795 0.02062698 0.01493326 0.03142836 0.0281392  0.0286748
  0.02434725 0.02695843 0.02498588 0.02840697 0.03092674 0.02418081
  0.01621982 0.02080316]
 [0.0288189  0.04528211 0.05363337 0.03740646 0.02753327 0.07712097
  0.06615815 0.04736042 0.0607765  0.03964902 0.0305131  0.05813426
  0.04301489 0.02094772 0.0157662  0.02953617 0.02352156 0.02274481
  0.02032164 0.02403559 0.02207777 0.0291924  0.03733663 0.02353468
  0.01151754 0.01968959]
 [0.02818178 0.0227782  0.02311046 0.0187928  0.01672529 0.02158215
  0.03150027 0.03036569 0.02567206 0.02225146 0.02889567 0.02788988
  0.03718919 0.0109093  0.01045804 0.03103379 0.03322052 0.03614164
  0.03900156 0.03864347 0.04005918 0.02917603 0.01980637 0.03061273
  0.03126014 0.02457151]
 [0.02828871 0.02006555 0.01783221 0.01641878 0.01425066 0.01530211
  0.02484109 0.0248095  0.01939503 0.01690089 0.02231521 0.01885176
  0.02297121 0.00862408 0.0090422  0.03096449 0.0276908  0.03844838
  0.04044775 0.04468    0.04335374 0.02630382 0.01704192 0.03475699
  0.04291407 0.03103367]
 [0.02870295 0.02063427 0.0181238  0.01809337 0.01632581 0.01791057
  0.02457125 0.02654498 0.02047551 0.02077146 0.02707982 0.02574876
  0.02638572 0.00975969 0.00946288 0.03120996 0.03122995 0.03530553
  0.03780505 0.03790306 0.03699414 0.0241843  0.01489404 0.02632325
  0.03837708 0.01969706]
 [0.02866019 0.01692132 0.01513296 0.01348552 0.0132458  0.01360526
  0.02125538 0.02043594 0.01768572 0.01558359 0.02706943 0.01838866
  0.01985798 0.00747047 0.00804993 0.02842265 0.034529   0.03258754
  0.0453348  0.04300698 0.04116808 0.02378795 0.01492594 0.02826257
  0.04031543 0.02246727]
 [0.02800579 0.0195193  0.01708265 0.01402917 0.01304674 0.01501168
  0.02144839 0.0194964  0.02011119 0.01513687 0.02520858 0.01639664
  0.01912373 0.00772853 0.00855632 0.03108242 0.03479113 0.0309672
  0.04144071 0.03784666 0.03675931 0.02582512 0.0222567  0.05109873
  0.0526135  0.04328372]
 [0.02885578 0.02445104 0.02188645 0.01835351 0.01575044 0.01959487
  0.02457491 0.02438179 0.02474878 0.02097983 0.02566428 0.02411869
  0.02341082 0.0107766  0.01017619 0.02367792 0.02497534 0.02784238
  0.04043669 0.04599794 0.03756997 0.02582793 0.02185424 0.02149885
  0.02195756 0.02140602]
 [0.02836798 0.02843052 0.02808394 0.03070965 0.02665658 0.03368597
  0.02833075 0.03102316 0.03281746 0.03791212 0.02752397 0.04411371
  0.03782964 0.02282818 0.01565131 0.02404919 0.02640587 0.02920045
  0.02539929 0.02516177 0.0237752  0.0317177  0.03508016 0.02433522
  0.02051717 0.03291287]
 [0.02831235 0.04495668 0.04183638 0.0244942  0.0207229  0.02870568
  0.03454629 0.0361065  0.03595909 0.02409826 0.02430065 0.02870545
  0.03141464 0.01552108 0.01347509 0.03068173 0.02670439 0.02443873
  0.02462398 0.02664214 0.02500505 0.02993319 0.0522227  0.03295002
  0.03607501 0.04035241]
 [0.02874867 0.06917373 0.07042114 0.02934505 0.02299166 0.03296797
  0.0446942  0.04012107 0.04519435 0.02606209 0.02428912 0.02784562
  0.02919578 0.01571846 0.01416237 0.04079202 0.02804927 0.02283641
  0.01974378 0.02425623 0.02204621 0.03028209 0.06817503 0.03024141
  0.0136471  0.02557629]
 [0.02879932 0.03755249 0.0400539  0.0246157  0.01953262 0.02712716
  0.03533386 0.03471259 0.03436832 0.02276097 0.02203487 0.02517028
  0.02451835 0.0136713  0.01250569 0.03142224 0.02531821 0.02237881
  0.020359   0.02385241 0.02406931 0.03110391 0.04740668 0.04014388
  0.02099985 0.03594797]
 [0.02946172 0.02807952 0.02837224 0.02171048 0.01679347 0.02535949
  0.02890977 0.03509106 0.02778935 0.02157783 0.02249287 0.02573612
  0.0265951  0.01207558 0.01032605 0.02213546 0.02075044 0.02007244
  0.01885221 0.02047476 0.02062402 0.02893147 0.02269106 0.02352181
  0.02771824 0.02772453]
 [0.02893184 0.01962777 0.01872345 0.01526136 0.01263225 0.01633294
  0.02160847 0.02197653 0.02023222 0.01561213 0.02244326 0.01611846
  0.02070403 0.00894283 0.00827289 0.02501363 0.02421771 0.0219591
  0.02260794 0.02488835 0.0295153  0.02536312 0.01828242 0.05019616
  0.05708336 0.03298096]
 [0.0287189  0.02051882 0.01904058 0.01325808 0.01123746 0.01412695
  0.02322844 0.0226576  0.02008125 0.0145032  0.0277997  0.01478658
  0.02449467 0.00833268 0.00730664 0.02741453 0.03015025 0.0245969
  0.02686987 0.02780307 0.03582977 0.02426963 0.0167094  0.06122913
  0.06394961 0.03605302]
 [0.02911968 0.01457671 0.0134971  0.01159751 0.00970359 0.01164846
  0.01424862 0.0129135  0.01538876 0.01208552 0.01849314 0.01146269
  0.01351972 0.00697835 0.00602226 0.01759544 0.02483403 0.01711608
  0.02314692 0.02526871 0.03200097 0.02029119 0.01224984 0.0474949
  0.07053203 0.0514374 ]
 [0.02926327 0.01549023 0.0145819  0.01146199 0.00994628 0.01202853
  0.01552191 0.0147618  0.01676245 0.01244232 0.01858659 0.01309487
  0.01537099 0.00735911 0.00623497 0.02204723 0.02688546 0.01805151
  0.02860117 0.02472276 0.02664584 0.02432882 0.01325721 0.02952542
  0.05667207 0.05478433]
 [0.02848709 0.01796346 0.01694839 0.01287799 0.01120201 0.01313376
  0.0181124  0.01735065 0.02016484 0.01449178 0.02075431 0.01451157
  0.01851075 0.00822065 0.00702058 0.02561203 0.03484068 0.02847764
  0.04284192 0.03859609 0.04106513 0.02538891 0.01811125 0.03996465
  0.05291943 0.05775591]
 [0.02953625 0.01863213 0.01750603 0.01418183 0.01136426 0.01422824
  0.02038    0.02220937 0.01948361 0.01500985 0.02101734 0.01576547
  0.01996599 0.00871144 0.00693645 0.01995121 0.02695489 0.01932057
  0.02894042 0.02293964 0.02467259 0.02556187 0.01397256 0.01877646
  0.04138531 0.03620124]
 [0.02943865 0.02346314 0.02250916 0.01624275 0.0130372  0.01778149
  0.03031844 0.03332892 0.02342376 0.0185436  0.04069875 0.02107718
  0.03162118 0.01120204 0.00809778 0.02641864 0.0295841  0.02583211
  0.02669339 0.0252854  0.02614906 0.02832578 0.01633884 0.02365049
  0.03698428 0.02102155]
 [0.02931598 0.02784321 0.02436248 0.01853577 0.01408704 0.0181777
  0.03281197 0.03509209 0.02486482 0.02088135 0.04055454 0.02117675
  0.032075   0.01262905 0.00908506 0.02830675 0.03260481 0.02689518
  0.02834578 0.0254379  0.02591041 0.02768172 0.01717075 0.0263591
  0.04147284 0.02141599]
 [0.02961264 0.02396522 0.02456346 0.01861366 0.01448926 0.01853266
  0.03487376 0.03376177 0.02627593 0.02046461 0.04475501 0.02236744
  0.03197931 0.01109335 0.0084898  0.02871442 0.03072436 0.0274944
  0.02596915 0.02606732 0.02783558 0.02589143 0.01587871 0.02347494
  0.02150887 0.01566382]
 [0.02923123 0.01907533 0.01760405 0.0139653  0.01050665 0.01351741
  0.01969121 0.01923793 0.01950233 0.01456029 0.01774903 0.01228246
  0.02026821 0.00844204 0.00667826 0.02439746 0.02581279 0.02297435
  0.02561008 0.02623832 0.03170715 0.02726999 0.01668731 0.03702351
  0.03527452 0.02980883]
 [0.0295472  0.01970913 0.01904222 0.01763538 0.01284222 0.0153783
  0.01943692 0.0188615  0.02054663 0.01778718 0.01868349 0.01489617
  0.02018769 0.01065191 0.00872327 0.02126741 0.02076359 0.02142647
  0.02389365 0.02367283 0.02654348 0.02532757 0.01638363 0.02427272
  0.02721517 0.02857943]
 [0.02822384 0.03032263 0.02985818 0.0534171  0.05936273 0.04047336
  0.02485298 0.02571724 0.03154484 0.05297621 0.03389448 0.02936401
  0.03291063 0.08997172 0.10466219 0.02905861 0.02643186 0.02735314
  0.02001137 0.02054876 0.0204122  0.03298134 0.03448936 0.01419516
  0.00415714 0.01905309]
 [0.02812582 0.03020409 0.02892658 0.05619147 0.11286677 0.03657052
  0.02037451 0.02216219 0.02731898 0.05483871 0.03683861 0.02788514
  0.02396411 0.08459842 0.10778151 0.03385168 0.03711478 0.04170269
  0.02747518 0.0244173  0.02536053 0.02927012 0.03354824 0.01279444
  0.00428079 0.01626876]
 [0.02792149 0.02392416 0.02314176 0.03844237 0.06168057 0.02531826
  0.01652627 0.02075801 0.02532271 0.04665942 0.03436978 0.03074647
  0.02760316 0.02900767 0.03033216 0.02338119 0.03715332 0.0697746
  0.05341497 0.04071175 0.03809212 0.0265507  0.02666534 0.01664688
  0.01066139 0.01828123]
 [0.02816065 0.0267786  0.02488882 0.03803267 0.05214196 0.02755025
  0.01946619 0.02268016 0.02991913 0.04363804 0.03245471 0.0289262
  0.02888503 0.02867692 0.02755805 0.02045352 0.03054574 0.05163113
  0.04617758 0.0358984  0.03347361 0.0437648  0.03241019 0.01462806
  0.00883902 0.01594283]]

-* TASK 10/20 | SAMPLE 10/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 47/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill being in the park. The context sentences only mention the kitchen and the cinema as possible locations for Bill.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' the', ' kitchen', ' and', ' the', ' cinema', ' as', ' possible', ' locations', ' for', ' Bill', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 32), x_tokens=32, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 32)
DEBUG result.interpretability.attn_scores 1120 
 [[0.02683649 0.04591701 0.04719443 ... 0.01153875 0.00638906 0.00399518]
 [0.02776318 0.04399743 0.0440296  ... 0.01163536 0.00778646 0.00508075]
 [0.02812605 0.04185349 0.04602027 ... 0.01931838 0.01227818 0.00688225]
 ...
 [0.02815904 0.03756414 0.03398582 ... 0.00646642 0.00397141 0.0032006 ]
 [0.02851276 0.02628287 0.02277058 ... 0.00950538 0.00535532 0.00542808]
 [0.02837577 0.03129429 0.02663991 ... 0.00836597 0.00452696 0.00446291]]

-* TASK 10/20 | SAMPLE 10/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 48/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 8, Fred went back to the cinema, which implies that Fred is currently in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Fred', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03083207 0.04717249 0.04583554 ... 0.02945617 0.02195834 0.02149416]
 [0.03135547 0.03777835 0.0354948  ... 0.03013457 0.0313428  0.04754145]
 [0.032251   0.05132159 0.05215488 ... 0.02216855 0.01557299 0.01409611]
 ...
 [0.03265644 0.04406681 0.03881001 ... 0.02137603 0.01263912 0.01262438]
 [0.03276181 0.03487939 0.0287551  ... 0.02920386 0.02141136 0.02055531]
 [0.0328116  0.04191105 0.03308617 ... 0.0239724  0.01771413 0.01755904]]

-* TASK 10/20 | SAMPLE 10/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 49/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no new information provided about Fred's location. The context sentences 10 and 11 only mention Mary's movements and do not update our knowledge about Fred's location. Previously, we knew that Fred went back to the cinema (sentence 8).

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' provided', ' about', ' Fred', "'s", ' location', '.', ' The', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ' only', ' mention', ' Mary', "'s", ' movements', ' and', ' do', ' not', ' update', ' our', ' knowledge', ' about', ' Fred', "'s", ' location', '.', ' Previously', ',', ' we', ' knew', ' that', ' Fred', ' went', ' back', ' to', ' the', ' cinema', ' (', 'sentence', ' ', '8', ').\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 44), x_tokens=44, y_tokens=58, max_supp_attn=0.0345, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 44)
DEBUG result.interpretability.attn_scores 2552 
 [[0.01584502 0.01785267 0.01886461 ... 0.02750304 0.01192634 0.00618288]
 [0.01607805 0.01642284 0.01747165 ... 0.01579511 0.00920023 0.01061363]
 [0.01657773 0.01800664 0.0210737  ... 0.03575864 0.01289423 0.00803788]
 ...
 [0.01687934 0.02152253 0.02121382 ... 0.00959091 0.00671547 0.00475297]
 [0.01738091 0.01609519 0.01484585 ... 0.00804062 0.00751973 0.00551459]
 [0.01721275 0.01795218 0.01664096 ... 0.00701668 0.00696747 0.00488241]]

-* TASK 10/20 | SAMPLE 10/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 50/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 10, Mary was initially in the bedroom. However, sentence 14 states that Mary moved to the school, which implies that Mary is no longer in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Mary', ' was', ' initially', ' in', ' the', ' bedroom', '.', ' However', ',', ' sentence', ' ', '14', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0682, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02092514 0.02944859 0.03501685 ... 0.0343147  0.01115606 0.01238718]
 [0.02143349 0.02351139 0.02553439 ... 0.02411135 0.01465337 0.01749526]
 [0.02180615 0.03308399 0.04023464 ... 0.02616625 0.0094197  0.01065532]
 ...
 [0.02212511 0.0352745  0.03321636 ... 0.02866844 0.00841903 0.01170038]
 [0.02266595 0.02610625 0.02405795 ... 0.02292197 0.01222046 0.01511292]
 [0.0224237  0.02836168 0.02528311 ... 0.02832135 0.01088213 0.0125143 ]]
Model's predictions for the sample 10:

+----------+-----------------+-------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef               |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |   There is no information provided about  |
|          |                 |    Fred being in the park. The context    |
|          |                 |   sentences only mention the bedroom and  |
|          |                 |    the office as possible locations for   |
|          |                 |                   Fred.                   |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |   There is no information provided about  |
|          |                 |    Bill being in the park. The context    |
|          |                 |   sentences only mention the kitchen and  |
|          |                 |    the cinema as possible locations for   |
|          |                 |                   Bill.                   |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |  According to sentence 8, Fred went back  |
|          |                 |   to the cinema, which implies that Fred  |
|          |                 |        is currently in the cinema.        |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |    There is no new information provided   |
|          |                 |     about Fred's location. The context    |
|          |                 |  sentences 10 and 11 only mention Mary's  |
|          |                 |      movements and do not update our      |
|          |                 |      knowledge about Fred's location.     |
|          |                 |  Previously, we knew that Fred went back  |
|          |                 |        to the cinema (sentence 8).        |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |     According to sentence 10, Mary was    |
|          |                 |     initially in the bedroom. However,    |
|          |                 |   sentence 14 states that Mary moved to   |
|          |                 |   the school, which implies that Mary is  |
|          |                 |         no longer in the bedroom.         |
+----------+-----------------+-------------------------------------------+

Metrics for sample 10:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 11/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 51/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred being in the cinema. Sentence 2 only mentions the bedroom as a possible location for Fred.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '2', ' only', ' mentions', ' the', ' bedroom', ' as', ' a', ' possible', ' location', ' for', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0909, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02848971 0.05244214 0.05604672 0.08877775 0.08220951 0.05809884
  0.04040949 0.03436876 0.03884894 0.05593527 0.03887439 0.02934921
  0.0285261  0.13078418 0.13459538 0.04325718 0.02764216 0.02291776
  0.01843093 0.02334912 0.02367362 0.04280499 0.07191485 0.02245075
  0.00357521 0.02313007]
 [0.02940047 0.03202426 0.0327506  0.06411412 0.0586241  0.04883715
  0.02829575 0.02455062 0.03071433 0.04829396 0.03281865 0.031336
  0.0282275  0.13758056 0.16195795 0.04086675 0.02969949 0.0265228
  0.02026002 0.02424143 0.02231345 0.03546735 0.04270128 0.0160695
  0.00330749 0.01529659]
 [0.02988765 0.03591881 0.04140892 0.06737644 0.06480882 0.06177905
  0.03740865 0.03415865 0.04043247 0.05693005 0.03823435 0.04973792
  0.04376721 0.10801875 0.09931332 0.0341961  0.02712538 0.02665894
  0.01982061 0.02430185 0.02094238 0.03230815 0.03877819 0.02007614
  0.00454321 0.0159737 ]
 [0.02876818 0.04173255 0.04736557 0.04911941 0.05353853 0.05465272
  0.0403484  0.04245814 0.0426742  0.04891531 0.03810937 0.0537824
  0.0451036  0.06288    0.05575054 0.04181135 0.03357424 0.03378946
  0.02589895 0.03138683 0.02865323 0.03663179 0.05267041 0.04228636
  0.01345432 0.03558225]
 [0.02893806 0.05624974 0.06036264 0.03762645 0.03241012 0.04717525
  0.04767258 0.04975026 0.0450532  0.03681946 0.03358493 0.04539691
  0.04443879 0.02560454 0.01925444 0.03934931 0.0301775  0.03100609
  0.02596661 0.03037744 0.02827481 0.03307857 0.06215735 0.04456486
  0.02820159 0.049136  ]
 [0.0299524  0.07405368 0.08064664 0.03527532 0.0260353  0.0435425
  0.05043336 0.04469585 0.05173561 0.03241983 0.02778167 0.03831166
  0.03471562 0.0194206  0.0162928  0.04626729 0.03073121 0.02955825
  0.02462079 0.0316889  0.02783991 0.03219996 0.07546292 0.04111638
  0.01389164 0.0296375 ]
 [0.02999108 0.04642991 0.05627224 0.03133792 0.0229022  0.04091678
  0.0458185  0.0428702  0.04472262 0.02953904 0.02576056 0.03822721
  0.0304642  0.01710456 0.01481866 0.0395325  0.02898339 0.0289628
  0.02410327 0.03000052 0.02833641 0.03297883 0.05506659 0.05144426
  0.01802224 0.03688966]
 [0.03016663 0.03518891 0.0360001  0.04571908 0.03883927 0.05315639
  0.03846538 0.03804809 0.04428873 0.0510963  0.03551893 0.05383912
  0.04167587 0.02939554 0.02042941 0.02329953 0.02234253 0.02854913
  0.02374029 0.02678416 0.02425452 0.03738846 0.03803349 0.02663109
  0.00937733 0.02802736]
 [0.03029937 0.03679276 0.03918111 0.03342301 0.02569226 0.04368486
  0.04053595 0.05036892 0.0423451  0.0377907  0.03204354 0.05776628
  0.04240829 0.01788674 0.0138789  0.03052184 0.02534765 0.02949604
  0.02496915 0.02751661 0.02769392 0.031678   0.02871933 0.02736636
  0.0194521  0.02702707]
 [0.02983564 0.02857238 0.02802199 0.0221113  0.01907731 0.0275921
  0.03691887 0.03468977 0.03090323 0.02538732 0.0327732  0.03500336
  0.03500183 0.0120104  0.01152976 0.04135456 0.03301412 0.03787201
  0.0354375  0.03826919 0.04779848 0.03150531 0.02460604 0.04160623
  0.02970141 0.02495116]
 [0.03008058 0.02086671 0.01825159 0.01638145 0.01417898 0.01665691
  0.02538601 0.02455996 0.02023911 0.01713095 0.02206678 0.01992843
  0.02299238 0.00840021 0.00871662 0.03263003 0.02717605 0.03920107
  0.04150498 0.04539909 0.05085574 0.02713251 0.01742152 0.04131739
  0.04371399 0.0280961 ]
 [0.03050595 0.02249515 0.01956362 0.01749716 0.0153153  0.01841371
  0.02463151 0.02645682 0.0209711  0.0195928  0.02544244 0.02498693
  0.02623869 0.00884014 0.00887156 0.03800462 0.03057889 0.03792614
  0.03907983 0.03982124 0.04082711 0.0256174  0.0152872  0.03208143
  0.04158441 0.02136017]
 [0.03045939 0.01802704 0.01587404 0.01314241 0.01234944 0.01442137
  0.02112697 0.02023979 0.01794867 0.01512256 0.02533766 0.01870748
  0.02077371 0.00697443 0.00743141 0.03466751 0.03225528 0.03351718
  0.04320251 0.03991801 0.04541673 0.02474055 0.01467844 0.03312359
  0.04489133 0.02398449]
 [0.02992036 0.0198127  0.01724634 0.01401036 0.01260386 0.01590084
  0.02265954 0.01964447 0.02040883 0.01513511 0.02581106 0.01795196
  0.02002213 0.00736447 0.00801903 0.03674197 0.03061308 0.03259693
  0.0393814  0.0365327  0.04130353 0.02581759 0.020251   0.05757034
  0.04873977 0.03627178]
 [0.03083559 0.02312404 0.02020914 0.01754704 0.01496798 0.01899685
  0.02345047 0.02378954 0.02228162 0.0196838  0.02574163 0.02346106
  0.02298562 0.00973524 0.0093203  0.02798343 0.02376924 0.03106669
  0.03902511 0.03621726 0.03928487 0.02715524 0.01726749 0.02371588
  0.02291873 0.02267124]
 [0.03021596 0.02778715 0.02740569 0.02919962 0.02438156 0.03522458
  0.02849724 0.03101745 0.03314645 0.03646956 0.02754308 0.04382592
  0.0367833  0.02028244 0.01454599 0.02409286 0.0278311  0.02897532
  0.02731578 0.02731291 0.02550478 0.03301971 0.02825858 0.02840558
  0.02256431 0.03785852]
 [0.03055537 0.0355587  0.03621832 0.02430613 0.02195599 0.02609154
  0.0404395  0.03075131 0.03345489 0.02369274 0.02339356 0.02509265
  0.0255874  0.01444906 0.01416147 0.03692367 0.02938936 0.02621902
  0.02564708 0.03003848 0.02754385 0.02946156 0.04454831 0.04895987
  0.01735904 0.03504554]
 [0.03079866 0.01625192 0.01678799 0.01199012 0.01192778 0.01360202
  0.01610271 0.01456205 0.01839436 0.01250067 0.01422348 0.01265495
  0.01347316 0.00721829 0.00779854 0.02088822 0.02109104 0.01950379
  0.02371898 0.02668739 0.02736247 0.01969126 0.03293039 0.06485567
  0.02782435 0.04487742]
 [0.03044549 0.02532692 0.02453419 0.01890883 0.01621721 0.02237864
  0.02706327 0.027714   0.02558593 0.0194657  0.02168048 0.02414825
  0.0265418  0.01154206 0.01065368 0.02882867 0.02991896 0.02498529
  0.02725605 0.02507279 0.02398772 0.03029717 0.02543781 0.03561286
  0.04508452 0.04706667]
 [0.03127333 0.02583811 0.02412241 0.02031386 0.01639874 0.02632775
  0.02836434 0.03412713 0.02801214 0.02290194 0.02409293 0.02904817
  0.03188847 0.01189123 0.00952152 0.02010981 0.0274993  0.02178663
  0.02440317 0.02195961 0.02043601 0.02887917 0.01746371 0.01866025
  0.04123532 0.03173095]
 [0.03083164 0.02046794 0.01908976 0.01634819 0.01345574 0.01928157
  0.02456721 0.02585566 0.02334124 0.01828107 0.02486679 0.02142013
  0.0263694  0.00975602 0.00843619 0.02271863 0.03062712 0.02256024
  0.02751837 0.02480013 0.02465199 0.02693585 0.01397995 0.02559137
  0.06870601 0.03711597]
 [0.03056868 0.01796029 0.01645565 0.01299608 0.01095584 0.01534933
  0.02152565 0.02121798 0.02022583 0.01510216 0.02639681 0.01715325
  0.0237541  0.00831985 0.0067999  0.02102636 0.03192074 0.02057835
  0.02762321 0.02531819 0.02565587 0.02449086 0.01178869 0.02570066
  0.08839693 0.06439275]
 [0.03098368 0.01667703 0.01518288 0.01329372 0.01094869 0.01471874
  0.01805647 0.01731921 0.0192459  0.01462987 0.02226371 0.01604963
  0.01877026 0.00802818 0.00650154 0.01583645 0.02565747 0.01845144
  0.02658606 0.02762941 0.02658489 0.022559   0.01111129 0.02054258
  0.06986054 0.06169092]
 [0.03144619 0.0196792  0.01800142 0.01466549 0.01226796 0.01765764
  0.02223192 0.02569341 0.02222406 0.01832029 0.02862874 0.02182625
  0.02661617 0.01034352 0.00704689 0.01770714 0.03001877 0.01979182
  0.02928523 0.02307593 0.02235462 0.02620544 0.01252804 0.01756638
  0.0512983  0.03438599]
 [0.0310363  0.02660051 0.02396263 0.01747055 0.01489222 0.02096772
  0.03178101 0.03682943 0.02698794 0.02333813 0.04673662 0.02746557
  0.03670667 0.01150881 0.00826119 0.025738   0.0419214  0.02686254
  0.03342462 0.0268681  0.02645183 0.02715859 0.01562941 0.02293231
  0.05717591 0.03017749]
 [0.03104651 0.02952538 0.02555405 0.01889387 0.01460493 0.02069249
  0.03638086 0.03850801 0.02824827 0.02352799 0.04123382 0.02642125
  0.03746163 0.01205612 0.00900374 0.0274073  0.03792394 0.02968187
  0.03463385 0.0298952  0.0293049  0.02831404 0.01775905 0.02690773
  0.04667105 0.02169214]
 [0.03150165 0.02471033 0.02493775 0.01909673 0.01488222 0.02147704
  0.03556313 0.03778311 0.03058446 0.0229851  0.0487388  0.02913842
  0.03769713 0.01149911 0.00841131 0.02656027 0.03204497 0.0275089
  0.02849578 0.02845222 0.02978983 0.02774134 0.01563276 0.02229609
  0.02508937 0.01458842]
 [0.03091612 0.02167654 0.02001649 0.01518759 0.01179057 0.01661895
  0.0278124  0.0246405  0.02417064 0.01673241 0.02216398 0.01767735
  0.02580825 0.00957659 0.00762353 0.02612676 0.03523171 0.03025793
  0.0333582  0.03078323 0.03285661 0.031026   0.01689045 0.02963119
  0.04177303 0.02333737]
 [0.03132794 0.02051274 0.01956545 0.0173791  0.01340857 0.0176376
  0.02316968 0.0219347  0.0236851  0.01853682 0.0216161  0.01886219
  0.02303407 0.0107592  0.00828875 0.0211102  0.02339959 0.02459869
  0.02832327 0.0288024  0.0315046  0.02598323 0.01528586 0.0251347
  0.02860012 0.02558585]
 [0.03014894 0.0332188  0.03241643 0.05187127 0.05481206 0.04372914
  0.02833755 0.0287097  0.03628547 0.05100843 0.03431586 0.0336206
  0.03470773 0.08911706 0.10402579 0.02924786 0.02594562 0.02734368
  0.02155322 0.02402277 0.02286984 0.03408829 0.03591456 0.01575334
  0.00361856 0.01830188]
 [0.02988251 0.03452401 0.03197726 0.05969286 0.11560874 0.04261875
  0.02427356 0.02524049 0.03201008 0.05863561 0.04006989 0.03350973
  0.028072   0.08885796 0.11116258 0.03563686 0.03847002 0.04205877
  0.02969708 0.02844153 0.02850043 0.03112116 0.03684946 0.01367732
  0.0033054  0.01525821]
 [0.02963071 0.02708975 0.02550475 0.04101681 0.06488028 0.02852955
  0.0187263  0.02301212 0.02812725 0.04831279 0.0371752  0.03444768
  0.02996164 0.03030866 0.03321442 0.02632994 0.04380017 0.07182548
  0.06170068 0.04760713 0.0423901  0.02785517 0.02965691 0.01889737
  0.00969297 0.02022606]
 [0.02985929 0.03286395 0.02906559 0.04391    0.06305788 0.03327164
  0.02354585 0.02443389 0.03270223 0.04576622 0.03496095 0.02985203
  0.02942529 0.03248544 0.0343629  0.02322703 0.03427843 0.04736899
  0.04401744 0.03742821 0.03478101 0.04866734 0.04331874 0.01745416
  0.00636951 0.01863275]]

-* TASK 10/20 | SAMPLE 11/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 52/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred at all. They only talk about Bill's movements.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Bill', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 32), x_tokens=32, y_tokens=26, max_supp_attn=0.0769, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 32)
DEBUG result.interpretability.attn_scores 832 
 [[0.03605101 0.04834184 0.04738972 0.07554376 0.07281931 0.05588663
  0.0374417  0.04173051 0.05243121 0.05918464 0.04472585 0.04303068
  0.04247519 0.11664463 0.11890278 0.03894162 0.03850577 0.03115013
  0.03237524 0.03300987 0.02851941 0.04093958 0.0545603  0.02711321
  0.01453552 0.04249703 0.04341546 0.04997268 0.10805076 0.01456259
  0.02119279 0.00911446]
 [0.03711873 0.04881138 0.04630167 0.08755966 0.09892853 0.08955625
  0.04515446 0.04787683 0.056903   0.08313812 0.06314369 0.07126404
  0.06405132 0.16708434 0.13288005 0.04160793 0.03734009 0.03437033
  0.03326533 0.03393779 0.02950568 0.04406669 0.0418066  0.02292496
  0.01684818 0.03460627 0.04688759 0.03968789 0.09557033 0.0193994
  0.02779393 0.01464348]
 [0.03785215 0.04428735 0.04658314 0.07447927 0.07244729 0.06433852
  0.03858935 0.04167326 0.0513086  0.06114058 0.04579352 0.05565382
  0.0473861  0.1270102  0.09453847 0.03675822 0.03569416 0.02814683
  0.02983708 0.02968808 0.02558559 0.04017358 0.03975849 0.0243829
  0.01699938 0.03258063 0.0419155  0.03427585 0.08134722 0.02369693
  0.03710384 0.01486474]
 [0.03665571 0.04009076 0.0429633  0.04181743 0.03660389 0.04205537
  0.03606259 0.04213505 0.0418907  0.03845179 0.03515355 0.0436209
  0.03952796 0.03167016 0.03100523 0.03473683 0.03829983 0.03012021
  0.03385364 0.03542552 0.0313328  0.04075934 0.04965812 0.04220331
  0.03326004 0.0484622  0.04563762 0.04631462 0.06551271 0.05422293
  0.06909674 0.03063463]
 [0.036978   0.0522882  0.05234966 0.03143184 0.02448755 0.03658592
  0.03974659 0.03970591 0.04756173 0.02910778 0.02969066 0.0341657
  0.03323174 0.02254772 0.02326913 0.03689842 0.03478944 0.02571006
  0.03138863 0.03188373 0.02942857 0.04071428 0.06209538 0.03941909
  0.03704872 0.0484111  0.05983167 0.03427458 0.05863196 0.07688772
  0.05262681 0.04071963]
 [0.03792265 0.07149179 0.06749136 0.0314475  0.02472597 0.03859579
  0.04369874 0.03871173 0.0524747  0.02832986 0.02769209 0.03276162
  0.0299832  0.01934695 0.02176124 0.04388106 0.03994419 0.02827121
  0.03375711 0.03673354 0.03097883 0.03677305 0.0857024  0.04222186
  0.03209074 0.04321234 0.04802644 0.02831815 0.04168259 0.07584695
  0.04956724 0.03049132]
 [0.03795889 0.04215121 0.04624706 0.03005649 0.02310429 0.03658029
  0.03842176 0.03874226 0.0436119  0.02986126 0.02762064 0.03610653
  0.03059966 0.01926127 0.01978112 0.03454741 0.03465031 0.02642069
  0.03275322 0.03355225 0.03104713 0.03552087 0.05323685 0.0434536
  0.03524294 0.04281636 0.04472098 0.02931661 0.03388815 0.0762406
  0.06683176 0.04398197]
 [0.0382049  0.02628697 0.02655292 0.02537582 0.02269733 0.029108
  0.02479194 0.0261901  0.02774417 0.02827207 0.02592421 0.02996026
  0.02647838 0.01630834 0.01753449 0.02193368 0.02674684 0.02360472
  0.0304132  0.02962382 0.03028925 0.03341897 0.03240785 0.02834849
  0.03636039 0.05190888 0.0349157  0.04170644 0.03331325 0.06891674
  0.0559672  0.03731019]
 [0.03855825 0.03369008 0.03608492 0.03243596 0.02530558 0.03870417
  0.03481119 0.03935289 0.03804235 0.03761608 0.02920276 0.04799262
  0.0400994  0.02139027 0.01980376 0.02655096 0.03141504 0.02708202
  0.03054021 0.02934065 0.0274296  0.03599287 0.03299003 0.02758241
  0.04049899 0.04189029 0.04424877 0.03623461 0.0328167  0.0741488
  0.06234967 0.05541213]
 [0.03815337 0.03088206 0.02953841 0.02370079 0.02118459 0.02816781
  0.0344744  0.03238222 0.02738999 0.02723409 0.03252009 0.0332196
  0.03696341 0.01688311 0.0177499  0.03405577 0.04259388 0.0357385
  0.04186438 0.0393681  0.04295427 0.03761693 0.02601527 0.04354196
  0.05928256 0.03922917 0.03355462 0.04330906 0.02239605 0.05712508
  0.04301628 0.06482203]
 [0.03844009 0.02804933 0.0268862  0.01992137 0.01820843 0.02410442
  0.03692134 0.03314168 0.02478645 0.0226021  0.03099106 0.02710153
  0.03183778 0.01376407 0.01585452 0.03534687 0.03870384 0.03572637
  0.04235718 0.04146464 0.04715635 0.03513314 0.02437276 0.05014244
  0.08137239 0.04034578 0.02684648 0.0483497  0.02037492 0.05718781
  0.03723413 0.07345121]
 [0.0397952  0.02870577 0.0312244  0.02038206 0.02116198 0.02750629
  0.04345293 0.04134505 0.0329699  0.02498922 0.03114825 0.0309122
  0.03688029 0.01577576 0.01632869 0.03572136 0.03897895 0.03021956
  0.03933841 0.03619552 0.04145174 0.03306657 0.03013159 0.04182248
  0.05869791 0.04496442 0.03019361 0.03709316 0.02288731 0.03641319
  0.03401895 0.0493639 ]
 [0.03998253 0.02732338 0.03047802 0.02330272 0.02249796 0.03055629
  0.033381   0.03155024 0.03707301 0.02824762 0.02912927 0.03353951
  0.03168366 0.0183978  0.01743098 0.02721895 0.02887618 0.02403625
  0.03193935 0.03005184 0.03012035 0.03674134 0.02901095 0.03062552
  0.03295907 0.04322511 0.0339435  0.03293015 0.02872891 0.03580383
  0.0533192  0.04338231]
 [0.0385432  0.03023489 0.03200017 0.02812876 0.0262716  0.0322157
  0.03261644 0.03342219 0.03630872 0.03362865 0.02996421 0.03602388
  0.03521793 0.02214433 0.0205425  0.02925778 0.03218691 0.02754238
  0.03122504 0.03115947 0.03091714 0.03923542 0.03219981 0.03737444
  0.02786718 0.03994235 0.0370823  0.03766172 0.03710883 0.03653289
  0.08693948 0.0394436 ]
 [0.03956579 0.03721478 0.04213151 0.02626365 0.02355236 0.03249438
  0.04352156 0.04151297 0.03488786 0.02776975 0.03095023 0.03295803
  0.03535299 0.01786126 0.0179472  0.03780319 0.03329914 0.02875583
  0.03251038 0.03186304 0.0335932  0.03848388 0.03361766 0.04041579
  0.03507301 0.0342582  0.04519319 0.02238843 0.02456224 0.03988757
  0.03995211 0.04790056]
 [0.03987219 0.03751443 0.04049313 0.02690548 0.02325844 0.03408765
  0.04862457 0.04913816 0.03405729 0.02917224 0.03230166 0.03482983
  0.04066737 0.01854676 0.01746333 0.03741997 0.03207451 0.02876873
  0.03051989 0.03008234 0.03214502 0.03763139 0.03027845 0.0384489
  0.03719416 0.03213356 0.04355435 0.02272422 0.02488621 0.04102501
  0.04016479 0.06798757]
 [0.04032792 0.04125845 0.04745134 0.0312999  0.02840301 0.03747404
  0.05414258 0.05051206 0.04080745 0.03263957 0.03705413 0.03750089
  0.04212021 0.02213246 0.01989109 0.03905752 0.03266168 0.02823936
  0.03133376 0.03175848 0.0310978  0.03813399 0.03367011 0.03745397
  0.03001424 0.03122665 0.04185995 0.02393382 0.02516519 0.03144101
  0.02986648 0.0405411 ]
 [0.03904631 0.03275407 0.03003552 0.01931979 0.01803989 0.02287851
  0.04169074 0.03673865 0.02653872 0.02019053 0.03601912 0.02353979
  0.03458242 0.01327104 0.0147794  0.05117837 0.04292165 0.03463274
  0.03736519 0.03546255 0.04388766 0.03576647 0.02467609 0.06485965
  0.05311353 0.03066888 0.02372156 0.02751048 0.01699807 0.02902276
  0.02461375 0.04702055]
 [0.03874112 0.02854668 0.02641149 0.02016513 0.01669363 0.02170046
  0.03353424 0.03160176 0.02515306 0.02018164 0.03612323 0.02371384
  0.02988623 0.01347801 0.01442102 0.05761204 0.04208689 0.04325509
  0.04362931 0.04265722 0.05291899 0.03597757 0.02086396 0.0609188
  0.05774749 0.03160985 0.02015222 0.03048233 0.01708118 0.03038999
  0.02737408 0.05786486]
 [0.03881639 0.04747997 0.03961513 0.02620327 0.02024117 0.02728814
  0.05376429 0.05471393 0.03445704 0.0250559  0.05988147 0.03175329
  0.04688912 0.01596031 0.01802935 0.07608929 0.05228635 0.05898298
  0.04770072 0.05037793 0.05162649 0.03935279 0.02661056 0.07140182
  0.07427599 0.02943412 0.02908253 0.02793848 0.01712777 0.02730221
  0.02264063 0.0737806 ]
 [0.0397619  0.03103034 0.03066427 0.02308804 0.01818171 0.0256625
  0.03557257 0.03459955 0.02942188 0.02304218 0.0429845  0.02792512
  0.03386552 0.01556483 0.01552914 0.05179152 0.04417064 0.04454515
  0.04446452 0.04701911 0.04627584 0.03306184 0.02062445 0.05671994
  0.05948704 0.02976729 0.02255493 0.02698962 0.0164957  0.02520017
  0.02839793 0.05308511]
 [0.03835366 0.0341411  0.03621935 0.05176917 0.04787342 0.046693
  0.03630043 0.03557846 0.04635628 0.0570109  0.04215568 0.04461368
  0.0459298  0.06775784 0.0890393  0.03228051 0.03515887 0.0440044
  0.04070707 0.04029711 0.03878302 0.04023616 0.03778993 0.0233482
  0.01504672 0.03728442 0.03630455 0.05006553 0.04582861 0.01342356
  0.02125816 0.0106834 ]
 [0.0377221  0.04472138 0.03973416 0.08131578 0.14136553 0.05955873
  0.03514    0.03538573 0.04236915 0.08111329 0.06103081 0.05505971
  0.04293061 0.08535149 0.11217775 0.04268593 0.05427892 0.0868947
  0.05903811 0.05592259 0.05553997 0.04084696 0.04836789 0.02370606
  0.01585169 0.03563772 0.05185967 0.05138198 0.0429012  0.00913082
  0.01321839 0.00778689]
 [0.03800974 0.03853693 0.03246648 0.04447421 0.05283095 0.03633679
  0.03112081 0.03326953 0.03580956 0.04746685 0.04925171 0.04477801
  0.04287867 0.03338655 0.04154947 0.03775334 0.05647429 0.08246256
  0.06370596 0.06646518 0.05711887 0.03762193 0.04090449 0.02993543
  0.04314574 0.04440452 0.03849893 0.05657525 0.02743513 0.01449538
  0.01725991 0.01644248]
 [0.03868277 0.03989615 0.03771349 0.057161   0.05929299 0.04242272
  0.03330439 0.03645242 0.04116577 0.0587379  0.04825549 0.04913222
  0.04211328 0.03665981 0.03799289 0.03152717 0.04240209 0.06903948
  0.05161668 0.05165545 0.05365042 0.0418427  0.0437839  0.02722543
  0.03231971 0.03662766 0.04199883 0.05811555 0.02707939 0.01567506
  0.01757388 0.01439959]
 [0.03888549 0.03427084 0.03497306 0.04645114 0.03982258 0.03944169
  0.0337194  0.03253678 0.03847938 0.04581542 0.04129215 0.03884274
  0.03636773 0.03180066 0.03379719 0.02734419 0.03345949 0.04227978
  0.04250044 0.04500425 0.04664596 0.05089167 0.04486609 0.0244094
  0.02366665 0.03285526 0.03399906 0.062449   0.03212958 0.01602102
  0.02062194 0.01487165]]

-* TASK 10/20 | SAMPLE 11/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 53/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Fred is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.04969424 0.05969629 0.06609438 0.07991881 0.06816296 0.07870872
  0.06094789 0.05935759 0.07622592 0.07031134 0.05110253 0.05731215
  0.06523902 0.12847452 0.1127525  0.04575891 0.03933403 0.03891068
  0.03148478 0.03758078 0.03493502 0.05105617 0.07810082 0.03689397
  0.01519858 0.05183427 0.0596473  0.06097935 0.12604854 0.02499773
  0.0265112  0.01428195 0.01099922 0.06226415 0.07804399 0.05373868
  0.03340378 0.05748741]
 [0.05075483 0.06697578 0.06386019 0.05567608 0.04675529 0.07327884
  0.08523016 0.08926328 0.06773103 0.05572651 0.05404243 0.0710435
  0.09382518 0.0513184  0.06117516 0.04381606 0.03886416 0.04719709
  0.04193078 0.04990137 0.0398059  0.05434288 0.05826255 0.04904779
  0.0502508  0.07305198 0.04187414 0.05681746 0.09006878 0.05298048
  0.05537633 0.05271692 0.06827342 0.04319628 0.05760106 0.05630671
  0.04094372 0.05727685]
 [0.05192295 0.06604222 0.07569027 0.09706986 0.0894238  0.10888925
  0.06970073 0.06411894 0.08155739 0.08406888 0.05979601 0.07481557
  0.07817154 0.17187642 0.11418308 0.04796687 0.03455674 0.0340566
  0.02772881 0.03277884 0.02981378 0.05297296 0.06774241 0.03743322
  0.01382289 0.04252116 0.05899032 0.04344016 0.11502928 0.03912337
  0.04835691 0.02151293 0.01682302 0.06710703 0.06180548 0.04404336
  0.02907348 0.04239415]
 [0.05028936 0.06723584 0.07087819 0.05239459 0.04217414 0.06118155
  0.06046658 0.06522291 0.06701076 0.05416119 0.04658227 0.05581834
  0.05795804 0.04490224 0.03875521 0.05506495 0.04284305 0.03979452
  0.03568237 0.04046319 0.03693908 0.05781943 0.08148579 0.06939901
  0.03370541 0.0604506  0.07503458 0.0520945  0.09186191 0.09675351
  0.1343504  0.04576839 0.04002477 0.04609874 0.05926387 0.07578187
  0.05659622 0.05558281]
 [0.05213681 0.06565992 0.06850259 0.03936076 0.02872432 0.04814929
  0.06464538 0.05372932 0.06356865 0.03859729 0.04094053 0.04029275
  0.04186001 0.02988073 0.0304772  0.05836339 0.04062944 0.0359978
  0.03768695 0.04355506 0.03875238 0.05062411 0.0828789  0.07393961
  0.03091484 0.06084625 0.09080222 0.03820424 0.05157952 0.08217663
  0.17509541 0.05719805 0.03392642 0.03548032 0.05714964 0.09728238
  0.08203736 0.06161245]
 [0.05335181 0.03439922 0.0332234  0.02182767 0.01773735 0.02624442
  0.03202784 0.03088099 0.03796818 0.02297684 0.02985212 0.02468705
  0.02614198 0.0162135  0.01801983 0.03773241 0.03120028 0.02897154
  0.03425582 0.03751512 0.03169428 0.03949546 0.03762598 0.05265405
  0.02705178 0.04699198 0.04560858 0.02699273 0.02394562 0.03311798
  0.07662109 0.03386164 0.02211526 0.02070085 0.02747472 0.05280903
  0.06621037 0.04827784]
 [0.05208852 0.05576203 0.05488214 0.03645791 0.02562927 0.04870809
  0.05235763 0.05615402 0.0531844  0.04084706 0.04291098 0.05181093
  0.04940184 0.02613888 0.02548444 0.052869   0.04569033 0.04427879
  0.0489306  0.04895724 0.04281795 0.05783326 0.05754251 0.0672551
  0.06630325 0.06682273 0.07081605 0.04423555 0.05009248 0.09432168
  0.08429703 0.10257716 0.08645163 0.03193687 0.05055662 0.07570625
  0.07158516 0.05547992]
 [0.05346299 0.06687132 0.06969909 0.05717697 0.03658927 0.06811064
  0.06738343 0.07186712 0.0647486  0.06219907 0.06119282 0.08360483
  0.07179545 0.03991611 0.03306141 0.06055534 0.05103577 0.05182125
  0.0482601  0.04994044 0.04497592 0.05839438 0.0566855  0.06136262
  0.06472956 0.05694692 0.07060858 0.05408678 0.04971476 0.10001514
  0.06508878 0.10340548 0.10383541 0.04002066 0.05588516 0.06508869
  0.05536741 0.04526302]
 [0.05433333 0.05038298 0.05305258 0.041155   0.02842171 0.0478549
  0.05558017 0.05237475 0.04725572 0.04440027 0.051484   0.05064426
  0.05194905 0.0275707  0.02580094 0.05580628 0.04854229 0.04398707
  0.04792716 0.0487259  0.04422697 0.05675333 0.04507291 0.05795297
  0.06101913 0.04800967 0.0514177  0.04821252 0.04096838 0.07399885
  0.05164715 0.07959491 0.07561012 0.0400163  0.04294443 0.05102091
  0.05593266 0.03842703]
 [0.05364581 0.03905142 0.03739808 0.02884773 0.01971782 0.03062212
  0.04103568 0.04108096 0.03522101 0.0320176  0.04264998 0.03568782
  0.04098089 0.01832336 0.0197305  0.05806626 0.05906375 0.04876197
  0.05881938 0.05536138 0.0501481  0.05528577 0.03496496 0.06444087
  0.07801414 0.04603363 0.03762102 0.046547   0.03040391 0.05745551
  0.03377269 0.06444219 0.06149748 0.03450794 0.03648923 0.04637415
  0.06284345 0.03990094]
 [0.0532237  0.04162314 0.03743071 0.03136512 0.01983467 0.03130086
  0.04801627 0.04570345 0.03460208 0.03217532 0.04487856 0.03666756
  0.04470672 0.01781844 0.01855155 0.06309144 0.0551925  0.0618157
  0.07789522 0.07723426 0.06455696 0.05199906 0.03177957 0.06903202
  0.10936624 0.04260468 0.03571923 0.04640515 0.02254542 0.06309445
  0.0267156  0.06813891 0.08799374 0.03084422 0.03605172 0.0536601
  0.07919391 0.05208226]
 [0.05428407 0.03912033 0.03678243 0.03046118 0.02149155 0.03082928
  0.04030893 0.04297059 0.03480839 0.0346334  0.04880224 0.0419518
  0.04197916 0.01832156 0.01862355 0.05557518 0.0653564  0.04876089
  0.08308238 0.05996324 0.05648653 0.05053317 0.02682734 0.04785319
  0.11530624 0.0437103  0.03720609 0.04352375 0.02095743 0.05327222
  0.02799948 0.08003102 0.08308703 0.02648455 0.03172845 0.03778344
  0.05059966 0.04524866]
 [0.05427727 0.03575731 0.03340831 0.02610861 0.01929836 0.0258628
  0.04027068 0.03869351 0.03246659 0.02814596 0.05197159 0.03562273
  0.03951246 0.01491692 0.01606783 0.05924377 0.06571021 0.05062292
  0.08149051 0.06474954 0.05999932 0.04905639 0.02534031 0.05655428
  0.10296835 0.04557424 0.02845781 0.04598719 0.01842622 0.04691654
  0.02765096 0.08245745 0.11430307 0.0241333  0.03299293 0.04045821
  0.06172279 0.06227763]
 [0.05257379 0.04280786 0.03683681 0.02902851 0.02038297 0.03189509
  0.05043557 0.04467397 0.04147906 0.03065464 0.05668403 0.04138432
  0.0478851  0.01663186 0.01833712 0.05896965 0.06699345 0.06236553
  0.08929148 0.08615036 0.06305906 0.05292938 0.03687659 0.06569351
  0.09788635 0.07190021 0.03250346 0.06214964 0.02530892 0.04453821
  0.03419469 0.06561296 0.06803977 0.02857623 0.043693   0.0507051
  0.07231507 0.08503954]
 [0.05453321 0.03977382 0.03984763 0.03670009 0.02409822 0.03445465
  0.04024837 0.04343453 0.03723705 0.03596362 0.04659947 0.04317855
  0.04082954 0.02324277 0.02069899 0.03855778 0.03592141 0.03634917
  0.04244406 0.04409278 0.0420419  0.04831633 0.02827134 0.03934683
  0.03761179 0.04376745 0.03143154 0.04130729 0.03264098 0.04249604
  0.0441935  0.0647788  0.07196514 0.04447175 0.03606563 0.03273635
  0.04579995 0.0501968 ]
 [0.05250993 0.0502874  0.05487996 0.07929117 0.0677345  0.07165151
  0.04939326 0.05066798 0.06174444 0.08038175 0.05903881 0.06198385
  0.06158404 0.1148163  0.1212845  0.04333485 0.04065471 0.04668847
  0.0340038  0.04086804 0.04085507 0.05057173 0.0537486  0.03292259
  0.01614733 0.04694582 0.05245505 0.05992938 0.06742242 0.02857532
  0.03317832 0.01679911 0.01406591 0.11780922 0.06065353 0.03826531
  0.03332268 0.05051982]
 [0.0521543  0.06599999 0.0642409  0.11715786 0.24475144 0.08169897
  0.05135675 0.05275064 0.06042695 0.10917646 0.08472345 0.0785092
  0.05125026 0.13361032 0.17660761 0.06027922 0.07325336 0.08538333
  0.04887049 0.05216947 0.07394212 0.04954209 0.07227006 0.03443175
  0.01589983 0.04632377 0.07710927 0.06360237 0.06376345 0.01960408
  0.01655761 0.01149551 0.00922345 0.12028344 0.0802012  0.03827866
  0.02836815 0.05168507]
 [0.05222891 0.0535704  0.04881699 0.06447332 0.1010939  0.04401419
  0.03900844 0.0448907  0.04485602 0.07093628 0.06643301 0.05987749
  0.04484519 0.04490945 0.06612518 0.05849245 0.09949476 0.12004941
  0.07750332 0.06849167 0.12917027 0.04843367 0.05522782 0.04577107
  0.04180073 0.05410045 0.05518672 0.07632995 0.03539797 0.02484833
  0.02051568 0.02053973 0.01691648 0.08059362 0.05712562 0.04847513
  0.04046695 0.05171857]
 [0.05253423 0.05898279 0.05447533 0.07552872 0.07797842 0.05654489
  0.05158626 0.05216479 0.05790781 0.07262658 0.06031515 0.05510733
  0.05008453 0.06111754 0.06426339 0.04645621 0.06566341 0.0741873
  0.05271202 0.06150135 0.07577926 0.06404042 0.06929598 0.03801554
  0.02200277 0.05156391 0.04751037 0.08915504 0.04382414 0.02171389
  0.01787728 0.01478685 0.01484865 0.10547458 0.09427365 0.04148572
  0.03421725 0.04952923]]

-* TASK 10/20 | SAMPLE 11/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 54/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 explicitly states that Mary went back to the kitchen, implying that she is now in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' kitchen', ',', ' implying', ' that', ' she', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03217521 0.04490597 0.0478925  ... 0.03014905 0.03188963 0.0507666 ]
 [0.03263774 0.04736073 0.04571675 ... 0.06209192 0.0392676  0.02889667]
 [0.03339042 0.04981094 0.0548573  ... 0.0421632  0.04196458 0.0451889 ]
 ...
 [0.0337242  0.04999784 0.04550801 ... 0.01818813 0.03973176 0.10384285]
 [0.03392995 0.03962037 0.03324435 ... 0.01757688 0.01990275 0.08130399]
 [0.03398501 0.04259253 0.03510698 ... 0.01642297 0.01827148 0.11137754]]

-* TASK 10/20 | SAMPLE 11/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 55/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred at all. They only talk about Julie's movements.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Julie', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 50), x_tokens=50, y_tokens=26, max_supp_attn=0.0, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 50)
DEBUG result.interpretability.attn_scores 1300 
 [[0.03630873 0.04279985 0.04303475 ... 0.02862244 0.04277567 0.03993919]
 [0.03698473 0.0411575  0.04339072 ... 0.03040132 0.03679528 0.02629951]
 [0.03778632 0.04475053 0.04849673 ... 0.0192693  0.03844339 0.02575923]
 ...
 [0.03840481 0.03528285 0.03276812 ... 0.06381661 0.06486446 0.0619788 ]
 [0.03880079 0.04570018 0.04174083 ... 0.02572715 0.03317422 0.04543151]
 [0.03857972 0.04068473 0.03750309 ... 0.02628215 0.03657815 0.05347817]]
Model's predictions for the sample 11:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Fred being in the cinema. Sentence 2    |
|          |                 |  only mentions the bedroom as a possible   |
|          |                 |             location for Fred.             |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |    The context sentences do not mention    |
|          |                 |  Fred at all. They only talk about Bill's  |
|          |                 |                 movements.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Fred   |
|          |                 |             is in the school.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 11 explicitly states that Mary   |
|          |                 |  went back to the kitchen, implying that   |
|          |                 |         she is now in the kitchen.         |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |    The context sentences do not mention    |
|          |                 |     Fred at all. They only talk about      |
|          |                 |             Julie's movements.             |
+----------+-----------------+--------------------------------------------+

Metrics for sample 11:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.08 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 12/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 56/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Julie went to the school, which implies that she is currently in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' went', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02717428 0.04625931 0.05901215 0.0685867  0.07165725 0.07150596
  0.0730227  0.08307313 0.06007914 0.06195492 0.0479273  0.06561495
  0.07480256 0.08244583 0.05150864 0.03267757 0.03128394 0.0337946
  0.03111114 0.0330807  0.02707383 0.03890384 0.04140188 0.02191537
  0.01649691 0.0278576 ]
 [0.0270147  0.07911958 0.05462068 0.05022593 0.04096195 0.05005972
  0.12234334 0.0743064  0.05852535 0.04444524 0.0507721  0.04192682
  0.05793995 0.02166976 0.021463   0.03802444 0.03641757 0.04888403
  0.04393091 0.05019513 0.0463738  0.04459608 0.04812444 0.04289368
  0.03322942 0.03770768]
 [0.02776081 0.05730704 0.04809859 0.07188781 0.05915159 0.05692072
  0.03799551 0.03364886 0.0386429  0.04772107 0.03756592 0.030805
  0.02980966 0.10753355 0.10437563 0.03173889 0.02512261 0.02252948
  0.0225727  0.02238635 0.01999036 0.04135224 0.04422693 0.01270811
  0.00915865 0.02200869]
 [0.02978559 0.05732714 0.03669755 0.05324327 0.0367001  0.03672437
  0.03059509 0.02249445 0.02230687 0.03363014 0.02718149 0.01717953
  0.0180844  0.02722299 0.03640851 0.02318244 0.01380642 0.01308177
  0.01603682 0.01620018 0.01450471 0.04373093 0.05135708 0.00737437
  0.00539961 0.01165337]
 [0.02817098 0.02497988 0.02825806 0.02138622 0.01541477 0.02294878
  0.02382149 0.02057761 0.02367886 0.02194177 0.02367432 0.02273638
  0.02076014 0.01105581 0.01068526 0.02805929 0.02820665 0.03013438
  0.03592856 0.03780398 0.03368813 0.02937035 0.03906314 0.04704902
  0.06619368 0.05890453]
 [0.02829893 0.04143086 0.04701619 0.06471538 0.06011295 0.04783652
  0.03269865 0.03002429 0.03430111 0.04577729 0.03438266 0.02685063
  0.02571039 0.09495852 0.09862579 0.03655002 0.02647905 0.02000262
  0.02146988 0.02213414 0.02045508 0.03791253 0.06076724 0.01248148
  0.008201   0.02651829]
 [0.02890834 0.02703188 0.02859987 0.04895711 0.04560379 0.04255847
  0.02392241 0.02361839 0.02898644 0.04252862 0.03125883 0.03015801
  0.02771325 0.10727924 0.12631536 0.03625374 0.02985677 0.02399626
  0.02392207 0.02326754 0.01947361 0.03188996 0.03551451 0.00905701
  0.00628667 0.01673261]
 [0.02929964 0.03062436 0.03709958 0.05180284 0.04906355 0.05317583
  0.0316478  0.03230348 0.03766007 0.0505767  0.03661725 0.04762107
  0.04247494 0.08513813 0.07907897 0.03127372 0.02767066 0.02435623
  0.0228405  0.02275754 0.01850195 0.02893163 0.03347884 0.0129966
  0.00880621 0.0163861 ]
 [0.02828349 0.03879364 0.04650917 0.04046991 0.04417597 0.04840979
  0.0362984  0.04088681 0.03969106 0.04354624 0.03664515 0.05078232
  0.04293142 0.0514821  0.04670256 0.04031365 0.036464   0.03192972
  0.02862486 0.02916185 0.02637601 0.03311101 0.04709661 0.02977775
  0.03094405 0.03294728]
 [0.02948147 0.03933866 0.04869432 0.04609381 0.04317592 0.05577897
  0.04016295 0.04594398 0.04763325 0.04931324 0.0362897  0.05333779
  0.04707691 0.03853367 0.025675   0.02818993 0.02693909 0.02578712
  0.02469977 0.02482095 0.02071375 0.03348317 0.03545578 0.01815755
  0.0135162  0.02244682]
 [0.028701   0.05031491 0.05433828 0.02822084 0.02386679 0.03699904
  0.04281276 0.0420566  0.04416351 0.03010991 0.02937241 0.03811609
  0.03803189 0.01677654 0.01475422 0.04579412 0.03616387 0.03066816
  0.03138833 0.03240951 0.03068722 0.03378793 0.06641968 0.03972811
  0.03506268 0.03622731]
 [0.0292716  0.03955383 0.04608679 0.02354281 0.02122959 0.02706691
  0.04440802 0.03442164 0.04085853 0.02416711 0.02432456 0.02733837
  0.02681608 0.01317048 0.01309377 0.04533084 0.03409338 0.02841566
  0.03092536 0.03347478 0.0296234  0.0296537  0.05449224 0.04226438
  0.04150482 0.03362941]
 [0.02961568 0.0143759  0.0166389  0.0108154  0.01020636 0.01393828
  0.01559243 0.01605389 0.02157543 0.01333486 0.01363927 0.01433865
  0.01427027 0.00608189 0.00640901 0.01987374 0.0194293  0.01852313
  0.02390675 0.02643792 0.02706373 0.01963617 0.03623458 0.0527142
  0.07193571 0.06227618]
 [0.02937813 0.02395164 0.02570342 0.01542991 0.01477538 0.01988531
  0.02263639 0.02137051 0.02315762 0.01720382 0.02110369 0.02058871
  0.02040623 0.00850151 0.00917586 0.03437582 0.0280323  0.02501336
  0.02560199 0.02643487 0.02667988 0.02741263 0.03053633 0.04494423
  0.06975909 0.05093757]
 [0.02956264 0.02283481 0.02383892 0.01745273 0.01590512 0.02276216
  0.02469365 0.02643999 0.02501676 0.02105564 0.02535208 0.02801533
  0.02806153 0.0097436  0.00896372 0.03259381 0.03606547 0.03220746
  0.02905867 0.02894676 0.03184947 0.02792339 0.02157782 0.03380249
  0.05979732 0.03133266]
 [0.02908603 0.01859009 0.01643626 0.01335845 0.01101299 0.01478239
  0.01868574 0.01928815 0.01817102 0.0152186  0.0205141  0.01775283
  0.02071957 0.00655101 0.00677388 0.03058041 0.02923344 0.03989272
  0.03080332 0.03977688 0.04654952 0.02531049 0.01683926 0.04778141
  0.0917448  0.0463223 ]
 [0.02976167 0.01695058 0.01649974 0.01292199 0.01125873 0.01588298
  0.01922922 0.02033492 0.01871499 0.01596038 0.02397275 0.02098277
  0.02166521 0.00652597 0.00646736 0.02911542 0.02632867 0.03591066
  0.02995496 0.04160436 0.04081412 0.02093623 0.01463561 0.04107299
  0.07086838 0.03317314]
 [0.02973414 0.01550316 0.01415344 0.0102195  0.00880925 0.01288076
  0.0168155  0.01661753 0.01700498 0.01266168 0.02466666 0.01681857
  0.01854087 0.00539574 0.00561333 0.03109729 0.02825801 0.03486739
  0.03423579 0.04061791 0.03734107 0.02159008 0.0149005  0.04757215
  0.04817494 0.04404279]
 [0.02907562 0.01971512 0.0173738  0.01223556 0.01088557 0.01525038
  0.02038377 0.01913605 0.0219589  0.01449683 0.02120195 0.01690912
  0.0196691  0.00642191 0.00673912 0.02796017 0.02458599 0.02681544
  0.03274956 0.0322951  0.04005475 0.02482778 0.02261798 0.0790041
  0.04957611 0.06223354]
 [0.03028571 0.02061454 0.01996261 0.01498671 0.01253183 0.01760278
  0.02000324 0.02174963 0.02209525 0.01730101 0.02393029 0.02219743
  0.02235161 0.00813979 0.00747349 0.02377609 0.02366499 0.0251812
  0.03014766 0.02847032 0.02751447 0.02587868 0.01642637 0.02785932
  0.02352519 0.03093989]
 [0.03047406 0.0217001  0.0248139  0.02037819 0.01684601 0.02459967
  0.02366595 0.03147926 0.02550533 0.02504895 0.02768858 0.0351066
  0.03102694 0.011762   0.00850153 0.01986189 0.02109941 0.02384076
  0.02348479 0.02189058 0.02183229 0.0272312  0.01506553 0.01957461
  0.01672631 0.02071881]
 [0.03058203 0.02644963 0.02882286 0.02489541 0.01861855 0.02965857
  0.03004143 0.04044059 0.02824505 0.03088742 0.03574501 0.04427496
  0.04050927 0.01394455 0.00965533 0.02274205 0.022998   0.02684646
  0.02413354 0.02273974 0.02186083 0.02848328 0.01662371 0.01788758
  0.01280417 0.01502048]
 [0.03044689 0.02410875 0.02537626 0.0231496  0.01858328 0.02658744
  0.02716755 0.03438138 0.02788714 0.02927094 0.03363051 0.0389854
  0.03799019 0.01318216 0.01001767 0.02616172 0.0263585  0.03008167
  0.0267972  0.02472282 0.02409672 0.02849225 0.01419101 0.01801664
  0.01541384 0.0139025 ]
 [0.03029407 0.01825653 0.0180151  0.01408542 0.01098796 0.01635863
  0.01965974 0.02300554 0.02126155 0.01752112 0.02384537 0.02302803
  0.02524038 0.00770796 0.00686509 0.02622825 0.02965566 0.03050481
  0.02894256 0.02722861 0.03134967 0.02701424 0.01199029 0.02427981
  0.02777353 0.01916724]
 [0.03043043 0.01803912 0.01671215 0.01321657 0.00972738 0.01418137
  0.01899035 0.02048367 0.01983559 0.01540726 0.02135844 0.01923915
  0.02258492 0.00667233 0.00603466 0.02623741 0.02650242 0.03146622
  0.02930325 0.02928693 0.03505493 0.02216757 0.01152101 0.0321147
  0.02709155 0.02192071]
 [0.03062066 0.01877474 0.01740391 0.01395976 0.01117341 0.01545614
  0.01903664 0.02207843 0.02107123 0.01784556 0.02483893 0.02268705
  0.02409299 0.00766288 0.00659565 0.02618542 0.03076978 0.02966489
  0.03301884 0.02828167 0.03027543 0.02363545 0.01184287 0.02253398
  0.01623843 0.01647545]
 [0.0305414  0.02111637 0.0196558  0.01518939 0.0114931  0.0170544
  0.02228086 0.02468642 0.02548403 0.01885746 0.02825754 0.02363817
  0.02623111 0.00804463 0.00680337 0.02889239 0.02992965 0.03198094
  0.03404853 0.0319173  0.03447128 0.02410571 0.01289536 0.0272873
  0.01813845 0.0171018 ]
 [0.03065839 0.01552029 0.01490055 0.00983574 0.00840082 0.01188735
  0.01687383 0.01728295 0.01924333 0.01265025 0.02819931 0.01616845
  0.0199768  0.00577916 0.00481576 0.02765688 0.03371299 0.02906046
  0.03890894 0.03390139 0.03388853 0.02161946 0.01210776 0.03110966
  0.01807788 0.02340561]
 [0.02948601 0.01992285 0.01937991 0.01180857 0.01008576 0.01450772
  0.02039765 0.02178654 0.02545136 0.01499564 0.02217731 0.017686
  0.02267509 0.00681924 0.00606752 0.02566154 0.02473391 0.02342809
  0.03348032 0.03085966 0.04118816 0.02442724 0.02121603 0.06727354
  0.03948081 0.05189092]
 [0.03060539 0.02005315 0.02027594 0.01568125 0.01235776 0.01882396
  0.02025415 0.02488436 0.02549823 0.01924764 0.0247807  0.02403598
  0.02414033 0.0099278  0.00805197 0.02005851 0.02497346 0.02315185
  0.03088534 0.02743759 0.02782398 0.02503361 0.01412111 0.01999847
  0.01390203 0.0209796 ]
 [0.02951189 0.02677501 0.02765826 0.04091312 0.04307467 0.0364765
  0.02246696 0.02474569 0.03031297 0.04249432 0.03157667 0.03193848
  0.03012751 0.06651182 0.08176725 0.02472447 0.02752244 0.02487693
  0.02497597 0.02329805 0.02097629 0.03070576 0.03017688 0.01033393
  0.00776916 0.01856675]
 [0.02930357 0.02831326 0.02792438 0.04577357 0.09047717 0.03717992
  0.02119112 0.02342939 0.02953182 0.05035231 0.03812517 0.03243871
  0.02522348 0.06853633 0.08658049 0.03083845 0.0377983  0.0340798
  0.02921333 0.02548401 0.02397571 0.02795625 0.02977985 0.00874083
  0.00577542 0.01591124]
 [0.02909974 0.02462398 0.02406517 0.03614186 0.08025489 0.02455565
  0.01699141 0.02183015 0.02496705 0.04310032 0.03568799 0.03274784
  0.02478503 0.02906386 0.03913891 0.02551151 0.05713627 0.05394374
  0.04114125 0.03114035 0.03913631 0.02486646 0.02724964 0.0168306
  0.0112337  0.02085397]
 [0.029295   0.03172928 0.02935755 0.03841871 0.05141974 0.02970259
  0.0232132  0.02513935 0.03148328 0.0393757  0.03369602 0.02795475
  0.02755996 0.02975725 0.03280237 0.02247809 0.038707   0.03508195
  0.03175643 0.02953456 0.02874094 0.04402274 0.04005221 0.0128639
  0.00939329 0.01980719]]

-* TASK 10/20 | SAMPLE 12/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 57/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 4, Fred travelled to the cinema, which implies that he is currently in the cinema, not in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Fred', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' cinema', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02748362 0.0473115  0.04819432 ... 0.07795168 0.00800485 0.02298608]
 [0.02834141 0.04612102 0.04401563 ... 0.07285296 0.0115651  0.02677857]
 [0.02876863 0.0443409  0.0477346  ... 0.06936524 0.01810654 0.0267658 ]
 ...
 [0.02872416 0.04179171 0.03718542 ... 0.02983947 0.00617903 0.01184212]
 [0.02913275 0.03024744 0.02590185 ... 0.01575227 0.00873912 0.01227692]
 [0.02915207 0.03127449 0.02729806 ... 0.01634472 0.00756917 0.01345861]]

-* TASK 10/20 | SAMPLE 12/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 58/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 8, Fred moved to the kitchen, which implies that he is currently in the kitchen, not in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' kitchen', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 38), x_tokens=38, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 38)
DEBUG result.interpretability.attn_scores 1292 
 [[0.02754779 0.04097058 0.03749741 ... 0.02095402 0.01853263 0.02095971]
 [0.02788395 0.06754628 0.06124021 ... 0.03030837 0.03431289 0.03360363]
 [0.0287516  0.04496318 0.0454586  ... 0.01645636 0.0158461  0.01404682]
 ...
 [0.0289141  0.03956857 0.0372113  ... 0.01499711 0.01344128 0.01607784]
 [0.02941352 0.02734611 0.02335073 ... 0.01838894 0.02226074 0.02222024]
 [0.02909199 0.0313873  0.02721855 ... 0.01784198 0.01575543 0.02234042]]

-* TASK 10/20 | SAMPLE 12/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 59/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 7, Bill is in the office, and there is no information that suggests he has moved from the office. Sentence 10 mentions Fred moving to the office, but it does not imply that Bill is no longer in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', ' from', ' the', ' office', '.', ' Sentence', ' ', '10', ' mentions', ' Fred', ' moving', ' to', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' imply', ' that', ' Bill', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 44), x_tokens=44, y_tokens=57, max_supp_attn=0.0175, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 44)
DEBUG result.interpretability.attn_scores 2508 
 [[0.01583182 0.02039    0.02444718 ... 0.02772654 0.00790484 0.00717887]
 [0.01635158 0.01562096 0.01841218 ... 0.02616195 0.01482884 0.01191495]
 [0.01666983 0.02029234 0.02715491 ... 0.04368598 0.01153078 0.01143976]
 ...
 [0.01687646 0.02553054 0.02425377 ... 0.01002018 0.0060837  0.00652829]
 [0.01741244 0.02046047 0.01837702 ... 0.00720042 0.00710356 0.00871386]
 [0.01716541 0.02277804 0.0208086  ... 0.00647522 0.00682677 0.00762901]]

-* TASK 10/20 | SAMPLE 12/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 60/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 14, Mary travelled to the kitchen, which implies that she is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '14', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.0324366  0.04470733 0.05431864 ... 0.04988166 0.02401186 0.01543517]
 [0.03290184 0.04021701 0.04970871 ... 0.03555882 0.03210961 0.03196351]
 [0.0339086  0.04681182 0.06298632 ... 0.03674516 0.01933665 0.01394509]
 ...
 [0.03406828 0.05055191 0.04804458 ... 0.04482886 0.02222889 0.01459478]
 [0.03448154 0.03612939 0.03208967 ... 0.0428976  0.0365332  0.02277026]
 [0.0341506  0.04498315 0.03893617 ... 0.04452143 0.02584082 0.01896746]]
Model's predictions for the sample 12:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to sentence 2, Julie went to   |
|          |                 |   the school, which implies that she is    |
|          |                 |          currently in the school.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 4, Fred travelled   |
|          |                 |  to the cinema, which implies that he is   |
|          |                 |    currently in the cinema, not in the     |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 8, Fred moved to   |
|          |                 |   the kitchen, which implies that he is    |
|          |                 |    currently in the kitchen, not in the    |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 7, Bill is in the   |
|          |                 |  office, and there is no information that  |
|          |                 |   suggests he has moved from the office.   |
|          |                 |  Sentence 10 mentions Fred moving to the   |
|          |                 |  office, but it does not imply that Bill   |
|          |                 |        is no longer in the office.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 14, Mary travelled  |
|          |                 |   to the kitchen, which implies that she   |
|          |                 |        is currently in the kitchen.        |
+----------+-----------------+--------------------------------------------+

Metrics for sample 12:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 13/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 61/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 2 states that Julie is either in the school or the office, but it does not provide a definitive location. Therefore, we can only conclude that Julie might be in the school, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 26), x_tokens=26, y_tokens=53, max_supp_attn=0.0377, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 26)
DEBUG result.interpretability.attn_scores 1378 
 [[0.01735408 0.03565094 0.03664929 ... 0.01675507 0.00735536 0.02292335]
 [0.01789994 0.02216081 0.0216354  ... 0.01198982 0.00638255 0.01476939]
 [0.01819765 0.02512126 0.0281425  ... 0.01585669 0.0071989  0.01446311]
 ...
 [0.01831202 0.02100952 0.02117232 ... 0.01032103 0.00558682 0.01318544]
 [0.01837265 0.01721411 0.01729514 ... 0.0142927  0.00910525 0.01469244]
 [0.01846318 0.01874176 0.01862807 ... 0.01339281 0.00875992 0.01473073]]

-* TASK 10/20 | SAMPLE 13/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 62/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Julie in the provided context sentences. The context sentences only talk about Mary and Fred, but not Julie. Therefore, we cannot determine Julie's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' in', ' the', ' provided', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' talk', ' about', ' Mary', ' and', ' Fred', ',', ' but', ' not', ' Julie', '.', ' Therefore', ',', ' we', ' cannot', ' determine', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 32), x_tokens=32, y_tokens=43, max_supp_attn=0.0465, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 32)
DEBUG result.interpretability.attn_scores 1376 
 [[0.02142012 0.02559611 0.02940515 ... 0.01002645 0.01855841 0.01205562]
 [0.02213655 0.02321234 0.02517387 ... 0.01231098 0.02850747 0.01788001]
 [0.02262619 0.02215114 0.02656595 ... 0.01836589 0.02731604 0.01969986]
 ...
 [0.02288149 0.02484425 0.02175391 ... 0.00816231 0.01866093 0.010978  ]
 [0.02326409 0.02552746 0.02368766 ... 0.0076673  0.01698412 0.01257522]
 [0.02330651 0.02288067 0.02179938 ... 0.00770448 0.01475591 0.01053417]]

-* TASK 10/20 | SAMPLE 13/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 63/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 states that Julie is in the bedroom, but it does not mention Mary being in the bedroom. According to context sentence 4, Mary went to the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' mention', ' Mary', ' being', ' in', ' the', ' bedroom', '.', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Mary', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.0682, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02110858 0.02897946 0.03380408 ... 0.0394344  0.04005201 0.01385341]
 [0.02114726 0.02760505 0.02823226 ... 0.02418025 0.03045705 0.03784805]
 [0.0219983  0.03367165 0.03851366 ... 0.04227536 0.03098848 0.01169077]
 ...
 [0.02225288 0.02974178 0.02860413 ... 0.07461074 0.0369374  0.00886054]
 [0.02260121 0.02523043 0.02259236 ... 0.04764154 0.02409545 0.00996731]
 [0.0225872  0.024016   0.0216507  ... 0.0649253  0.03403204 0.00887978]]

-* TASK 10/20 | SAMPLE 13/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 64/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 states that Julie is either in the bedroom or the school, but it does not provide a definitive location. Therefore, we can only conclude that Julie might be in the school, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 44), x_tokens=44, y_tokens=53, max_supp_attn=0.0189, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 44)
DEBUG result.interpretability.attn_scores 2332 
 [[0.01751344 0.02808531 0.02739665 ... 0.02924811 0.08209317 0.01284179]
 [0.01763846 0.0234738  0.02548075 ... 0.02151462 0.03951183 0.02025358]
 [0.01829535 0.02780697 0.02978161 ... 0.01756069 0.06492487 0.01890295]
 ...
 [0.01850844 0.02429756 0.02756117 ... 0.02578656 0.0320122  0.00863936]
 [0.01876887 0.01769124 0.01922316 ... 0.02490732 0.01465193 0.01038808]
 [0.01870351 0.02075555 0.02223236 ... 0.03575742 0.02166174 0.0101029 ]]

-* TASK 10/20 | SAMPLE 13/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 65/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 14 states that Bill is in the office, which contradicts the idea that Bill is in the park. There is no mention of Bill being in the park in the provided context sentences.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' Bill', ' is', ' in', ' the', ' office', ',', ' which', ' contrad', 'icts', ' the', ' idea', ' that', ' Bill', ' is', ' in', ' the', ' park', '.', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' park', ' in', ' the', ' provided', ' context', ' sentences', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01926128 0.02688111 0.0276279  ... 0.02478239 0.04062954 0.03231055]
 [0.01968107 0.01955259 0.02066511 ... 0.01239538 0.01560492 0.0207481 ]
 [0.02011214 0.02894937 0.03152268 ... 0.0266355  0.03133224 0.03336909]
 ...
 [0.02029366 0.03067318 0.02571652 ... 0.05165057 0.09211984 0.03020612]
 [0.02072756 0.02146655 0.01788086 ... 0.02908781 0.07259607 0.01889637]
 [0.02065603 0.02422059 0.01919448 ... 0.02096363 0.08358108 0.02694067]]
Model's predictions for the sample 13:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 2 states that Julie  |
|          |                 |   is either in the school or the office,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |      location. Therefore, we can only      |
|          |                 |    conclude that Julie might be in the     |
|          |                 |     school, but we cannot be certain.      |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |    There is no mention of Julie in the     |
|          |                 |  provided context sentences. The context   |
|          |                 |  sentences only talk about Mary and Fred,  |
|          |                 |    but not Julie. Therefore, we cannot     |
|          |                 |        determine Julie's location.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 7 states that Julie  |
|          |                 |     is in the bedroom, but it does not     |
|          |                 |     mention Mary being in the bedroom.     |
|          |                 |   According to context sentence 4, Mary    |
|          |                 |            went to the kitchen.            |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentence 10 states that     |
|          |                 |   Julie is either in the bedroom or the    |
|          |                 |     school, but it does not provide a      |
|          |                 |   definitive location. Therefore, we can   |
|          |                 |  only conclude that Julie might be in the  |
|          |                 |     school, but we cannot be certain.      |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 14 states that Bill  |
|          |                 |  is in the office, which contradicts the   |
|          |                 |  idea that Bill is in the park. There is   |
|          |                 |  no mention of Bill being in the park in   |
|          |                 |      the provided context sentences.       |
+----------+-----------------+--------------------------------------------+

Metrics for sample 13:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 14/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 66/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Mary went back to the park, which implies that Mary is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Mary', ' went', ' back', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02631555 0.04472904 0.05445293 0.07018399 0.07529898 0.07184158
  0.0662924  0.07200292 0.05565022 0.06214496 0.04650137 0.0606174
  0.07012349 0.08969208 0.05878869 0.03066467 0.03129578 0.03345201
  0.0295283  0.03096632 0.02358006 0.03865751 0.03907604 0.01437592
  0.01858643 0.03366369]
 [0.02668429 0.05516149 0.05126385 0.06279193 0.0560604  0.05680297
  0.0547586  0.05252101 0.0465492  0.04821207 0.03962526 0.03727916
  0.04009174 0.09419119 0.09304468 0.0329931  0.02994677 0.02785646
  0.0255418  0.02590386 0.02021576 0.03788151 0.04392258 0.0106721
  0.0138376  0.03191856]
 [0.02877576 0.05633655 0.0357358  0.05371025 0.03848724 0.03623865
  0.03194515 0.02261325 0.02175455 0.03337791 0.02703631 0.01616496
  0.01820204 0.028456   0.03639681 0.02274625 0.0140464  0.01328109
  0.0157325  0.01554853 0.013352   0.0422981  0.04776779 0.00499806
  0.00656686 0.01707249]
 [0.02715136 0.02882625 0.02849777 0.02350703 0.01691505 0.02438051
  0.02758499 0.0224174  0.0245591  0.02297213 0.02596126 0.02465908
  0.02291164 0.01228519 0.0115659  0.02913366 0.0273566  0.03406257
  0.03336905 0.03830682 0.03751582 0.02984897 0.03993718 0.06490913
  0.06637469 0.04036918]
 [0.0273833  0.04032975 0.04445891 0.06528573 0.05909689 0.04744967
  0.03458359 0.02909192 0.03286531 0.0446181  0.03345134 0.02520292
  0.02503909 0.09527935 0.0984394  0.0352333  0.02663468 0.02024444
  0.02065299 0.02118751 0.01869527 0.03741499 0.05685853 0.00827897
  0.00975765 0.03669766]
 [0.02790905 0.02638688 0.02745285 0.04966763 0.04456022 0.04259391
  0.02571791 0.02309559 0.02795321 0.04144065 0.03017678 0.02854167
  0.02713088 0.10449873 0.12462043 0.03536879 0.03055197 0.02475976
  0.02353002 0.02278534 0.01811208 0.0319103  0.03387152 0.00652773
  0.0078624  0.02409425]
 [0.02831892 0.02970183 0.03531531 0.05205584 0.04815074 0.05306469
  0.03378554 0.0315238  0.03648395 0.04889325 0.03528741 0.04511767
  0.04133433 0.08335852 0.0782158  0.02999303 0.0279396  0.02479094
  0.02263601 0.02246978 0.01715391 0.02879409 0.03203065 0.00984532
  0.01100208 0.02303167]
 [0.02739887 0.04088815 0.04714089 0.04096909 0.04326415 0.04878477
  0.03921967 0.04066601 0.03958879 0.04284202 0.03593197 0.04919557
  0.04269506 0.05098946 0.04585698 0.04064004 0.03649165 0.03218006
  0.0285441  0.02904192 0.02455499 0.03305528 0.04744805 0.02818127
  0.02948628 0.03791025]
 [0.02846649 0.03961129 0.04724719 0.04660926 0.04253329 0.05605512
  0.04356796 0.04585544 0.04730682 0.04853525 0.03596843 0.05094006
  0.04640389 0.03855282 0.02538951 0.02816243 0.02773787 0.02653332
  0.02472919 0.02516055 0.01945566 0.03364281 0.03454979 0.0135399
  0.01735755 0.03003093]
 [0.02782104 0.05233116 0.05462696 0.02888862 0.02342118 0.03732194
  0.04519177 0.04232234 0.04457252 0.03024503 0.02891471 0.03764273
  0.03791302 0.01711026 0.01489785 0.0454195  0.03589787 0.03159375
  0.03132705 0.03295034 0.02948731 0.03277159 0.06264934 0.0353623
  0.03928616 0.03696268]
 [0.02829085 0.0666045  0.06590763 0.0272843  0.02252467 0.03211077
  0.04651297 0.03990277 0.04694179 0.02665246 0.02592009 0.03006322
  0.03025464 0.01448673 0.0142201  0.04958903 0.03639522 0.03014203
  0.03179989 0.03503753 0.02782754 0.03033748 0.06683645 0.02631252
  0.0288674  0.03345742]
 [0.02847642 0.03622036 0.04046429 0.02070861 0.01793691 0.02373624
  0.03600567 0.03073257 0.03667129 0.02162091 0.02129171 0.02442051
  0.02332063 0.01219135 0.01229568 0.04085692 0.03140203 0.02552855
  0.02868888 0.03011582 0.02678504 0.02868134 0.05291856 0.03792823
  0.04658717 0.03977289]
 [0.0286484  0.01541521 0.01655408 0.01124379 0.01038429 0.01363226
  0.01599681 0.01572497 0.01873925 0.013072   0.01420624 0.01439883
  0.01438622 0.00621942 0.00704552 0.02128928 0.02088214 0.02037764
  0.02595517 0.02929487 0.03007627 0.02106606 0.03393358 0.05700483
  0.08045895 0.04495201]
 [0.0285262  0.02271711 0.02402676 0.01614069 0.01523619 0.02011104
  0.02417025 0.02270949 0.02423953 0.01841141 0.02133405 0.02191103
  0.02149073 0.00930334 0.0099056  0.03546751 0.02587502 0.02419077
  0.02444841 0.02588884 0.02612355 0.02651091 0.03009225 0.0532858
  0.05980477 0.04229307]
 [0.02866985 0.02291038 0.02321886 0.01822699 0.01598272 0.0230112
  0.02581186 0.02629744 0.024015   0.02160837 0.02539903 0.02822378
  0.02861865 0.01021644 0.00923921 0.03433139 0.02857366 0.02915882
  0.02620085 0.02755579 0.03021445 0.02717796 0.0220361  0.04914944
  0.042505   0.02521808]
 [0.02811137 0.01749609 0.01509183 0.01301599 0.010466   0.01375674
  0.01881227 0.0183997  0.01705459 0.01433825 0.01940272 0.01682178
  0.02036515 0.00636374 0.00644418 0.03026663 0.02831642 0.03966004
  0.03236194 0.04223528 0.05342064 0.02387445 0.01726492 0.08420961
  0.05398374 0.02726073]
 [0.02883016 0.0170572  0.01610603 0.0139488  0.01198592 0.01657137
  0.01948078 0.01992285 0.01863869 0.01661582 0.0227655  0.02119773
  0.02144393 0.00703869 0.00671779 0.02401627 0.02129607 0.0314132
  0.02635782 0.03931461 0.0505629  0.02065029 0.01454795 0.06503248
  0.03716729 0.01986144]
 [0.02944917 0.01413245 0.01264293 0.01082274 0.00896286 0.01291957
  0.01559135 0.01540937 0.01558068 0.01294663 0.02067656 0.01670219
  0.01709652 0.00575409 0.00559296 0.02037686 0.01912428 0.02530873
  0.02498755 0.02983232 0.04164544 0.01977081 0.01169688 0.04799417
  0.03076738 0.0196508 ]
 [0.02911341 0.01552512 0.01406187 0.01060206 0.00917439 0.01268866
  0.01822979 0.0168497  0.01733697 0.01274604 0.0292217  0.01885772
  0.01820427 0.00576726 0.00624139 0.02564313 0.02503954 0.02846587
  0.03010302 0.03251306 0.0381372  0.02189396 0.01434569 0.05197947
  0.03223402 0.02247725]
 [0.02822911 0.02441295 0.0247441  0.0175663  0.01638229 0.02528324
  0.03958557 0.04182544 0.03290526 0.02344157 0.03479575 0.03168212
  0.03518712 0.00949539 0.00935713 0.02806607 0.02982846 0.03639818
  0.04079463 0.03737317 0.03887752 0.02668962 0.02191419 0.03642519
  0.0367773  0.04203805]
 [0.02934418 0.02038764 0.01919826 0.01580765 0.01294623 0.01727265
  0.02124402 0.02200332 0.0215438  0.01742795 0.0257613  0.02184673
  0.02239454 0.00849504 0.00776023 0.02309204 0.02253628 0.02476553
  0.02834278 0.02696825 0.02661143 0.02629633 0.01548501 0.02824593
  0.03085404 0.024143  ]
 [0.02958512 0.02094751 0.02291334 0.02139501 0.01768508 0.02386072
  0.0243443  0.02954629 0.02486904 0.02546561 0.02721274 0.03372348
  0.0313401  0.0125612  0.00884499 0.01839896 0.02063695 0.02339504
  0.02270376 0.02098666 0.02023499 0.02822391 0.01470089 0.01636069
  0.02260193 0.02179158]
 [0.02974859 0.02485774 0.0256024  0.024758   0.01812494 0.02667916
  0.02864215 0.03541503 0.02621759 0.02948584 0.03271151 0.0396961
  0.03764221 0.01388092 0.00956962 0.02033354 0.0211692  0.02448874
  0.02297821 0.02127817 0.02011715 0.02845734 0.01510209 0.01404037
  0.01639534 0.01646244]
 [0.02966627 0.02297455 0.02252356 0.02204351 0.01667553 0.02516827
  0.02663959 0.03027484 0.02698622 0.02692549 0.02970042 0.03493134
  0.03553148 0.01240646 0.00925387 0.02398792 0.02315607 0.02659453
  0.02528929 0.02338841 0.02157775 0.0275028  0.01259515 0.01689268
  0.01866642 0.01490046]
 [0.02948546 0.01824554 0.01700685 0.01379581 0.0105477  0.01587199
  0.01996337 0.02184216 0.02179863 0.01734854 0.02325245 0.02268503
  0.02513604 0.00759566 0.00660731 0.02720696 0.02627087 0.0276174
  0.02734055 0.02589334 0.02834371 0.02515664 0.01093659 0.0280139
  0.02852074 0.01643119]
 [0.02949985 0.01898244 0.0172478  0.01440099 0.010635   0.01520682
  0.02196099 0.02314819 0.02111678 0.01690557 0.02244793 0.0207891
  0.02499228 0.00747164 0.00638284 0.02728967 0.02865645 0.03086501
  0.02976326 0.02725776 0.03066909 0.02292322 0.0108568  0.02655107
  0.02804185 0.01730438]
 [0.02951811 0.01892122 0.01692889 0.01456751 0.01158971 0.01521727
  0.01933244 0.02146501 0.02057405 0.01778734 0.02368765 0.02177102
  0.02288377 0.00793258 0.00670334 0.02460363 0.02857842 0.02824143
  0.03051542 0.02683501 0.02990541 0.02312805 0.01197617 0.0235265
  0.02858851 0.01760378]
 [0.02961836 0.02120495 0.01924786 0.01583201 0.01184825 0.0166778
  0.02265027 0.02447213 0.02478088 0.01891986 0.02773968 0.0229272
  0.02503909 0.00825524 0.00697902 0.0267564  0.02736802 0.02964696
  0.03092879 0.02955383 0.03175059 0.02432923 0.01306617 0.02454864
  0.02357803 0.01615555]
 [0.02970249 0.01561954 0.01521624 0.01053572 0.00908597 0.01224774
  0.01794004 0.01836948 0.01961257 0.01326981 0.02895588 0.01785417
  0.01945912 0.0062496  0.00542219 0.0242363  0.03004668 0.02671503
  0.03331348 0.03000913 0.03114817 0.02180701 0.01215959 0.03086892
  0.02382969 0.01680747]
 [0.02827645 0.02097333 0.02055263 0.01355889 0.01311971 0.01640603
  0.02498017 0.02527679 0.02665425 0.01666318 0.02397699 0.0192297
  0.02290495 0.00825854 0.00799255 0.02358724 0.02901709 0.03044346
  0.04688163 0.04079973 0.04373128 0.02737221 0.02392684 0.03308436
  0.0466905  0.0876051 ]
 [0.02963211 0.01941175 0.01962111 0.01716421 0.01364463 0.01963972
  0.02100273 0.02494552 0.02473542 0.02060819 0.02440513 0.02419817
  0.02373074 0.01124642 0.00896621 0.01831232 0.02344154 0.02208036
  0.02926702 0.02649942 0.02504973 0.0246764  0.01341085 0.01756269
  0.01979641 0.02091589]
 [0.02857216 0.0263618  0.02658432 0.0404966  0.04175877 0.03602865
  0.02392598 0.02446765 0.02930315 0.04194353 0.03095308 0.03002597
  0.02971302 0.06522212 0.08088487 0.02429328 0.02787584 0.02500884
  0.02428365 0.02276681 0.01901503 0.03039302 0.02869692 0.00700891
  0.01000515 0.02629878]
 [0.02834041 0.02800894 0.02688197 0.04563719 0.08494794 0.03648477
  0.0221657  0.0229322  0.02821907 0.04882918 0.03655301 0.03020684
  0.02524414 0.06787363 0.08698687 0.03021963 0.03834974 0.0335086
  0.02868401 0.02483096 0.02214996 0.02772053 0.02836776 0.00587239
  0.00726602 0.02284478]
 [0.02809758 0.02529959 0.02384329 0.03831553 0.08772253 0.02540583
  0.0182021  0.02197422 0.02448059 0.04395225 0.03548266 0.03297051
  0.02486635 0.03104221 0.04056737 0.02526818 0.05835897 0.0521635
  0.04031448 0.03040633 0.03674252 0.02514986 0.0267153  0.0121814
  0.0142887  0.02688695]
 [0.0283433  0.03100967 0.02762057 0.03846174 0.0528437  0.02947764
  0.02416135 0.02398307 0.02970124 0.03973282 0.03329138 0.02750447
  0.02690911 0.03025861 0.03280322 0.022156   0.03990587 0.03506734
  0.03210456 0.02904392 0.02715974 0.04393538 0.03830578 0.0092291
  0.01160596 0.02511557]]

-* TASK 10/20 | SAMPLE 14/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 67/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Mary is either in the bedroom or the school, but it does not provide a definitive location. Therefore, we can only conclude that Mary might be in the school.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Mary', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0213, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01960969 0.03192358 0.03284422 ... 0.01018542 0.0081411  0.00652648]
 [0.02020879 0.03029923 0.03058549 ... 0.01407166 0.01223686 0.0085854 ]
 [0.02053866 0.02921947 0.03315644 ... 0.02495913 0.01768988 0.01115906]
 ...
 [0.02058628 0.03034836 0.02463702 ... 0.00610532 0.00594394 0.00550086]
 [0.02095564 0.02429938 0.01927445 ... 0.00752825 0.00820048 0.00905866]
 [0.0210596  0.02367431 0.01873963 ... 0.00629778 0.00776528 0.00871237]]

-* TASK 10/20 | SAMPLE 14/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 68/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Mary is in the office, which provides a definitive location.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' in', ' the', ' office', ',', ' which', ' provides', ' a', ' definitive', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 38), x_tokens=38, y_tokens=26, max_supp_attn=0.0, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 38)
DEBUG result.interpretability.attn_scores 988 
 [[0.03643793 0.04612224 0.04802957 0.06024196 0.05369433 0.04726366
  0.03768484 0.04215728 0.04967199 0.04633978 0.03516056 0.03771655
  0.03645987 0.08202812 0.08508144 0.03559523 0.03114091 0.0323339
  0.02910232 0.03569233 0.02941721 0.03956531 0.05515162 0.02000336
  0.01985228 0.0517101  0.04981594 0.05451007 0.11472731 0.01461488
  0.01390649 0.01083471 0.01571041 0.05932644 0.05479541 0.02738674
  0.02516555 0.04020125]
 [0.03674906 0.03977467 0.04539765 0.04775327 0.0416168  0.04631692
  0.04646215 0.05798751 0.04329692 0.04235182 0.03699679 0.05085154
  0.05686492 0.04845971 0.0606044  0.03375527 0.03172123 0.03819065
  0.03638765 0.04069847 0.03449814 0.04029658 0.03890231 0.02685066
  0.03153918 0.04714151 0.04332742 0.04425285 0.07837037 0.04649158
  0.03958746 0.02836485 0.03923982 0.04263052 0.04096309 0.03181606
  0.03444795 0.04013195]
 [0.03800611 0.04450726 0.05207353 0.07110012 0.07120626 0.06552594
  0.03988094 0.04406305 0.05018634 0.05443999 0.03907281 0.04823571
  0.04476174 0.13760047 0.09892949 0.03887335 0.0292131  0.02946641
  0.02660313 0.03142379 0.02500637 0.04100068 0.04239223 0.01918783
  0.01846412 0.04140555 0.05153738 0.03879819 0.06770487 0.02819414
  0.02102612 0.01439938 0.01966335 0.05442429 0.03831613 0.02132335
  0.01992083 0.03072845]
 [0.03705395 0.03629393 0.04615799 0.03620072 0.03199014 0.03692468
  0.03318353 0.03685677 0.03803287 0.03169834 0.02884609 0.03513563
  0.03141043 0.03107958 0.02957976 0.03626737 0.02845227 0.02896921
  0.02785333 0.0330172  0.02787193 0.04081924 0.04692493 0.03395395
  0.03494482 0.04635606 0.0567282  0.03629179 0.04465541 0.08260261
  0.03325041 0.02379275 0.02535385 0.03229959 0.04845834 0.03601974
  0.04030532 0.04106522]
 [0.03822705 0.02978385 0.03876689 0.02674677 0.02340258 0.0340638
  0.03057713 0.03241454 0.03592549 0.02651075 0.02641363 0.03035314
  0.02808057 0.02025289 0.01975761 0.03059355 0.02454973 0.02604591
  0.02868883 0.03285262 0.02688023 0.03360328 0.0320995  0.02581972
  0.03016238 0.03462232 0.04804153 0.02253996 0.03175814 0.06293332
  0.0275254  0.02112274 0.02199457 0.02316413 0.03404191 0.03695732
  0.0455622  0.03713657]
 [0.03803072 0.04348009 0.05508478 0.03243303 0.02704065 0.04037727
  0.04098611 0.04265086 0.04909003 0.03025014 0.02553656 0.03404299
  0.03416633 0.02817343 0.02346867 0.0374134  0.02679973 0.02600634
  0.02658361 0.03146419 0.02487594 0.04206992 0.05904664 0.03189906
  0.02954213 0.03916689 0.06101856 0.02560907 0.03597001 0.09982875
  0.02495094 0.02002616 0.01875113 0.02513816 0.05796953 0.03627937
  0.04336094 0.03897384]
 [0.03814996 0.06055877 0.05988741 0.02932372 0.0243772  0.03596666
  0.04473799 0.04394239 0.0543776  0.02949092 0.02654541 0.03293871
  0.03586997 0.01994241 0.02078728 0.04907045 0.03906873 0.03849506
  0.03702556 0.04281104 0.03214636 0.0372525  0.07448274 0.03704678
  0.03776659 0.04430716 0.04737943 0.02708572 0.03056298 0.08738627
  0.0193688  0.01928402 0.01869321 0.02254039 0.06962396 0.04146597
  0.05373941 0.0403953 ]
 [0.03834157 0.04349414 0.04407251 0.02538886 0.02151069 0.02792127
  0.0337622  0.03146851 0.04044593 0.02364136 0.02282542 0.02327714
  0.02517663 0.01823311 0.02035761 0.04177447 0.03230968 0.02878758
  0.0313783  0.03515072 0.02769569 0.0347867  0.05145614 0.03812248
  0.03652383 0.03631813 0.03893112 0.02452015 0.02732342 0.06656065
  0.01808572 0.01489557 0.0174914  0.02198167 0.05061053 0.05146
  0.06197895 0.03747692]
 [0.03815832 0.03724085 0.03646083 0.02396408 0.01763853 0.02549995
  0.03141668 0.03830461 0.03485269 0.02388724 0.02471565 0.02917438
  0.03229414 0.01747861 0.01734162 0.02966982 0.03281961 0.03114875
  0.0367865  0.03679051 0.02956855 0.03892719 0.03662771 0.03102478
  0.03126427 0.03460311 0.0251066  0.03096805 0.0300419  0.043005
  0.02084361 0.02069957 0.02642534 0.02263222 0.03396931 0.03952898
  0.04778171 0.04312579]
 [0.03846966 0.02675451 0.03295495 0.02373004 0.01914822 0.02749862
  0.02710272 0.02782424 0.03344776 0.02341711 0.02379754 0.02488177
  0.02527457 0.01721487 0.01793174 0.03776487 0.03125914 0.03360733
  0.0339092  0.03770915 0.03408992 0.0356855  0.03667122 0.05018464
  0.05167545 0.04357695 0.03440239 0.03029205 0.03116278 0.06411505
  0.04015249 0.03092531 0.03735746 0.0227456  0.03651352 0.04461873
  0.05188172 0.03638965]
 [0.03858461 0.03229359 0.03618845 0.02866534 0.0225713  0.033288
  0.03365785 0.03382948 0.0311846  0.02845069 0.03009257 0.03439091
  0.03465829 0.0214681  0.01904581 0.04451713 0.03576276 0.03411772
  0.03449466 0.03598109 0.03513836 0.04206216 0.03240259 0.0699418
  0.05808234 0.03446379 0.03352843 0.03308672 0.03006851 0.06196466
  0.05381011 0.05433356 0.04488688 0.02482161 0.03116934 0.04740572
  0.04825145 0.03146306]
 [0.03838314 0.03032954 0.02840132 0.02370947 0.01737577 0.02474857
  0.03018581 0.02986712 0.02668767 0.02220127 0.02571802 0.02421386
  0.03130338 0.01408171 0.01451573 0.05190923 0.04056964 0.04345382
  0.04147751 0.04278411 0.04573433 0.03779682 0.0252922  0.10169818
  0.07858893 0.034471   0.02899971 0.03845452 0.02075227 0.03719893
  0.03779004 0.06179262 0.04187511 0.01769716 0.0258475  0.0629655
  0.05935811 0.03543636]
 [0.03907327 0.02952305 0.02837458 0.02460703 0.01952564 0.02706658
  0.02745135 0.02918707 0.02648193 0.02483019 0.02925654 0.03065917
  0.03101868 0.01568752 0.01523437 0.03975653 0.03754887 0.03370575
  0.04027365 0.03530632 0.03936201 0.03753291 0.02607541 0.05405802
  0.08062914 0.0305005  0.03233666 0.03365951 0.02200619 0.03105662
  0.05055817 0.08024535 0.04952036 0.01988289 0.02537954 0.06125209
  0.05153055 0.03370382]
 [0.03938795 0.02627303 0.02511602 0.02030954 0.01668303 0.02264846
  0.02877708 0.02861946 0.02587352 0.02077468 0.0365345  0.02703681
  0.03164047 0.01240746 0.01318036 0.04883989 0.04474023 0.04068779
  0.04696255 0.04094234 0.04786308 0.03514473 0.0237783  0.05700537
  0.08083589 0.03994994 0.02219339 0.04036169 0.01841462 0.02191645
  0.04133511 0.06571279 0.06817014 0.01686903 0.02236848 0.0585671
  0.04790485 0.03879673]
 [0.0379135  0.05363742 0.03395424 0.02611668 0.02438197 0.02932823
  0.13105501 0.0566521  0.04503398 0.02917209 0.11886672 0.04640301
  0.07117511 0.01574427 0.02074773 0.08181787 0.08510952 0.08867318
  0.08943047 0.08485156 0.08134364 0.04099518 0.03767648 0.10276409
  0.10730181 0.08449969 0.02595408 0.04656916 0.02224178 0.01580297
  0.02550676 0.03529764 0.0368362  0.02348108 0.04456384 0.08581682
  0.0859405  0.08880805]
 [0.03927891 0.02751686 0.02874054 0.02749259 0.02131482 0.03126303
  0.02676121 0.02997132 0.02947107 0.02817781 0.03152915 0.03598391
  0.0321461  0.01976714 0.01708914 0.03372373 0.0311725  0.03040093
  0.03663891 0.03430838 0.03789837 0.03646172 0.02411439 0.03125279
  0.03008513 0.03240528 0.02534495 0.03526833 0.02759061 0.02766486
  0.08818413 0.07491928 0.11265159 0.02480374 0.02405382 0.02632243
  0.02711294 0.03340813]
 [0.03901242 0.0292482  0.03545319 0.03704942 0.02831624 0.04025892
  0.02961426 0.03597381 0.03762432 0.04149262 0.0325704  0.04442484
  0.03799498 0.02899637 0.02120097 0.02681451 0.02833765 0.02995041
  0.03036959 0.03042286 0.02848228 0.03861897 0.0260289  0.02562248
  0.02378956 0.03279921 0.03265447 0.0359242  0.03261515 0.03182978
  0.10704783 0.06386333 0.06602715 0.03325938 0.02858939 0.02486454
  0.02713118 0.03411501]
 [0.03923682 0.03352539 0.03707578 0.0394772  0.02860289 0.04338654
  0.03276138 0.03893529 0.03406793 0.04215458 0.0342943  0.0465182
  0.04084882 0.02788799 0.01952339 0.02557161 0.0237185  0.02535998
  0.02733983 0.02807389 0.02587261 0.03814159 0.02914072 0.02538887
  0.02167892 0.0282018  0.03922244 0.02960722 0.02907181 0.03211227
  0.12156083 0.07061784 0.05374842 0.02830765 0.03198018 0.03005319
  0.02733641 0.03602158]
 [0.03933313 0.04046279 0.04098105 0.0418304  0.03111586 0.05323901
  0.03841529 0.04383271 0.03921735 0.05392393 0.04147719 0.05556538
  0.04930556 0.03378208 0.02088918 0.02784714 0.02673114 0.02883324
  0.03019884 0.03057098 0.02780721 0.03917914 0.03410254 0.02743817
  0.02268767 0.02867499 0.04147356 0.02955057 0.02884231 0.02975856
  0.04619735 0.05503597 0.03897918 0.02467736 0.03440042 0.03054568
  0.02680738 0.03694098]
 [0.03927792 0.04074566 0.03609988 0.03495854 0.02861245 0.04315737
  0.0381473  0.04305943 0.03461168 0.05122746 0.05395492 0.04885127
  0.04887281 0.02846221 0.01816672 0.02991089 0.03196402 0.03307462
  0.03446295 0.03225116 0.03162462 0.03817588 0.0343381  0.03372734
  0.03048045 0.02870622 0.03726264 0.03234021 0.02638436 0.02665808
  0.04009995 0.0571056  0.04659548 0.02221369 0.03606566 0.04432612
  0.03210379 0.0420955 ]
 [0.03953671 0.04448519 0.04081394 0.03785439 0.02929085 0.04324754
  0.04312531 0.04970083 0.03792118 0.04865528 0.0480617  0.04626104
  0.05077006 0.02868422 0.02108766 0.03349693 0.0324568  0.03507456
  0.03506549 0.03380717 0.03169133 0.03764578 0.03252862 0.03331748
  0.02813126 0.0277262  0.03522339 0.03319499 0.02417588 0.02299459
  0.03481462 0.05028665 0.04419186 0.02120798 0.03316517 0.0327114
  0.02547871 0.03406418]
 [0.04011303 0.03119019 0.03028794 0.02995895 0.02337631 0.03280899
  0.03510927 0.03838138 0.03214865 0.0327845  0.04161545 0.03765022
  0.04107885 0.02292367 0.01755379 0.03039379 0.02957682 0.02849434
  0.03374819 0.03138339 0.03164354 0.03414858 0.0241609  0.02733465
  0.0247665  0.02497352 0.02568924 0.03572782 0.02291919 0.02215104
  0.04533275 0.07177456 0.08189683 0.027139   0.02433862 0.02545285
  0.02491168 0.03051747]
 [0.03847607 0.03827404 0.0354699  0.05943184 0.05326196 0.04882841
  0.03351081 0.03596833 0.04654471 0.05745527 0.03766216 0.04064656
  0.03918161 0.08790552 0.10295843 0.03093301 0.03526276 0.03585282
  0.03474836 0.03548436 0.03400628 0.03838351 0.03875077 0.01749384
  0.01717138 0.03672887 0.04049366 0.04790355 0.05804993 0.01134383
  0.01343732 0.01167566 0.01836018 0.09594142 0.03780014 0.02095038
  0.02198375 0.03508985]
 [0.03816505 0.04823475 0.03920972 0.08024288 0.15720843 0.06076408
  0.03710142 0.03642351 0.04475475 0.07542001 0.05486655 0.04991482
  0.03869193 0.12416308 0.16081451 0.04531319 0.06348488 0.05957105
  0.05072658 0.04387481 0.05774316 0.03718781 0.05112305 0.01976136
  0.01740766 0.04034387 0.05598665 0.05087195 0.06084879 0.00962009
  0.00953462 0.00915387 0.01287964 0.10513295 0.04607049 0.02197863
  0.017414   0.03510217]
 [0.0380917  0.04268163 0.03152118 0.05566671 0.10344482 0.03638744
  0.03104434 0.03254891 0.03304216 0.05960326 0.05131723 0.04420026
  0.03433487 0.04828778 0.0721125  0.0443504  0.08975665 0.08744136
  0.07156292 0.0560251  0.09840653 0.03640512 0.04186109 0.03470232
  0.03219122 0.03766805 0.03705077 0.06765261 0.04134268 0.01287697
  0.01460057 0.01984895 0.02234208 0.0945314  0.03911804 0.03213752
  0.02656719 0.03276285]
 [0.03851144 0.04356837 0.03342619 0.05574644 0.06329232 0.04222003
  0.03748799 0.03937951 0.04600684 0.05164896 0.04227217 0.04067215
  0.03661931 0.04928765 0.05204006 0.03402638 0.05647313 0.05225721
  0.04818104 0.04632252 0.05333233 0.04811313 0.04487089 0.0243999
  0.02443707 0.03867929 0.03029741 0.07495905 0.04239869 0.00931806
  0.01149242 0.01399125 0.02035837 0.09315064 0.04982761 0.02779372
  0.02602295 0.0360493 ]]

-* TASK 10/20 | SAMPLE 14/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 69/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Julie's location in the context sentences 10 and 11. The previous information about Julie was in sentence 5, but it's not relevant to the current question.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '10', ' and', ' ', '11', '.', ' The', ' previous', ' information', ' about', ' Julie', ' was', ' in', ' sentence', ' ', '5', ',', ' but', ' it', "'s", ' not', ' relevant', ' to', ' the', ' current', ' question', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 44), x_tokens=44, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 44)
DEBUG result.interpretability.attn_scores 2112 
 [[0.01914256 0.01911358 0.01976302 ... 0.00946711 0.01265054 0.01142219]
 [0.01951737 0.01273317 0.01366784 ... 0.01552613 0.01848592 0.01329521]
 [0.02005272 0.01785007 0.01994578 ... 0.01349606 0.01695709 0.02311063]
 ...
 [0.02054006 0.02149901 0.01791918 ... 0.00872279 0.01497214 0.01364667]
 [0.02083647 0.02255557 0.02073508 ... 0.00750365 0.01429642 0.01651435]
 [0.02090418 0.01917307 0.01792565 ... 0.00713699 0.01258539 0.01204425]]

-* TASK 10/20 | SAMPLE 14/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 70/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 13, Fred journeyed to the bedroom, but context sentence 14 provides alternative locations for Fred (school or cinema). There is no information that suggests Fred is in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' but', ' context', ' sentence', ' ', '14', ' provides', ' alternative', ' locations', ' for', ' Fred', ' (', 'school', ' or', ' cinema', ').', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0208, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01925443 0.02490392 0.02810359 ... 0.03471918 0.02455533 0.01394568]
 [0.01965351 0.02304656 0.02425339 ... 0.01321982 0.02306094 0.01568147]
 [0.02008021 0.02858722 0.03245281 ... 0.03070049 0.0208278  0.01035986]
 ...
 [0.02027881 0.02648494 0.02657602 ... 0.0719552  0.01927658 0.01029161]
 [0.02070152 0.02112484 0.02018496 ... 0.06169208 0.02063428 0.013284  ]
 [0.02057636 0.02330719 0.02224664 ... 0.07678021 0.01834431 0.01166541]]
Model's predictions for the sample 14:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Mary    |
|          |                 |    went back to the park, which implies    |
|          |                 |    that Mary is currently in the park.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to context sentence 4, Mary is  |
|          |                 |  either in the bedroom or the school, but  |
|          |                 |      it does not provide a definitive      |
|          |                 |      location. Therefore, we can only      |
|          |                 |     conclude that Mary might be in the     |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 7, Mary is  |
|          |                 |      in the office, which provides a       |
|          |                 |            definitive location.            |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |      Julie's location in the context       |
|          |                 |     sentences 10 and 11. The previous      |
|          |                 |  information about Julie was in sentence   |
|          |                 |  5, but it's not relevant to the current   |
|          |                 |                 question.                  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 13, Fred   |
|          |                 |   journeyed to the bedroom, but context    |
|          |                 |      sentence 14 provides alternative      |
|          |                 |   locations for Fred (school or cinema).   |
|          |                 |   There is no information that suggests    |
|          |                 |           Fred is in the office.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 14:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.04 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 15/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 71/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 1, Bill travelled to the kitchen, which implies that Bill is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 26), x_tokens=26, y_tokens=30, max_supp_attn=0.1, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 26)
DEBUG result.interpretability.attn_scores 780 
 [[0.03126648 0.05164257 0.05574529 0.0840124  0.07846308 0.05877497
  0.04076888 0.03600784 0.041744   0.05714355 0.03947858 0.02943236
  0.03151704 0.13076714 0.1275009  0.03631242 0.03043622 0.02190664
  0.02530927 0.02496348 0.0247523  0.0455674  0.06931181 0.01431578
  0.0112471  0.0443809 ]
 [0.03229167 0.03244291 0.03284603 0.06254282 0.05556952 0.05004454
  0.02864899 0.02599157 0.03354514 0.0494183  0.03417671 0.03158399
  0.03130549 0.13345663 0.15335856 0.03507248 0.03310441 0.02569259
  0.02792937 0.02584983 0.02321353 0.0390717  0.04112368 0.00988902
  0.0090772  0.02900953]
 [0.03278819 0.03679158 0.0438066  0.06488171 0.06113371 0.06454571
  0.03926782 0.03814915 0.04467067 0.05796773 0.03937861 0.05159319
  0.05081538 0.10582948 0.09364144 0.03008305 0.03048552 0.02662153
  0.02713751 0.02619423 0.02226138 0.03540708 0.03872151 0.01362525
  0.01258052 0.02798287]
 [0.03165649 0.04913321 0.05830032 0.05294103 0.05176313 0.06196249
  0.04669664 0.04958826 0.0496924  0.05163014 0.03967731 0.05706589
  0.05138457 0.06366897 0.0558617  0.04280554 0.03918686 0.03502408
  0.03298786 0.03381991 0.0306256  0.03957851 0.05684647 0.03568479
  0.0377079  0.04437187]
 [0.03290953 0.04905485 0.06014597 0.06025738 0.05096975 0.07336727
  0.05516767 0.05753621 0.06080348 0.06083212 0.04140566 0.05984232
  0.05921598 0.04769816 0.03099881 0.03054868 0.03125862 0.03016601
  0.0299623  0.03215984 0.02574549 0.04037244 0.04445318 0.02066766
  0.02186198 0.0358256 ]
 [0.03232375 0.06106015 0.06609429 0.0373851  0.02751832 0.04764034
  0.05463126 0.0514491  0.05468845 0.03755111 0.03292532 0.04417187
  0.04615607 0.02291023 0.01904368 0.04779497 0.03894754 0.03387614
  0.03436296 0.03708225 0.03387866 0.0384773  0.07354506 0.04299065
  0.04711342 0.04357946]
 [0.03294653 0.07695626 0.07688665 0.03404035 0.02500266 0.0400339
  0.05374745 0.04543114 0.05539002 0.03267081 0.02881101 0.03350174
  0.03448011 0.01905316 0.01758584 0.04997165 0.03881846 0.03087515
  0.0350707  0.03995596 0.03294202 0.03485686 0.07823675 0.03572689
  0.03566207 0.04071112]
 [0.03309306 0.04204891 0.04871279 0.02627858 0.02023975 0.02967716
  0.04165815 0.03562875 0.04398676 0.02703757 0.0245618  0.02697589
  0.02687033 0.0161274  0.01559378 0.04383087 0.03540831 0.02693799
  0.03279718 0.03490441 0.0321047  0.03336763 0.06483754 0.05071756
  0.05590388 0.04826461]
 [0.03329688 0.01848296 0.02033783 0.01512994 0.0125283  0.01798162
  0.01968854 0.01992879 0.02420965 0.01686893 0.01705222 0.01701662
  0.01760587 0.00893731 0.00946418 0.02464771 0.02398399 0.02273772
  0.02852326 0.03206844 0.03386487 0.02490483 0.04267317 0.06536898
  0.08733439 0.05508745]
 [0.03325347 0.02675503 0.0285066  0.02067591 0.01626364 0.02572151
  0.02828738 0.0250746  0.02776886 0.02204393 0.02383192 0.02410814
  0.02304844 0.0117106  0.01222767 0.04085418 0.02683605 0.02557667
  0.02727995 0.02990829 0.03061319 0.03074445 0.03429833 0.06019365
  0.07585664 0.04838061]
 [0.03333498 0.02935244 0.0297087  0.02484187 0.01932927 0.02946126
  0.03386774 0.03367827 0.03155443 0.02741485 0.02919401 0.03506209
  0.03461611 0.01451892 0.01251737 0.04375825 0.03033316 0.03237444
  0.030204   0.0314168  0.03382486 0.03294402 0.02634262 0.04937741
  0.04548864 0.02862463]
 [0.03278569 0.02510678 0.01998497 0.0182042  0.01302302 0.01872805
  0.0269207  0.02520267 0.02177424 0.01799752 0.02335738 0.02198213
  0.02445631 0.00903346 0.00884364 0.04499145 0.02710653 0.04077058
  0.03426987 0.04039412 0.05059952 0.03135369 0.02180418 0.08468325
  0.06573837 0.03675661]
 [0.03373337 0.02191329 0.01901141 0.01751905 0.0139506  0.01931934
  0.02423322 0.0228129  0.02164581 0.01853024 0.02797875 0.02450562
  0.02424853 0.00917494 0.00877223 0.03453149 0.02542474 0.04703048
  0.0356674  0.05515189 0.03997061 0.02620157 0.01689441 0.05834823
  0.0454794  0.02632875]
 [0.03369417 0.02032051 0.01771424 0.01416296 0.012227   0.01608299
  0.02359412 0.021951   0.02030368 0.01593627 0.03825007 0.02293607
  0.02310259 0.00758157 0.00814943 0.03655646 0.02842231 0.03738694
  0.03502864 0.03875352 0.03862427 0.02763787 0.01771958 0.05943034
  0.04565891 0.03198257]
 [0.0327548  0.03026549 0.02808244 0.02100634 0.02010686 0.02489913
  0.03592595 0.03616024 0.03397058 0.0232891  0.03395028 0.02978713
  0.03321202 0.01098466 0.01141334 0.0326001  0.03667685 0.04272191
  0.0434374  0.04657675 0.0453987  0.03192962 0.02748346 0.05206132
  0.0493348  0.05339719]
 [0.03424923 0.02430026 0.02299798 0.01958583 0.01592024 0.02133622
  0.02441676 0.02677023 0.02325925 0.02087972 0.0283196  0.02589711
  0.02515646 0.01043384 0.0097024  0.02548764 0.02433699 0.02820946
  0.02920408 0.02759658 0.02904683 0.03000098 0.01818718 0.0305281
  0.03585346 0.02875569]
 [0.03434914 0.02693553 0.02927539 0.02825789 0.02224754 0.03262058
  0.030622   0.03807743 0.02940317 0.03239878 0.03102835 0.04256882
  0.03774162 0.01668989 0.01165231 0.02225118 0.02414423 0.02787575
  0.02674718 0.02632632 0.02477782 0.03230012 0.01780865 0.0188842
  0.02579722 0.02422269]
 [0.0344811  0.03199299 0.03267509 0.03225864 0.02340275 0.03555097
  0.0371091  0.04609326 0.03001965 0.03670912 0.03938223 0.04819394
  0.04528592 0.0181672  0.01245706 0.02478545 0.02424592 0.02962132
  0.02626937 0.02667839 0.02449675 0.03240655 0.01869669 0.0166424
  0.01934297 0.01944715]
 [0.03433032 0.03041517 0.0293019  0.03013193 0.02341722 0.0326911
  0.03395076 0.03996645 0.03028615 0.0348535  0.03614233 0.042896
  0.04286686 0.01747353 0.01285073 0.029977   0.02577671 0.03204273
  0.02865505 0.02929852 0.02714355 0.03245662 0.01649885 0.01950495
  0.02069849 0.01761979]
 [0.034203   0.02459874 0.02221913 0.01883752 0.01466372 0.02074494
  0.02601395 0.02847739 0.0247266  0.02144158 0.02752468 0.02736351
  0.02999333 0.01026283 0.00903064 0.03571054 0.02773823 0.03306793
  0.03042272 0.0298216  0.03325653 0.03036443 0.01528336 0.03001803
  0.03144635 0.01990136]
 [0.03418374 0.0261343  0.02240653 0.01941414 0.01445057 0.01947014
  0.03013366 0.030579   0.02472981 0.02074208 0.0299251  0.02514421
  0.03081311 0.00965089 0.00886181 0.03938268 0.02920398 0.03545245
  0.03259249 0.03061478 0.03746899 0.02741892 0.01496115 0.03099848
  0.0319347  0.0223185 ]
 [0.03428004 0.02458642 0.02117244 0.01922139 0.01579393 0.01980213
  0.02553217 0.0282443  0.02430438 0.02236939 0.02961195 0.02708429
  0.02885998 0.01036654 0.0094561  0.03258962 0.03282811 0.03423272
  0.03660114 0.03092497 0.03603162 0.02779094 0.0154353  0.02398916
  0.02515444 0.02078867]
 [0.03439562 0.02736696 0.023775   0.0205188  0.01580445 0.02125377
  0.03002988 0.03134741 0.02900984 0.02327291 0.03419477 0.02760331
  0.03125637 0.01062271 0.00990276 0.03338613 0.03118432 0.03536381
  0.03687482 0.03458183 0.03803491 0.02912842 0.01612425 0.02511758
  0.0244483  0.02121877]
 [0.03449323 0.02131721 0.01869877 0.01405768 0.01218622 0.01560454
  0.02565125 0.02393094 0.02283381 0.01602533 0.04164052 0.02095066
  0.02508217 0.00785079 0.00785064 0.03189142 0.03324822 0.03207001
  0.03785175 0.03226305 0.03634268 0.02739264 0.01469984 0.03412569
  0.02647432 0.02271922]
 [0.0327825  0.03053492 0.02594792 0.01738299 0.01576761 0.02177779
  0.04894713 0.04056581 0.03475884 0.02118575 0.05186607 0.02905525
  0.03987105 0.00995652 0.01078902 0.03075704 0.05818849 0.05181515
  0.06156944 0.05514304 0.05245762 0.0331405  0.02738326 0.04764869
  0.04288846 0.06296183]
 [0.03458385 0.02491748 0.02378415 0.02186156 0.01680572 0.02507923
  0.02708457 0.03054058 0.02938872 0.02428816 0.02845209 0.02945798
  0.02897458 0.01320645 0.01100604 0.01966227 0.02668883 0.02589033
  0.02988042 0.02632632 0.02903718 0.02948864 0.01592712 0.01899488
  0.02301358 0.02535105]
 [0.03311685 0.03185211 0.03104061 0.05103946 0.05244994 0.04460688
  0.0288653  0.02838134 0.03445541 0.05095331 0.03355161 0.03491623
  0.03434789 0.08833397 0.10216006 0.02362212 0.03086454 0.02640574
  0.02800003 0.02643071 0.02437916 0.03736733 0.03620736 0.01104661
  0.01122532 0.03127001]
 [0.03290392 0.03413958 0.03115579 0.0573791  0.10646954 0.04420437
  0.02651321 0.02686116 0.03336534 0.05807298 0.03864271 0.03521516
  0.02875168 0.08692534 0.10723585 0.02856788 0.04267541 0.03586438
  0.03298954 0.02879077 0.02938204 0.03436147 0.03640383 0.00961894
  0.00803944 0.02732228]
 [0.03265765 0.03072422 0.02745442 0.04676336 0.10443938 0.03066336
  0.02230391 0.0264603  0.02907567 0.0525709  0.03858731 0.03999802
  0.02868872 0.03905343 0.04905074 0.02509412 0.06686039 0.05565565
  0.04647417 0.0342392  0.04557285 0.02962839 0.03245413 0.01633623
  0.015184   0.03137546]
 [0.0328607  0.03885718 0.03221071 0.04941001 0.06809256 0.03635382
  0.0297218  0.02911389 0.03463522 0.04790434 0.03710105 0.0340904
  0.0302754  0.03955342 0.04302107 0.02247551 0.04558602 0.03673355
  0.03590013 0.03176414 0.03415179 0.05433902 0.04963735 0.01346525
  0.01245381 0.03004373]]

-* TASK 10/20 | SAMPLE 15/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 72/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Julie was either in the bedroom or the cinema, but then according to context sentence 5, Julie went to the kitchen, which means Julie is no longer in the bedroom or the cinema, but now in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' was', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 32), x_tokens=32, y_tokens=58, max_supp_attn=0.1034, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 32)
DEBUG result.interpretability.attn_scores 1856 
 [[0.01586014 0.02734702 0.02922921 ... 0.00659358 0.00464407 0.03900794]
 [0.0162967  0.02686794 0.02663263 ... 0.00833321 0.00686031 0.04570384]
 [0.01657954 0.02514002 0.02822213 ... 0.01364308 0.009061   0.03454534]
 ...
 [0.01662914 0.02729588 0.02330184 ... 0.00451472 0.00374315 0.0673007 ]
 [0.01684217 0.02119614 0.01666074 ... 0.00671129 0.00655079 0.05242144]
 [0.01690781 0.02481974 0.01850862 ... 0.00480765 0.00452087 0.05763288]]

-* TASK 10/20 | SAMPLE 15/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 73/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to previous context sentences, Julie was in the kitchen (sentence 5), but then according to context sentence 7, Julie went back to the park, which means Julie is no longer in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' previous', ' context', ' sentences', ',', ' Julie', ' was', ' in', ' the', ' kitchen', ' (', 'sentence', ' ', '5', '),', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '7', ',', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' which', ' means', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 38), x_tokens=38, y_tokens=49, max_supp_attn=0.0612, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 38)
DEBUG result.interpretability.attn_scores 1862 
 [[0.01901716 0.02718843 0.03095684 ... 0.00874883 0.00792999 0.02064087]
 [0.01922614 0.02037944 0.02594374 ... 0.02504512 0.03141151 0.0330715 ]
 [0.01982697 0.02833524 0.03700533 ... 0.00650107 0.00576929 0.01952224]
 ...
 [0.01994774 0.02848514 0.02658452 ... 0.00556944 0.00510221 0.02509548]
 [0.02035229 0.02086449 0.018961   ... 0.00879838 0.00750781 0.02304292]
 [0.02020712 0.02251951 0.02037667 ... 0.00760208 0.00672775 0.0196774 ]]

-* TASK 10/20 | SAMPLE 15/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 74/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, Fred was in the school, but then according to context sentence 11, Fred moved to the kitchen, which means Fred is no longer in the school, but now in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Fred', ' was', ' in', ' the', ' school', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Fred', ' is', ' no', ' longer', ' in', ' the', ' school', ',', ' but', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 44), x_tokens=44, y_tokens=51, max_supp_attn=0.1176, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 44)
DEBUG result.interpretability.attn_scores 2244 
 [[0.01823744 0.02764054 0.0252899  ... 0.00791604 0.00704783 0.01044539]
 [0.0186235  0.01912097 0.01857808 ... 0.02448868 0.01696382 0.01516112]
 [0.01909743 0.02832252 0.02944438 ... 0.0106872  0.00973365 0.01436654]
 ...
 [0.01926658 0.02855641 0.02750413 ... 0.00527797 0.00466051 0.00511333]
 [0.01963384 0.02097818 0.01923147 ... 0.00648803 0.00557222 0.00506472]
 [0.01936181 0.02542786 0.02209206 ... 0.00543915 0.00530748 0.00457052]]

-* TASK 10/20 | SAMPLE 15/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 75/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 13, Mary went to the school, but then according to context sentence 14, Mary went to the park, which means Mary is no longer in the school, but now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Mary', ' went', ' to', ' the', ' school', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '14', ',', ' Mary', ' went', ' to', ' the', ' park', ',', ' which', ' means', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', ',', ' but', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 50), x_tokens=50, y_tokens=51, max_supp_attn=0.0784, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 50)
DEBUG result.interpretability.attn_scores 2550 
 [[0.01820169 0.0220534  0.02504674 ... 0.02433261 0.02857417 0.02937539]
 [0.01874817 0.01558395 0.01947477 ... 0.01139111 0.01671745 0.01811164]
 [0.01900697 0.02406603 0.03101435 ... 0.02417929 0.02721124 0.02973556]
 ...
 [0.01917459 0.02324439 0.02385057 ... 0.02688488 0.05625964 0.02926305]
 [0.01959718 0.01572651 0.01531068 ... 0.01390037 0.05118288 0.01895705]
 [0.01933091 0.01973752 0.01786444 ... 0.01292581 0.05383938 0.03007952]]
Model's predictions for the sample 15:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Bill    |
|          |                 |  travelled to the kitchen, which implies   |
|          |                 |   that Bill is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 4, Julie   |
|          |                 |  was either in the bedroom or the cinema,  |
|          |                 |   but then according to context sentence   |
|          |                 |    5, Julie went to the kitchen, which     |
|          |                 |  means Julie is no longer in the bedroom   |
|          |                 |   or the cinema, but now in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to previous context sentences,  |
|          |                 |   Julie was in the kitchen (sentence 5),   |
|          |                 |   but then according to context sentence   |
|          |                 |   7, Julie went back to the park, which    |
|          |                 |  means Julie is no longer in the kitchen.  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 10, Fred   |
|          |                 |  was in the school, but then according to  |
|          |                 |   context sentence 11, Fred moved to the   |
|          |                 |   kitchen, which means Fred is no longer   |
|          |                 |   in the school, but now in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 13, Mary   |
|          |                 |   went to the school, but then according   |
|          |                 |  to context sentence 14, Mary went to the  |
|          |                 |   park, which means Mary is no longer in   |
|          |                 |      the school, but now in the park.      |
+----------+-----------------+--------------------------------------------+

Metrics for sample 15:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.09 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 16/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 76/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Julie went to the school, which implies that she is now in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' went', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02809828 0.0470335  0.05761209 0.07443722 0.08318438 0.07518259
  0.06303025 0.07045761 0.05765634 0.06743141 0.05146471 0.06274078
  0.07071131 0.09979263 0.0681676  0.03314873 0.03374092 0.03355019
  0.02984563 0.03046824 0.02588325 0.03991845 0.04473327 0.02094712
  0.01282073 0.02338435]
 [0.02847595 0.06086999 0.05539505 0.07539083 0.06849    0.06295179
  0.05007498 0.04762933 0.04536132 0.05230458 0.04274603 0.03433147
  0.03607923 0.10744492 0.10698121 0.03388179 0.02717232 0.02307092
  0.02290579 0.02212078 0.02052524 0.04167994 0.04609566 0.01580331
  0.00804674 0.02042794]
 [0.03065374 0.06314731 0.03931296 0.0533328  0.03918702 0.03659431
  0.03500731 0.02455447 0.02404539 0.03491259 0.03064435 0.0175762
  0.01931369 0.0265258  0.03502274 0.02438349 0.01476127 0.01366987
  0.0167985  0.01618084 0.01565296 0.04505722 0.05430886 0.00956042
  0.00479267 0.01147492]
 [0.02870754 0.04226996 0.03889368 0.02425003 0.0168535  0.02676295
  0.03143187 0.02623363 0.02989646 0.02437663 0.02780479 0.02532649
  0.02420379 0.01205023 0.01185737 0.03447638 0.02880942 0.02984658
  0.03440234 0.03589515 0.03466701 0.03488022 0.04981184 0.05782076
  0.06910899 0.05967104]
 [0.02907644 0.04536308 0.0502387  0.06862211 0.06200789 0.04962997
  0.03849949 0.03276725 0.03689128 0.04717808 0.03780377 0.02725375
  0.02716314 0.09442639 0.09883653 0.03886301 0.02865548 0.02139066
  0.02176507 0.02210554 0.02212071 0.04066178 0.06683357 0.01732685
  0.00752581 0.02658898]
 [0.02963434 0.02885953 0.03044834 0.05266542 0.04667243 0.04506769
  0.0285602  0.02550019 0.03125029 0.04427285 0.03345759 0.03116283
  0.02944985 0.1078166  0.13041987 0.03879048 0.03264827 0.02589455
  0.02446663 0.0234691  0.02107047 0.03407162 0.03893653 0.01203917
  0.00592306 0.01692544]
 [0.03005287 0.03300462 0.03990575 0.05567726 0.05131358 0.05756644
  0.03812763 0.03548494 0.04114264 0.0525482  0.03948014 0.04991721
  0.04515243 0.08483861 0.0799666  0.03290791 0.02997098 0.02596131
  0.02382001 0.02352955 0.02013989 0.03095082 0.03672563 0.01700719
  0.00867905 0.0167387 ]
 [0.02902732 0.04279593 0.04998943 0.04277268 0.0446706  0.05092221
  0.04230027 0.04507944 0.04371804 0.04626263 0.03973541 0.05336259
  0.0464891  0.05169449 0.04643476 0.04235919 0.03783417 0.03361372
  0.02954825 0.03018754 0.02808731 0.03534379 0.05115668 0.04229091
  0.02842997 0.03299187]
 [0.03022892 0.04441764 0.05411785 0.04923216 0.0444025  0.06093052
  0.04971977 0.0526198  0.05289145 0.05275852 0.04092755 0.05647935
  0.05178181 0.039783   0.02601041 0.03066428 0.02923078 0.02767434
  0.02585029 0.02654262 0.02232979 0.03543904 0.03946545 0.0219861
  0.01383841 0.02297899]
 [0.0295599  0.05843331 0.06129393 0.03104176 0.02446403 0.03977941
  0.05000061 0.04770561 0.04819193 0.03267921 0.03219045 0.04101934
  0.04136948 0.0177796  0.01467032 0.04632066 0.03564475 0.03103486
  0.030426   0.031846   0.03075618 0.03442653 0.06700653 0.0439061
  0.03504927 0.03767767]
 [0.03012203 0.04292475 0.04923632 0.02566533 0.02124681 0.02949102
  0.04991958 0.03775899 0.04364802 0.02602595 0.02614684 0.02910118
  0.02860538 0.01368026 0.01290593 0.0457966  0.03335591 0.02823672
  0.02960783 0.03144387 0.02916103 0.02983017 0.05376741 0.04951494
  0.04073263 0.03832261]
 [0.03063925 0.01489588 0.01734255 0.01184598 0.01010805 0.01494369
  0.01770402 0.01729884 0.02229785 0.01428098 0.01410306 0.01544271
  0.01463348 0.00640308 0.00630728 0.01945244 0.01851373 0.0176308
  0.02085804 0.021736   0.0227901  0.01826952 0.03004402 0.05634381
  0.06868364 0.06363174]
 [0.03021494 0.02429003 0.02558266 0.01662695 0.01444058 0.02110358
  0.02606705 0.0234918  0.0245418  0.01845875 0.02209935 0.02295816
  0.02204842 0.00908135 0.0091984  0.03486972 0.02866988 0.02904509
  0.0291502  0.03111743 0.0283633  0.02934085 0.02834699 0.04464007
  0.06678362 0.04742639]
 [0.03040051 0.02360964 0.02437593 0.01789986 0.01558329 0.02255457
  0.02740354 0.02788356 0.02600768 0.02131101 0.02556261 0.02910451
  0.02960942 0.00992177 0.00868607 0.03475791 0.03329419 0.03465918
  0.02943269 0.03083253 0.03154813 0.02966048 0.02097103 0.04673906
  0.05631682 0.02849555]
 [0.02996854 0.01929611 0.01699639 0.01420194 0.01172262 0.01561813
  0.02140156 0.02109317 0.01969133 0.01615273 0.02193224 0.02017072
  0.02318134 0.00700542 0.00688033 0.03246698 0.03097243 0.04306574
  0.03376495 0.0451909  0.04932923 0.02684661 0.0166288  0.04425092
  0.09508    0.0414152 ]
 [0.03073011 0.01713357 0.01610411 0.01321382 0.01167377 0.01572935
  0.02038143 0.02100674 0.01888525 0.01615273 0.02365335 0.02146465
  0.02237491 0.0065361  0.00641603 0.02854937 0.02550986 0.03859745
  0.03345936 0.05250807 0.04534153 0.02182497 0.0139435  0.02767983
  0.07051862 0.03450401]
 [0.03065089 0.01536076 0.01358319 0.01070396 0.00924536 0.01271513
  0.01733881 0.0168603  0.01689651 0.01310073 0.02343097 0.01655436
  0.01886813 0.00529488 0.00553696 0.02907172 0.02895067 0.03569776
  0.04035708 0.05024301 0.0410151  0.02281825 0.01477761 0.03452824
  0.05210901 0.05657162]
 [0.02989338 0.01972466 0.01742799 0.01306711 0.01158083 0.0164321
  0.02145595 0.0206915  0.0213984  0.01554294 0.02300727 0.01873642
  0.02080625 0.00648129 0.00671473 0.02744992 0.02948379 0.03142691
  0.04035913 0.0374101  0.0400144  0.02579159 0.02201758 0.06513795
  0.05151317 0.06545359]
 [0.03103973 0.02002769 0.01849731 0.01437598 0.01156414 0.01650996
  0.02116956 0.02147324 0.02064368 0.01633733 0.02308228 0.02074484
  0.02157586 0.00726177 0.00692556 0.02384251 0.02385665 0.0267098
  0.03340235 0.03323689 0.03118496 0.02596128 0.01581099 0.02767382
  0.03050927 0.03778061]
 [0.03120481 0.02417856 0.02666872 0.02174735 0.01667596 0.02615829
  0.02855243 0.03520656 0.02721523 0.02627107 0.02861534 0.03902023
  0.03547165 0.01225063 0.00876015 0.02231933 0.02387448 0.02752181
  0.02651849 0.02547659 0.02465384 0.02936555 0.01623275 0.02055422
  0.02041158 0.02008407]
 [0.03140045 0.02861925 0.02944596 0.02533883 0.01894947 0.02951327
  0.03496846 0.04396466 0.0293378  0.03000247 0.03666427 0.04507544
  0.04320449 0.01376361 0.00946996 0.0245836  0.02380865 0.02898157
  0.02552364 0.02535201 0.02386093 0.02969735 0.01776684 0.01805481
  0.01632065 0.01555404]
 [0.03128261 0.02666561 0.0263252  0.02369052 0.01863489 0.02728369
  0.03098786 0.0367764  0.02933469 0.02959695 0.03409577 0.03967418
  0.04013836 0.01277304 0.00953715 0.02839857 0.02607521 0.03153696
  0.02796583 0.0271403  0.02632361 0.02913218 0.01558101 0.02201089
  0.01744642 0.01479888]
 [0.03110901 0.01922097 0.01808156 0.01358059 0.01064426 0.01576171
  0.02077994 0.02356553 0.02183101 0.01677009 0.0234836  0.02170348
  0.02528271 0.00696488 0.006295   0.02975834 0.02789024 0.03049635
  0.02865201 0.02794666 0.03239025 0.02627773 0.01359445 0.03575052
  0.03193384 0.01983448]
 [0.03130531 0.01887582 0.01675064 0.01339217 0.009946   0.01438959
  0.02152477 0.02159019 0.02060478 0.01552629 0.02255331 0.01923736
  0.023703   0.00649443 0.00606177 0.0290161  0.02597407 0.03251849
  0.02858781 0.02884606 0.03531742 0.02262069 0.01252847 0.03397832
  0.03383913 0.02239417]
 [0.03141083 0.01908308 0.01698229 0.01430263 0.01121978 0.01584361
  0.02178452 0.02354264 0.02156335 0.01797455 0.02432574 0.02248849
  0.02521643 0.00745988 0.00663698 0.0252513  0.03040434 0.02981057
  0.03457028 0.02881978 0.03221558 0.02392179 0.01205283 0.02621715
  0.02097798 0.01896545]
 [0.03142604 0.02065358 0.01854752 0.01446228 0.01111373 0.01674252
  0.0245907  0.02487098 0.02431927 0.01765679 0.02605473 0.02228359
  0.02558834 0.00761061 0.00685083 0.02708095 0.02870519 0.03065131
  0.03271976 0.02977227 0.03318734 0.02464166 0.01330304 0.028833
  0.0234901  0.02263284]
 [0.03151456 0.01646474 0.01522417 0.01065793 0.00900228 0.01280715
  0.02070334 0.01960849 0.02095491 0.0135456  0.02777189 0.01760148
  0.02194286 0.00600684 0.00515233 0.02582296 0.03456616 0.02926073
  0.04297287 0.03630569 0.03487577 0.02353036 0.01168748 0.02687975
  0.02089405 0.03056972]
 [0.03058045 0.02095002 0.01977099 0.01226597 0.01038211 0.01530063
  0.02377815 0.02447439 0.02780034 0.01606951 0.02512707 0.01975426
  0.02554293 0.00687239 0.00595668 0.0258436  0.02887113 0.02736442
  0.03932473 0.03571327 0.0422651  0.02616078 0.02102493 0.05114214
  0.03570839 0.05096214]
 [0.03142662 0.02149664 0.02052585 0.0160847  0.01232794 0.01876986
  0.02229736 0.02478327 0.02589097 0.01949222 0.02441784 0.0239321
  0.02470459 0.00906251 0.00725354 0.0198925  0.02487079 0.023448
  0.03088208 0.02678338 0.02850291 0.02584715 0.01482336 0.02203944
  0.01753606 0.0236804 ]
 [0.03023926 0.02917165 0.02935524 0.04332499 0.0459003  0.03959235
  0.02678414 0.02749968 0.03240805 0.04577086 0.0345142  0.03534599
  0.03338132 0.06690315 0.08164938 0.02610477 0.03050376 0.02730697
  0.02614715 0.02404206 0.02323722 0.03274142 0.03423146 0.01339781
  0.00805443 0.01935943]
 [0.03002258 0.03108401 0.03002466 0.04890566 0.0953741  0.03965807
  0.02540325 0.0265654  0.03188831 0.05346819 0.04062886 0.03523755
  0.02724292 0.0705189  0.08800575 0.03273532 0.04235324 0.03731693
  0.0307619  0.02620936 0.0272394  0.02973545 0.03352332 0.01123233
  0.00550188 0.01643991]
 [0.02986177 0.02595797 0.02483837 0.03643545 0.07761501 0.02548285
  0.02024379 0.02423414 0.02701761 0.04335136 0.0360024  0.03416515
  0.02575282 0.02732455 0.03539013 0.02673348 0.058886   0.05530417
  0.04197494 0.03142967 0.04424464 0.0264005  0.0296417  0.01949796
  0.01226487 0.02270389]
 [0.03004101 0.03412016 0.03110455 0.04078779 0.05380276 0.032211
  0.0280074  0.02772721 0.03477805 0.04241624 0.03647215 0.0310331
  0.02941057 0.03217638 0.03504169 0.02440614 0.04214136 0.03770533
  0.03317842 0.03009871 0.03170542 0.04715422 0.04262639 0.01521508
  0.00915911 0.01955938]]

-* TASK 10/20 | SAMPLE 16/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 77/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie being in the kitchen in the context sentences. The last known location of Julie is the park, according to sentence 5.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' The', ' last', ' known', ' location', ' of', ' Julie', ' is', ' the', ' park', ',', ' according', ' to', ' sentence', ' ', '5', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.0789, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02456123 0.03127002 0.03173167 ... 0.03244608 0.01005633 0.0081974 ]
 [0.02516298 0.03154598 0.02937323 ... 0.04427192 0.01924492 0.0122833 ]
 [0.02570696 0.02896173 0.03116648 ... 0.05071764 0.02157205 0.01385101]
 ...
 [0.02567917 0.02715754 0.02428473 ... 0.01331108 0.00763086 0.00709526]
 [0.02601528 0.02234569 0.01933045 ... 0.00993944 0.01066419 0.01253169]
 [0.02616356 0.02203686 0.01900357 ... 0.0082012  0.0096538  0.01142456]]

-* TASK 10/20 | SAMPLE 16/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 78/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred's location in the context sentences. The sentences only mention Julie and Mary's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Julie', ' and', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03015692 0.03893512 0.03728876 ... 0.02246427 0.02148101 0.04956833]
 [0.03076181 0.03148309 0.02711802 ... 0.02337991 0.02809939 0.03247646]
 [0.03149109 0.03838918 0.0373952  ... 0.01885303 0.01624579 0.03828911]
 ...
 [0.03192369 0.03202491 0.0267585  ... 0.02804095 0.0249152  0.03791565]
 [0.03239553 0.03753108 0.03257592 ... 0.02274518 0.02087884 0.039876  ]
 [0.03262663 0.03150922 0.0283669  ... 0.02102283 0.0206106  0.03563929]]

-* TASK 10/20 | SAMPLE 16/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 79/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 10, Mary is in the office, and there is no information about her moving to the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Mary', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' her', ' moving', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0645, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03003008 0.03827082 0.04551922 ... 0.01518512 0.02076341 0.01256667]
 [0.03057719 0.03421121 0.03824984 ... 0.02493361 0.03685021 0.02602834]
 [0.03129653 0.04111415 0.05251294 ... 0.0225454  0.03002471 0.01571436]
 ...
 [0.03153642 0.04684873 0.04271372 ... 0.00968936 0.01254035 0.00931714]
 [0.03213768 0.03584053 0.02980891 ... 0.01192976 0.00990611 0.01209058]
 [0.03193839 0.03898964 0.03200751 ... 0.01202478 0.0126838  0.01399671]]

-* TASK 10/20 | SAMPLE 16/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 80/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 13, Mary went to the park, which implies that she is now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Mary', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03225663 0.05152523 0.0453885  ... 0.04788571 0.02538541 0.01972665]
 [0.03293304 0.05459982 0.04867075 ... 0.0384089  0.03091119 0.02812056]
 [0.03375001 0.05398702 0.05347062 ... 0.04091259 0.02267708 0.01585915]
 ...
 [0.03394797 0.04833391 0.04691057 ... 0.03519473 0.01996439 0.0173584 ]
 [0.03417641 0.03658734 0.03233293 ... 0.03867902 0.03028266 0.0274521 ]
 [0.03409177 0.0445245  0.03744211 ... 0.03926692 0.02435969 0.02543957]]
Model's predictions for the sample 16:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to sentence 2, Julie went to   |
|          |                 |   the school, which implies that she is    |
|          |                 |             now in the school.             |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    There is no information about Julie     |
|          |                 |    being in the kitchen in the context     |
|          |                 |   sentences. The last known location of    |
|          |                 |  Julie is the park, according to sentence  |
|          |                 |                     5.                     |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Fred's    |
|          |                 |   location in the context sentences. The   |
|          |                 |  sentences only mention Julie and Mary's   |
|          |                 |                 locations.                 |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 10, Mary is in the  |
|          |                 |    office, and there is no information     |
|          |                 |      about her moving to the school.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to sentence 13, Mary went to   |
|          |                 |  the park, which implies that she is now   |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+

Metrics for sample 16:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 17/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 81/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence (1) states that Julie is either in the kitchen or the office, but it does not provide a definitive location. Therefore, we cannot conclude that Julie is definitely in the kitchen.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '1', ')', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Julie', ' is', ' definitely', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 26), x_tokens=26, y_tokens=51, max_supp_attn=0.0392, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 26)
DEBUG result.interpretability.attn_scores 1326 
 [[0.01799032 0.02998351 0.03389082 ... 0.01041004 0.01375321 0.02277045]
 [0.01812174 0.04064819 0.03792371 ... 0.00778588 0.0119743  0.02333879]
 [0.01955799 0.04253055 0.02498159 ... 0.00296185 0.00548007 0.01295873]
 ...
 [0.01924139 0.01875265 0.01982786 ... 0.00346649 0.00578659 0.01611399]
 [0.01918156 0.0160903  0.01672694 ... 0.01005821 0.01189033 0.01706484]
 [0.01952819 0.01590539 0.01657077 ... 0.00815326 0.01055631 0.01572531]]

-* TASK 10/20 | SAMPLE 17/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 82/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence (4) states that Julie is either in the bedroom or the bedroom, which means Julie is definitely in the bedroom. There is no mention of the kitchen in the context sentences.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '4', ')', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' bedroom', ',', ' which', ' means', ' Julie', ' is', ' definitely', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' mention', ' of', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0217, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02018948 0.02861249 0.03149459 ... 0.00764774 0.00567294 0.01097546]
 [0.0208129  0.02682198 0.0284991  ... 0.00954924 0.00652122 0.0158282 ]
 [0.02119857 0.02576501 0.03066057 ... 0.01733899 0.00700418 0.01887989]
 ...
 [0.02116973 0.02840745 0.02648764 ... 0.00529077 0.00646414 0.00775707]
 [0.02137471 0.0231861  0.02076273 ... 0.00608729 0.01085795 0.00795578]
 [0.02143916 0.0239976  0.02081934 ... 0.00472753 0.00783808 0.00710361]]

-* TASK 10/20 | SAMPLE 17/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 83/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence (7) states that Fred moved to the bedroom, but the context sentence (8) states that Fred is either in the office or the cinema. These two sentences contradict each other, and we cannot conclude that Fred is in the cinema based on the provided information.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '7', ')', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' bedroom', ',', ' but', ' the', ' context', ' sentence', ' (', '8', ')', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' cinema', '.', ' These', ' two', ' sentences', ' contradict', ' each', ' other', ',', ' and', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' in', ' the', ' cinema', ' based', ' on', ' the', ' provided', ' information', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(63, 38), x_tokens=38, y_tokens=63, max_supp_attn=0.0317, attn_on_target=0.0159)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (63, 38)
DEBUG result.interpretability.attn_scores 2394 
 [[0.01440483 0.02225007 0.02300012 ... 0.02754582 0.02168594 0.01138842]
 [0.01477102 0.02184287 0.02073923 ... 0.01561868 0.02315038 0.01748197]
 [0.01519666 0.02279623 0.02347696 ... 0.02646027 0.01729399 0.01019039]
 ...
 [0.01533605 0.01957644 0.01807691 ... 0.06758749 0.01571477 0.00887564]
 [0.0158825  0.01562931 0.01318512 ... 0.03940201 0.01299953 0.01142119]
 [0.01576511 0.01665215 0.01439884 ... 0.04597122 0.0135589  0.01086723]]

-* TASK 10/20 | SAMPLE 17/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 84/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred in the context sentences. The sentences only talk about Mary and Julie's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', ' and', ' Julie', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03109915 0.03913783 0.03894786 ... 0.04952229 0.09264644 0.01884938]
 [0.03187448 0.02654122 0.0287703  ... 0.03145875 0.078393   0.03234262]
 [0.03266454 0.03503729 0.03770843 ... 0.02443649 0.08383115 0.0293894 ]
 ...
 [0.03297428 0.03097953 0.02931743 ... 0.04598075 0.01571706 0.01625533]
 [0.03347887 0.0326439  0.033931   ... 0.04823584 0.01575066 0.01555168]
 [0.03371971 0.02765997 0.02988068 ... 0.05138354 0.01694638 0.01424731]]

-* TASK 10/20 | SAMPLE 17/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 85/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence (13) states that Mary is either in the school or the kitchen, but the context sentence (14) states that Mary travelled to the bedroom. This means Mary is no longer in the school or the kitchen, but is now in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '13', ')', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' the', ' context', ' sentence', ' (', '14', ')', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', '.', ' This', ' means', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' is', ' now', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(60, 50), x_tokens=50, y_tokens=60, max_supp_attn=0.0167, attn_on_target=0.0167)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (60, 50)
DEBUG result.interpretability.attn_scores 3000 
 [[0.01526195 0.02442796 0.02569916 ... 0.01904076 0.02902955 0.03143007]
 [0.01565522 0.01702577 0.01833624 ... 0.01530058 0.01231379 0.01804819]
 [0.01595567 0.02602343 0.03000178 ... 0.02254967 0.02488924 0.02494259]
 ...
 [0.01615311 0.02611455 0.02414982 ... 0.04226734 0.0847669  0.02724906]
 [0.01658614 0.02133263 0.01867596 ... 0.02228014 0.06119241 0.02018289]
 [0.01656723 0.02132965 0.01776767 ... 0.01555885 0.08201146 0.0244773 ]]
Model's predictions for the sample 17:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentence (1) states that    |
|          |                 |   Julie is either in the kitchen or the    |
|          |                 |     office, but it does not provide a      |
|          |                 |     definitive location. Therefore, we     |
|          |                 |  cannot conclude that Julie is definitely  |
|          |                 |              in the kitchen.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentence (4) states that    |
|          |                 |   Julie is either in the bedroom or the    |
|          |                 |  bedroom, which means Julie is definitely  |
|          |                 |   in the bedroom. There is no mention of   |
|          |                 |   the kitchen in the context sentences.    |
+----------+-----------------+--------------------------------------------+
|  maybe   |        no       |    The context sentence (7) states that    |
|          |                 |     Fred moved to the bedroom, but the     |
|          |                 |  context sentence (8) states that Fred is  |
|          |                 |    either in the office or the cinema.     |
|          |                 |    These two sentences contradict each     |
|          |                 |  other, and we cannot conclude that Fred   |
|          |                 |   is in the cinema based on the provided   |
|          |                 |                information.                |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |     There is no mention of Fred in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |   talk about Mary and Julie's locations.   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   The context sentence (13) states that    |
|          |                 |    Mary is either in the school or the     |
|          |                 |   kitchen, but the context sentence (14)   |
|          |                 |     states that Mary travelled to the      |
|          |                 |  bedroom. This means Mary is no longer in  |
|          |                 |  the school or the kitchen, but is now in  |
|          |                 |                the bedroom.                |
+----------+-----------------+--------------------------------------------+

Metrics for sample 17:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 18/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 86/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 2, Mary moved to the school. There is no information that suggests Mary is in the cinema. Sentence 1 only provides information about Fred's possible locations, which does not affect Mary's location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' moved', ' to', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '1', ' only', ' provides', ' information', ' about', ' Fred', "'s", ' possible', ' locations', ',', ' which', ' does', ' not', ' affect', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 26), x_tokens=26, y_tokens=51, max_supp_attn=0.2157, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 26)
DEBUG result.interpretability.attn_scores 1326 
 [[0.0181558  0.03701766 0.03872333 ... 0.00463814 0.00600328 0.0202978 ]
 [0.01872598 0.02300555 0.02306606 ... 0.00395806 0.00488483 0.01327241]
 [0.0190255  0.02589652 0.02916699 ... 0.0062066  0.00709135 0.01290446]
 ...
 [0.0191486  0.02315709 0.02331251 ... 0.00348709 0.00422966 0.0118087 ]
 [0.01915115 0.0165283  0.01712201 ... 0.00845052 0.00873923 0.01402832]
 [0.01920908 0.02192424 0.02143681 ... 0.0062484  0.00646551 0.01210853]]

-* TASK 10/20 | SAMPLE 18/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 87/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary's location in the given context sentences. Sentence 2 from the previous part mentioned that Mary moved to the school, but it is not mentioned in the current context.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '2', ' from', ' the', ' previous', ' part', ' mentioned', ' that', ' Mary', ' moved', ' to', ' the', ' school', ',', ' but', ' it', ' is', ' not', ' mentioned', ' in', ' the', ' current', ' context', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 32), x_tokens=32, y_tokens=48, max_supp_attn=0.0417, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 32)
DEBUG result.interpretability.attn_scores 1536 
 [[0.01919073 0.02227684 0.02267262 ... 0.00880201 0.01078793 0.01257165]
 [0.01986123 0.02008456 0.01996093 ... 0.01096155 0.01465081 0.0179387 ]
 [0.02024044 0.01852797 0.0208113  ... 0.01660832 0.02011323 0.02032663]
 ...
 [0.02072126 0.02147938 0.01921588 ... 0.00720784 0.00963438 0.01051572]
 [0.02090712 0.02230592 0.02013126 ... 0.00618618 0.01113411 0.01338344]
 [0.02100031 0.01865354 0.01671678 ... 0.00646314 0.01074304 0.01306192]]

-* TASK 10/20 | SAMPLE 18/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 88/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 5, Fred journeyed to the office. There is no information that suggests Fred left the office or moved to a different location.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '5', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' left', ' the', ' office', ' or', ' moved', ' to', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 38), x_tokens=38, y_tokens=37, max_supp_attn=0.1081, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 38)
DEBUG result.interpretability.attn_scores 1406 
 [[0.02514887 0.03613841 0.03803387 ... 0.0408974  0.05856487 0.02750531]
 [0.02551346 0.02779269 0.02719917 ... 0.02356086 0.03475671 0.03877972]
 [0.0261168  0.04224594 0.04867202 ... 0.04558326 0.04242118 0.02061531]
 ...
 [0.02629869 0.04192394 0.03961785 ... 0.09491529 0.05865195 0.01940186]
 [0.02688965 0.02852292 0.02574344 ... 0.05772567 0.02982282 0.02196211]
 [0.0266631  0.03659238 0.03256738 ... 0.08004022 0.0682382  0.01910183]]

-* TASK 10/20 | SAMPLE 18/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 89/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 states that Mary is either in the park or the kitchen, but it does not provide a definitive location. Therefore, we can only conclude that Mary might be in the park, but we are not certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' park', ',', ' but', ' we', ' are', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 44), x_tokens=44, y_tokens=51, max_supp_attn=0.0, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 44)
DEBUG result.interpretability.attn_scores 2244 
 [[0.01788595 0.0253927  0.02356701 ... 0.03929164 0.03658831 0.00910825]
 [0.01812719 0.01968849 0.01875439 ... 0.04624263 0.05193376 0.0296713 ]
 [0.01861552 0.0262437  0.02701348 ... 0.02737447 0.05470692 0.01349318]
 ...
 [0.01887227 0.02591428 0.02554047 ... 0.02965741 0.0150392  0.00716957]
 [0.0192727  0.02048002 0.0193715  ... 0.02278217 0.0107128  0.00850499]
 [0.01930675 0.01987608 0.01970514 ... 0.0320036  0.01067473 0.00815351]]

-* TASK 10/20 | SAMPLE 18/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 90/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Fred travelled to the kitchen, but sentence 14 provides alternative locations for Fred (cinema or bedroom). There is no information that suggests Fred left the kitchen or moved to one of the alternative locations.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' kitchen', ',', ' but', ' sentence', ' ', '14', ' provides', ' alternative', ' locations', ' for', ' Fred', ' (', 'cin', 'ema', ' or', ' bedroom', ').', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' left', ' the', ' kitchen', ' or', ' moved', ' to', ' one', ' of', ' the', ' alternative', ' locations', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0577, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01740541 0.02888675 0.02966071 ... 0.01275502 0.03591622 0.02799367]
 [0.01801722 0.02372104 0.02509035 ... 0.0158436  0.01922095 0.01948836]
 [0.01827184 0.02995134 0.03277601 ... 0.01583061 0.04090246 0.02951677]
 ...
 [0.01861973 0.02895724 0.02530572 ... 0.01068766 0.10061615 0.02495692]
 [0.01929692 0.02271971 0.01819665 ... 0.00960038 0.07265861 0.01512566]
 [0.01899618 0.02705399 0.02141201 ... 0.01049057 0.07756628 0.02308006]]
Model's predictions for the sample 18:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 2, Mary moved to   |
|          |                 |  the school. There is no information that  |
|          |                 |  suggests Mary is in the cinema. Sentence  |
|          |                 |  1 only provides information about Fred's  |
|          |                 |     possible locations, which does not     |
|          |                 |          affect Mary's location.           |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |   There is no information provided about   |
|          |                 |    Mary's location in the given context    |
|          |                 |  sentences. Sentence 2 from the previous   |
|          |                 |   part mentioned that Mary moved to the    |
|          |                 |   school, but it is not mentioned in the   |
|          |                 |              current context.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 5, Fred journeyed   |
|          |                 |   to the office. There is no information   |
|          |                 |   that suggests Fred left the office or    |
|          |                 |       moved to a different location.       |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 11 states that Mary is either   |
|          |                 |  in the park or the kitchen, but it does   |
|          |                 |     not provide a definitive location.     |
|          |                 |    Therefore, we can only conclude that    |
|          |                 |   Mary might be in the park, but we are    |
|          |                 |                not certain.                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 13 states that Fred travelled   |
|          |                 |  to the kitchen, but sentence 14 provides  |
|          |                 |   alternative locations for Fred (cinema   |
|          |                 |    or bedroom). There is no information    |
|          |                 |   that suggests Fred left the kitchen or   |
|          |                 |      moved to one of the alternative       |
|          |                 |                 locations.                 |
+----------+-----------------+--------------------------------------------+

Metrics for sample 18:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.11 ± 0.08 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 19/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 91/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: Sentence 2 explicitly states that Fred is in the kitchen, which contradicts the ambiguity in sentence 1.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '2', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' kitchen', ',', ' which', ' contrad', 'icts', ' the', ' ambiguity', ' in', ' sentence', ' ', '1', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1818, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02793854 0.04886739 0.0613154  0.07677941 0.08163331 0.0766843
  0.05898672 0.07016668 0.05607535 0.06136442 0.04711509 0.05765901
  0.0610343  0.09557702 0.06558871 0.03446832 0.03213416 0.03391932
  0.02915411 0.03497082 0.02935644 0.0389875  0.04985328 0.01734647
  0.02064453 0.02620566]
 [0.027739   0.08270896 0.06177294 0.04871058 0.03727528 0.0489964
  0.15506724 0.09800993 0.0548399  0.04392497 0.07795624 0.0486601
  0.07762598 0.02141024 0.0198978  0.04736678 0.04505126 0.06175381
  0.04689509 0.0555874  0.04854548 0.04064954 0.04292254 0.0411318
  0.03057219 0.03521502]
 [0.0304716  0.06165454 0.03826213 0.05689967 0.03922158 0.03733096
  0.03138913 0.02355673 0.02286085 0.03409484 0.02668506 0.01704079
  0.01805788 0.03202471 0.0427498  0.02577477 0.01637641 0.01534003
  0.01830217 0.0207596  0.01937175 0.04452157 0.05767741 0.00483713
  0.0051129  0.01156084]
 [0.02861641 0.03593677 0.03630965 0.02312777 0.01829657 0.02521012
  0.02619843 0.02632599 0.02805089 0.02380483 0.02478603 0.02501078
  0.0227779  0.01332063 0.01317459 0.03646983 0.03381339 0.03046989
  0.03653801 0.03637455 0.03315004 0.03200408 0.05710261 0.06496467
  0.06812642 0.05234595]
 [0.02895777 0.04450358 0.04872938 0.06769873 0.06412265 0.04829505
  0.03354622 0.03038773 0.0345557  0.04611722 0.03508455 0.02681169
  0.02613097 0.10370415 0.10983491 0.04159764 0.03082912 0.02331864
  0.02370433 0.02732472 0.02703978 0.03890368 0.06692459 0.00725751
  0.00890129 0.02570801]
 [0.02959426 0.02949984 0.02983871 0.05155014 0.04922732 0.04155634
  0.02462569 0.02401415 0.02963156 0.04263819 0.03151929 0.0302591
  0.02807424 0.1136812  0.13520493 0.04099571 0.03422892 0.02779317
  0.02665143 0.02858994 0.02637163 0.03337904 0.03963704 0.00625858
  0.0066537  0.0166664 ]
 [0.03004387 0.03283339 0.03710322 0.05356149 0.05216823 0.051601
  0.03195805 0.03172179 0.03699721 0.04922636 0.03604481 0.04649226
  0.04098127 0.0892894  0.08547454 0.03413504 0.03074074 0.02716309
  0.02481537 0.02717011 0.02446576 0.0303417  0.03621083 0.00911744
  0.01111754 0.0168178 ]
 [0.02897846 0.0409099  0.04617719 0.04142575 0.0463544  0.04622271
  0.03466767 0.03897537 0.03904062 0.04188268 0.03528191 0.04865135
  0.04101172 0.05278886 0.04879457 0.04256701 0.0376861  0.03305551
  0.03061321 0.03326496 0.03197294 0.03498904 0.05211795 0.02517624
  0.03388699 0.03844438]
 [0.02976366 0.03874534 0.04620735 0.02717443 0.02451229 0.03175284
  0.04236742 0.03625668 0.03998079 0.0276252  0.02707599 0.03286076
  0.03051602 0.0174864  0.01672573 0.04757388 0.03730015 0.0313288
  0.03377061 0.0359906  0.03340863 0.02928594 0.05232636 0.02679376
  0.04374705 0.0454399 ]
 [0.03030495 0.01664332 0.02038648 0.01378933 0.01304921 0.01787382
  0.01872914 0.01955793 0.02481612 0.01651542 0.015487   0.01884544
  0.01773757 0.0085007  0.00850882 0.02432656 0.02264252 0.02070369
  0.02460564 0.02522653 0.02427027 0.0199537  0.03004737 0.03013431
  0.06469313 0.07117243]
 [0.02991928 0.02830799 0.03215222 0.02110515 0.0187414  0.02756972
  0.02814337 0.0289986  0.02724881 0.02280511 0.02489357 0.02998781
  0.02594713 0.01157927 0.01146348 0.03966567 0.03027425 0.03158208
  0.03244529 0.03282561 0.03116786 0.03091497 0.03147706 0.03593185
  0.05174235 0.05276919]
 [0.03056197 0.03585558 0.0396804  0.03282115 0.02561543 0.04051777
  0.03633972 0.04113999 0.03525936 0.03762957 0.03668752 0.05509611
  0.04327417 0.01807474 0.0140946  0.0332226  0.03058144 0.03403573
  0.03071071 0.03248933 0.02977424 0.03186735 0.025903   0.02665356
  0.02433379 0.02550285]
 [0.03094979 0.02619467 0.02842561 0.02190236 0.01907174 0.02599409
  0.0289013  0.02890307 0.02551831 0.02415616 0.02928119 0.03009095
  0.02875884 0.01154636 0.01105777 0.03368205 0.02895496 0.02852011
  0.02886048 0.02973019 0.02893369 0.03004344 0.02196239 0.02799589
  0.03227745 0.02371869]
 [0.03034759 0.02019759 0.01898631 0.01443021 0.01258053 0.01674782
  0.02123626 0.02166185 0.01998599 0.01629263 0.02455577 0.02016753
  0.02219931 0.00746316 0.00842732 0.03771339 0.03269545 0.03291821
  0.03319015 0.03139611 0.0324691  0.02835661 0.01756248 0.04017052
  0.05359268 0.04086941]
 [0.0301118  0.02068394 0.01867009 0.01465979 0.01196635 0.01636832
  0.02706338 0.02662045 0.02064264 0.01611268 0.02765924 0.01989311
  0.02601029 0.00716003 0.0075335  0.03957674 0.03590708 0.04878479
  0.04757192 0.04897268 0.05059653 0.02610348 0.01616863 0.05222855
  0.05514982 0.03861385]
 [0.03069386 0.01897893 0.01686925 0.01344847 0.01220129 0.01599459
  0.02121698 0.02147753 0.01900909 0.01558997 0.02870554 0.02116768
  0.02212826 0.00702204 0.0071025  0.0312894  0.0342863  0.03342121
  0.03893866 0.03080988 0.03376044 0.02501734 0.01238666 0.04576262
  0.04877545 0.04200063]
 [0.03043807 0.01672372 0.0148823  0.01092724 0.01067478 0.0130643
  0.01974935 0.01848799 0.0178515  0.01306352 0.03106762 0.01812033
  0.01994701 0.00595794 0.00642361 0.03303765 0.03906633 0.03774022
  0.04233188 0.03531676 0.04133237 0.024461   0.01336501 0.05326132
  0.03429716 0.05888984]
 [0.0304845  0.01964659 0.01983331 0.01354425 0.01262704 0.01845315
  0.0217994  0.02402539 0.02508642 0.01582276 0.02167749 0.02023254
  0.02186322 0.00779341 0.007233   0.02012719 0.02434385 0.02242107
  0.02859462 0.02692853 0.02870561 0.02570046 0.02101988 0.06806993
  0.05223456 0.04254431]
 [0.03103445 0.01903569 0.01848053 0.01716554 0.01346184 0.01816589
  0.01956999 0.02175963 0.02173118 0.01902473 0.02415597 0.02215971
  0.02223202 0.00962196 0.00871744 0.01865651 0.02229114 0.02550836
  0.02718484 0.02598541 0.02822017 0.02580122 0.01569339 0.02656125
  0.02344965 0.03716519]
 [0.03108079 0.02234559 0.02725809 0.02735894 0.02007947 0.03000523
  0.02411656 0.03026972 0.03044393 0.03090429 0.02629158 0.03668448
  0.03167093 0.0162537  0.01073243 0.01803335 0.02189841 0.02367723
  0.02389253 0.02309549 0.02373946 0.02907884 0.01815121 0.02336577
  0.02247283 0.02843284]
 [0.03138249 0.02476161 0.0264266  0.02679976 0.01906578 0.02820382
  0.02622639 0.03480574 0.02999587 0.03172264 0.02773262 0.03858665
  0.0355789  0.0151538  0.01029896 0.01837063 0.02135994 0.02305781
  0.02362611 0.02225931 0.02193092 0.02738834 0.01642151 0.0241813
  0.01903879 0.02232854]
 [0.03175186 0.02294231 0.0229223  0.02422078 0.01791256 0.02932405
  0.02404038 0.02762521 0.03208188 0.02806222 0.02394342 0.03112549
  0.03150288 0.01313703 0.00898791 0.01678086 0.02003138 0.02385052
  0.02589694 0.02675395 0.02305646 0.02419977 0.01488695 0.02113851
  0.02174364 0.01998609]
 [0.03120498 0.02174336 0.02125674 0.01584999 0.01230027 0.01891912
  0.01940607 0.0240917  0.02620434 0.01861913 0.02108413 0.02376559
  0.02467944 0.00954575 0.00748721 0.01998316 0.02176834 0.02098584
  0.026669   0.02681386 0.027823   0.02732041 0.01792422 0.04497207
  0.03746687 0.02455313]
 [0.03071121 0.02745194 0.02574676 0.01606408 0.01327461 0.02111636
  0.02272221 0.0292054  0.02959924 0.01996732 0.02429261 0.02691421
  0.03044722 0.01043664 0.00736869 0.02302452 0.02619663 0.02285031
  0.02944207 0.02657937 0.02843176 0.02753485 0.02068801 0.07516399
  0.04933298 0.026419  ]
 [0.03144517 0.027005   0.02650673 0.02040089 0.01598057 0.02549258
  0.02537397 0.03116209 0.03252112 0.02750524 0.03160152 0.03525614
  0.03597816 0.01228424 0.00825867 0.0220133  0.02814599 0.031415
  0.0312906  0.02830649 0.02700431 0.02930689 0.01730959 0.03774892
  0.02459205 0.01375791]
 [0.03154997 0.0233656  0.02438881 0.01437387 0.01246008 0.01836861
  0.02110512 0.0255359  0.02846809 0.01756799 0.02022002 0.02276293
  0.0240095  0.00943201 0.0073215  0.02319532 0.02248999 0.01902274
  0.02462094 0.02427118 0.02410983 0.02930707 0.02208452 0.03736857
  0.03294739 0.01753525]
 [0.03115789 0.03179683 0.03659227 0.01819375 0.01493945 0.02202907
  0.03239487 0.02950323 0.04087248 0.01957458 0.01965828 0.0220497
  0.02347829 0.01081944 0.00920668 0.03442031 0.02838939 0.02334353
  0.02723076 0.03018565 0.02781764 0.02700278 0.03985873 0.02206925
  0.03023115 0.02323007]
 [0.03097465 0.02957867 0.02634388 0.03640159 0.04060258 0.04300036
  0.02519462 0.02518187 0.03182186 0.04678132 0.04211386 0.03838037
  0.03596124 0.0540002  0.03886497 0.02469338 0.02305449 0.02304271
  0.02118691 0.02267611 0.02059917 0.03702844 0.02736189 0.00885178
  0.00994627 0.01399276]
 [0.03121228 0.01835385 0.01978075 0.01334143 0.01103137 0.01657392
  0.01756333 0.0203188  0.02437982 0.01615552 0.02066789 0.0193674
  0.02091132 0.0087022  0.00679433 0.02203454 0.02145437 0.01931867
  0.02436415 0.02452048 0.0251038  0.02364116 0.01771647 0.0565158
  0.04198179 0.03013527]
 [0.03030012 0.02814719 0.02820331 0.04278638 0.04399786 0.03753464
  0.02225068 0.02471995 0.03110351 0.04348367 0.03180395 0.03046164
  0.03253599 0.07452244 0.08946074 0.02919556 0.02859787 0.02764343
  0.02661118 0.02721392 0.02567791 0.03081265 0.03216071 0.00689972
  0.0084708  0.01820624]
 [0.03005075 0.02978913 0.02923211 0.04809928 0.09501167 0.03658734
  0.02070205 0.02317348 0.02990773 0.05017467 0.03771738 0.03089795
  0.02612533 0.07177413 0.09240659 0.03478713 0.04214825 0.04070798
  0.03240221 0.03075899 0.03202615 0.02828362 0.03252975 0.00624955
  0.00652799 0.01645134]
 [0.02996092 0.02442896 0.02330573 0.03607481 0.06977071 0.02423688
  0.01607835 0.02017944 0.02438129 0.04214832 0.03369665 0.02851133
  0.02447304 0.02728388 0.03985859 0.02704141 0.05567189 0.06292954
  0.04302854 0.03441229 0.05206811 0.024728   0.02548816 0.01519382
  0.01490213 0.02443786]
 [0.03026708 0.0303622  0.02795343 0.03931298 0.05077171 0.03020891
  0.02127001 0.02217996 0.02903661 0.03964187 0.03345627 0.02602907
  0.02633962 0.03265232 0.03494515 0.02417977 0.03958949 0.03837696
  0.03485955 0.03243908 0.0376988  0.04308549 0.03705975 0.01062755
  0.01103665 0.01888325]]

-* TASK 10/20 | SAMPLE 19/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 92/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 4 states that Mary travelled to the bedroom, implying that she has arrived at the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', ',', ' implying', ' that', ' she', ' has', ' arrived', ' at', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 32), x_tokens=32, y_tokens=27, max_supp_attn=0.037, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 32)
DEBUG result.interpretability.attn_scores 864 
 [[0.03459199 0.05234468 0.0507935  0.0801513  0.07110042 0.05850502
  0.03947601 0.04397176 0.05623903 0.05979932 0.03708557 0.0387249
  0.03953058 0.1188506  0.11860902 0.03249392 0.03021611 0.02402746
  0.02750513 0.02764735 0.02457418 0.04131368 0.0680554  0.01238269
  0.02451379 0.04283479 0.05464334 0.05317835 0.1202025  0.07033692
  0.01306794 0.0200562 ]
 [0.03540127 0.05445592 0.05361387 0.10016231 0.098963   0.09561118
  0.0497996  0.05371343 0.06891157 0.09021448 0.05335279 0.06874341
  0.06472879 0.17644311 0.13917077 0.03465383 0.03166916 0.02921514
  0.02923636 0.02924565 0.02605428 0.04460486 0.05452235 0.01257822
  0.02181395 0.0352989  0.05981645 0.04499275 0.09159511 0.08208463
  0.01742894 0.02861512]
 [0.03606084 0.05105014 0.05959911 0.08359949 0.07284968 0.07297549
  0.04514999 0.05041831 0.06248811 0.06816506 0.04008829 0.05755092
  0.04998315 0.1259179  0.09042273 0.03170744 0.0295495  0.02387688
  0.02606213 0.02576706 0.02276116 0.04109862 0.05139623 0.01335538
  0.02472296 0.03331809 0.0539536  0.03800478 0.06351434 0.08185896
  0.02513366 0.0376216 ]
 [0.03481369 0.05175389 0.0538042  0.04395892 0.03722135 0.04286382
  0.04093258 0.04598557 0.0446287  0.03913458 0.03185612 0.04267287
  0.0397186  0.03301458 0.03209754 0.03944005 0.03522956 0.02895737
  0.03043204 0.0319108  0.02827307 0.04077054 0.05882137 0.02807809
  0.05012939 0.04676208 0.05176939 0.04255545 0.04601764 0.09674782
  0.0424836  0.07180969]
 [0.03601341 0.04368428 0.04658889 0.0312133  0.02421608 0.03274896
  0.03720833 0.03615205 0.04270774 0.02892261 0.02457041 0.02983717
  0.02766788 0.02053348 0.02150767 0.03370311 0.03034632 0.02281948
  0.02954005 0.02985796 0.02608015 0.03422794 0.05114795 0.02255405
  0.042852   0.04040204 0.04617478 0.02875549 0.03377866 0.08716867
  0.03587215 0.07152861]
 [0.03686266 0.02158323 0.0236405  0.01679719 0.01378637 0.01838549
  0.01906113 0.01784638 0.02181759 0.01754672 0.01882601 0.01748572
  0.01763443 0.010741   0.01257197 0.02133009 0.02062648 0.01861358
  0.02297428 0.0256586  0.02205379 0.02387415 0.02805555 0.02456629
  0.03638942 0.03001993 0.02094151 0.02072719 0.02283875 0.03679531
  0.02721527 0.03033079]
 [0.03580764 0.0430344  0.04488849 0.03157483 0.02374536 0.0337529
  0.03684085 0.0359118  0.03519564 0.03095698 0.02886406 0.03608381
  0.03210391 0.01977303 0.01954242 0.04018547 0.03713284 0.03479935
  0.03359808 0.03799046 0.03193588 0.04165422 0.04649792 0.03447741
  0.04770684 0.04159438 0.04552335 0.02755475 0.03147206 0.0765411
  0.04559516 0.05526051]
 [0.03702078 0.04264691 0.04664551 0.03535962 0.02777007 0.04104321
  0.04320979 0.04372209 0.03961094 0.03670638 0.03140154 0.0431561
  0.04131479 0.02339531 0.02033971 0.0387157  0.03401037 0.02995098
  0.03148496 0.03214646 0.02890283 0.03963057 0.04321892 0.03402022
  0.04873813 0.03689647 0.04406721 0.02939402 0.03188079 0.07051069
  0.07077947 0.06554374]
 [0.0367882  0.02995519 0.02719704 0.01965698 0.01693748 0.02326039
  0.02782723 0.02511023 0.02570708 0.02260128 0.02530733 0.02490854
  0.02769334 0.01235797 0.01415693 0.04123621 0.03629327 0.03291077
  0.03324438 0.03465582 0.03169419 0.03728418 0.02976904 0.03767281
  0.04330684 0.02908996 0.03113444 0.02508085 0.02359404 0.03007684
  0.06968681 0.03460755]
 [0.03643845 0.03210291 0.02720333 0.01936277 0.01643799 0.02303537
  0.02968936 0.02806853 0.02624347 0.02215226 0.02530733 0.02388939
  0.0283514  0.01230385 0.01406065 0.04627407 0.04127498 0.04493009
  0.04025023 0.04111212 0.04271189 0.03521633 0.02775223 0.04443689
  0.04603586 0.03713274 0.03027226 0.03127222 0.02235428 0.02005045
  0.05852139 0.02935134]
 [0.03762136 0.03022973 0.02790016 0.02023791 0.01846473 0.02546809
  0.02949705 0.02688144 0.02814858 0.02433964 0.03354659 0.02826791
  0.02953826 0.01358389 0.01472977 0.04717793 0.03768478 0.05598868
  0.04294891 0.06390936 0.04760563 0.03061906 0.02589442 0.04815703
  0.03903574 0.03775088 0.02860537 0.02658216 0.02090373 0.01695594
  0.04107496 0.02934701]
 [0.03767295 0.02573272 0.02493665 0.01556551 0.01540612 0.02095827
  0.02652678 0.02321419 0.02525789 0.02000502 0.03474875 0.02413759
  0.02606974 0.01112799 0.01266463 0.04134728 0.04153087 0.04026716
  0.04156684 0.04665244 0.04360309 0.03266555 0.02485605 0.06250858
  0.04085266 0.03978664 0.02507999 0.02834356 0.02052429 0.0156772
  0.04472682 0.02746809]
 [0.03662036 0.04110041 0.04095128 0.0259874  0.02779063 0.03901017
  0.04807837 0.04380453 0.04146321 0.03396212 0.04900232 0.04558039
  0.04345544 0.0180424  0.01799838 0.03861304 0.04673737 0.04194334
  0.04779891 0.04503935 0.04326064 0.03805276 0.03965128 0.06035556
  0.0490227  0.04717418 0.03441074 0.03610944 0.03069176 0.02227439
  0.03743757 0.052227  ]
 [0.03781769 0.03082053 0.03227308 0.02322984 0.02223867 0.02872065
  0.03220076 0.03168397 0.03087017 0.02793929 0.03266585 0.03346297
  0.03162603 0.01654856 0.01575693 0.03131315 0.03384193 0.0300391
  0.0359758  0.03439552 0.03549589 0.03838915 0.02741956 0.04190632
  0.03623861 0.03846931 0.03408503 0.03071312 0.02542617 0.0242062
  0.04870913 0.04087782]
 [0.03767642 0.03293872 0.03794372 0.03143271 0.02790162 0.03732488
  0.03772051 0.04399531 0.03714302 0.03820645 0.03505594 0.05148259
  0.04446211 0.02394467 0.01751759 0.02728129 0.02808479 0.03214468
  0.03117127 0.03246592 0.02938213 0.04053709 0.02911593 0.02894698
  0.03801418 0.03644728 0.03711225 0.03398674 0.03040594 0.03428157
  0.04477988 0.06851455]
 [0.03804126 0.03637576 0.03879471 0.0326968  0.02856967 0.0386388
  0.04199884 0.04722919 0.03684708 0.04018061 0.03869614 0.04969552
  0.04957187 0.02393249 0.01904178 0.03679531 0.03205396 0.0384542
  0.03614765 0.03512713 0.03429697 0.03902217 0.02878326 0.03493318
  0.03931303 0.03057764 0.03958385 0.0349819  0.02939412 0.03065819
  0.04339054 0.05724104]
 [0.03802531 0.02817236 0.02818016 0.02087619 0.01787685 0.02496141
  0.0317933  0.03270619 0.0276439  0.02410887 0.02929023 0.0305757
  0.03412313 0.01408049 0.01350285 0.04230116 0.03650964 0.03696937
  0.03639315 0.0336294  0.03773646 0.03667518 0.0223329  0.04564779
  0.04265863 0.03078781 0.02758991 0.04087503 0.02315745 0.02256594
  0.05253224 0.03663133]
 [0.03844406 0.02928098 0.02760444 0.02153441 0.01736092 0.02361444
  0.03194372 0.03050159 0.02674815 0.02332121 0.02898304 0.02795183
  0.03276393 0.01341475 0.01319717 0.04480061 0.03937364 0.04471177
  0.04023932 0.0400857  0.04448611 0.03226302 0.0217336  0.04610071
  0.03442048 0.02978916 0.02488839 0.03396026 0.02057967 0.0147976
  0.0389427  0.02628647]
 [0.03880106 0.03004381 0.0278687  0.02177875 0.01700326 0.02512348
  0.03228454 0.03256016 0.02873518 0.02460554 0.03047995 0.02888791
  0.03512981 0.01367455 0.01272661 0.04489589 0.03445024 0.0433578
  0.03787979 0.04009162 0.04135843 0.03125535 0.02159417 0.04722486
  0.03294287 0.02981526 0.02410285 0.03189984 0.02019131 0.01443754
  0.03403898 0.0280562 ]
 [0.03906883 0.02958333 0.02799927 0.02237215 0.01727664 0.02572616
  0.03227692 0.02981855 0.02934819 0.02500188 0.03254865 0.02884435
  0.03235852 0.01456084 0.01368637 0.0400665  0.03288187 0.03596525
  0.0387445  0.03909379 0.04021193 0.03247274 0.02155993 0.04286763
  0.02906824 0.03202685 0.02538655 0.02930057 0.01939029 0.01480897
  0.03302471 0.02604971]
 [0.03884673 0.0296094  0.02845229 0.01932537 0.01419131 0.02352789
  0.03767291 0.03387915 0.02907868 0.02144488 0.05537887 0.02773503
  0.03416231 0.01272873 0.01271398 0.04294498 0.0393717  0.03617304
  0.04121768 0.03725984 0.04140949 0.03283108 0.0233945  0.06145056
  0.03136189 0.0370874  0.02814554 0.03025758 0.02068078 0.01471509
  0.03578411 0.02520863]
 [0.03679165 0.05305712 0.04913871 0.02646112 0.01948427 0.03434141
  0.07629021 0.06203012 0.04757488 0.02963753 0.08390023 0.0401503
  0.05974438 0.01622787 0.01698566 0.05585389 0.0642038  0.06018472
  0.05490296 0.0531896  0.05778933 0.03746038 0.044815   0.09294944
  0.05374864 0.0592088  0.03762957 0.04457926 0.02891537 0.01635185
  0.03695758 0.0337816 ]
 [0.03885967 0.02858071 0.02854667 0.02323732 0.01567745 0.02669233
  0.03413143 0.03325734 0.02947502 0.02367239 0.03215977 0.02688709
  0.0315379  0.0154999  0.01430977 0.02971915 0.03118524 0.02747386
  0.03386631 0.03160416 0.03470478 0.03479748 0.02107682 0.04326155
  0.03067112 0.03279884 0.0266894  0.03009173 0.02133746 0.0154498
  0.03730009 0.02634377]
 [0.03676965 0.03542354 0.03739632 0.05392454 0.0472009  0.0457812
  0.03522434 0.03712244 0.04005221 0.04992098 0.03429594 0.03855876
  0.03848278 0.06775573 0.09567343 0.02621212 0.02801223 0.02835174
  0.03036202 0.02917565 0.02991658 0.0390014  0.0423102  0.01629552
  0.0271066  0.03719455 0.04153814 0.05107744 0.05761065 0.03255851
  0.02009487 0.02743458]
 [0.03614162 0.04608222 0.0437229  0.08464417 0.17726184 0.06856952
  0.04007197 0.04325338 0.04890661 0.08783644 0.0597471  0.06654604
  0.04440532 0.10210042 0.13672714 0.03577932 0.05083935 0.05442758
  0.04425552 0.03631722 0.04422876 0.03876469 0.05460674 0.01376921
  0.02158288 0.03547198 0.05690418 0.05385892 0.05900761 0.02737855
  0.01114492 0.01418432]
 [0.03642657 0.03387878 0.03060886 0.04590368 0.06739432 0.03099602
  0.02800049 0.03125766 0.03006954 0.04532045 0.0372809  0.03465638
  0.03047247 0.03277238 0.04763905 0.030782   0.05697417 0.06144992
  0.06149146 0.04676287 0.06901059 0.03624833 0.04287525 0.03154012
  0.04039539 0.03906547 0.03856839 0.05910886 0.04013681 0.01661075
  0.02015155 0.01959675]
 [0.0365759  0.03647828 0.03370765 0.04895544 0.04587303 0.03836343
  0.03509296 0.03590474 0.03908776 0.044297   0.03556024 0.0335268
  0.03336911 0.0366734  0.0426495  0.02437649 0.03991586 0.04199661
  0.04071032 0.03920817 0.04046179 0.04926946 0.04874344 0.0179629
  0.02735713 0.03319858 0.03138352 0.0627578  0.04439845 0.01410051
  0.01412502 0.01602594]]

-* TASK 10/20 | SAMPLE 19/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 93/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Julie or the cinema in the context sentences, so we cannot determine Julie's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' or', ' the', ' cinema', ' in', ' the', ' context', ' sentences', ',', ' so', ' we', ' cannot', ' determine', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03095961 0.03486089 0.03225274 ... 0.02534616 0.01768382 0.05017918]
 [0.03172532 0.02419201 0.02301024 ... 0.02361782 0.01983693 0.02970507]
 [0.03232449 0.03247675 0.03329116 ... 0.02200069 0.01698181 0.03538832]
 ...
 [0.03293918 0.02770848 0.02589677 ... 0.02776146 0.02694966 0.03102084]
 [0.03341953 0.02945387 0.02998868 ... 0.02684585 0.02374202 0.03455954]
 [0.03354977 0.0258235  0.02798326 ... 0.02376021 0.0225401  0.03285572]]

-* TASK 10/20 | SAMPLE 19/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 94/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Julie or the office in the context sentences, so we cannot determine Julie's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' or', ' the', ' office', ' in', ' the', ' context', ' sentences', ',', ' so', ' we', ' cannot', ' determine', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03139977 0.03757937 0.0373529  ... 0.01546696 0.01172481 0.05071742]
 [0.03200233 0.04149916 0.03981457 ... 0.03475371 0.0308612  0.02992638]
 [0.03273616 0.0383786  0.04244193 ... 0.02725391 0.01608801 0.05453302]
 ...
 [0.03311971 0.03566366 0.02777388 ... 0.01858091 0.01805937 0.05960505]
 [0.03257104 0.05038897 0.03892786 ... 0.02339985 0.02326868 0.06274915]
 [0.03332053 0.03504316 0.02825456 ... 0.01421288 0.01345837 0.06443983]]

-* TASK 10/20 | SAMPLE 19/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 95/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 previously stated that Bill is in the bedroom, and there is no information that suggests he has moved.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' previously', ' stated', ' that', ' Bill', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 50), x_tokens=50, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 50)
DEBUG result.interpretability.attn_scores 1500 
 [[0.03061863 0.03951775 0.03896736 ... 0.02065308 0.02195172 0.04066793]
 [0.03140353 0.02973012 0.02974874 ... 0.0325973  0.02657114 0.03086241]
 [0.0320692  0.04315551 0.04804607 ... 0.01713462 0.01506143 0.03613422]
 ...
 [0.03240269 0.04088028 0.04277555 ... 0.01624438 0.01610021 0.04204604]
 [0.03298926 0.03041899 0.03183203 ... 0.02747767 0.02447009 0.04996193]
 [0.03282738 0.03404589 0.03562297 ... 0.02077419 0.02055704 0.03870123]]
Model's predictions for the sample 19:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 2 explicitly states that Fred   |
|          |                 |  is in the kitchen, which contradicts the  |
|          |                 |          ambiguity in sentence 1.          |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 4 states that Mary travelled to  |
|          |                 |     the bedroom, implying that she has     |
|          |                 |          arrived at the bedroom.           |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no mention of Julie or the     |
|          |                 |   cinema in the context sentences, so we   |
|          |                 |     cannot determine Julie's location.     |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |    There is no mention of Julie or the     |
|          |                 |   office in the context sentences, so we   |
|          |                 |     cannot determine Julie's location.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 11 previously stated that Bill   |
|          |                 |     is in the bedroom, and there is no     |
|          |                 |  information that suggests he has moved.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 19:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.07 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 20/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 96/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary going to the office in the context sentences. She travelled to the park and then to the school, but there is no information about her going to the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' going', ' to', ' the', ' office', ' in', ' the', ' context', ' sentences', '.', ' She', ' travelled', ' to', ' the', ' park', ' and', ' then', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' her', ' going', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 26), x_tokens=26, y_tokens=45, max_supp_attn=0.0667, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 26)
DEBUG result.interpretability.attn_scores 1170 
 [[0.02064713 0.03674553 0.03984556 ... 0.01218672 0.00761599 0.02041909]
 [0.02131012 0.02306518 0.02362742 ... 0.0084872  0.00620665 0.01356854]
 [0.02166261 0.02613233 0.03016475 ... 0.01111531 0.00852623 0.01297976]
 ...
 [0.02167506 0.02444929 0.02405452 ... 0.00804532 0.00529555 0.01322907]
 [0.02163238 0.01975185 0.01938791 ... 0.01150352 0.01037867 0.01532554]
 [0.02174753 0.02481102 0.02239144 ... 0.00963022 0.00821337 0.01295533]]

-* TASK 10/20 | SAMPLE 20/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 97/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary in the context sentences. The sentences only talk about Julie being in the bedroom and Bill going to the school, but there is no information about Mary's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', ' being', ' in', ' the', ' bedroom', ' and', ' Bill', ' going', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02003451 0.03044408 0.03213972 ... 0.00828734 0.01284312 0.00669557]
 [0.02073463 0.02843458 0.0295037  ... 0.0094437  0.01263895 0.00770008]
 [0.02109316 0.02755943 0.03112094 ... 0.01438482 0.01972773 0.00883493]
 ...
 [0.02143687 0.02510841 0.0197446  ... 0.00971615 0.00750422 0.007842  ]
 [0.02158156 0.02909193 0.02423817 ... 0.0108361  0.0089372  0.00736582]
 [0.02173131 0.0258988  0.02213938 ... 0.01078082 0.01040027 0.00776496]]

-* TASK 10/20 | SAMPLE 20/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 98/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Julie going to the school in the context sentences. The previous sentence (4) mentioned Julie being in the bedroom, but there is no update about her going to the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' going', ' to', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' previous', ' sentence', ' (', '4', ')', ' mentioned', ' Julie', ' being', ' in', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' update', ' about', ' her', ' going', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01975354 0.02817806 0.0304623  ... 0.04751228 0.02951101 0.00730362]
 [0.01985297 0.03247973 0.03394704 ... 0.02267322 0.02892461 0.02057743]
 [0.02059018 0.03017389 0.0358223  ... 0.03800729 0.02195649 0.00562961]
 ...
 [0.02078344 0.02612871 0.02534148 ... 0.07521797 0.0190329  0.00524751]
 [0.02122192 0.02112857 0.01958283 ... 0.04634855 0.01669311 0.01021135]
 [0.02121848 0.02164776 0.01947546 ... 0.09884712 0.01646478 0.0074901 ]]

-* TASK 10/20 | SAMPLE 20/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 99/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence (10) explicitly states that Julie is in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '10', ')', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(22, 44), x_tokens=44, y_tokens=22, max_supp_attn=0.0, attn_on_target=0.0455)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (22, 44)
DEBUG result.interpretability.attn_scores 968 
 [[0.04309426 0.0471101  0.05015538 0.07482232 0.06009788 0.06484006
  0.04678256 0.0532218  0.0588893  0.06143667 0.04003539 0.04519647
  0.05491129 0.10228933 0.09593072 0.03706479 0.03046937 0.0364589
  0.03315475 0.03893401 0.03407767 0.04371101 0.05885708 0.02700286
  0.03695479 0.05654229 0.051294   0.05711492 0.13730328 0.01991264
  0.02505873 0.01798499 0.0166408  0.02677849 0.07152345 0.07213169
  0.04665098 0.01715384 0.01112886 0.02912165 0.0565375  0.0729894
  0.16137907 0.02117905]
 [0.04361696 0.04020001 0.04016634 0.0446755  0.03347998 0.04524687
  0.04730697 0.05140337 0.05110766 0.04007671 0.03431063 0.0409448
  0.05670644 0.04819674 0.0547912  0.03278655 0.02770213 0.03817613
  0.03768467 0.04575955 0.03914994 0.04726134 0.03423267 0.02853493
  0.04016118 0.04603229 0.04393078 0.03204479 0.07345264 0.040009
  0.04151865 0.0459624  0.04761217 0.04562851 0.02759163 0.02974587
  0.0324959  0.02290584 0.02549764 0.04244008 0.04373944 0.04598943
  0.07085337 0.03863515]
 [0.04493412 0.05196    0.05487523 0.09317876 0.08131059 0.09611987
  0.05448706 0.05651834 0.0641657  0.07410051 0.04740806 0.0594799
  0.0676943  0.15365285 0.09868788 0.03786401 0.02568705 0.03044192
  0.02981155 0.03324441 0.02891033 0.04657941 0.04662754 0.02632421
  0.02910308 0.04643048 0.05499114 0.04108172 0.11927503 0.03478416
  0.04086025 0.02054733 0.01902321 0.04114008 0.07658216 0.0597539
  0.03677185 0.01466567 0.01036327 0.02398623 0.04607874 0.05167335
  0.1251225  0.03050087]
 [0.04333307 0.05568961 0.05917466 0.05004241 0.03982196 0.05430141
  0.05198692 0.05690205 0.05691586 0.0478154  0.03862252 0.04816023
  0.05220632 0.04046947 0.0340919  0.04739342 0.03447067 0.03593172
  0.03542187 0.04043997 0.03550476 0.04999413 0.06700515 0.05287339
  0.05083408 0.05764254 0.06191941 0.04559245 0.06815284 0.06966969
  0.09333895 0.04336534 0.03342598 0.06070898 0.03819448 0.03353644
  0.06042592 0.03773111 0.02429931 0.0491508  0.06010977 0.04738888
  0.08559273 0.08575057]
 [0.04420107 0.05846527 0.05927977 0.0343877  0.02694548 0.04462893
  0.05316329 0.05322514 0.05784812 0.03591809 0.03453558 0.04013326
  0.04533716 0.02891461 0.02545233 0.04848215 0.032913   0.03286873
  0.03676087 0.04164155 0.03525596 0.04783923 0.07203035 0.05246248
  0.04859829 0.0582468  0.06816416 0.03709002 0.04141524 0.06778818
  0.10006835 0.05698602 0.04732339 0.06009378 0.02436964 0.02457961
  0.06885325 0.0373784  0.03652664 0.05389176 0.0501982  0.04029609
  0.0466237  0.11179687]
 [0.04569156 0.08357048 0.08730537 0.0394987  0.02762365 0.05224333
  0.06481075 0.05741922 0.07794775 0.03915747 0.03340832 0.04143514
  0.04436435 0.02827439 0.02543175 0.0609662  0.03546771 0.03230596
  0.03746342 0.0434857  0.03382652 0.0441568  0.10974443 0.05421953
  0.04039912 0.06016089 0.08065368 0.03267042 0.03533384 0.04844728
  0.13455881 0.04049052 0.03555572 0.04729208 0.02079232 0.02837254
  0.09229257 0.02693415 0.02323414 0.04316115 0.04531172 0.03802468
  0.03581617 0.1196987 ]
 [0.04519916 0.05607439 0.06175868 0.033832   0.02572134 0.03978363
  0.05866529 0.05069935 0.06026046 0.03338649 0.03286238 0.03647279
  0.03662386 0.02511963 0.02552473 0.06346823 0.04254586 0.03522548
  0.04066008 0.04595849 0.03724637 0.04401028 0.08263807 0.07871603
  0.05878399 0.06162089 0.08257993 0.03588818 0.03489505 0.04575805
  0.07616512 0.05034407 0.04360539 0.04522759 0.02280619 0.02897714
  0.07533053 0.0534326  0.02394425 0.07479524 0.0521528  0.04166055
  0.03618383 0.06857739]
 [0.04542526 0.03644435 0.03879203 0.02280205 0.0192558  0.02746097
  0.03957129 0.0320245  0.04172741 0.02398259 0.02984961 0.0263712
  0.02659131 0.01741811 0.02377654 0.05298873 0.04327178 0.03528998
  0.04171893 0.04838552 0.03677224 0.04093185 0.05372227 0.0648697
  0.05745837 0.05013989 0.0443036  0.0257313  0.0229962  0.02343809
  0.03160436 0.03443535 0.0344367  0.02670937 0.01531122 0.02676893
  0.04437019 0.04509987 0.02002752 0.06358223 0.03530218 0.03318715
  0.01920414 0.02900159]
 [0.04598825 0.03397731 0.03432801 0.02397195 0.01963224 0.03005943
  0.03961948 0.03146395 0.04153839 0.02590038 0.03084292 0.02940634
  0.02899185 0.01756915 0.02049355 0.04551771 0.0344112  0.03364282
  0.04377485 0.0440288  0.0361162  0.03819321 0.0422767  0.06883004
  0.05845919 0.04694044 0.04585702 0.02751397 0.02886164 0.03630141
  0.03817113 0.0485421  0.04670974 0.0381885  0.01986646 0.02787893
  0.04709769 0.0589851  0.02667377 0.07142355 0.04011938 0.04014942
  0.02957657 0.03986953]
 [0.04567432 0.04647681 0.04904085 0.03803632 0.02553456 0.04600702
  0.04946128 0.04851055 0.04916305 0.04158334 0.03973209 0.05301395
  0.0471568  0.02649276 0.02238195 0.04354903 0.03535314 0.03784915
  0.03834412 0.04028878 0.03671473 0.04728667 0.04069762 0.05289756
  0.05343999 0.04710111 0.05943393 0.03971614 0.03902931 0.0871465
  0.05996168 0.06262109 0.04735949 0.08109354 0.02771875 0.02465873
  0.05012156 0.05379649 0.02949204 0.04745742 0.046246   0.04157713
  0.04218272 0.06637894]
 [0.04646829 0.05504229 0.05667393 0.04982306 0.03375585 0.05872268
  0.05649397 0.05747594 0.05010172 0.05358931 0.05243523 0.07150095
  0.06484935 0.0332863  0.02565809 0.04717404 0.04176135 0.04404964
  0.04445728 0.04645782 0.04077068 0.04742929 0.04084438 0.05070357
  0.05231831 0.04429984 0.06024171 0.04686535 0.03875369 0.09114709
  0.05899921 0.0594685  0.04786485 0.08270872 0.03352615 0.02948608
  0.05002921 0.04831741 0.03401904 0.0435958  0.04619582 0.04234952
  0.03978369 0.0631209 ]
 [0.04717105 0.04287947 0.04284754 0.03365652 0.02611789 0.03979139
  0.04731264 0.04230784 0.03719105 0.0377507  0.0441375  0.04382476
  0.04401092 0.0226995  0.02096908 0.04680705 0.03827868 0.03597065
  0.0402851  0.04095124 0.03942222 0.04587527 0.0332332  0.05306862
  0.05356462 0.03484469 0.04101035 0.04223566 0.03236376 0.06679358
  0.04601372 0.05793388 0.04837021 0.05984724 0.02911905 0.02649142
  0.03789936 0.0575471  0.03539489 0.04497512 0.04781589 0.03878899
  0.03420403 0.04926342]
 [0.04626144 0.03677502 0.03270779 0.02496271 0.01953741 0.02824698
  0.03871807 0.03517757 0.02932932 0.02907808 0.04327815 0.03444937
  0.03755468 0.01509066 0.01702842 0.05082515 0.05044526 0.04310761
  0.04334814 0.04343199 0.04845068 0.04569407 0.02584866 0.06190595
  0.0597206  0.03061135 0.02650138 0.04295707 0.0238066  0.05439747
  0.03224028 0.05811095 0.05988521 0.04549717 0.02244085 0.0219522
  0.03512891 0.0860581  0.06635156 0.05506758 0.05448733 0.04033377
  0.02357768 0.03971996]
 [0.04589085 0.03713375 0.03170432 0.02494809 0.01785925 0.02731877
  0.04327897 0.03968195 0.02775954 0.02776236 0.04223177 0.03285577
  0.0389474  0.01394582 0.01568794 0.05034562 0.05127788 0.05228434
  0.04480352 0.04532985 0.05279885 0.04290321 0.02154427 0.06291928
  0.06086116 0.02832005 0.02000808 0.03885569 0.01806184 0.05224039
  0.0254937  0.06516606 0.06786269 0.03840278 0.01948811 0.01848873
  0.02910049 0.09397109 0.07416284 0.05270841 0.0398876  0.0401252
  0.0173037  0.0364403 ]
 [0.04681351 0.03314161 0.03025862 0.02393174 0.01937649 0.02778934
  0.0362803  0.03560799 0.02739112 0.02843197 0.05017566 0.03940551
  0.0374217  0.0145929  0.01566966 0.0458847  0.05501506 0.04600377
  0.05128448 0.0442715  0.05060188 0.04221505 0.01940786 0.04483556
  0.04938383 0.03027255 0.02159257 0.04966293 0.01815508 0.05330785
  0.02682768 0.07707157 0.09464679 0.04554325 0.02187532 0.01935548
  0.02795365 0.08983903 0.0908062  0.04419124 0.03077412 0.03647183
  0.01764755 0.03310658]
 [0.04678552 0.03094913 0.02825962 0.02068892 0.0175604  0.02447468
  0.03807178 0.03370948 0.0256131  0.02493708 0.06697334 0.03715554
  0.03567204 0.01236157 0.01412646 0.04598093 0.05418506 0.0450673
  0.05079313 0.04390546 0.04843308 0.0422735  0.01758727 0.04331464
  0.04292949 0.03222505 0.01783329 0.04908055 0.0147462  0.04582774
  0.02408832 0.06949566 0.10331011 0.03801569 0.01856425 0.01843914
  0.02620547 0.07565057 0.16598983 0.04572132 0.02592586 0.04122861
  0.01318937 0.02880157]
 [0.04468336 0.03091908 0.02821005 0.02158463 0.01677017 0.02683269
  0.039662   0.03747981 0.0323055  0.02873153 0.05034753 0.0380245
  0.04387445 0.01401619 0.0148893  0.03913296 0.07715472 0.0664337
  0.06900044 0.06311285 0.05288687 0.0468023  0.02510371 0.04741072
  0.04909303 0.04775078 0.0203809  0.04981895 0.02131439 0.04288828
  0.03143645 0.05954836 0.06941486 0.04869529 0.02057211 0.02625171
  0.03963679 0.07396199 0.18800347 0.06380584 0.04025558 0.0521349
  0.01563337 0.03110995]
 [0.04722088 0.02975269 0.03117879 0.02699175 0.01833051 0.02971556
  0.03353639 0.03648885 0.03145013 0.03076679 0.03940099 0.03736192
  0.03656437 0.01792273 0.01554849 0.03013854 0.02802486 0.0323827
  0.03784845 0.0361847  0.03467738 0.04173147 0.01791981 0.02375649
  0.03347269 0.03374794 0.0209712  0.03352468 0.02440789 0.04042236
  0.03887713 0.05268073 0.05649208 0.07079181 0.03278546 0.02002385
  0.02514883 0.02157637 0.0401438  0.03158384 0.02807878 0.03437131
  0.02451798 0.03333724]
 [0.04568877 0.04082528 0.04498337 0.07419716 0.06080478 0.06489694
  0.04134009 0.04800005 0.05289209 0.07647938 0.05040061 0.05673494
  0.05703888 0.10842893 0.10942008 0.03547942 0.03453364 0.03964868
  0.0396472  0.04049368 0.03727102 0.04542558 0.03926344 0.02198828
  0.02769815 0.04635364 0.04073073 0.05605675 0.06397883 0.02158509
  0.02806911 0.02022096 0.01927589 0.03061946 0.13759182 0.06619667
  0.03821291 0.01558976 0.0130484  0.02647606 0.04698674 0.05573849
  0.06518246 0.02214674]
 [0.04529815 0.05311836 0.05030609 0.10079407 0.21020465 0.07665079
  0.04121537 0.04862399 0.04672188 0.09793332 0.07527613 0.07059165
  0.04948385 0.14292529 0.17764962 0.049336   0.06337712 0.06920418
  0.05682584 0.05031721 0.06131915 0.04414083 0.05215991 0.02238617
  0.02225218 0.04779619 0.0524746  0.05514997 0.06371075 0.01551136
  0.01322346 0.01492615 0.01559398 0.01950899 0.13638571 0.11389872
  0.04400294 0.01777309 0.0145463  0.02385056 0.0517442  0.05173795
  0.04654303 0.01567571]
 [0.0450804  0.04889975 0.04328383 0.07197801 0.12611245 0.04333616
  0.03497354 0.04482029 0.03558603 0.07514016 0.06867181 0.06240176
  0.04503972 0.05222    0.07986783 0.04906769 0.10146514 0.10917206
  0.0849665  0.06660818 0.11449002 0.04567069 0.04692292 0.03537722
  0.04134329 0.04806164 0.0472551  0.07930868 0.03686619 0.02420305
  0.01782959 0.02387351 0.02400462 0.02572781 0.12031177 0.109846
  0.04452911 0.03122581 0.0278499  0.03889503 0.06235349 0.04842367
  0.02437383 0.01869768]
 [0.04547971 0.05059521 0.0447097  0.07119564 0.07414677 0.05153231
  0.04326196 0.04923792 0.04409489 0.0660417  0.05506382 0.05507927
  0.04895895 0.06411299 0.06692258 0.03974706 0.06218942 0.06848459
  0.0619448  0.05676875 0.0653035  0.05987473 0.05233268 0.02560279
  0.03317055 0.0448587  0.03787243 0.08203984 0.04311968 0.01842074
  0.01559527 0.02022443 0.02158611 0.02178086 0.06258314 0.1731661
  0.04774198 0.0204065  0.01849633 0.03011909 0.0496988  0.0653597
  0.02550854 0.0171912 ]]

-* TASK 10/20 | SAMPLE 20/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 100/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences (13) and (14) do not mention Julie being in the cinema. They only provide possibilities for her location as either in the school or the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' (', '13', ')', ' and', ' (', '14', ')', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' cinema', '.', ' They', ' only', ' provide', ' possibilities', ' for', ' her', ' location', ' as', ' either', ' in', ' the', ' school', ' or', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 50), x_tokens=50, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 50)
DEBUG result.interpretability.attn_scores 2100 
 [[0.02212058 0.02944346 0.03532063 ... 0.02541793 0.03777573 0.03096954]
 [0.02260754 0.0249482  0.02678598 ... 0.01251074 0.02271566 0.02687323]
 [0.02302089 0.03218475 0.03681093 ... 0.02390761 0.03524704 0.02749736]
 ...
 [0.02324424 0.02997328 0.02984737 ... 0.04143343 0.03546001 0.02344429]
 [0.02373872 0.02280001 0.02135064 ... 0.02556897 0.02015558 0.02043832]
 [0.02362749 0.02640925 0.02470054 ... 0.01852708 0.03251098 0.02083122]]
Model's predictions for the sample 20:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Mary going to the  |
|          |                 |    office in the context sentences. She    |
|          |                 |   travelled to the park and then to the    |
|          |                 |    school, but there is no information     |
|          |                 |       about her going to the office.       |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |     There is no mention of Mary in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |   talk about Julie being in the bedroom    |
|          |                 |  and Bill going to the school, but there   |
|          |                 |  is no information about Mary's location.  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no mention of Julie going to    |
|          |                 |  the school in the context sentences. The  |
|          |                 |   previous sentence (4) mentioned Julie    |
|          |                 |   being in the bedroom, but there is no    |
|          |                 |   update about her going to the school.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    The context sentence (10) explicitly    |
|          |                 |    states that Julie is in the kitchen.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   The context sentences (13) and (14) do   |
|          |                 |   not mention Julie being in the cinema.   |
|          |                 |  They only provide possibilities for her   |
|          |                 |  location as either in the school or the   |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 20:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 21/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 101/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, Fred is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 26), x_tokens=26, y_tokens=24, max_supp_attn=0.0833, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 26)
DEBUG result.interpretability.attn_scores 624 
 [[0.03912661 0.05674287 0.06942914 0.09058746 0.09859896 0.09192581
  0.076186   0.08844639 0.07275158 0.08325449 0.06815338 0.08241138
  0.09111985 0.1088044  0.07083107 0.04259037 0.03993209 0.04425814
  0.03584442 0.03998666 0.03422707 0.05031374 0.04461268 0.02641802
  0.01659794 0.03126601]
 [0.03967369 0.07238971 0.06602948 0.08421042 0.06889109 0.07154796
  0.0613728  0.06131904 0.05668209 0.06034911 0.05373963 0.04300315
  0.04679731 0.11501895 0.11185361 0.04619407 0.03496116 0.03278557
  0.0292471  0.03139034 0.02804117 0.05248177 0.04932952 0.01993999
  0.01172695 0.02664112]
 [0.0428155  0.07512134 0.04585245 0.06215321 0.0415159  0.0427751
  0.0421115  0.03077786 0.02943097 0.04104082 0.03837985 0.02227216
  0.02511663 0.02813623 0.03645544 0.03182288 0.01855681 0.01919617
  0.02105344 0.02272629 0.021587   0.05703593 0.05593068 0.0115016
  0.00712071 0.01392102]
 [0.04011594 0.03066838 0.02993304 0.02389751 0.01670447 0.02817197
  0.03152892 0.02780133 0.03331823 0.02790205 0.03146957 0.02908622
  0.03021309 0.01121487 0.01047568 0.03299441 0.03285202 0.03975756
  0.04723601 0.06744577 0.05641087 0.04165176 0.05500256 0.08215243
  0.08242761 0.09279798]
 [0.04058732 0.05355224 0.05863259 0.07828115 0.06780026 0.05769566
  0.04644619 0.04088616 0.04543325 0.0563807  0.04829356 0.03504314
  0.03552987 0.10258196 0.10401868 0.05131659 0.0360629  0.02941155
  0.02772474 0.03107849 0.03030192 0.0509874  0.06878262 0.01897708
  0.01055189 0.03230081]
 [0.04136682 0.03451834 0.03590866 0.05980774 0.05117841 0.05211773
  0.03444941 0.03213212 0.03866704 0.05260687 0.0434833  0.03990731
  0.03849801 0.11571662 0.13466585 0.05080134 0.04097422 0.03589265
  0.03148935 0.03336861 0.02938248 0.04325358 0.04041875 0.01498698
  0.00858163 0.02095383]
 [0.0419513  0.03888175 0.04639607 0.06355228 0.05579473 0.06622538
  0.04544023 0.04428903 0.05083776 0.06258413 0.05115381 0.06356187
  0.05886467 0.09257828 0.08391421 0.04253691 0.0368816  0.03529318
  0.02979594 0.03242785 0.02740993 0.03909711 0.03778952 0.02013351
  0.01180497 0.02128331]
 [0.04042624 0.05281026 0.06257068 0.05072111 0.05075628 0.06340127
  0.05390149 0.06103378 0.05764237 0.05650031 0.05167371 0.07156327
  0.06395633 0.05709836 0.04944141 0.0545074  0.04833604 0.04558377
  0.0383753  0.04238173 0.0386081  0.04582881 0.05640945 0.04291947
  0.03404385 0.04416491]
 [0.04212383 0.05247768 0.06468289 0.05667826 0.04868436 0.07033446
  0.05975846 0.06532067 0.06652314 0.0620111  0.05101915 0.07025602
  0.06529271 0.0416258  0.02683112 0.03992883 0.03654023 0.03745298
  0.03232285 0.03640598 0.03107272 0.04485699 0.04208108 0.02850485
  0.01849275 0.03022071]
 [0.04106975 0.06303856 0.06647039 0.03375502 0.02625467 0.04537079
  0.05864844 0.05756821 0.05944388 0.03784003 0.04020543 0.05062031
  0.05370754 0.01843823 0.0154154  0.05893876 0.04727247 0.04427737
  0.04348461 0.04769135 0.04575422 0.04499996 0.07919256 0.0602231
  0.04755242 0.04971919]
 [0.04188922 0.08512403 0.08293133 0.03243796 0.02559631 0.04014309
  0.06275366 0.05597101 0.06386122 0.03393946 0.03737586 0.04238246
  0.0444822  0.01587244 0.01504031 0.06976274 0.04913201 0.04387075
  0.04262865 0.0508999  0.04429735 0.04141581 0.07926746 0.05448958
  0.03527806 0.03321972]
 [0.04214064 0.04435571 0.04959239 0.02431412 0.02021964 0.02908562
  0.04796047 0.04232191 0.04938196 0.02727546 0.03031388 0.03345468
  0.03374484 0.01317173 0.01280726 0.05447556 0.04199619 0.03723242
  0.03983954 0.04390897 0.04087791 0.03901568 0.0613737  0.0623802
  0.0570757  0.05272813]
 [0.04244027 0.01852725 0.02002349 0.0130854  0.01157694 0.01661081
  0.020921   0.02121503 0.02442978 0.01603074 0.01975754 0.01929539
  0.02002337 0.00669404 0.00704142 0.02526304 0.02486449 0.02649166
  0.03365896 0.03864698 0.04059016 0.02798478 0.03804763 0.07660628
  0.08931619 0.07801711]
 [0.04230556 0.02784631 0.02893088 0.01918197 0.01778368 0.02550131
  0.03210261 0.03166189 0.03031444 0.02319637 0.02978717 0.02975082
  0.0309635  0.01012097 0.01050986 0.04282885 0.04046602 0.03884421
  0.04377059 0.0413003  0.03970879 0.03718492 0.03099578 0.05755659
  0.08455583 0.05813892]
 [0.04255041 0.02936723 0.03049015 0.02400084 0.02031646 0.03246142
  0.0392177  0.0427843  0.03464343 0.03178477 0.03773041 0.04471743
  0.04644606 0.01329084 0.01108287 0.0385518  0.04656184 0.0454667
  0.04929532 0.04208327 0.040553   0.04066636 0.02373664 0.03862518
  0.06530976 0.03876406]
 [0.04201236 0.02311336 0.01957428 0.01622636 0.01275684 0.01922994
  0.02932355 0.03164465 0.02383824 0.01975993 0.02940023 0.0249787
  0.03206199 0.00744275 0.00749246 0.03394946 0.03995524 0.04958215
  0.07091544 0.05813867 0.05987245 0.03480582 0.0173334  0.05324591
  0.11570919 0.05677353]
 [0.04268598 0.02485892 0.02237638 0.01781242 0.01502369 0.02329098
  0.03312859 0.03750836 0.0274182  0.02379975 0.03796223 0.03633856
  0.03802381 0.00890736 0.00832684 0.03645821 0.05089119 0.04329729
  0.06357709 0.04354576 0.04828187 0.03460494 0.01697633 0.03907955
  0.08266293 0.0422399 ]
 [0.0426569  0.02005498 0.01801087 0.01279837 0.01134716 0.01695753
  0.0285991  0.02920887 0.02364426 0.01728392 0.0386969  0.02752563
  0.03085334 0.00644973 0.0065714  0.03860261 0.04944979 0.04527159
  0.0625428  0.05062378 0.05580999 0.03123548 0.01520969 0.05274586
  0.06255484 0.05878905]
 [0.04117848 0.02908911 0.02627921 0.01652651 0.01398967 0.02042353
  0.033797   0.03105843 0.03224846 0.01941897 0.03291674 0.02427103
  0.02990174 0.00765849 0.00797499 0.03957054 0.03540374 0.04298058
  0.04891424 0.05208031 0.07035464 0.03647031 0.03243209 0.1317493
  0.08412097 0.08256473]
 [0.0434182  0.02574677 0.02574804 0.02157829 0.01629008 0.02451152
  0.02955436 0.03348637 0.03168381 0.02643822 0.03420027 0.0353159
  0.03397156 0.01162508 0.00985419 0.02811491 0.03085911 0.0343623
  0.04113271 0.03915904 0.04110675 0.03405705 0.01856443 0.03339404
  0.02682146 0.03971774]
 [0.04225646 0.03407782 0.03426225 0.05120332 0.05025283 0.04718286
  0.03409318 0.03499736 0.03892632 0.05615399 0.04547763 0.04580427
  0.04250397 0.07115431 0.08517305 0.03436613 0.03886122 0.03726126
  0.03214123 0.03194185 0.03149324 0.03967351 0.03322113 0.01541676
  0.01085149 0.02351408]
 [0.04198725 0.03571446 0.03290114 0.05452962 0.09756494 0.04475467
  0.03221735 0.03174496 0.03661394 0.06029734 0.05118279 0.04327085
  0.03519458 0.07347277 0.09542868 0.04175286 0.05130548 0.05237536
  0.03691436 0.0350261  0.036989   0.03713855 0.03229903 0.01303511
  0.0076387  0.01914747]
 [0.04131962 0.03220291 0.02912592 0.04495749 0.0955666  0.03204091
  0.02822687 0.03145969 0.03282656 0.05400465 0.04944925 0.04546817
  0.03506047 0.03184454 0.04409779 0.03509786 0.078123   0.08428546
  0.05515161 0.04575476 0.06110184 0.03473774 0.02946986 0.02582136
  0.01624239 0.02753409]
 [0.0419017  0.03972001 0.03384832 0.04770317 0.06553599 0.03823966
  0.03826111 0.03536257 0.03943912 0.05014692 0.04817766 0.03970126
  0.03767256 0.03108124 0.03469642 0.02957383 0.04976115 0.0547693
  0.04294369 0.04198726 0.04616749 0.06050199 0.0415234  0.0200972
  0.01296181 0.02558258]]

-* TASK 10/20 | SAMPLE 21/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 102/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Bill journeyed to the cinema, not the park. There is no information about Bill being in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' not', ' the', ' park', '.', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 32), x_tokens=32, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 32)
DEBUG result.interpretability.attn_scores 1152 
 [[0.02592517 0.04088577 0.04100762 ... 0.03216533 0.05387369 0.08324865]
 [0.02671877 0.03780502 0.0364087  ... 0.04151358 0.06838457 0.06153949]
 [0.02710328 0.03761536 0.04173134 ... 0.05943539 0.05096734 0.04684437]
 ...
 [0.02716069 0.03203282 0.0307439  ... 0.0136114  0.08407713 0.05350866]
 [0.02754823 0.02594244 0.02382976 ... 0.01130407 0.05977515 0.0328379 ]
 [0.02756271 0.02451624 0.02298336 ... 0.00903373 0.06870073 0.07082676]]

-* TASK 10/20 | SAMPLE 21/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 103/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Mary is either in the school or the cinema, but it doesn't specify which one. Therefore, we can't be certain about Mary's location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', ',', ' but', ' it', ' doesn', "'t", ' specify', ' which', ' one', '.', ' Therefore', ',', ' we', ' can', "'t", ' be', ' certain', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02093823 0.03068777 0.03042735 ... 0.01843121 0.0203465  0.10171203]
 [0.0210549  0.04048496 0.03966907 ... 0.02718421 0.02662932 0.05545609]
 [0.02183648 0.03185836 0.03327665 ... 0.01424413 0.01474474 0.06350255]
 ...
 [0.0220385  0.0297384  0.02498404 ... 0.01425337 0.02013357 0.03856042]
 [0.02240037 0.02409888 0.01948909 ... 0.02115194 0.02948494 0.01697586]
 [0.02259764 0.02279377 0.01865691 ... 0.0174292  0.02455292 0.02910505]]

-* TASK 10/20 | SAMPLE 21/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 104/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 11, Bill is explicitly stated to be in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Bill', ' is', ' explicitly', ' stated', ' to', ' be', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 44), x_tokens=44, y_tokens=24, max_supp_attn=0.0417, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 44)
DEBUG result.interpretability.attn_scores 1056 
 [[0.0390125  0.05249302 0.05567281 ... 0.02768518 0.04720798 0.06595297]
 [0.0400358  0.04353074 0.05004851 ... 0.05018785 0.03160925 0.03173856]
 [0.04089628 0.04975792 0.05901888 ... 0.04456437 0.0511802  0.05049866]
 ...
 [0.0410545  0.05754427 0.0515715  ... 0.01624065 0.08831255 0.08792564]
 [0.04126655 0.04913425 0.0397052  ... 0.01930672 0.05114346 0.06971806]
 [0.04149654 0.05255491 0.04279369 ... 0.02144936 0.03941178 0.14081624]]

-* TASK 10/20 | SAMPLE 21/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 105/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 13, Julie travelled to the office, but then according to context sentence 14, Julie travelled to the kitchen, which implies that Julie is no longer in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Julie', ' travelled', ' to', ' the', ' office', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '14', ',', ' Julie', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.01995466 0.03182323 0.0299644  ... 0.01700788 0.01143721 0.03164979]
 [0.02054566 0.0306426  0.02917822 ... 0.02179505 0.01587652 0.02453851]
 [0.0209067  0.03197008 0.03328269 ... 0.01558671 0.00993982 0.02945565]
 ...
 [0.02103383 0.02987199 0.02487168 ... 0.01481438 0.01067624 0.03552294]
 [0.02165758 0.02351811 0.01876612 ... 0.01715938 0.01331792 0.02254885]
 [0.02142666 0.02346286 0.01852262 ... 0.01680038 0.01442822 0.02499267]]
Model's predictions for the sample 21:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 2, Fred is  |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 4, Bill    |
|          |                 |   journeyed to the cinema, not the park.   |
|          |                 |  There is no information about Bill being  |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to context sentence 7, Mary is  |
|          |                 |  either in the school or the cinema, but   |
|          |                 |  it doesn't specify which one. Therefore,  |
|          |                 |      we can't be certain about Mary's      |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 11, Bill   |
|          |                 |     is explicitly stated to be in the      |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to context sentence 13, Julie   |
|          |                 |     travelled to the office, but then      |
|          |                 |  according to context sentence 14, Julie   |
|          |                 |  travelled to the kitchen, which implies   |
|          |                 |   that Julie is no longer in the office.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 21:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 22/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 106/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the bedroom. The context sentences only mention Mary going back to the office and Bill's possible locations.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' going', ' back', ' to', ' the', ' office', ' and', ' Bill', "'s", ' possible', ' locations', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02602015 0.0435097  0.04628245 0.07841518 0.07392862 0.04803885
  0.03484013 0.03018917 0.03195509 0.04870722 0.0339009  0.02466796
  0.02501745 0.12198313 0.12882558 0.03963933 0.0273287  0.02127857
  0.02044992 0.02131063 0.01909709 0.03994102 0.06411059 0.0082098
  0.00538189 0.030429  ]
 [0.02687118 0.02718525 0.0272619  0.05647771 0.05327812 0.04071578
  0.02458655 0.02213975 0.02543869 0.04232043 0.0293271  0.02639967
  0.02504028 0.12776265 0.15277894 0.03736911 0.02929926 0.02466869
  0.02256828 0.02217828 0.01805877 0.03317071 0.03747008 0.00651084
  0.00497081 0.02000425]
 [0.02733141 0.03086348 0.03512866 0.06022281 0.05831599 0.05155674
  0.03277126 0.0308295  0.03396979 0.0505166  0.03441561 0.04225068
  0.03908666 0.09999374 0.09312262 0.03111553 0.02684034 0.0251155
  0.02188382 0.02205124 0.01696387 0.02981625 0.03425565 0.0093208
  0.00654377 0.01897402]
 [0.02646112 0.03684507 0.042308   0.0440551  0.04844891 0.0459601
  0.03624407 0.03824785 0.03726966 0.04353853 0.03388626 0.04572274
  0.03913828 0.05866327 0.0529118  0.03775445 0.03408178 0.03108826
  0.02693501 0.02785916 0.02329651 0.03317236 0.04736988 0.02470782
  0.01461925 0.03211245]
 [0.02741271 0.03233623 0.03783156 0.03386831 0.03092715 0.03953846
  0.03585697 0.03836315 0.03445173 0.03373372 0.02865921 0.04115617
  0.03455807 0.02112961 0.01666134 0.02680153 0.02634026 0.02566806
  0.02335952 0.02460703 0.02179425 0.02737812 0.03493724 0.02264013
  0.01994011 0.0323564 ]
 [0.02779019 0.03033969 0.03303251 0.02746503 0.02380517 0.03721282
  0.03529761 0.03635672 0.03500613 0.0303471  0.02711171 0.04067625
  0.03341053 0.01722039 0.01379956 0.02528204 0.02789043 0.02475216
  0.02365485 0.02379857 0.02135063 0.02686591 0.03199711 0.02082946
  0.02060786 0.0306165 ]
 [0.02725068 0.04780815 0.04467021 0.0323561  0.02739144 0.04626234
  0.04608554 0.04914992 0.04386215 0.0387918  0.03671434 0.05916335
  0.04974404 0.02069014 0.01595222 0.03050894 0.02946044 0.02905516
  0.02586794 0.02586447 0.02290618 0.02922218 0.03566278 0.02131182
  0.02357095 0.02667805]
 [0.02786194 0.03747186 0.04038296 0.03124704 0.02416419 0.05344835
  0.04540302 0.0441395  0.04281131 0.03563733 0.03072818 0.06623673
  0.05160332 0.01960808 0.01449882 0.02969558 0.02868731 0.02869522
  0.02706178 0.02697611 0.02310533 0.02806113 0.02991788 0.01679234
  0.01862076 0.0220259 ]
 [0.02799637 0.04444113 0.05272313 0.03592103 0.02680301 0.07372364
  0.06707519 0.04765204 0.05988076 0.0377567  0.02999498 0.05694309
  0.04399941 0.01972753 0.01514649 0.02807407 0.0239938  0.02290527
  0.02313107 0.02438422 0.02017606 0.02884462 0.03578984 0.01491728
  0.01261042 0.02154304]
 [0.02746409 0.02364291 0.02412108 0.01857781 0.01617642 0.02140605
  0.03035049 0.03145644 0.02484322 0.02171259 0.02901061 0.02709129
  0.03645904 0.01011416 0.01026331 0.02966687 0.03464532 0.03071359
  0.02890106 0.02858292 0.03029555 0.02720139 0.01998187 0.03693517
  0.02775139 0.02471033]
 [0.02750416 0.0195965  0.01747916 0.01513692 0.01280012 0.01420598
  0.02265845 0.02303333 0.01798017 0.01540638 0.02156143 0.01701716
  0.02123435 0.00760957 0.00807044 0.02822449 0.0335829  0.0336316
  0.03226898 0.03229703 0.0413182  0.02404098 0.01718185 0.04846755
  0.03142571 0.02624459]
 [0.02800069 0.02025471 0.0179216  0.01733141 0.014927   0.01712818
  0.0225927  0.02488226 0.01914334 0.01926549 0.02689209 0.02385946
  0.02408433 0.00886091 0.00894521 0.02765263 0.03269129 0.03082803
  0.02923168 0.02962863 0.03101138 0.02235352 0.01430168 0.02865167
  0.0322997  0.01853401]
 [0.02797569 0.01753713 0.01565662 0.01268548 0.01177622 0.0132571
  0.02033398 0.0203526  0.01743905 0.01420604 0.0266398  0.01799909
  0.01972251 0.00691077 0.00745868 0.0265461  0.03778294 0.02989438
  0.03362256 0.03430326 0.03607662 0.02197728 0.01407904 0.02851235
  0.03382249 0.01937976]
 [0.02738822 0.02064554 0.01829093 0.0133456  0.01210024 0.01475422
  0.02275569 0.02045142 0.02149987 0.01412547 0.02685605 0.01646236
  0.01947037 0.00751056 0.00820068 0.02975958 0.03630705 0.02776876
  0.03253459 0.03218153 0.03409749 0.02392663 0.02110579 0.04145798
  0.04242192 0.03452774]
 [0.02810262 0.02593459 0.02406154 0.01740082 0.01497884 0.01906987
  0.02491624 0.0245065  0.02383949 0.01953177 0.02640441 0.02328905
  0.02205728 0.0099928  0.00980607 0.02369827 0.03152724 0.02702509
  0.02988595 0.04170837 0.03115559 0.02500963 0.02191089 0.02167929
  0.01832256 0.0210491 ]
 [0.02769744 0.03093434 0.03100798 0.02917513 0.02488999 0.03270476
  0.02782691 0.02971458 0.03139464 0.03458037 0.02743158 0.04039723
  0.03380363 0.02087219 0.01537334 0.02635876 0.0275419  0.0277578
  0.02506368 0.02606996 0.02177474 0.0299542  0.03748314 0.02892311
  0.01353792 0.0231035 ]
 [0.02761023 0.04263014 0.04168089 0.02244843 0.01874267 0.02574454
  0.03428633 0.03359568 0.03486361 0.02154326 0.02323056 0.0260194
  0.02840049 0.01413389 0.01266532 0.03040556 0.02564772 0.02402624
  0.02455383 0.02582164 0.02524075 0.02873373 0.05352208 0.03470374
  0.02182744 0.032683  ]
 [0.02792477 0.06435759 0.06584569 0.0274414  0.02125707 0.02979749
  0.04361754 0.03796989 0.04349496 0.02410917 0.02294562 0.0258842
  0.02802526 0.01463915 0.0136764  0.04065041 0.02826902 0.02373052
  0.02382527 0.0259304  0.02167421 0.02958093 0.06585852 0.01983919
  0.01348218 0.02501678]
 [0.02806597 0.03531606 0.03817149 0.02338766 0.01786003 0.02527098
  0.0353254  0.03278652 0.03385142 0.02095197 0.02049034 0.02348349
  0.02387686 0.012758   0.01196808 0.03023162 0.02438713 0.02280367
  0.02349837 0.02503195 0.02283833 0.03040288 0.04562908 0.02504642
  0.01867595 0.0361386 ]
 [0.02872331 0.02575853 0.02658053 0.020632   0.01518103 0.02370884
  0.0274926  0.02933471 0.02651973 0.0195386  0.02047682 0.0234808
  0.02450522 0.01125116 0.00973602 0.02173435 0.01888982 0.01987432
  0.02024282 0.0213241  0.02078147 0.02802713 0.02204863 0.02450466
  0.018657   0.02597141]
 [0.02813419 0.01927068 0.01836781 0.01470423 0.01197322 0.01599479
  0.02212039 0.02089616 0.02034999 0.01491341 0.02092958 0.01620813
  0.02045212 0.0085543  0.00786458 0.025957   0.02256572 0.02218011
  0.02416517 0.02618064 0.03076856 0.02615683 0.01895413 0.05625202
  0.02906683 0.02865383]
 [0.02790919 0.01562168 0.01406322 0.01214794 0.00968175 0.01175646
  0.01586193 0.0141624  0.01606572 0.01224645 0.01539169 0.01190495
  0.0153587  0.00704044 0.00634164 0.022295   0.02339298 0.02524391
  0.02723126 0.03116711 0.04161898 0.023522   0.01608524 0.07666239
  0.03032653 0.02539581]
 [0.02817214 0.01475015 0.01406548 0.01206524 0.00992671 0.01202882
  0.01399032 0.01389062 0.01658751 0.01286915 0.01495694 0.01254593
  0.01473431 0.00704107 0.00589654 0.0201875  0.01594946 0.02019762
  0.02039559 0.03115315 0.04508884 0.02010203 0.01567616 0.07938229
  0.03002777 0.02064487]
 [0.02835074 0.01424755 0.013363   0.01121166 0.00925533 0.01126884
  0.01334669 0.01350354 0.01626381 0.01240622 0.01743362 0.01286911
  0.01495369 0.00685583 0.00569447 0.02448783 0.01889944 0.02144248
  0.02297086 0.02747418 0.04792251 0.02096226 0.01384808 0.06575558
  0.0339741  0.01964589]
 [0.02825477 0.01483051 0.01396222 0.01072137 0.00919831 0.01114759
  0.01400977 0.01365899 0.0162626  0.01185999 0.02082033 0.01248614
  0.01491497 0.00674469 0.0059499  0.02617525 0.02254768 0.02050997
  0.02493274 0.02674608 0.03965442 0.02240798 0.01501059 0.06587715
  0.03501308 0.02113831]
 [0.02754887 0.03302366 0.02784002 0.04396354 0.05508875 0.04322855
  0.03133769 0.02842981 0.0312654  0.05033088 0.04703666 0.04135439
  0.03275635 0.04487751 0.03379104 0.02854092 0.0268641  0.02996917
  0.02939652 0.02658198 0.02597114 0.03609613 0.02808564 0.02485103
  0.01718771 0.02131724]
 [0.02860701 0.01563994 0.01522171 0.01219076 0.01006668 0.01240398
  0.01480898 0.01517952 0.01749099 0.01260969 0.01829748 0.01300647
  0.0152634  0.00795323 0.00640663 0.02060102 0.02032241 0.0177502
  0.0243054  0.02288472 0.02674192 0.02285732 0.01568388 0.0372127
  0.0296755  0.02744165]
 [0.02849178 0.02240612 0.02110764 0.01593291 0.0124437  0.01590693
  0.02237321 0.0257676  0.02217144 0.01618885 0.01877614 0.01697945
  0.0230986  0.00978967 0.00687651 0.02025861 0.01983255 0.01828652
  0.02107679 0.02118984 0.02545171 0.02762927 0.01643851 0.01873458
  0.04313761 0.05604255]
 [0.02811693 0.01817269 0.01654452 0.01408842 0.01085729 0.01370781
  0.0205368  0.02220049 0.01851767 0.0148383  0.01941474 0.01469294
  0.02135447 0.00865139 0.00656899 0.02639404 0.02598151 0.02441866
  0.02905523 0.02476102 0.03282597 0.02509148 0.0139787  0.0177543
  0.09377102 0.05513732]
 [0.02814558 0.02495129 0.02255407 0.01803731 0.0137333  0.01723361
  0.02802694 0.03555373 0.02416078 0.02055595 0.03556103 0.02127293
  0.0331028  0.01100396 0.0082328  0.03217557 0.03089274 0.03000014
  0.03409434 0.02859784 0.0321332  0.02625996 0.01532171 0.01605686
  0.08913353 0.04214154]
 [0.02836199 0.02383358 0.0207971  0.01801073 0.01394716 0.01699727
  0.0272796  0.03193309 0.02346385 0.02176585 0.04302824 0.02060609
  0.03159492 0.01165038 0.00820523 0.02883656 0.03160723 0.03149691
  0.03352829 0.02790969 0.02848206 0.02572465 0.01452077 0.01391258
  0.07817967 0.03943745]
 [0.02888107 0.01838089 0.01877031 0.01548692 0.01217023 0.01571716
  0.02271216 0.02590761 0.023058   0.01832461 0.03085207 0.01738612
  0.0258503  0.0099583  0.00739419 0.02144473 0.02316173 0.02163359
  0.02667358 0.02370617 0.024295   0.02272316 0.013477   0.01169225
  0.05839229 0.03934672]
 [0.02751762 0.0281386  0.02788223 0.04902297 0.05373952 0.03892871
  0.02508756 0.02644808 0.03212902 0.04985293 0.03232299 0.02900129
  0.03328148 0.08655418 0.10197552 0.02703044 0.02581942 0.02693935
  0.02398082 0.02161861 0.0184491  0.03286146 0.03128286 0.00639371
  0.00497304 0.02236158]
 [0.02733481 0.02912774 0.02715487 0.05454462 0.10724964 0.03608998
  0.02072849 0.02271317 0.02741475 0.05422822 0.03763901 0.02919412
  0.02483678 0.08154757 0.10484995 0.03192916 0.03678759 0.04177494
  0.03255595 0.02654685 0.02255128 0.02968489 0.03062442 0.00618625
  0.00539917 0.01952896]
 [0.02729224 0.02382408 0.02336282 0.04111927 0.05961856 0.02626906
  0.01728347 0.02222314 0.02584936 0.04797254 0.03762662 0.03416898
  0.02831115 0.03031373 0.03258953 0.02270387 0.0391972  0.06948099
  0.05935351 0.04924005 0.02873587 0.02559478 0.02372353 0.01067756
  0.01282668 0.02080717]
 [0.02742814 0.02637217 0.02450398 0.03916107 0.05329756 0.02781539
  0.02017933 0.02238065 0.02943429 0.04271645 0.03323527 0.02812277
  0.02689857 0.03003204 0.03150157 0.01981337 0.03098355 0.04739456
  0.04774294 0.04233252 0.02629637 0.04464532 0.03267515 0.00863736
  0.00982541 0.01886062]]

-* TASK 10/20 | SAMPLE 22/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 107/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Bill being in the school. Bill is mentioned as going to the bedroom, but there is no connection to the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Bill', ' being', ' in', ' the', ' school', '.', ' Bill', ' is', ' mentioned', ' as', ' going', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' connection', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.025, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02321366 0.03749622 0.04009263 ... 0.00899319 0.0078491  0.00971167]
 [0.02388134 0.03506338 0.03609126 ... 0.01230465 0.01055479 0.01202371]
 [0.02431064 0.03344705 0.03734395 ... 0.01721243 0.0138958  0.01323147]
 ...
 [0.02432631 0.03376531 0.02816304 ... 0.0057513  0.00539294 0.00709537]
 [0.02462272 0.02500542 0.02043758 ... 0.0083279  0.00642699 0.00913471]
 [0.02478532 0.02742873 0.02196535 ... 0.0069743  0.00564829 0.00763348]]

-* TASK 10/20 | SAMPLE 22/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 108/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any new information about Bill's location. The previous information (sentence 4) stated that Bill went to the bedroom, and there is no update to change this information.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' The', ' previous', ' information', ' (', 'sentence', ' ', '4', ')', ' stated', ' that', ' Bill', ' went', ' to', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01956351 0.02796471 0.02784125 ... 0.00960457 0.01147457 0.02013537]
 [0.01997801 0.0220844  0.02396104 ... 0.04721127 0.05681205 0.03732482]
 [0.0205215  0.02936494 0.03145219 ... 0.00556109 0.00652956 0.01136045]
 ...
 [0.02066173 0.02733832 0.02511856 ... 0.00592461 0.00721369 0.01106371]
 [0.02110826 0.01950567 0.01759    ... 0.01187541 0.01709539 0.01803512]
 [0.02101233 0.02321856 0.0203127  ... 0.00795525 0.01120934 0.01604067]]

-* TASK 10/20 | SAMPLE 22/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 109/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences provide information about Mary's location, stating that Mary is in the bedroom. There is no information about Mary being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' provide', ' information', ' about', ' Mary', "'s", ' location', ',', ' stating', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02587595 0.03770408 0.03834813 ... 0.05493681 0.00922846 0.01415764]
 [0.02624856 0.02946871 0.02898402 ... 0.04807322 0.01657491 0.02626581]
 [0.02705867 0.04083508 0.04167015 ... 0.0613926  0.01565541 0.01958893]
 ...
 [0.02717673 0.03924862 0.03901286 ... 0.01838887 0.00704536 0.00839014]
 [0.02785294 0.02863034 0.02602896 ... 0.00988543 0.00701095 0.00832934]
 [0.02762816 0.03167104 0.02892768 ... 0.0102722  0.00699757 0.00941488]]

-* TASK 10/20 | SAMPLE 22/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 110/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences provide information about Mary's location, stating that Mary is in the kitchen, but then updating that Mary journeyed to the school. This implies that Mary is no longer in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' provide', ' information', ' about', ' Mary', "'s", ' location', ',', ' stating', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', ',', ' but', ' then', ' updating', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' school', '.', ' This', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 50), x_tokens=50, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 50)
DEBUG result.interpretability.attn_scores 2350 
 [[0.01969739 0.02830266 0.031278   ... 0.03264195 0.0279458  0.01197807]
 [0.01995438 0.03160458 0.02981023 ... 0.02027665 0.04137636 0.01741178]
 [0.0205374  0.03125555 0.03492698 ... 0.03260128 0.02312357 0.0100116 ]
 ...
 [0.02072582 0.0287042  0.02822842 ... 0.04328325 0.02225919 0.00957226]
 [0.02124469 0.02234746 0.02069947 ... 0.03009427 0.02044455 0.0130149 ]
 [0.02109982 0.02210499 0.02057667 ... 0.05403093 0.01991808 0.01279172]]
Model's predictions for the sample 22:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the bedroom. The context   |
|          |                 |   sentences only mention Mary going back   |
|          |                 |     to the office and Bill's possible      |
|          |                 |                 locations.                 |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences do not provide any  |
|          |                 |    information about Bill being in the     |
|          |                 |   school. Bill is mentioned as going to    |
|          |                 |  the bedroom, but there is no connection   |
|          |                 |               to the school.               |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentences do not provide any  |
|          |                 |   new information about Bill's location.   |
|          |                 |   The previous information (sentence 4)    |
|          |                 |   stated that Bill went to the bedroom,    |
|          |                 |   and there is no update to change this    |
|          |                 |                information.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |       The context sentences provide        |
|          |                 |     information about Mary's location,     |
|          |                 |    stating that Mary is in the bedroom.    |
|          |                 |  There is no information about Mary being  |
|          |                 |               in the school.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |       The context sentences provide        |
|          |                 |     information about Mary's location,     |
|          |                 |  stating that Mary is in the kitchen, but  |
|          |                 |  then updating that Mary journeyed to the  |
|          |                 |    school. This implies that Mary is no    |
|          |                 |           longer in the kitchen.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 22:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 23/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 111/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 2 explicitly states that Fred is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03739988 0.0569838  0.07012395 0.09153112 0.10131972 0.09187164
  0.06891912 0.08468901 0.07325032 0.08165932 0.06341736 0.07749253
  0.0845982  0.11149259 0.06908661 0.0400097  0.03849406 0.04264137
  0.034288   0.03944761 0.03441835 0.04952263 0.04719975 0.02739175
  0.02153519 0.03087861]
 [0.03712536 0.10328188 0.07818595 0.06972997 0.05247497 0.068846
  0.19876914 0.13354494 0.07889214 0.06394909 0.09245834 0.06804846
  0.11181814 0.03109307 0.02593289 0.05245592 0.04814234 0.07217769
  0.05048134 0.06410066 0.05453952 0.05813779 0.04643141 0.04800081
  0.03219486 0.03707562]
 [0.04079206 0.06852487 0.04379429 0.06359431 0.04696191 0.0428932
  0.03541857 0.02773111 0.0285293  0.04178739 0.03734155 0.02080869
  0.02364295 0.03602994 0.0457583  0.03154691 0.01844475 0.0184041
  0.02048183 0.0224152  0.02217015 0.05507031 0.05934337 0.01205574
  0.00734194 0.01426751]
 [0.0383895  0.04434075 0.04425687 0.02728415 0.01864774 0.03215915
  0.0313725  0.02961464 0.0389389  0.02889363 0.03118773 0.029659
  0.02857834 0.01340632 0.01286128 0.04154038 0.03740852 0.03924904
  0.04559033 0.04915983 0.04422739 0.04204195 0.06676716 0.06637736
  0.08872046 0.07496687]
 [0.03879575 0.04875499 0.05390665 0.07799046 0.0699476  0.05666987
  0.0382276  0.03595725 0.04307541 0.05524259 0.04560749 0.03259042
  0.03254055 0.11777413 0.11913428 0.04808114 0.03506962 0.0287053
  0.0263992  0.03028225 0.03079551 0.04899042 0.06857692 0.02098115
  0.01168377 0.030622  ]
 [0.03961113 0.03195249 0.03358383 0.06088716 0.05268477 0.05142226
  0.02878899 0.02833663 0.03670699 0.05178015 0.04054594 0.03700585
  0.03516755 0.12706098 0.14815502 0.04751569 0.03925787 0.03434977
  0.02968056 0.03230539 0.02965699 0.04197277 0.04161452 0.0148399
  0.0094175  0.02022921]
 [0.0402135  0.0355514  0.04258542 0.06331459 0.05684213 0.06468844
  0.03743608 0.03842676 0.0478162  0.06057008 0.04674855 0.05808379
  0.05293669 0.10056695 0.09154975 0.03922839 0.0350115  0.03341534
  0.02820184 0.03146457 0.02745583 0.03782047 0.03853377 0.01990053
  0.01320138 0.02030268]
 [0.0388412  0.04807342 0.05748132 0.05082736 0.05109007 0.06089422
  0.04198956 0.05038228 0.05295446 0.05510005 0.04751187 0.06364549
  0.05472519 0.0618927  0.0543056  0.05028537 0.04425331 0.04171867
  0.03508414 0.03946923 0.0363219  0.04426254 0.05738503 0.04022035
  0.03217683 0.04091096]
 [0.03909603 0.06009496 0.06854482 0.03942461 0.03233743 0.04993718
  0.04963618 0.05718531 0.05632121 0.04246528 0.04300275 0.05268707
  0.05220825 0.02884621 0.02036914 0.05009092 0.04038107 0.03878315
  0.03594853 0.03854268 0.03713886 0.03934207 0.06409667 0.04897823
  0.04643225 0.05481485]
 [0.04021806 0.0791387  0.08688075 0.03543995 0.02506636 0.0452793
  0.05168685 0.05121104 0.06221844 0.03581851 0.03476985 0.04416905
  0.04133099 0.01936196 0.01577196 0.05779908 0.04082314 0.03693027
  0.0347807  0.04098298 0.03650525 0.03792023 0.07587085 0.03987048
  0.03095655 0.03872177]
 [0.04017252 0.04440445 0.0514014  0.02796135 0.02175879 0.03271153
  0.0411118  0.04214638 0.04752485 0.03081953 0.03103979 0.03688134
  0.03322988 0.01662426 0.01498988 0.05462084 0.04241911 0.03664402
  0.03847719 0.04051827 0.03796396 0.03836526 0.05831132 0.0550658
  0.05313667 0.04780434]
 [0.04062121 0.0224379  0.02678166 0.01787537 0.0151556  0.02258985
  0.02472191 0.0276195  0.04018525 0.02241199 0.02138254 0.02321095
  0.0215764  0.01113826 0.01068662 0.03379326 0.03143028 0.02852193
  0.03361968 0.03640282 0.0326268  0.03059462 0.04176377 0.06317484
  0.07147428 0.07675144]
 [0.04028301 0.03002519 0.03173639 0.02241946 0.01852956 0.02949007
  0.02867402 0.03202137 0.03166585 0.02582924 0.02870259 0.03511097
  0.03014961 0.01228554 0.01201559 0.04644797 0.03643718 0.03557365
  0.03894321 0.03905711 0.03788719 0.03815771 0.03319684 0.05566835
  0.0781671  0.05214651]
 [0.04106282 0.04282202 0.04680443 0.04039297 0.02952779 0.0525508
  0.04383572 0.05435862 0.04834316 0.05180101 0.04811623 0.08021851
  0.05994297 0.02326549 0.01631739 0.03730179 0.03686125 0.04028955
  0.03691408 0.03777824 0.03413609 0.04023473 0.02736196 0.02789897
  0.02408333 0.02484024]
 [0.04165032 0.02947011 0.03134208 0.02485834 0.0209382  0.03051106
  0.03276983 0.03487038 0.03149319 0.02986006 0.03596756 0.03885715
  0.03650566 0.01342951 0.01216523 0.03834494 0.03466152 0.03366214
  0.03479994 0.03499714 0.03328661 0.03759926 0.02326925 0.04104134
  0.04008606 0.02350501]
 [0.04077435 0.02142238 0.01971984 0.01580125 0.01346796 0.01824212
  0.02091021 0.02386081 0.02311947 0.01913206 0.0267573  0.02393311
  0.02668847 0.00809652 0.00887119 0.0383811  0.03916168 0.03753581
  0.04593968 0.04067389 0.04172364 0.0348599  0.02072527 0.065474
  0.07771739 0.04159135]
 [0.04039429 0.02218493 0.01952076 0.01649644 0.01306165 0.01865074
  0.0295385  0.0334096  0.02431006 0.01983776 0.03120347 0.02452997
  0.03329071 0.00776996 0.00788586 0.03919119 0.04008471 0.04942124
  0.06164096 0.06044489 0.06522153 0.03219494 0.01826362 0.07571374
  0.0855042  0.04344939]
 [0.04112205 0.01982812 0.01781084 0.0147462  0.01268721 0.01800441
  0.02131924 0.02502023 0.02226699 0.01877052 0.02924716 0.02538209
  0.02725036 0.00752686 0.0073046  0.03234998 0.04543464 0.03665202
  0.0588101  0.04131152 0.04618919 0.03064558 0.0144085  0.05218445
  0.07437613 0.04355321]
 [0.04102539 0.01751318 0.01557679 0.01187547 0.01053748 0.01488256
  0.02095443 0.02250746 0.0208282  0.01539499 0.03382868 0.02153007
  0.02597452 0.00627956 0.00624176 0.0356974  0.04818982 0.04185246
  0.06681368 0.05086956 0.05273172 0.02999452 0.01437169 0.05244454
  0.04669254 0.06698368]
 [0.04011652 0.02196108 0.02005836 0.01472166 0.01298862 0.01914992
  0.02506904 0.02595223 0.02777393 0.01747906 0.02851059 0.02311601
  0.02671453 0.00781897 0.00751663 0.02925176 0.03480028 0.03603208
  0.04823378 0.04689173 0.05252758 0.03283841 0.02496188 0.0722974
  0.06886106 0.08501945]
 [0.04166859 0.02244791 0.02154516 0.01900076 0.01433236 0.02192201
  0.02225779 0.02595641 0.02645925 0.02160895 0.02763079 0.02790419
  0.02806279 0.01063815 0.00943905 0.02370642 0.02636607 0.02857097
  0.03983057 0.03668958 0.03744416 0.03286856 0.01737815 0.02935121
  0.03187659 0.03878353]
 [0.04051198 0.03149569 0.03114782 0.05041352 0.04880358 0.04698738
  0.02821193 0.03043084 0.03650556 0.05423271 0.04209462 0.04177146
  0.03870545 0.07938803 0.09351871 0.03187614 0.03505243 0.03479753
  0.02954839 0.0305445  0.03079731 0.03862724 0.03425633 0.0156234
  0.01256869 0.02227572]
 [0.04020496 0.03304172 0.03041211 0.05441781 0.10005963 0.04336295
  0.02639562 0.02822083 0.0344427  0.05919867 0.04710424 0.03932173
  0.03202355 0.08121757 0.10482436 0.03917574 0.04961797 0.04988073
  0.0348049  0.03391136 0.03765461 0.03600609 0.03335948 0.01269856
  0.00864049 0.01897916]
 [0.03969856 0.02854194 0.02617001 0.04303469 0.09337943 0.02979569
  0.02219036 0.02644194 0.02969651 0.04885306 0.04285952 0.03898633
  0.02975716 0.03219597 0.04482634 0.03232822 0.07334919 0.07395703
  0.05071528 0.04190521 0.06176172 0.03307979 0.03053708 0.0238699
  0.01850512 0.02861595]
 [0.04021093 0.0357061  0.03062849 0.04596103 0.06739953 0.03648764
  0.02979498 0.03010436 0.03668181 0.04750424 0.0429634  0.03505572
  0.0325811  0.03480053 0.0404719  0.02897974 0.04884762 0.05023414
  0.03997205 0.0398338  0.0448181  0.05885218 0.04201543 0.0188773
  0.01464973 0.02291086]]

-* TASK 10/20 | SAMPLE 23/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 112/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Fred's location. They only mention Mary's movements.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', "'s", ' location', '.', ' They', ' only', ' mention', ' Mary', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03340377 0.04056262 0.04114252 0.06270306 0.05871486 0.04427006
  0.03368266 0.03316754 0.04612658 0.05435071 0.03792741 0.0319122
  0.03603048 0.10067677 0.10709688 0.03413332 0.03415703 0.030404
  0.02837231 0.02939803 0.02731229 0.03438192 0.04824081 0.02142707
  0.01983324 0.03406584 0.04027436 0.03876413 0.0988943  0.06363796
  0.01293502 0.07385987]
 [0.03438653 0.04062599 0.0374426  0.07107747 0.07807869 0.07315639
  0.03632712 0.03569992 0.0443214  0.06315499 0.05018402 0.04650287
  0.04666845 0.14444292 0.11933243 0.03598191 0.03008015 0.02995665
  0.02749866 0.02929627 0.02722256 0.03746863 0.03681877 0.01825642
  0.01708888 0.02875634 0.04170084 0.03033155 0.08183263 0.07424179
  0.02118481 0.08465582]
 [0.03504783 0.03895741 0.04145459 0.06306044 0.0626668  0.05518485
  0.03450679 0.03639114 0.04415878 0.05380414 0.04012255 0.04307204
  0.04098757 0.10836374 0.082594   0.03164389 0.02976842 0.02566184
  0.02495625 0.0256995  0.02362151 0.03360809 0.03414512 0.02041459
  0.01857552 0.0262324  0.03922827 0.02721526 0.05568753 0.06892839
  0.0277555  0.06478946]
 [0.03394461 0.03751496 0.04115824 0.03810063 0.03378079 0.03775333
  0.03357277 0.03936967 0.04269525 0.03759516 0.03219369 0.03780567
  0.03684328 0.03279529 0.03015631 0.03172393 0.03118019 0.02738372
  0.02913686 0.03143417 0.02961861 0.03749617 0.04811534 0.04071599
  0.0378787  0.04584713 0.0491661  0.04495918 0.04837107 0.0739122
  0.04855956 0.04529552]
 [0.03419989 0.04952173 0.05040916 0.03148443 0.02395997 0.03181796
  0.0338576  0.03545328 0.04541206 0.02668703 0.02826981 0.02884027
  0.02924932 0.02635485 0.02335119 0.03091246 0.02772613 0.02265042
  0.02732934 0.02850978 0.0273834  0.03656472 0.05632003 0.034746
  0.03413552 0.04332027 0.05843824 0.03438184 0.03390946 0.0735127
  0.05400771 0.02559468]
 [0.03497041 0.06048736 0.06185467 0.02963282 0.02365437 0.03282708
  0.03894557 0.03753165 0.05176387 0.02633758 0.02848611 0.02970767
  0.0300198  0.02077672 0.02083609 0.03665998 0.03475163 0.02808338
  0.03125074 0.03458111 0.03075249 0.03323654 0.08151213 0.03986983
  0.03640977 0.04742471 0.04745432 0.02830354 0.03286809 0.0690852
  0.04017626 0.02150775]
 [0.03506919 0.04691389 0.05488476 0.02943168 0.02360749 0.0340229
  0.04193849 0.04211098 0.04547776 0.02469428 0.0294054  0.03025647
  0.0269685  0.0220657  0.02221727 0.03949678 0.03563872 0.02690841
  0.03117655 0.03291016 0.03101237 0.03722667 0.05866507 0.0432641
  0.04152104 0.04218037 0.05453919 0.02588932 0.03204508 0.06815535
  0.04952227 0.02269535]
 [0.03601162 0.03256639 0.03810378 0.03472967 0.0273858  0.03965104
  0.03435932 0.03941837 0.04663742 0.03580133 0.03158533 0.03896607
  0.03313677 0.02576621 0.02203142 0.02723029 0.02898011 0.02536519
  0.02828416 0.02845557 0.02497539 0.03557032 0.03190164 0.02646946
  0.02752807 0.03543528 0.03682703 0.02879869 0.03223655 0.0352632
  0.03986037 0.02929264]
 [0.03590757 0.03743917 0.03940145 0.03581979 0.02737538 0.0406058
  0.0409958  0.0466259  0.04037102 0.03571173 0.03346784 0.04889963
  0.04260442 0.0248112  0.02126758 0.03273326 0.0337818  0.03017555
  0.0324543  0.03115267 0.03007721 0.03653497 0.03005398 0.03348299
  0.03922498 0.03762853 0.03884788 0.03732457 0.03131836 0.03955287
  0.05964296 0.0246257 ]
 [0.03629822 0.04053777 0.04201923 0.04083224 0.03105124 0.0517262
  0.04021069 0.04456638 0.04101655 0.04494968 0.03826707 0.06331512
  0.05257551 0.03330686 0.02284644 0.03302617 0.03411598 0.0310532
  0.03409164 0.03305281 0.03089805 0.03660677 0.02979856 0.03128272
  0.03397882 0.03464844 0.04074986 0.03636451 0.03037105 0.03610616
  0.05296979 0.02171189]
 [0.03606411 0.04063592 0.03678816 0.03409391 0.02920723 0.03770252
  0.03828626 0.04226022 0.03372027 0.03540529 0.03489916 0.04468436
  0.04696905 0.02443925 0.02050804 0.03261821 0.03336615 0.03061335
  0.03338992 0.03225396 0.03141382 0.03616735 0.02790982 0.03763092
  0.04608452 0.03620657 0.03706478 0.03609452 0.03028482 0.03314284
  0.05175888 0.02084361]
 [0.0367071  0.03550348 0.04036123 0.03400591 0.0269274  0.04390375
  0.04125171 0.04426162 0.04030861 0.03526909 0.03409985 0.05291104
  0.04850273 0.02378695 0.02003831 0.03219913 0.03415767 0.02862415
  0.03241241 0.03154069 0.03030851 0.0360776  0.0269845  0.03166094
  0.03547908 0.03006742 0.032714   0.03286096 0.02754479 0.02828887
  0.04228408 0.02013532]
 [0.03572585 0.0313339  0.02889664 0.02498855 0.02110019 0.02349451
  0.03867375 0.0353496  0.02543351 0.0244649  0.03513068 0.02629545
  0.0384149  0.01491599 0.01732983 0.04424276 0.03827304 0.03560101
  0.03710534 0.03718501 0.04328705 0.03682463 0.02459091 0.0674836
  0.05259658 0.03079104 0.02175386 0.04619132 0.02660308 0.01855995
  0.04996132 0.01821738]
 [0.03567805 0.025866   0.0238014  0.02124224 0.01763964 0.02067512
  0.02977884 0.02858193 0.02306822 0.02017118 0.0291722  0.02217165
  0.02546401 0.01252344 0.01552472 0.03627592 0.03503    0.033352
  0.04122573 0.04032529 0.04838887 0.03444241 0.02449606 0.0685023
  0.07402411 0.04429386 0.02100496 0.053164   0.02584781 0.01886507
  0.05298859 0.01979188]
 [0.03570908 0.04048808 0.03329591 0.02720113 0.02190065 0.02658921
  0.052139   0.05231119 0.02933625 0.02690207 0.05965573 0.03319585
  0.04572431 0.01555378 0.01953088 0.06025756 0.05473001 0.05723399
  0.0556711  0.05513367 0.06520108 0.03797837 0.02743335 0.0752784
  0.06362988 0.04991655 0.02836323 0.05359139 0.02929161 0.01699389
  0.05295099 0.01648013]
 [0.03692693 0.02570697 0.02633948 0.02264486 0.01831855 0.02360912
  0.02957787 0.03299788 0.02737503 0.02261193 0.04315248 0.0277163
  0.02932228 0.01448149 0.01568309 0.03572457 0.04128772 0.03408985
  0.04133046 0.03860679 0.04359411 0.03153938 0.02116967 0.0442966
  0.04473006 0.0401904  0.02194406 0.04092297 0.02253502 0.01772798
  0.0351728  0.02034912]
 [0.03582881 0.02795203 0.02972059 0.03182565 0.02564944 0.03337182
  0.02891133 0.03148034 0.03877609 0.03642496 0.03058831 0.0382351
  0.03544969 0.02558414 0.02244243 0.02853253 0.03102625 0.02820477
  0.03055426 0.03058206 0.02891076 0.03766903 0.03433332 0.03481778
  0.03862133 0.04033434 0.03466353 0.04149838 0.04199744 0.0446865
  0.03252816 0.03677821]
 [0.03703451 0.03256514 0.03482033 0.02613615 0.02116096 0.02989662
  0.03669437 0.03516894 0.02990622 0.02429286 0.02807885 0.02919839
  0.0291603  0.0165825  0.01703248 0.02965079 0.02970043 0.02478623
  0.0280712  0.02925823 0.027186   0.03662718 0.02868877 0.02679246
  0.03108048 0.02954026 0.0365655  0.01805873 0.02294485 0.02515975
  0.03520852 0.01388907]
 [0.03731877 0.03349324 0.03412547 0.02575541 0.02073382 0.0313004
  0.04195006 0.04108672 0.02915229 0.02579101 0.02824446 0.03151687
  0.03529355 0.01680478 0.01660908 0.02998705 0.02954007 0.02592643
  0.02721937 0.02850122 0.02615979 0.03537804 0.02813462 0.02576687
  0.02988817 0.02800742 0.03259513 0.01816922 0.02366709 0.02355974
  0.03716967 0.01347665]
 [0.03673552 0.02709848 0.02504518 0.01889856 0.01725937 0.02236368
  0.03385182 0.03007748 0.02256066 0.02018193 0.02841007 0.02214374
  0.02985199 0.0130674  0.01483898 0.03415055 0.03510377 0.02816658
  0.03141482 0.03108515 0.03193689 0.03407184 0.02339747 0.03672956
  0.03839377 0.0274647  0.0247257  0.01855179 0.01955312 0.01750925
  0.03494528 0.01239251]
 [0.03625008 0.02277237 0.02083001 0.01575029 0.01481632 0.0186108
  0.02971523 0.02542431 0.01980115 0.01761215 0.02629097 0.01932607
  0.02526263 0.01104346 0.01324557 0.04273487 0.04373475 0.03995857
  0.04156262 0.04020451 0.04186603 0.03160676 0.01999715 0.03829625
  0.04314939 0.03147285 0.02063645 0.02210641 0.01850223 0.01373045
  0.03436051 0.01476149]
 [0.03661273 0.03280618 0.02668298 0.01760549 0.01682181 0.02160861
  0.03986947 0.03449971 0.0234033  0.0196031  0.03651468 0.02402581
  0.03313239 0.01215596 0.01498012 0.05576503 0.04080217 0.04385377
  0.03845553 0.04058872 0.0373943  0.0343802  0.02144301 0.03791113
  0.0369848  0.03070059 0.02819681 0.02098321 0.01918192 0.01482808
  0.03367044 0.01227113]
 [0.03700709 0.02557527 0.02483414 0.01812451 0.01754761 0.02272526
  0.0315717  0.02810279 0.02423115 0.02040235 0.0328916  0.02427773
  0.02893995 0.01341143 0.0146025  0.04440672 0.03956037 0.04128356
  0.03953778 0.04303285 0.03815465 0.03078793 0.0194781  0.03289772
  0.031864   0.0322986  0.02439285 0.02013312 0.01767921 0.01565805
  0.02984968 0.01781531]
 [0.03542409 0.031893   0.03356757 0.05074217 0.05322971 0.0453938
  0.03447209 0.03105304 0.04193639 0.05510516 0.03882304 0.03780722
  0.03838863 0.07516187 0.09814189 0.03055452 0.03308649 0.03666278
  0.03521926 0.03414269 0.03339845 0.03781116 0.03543564 0.0180473
  0.01897886 0.02772147 0.03639908 0.03593347 0.0485144  0.02875928
  0.01114075 0.0914138 ]
 [0.03477732 0.03847286 0.03442519 0.06962097 0.13199079 0.05106211
  0.03188979 0.0293784  0.03664732 0.07287859 0.05314129 0.04744622
  0.03625082 0.08056911 0.10462111 0.03883038 0.05050112 0.07929453
  0.05496677 0.0493486  0.04845401 0.03671496 0.04375833 0.01927442
  0.01684497 0.02937881 0.04391189 0.04085521 0.04474139 0.02336498
  0.00941041 0.0890393 ]
 [0.03508502 0.03313914 0.0296712  0.03453391 0.04647876 0.02988835
  0.02625096 0.02718692 0.02958592 0.03912198 0.03326506 0.03557246
  0.031123   0.02791749 0.03677021 0.03362143 0.04196122 0.05903906
  0.05037159 0.04834812 0.04937254 0.03337375 0.05041857 0.04427037
  0.0453446  0.05636304 0.04001284 0.0675378  0.03895619 0.02349382
  0.02125109 0.0511328 ]
 [0.03582352 0.03870272 0.03691725 0.05102413 0.06666736 0.04066725
  0.03337324 0.03321939 0.03932635 0.05828603 0.04175834 0.04890738
  0.03649306 0.03400608 0.03512132 0.02999428 0.03737056 0.05888904
  0.04760575 0.04500147 0.04859624 0.03574761 0.04365227 0.02618097
  0.02343879 0.03195819 0.03720742 0.05242285 0.02867462 0.01620687
  0.01482143 0.04497069]
 [0.03605177 0.030868   0.0320061  0.03893394 0.04227504 0.03612149
  0.03334577 0.02722462 0.03745054 0.04238886 0.03597392 0.0352903
  0.03117261 0.02863458 0.03124983 0.02691181 0.03058815 0.03677803
  0.03933529 0.04037094 0.04350306 0.04410703 0.04310709 0.02423331
  0.02269206 0.02775454 0.03062183 0.04859199 0.03594629 0.0170688
  0.01391324 0.07221296]]

-* TASK 10/20 | SAMPLE 23/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 113/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 explicitly states that Mary travelled to the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' explicitly', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 38), x_tokens=38, y_tokens=21, max_supp_attn=0.0476, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 38)
DEBUG result.interpretability.attn_scores 798 
 [[0.04504929 0.05249947 0.05743859 0.07000107 0.06335743 0.06763493
  0.05132193 0.05761338 0.05972061 0.06200617 0.04299819 0.05030646
  0.05978002 0.09769931 0.09865177 0.03823422 0.03793448 0.0327506
  0.03632636 0.03412853 0.03279335 0.04850147 0.06605279 0.03095166
  0.03210964 0.05400041 0.06488879 0.06348566 0.12591943 0.06238715
  0.01374725 0.07103202 0.12096998 0.07903792 0.03269498 0.02135549
  0.05535423 0.06602581]
 [0.04629866 0.08672971 0.06617302 0.05470561 0.04999482 0.06215839
  0.08117936 0.10817136 0.0670341  0.05409878 0.04762288 0.06462041
  0.09413928 0.05221295 0.06490798 0.04329006 0.05408285 0.04190803
  0.05203189 0.04110219 0.03774978 0.06177177 0.04595897 0.03303795
  0.03847583 0.0504648  0.05147376 0.05509564 0.07163686 0.05271009
  0.02411766 0.02835728 0.0587387  0.04015748 0.03218029 0.02816756
  0.04345671 0.05312859]
 [0.04703488 0.06103276 0.07164568 0.09638743 0.09747321 0.11158777
  0.06530185 0.0674509  0.07632585 0.08761688 0.06048156 0.07516322
  0.08154652 0.1804039  0.1204889  0.04498712 0.03883278 0.0337069
  0.03417541 0.03081765 0.02999783 0.05354962 0.05718962 0.02953866
  0.02986565 0.04434666 0.05301231 0.04931298 0.08011221 0.0755395
  0.02988201 0.06951788 0.07080396 0.06033299 0.02593775 0.01833628
  0.04723847 0.03819449]
 [0.04549198 0.05492057 0.05921667 0.0475197  0.04328113 0.05526542
  0.05206852 0.05516263 0.05428376 0.0485713  0.0433755  0.05069776
  0.05488669 0.04114676 0.03799912 0.05099598 0.0452732  0.03643681
  0.03888489 0.03647205 0.03605547 0.05311137 0.06781038 0.06036503
  0.061894   0.0601081  0.05835672 0.05318801 0.05877601 0.09991024
  0.05543205 0.04000233 0.04074667 0.04705264 0.06329235 0.04781461
  0.06259015 0.05328779]
 [0.04639816 0.05541786 0.05758676 0.03239542 0.02647908 0.04151191
  0.04927192 0.04448633 0.04805087 0.03426738 0.03727768 0.03667599
  0.04081301 0.02732517 0.02636321 0.04621415 0.03716665 0.03056419
  0.0358411  0.03490421 0.03354718 0.05030559 0.06850965 0.05338003
  0.05163785 0.0551128  0.06769596 0.03780199 0.04233685 0.09304871
  0.049115   0.02157141 0.02469936 0.03993287 0.06460954 0.04944351
  0.0508247  0.04355093]
 [0.04741466 0.0685457  0.06775808 0.03580115 0.02706852 0.04568554
  0.05786083 0.04665403 0.06273204 0.03651522 0.03551048 0.03701773
  0.04085277 0.02657088 0.02680237 0.05447461 0.04260222 0.03235854
  0.03820334 0.03778233 0.03367991 0.04448155 0.08937486 0.0520244
  0.0453094  0.05342594 0.06640035 0.03340385 0.04129033 0.09802007
  0.0398745  0.02010657 0.03008374 0.04770529 0.07279344 0.04230711
  0.04360421 0.0427615 ]
 [0.04771886 0.05099569 0.05339697 0.03319069 0.02586051 0.03926561
  0.05492423 0.04147639 0.05201756 0.03360714 0.03491956 0.03504245
  0.03548237 0.02607448 0.02693692 0.04897754 0.03911959 0.02930191
  0.03738549 0.03596591 0.03316041 0.04446304 0.066716   0.06025482
  0.05576876 0.05321443 0.06861369 0.03609817 0.04241428 0.09872505
  0.05401902 0.02516353 0.03257088 0.05109848 0.07012197 0.05343779
  0.04922281 0.04206601]
 [0.04811788 0.03252241 0.03473688 0.02348704 0.01882295 0.02677988
  0.03352817 0.02789715 0.03573074 0.0249382  0.02988151 0.02496612
  0.02684204 0.01838418 0.02076566 0.04164225 0.03564294 0.0277959
  0.03633454 0.03545378 0.03179791 0.03768925 0.04352564 0.05841158
  0.06229171 0.04923229 0.04642626 0.03317967 0.03213334 0.05152126
  0.02820327 0.0191948  0.03304714 0.04036514 0.05842615 0.05658715
  0.03781066 0.04167325]
 [0.04708399 0.04498057 0.04767865 0.03612211 0.02700698 0.04249045
  0.04868709 0.04320227 0.04615051 0.03829323 0.04361131 0.05064137
  0.04580904 0.0270634  0.02529918 0.06098321 0.05337079 0.05597349
  0.05188059 0.05618307 0.04783167 0.04908259 0.04654849 0.0639866
  0.06769412 0.05463756 0.05519866 0.03969875 0.03840538 0.08018756
  0.14164385 0.02123424 0.02508301 0.03794527 0.05308852 0.05110031
  0.04568975 0.03745725]
 [0.04854897 0.04739574 0.04918768 0.04771941 0.03249971 0.0515324
  0.0471348  0.04720977 0.04945666 0.05054584 0.04758404 0.05779579
  0.05351511 0.0326886  0.02642595 0.0352126  0.03176195 0.03307006
  0.03618596 0.03772692 0.03700217 0.04645388 0.04042909 0.04299689
  0.046488   0.04611447 0.05042107 0.04557924 0.04194264 0.06884729
  0.17573078 0.04588663 0.04027041 0.04478392 0.04616707 0.04346501
  0.05319494 0.04377276]
 [0.04905916 0.0413727  0.04341672 0.03738454 0.02665397 0.04100643
  0.04384669 0.03888411 0.04052736 0.03843756 0.04346982 0.04219516
  0.04116419 0.02496534 0.02351285 0.04143604 0.03599947 0.03421098
  0.03772762 0.03909709 0.03905525 0.04379339 0.03884085 0.05557501
  0.06104924 0.04133068 0.04434787 0.04147866 0.03583251 0.03551031
  0.11954094 0.03753789 0.0257048  0.04054596 0.05165832 0.04958502
  0.05010094 0.03820363]
 [0.04812138 0.03246693 0.03062312 0.02535573 0.01808454 0.02727725
  0.03434009 0.02971623 0.03094767 0.02624637 0.03991045 0.03150198
  0.03313345 0.01693377 0.0176982  0.05335718 0.05055242 0.04679221
  0.04524234 0.04980091 0.04932171 0.04502564 0.02912475 0.06350352
  0.06393478 0.03504021 0.03093284 0.03617562 0.02712135 0.0188805
  0.06115964 0.02021424 0.01725119 0.03204179 0.07866607 0.07684671
  0.04365566 0.03918227]
 [0.0474062  0.03531995 0.03132305 0.0281445  0.01896221 0.02829903
  0.03972177 0.03469713 0.03297336 0.02792611 0.0394305  0.03227945
  0.03643321 0.01788197 0.0183495  0.06449806 0.05477201 0.0731101
  0.0523713  0.06544484 0.05989405 0.04392498 0.0260533  0.0603288
  0.06713675 0.04057865 0.0310948  0.04034414 0.02385451 0.01355045
  0.04166739 0.01526438 0.01809787 0.03053449 0.07972194 0.12027661
  0.04370368 0.0527815 ]
 [0.04928614 0.03656616 0.03480707 0.03165722 0.02220085 0.03299436
  0.04098786 0.03738605 0.03600512 0.03194583 0.04954544 0.03977732
  0.03980917 0.02046285 0.01971566 0.06222605 0.04689252 0.0753463
  0.053808   0.08993574 0.06505061 0.0403582  0.02562997 0.05374838
  0.04796851 0.03995195 0.03635824 0.03670416 0.0240082  0.01406568
  0.03801582 0.01713099 0.01830954 0.0303791  0.05020693 0.10222231
  0.03994594 0.03425513]
 [0.04932487 0.03192208 0.03084149 0.02631504 0.0193217  0.0259365
  0.03510223 0.03099683 0.0308054  0.02745628 0.04927634 0.03418297
  0.03277896 0.016672   0.01737544 0.05876506 0.04885044 0.0549757
  0.05651646 0.06704113 0.05390174 0.04297765 0.0262336  0.05364875
  0.04208421 0.0406387  0.02925934 0.03404652 0.02209761 0.01136581
  0.02848768 0.01784442 0.01866674 0.03061077 0.04259335 0.07685188
  0.0358812  0.03508241]
 [0.04787088 0.04246635 0.04270315 0.03822617 0.02817289 0.04156597
  0.05457893 0.0542272  0.04815588 0.04109383 0.05088818 0.04618502
  0.0518586  0.02395703 0.02308443 0.04320554 0.04839831 0.04545007
  0.06107054 0.05532203 0.05075161 0.05071366 0.04358679 0.05908034
  0.05128369 0.05769531 0.03692507 0.05177767 0.03697757 0.01981244
  0.02518437 0.02743984 0.03945018 0.0459762  0.03846167 0.04960878
  0.03949316 0.06193638]
 [0.04958226 0.03548637 0.03810783 0.03785172 0.02538443 0.03567316
  0.03816637 0.04212532 0.03634048 0.0408758  0.05057747 0.046631
  0.04199576 0.02515537 0.02289457 0.03932843 0.0438919  0.04220156
  0.05282521 0.04763858 0.04695133 0.04668931 0.02706457 0.03512575
  0.03603734 0.03713704 0.02734291 0.03982511 0.03066564 0.02057873
  0.02823229 0.04202535 0.01897101 0.02902578 0.0226483  0.0251184
  0.03530836 0.03299203]
 [0.04787526 0.04001554 0.04313987 0.06279733 0.05474914 0.05613313
  0.041806   0.04509383 0.04726498 0.0633604  0.04926247 0.05228174
  0.04993374 0.0896406  0.10199494 0.03411095 0.03691768 0.03753105
  0.03947783 0.03787816 0.03949594 0.04649252 0.04133062 0.02911295
  0.03191804 0.04300971 0.04008314 0.05761604 0.06522404 0.03005218
  0.01325259 0.13121346 0.07747159 0.05666009 0.02573116 0.01922046
  0.04794851 0.05478837]
 [0.04719038 0.05567542 0.055177   0.10797404 0.22896829 0.0809262
  0.04879908 0.05676425 0.05715292 0.10734694 0.08348847 0.0851114
  0.05396568 0.1345627  0.16271445 0.05029097 0.07136455 0.0768409
  0.05882963 0.04931424 0.06556596 0.04686759 0.05848782 0.03033272
  0.02918636 0.04979893 0.06154178 0.0688974  0.07014276 0.02764021
  0.00912442 0.1392596  0.08990726 0.08026128 0.02761867 0.01590997
  0.06432753 0.04908092]
 [0.04759545 0.04435648 0.03944919 0.05785457 0.08108896 0.03929805
  0.03619101 0.04080675 0.03657421 0.06113405 0.06534205 0.05648348
  0.04048502 0.04148997 0.05753978 0.04962404 0.08541159 0.10133021
  0.08812381 0.06415404 0.1124727  0.04464776 0.04145135 0.04472389
  0.04251384 0.04843326 0.04205355 0.06597346 0.03986721 0.01439518
  0.01490424 0.08521917 0.03733347 0.04522325 0.03560305 0.03155965
  0.05974312 0.05340783]
 [0.04753075 0.04931162 0.04559253 0.06910951 0.06456868 0.04697764
  0.04518122 0.04997808 0.05174995 0.06371662 0.05554615 0.05044315
  0.04477538 0.05870878 0.0604793  0.03814597 0.06116165 0.05834453
  0.05675773 0.05383656 0.06392349 0.0590992  0.0500809  0.02987229
  0.03535224 0.04572801 0.03757288 0.08031735 0.04924125 0.0132516
  0.00866523 0.104784   0.16182248 0.09032926 0.02777846 0.02078532
  0.05090531 0.08637115]]

-* TASK 10/20 | SAMPLE 23/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 114/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Fred being in the kitchen. In fact, sentence 10 states that Fred is in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', ' being', ' in', ' the', ' kitchen', '.', ' In', ' fact', ',', ' sentence', ' ', '10', ' states', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.1944, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02602414 0.03637565 0.03505114 ... 0.01989307 0.05674865 0.04741452]
 [0.02640866 0.0305332  0.03436637 ... 0.02262375 0.01973952 0.02765756]
 [0.02703508 0.0397852  0.04201755 ... 0.02369381 0.03568863 0.03875114]
 ...
 [0.02719226 0.03671994 0.03368921 ... 0.00924704 0.10265251 0.04775281]
 [0.02765209 0.03062806 0.0258463  ... 0.00896623 0.07938362 0.0284498 ]
 [0.02768469 0.03208603 0.0271428  ... 0.00943778 0.08435633 0.04493958]]

-* TASK 10/20 | SAMPLE 23/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 115/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 (from previous parts) explicitly states that Fred is in the bedroom, and there is no information that suggests Fred has moved from the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' (', 'from', ' previous', ' parts', ')', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' has', ' moved', ' from', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.125, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02332616 0.02458316 0.0228673  ... 0.02048062 0.03188051 0.04567282]
 [0.0235316  0.02323401 0.02251602 ... 0.02888219 0.0360927  0.02941576]
 [0.02415786 0.02745182 0.02805826 ... 0.01579984 0.02666889 0.03370028]
 ...
 [0.02440606 0.02690469 0.02442586 ... 0.01599479 0.03390236 0.03890215]
 [0.02474369 0.02167596 0.01931849 ... 0.02260735 0.03364772 0.03523845]
 [0.02468109 0.02345659 0.02124632 ... 0.01703354 0.02922683 0.0430451 ]]
Model's predictions for the sample 23:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 2 explicitly states  |
|          |                 |        that Fred is in the school.         |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |  The context sentences do not provide any  |
|          |                 |  information about Fred's location. They   |
|          |                 |       only mention Mary's movements.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 7 explicitly states  |
|          |                 |      that Mary travelled to the park.      |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences do not provide any  |
|          |                 |    information about Fred being in the     |
|          |                 |    kitchen. In fact, sentence 10 states    |
|          |                 |        that Fred is in the bedroom.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   The context sentence 10 (from previous   |
|          |                 |  parts) explicitly states that Fred is in  |
|          |                 |  the bedroom, and there is no information  |
|          |                 |   that suggests Fred has moved from the    |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 23:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.11 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 24/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 116/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 1 explicitly states that Julie is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03722049 0.06192299 0.07576098 0.08796579 0.08947363 0.09121011
  0.08453684 0.0997768  0.07460977 0.07949992 0.06258367 0.07701273
  0.09205272 0.09217175 0.05421434 0.03929915 0.03896625 0.04437365
  0.04075106 0.04491104 0.03702319 0.05096393 0.04664397 0.02424327
  0.02968565 0.04502264]
 [0.0378722  0.06924229 0.05939182 0.07631078 0.06562671 0.06696501
  0.06293804 0.06267552 0.05663016 0.05858905 0.04976486 0.04446259
  0.05244546 0.1112524  0.10512884 0.04033162 0.03574939 0.03530856
  0.03522009 0.0368974  0.03041623 0.04997639 0.04878373 0.01751434
  0.01979184 0.03904768]
 [0.04083787 0.06676115 0.04022266 0.06032707 0.04351486 0.04176876
  0.03856799 0.02828985 0.02768523 0.04040613 0.03533269 0.02038189
  0.02480229 0.03070876 0.03786158 0.02754011 0.01735903 0.01851416
  0.02380999 0.0245116  0.02179808 0.05631158 0.05499766 0.00920638
  0.00975905 0.02040485]
 [0.03836653 0.0414854  0.04976883 0.0293599  0.02001295 0.03451383
  0.0392608  0.03455112 0.0439911  0.03169227 0.0332507  0.03367675
  0.03271824 0.01464005 0.01403741 0.04752591 0.03975376 0.0406009
  0.04264983 0.04485459 0.04520574 0.0420125  0.06877775 0.07407799
  0.08871477 0.06453194]
 [0.03888355 0.04796105 0.05024212 0.07485175 0.06547491 0.05500785
  0.04186729 0.03666484 0.04163136 0.05342271 0.04318756 0.03133597
  0.03375587 0.1019043  0.10262655 0.04274452 0.03311759 0.02847921
  0.03029582 0.03271367 0.03004593 0.0497337  0.06436427 0.01599863
  0.01474228 0.0440161 ]
 [0.03958458 0.03098903 0.030816   0.05778041 0.04949667 0.05004611
  0.03127297 0.02872343 0.03542762 0.04991923 0.03815346 0.03561864
  0.03662579 0.11384714 0.13362159 0.04300304 0.03801964 0.03499003
  0.03463524 0.03544955 0.02924941 0.04266248 0.0390102  0.01155212
  0.01208084 0.02876642]
 [0.04018481 0.03445897 0.03976703 0.0601445  0.05331433 0.06259801
  0.04034092 0.03883132 0.04624732 0.0583486  0.04433526 0.0557813
  0.05480955 0.09159932 0.08491828 0.03620809 0.03450846 0.03409661
  0.03297026 0.03456383 0.02740234 0.03821898 0.03688547 0.01557783
  0.01612032 0.02756469]
 [0.03885689 0.05010386 0.06002493 0.05139192 0.04936494 0.06135174
  0.04807136 0.05402098 0.05370549 0.05485188 0.04732617 0.06439384
  0.05766877 0.05740928 0.05016342 0.04947729 0.04486661 0.04260372
  0.0393024  0.04168062 0.03632282 0.04340424 0.05314212 0.03728431
  0.03796823 0.04668209]
 [0.03922592 0.05917606 0.06881879 0.03991324 0.03107703 0.05017085
  0.05716578 0.06077147 0.0604303  0.04357603 0.04203239 0.05397034
  0.055268   0.02678421 0.01906907 0.04919499 0.04056115 0.03966493
  0.03885812 0.04077422 0.03804243 0.03890029 0.06266022 0.04491312
  0.05132445 0.05705827]
 [0.04023156 0.07680115 0.08277292 0.03427376 0.02379549 0.0439194
  0.05601349 0.05194435 0.06198649 0.03509416 0.03357755 0.04308629
  0.0423595  0.01732029 0.01430935 0.05417146 0.04027996 0.03740357
  0.03957918 0.04419546 0.03734117 0.03779493 0.07143211 0.03530149
  0.03953975 0.0454176 ]
 [0.04025669 0.04569846 0.05156574 0.02708164 0.02061013 0.03199788
  0.04588586 0.04359646 0.04766491 0.02986687 0.03010309 0.03601753
  0.03389035 0.01501965 0.0136186  0.05259119 0.04157776 0.03661433
  0.04078165 0.04319286 0.03922804 0.03752576 0.05789742 0.05420199
  0.05953183 0.04750263]
 [0.04051295 0.02646561 0.02978642 0.01823232 0.01542999 0.02294536
  0.0294026  0.0308186  0.04172961 0.02294794 0.02204823 0.02415835
  0.02402598 0.01052752 0.01059202 0.0373668  0.03523114 0.03157126
  0.03829439 0.04287801 0.039881   0.03319345 0.05261751 0.07595805
  0.09083379 0.05297088]
 [0.04043182 0.03389945 0.03638776 0.023619   0.01904818 0.03147442
  0.03598436 0.03548532 0.03517498 0.02712876 0.0302792  0.03669426
  0.03262961 0.01225937 0.01207019 0.04731308 0.03571638 0.03482858
  0.03562213 0.03748417 0.03716854 0.03657572 0.03643473 0.06041387
  0.07049191 0.05149665]
 [0.04110231 0.04359412 0.04692025 0.04008489 0.02874101 0.05117768
  0.04966508 0.05580095 0.04688945 0.05103682 0.05025887 0.07798025
  0.06202865 0.0214498  0.0150917  0.03627216 0.03676321 0.04081798
  0.03846045 0.03932876 0.03424991 0.04008684 0.02604269 0.02687304
  0.02723797 0.02733812]
 [0.04153457 0.03208885 0.03290608 0.025955   0.0212763  0.03047762
  0.03744336 0.03656785 0.03142923 0.03064241 0.03767288 0.0391378
  0.0380256  0.0130974  0.01182225 0.03682916 0.03307145 0.03289721
  0.03379036 0.03549488 0.03476959 0.03755686 0.02362498 0.04276602
  0.03686141 0.02602924]
 [0.04081864 0.02486134 0.02192855 0.01690906 0.01441253 0.01904503
  0.02664817 0.02601781 0.02391843 0.02012178 0.03184181 0.02598834
  0.02877249 0.0080583  0.0088472  0.0401524  0.0367115  0.03677905
  0.03561047 0.03705403 0.0465121  0.03406671 0.02143764 0.07505637
  0.06336262 0.03390093]
 [0.04039158 0.02341532 0.01928837 0.01568098 0.01252189 0.01744235
  0.0281998  0.03052765 0.02278505 0.018569   0.0296046  0.02276073
  0.02921261 0.00707777 0.0074406  0.04036493 0.04070553 0.05038977
  0.04341822 0.04332962 0.06525023 0.03128213 0.01892916 0.08359554
  0.067212   0.04352086]
 [0.04116631 0.02272727 0.01941287 0.0151161  0.01309774 0.01825316
  0.02529622 0.0262831  0.02268329 0.01903636 0.03535508 0.02783127
  0.02882445 0.00723362 0.00716557 0.03727513 0.04018649 0.04041163
  0.04280715 0.03937647 0.05073487 0.03002475 0.01622723 0.07239331
  0.04973434 0.0288177 ]
 [0.04089392 0.02181542 0.01817755 0.01246957 0.0114392  0.01566704
  0.027258   0.02557853 0.02223415 0.01639477 0.05282741 0.02717814
  0.02815511 0.00616213 0.00645721 0.04449671 0.04397768 0.04694809
  0.05285744 0.04550496 0.05760882 0.02961129 0.01619655 0.07408378
  0.04820676 0.03929645]
 [0.03954379 0.03289667 0.02913388 0.02000343 0.02056621 0.02763757
  0.05187704 0.04691251 0.0426349  0.02649207 0.04159658 0.03378484
  0.04325501 0.01142498 0.01147258 0.0441811  0.04685925 0.0576942
  0.06567905 0.06880645 0.06445728 0.03784744 0.03470064 0.06364863
  0.06227777 0.0757455 ]
 [0.04164257 0.02525039 0.02488927 0.02160914 0.01601462 0.02320487
  0.02626568 0.02992149 0.02905896 0.02454305 0.03106274 0.03065619
  0.02990793 0.01101142 0.0095908  0.0281025  0.027327   0.03294248
  0.03908828 0.0342943  0.03756926 0.03272726 0.0171237  0.02836885
  0.03695942 0.03542414]
 [0.04054569 0.03032809 0.02849193 0.04669964 0.04449092 0.04420118
  0.03016759 0.03003131 0.03466268 0.05076081 0.03969369 0.03960672
  0.03919465 0.0736975  0.08510567 0.02919206 0.03439312 0.03527366
  0.03427471 0.03322412 0.02996542 0.03918578 0.03213581 0.0122291
  0.01634168 0.0308438 ]
 [0.04019824 0.03203639 0.0279639  0.05208164 0.09420212 0.04236016
  0.02861236 0.0283526  0.03319245 0.0572581  0.04523671 0.03821139
  0.03339217 0.07441304 0.09565496 0.03553215 0.04795222 0.04862093
  0.0399885  0.03654518 0.03591226 0.03650556 0.03113917 0.01017861
  0.01119918 0.02616625]
 [0.03960764 0.03028088 0.02623144 0.04647026 0.10694105 0.0312461
  0.0251603  0.02750255 0.02933617 0.05274199 0.04761123 0.04275287
  0.03257765 0.03703764 0.04979679 0.03264187 0.08266034 0.06947172
  0.05627989 0.04258304 0.05262934 0.03415915 0.02932808 0.01897359
  0.02117072 0.03165669]
 [0.04008881 0.03573976 0.02932991 0.04566818 0.07005661 0.03531795
  0.03209809 0.03035364 0.03426091 0.0470592  0.04526358 0.03752095
  0.03360153 0.0338923  0.03932346 0.02819258 0.05368513 0.04870384
  0.0449754  0.04035124 0.04121599 0.05967223 0.0394672  0.01558977
  0.01885146 0.03077797]]

-* TASK 10/20 | SAMPLE 24/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 117/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the cinema. The context sentence 5 only mentions Mary being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentence', ' ', '5', ' only', ' mentions', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.1562, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02916818 0.03979078 0.04072927 ... 0.05645379 0.01197775 0.07602034]
 [0.02988218 0.04175816 0.03876706 ... 0.06493483 0.01945924 0.08490289]
 [0.03050917 0.0377822  0.04058041 ... 0.06290475 0.02781118 0.06705794]
 ...
 [0.03043009 0.03287124 0.03060023 ... 0.01950755 0.00880394 0.0916428 ]
 [0.03093385 0.02661956 0.02482188 ... 0.01216395 0.01323271 0.05258497]
 [0.03105542 0.02804391 0.02624166 ... 0.01114761 0.01185012 0.06948138]]

-* TASK 10/20 | SAMPLE 24/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 118/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 explicitly states that Mary is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 38), x_tokens=38, y_tokens=21, max_supp_attn=0.1429, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 38)
DEBUG result.interpretability.attn_scores 798 
 [[0.0451552  0.05966403 0.06282704 0.07926362 0.06832802 0.07986893
  0.06157076 0.05707943 0.0730924  0.07304651 0.05253209 0.05799234
  0.065266   0.11870763 0.11090748 0.04494295 0.04115452 0.03852217
  0.03443426 0.0376964  0.03521227 0.05047699 0.07448358 0.03240734
  0.02577068 0.05115215 0.05083849 0.06660062 0.13514808 0.06398028
  0.01419924 0.07429495 0.12331093 0.08746045 0.04047567 0.02961492
  0.05749369 0.05550195]
 [0.04603438 0.04819876 0.05132909 0.04542436 0.03896068 0.05396823
  0.05531593 0.05471188 0.05645315 0.0467855  0.04124995 0.05158292
  0.06263188 0.04403067 0.0532661  0.04257489 0.04086845 0.03801711
  0.04167671 0.04280706 0.03575563 0.0524683  0.05004524 0.03813607
  0.03612181 0.04581309 0.05239414 0.03949667 0.07560264 0.07923605
  0.02966483 0.03134316 0.05840433 0.04431611 0.04519674 0.03637743
  0.04945293 0.04232122]
 [0.04707312 0.06409209 0.07300989 0.09665148 0.09499791 0.10547074
  0.07001915 0.06338921 0.07479847 0.08141298 0.06123741 0.07258372
  0.07823744 0.17106123 0.12263142 0.05012505 0.04011101 0.03731518
  0.03277403 0.03561271 0.03151214 0.05263792 0.06252178 0.0341348
  0.02527961 0.04597975 0.05967456 0.05189101 0.08620682 0.07299542
  0.0241546  0.06988112 0.07518251 0.06735067 0.03291741 0.02530436
  0.0512152  0.03442871]
 [0.04572655 0.05297779 0.05841989 0.04896255 0.04082216 0.05733324
  0.0568746  0.05891594 0.05766983 0.04973417 0.04707232 0.05722355
  0.05827546 0.0429725  0.03685683 0.05104422 0.04372919 0.0389783
  0.03890312 0.04123374 0.03681215 0.05600128 0.0611076  0.05796204
  0.04995209 0.05366364 0.06396814 0.05107462 0.05552108 0.09063588
  0.05515926 0.03583138 0.04319366 0.04644209 0.05945782 0.04239376
  0.06265352 0.04173535]
 [0.04646791 0.06093329 0.05747473 0.03465655 0.02639331 0.04512208
  0.05278981 0.05469713 0.0509645  0.03628349 0.04029888 0.04349598
  0.05003424 0.03025224 0.0257824  0.04536799 0.03653183 0.03252635
  0.03653057 0.03835987 0.0351937  0.05235913 0.06473967 0.05302073
  0.04316046 0.05170675 0.0686973  0.03915785 0.04129371 0.09210061
  0.05330045 0.0232532  0.03094384 0.04228493 0.06893213 0.04285772
  0.05147133 0.03847967]
 [0.04768044 0.07297692 0.06945166 0.03715269 0.02628144 0.04748372
  0.0611475  0.05629762 0.06824269 0.03874369 0.03781122 0.04207416
  0.04655119 0.02967321 0.02670282 0.05499936 0.04319388 0.03709261
  0.03927471 0.04316079 0.03672739 0.04546038 0.08773314 0.05134356
  0.04020214 0.04605447 0.06082574 0.03440309 0.03921739 0.0870719
  0.03584233 0.01939668 0.03042134 0.04797752 0.08152254 0.03663763
  0.04712367 0.0346407 ]
 [0.04780648 0.05483864 0.05510329 0.03238175 0.02361197 0.0387443
  0.05624979 0.04648076 0.05179375 0.03198558 0.03644405 0.03521556
  0.03715362 0.02572171 0.02560615 0.05008003 0.03909241 0.03275625
  0.03684327 0.03903742 0.03475832 0.04327469 0.06182643 0.05266517
  0.04255034 0.04145965 0.05665661 0.03187646 0.0374429  0.07509304
  0.03669561 0.02017034 0.02753306 0.04809252 0.06977686 0.03517967
  0.04492139 0.03365654]
 [0.0484718  0.02966536 0.03095484 0.0219647  0.01816735 0.02616488
  0.03096174 0.03082614 0.03597695 0.02286259 0.02989648 0.02533019
  0.02705384 0.0168179  0.01770179 0.03335179 0.03053079 0.02696955
  0.0323127  0.03430161 0.02903106 0.03386438 0.0299903  0.03885932
  0.03925572 0.03399415 0.03503314 0.02349794 0.0235903  0.03475242
  0.01846233 0.01302142 0.0221919  0.03010872 0.05134177 0.03445689
  0.03257676 0.03065269]
 [0.04717732 0.04814578 0.04934042 0.03869533 0.02784459 0.04770254
  0.05241358 0.05487414 0.05155246 0.04227613 0.04583295 0.05444384
  0.05084124 0.02958626 0.02602066 0.05207436 0.04568944 0.04767058
  0.05105895 0.05047833 0.04467219 0.05356804 0.04277207 0.05451752
  0.05566039 0.04689929 0.05581656 0.03758637 0.03757872 0.08560717
  0.13141416 0.02193835 0.02454317 0.0384044  0.05233667 0.04311654
  0.04589337 0.03395976]
 [0.04837901 0.04903316 0.05020432 0.0477298  0.03067877 0.05232709
  0.05146965 0.05171371 0.04693044 0.04939165 0.05197927 0.05892352
  0.05587192 0.03231123 0.0258591  0.03947923 0.03454449 0.03794863
  0.03953833 0.04277714 0.03995965 0.04812979 0.03971073 0.04531997
  0.04196999 0.04162057 0.05958122 0.04204104 0.03908785 0.07523657
  0.17387155 0.04288112 0.03756223 0.04380171 0.04701625 0.04366311
  0.05417274 0.04137817]
 [0.04894686 0.04092535 0.04395605 0.03794274 0.02565991 0.04086845
  0.04530552 0.04329452 0.03769321 0.03852031 0.04471246 0.04243005
  0.04285155 0.02458214 0.02221332 0.04167561 0.03601603 0.03605316
  0.0417987  0.04275074 0.04308625 0.04628985 0.03667287 0.0550812
  0.05750561 0.04010621 0.04800722 0.04476935 0.03476418 0.04101344
  0.122794   0.03695468 0.02807007 0.03800655 0.04360919 0.04819944
  0.0518216  0.03717689]
 [0.04846226 0.03242903 0.03192566 0.0261431  0.01807412 0.02680532
  0.03452585 0.03585995 0.02904392 0.02817019 0.03877121 0.03190373
  0.03563044 0.01648861 0.01685154 0.05015122 0.05019185 0.04111836
  0.05207836 0.04789132 0.04993505 0.04743667 0.02943583 0.06623688
  0.07913644 0.04118092 0.0301173  0.04161026 0.02597536 0.02303127
  0.07159331 0.02201275 0.01986966 0.02810707 0.041846   0.07199766
  0.0420952  0.03962057]
 [0.04799365 0.03546422 0.03317232 0.028234   0.01841907 0.0271976
  0.03979307 0.03953298 0.02967605 0.02893267 0.0410211  0.03273817
  0.04016503 0.01620927 0.01707348 0.0617539  0.06462449 0.06040084
  0.07548277 0.07099664 0.0632797  0.04430909 0.02760444 0.07271488
  0.08934768 0.048724   0.02495255 0.04003072 0.022261   0.01499153
  0.05203477 0.01604353 0.01934716 0.0265188  0.0479803  0.10812315
  0.03393842 0.06160602]
 [0.04884362 0.0310494  0.02998189 0.0262078  0.0184688  0.02530561
  0.03201317 0.03453604 0.02637947 0.02756556 0.03979659 0.03294376
  0.03383128 0.01575233 0.01605025 0.04932523 0.05181077 0.0457103
  0.07183561 0.0563211  0.05755824 0.04133492 0.02280382 0.06353988
  0.09066315 0.04698262 0.0267571  0.04098264 0.02142343 0.01604849
  0.05407231 0.02158562 0.01834569 0.02383025 0.04018069 0.06866872
  0.03275846 0.04764799]
 [0.04911798 0.02959031 0.02841447 0.02359588 0.01739665 0.02293863
  0.03367261 0.03426683 0.02620274 0.02471519 0.04703665 0.03189164
  0.03448107 0.01385243 0.01462148 0.05427806 0.06183419 0.04530063
  0.07374403 0.05584593 0.05651101 0.04140147 0.02001159 0.06233274
  0.06663948 0.05968373 0.02224573 0.03785582 0.01822658 0.01162003
  0.03525649 0.01809547 0.01676367 0.02254968 0.03721879 0.09229346
  0.02686965 0.05757947]
 [0.04747567 0.03829853 0.03542828 0.0288674  0.02180953 0.02885208
  0.03843595 0.03711748 0.03395481 0.02749408 0.03612306 0.03117987
  0.03401993 0.01782982 0.01831377 0.03911806 0.03683524 0.03687127
  0.04118313 0.04499458 0.04125998 0.0446934  0.03865055 0.05499274
  0.0570443  0.069336   0.03123736 0.03874966 0.02905337 0.02080725
  0.01939504 0.02039599 0.03320803 0.03962279 0.06615393 0.08325934
  0.04841965 0.08300047]
 [0.04932012 0.03546863 0.03519093 0.03372688 0.02233472 0.03080278
  0.03557392 0.03892081 0.03365234 0.03271531 0.04321749 0.03930999
  0.03765319 0.02130218 0.01877561 0.03547279 0.03433643 0.0346713
  0.03980755 0.04149948 0.03695728 0.04518849 0.02394167 0.03066946
  0.03152958 0.03620967 0.02874833 0.03304781 0.02588167 0.02143849
  0.02409966 0.0366317  0.01966647 0.02702388 0.02698289 0.03758896
  0.02929304 0.03846169]
 [0.04779813 0.04543729 0.04783716 0.06319363 0.05172692 0.05939867
  0.04549699 0.05065532 0.05847868 0.0682929  0.0517207  0.0566759
  0.05589637 0.08894378 0.09619951 0.04019007 0.03761003 0.04620801
  0.03697788 0.04373099 0.03904361 0.04814968 0.04587856 0.02896975
  0.02958018 0.04689354 0.04545596 0.06438538 0.06543107 0.03297207
  0.01436805 0.11610485 0.08841928 0.05825154 0.03518341 0.02870902
  0.05181503 0.05223985]
 [0.04717324 0.06397289 0.06054755 0.1116011  0.22677805 0.08438674
  0.0545198  0.05721219 0.05792472 0.10726593 0.08530557 0.08481
  0.0568501  0.13685565 0.17484738 0.06213182 0.07148484 0.09015857
  0.05388862 0.05714472 0.07092611 0.04703898 0.06709664 0.03063131
  0.02644925 0.05444524 0.0706263  0.07426923 0.07693445 0.02922949
  0.00920866 0.13937789 0.09312182 0.0868326  0.03482407 0.02410798
  0.06748497 0.04981801]
 [0.04721549 0.05203523 0.04594044 0.06536626 0.10911289 0.04358234
  0.04074373 0.04530067 0.04161852 0.07142623 0.0666199  0.05928805
  0.0459538  0.04699799 0.07087732 0.05675814 0.09878537 0.12298331
  0.08032463 0.07278115 0.12178764 0.04577163 0.05461106 0.04470946
  0.03960393 0.04975273 0.05852338 0.0786287  0.05397547 0.01695294
  0.01456928 0.11209892 0.04081336 0.0540462  0.04196534 0.03537379
  0.06455589 0.05738161]
 [0.04768087 0.05480332 0.04949011 0.07223832 0.07413312 0.05567608
  0.05110686 0.05431728 0.05790093 0.07237934 0.06132063 0.05796297
  0.05075041 0.06005125 0.06284159 0.04510522 0.06102473 0.07272754
  0.04953194 0.06057822 0.06002074 0.06014499 0.05836233 0.0317552
  0.03257719 0.04834181 0.04984288 0.08804467 0.055384   0.01518563
  0.00984415 0.10868688 0.1490878  0.09897152 0.03508151 0.03207652
  0.05397353 0.08871267]]

-* TASK 10/20 | SAMPLE 24/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 119/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 states that Mary travelled to the bedroom, which implies that Mary is no longer in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03012326 0.04432252 0.04555106 ... 0.01827377 0.05815234 0.05083847]
 [0.03083121 0.03652566 0.04087016 ... 0.04323824 0.0232519  0.02663142]
 [0.03135158 0.0473487  0.05286084 ... 0.03102329 0.05185119 0.04549731]
 ...
 [0.03156949 0.04389948 0.03936403 ... 0.01148393 0.10136417 0.05115069]
 [0.03215179 0.033311   0.02768371 ... 0.01099247 0.0786566  0.03288932]
 [0.03184665 0.03622409 0.03052802 ... 0.01084158 0.09760594 0.05626136]]

-* TASK 10/20 | SAMPLE 24/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 120/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 previously stated that Mary travelled to the bedroom, and there is no information provided about Mary leaving the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' previously', ' stated', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' leaving', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 50), x_tokens=50, y_tokens=33, max_supp_attn=0.1818, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 50)
DEBUG result.interpretability.attn_scores 1650 
 [[0.02811538 0.03657562 0.03799032 ... 0.02263672 0.03613057 0.08281973]
 [0.02887419 0.03136216 0.0304328  ... 0.02068612 0.02512591 0.03736877]
 [0.02943837 0.03992397 0.04359616 ... 0.01498723 0.02976489 0.04511894]
 ...
 [0.02960059 0.0383898  0.03574922 ... 0.01612879 0.03466208 0.05021295]
 [0.03007657 0.02943937 0.02605585 ... 0.02554777 0.04402087 0.0382264 ]
 [0.02989639 0.0305883  0.02860649 ... 0.01776765 0.03419504 0.04909195]]
Model's predictions for the sample 24:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 1 explicitly states  |
|          |                 |        that Julie is in the cinema.        |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the cinema. The context    |
|          |                 |   sentence 5 only mentions Mary being in   |
|          |                 |                the school.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 8 explicitly states  |
|          |                 |        that Mary is in the school.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 10 states that Mary  |
|          |                 |  travelled to the bedroom, which implies   |
|          |                 |   that Mary is no longer in the school.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 10 previously     |
|          |                 |     stated that Mary travelled to the      |
|          |                 |    bedroom, and there is no information    |
|          |                 |  provided about Mary leaving the bedroom.  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 24:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.13 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 25/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 121/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences do not mention Julie being in the school. Sentence 1 states Julie went to the kitchen, and sentence 2 states Julie is in the office. There is no information about Julie being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' school', '.', ' Sentence', ' ', '1', ' states', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' and', ' sentence', ' ', '2', ' states', ' Julie', ' is', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 26), x_tokens=26, y_tokens=53, max_supp_attn=0.1321, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 26)
DEBUG result.interpretability.attn_scores 1378 
 [[0.01801901 0.03703444 0.02851124 ... 0.00767585 0.00413654 0.0123066 ]
 [0.01850943 0.03407979 0.03033956 ... 0.00776718 0.00354561 0.01269918]
 [0.01742543 0.03242984 0.0380987  ... 0.01305501 0.00652161 0.02017281]
 ...
 [0.01844565 0.02092001 0.02071408 ... 0.00627991 0.00372766 0.01051957]
 [0.0183177  0.01611443 0.01646124 ... 0.00872063 0.00634825 0.01354792]
 [0.01851554 0.01983707 0.01931548 ... 0.0073405  0.00507289 0.01027363]]

-* TASK 10/20 | SAMPLE 25/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 122/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 5 explicitly states that Mary is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.0476, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.0446861  0.08042186 0.06562854 0.09111533 0.09603889 0.10196356
  0.08271977 0.0711589  0.0793447  0.09855433 0.08213485 0.09152182
  0.11077932 0.09134947 0.06760798 0.04608542 0.03124435 0.0615749
  0.04484203 0.04966668 0.0457328  0.05444894 0.11624993 0.0422882
  0.02121213 0.04785414 0.05727551 0.05979918 0.10629688 0.03254187
  0.03120875 0.02601947]
 [0.04697233 0.07223277 0.0580689  0.06375241 0.05048878 0.04497449
  0.04899777 0.03565931 0.03739372 0.04233725 0.03856358 0.0245799
  0.03021158 0.05853965 0.08206572 0.05528218 0.02715945 0.02481092
  0.02723319 0.02923742 0.03006354 0.05027057 0.12436845 0.03676456
  0.01447081 0.04478491 0.06865665 0.04903091 0.13021931 0.01258256
  0.01143328 0.01250932]
 [0.04528933 0.0620822  0.06947625 0.07497427 0.06716318 0.06708419
  0.05542859 0.05373461 0.07085847 0.06605135 0.04764154 0.0473628
  0.04915024 0.11188533 0.11588325 0.05705163 0.0343674  0.03718081
  0.03599673 0.04011979 0.03850948 0.04723532 0.07445068 0.04581448
  0.02371838 0.0588722  0.06693099 0.06226425 0.13132031 0.02881181
  0.02608294 0.02143805]
 [0.04690149 0.0570589  0.06067086 0.08964843 0.0919745  0.09051196
  0.05479492 0.05535845 0.06599666 0.0857073  0.06382474 0.06974101
  0.07194191 0.15975356 0.13164008 0.05418687 0.03235741 0.04315688
  0.03520861 0.03727103 0.03628325 0.04769345 0.04646406 0.03387545
  0.02153129 0.04350995 0.05518007 0.04680969 0.10315024 0.03651679
  0.03348744 0.02749804]
 [0.04756941 0.05509941 0.06566837 0.07316086 0.06643732 0.07712085
  0.05571069 0.05762361 0.06029528 0.06586998 0.05191986 0.06325518
  0.06085126 0.10268615 0.07717615 0.04636765 0.02851142 0.03491424
  0.0306071  0.0330785  0.031568   0.04686559 0.04605233 0.04001669
  0.02655812 0.04245345 0.05181092 0.03970799 0.0861968  0.05989894
  0.05474579 0.03720189]
 [0.04569632 0.06049146 0.06588022 0.04472305 0.0342007  0.05235163
  0.0550811  0.06116897 0.05524964 0.04404515 0.04381358 0.05296096
  0.051312   0.02964017 0.02748355 0.05414227 0.03758781 0.03892839
  0.03773195 0.04018319 0.03848282 0.05231727 0.05884002 0.06656393
  0.05084731 0.05924287 0.06257576 0.04694979 0.04978054 0.1245481
  0.12273221 0.0657366 ]
 [0.04713336 0.05654304 0.06366213 0.03490487 0.0244738  0.04248537
  0.05705981 0.05286823 0.05529902 0.03169437 0.03846813 0.03931242
  0.04049686 0.02148801 0.02138865 0.05731631 0.03912621 0.03693728
  0.04077654 0.04274391 0.03857994 0.04655103 0.05138947 0.06331331
  0.05192142 0.0482839  0.0553855  0.0297422  0.02682264 0.07568179
  0.13137895 0.07548823]
 [0.04797579 0.02561472 0.02844416 0.01926963 0.01343142 0.02328744
  0.02714194 0.02708269 0.02835327 0.01822011 0.02788737 0.02217707
  0.02525226 0.01082345 0.01172516 0.03536562 0.02683769 0.02920633
  0.03601149 0.03845629 0.03363426 0.03397996 0.02704271 0.04992069
  0.04729764 0.03632753 0.02493991 0.023842   0.01540066 0.03234296
  0.05744189 0.04359987]
 [0.04716089 0.04713391 0.05098004 0.0316549  0.02147075 0.04287127
  0.04816785 0.04916315 0.04259301 0.03340479 0.03907757 0.04483471
  0.04139336 0.01845095 0.01783412 0.04917318 0.04782353 0.03928685
  0.04696564 0.04603371 0.04322378 0.05479914 0.04301692 0.06422313
  0.0751631  0.05612708 0.04909916 0.03509441 0.02680012 0.08439971
  0.06575172 0.09842157]
 [0.04842953 0.05711579 0.06334525 0.0508082  0.02981099 0.05889016
  0.05948824 0.06876791 0.05551303 0.0559022  0.05826635 0.08221643
  0.06594622 0.02962646 0.02305966 0.05131042 0.04590675 0.04818894
  0.04741194 0.04793977 0.04453685 0.05375574 0.04015344 0.0534801
  0.06800647 0.05383143 0.05361875 0.04183167 0.02980698 0.09307693
  0.06435429 0.0996995 ]
 [0.0492009  0.03917626 0.04237563 0.03330138 0.02143821 0.03861472
  0.04752395 0.04548952 0.03792874 0.03362646 0.04540449 0.04355681
  0.04395355 0.01904305 0.01713717 0.04694382 0.04970026 0.0395322
  0.04704059 0.0444653  0.04298954 0.05140511 0.02911779 0.04919916
  0.06218787 0.03810389 0.04094336 0.03041965 0.02161048 0.05780349
  0.04663595 0.0972798 ]
 [0.04861642 0.03388228 0.03169436 0.02415849 0.016528   0.02794158
  0.04136294 0.03898929 0.03293248 0.02567138 0.04197057 0.03460192
  0.03765479 0.01419313 0.01403061 0.05053391 0.06778401 0.04370414
  0.05876241 0.05182083 0.05198394 0.04960993 0.02457015 0.05720672
  0.0691972  0.03880941 0.03498572 0.03501993 0.01729494 0.04860503
  0.03968205 0.0561904 ]
 [0.04788011 0.03178744 0.02765289 0.02164704 0.01493599 0.02435158
  0.03769987 0.03585292 0.03036713 0.02270145 0.03537932 0.02922657
  0.03492081 0.01279633 0.01227157 0.04355554 0.06818449 0.0428869
  0.06366259 0.05359045 0.05742762 0.04392079 0.02192128 0.05526659
  0.0778003  0.0442889  0.03151385 0.04446433 0.01492767 0.04776475
  0.03457367 0.0538352 ]
 [0.04909222 0.03167564 0.02976778 0.02229956 0.01687161 0.02695429
  0.03896314 0.04223941 0.03485855 0.02640442 0.04608735 0.04113954
  0.04051594 0.01409368 0.01239398 0.04780954 0.08687378 0.04715644
  0.0748041  0.05615944 0.05534422 0.04212869 0.01979256 0.04332907
  0.10554301 0.04239256 0.02948004 0.04219611 0.01340536 0.04597127
  0.04116411 0.05468556]
 [0.04892704 0.02898255 0.02685981 0.01812392 0.01430976 0.02205959
  0.03791246 0.03630305 0.03298187 0.02062577 0.04462371 0.03131022
  0.03682612 0.01154813 0.0106313  0.05177471 0.07493948 0.04614036
  0.06863204 0.06020312 0.05812272 0.04128884 0.02005536 0.05366387
  0.09031521 0.05538753 0.02317316 0.0538839  0.01231894 0.04284516
  0.04907895 0.05071086]
 [0.04818775 0.03281524 0.0329383  0.02224392 0.01705054 0.0275039
  0.04166343 0.04138514 0.0393335  0.02287527 0.03159786 0.02917839
  0.03697447 0.01359532 0.01197571 0.03790208 0.03253693 0.03759308
  0.04321697 0.04819337 0.04399696 0.04504437 0.03234701 0.05712538
  0.05383641 0.05441698 0.02892536 0.0406488  0.01896663 0.04516513
  0.04727325 0.05111215]
 [0.04968447 0.03295647 0.03423294 0.02853899 0.01899836 0.03057437
  0.0396377  0.04679634 0.03877654 0.0308908  0.03754541 0.03793215
  0.04067701 0.01905905 0.01439575 0.03325325 0.03017962 0.03454758
  0.03982602 0.04283212 0.03864088 0.04574613 0.02315976 0.03399897
  0.03409121 0.03968864 0.03262321 0.04146368 0.02186088 0.04300403
  0.05195013 0.04804991]
 [0.04800144 0.04245779 0.04682631 0.06169368 0.05210519 0.05565263
  0.04286743 0.04573879 0.05292848 0.06486237 0.0484321  0.05542039
  0.05200079 0.08029628 0.09216727 0.03881897 0.03348013 0.04390572
  0.0368087  0.04272186 0.04057288 0.04727986 0.04222193 0.03348983
  0.02447742 0.04807618 0.05316679 0.05443367 0.05408515 0.02964421
  0.03437866 0.02478215]
 [0.04757209 0.05566823 0.05070662 0.0836948  0.17509231 0.06540863
  0.04616869 0.04661968 0.05267057 0.08556624 0.06858033 0.06450538
  0.04601781 0.10211349 0.13619469 0.05362606 0.0574965  0.07867038
  0.05068023 0.05441738 0.06145539 0.04618644 0.05478405 0.03442978
  0.02019735 0.05035572 0.07872301 0.0585897  0.05343595 0.01770631
  0.01666198 0.01831968]
 [0.04738749 0.04594526 0.04046535 0.05247743 0.0936214  0.03664681
  0.03670029 0.04070268 0.04201958 0.06322501 0.05795796 0.05008359
  0.03938844 0.03609835 0.0579846  0.05152904 0.09366468 0.11727041
  0.07841877 0.07461786 0.09896887 0.04185731 0.04528472 0.04676195
  0.03645834 0.05080518 0.05522115 0.0764579  0.02838072 0.02188933
  0.02088494 0.01978273]
 [0.04763541 0.05085873 0.04465529 0.05780889 0.06355829 0.042751
  0.04490951 0.0472973  0.05430581 0.06176397 0.05082336 0.04508282
  0.04373526 0.04292001 0.04495305 0.03797154 0.05423811 0.07440723
  0.05536238 0.06624797 0.06988228 0.05761543 0.05871738 0.03926805
  0.02516894 0.04638757 0.0457711  0.08735031 0.03791869 0.01919978
  0.01909916 0.01763892]]

-* TASK 10/20 | SAMPLE 25/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 123/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences 7 and 8 do not provide any new information about Julie. We need to refer to the previous context sentences 4 and 5, which mentioned Julie journeyed to the school. There is no information that suggests Julie left the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Julie', '.', ' We', ' need', ' to', ' refer', ' to', ' the', ' previous', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ',', ' which', ' mentioned', ' Julie', ' journey', 'ed', ' to', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Julie', ' left', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 38), x_tokens=38, y_tokens=61, max_supp_attn=0.0164, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 38)
DEBUG result.interpretability.attn_scores 2318 
 [[0.01505433 0.01564257 0.01374709 ... 0.01400183 0.06220109 0.0294543 ]
 [0.0156126  0.02775477 0.02077866 ... 0.03026281 0.06866828 0.01200539]
 [0.01503821 0.02247736 0.02086915 ... 0.03606831 0.0347564  0.0148224 ]
 ...
 [0.01594667 0.0190747  0.01737025 ... 0.06115288 0.03116014 0.00969016]
 [0.01641632 0.01202833 0.01023608 ... 0.03695073 0.014383   0.01074134]
 [0.01626741 0.01410257 0.01181317 ... 0.04886592 0.03102478 0.01040104]]

-* TASK 10/20 | SAMPLE 25/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 124/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 7 explicitly states that Bill journeyed to the park. There is no information that suggests Bill left the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' park', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' left', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 44), x_tokens=44, y_tokens=33, max_supp_attn=0.1515, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 44)
DEBUG result.interpretability.attn_scores 1452 
 [[0.02829598 0.03104638 0.03146184 ... 0.02608832 0.07004445 0.03198183]
 [0.02929291 0.05407532 0.0443507  ... 0.02822868 0.12881215 0.02591085]
 [0.02847267 0.04191801 0.0422129  ... 0.03749669 0.09477326 0.06024491]
 ...
 [0.02979646 0.04423051 0.04197843 ... 0.0361248  0.04309073 0.01827311]
 [0.03032394 0.03114923 0.02770863 ... 0.04293269 0.02410119 0.01081072]
 [0.03011677 0.03735474 0.03137564 ... 0.02995644 0.04127283 0.00908104]]

-* TASK 10/20 | SAMPLE 25/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 125/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 13 states that Julie is in the kitchen, and there is no information that suggests Julie was ever in the park or moved to the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Julie', ' was', ' ever', ' in', ' the', ' park', ' or', ' moved', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02374363 0.02905557 0.03113807 ... 0.03975761 0.01884277 0.01586241]
 [0.02434405 0.03915772 0.0364834  ... 0.05106573 0.01359948 0.01050603]
 [0.0239216  0.03558768 0.03821207 ... 0.03785658 0.01640221 0.01299965]
 ...
 [0.02505046 0.03772815 0.03562273 ... 0.02989895 0.01605303 0.01089918]
 [0.02553339 0.0268277  0.02459695 ... 0.024731   0.0191028  0.0162371 ]
 [0.02519823 0.03099792 0.02760381 ... 0.03033605 0.01760577 0.01502628]]
Model's predictions for the sample 25:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |   Julie being in the school. Sentence 1    |
|          |                 |   states Julie went to the kitchen, and    |
|          |                 |     sentence 2 states Julie is in the      |
|          |                 |   office. There is no information about    |
|          |                 |         Julie being in the school.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 5 explicitly states that Mary   |
|          |                 |             is in the school.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    The context sentences 7 and 8 do not    |
|          |                 |  provide any new information about Julie.  |
|          |                 |  We need to refer to the previous context  |
|          |                 |  sentences 4 and 5, which mentioned Julie  |
|          |                 |    journeyed to the school. There is no    |
|          |                 |  information that suggests Julie left the  |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 7 explicitly states that Bill   |
|          |                 |     journeyed to the park. There is no     |
|          |                 |  information that suggests Bill left the   |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  Sentence 13 states that Julie is in the   |
|          |                 |    kitchen, and there is no information    |
|          |                 |  that suggests Julie was ever in the park  |
|          |                 |           or moved to the park.            |
+----------+-----------------+--------------------------------------------+

Metrics for sample 25:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.09 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 26/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 126/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 2 explicitly states that Mary is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.12, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03748659 0.05564952 0.0679249  0.08909874 0.09552303 0.08717964
  0.06337325 0.07888477 0.06736592 0.07745145 0.05911573 0.07217944
  0.08109281 0.10846216 0.06729277 0.03881676 0.03386616 0.04219505
  0.03604428 0.04146704 0.03572496 0.04892398 0.04677526 0.0312939
  0.01663452 0.03255703]
 [0.03720073 0.08818106 0.07349607 0.06973069 0.05494293 0.07180895
  0.21020572 0.15071855 0.08455036 0.07425442 0.0907507  0.07140751
  0.11314306 0.03681407 0.02859185 0.05284989 0.04152051 0.06443819
  0.04750589 0.0600933  0.05251164 0.05819271 0.04579961 0.04567145
  0.02820272 0.03610238]
 [0.04085992 0.06816158 0.04149685 0.06062245 0.04396305 0.04056595
  0.03291696 0.0253042  0.02668495 0.03893109 0.03411794 0.01944533
  0.02262974 0.03398422 0.04329001 0.03020826 0.01586868 0.01839334
  0.02177767 0.02359551 0.02206674 0.05502576 0.05817425 0.01499193
  0.00628486 0.01538692]
 [0.0384915  0.04244407 0.04423713 0.02774864 0.01894429 0.03318419
  0.03089927 0.02886848 0.03829689 0.02905579 0.03080442 0.02958751
  0.0285158  0.01409654 0.01379679 0.04170897 0.03489072 0.03725441
  0.04233988 0.0448258  0.04465066 0.04184851 0.0633999  0.07373841
  0.07650343 0.07448974]
 [0.03883441 0.04832766 0.05178526 0.07566734 0.06693693 0.05363093
  0.03568533 0.03317871 0.04046965 0.05192947 0.04183064 0.03018141
  0.03104863 0.11357007 0.11593285 0.04698847 0.03055985 0.02850282
  0.02791351 0.03179109 0.03081128 0.04915871 0.06810112 0.02537284
  0.00903278 0.03358749]
 [0.03960262 0.03123266 0.03184546 0.0583715  0.05019629 0.04906956
  0.02679266 0.02608506 0.03447623 0.04844495 0.03709953 0.03432262
  0.03385118 0.12386463 0.14414114 0.04647572 0.03425819 0.03446903
  0.03174625 0.03427036 0.02975925 0.04220236 0.0412508  0.01849278
  0.00757489 0.02220805]
 [0.04020507 0.03474311 0.0409239  0.0608882  0.05434368 0.06175369
  0.03490056 0.0356997  0.04559227 0.05709465 0.04314677 0.05439905
  0.05136047 0.09899723 0.09018218 0.03881335 0.03110089 0.03383783
  0.03031713 0.03355927 0.0279396  0.03792468 0.03873048 0.02317256
  0.010643   0.02169574]
 [0.03890137 0.04827705 0.05755046 0.0503658  0.04983777 0.06102683
  0.04152774 0.05005508 0.05343807 0.05416706 0.04606458 0.06431798
  0.05578415 0.06177648 0.05445596 0.05118864 0.0421752  0.04214003
  0.03683772 0.04054928 0.03635446 0.04313431 0.05515813 0.04228083
  0.03009835 0.03957304]
 [0.03924561 0.05859709 0.06791941 0.03890537 0.031252   0.04933832
  0.04869186 0.05593349 0.05570457 0.04138553 0.04093776 0.05128147
  0.0521022  0.0289199  0.02019168 0.05003604 0.03882385 0.03875743
  0.03690095 0.03967515 0.03753238 0.03801386 0.06522076 0.05333903
  0.04293031 0.05117771]
 [0.04027913 0.07806168 0.08470248 0.03412504 0.02410068 0.04322639
  0.0486454  0.04790513 0.05925257 0.0337429  0.03278441 0.04188056
  0.03976815 0.01872229 0.01528332 0.05842615 0.03793616 0.0371859
  0.03675651 0.04239476 0.03700795 0.03725589 0.07416798 0.0477704
  0.02994802 0.03688427]
 [0.04034594 0.04505426 0.05171753 0.0271776  0.02064345 0.03219836
  0.04010586 0.04041199 0.04607624 0.02889808 0.02916796 0.03514999
  0.03243094 0.01580785 0.01412104 0.05464846 0.04098268 0.03632379
  0.03902367 0.04132085 0.03792502 0.03720037 0.05665022 0.06066143
  0.05006408 0.04573715]
 [0.04066515 0.0244506  0.02828053 0.0179618  0.01516568 0.02242275
  0.0248328  0.0275873  0.04010156 0.02155117 0.02080589 0.02274677
  0.02201163 0.01093809 0.01055078 0.03734561 0.03347628 0.02955267
  0.03565954 0.03869079 0.03661848 0.03153877 0.04722116 0.07142232
  0.06977094 0.0686594 ]
 [0.04029941 0.03344689 0.03558886 0.02414838 0.02006725 0.03244645
  0.03139285 0.03423882 0.03478298 0.02744743 0.02994488 0.03658949
  0.03193365 0.01291489 0.01248114 0.04604098 0.03948783 0.03665342
  0.03962408 0.03928936 0.03719725 0.03755619 0.03427684 0.05604039
  0.07050116 0.05379647]
 [0.04105397 0.04306732 0.04689321 0.04061375 0.02920456 0.05337631
  0.04329347 0.05305957 0.04856938 0.05253405 0.04884324 0.07980303
  0.06048738 0.02326996 0.01607526 0.0348125  0.03646133 0.03974254
  0.03739885 0.03848718 0.03357019 0.03948193 0.02705197 0.02779081
  0.0260132  0.02401223]
 [0.04159626 0.03011489 0.03159651 0.02529521 0.0211646  0.03130829
  0.03276103 0.03486324 0.0316576  0.03030766 0.03651683 0.03964579
  0.03735473 0.01352914 0.01206259 0.03453891 0.03807661 0.03316131
  0.03652553 0.03554405 0.03362272 0.03772405 0.0228286  0.03163463
  0.04518992 0.02659598]
 [0.04078805 0.02253645 0.02006152 0.0161585  0.01397742 0.01911815
  0.02339027 0.02597129 0.02390893 0.01988694 0.03020433 0.02599131
  0.02907631 0.00820585 0.0090125  0.03516819 0.04998856 0.03582962
  0.04502306 0.03898472 0.04221057 0.03482265 0.01916425 0.04104818
  0.08617939 0.04791127]
 [0.04027029 0.02152079 0.01811386 0.01501958 0.01229618 0.01742396
  0.0239014  0.02761962 0.022411   0.01785799 0.02817216 0.0219464
  0.02844415 0.00719142 0.00762074 0.0337938  0.05661335 0.04162805
  0.06109954 0.04802458 0.06153787 0.03165898 0.01725022 0.04781049
  0.10837081 0.05660719]
 [0.04106982 0.02124112 0.01857972 0.01535176 0.01321427 0.01942609
  0.02242996 0.02622339 0.02330056 0.01967172 0.03387732 0.02903812
  0.02862818 0.00780893 0.00777341 0.03091317 0.05508527 0.03689403
  0.0543786  0.04152904 0.04602376 0.03043548 0.01456686 0.03290402
  0.08889341 0.03919318]
 [0.04086817 0.01977977 0.01735328 0.01293787 0.01165084 0.01685596
  0.02456845 0.02612126 0.02281488 0.01676548 0.04912299 0.02723528
  0.02888385 0.00672358 0.00707624 0.03641516 0.05725696 0.04133781
  0.05795174 0.04731961 0.05401654 0.03056618 0.01487699 0.04157153
  0.06119144 0.06378367]
 [0.03968491 0.02983967 0.02696256 0.01896627 0.01647302 0.02344884
  0.03302022 0.03228538 0.03607811 0.02137538 0.03253365 0.02468678
  0.03047267 0.00961199 0.00988338 0.04267963 0.03634161 0.04141873
  0.04623319 0.04782174 0.06429633 0.037919   0.03185568 0.10392103
  0.07076114 0.07568359]
 [0.04173156 0.02403687 0.02466161 0.02268675 0.01656905 0.02505816
  0.02323022 0.0283255  0.02953937 0.02599349 0.02907084 0.03142975
  0.02935024 0.01210153 0.0106758  0.02467255 0.02780065 0.02977278
  0.03661606 0.03400016 0.03573583 0.03234614 0.01774071 0.0255137
  0.02295781 0.03824149]
 [0.04050193 0.0314999  0.03022729 0.05011587 0.04848946 0.04574428
  0.0265913  0.02805659 0.03474889 0.05128875 0.03940276 0.03874036
  0.03720863 0.08150734 0.09378292 0.03182659 0.03056342 0.03433578
  0.03102071 0.03211411 0.03055088 0.03899301 0.03473338 0.01875418
  0.00941683 0.02455664]
 [0.04024107 0.03249248 0.02918298 0.05300273 0.09623368 0.04173458
  0.02484519 0.02611867 0.03262044 0.05632251 0.0440556  0.03702944
  0.03090534 0.07998408 0.10322082 0.03833092 0.04253899 0.0508463
  0.03671923 0.03611737 0.03596861 0.0360372  0.03289722 0.01614858
  0.00708148 0.02053107]
 [0.03964597 0.03058988 0.02774236 0.04700755 0.10362573 0.0314715
  0.02257245 0.02684135 0.03072885 0.05396499 0.04640666 0.04307638
  0.03083511 0.03602218 0.05179723 0.03447213 0.06963599 0.08086725
  0.05332889 0.04593493 0.05395404 0.03329753 0.03003749 0.0268087
  0.01453882 0.02617586]
 [0.04013054 0.0366537  0.03115627 0.04803259 0.0711842  0.03718192
  0.02942576 0.02964287 0.03682963 0.0496771  0.04522244 0.03788818
  0.032681   0.03517563 0.04070761 0.02882911 0.04469031 0.05446195
  0.04125755 0.0425999  0.042413   0.05874174 0.04207005 0.02184582
  0.01121666 0.02485248]]

-* TASK 10/20 | SAMPLE 26/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 127/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Julie moved to the school, but there is no mention of Julie being in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02920366 0.04204734 0.0438995  ... 0.05578728 0.01065479 0.0723059 ]
 [0.02992176 0.0443932  0.04170686 ... 0.06520983 0.01852655 0.08122997]
 [0.03051523 0.04171241 0.04586746 ... 0.06375787 0.02598057 0.06254123]
 ...
 [0.03045009 0.03455921 0.0324101  ... 0.02055865 0.00792127 0.0922935 ]
 [0.03083839 0.02747246 0.02558231 ... 0.0120467  0.01073679 0.0562194 ]
 [0.03099984 0.02660322 0.0247461  ... 0.01097265 0.00873819 0.0786966 ]]

-* TASK 10/20 | SAMPLE 26/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 128/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 states that Mary moved to the office, which implies that Mary is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.0310555  0.04241337 0.04256351 ... 0.02272004 0.03674371 0.03029026]
 [0.0318842  0.05613614 0.05156288 ... 0.03358177 0.03701405 0.04047303]
 [0.03250966 0.04380819 0.04840743 ... 0.01944304 0.02780282 0.02796323]
 ...
 [0.03263876 0.04145576 0.04273658 ... 0.01746915 0.0310741  0.03425467]
 [0.03301111 0.03113077 0.03023711 ... 0.02696048 0.03098046 0.04199622]
 [0.03300952 0.034344   0.03360293 ... 0.02403383 0.03447224 0.03581211]]

-* TASK 10/20 | SAMPLE 26/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 129/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 explicitly states that Mary is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 44), x_tokens=44, y_tokens=21, max_supp_attn=0.1905, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 44)
DEBUG result.interpretability.attn_scores 924 
 [[0.04535989 0.05797715 0.05917485 0.06981286 0.07250266 0.06809443
  0.05030129 0.05384137 0.05690215 0.06870846 0.04888789 0.05536969
  0.06173233 0.0967393  0.09639521 0.04094974 0.03673748 0.03666056
  0.03824172 0.03793015 0.03669411 0.04577379 0.06041433 0.03258313
  0.01747374 0.0529663  0.05123305 0.05675219 0.11450917 0.05802962
  0.01215909 0.05784619 0.10039639 0.08472974 0.03722558 0.02498032
  0.04821173 0.03761249 0.01831108 0.1480432  0.02272769 0.02174531
  0.02118564 0.06843486]
 [0.04609056 0.04850419 0.05331954 0.04510859 0.04489844 0.05602817
  0.0505813  0.06066643 0.04749053 0.04256031 0.04303836 0.05337684
  0.065313   0.04241545 0.05390117 0.04068577 0.0398832  0.03863932
  0.04703546 0.04806931 0.04147036 0.0480137  0.04474647 0.03780147
  0.03146459 0.04781924 0.04171414 0.03454537 0.07459325 0.07157869
  0.02580241 0.02391864 0.04190991 0.04546924 0.04321119 0.03501881
  0.04712107 0.03950179 0.0359545  0.07087507 0.05550788 0.04788192
  0.05833139 0.03688974]
 [0.04714942 0.0609918  0.06809287 0.09353651 0.10349248 0.09873655
  0.05743844 0.06285443 0.06067517 0.08250038 0.05887811 0.07252104
  0.07656863 0.1529595  0.10027032 0.04501404 0.03587782 0.03579646
  0.03449201 0.03330039 0.03249934 0.05094176 0.05398246 0.0345569
  0.01770236 0.04893124 0.06365541 0.0463631  0.07902883 0.0787389
  0.02799094 0.06971761 0.07063063 0.07095473 0.03510593 0.02334757
  0.04156965 0.03906267 0.01439169 0.09861189 0.04321689 0.03541737
  0.03068424 0.06549447]
 [0.04591158 0.0494191  0.05755178 0.0466185  0.04384464 0.05625237
  0.04692959 0.05286931 0.04806589 0.0462563  0.04372267 0.05203227
  0.05172451 0.04245151 0.0353283  0.04370842 0.0380034  0.03445156
  0.03835499 0.03632041 0.03536347 0.05244891 0.05673419 0.04683683
  0.03406689 0.05541791 0.06670587 0.04837944 0.06057668 0.09509868
  0.05321085 0.03570898 0.03841441 0.0455755  0.05375187 0.03837347
  0.04798153 0.04431855 0.02079624 0.05497476 0.10381915 0.05655197
  0.05296499 0.04775713]
 [0.04651796 0.05651956 0.05993925 0.03396889 0.02816475 0.04814534
  0.04790669 0.04979168 0.04827163 0.03483767 0.03840667 0.04186992
  0.04398808 0.0321425  0.02779126 0.04654439 0.03754888 0.03135678
  0.03891803 0.03558856 0.03473195 0.05264197 0.06889796 0.04620028
  0.03937308 0.0508431  0.07747436 0.03211333 0.04482708 0.08573938
  0.03988979 0.01740288 0.02643243 0.04023855 0.06093949 0.04214586
  0.04344528 0.03604575 0.02274975 0.03432376 0.10855038 0.04701327
  0.05219736 0.02721004]
 [0.04742289 0.07803404 0.07323729 0.0409194  0.03031719 0.05283325
  0.05623968 0.05365932 0.05931521 0.0392829  0.0387005  0.04527538
  0.04774598 0.03299946 0.02840675 0.05391078 0.0408562  0.03500415
  0.0420514  0.04006517 0.03704029 0.04634653 0.08143476 0.04759473
  0.03526925 0.04408656 0.07089566 0.03145396 0.04013043 0.08061855
  0.036447   0.01831822 0.02938739 0.04284738 0.06889297 0.04173576
  0.04113942 0.03665564 0.02435707 0.0331219  0.10551469 0.03979602
  0.04555274 0.02657717]
 [0.04772936 0.05644853 0.05902708 0.03822782 0.02816849 0.04799502
  0.05278048 0.04995998 0.05401485 0.03620641 0.03587818 0.04143373
  0.04015422 0.03154644 0.0295927  0.05404276 0.04041066 0.03236445
  0.04099195 0.03742087 0.03471166 0.04480464 0.06134904 0.05904577
  0.03633331 0.04189183 0.06167077 0.0300731  0.03986793 0.07436603
  0.03493251 0.01943209 0.03073874 0.04341556 0.06121688 0.04130528
  0.03727493 0.03363059 0.01827399 0.03380541 0.09272291 0.04086571
  0.04083426 0.02594939]
 [0.0481297  0.03232003 0.03597528 0.02726045 0.02118055 0.03092237
  0.03246863 0.03469205 0.03798475 0.02689738 0.03045006 0.03042702
  0.03185356 0.02009198 0.02332068 0.04360497 0.03726831 0.03119696
  0.04052886 0.03895582 0.03449801 0.03794076 0.0396978  0.05409304
  0.03805218 0.03753162 0.03076188 0.02529027 0.03010205 0.03677884
  0.01551791 0.01388321 0.02531531 0.03425969 0.04822159 0.04313162
  0.03575028 0.02741244 0.02070969 0.02585991 0.05330801 0.03003099
  0.02596223 0.01959354]
 [0.04693873 0.04232147 0.04565005 0.03646352 0.02621411 0.04457336
  0.04358415 0.04500692 0.04437656 0.03777605 0.04179731 0.04693808
  0.04103673 0.02753738 0.02510311 0.04652894 0.04825533 0.03933954
  0.05184462 0.04296233 0.04184223 0.04806904 0.04037262 0.0513316
  0.0689551  0.04670074 0.04594068 0.03738831 0.04339889 0.10183037
  0.15145639 0.02122186 0.02463063 0.03429439 0.05794232 0.05316501
  0.04360379 0.03985417 0.02898121 0.0323088  0.08782168 0.05852951
  0.06060084 0.02578142]
 [0.04820932 0.04223055 0.04333391 0.04343455 0.02763786 0.04435934
  0.03817077 0.0413591  0.03803357 0.04025399 0.04230378 0.04422893
  0.03853026 0.02924918 0.02493597 0.0317914  0.02909258 0.03030307
  0.03631106 0.03673175 0.03833983 0.0468073  0.03542874 0.04035226
  0.05172127 0.04360535 0.05005697 0.05335977 0.04221061 0.08113082
  0.18114717 0.0502696  0.04209009 0.04018433 0.05543538 0.05237539
  0.04951751 0.05348043 0.03316024 0.04096661 0.06625433 0.06634104
  0.0901477  0.04785553]
 [0.04912042 0.03602795 0.04043428 0.03810063 0.02506316 0.04004851
  0.03888827 0.03919171 0.03830556 0.03641988 0.03950467 0.04354263
  0.03702565 0.02736768 0.02415735 0.03495199 0.03410912 0.03210982
  0.0392845  0.03789631 0.03907953 0.04407659 0.03368507 0.04359683
  0.05711496 0.03973936 0.04024404 0.04635832 0.03595876 0.04096083
  0.11590962 0.03436931 0.02558559 0.03324261 0.04309082 0.04218661
  0.03727493 0.04666052 0.02895648 0.02996606 0.05511875 0.0641182
  0.07336012 0.0328957 ]
 [0.0483628  0.03322357 0.03277498 0.02982894 0.02006697 0.03022173
  0.03694284 0.03553358 0.03393625 0.02884374 0.04168519 0.03730997
  0.03563317 0.02031682 0.02090174 0.04989285 0.05614488 0.04089167
  0.04866128 0.04494422 0.04745149 0.04769666 0.02966961 0.0575872
  0.07950539 0.04292579 0.02863023 0.04601589 0.02888132 0.02297947
  0.07261712 0.02075964 0.01987387 0.02745026 0.04610369 0.05438767
  0.04035445 0.04954191 0.04547478 0.02183338 0.0382967  0.06075487
  0.05652146 0.02140392]
 [0.04806045 0.03480334 0.03159016 0.03032541 0.01886743 0.02843319
  0.03931994 0.03594577 0.03443839 0.02834982 0.03868503 0.03311417
  0.03640355 0.01906108 0.01956667 0.05000106 0.05727051 0.04408667
  0.05246596 0.04623521 0.05200732 0.04380888 0.02608796 0.05160866
  0.10189301 0.04178128 0.02554302 0.04050839 0.02366109 0.01442073
  0.05296651 0.01445605 0.01936937 0.02577176 0.04694457 0.06314747
  0.04333207 0.05016806 0.05410485 0.02088731 0.02767246 0.0660047
  0.05862717 0.01787987]
 [0.04883621 0.03052715 0.02945239 0.02886884 0.01927101 0.02785485
  0.03325614 0.03312919 0.03361195 0.02875165 0.03752904 0.03610745
  0.03303265 0.01905683 0.01893217 0.04150029 0.05605622 0.04170972
  0.05486471 0.04737306 0.05470783 0.04075684 0.02733913 0.04887012
  0.1164173  0.04331597 0.03006358 0.05002309 0.02592051 0.01670358
  0.05581545 0.02248955 0.0205045  0.02565682 0.04133578 0.0664741
  0.04497749 0.05321479 0.06330366 0.02375518 0.02408048 0.06384256
  0.07061177 0.02450549]
 [0.0489192  0.03013789 0.02925364 0.02566028 0.01841153 0.02575548
  0.03858202 0.03449282 0.03415245 0.02631976 0.05303244 0.03493895
  0.03526063 0.01652412 0.01815454 0.05139705 0.06614317 0.04414085
  0.05867106 0.05055335 0.05285926 0.04281442 0.02631221 0.05335116
  0.07904252 0.05199737 0.02704987 0.04025514 0.02161477 0.01199958
  0.03430689 0.01812424 0.01754955 0.02521659 0.04116656 0.08543795
  0.05712571 0.05860891 0.11513353 0.02453863 0.01886388 0.06228986
  0.06146002 0.0205895 ]
 [0.0476645  0.09198208 0.06747881 0.04616716 0.03535074 0.04505744
  0.12892076 0.09870746 0.07406904 0.04598423 0.09449726 0.06820318
  0.10165869 0.02715556 0.03004106 0.12121661 0.08435423 0.13877055
  0.0796801  0.10843773 0.08706382 0.05761387 0.06126521 0.13057525
  0.0876933  0.0798884  0.04818259 0.0487585  0.03571743 0.01570337
  0.01994263 0.01497737 0.0430991  0.05463161 0.10190891 0.12512831
  0.09903879 0.11426325 0.34500495 0.03715944 0.02014784 0.05824881
  0.05199136 0.02471758]
 [0.04912656 0.03110394 0.03430378 0.0346623  0.02507063 0.03495805
  0.03700409 0.0390337  0.04297825 0.0387262  0.04015031 0.04238614
  0.03902938 0.02661678 0.02354986 0.03186275 0.03467587 0.03435539
  0.04367388 0.04635096 0.04027224 0.04277795 0.02539427 0.02824177
  0.02630799 0.04055222 0.03675254 0.04472741 0.03229938 0.02540354
  0.0286453  0.05228215 0.02147748 0.02795988 0.0272327  0.04523815
  0.04440763 0.03702971 0.02680514 0.03632178 0.024412   0.1013854
  0.06837929 0.05856258]
 [0.04784105 0.03980975 0.04120888 0.06044567 0.04981989 0.05116191
  0.03819118 0.03920201 0.04783924 0.06096071 0.04602692 0.04690807
  0.0433913  0.07580733 0.09221987 0.03312556 0.03331343 0.03922442
  0.03696572 0.04297302 0.04173811 0.04907209 0.04447612 0.02796013
  0.0179338  0.04576432 0.04902789 0.06584006 0.06099723 0.03070844
  0.01371141 0.13271411 0.10601802 0.05982976 0.03059797 0.02952452
  0.05029494 0.04065109 0.01324184 0.07015006 0.018722   0.02678778
  0.02345509 0.12644856]
 [0.04738156 0.05736059 0.05463431 0.10777398 0.20283704 0.08092249
  0.0497967  0.05212395 0.0629871  0.11504429 0.0781085  0.07520419
  0.05440821 0.15598221 0.17837888 0.05455051 0.06496254 0.08378106
  0.05426336 0.05447973 0.06587901 0.04805189 0.06439418 0.03133293
  0.01529482 0.04980588 0.06913154 0.06274229 0.06899834 0.02780521
  0.00810581 0.13868354 0.08518919 0.08410735 0.03113704 0.02637873
  0.05081196 0.0513282  0.01562809 0.06452359 0.01187658 0.01631088
  0.01657632 0.10670486]
 [0.04764707 0.04211974 0.03945585 0.05724531 0.09516675 0.03988035
  0.03644992 0.03967259 0.04276205 0.06873357 0.05706487 0.05049961
  0.04055208 0.04844389 0.06933054 0.04548016 0.07622115 0.09462564
  0.07076475 0.06951219 0.09244048 0.04603164 0.05442257 0.04159559
  0.0284474  0.04488317 0.04516888 0.0728431  0.0464472  0.01588647
  0.01179143 0.12152087 0.0461982  0.05319599 0.03685573 0.03503155
  0.04461142 0.06125447 0.03113254 0.03682658 0.0118808  0.01871326
  0.02214695 0.07171798]
 [0.04758075 0.04813766 0.04411105 0.06557034 0.06365376 0.04776572
  0.04624709 0.0482666  0.05978945 0.0665863  0.05165221 0.04831268
  0.04495739 0.05553505 0.05972183 0.03923983 0.05281511 0.06119123
  0.05193457 0.0638995  0.05930963 0.06351074 0.06389539 0.03488433
  0.01993774 0.04955227 0.04009703 0.08620892 0.050259   0.01351888
  0.00763375 0.10190388 0.16518919 0.10096829 0.03168309 0.03148586
  0.05215547 0.04970454 0.02352868 0.06114669 0.00948497 0.01737046
  0.01840913 0.10303065]]

-* TASK 10/20 | SAMPLE 26/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 130/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 13 states that Fred moved to the office, but there is no mention of Fred being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.0292417  0.04273395 0.04389179 ... 0.01739411 0.0425919  0.04112753]
 [0.0299076  0.03132567 0.03123636 ... 0.02491323 0.03206063 0.02757341]
 [0.03051507 0.04361342 0.04631048 ... 0.01548977 0.03478851 0.02495304]
 ...
 [0.03051668 0.04351633 0.04164729 ... 0.01566211 0.04310424 0.0456005 ]
 [0.0311961  0.03347103 0.03061509 ... 0.02128034 0.04194295 0.05141908]
 [0.03093326 0.03768751 0.03326361 ... 0.01867803 0.03647352 0.05166212]]
Model's predictions for the sample 26:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 2 explicitly states  |
|          |                 |        that Mary is in the office.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 4 states that Julie  |
|          |                 |    moved to the school, but there is no    |
|          |                 |    mention of Julie being in the park.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 8 states that Mary   |
|          |                 |  moved to the office, which implies that   |
|          |                 |      Mary is currently in the office.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 10 explicitly     |
|          |                 |     states that Mary is in the school.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 13 states that Fred  |
|          |                 |    moved to the office, but there is no    |
|          |                 |   mention of Fred being in the kitchen.    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 26:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.16 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 27/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 131/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the park. In fact, sentence 2 explicitly states that Bill is in the office, which is a different location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' park', '.', ' In', ' fact', ',', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' office', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 26), x_tokens=26, y_tokens=41, max_supp_attn=0.0488, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 26)
DEBUG result.interpretability.attn_scores 1066 
 [[0.02260021 0.03681357 0.04158325 ... 0.01483726 0.00945423 0.01660371]
 [0.02303962 0.04187252 0.04317718 ... 0.01299136 0.00609899 0.01797905]
 [0.02350375 0.02576337 0.02599269 ... 0.00989464 0.00546404 0.01320079]
 ...
 [0.02391855 0.0271886  0.02550375 ... 0.00918853 0.00466094 0.01230622]
 [0.02384555 0.0207058  0.0200546  ... 0.01272302 0.00769389 0.01538981]
 [0.02397173 0.02613238 0.0235227  ... 0.01072498 0.00612558 0.01288243]]

-* TASK 10/20 | SAMPLE 27/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 132/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 5 explicitly states that Fred is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 32), x_tokens=32, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 32)
DEBUG result.interpretability.attn_scores 608 
 [[0.04989603 0.07456218 0.07528825 0.10266046 0.07934541 0.07746661
  0.06049325 0.06323545 0.07596349 0.0775545  0.05913337 0.05416185
  0.05481759 0.13979355 0.13574168 0.05595971 0.04282    0.03897739
  0.03295453 0.04142335 0.03631646 0.05652536 0.08650155 0.04107616
  0.02595637 0.06525806 0.07230773 0.06771211 0.15416011 0.02896665
  0.03840335 0.01560783]
 [0.05136731 0.06992535 0.06736656 0.11275762 0.09807688 0.11091735
  0.06424196 0.06452882 0.08054376 0.1009823  0.07779045 0.07972129
  0.07598121 0.19762833 0.1614106  0.06120164 0.0414567  0.04561719
  0.03496694 0.04315297 0.03699385 0.05796685 0.06554279 0.03290593
  0.02293978 0.05481002 0.07473667 0.0535998  0.13322073 0.03719408
  0.05014873 0.02006479]
 [0.05216963 0.06599449 0.07341649 0.09521841 0.07364937 0.0858481
  0.06480544 0.06861496 0.07373479 0.07999101 0.06029657 0.07564192
  0.07146138 0.12719423 0.08887126 0.05040902 0.03837764 0.0383558
  0.03172448 0.03856882 0.03284957 0.05354529 0.06458019 0.03891519
  0.02852561 0.05297298 0.06333933 0.04765537 0.11284919 0.06246327
  0.07145464 0.03552169]
 [0.05035231 0.07261551 0.07715376 0.05714591 0.04313537 0.06034483
  0.06355587 0.07252676 0.06450941 0.05380735 0.05054871 0.06253695
  0.06375881 0.03997711 0.03608415 0.06074282 0.0487484  0.04415733
  0.03991457 0.04684637 0.04147683 0.05877769 0.08805334 0.06919096
  0.05969134 0.07220468 0.07931429 0.05669698 0.07847203 0.13556854
  0.10745969 0.10225024]
 [0.05193202 0.06725162 0.07082307 0.04128658 0.02980387 0.04564201
  0.06184978 0.05945362 0.06236603 0.03970869 0.0423805  0.04504116
  0.04725721 0.02590704 0.02759197 0.06337587 0.05077801 0.04335589
  0.04797446 0.05264289 0.0444162  0.05228864 0.07508585 0.06778633
  0.05943955 0.05956023 0.07067286 0.03774003 0.03704447 0.07832721
  0.05298922 0.1350092 ]
 [0.053174   0.03157594 0.03281811 0.02035489 0.01695723 0.0256981
  0.03080359 0.02940189 0.03379568 0.02330952 0.02897934 0.02567106
  0.02773145 0.01216065 0.01554005 0.03737317 0.03548972 0.03074417
  0.03968957 0.04116102 0.03591682 0.03857622 0.03637978 0.04491707
  0.04646381 0.03910183 0.03907327 0.02499918 0.01828129 0.03111954
  0.02761425 0.06030064]
 [0.05225116 0.05576156 0.0563336  0.03377615 0.02506469 0.04771954
  0.05277409 0.05207383 0.04748528 0.03606278 0.0412489  0.04854859
  0.04665292 0.02093262 0.02200335 0.05562939 0.05365103 0.04296147
  0.05105931 0.05281482 0.04905205 0.05857925 0.06328289 0.07166719
  0.07793512 0.06181687 0.07221431 0.03686412 0.03688332 0.09174111
  0.05031863 0.11470984]
 [0.05330792 0.06589364 0.07071701 0.05385155 0.03639668 0.06220631
  0.06635762 0.07357287 0.06072438 0.06195371 0.06033964 0.08321631
  0.07478905 0.03453137 0.02769531 0.05371476 0.04778751 0.04870833
  0.04644518 0.04985653 0.04453409 0.0570997  0.05095437 0.05506326
  0.05997736 0.05247307 0.07020576 0.04380182 0.03943245 0.09229925
  0.07245665 0.14064784]
 [0.0541383  0.04782947 0.05267744 0.03651749 0.02918385 0.04576932
  0.05566976 0.0523306  0.04579926 0.04149467 0.04715965 0.05156126
  0.05450315 0.02309615 0.02120773 0.04964575 0.0448838  0.04275849
  0.04689174 0.04718726 0.04315234 0.05518056 0.040948   0.05060515
  0.05657208 0.04130829 0.04867226 0.03763788 0.03180809 0.06681791
  0.05885537 0.09607955]
 [0.0535569  0.0361471  0.03491448 0.02346788 0.02019892 0.03108579
  0.04167406 0.03750761 0.03401753 0.02809976 0.03917812 0.03516937
  0.04180224 0.01428728 0.01554628 0.04895321 0.05064124 0.04617462
  0.05683269 0.05191221 0.04982935 0.05389867 0.0317839  0.05514318
  0.06191345 0.03641955 0.03127262 0.03503081 0.02300508 0.04746665
  0.04494042 0.05227599]
 [0.05313051 0.0344162  0.0313415  0.02177313 0.01765663 0.02789909
  0.03905231 0.03466728 0.03167961 0.02562776 0.03607627 0.03035269
  0.03830779 0.01329494 0.01380252 0.05072381 0.05028704 0.05659867
  0.07575865 0.07063416 0.06503773 0.04829425 0.02880896 0.06643646
  0.08502679 0.041756   0.0255506  0.03858986 0.01911232 0.04810376
  0.04157713 0.03632353]
 [0.05394468 0.0340855  0.0330968  0.02156203 0.01927426 0.02910278
  0.04274623 0.03951106 0.03328373 0.02646161 0.04136091 0.03702851
  0.04303816 0.01367683 0.01377886 0.05162937 0.06032814 0.04994625
  0.08594402 0.06267378 0.06234314 0.04661355 0.02621159 0.05746696
  0.09758452 0.04982292 0.02823645 0.04345189 0.01828589 0.04640393
  0.05218761 0.03398908]
 [0.0540333  0.0311866  0.03019973 0.01865716 0.0170409  0.02603954
  0.04503929 0.03895314 0.03203115 0.02290442 0.05425657 0.03442654
  0.04600762 0.01176457 0.01207619 0.0552456  0.06368511 0.04957393
  0.07395183 0.05899519 0.05876634 0.04560116 0.02367092 0.06194579
  0.07590369 0.05154752 0.02524698 0.04423326 0.01642776 0.04015606
  0.0602473  0.02335452]
 [0.05249742 0.04577491 0.04675853 0.02703876 0.02241083 0.0424283
  0.06383239 0.05743432 0.06020219 0.03307628 0.04277397 0.04108858
  0.0526028  0.01616972 0.01585133 0.04911103 0.04788395 0.0466069
  0.05635986 0.06086116 0.05384176 0.05235699 0.0478923  0.06912436
  0.05709522 0.06132097 0.03911998 0.04466034 0.02895432 0.05151144
  0.0597659  0.03443433]
 [0.05465648 0.03764345 0.03915504 0.03011608 0.02196888 0.03672811
  0.04600973 0.04937932 0.03995617 0.03554532 0.04635834 0.04318891
  0.04713963 0.0189366  0.01679137 0.04092212 0.03904045 0.04004598
  0.04759756 0.04711908 0.04420639 0.04754865 0.02877438 0.04243491
  0.04168225 0.0425631  0.03582689 0.04612308 0.02990353 0.04481921
  0.07061381 0.03299669]
 [0.05281237 0.05021707 0.05260257 0.07132535 0.05971501 0.06319974
  0.05018887 0.05159832 0.06388824 0.07591636 0.05804772 0.06294351
  0.05959991 0.08657259 0.10307034 0.04552585 0.04253156 0.04975378
  0.03979465 0.04453874 0.04380275 0.05068366 0.05229317 0.03680751
  0.02945454 0.05324402 0.0538104  0.0703659  0.06815887 0.03194536
  0.05638627 0.02022201]
 [0.05224655 0.06671452 0.05874193 0.10000832 0.20556131 0.08207113
  0.05447758 0.05515825 0.06048546 0.10157073 0.08497065 0.08087894
  0.05742613 0.11450689 0.15397301 0.06487652 0.07018952 0.08646987
  0.05318593 0.05424653 0.06626063 0.05057338 0.06706415 0.03855701
  0.02653085 0.05191895 0.07202747 0.07191993 0.06448174 0.01842104
  0.02468771 0.01326333]
 [0.05210821 0.05436137 0.04703306 0.06436497 0.11198978 0.04540281
  0.04312189 0.04763263 0.04444088 0.06695389 0.06765772 0.05563924
  0.04581895 0.04035616 0.06331254 0.0585755  0.10347779 0.11649673
  0.07820049 0.07110102 0.11315762 0.04836804 0.05693468 0.05620295
  0.05372661 0.06060021 0.05465119 0.09381975 0.04086125 0.02555763
  0.03001365 0.0196994 ]
 [0.05242486 0.05804362 0.04956201 0.06811722 0.07257023 0.05443052
  0.05330627 0.05241936 0.0550929  0.06897939 0.06144253 0.05318335
  0.051304   0.04921331 0.05565147 0.04638485 0.06794248 0.08269719
  0.06075357 0.06426408 0.07804607 0.06752217 0.06523714 0.04375369
  0.03358097 0.05130057 0.04372095 0.10509786 0.0486575  0.02111734
  0.02987968 0.01324949]]

-* TASK 10/20 | SAMPLE 27/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 133/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 states that Fred journeyed to the office, which implies that Fred is in the office, not in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' office', ',', ' not', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.02815259 0.04163479 0.04215299 ... 0.06150072 0.03101198 0.01984589]
 [0.02862113 0.0346388  0.03640068 ... 0.03887384 0.03334133 0.02839496]
 [0.02929657 0.04485304 0.04838076 ... 0.04516305 0.02672643 0.01694004]
 ...
 [0.02954787 0.0385871  0.04112982 ... 0.05034649 0.02657265 0.01370759]
 [0.0301245  0.0296879  0.03078229 ... 0.03539635 0.02585349 0.0192204 ]
 [0.03008836 0.03027927 0.0329189  ... 0.04743636 0.02542833 0.01701043]]

-* TASK 10/20 | SAMPLE 27/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 134/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 states that Fred moved to the bedroom, which contradicts sentence 11's claim that Fred is either in the cinema or the office. Therefore, sentence 11 is outdated, and we should rely on sentence 10. Sentence 10 does not mention the cinema, so we cannot conclude that Fred is in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' bedroom', ',', ' which', ' contrad', 'icts', ' sentence', ' ', '11', "'s", ' claim', ' that', ' Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' office', '.', ' Therefore', ',', ' sentence', ' ', '11', ' is', ' outdated', ',', ' and', ' we', ' should', ' rely', ' on', ' sentence', ' ', '10', '.', ' Sentence', ' ', '10', ' does', ' not', ' mention', ' the', ' cinema', ',', ' so', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(74, 44), x_tokens=44, y_tokens=74, max_supp_attn=0.027, attn_on_target=0.0135)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (74, 44)
DEBUG result.interpretability.attn_scores 3256 
 [[0.01217198 0.01709935 0.01823972 ... 0.05734509 0.0057989  0.03278141]
 [0.0124886  0.01336509 0.0146036  ... 0.03654226 0.01064099 0.01464749]
 [0.0127439  0.01855889 0.02124941 ... 0.04908896 0.01014089 0.03452273]
 ...
 [0.01295266 0.02058755 0.01948008 ... 0.021585   0.00456634 0.05833685]
 [0.01342912 0.01683205 0.01438785 ... 0.0091057  0.0045857  0.02597887]
 [0.01330828 0.01809598 0.01544912 ... 0.01281899 0.00466382 0.0383422 ]]

-* TASK 10/20 | SAMPLE 27/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 135/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred in the context sentences. Sentence 13 talks about Mary, and sentence 14 talks about Bill, but neither mentions Fred or the cinema.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '13', ' talks', ' about', ' Mary', ',', ' and', ' sentence', ' ', '14', ' talks', ' about', ' Bill', ',', ' but', ' neither', ' mentions', ' Fred', ' or', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 50), x_tokens=50, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 50)
DEBUG result.interpretability.attn_scores 2100 
 [[0.02189729 0.02919233 0.02825829 ... 0.01958825 0.02726369 0.05094541]
 [0.02237017 0.03352866 0.0286483  ... 0.02573431 0.02607161 0.02651764]
 [0.02299271 0.0291938  0.02844511 ... 0.01544842 0.02190482 0.02974449]
 ...
 [0.02340823 0.02657467 0.02257036 ... 0.02127318 0.03744819 0.02770438]
 [0.0237707  0.02911448 0.02725462 ... 0.01567374 0.03186456 0.02595537]
 [0.02384966 0.02612077 0.02474816 ... 0.0153583  0.02661367 0.03368413]]
Model's predictions for the sample 27:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |      Bill being in the park. In fact,      |
|          |                 |   sentence 2 explicitly states that Bill   |
|          |                 |   is in the office, which is a different   |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 5 explicitly states that Fred   |
|          |                 |             is in the school.              |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  Sentence 7 states that Fred journeyed to  |
|          |                 |   the office, which implies that Fred is   |
|          |                 |     in the office, not in the kitchen.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |        no       |   Sentence 10 states that Fred moved to    |
|          |                 |  the bedroom, which contradicts sentence   |
|          |                 |   11's claim that Fred is either in the    |
|          |                 |      cinema or the office. Therefore,      |
|          |                 |   sentence 11 is outdated, and we should   |
|          |                 |   rely on sentence 10. Sentence 10 does    |
|          |                 |    not mention the cinema, so we cannot    |
|          |                 |    conclude that Fred is in the cinema.    |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     There is no mention of Fred in the     |
|          |                 |    context sentences. Sentence 13 talks    |
|          |                 |  about Mary, and sentence 14 talks about   |
|          |                 |   Bill, but neither mentions Fred or the   |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 27:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.05 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 28/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 136/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred being in the park. Sentence 1 states that Fred moved to the school, and sentence 2 contradicts sentence 1, stating that Fred is in the bedroom. There is no information about Fred being in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' park', '.', ' Sentence', ' ', '1', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' school', ',', ' and', ' sentence', ' ', '2', ' contrad', 'icts', ' sentence', ' ', '1', ',', ' stating', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' about', ' Fred', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 26), x_tokens=26, y_tokens=59, max_supp_attn=0.1186, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 26)
DEBUG result.interpretability.attn_scores 1534 
 [[0.01563879 0.03226658 0.03401697 ... 0.00914974 0.00496043 0.01503734]
 [0.01613237 0.02030644 0.02019073 ... 0.006284   0.00408946 0.0099183 ]
 [0.01640818 0.02290396 0.02563577 ... 0.00814329 0.00546167 0.01025046]
 ...
 [0.01648461 0.02016078 0.02027483 ... 0.00569973 0.00296231 0.00935399]
 [0.01647983 0.01481007 0.01534624 ... 0.00816675 0.00541926 0.0120272 ]
 [0.01658466 0.0178229  0.01725965 ... 0.00662277 0.00416252 0.00922803]]

-* TASK 10/20 | SAMPLE 28/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 137/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred at all. They only talk about Bill and Julie. There is no information about Fred's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Bill', ' and', ' Julie', '.', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 32), x_tokens=32, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 32)
DEBUG result.interpretability.attn_scores 1120 
 [[0.02651935 0.03613055 0.04120679 ... 0.0125323  0.01153973 0.01782519]
 [0.0273969  0.03266107 0.03652843 ... 0.01623154 0.01641328 0.02162851]
 [0.02798845 0.03135705 0.03727852 ... 0.02052913 0.01963703 0.02350217]
 ...
 [0.02818913 0.03473398 0.02841872 ... 0.01303158 0.01260491 0.01493152]
 [0.02861307 0.03573543 0.03197606 ... 0.01448966 0.01148594 0.0142451 ]
 [0.02868863 0.03252343 0.03023802 ... 0.01545894 0.01113323 0.01469993]]

-* TASK 10/20 | SAMPLE 28/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 138/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred at all. They only talk about Bill and Julie. There is no information about Fred's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Bill', ' and', ' Julie', '.', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 38), x_tokens=38, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 38)
DEBUG result.interpretability.attn_scores 1330 
 [[0.02685302 0.03348126 0.0393152  ... 0.03230935 0.04705754 0.05356725]
 [0.027134   0.0257974  0.03115331 ... 0.02605959 0.03550299 0.05166942]
 [0.02804326 0.03814418 0.04746072 ... 0.04523654 0.04509232 0.04037956]
 ...
 [0.02841037 0.02849165 0.02713487 ... 0.01835547 0.04903596 0.03297473]
 [0.02817012 0.040596   0.03781201 ... 0.02021891 0.05296538 0.04152157]
 [0.02853642 0.0309469  0.0297409  ... 0.02105766 0.07771657 0.05621979]]

-* TASK 10/20 | SAMPLE 28/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 139/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the cinema. Sentence 10 states that Bill went back to the school, and there is no information about Bill being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 44), x_tokens=44, y_tokens=43, max_supp_attn=0.0465, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 44)
DEBUG result.interpretability.attn_scores 1892 
 [[0.02153117 0.0303729  0.03193055 ... 0.02313584 0.02587772 0.04633608]
 [0.02186562 0.03135486 0.02920957 ... 0.02353418 0.02334745 0.03120482]
 [0.0225172  0.03359123 0.03576654 ... 0.01737433 0.02091959 0.03396904]
 ...
 [0.02272351 0.03113357 0.03068239 ... 0.01962895 0.0317449  0.03575274]
 [0.02317447 0.02584898 0.02550671 ... 0.01915512 0.03459815 0.02441019]
 [0.0230483  0.02629294 0.02517387 ... 0.01979297 0.02935801 0.03740216]]

-* TASK 10/20 | SAMPLE 28/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 140/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 is redundant and does not provide any new information. Sentence 13 mentions Bill's possible locations, but does not provide information about Julie's location. We can refer back to sentence 8, which states that Julie is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' is', ' redundant', ' and', ' does', ' not', ' provide', ' any', ' new', ' information', '.', ' Sentence', ' ', '13', ' mentions', ' Bill', "'s", ' possible', ' locations', ',', ' but', ' does', ' not', ' provide', ' information', ' about', ' Julie', "'s", ' location', '.', ' We', ' can', ' refer', ' back', ' to', ' sentence', ' ', '8', ',', ' which', ' states', ' that', ' Julie', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 50), x_tokens=50, y_tokens=57, max_supp_attn=0.0175, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 50)
DEBUG result.interpretability.attn_scores 2850 
 [[0.0160465  0.02289017 0.02118204 ... 0.00897832 0.02517824 0.02899305]
 [0.01638828 0.02519655 0.02249286 ... 0.0119343  0.01372142 0.01938787]
 [0.01681776 0.02634786 0.02451907 ... 0.01203137 0.02501926 0.01905257]
 ...
 [0.01710155 0.02249558 0.02029423 ... 0.00596191 0.05007397 0.02093983]
 [0.01738697 0.01620581 0.01435161 ... 0.00755458 0.04851162 0.01813052]
 [0.0173003  0.02208101 0.01894164 ... 0.00638161 0.05818193 0.02525428]]
Model's predictions for the sample 28:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |     Fred being in the park. Sentence 1     |
|          |                 |   states that Fred moved to the school,    |
|          |                 |   and sentence 2 contradicts sentence 1,   |
|          |                 |    stating that Fred is in the bedroom.    |
|          |                 |  There is no information about Fred being  |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |    The context sentences do not mention    |
|          |                 |   Fred at all. They only talk about Bill   |
|          |                 |  and Julie. There is no information about  |
|          |                 |              Fred's location.              |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    The context sentences do not mention    |
|          |                 |   Fred at all. They only talk about Bill   |
|          |                 |  and Julie. There is no information about  |
|          |                 |              Fred's location.              |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |   Bill being in the cinema. Sentence 10    |
|          |                 |     states that Bill went back to the      |
|          |                 |    school, and there is no information     |
|          |                 |      about Bill being in the cinema.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 14 is redundant and does not    |
|          |                 |  provide any new information. Sentence 13  |
|          |                 |  mentions Bill's possible locations, but   |
|          |                 |     does not provide information about     |
|          |                 |   Julie's location. We can refer back to   |
|          |                 |   sentence 8, which states that Julie is   |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+

Metrics for sample 28:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.05 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 29/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 141/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 1, Mary journeyed to the park, which implies that Mary is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '1', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Mary', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 26), x_tokens=26, y_tokens=29, max_supp_attn=0.069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 26)
DEBUG result.interpretability.attn_scores 754 
 [[0.03234705 0.05786577 0.06205583 0.09276655 0.08164956 0.06644517
  0.04754535 0.04131693 0.04558104 0.06210388 0.04477445 0.03358257
  0.03429331 0.13438076 0.13496086 0.04147076 0.03412157 0.02502993
  0.02666513 0.02836237 0.02645327 0.04958967 0.07995711 0.01018481
  0.00701432 0.03406745]
 [0.03344293 0.03608942 0.03680699 0.06720866 0.058624   0.0560616
  0.03362834 0.03033262 0.03680822 0.05410068 0.03854327 0.03591822
  0.03427688 0.14162226 0.16058283 0.03923949 0.03642668 0.02873537
  0.02924795 0.02942443 0.02493205 0.04119513 0.04670582 0.00822585
  0.00651145 0.02246561]
 [0.03395848 0.04071557 0.04740537 0.07117349 0.06366614 0.07094189
  0.0447358  0.04226642 0.04778045 0.06380078 0.04510373 0.0575527
  0.05355908 0.11160015 0.09812706 0.03284731 0.0330047  0.02897437
  0.02812472 0.02901798 0.02329369 0.03715596 0.04272177 0.01192026
  0.00889732 0.02370998]
 [0.03268529 0.0529246  0.05993249 0.05329228 0.05445986 0.06299651
  0.05031047 0.05302114 0.04929166 0.05369138 0.04390622 0.05998741
  0.05414381 0.06669885 0.05597537 0.04267639 0.04147337 0.03623844
  0.03430676 0.03642198 0.03223885 0.04227003 0.06193734 0.0349258
  0.02211389 0.04819694]
 [0.03406103 0.05586382 0.06322347 0.06357586 0.05600977 0.07595173
  0.06054828 0.06322035 0.06127135 0.06425576 0.04671172 0.06490122
  0.06277773 0.049935   0.03155833 0.03159112 0.03303076 0.0316025
  0.03100972 0.03359047 0.02706062 0.04259525 0.04575412 0.01792783
  0.01571131 0.03420794]
 [0.03335267 0.06797368 0.07016814 0.03778259 0.02954844 0.04696142
  0.05734261 0.0538601  0.0538643  0.03760944 0.03565211 0.04578205
  0.04699565 0.022361   0.01915651 0.05183636 0.04184452 0.03577386
  0.03644212 0.03903862 0.0363511  0.04075344 0.08123863 0.04401317
  0.03337339 0.04378573]
 [0.03413714 0.05368006 0.06125906 0.03235973 0.02634135 0.03639225
  0.06048861 0.0453728  0.05153541 0.03097641 0.02971625 0.03362324
  0.03351824 0.01774832 0.01733256 0.04931386 0.03888848 0.03219553
  0.03687188 0.04019259 0.03582171 0.03641489 0.06951895 0.04400941
  0.02508892 0.03850784]
 [0.03450547 0.02020902 0.02310002 0.01499147 0.0127592  0.01821735
  0.02201052 0.02104605 0.02704567 0.01702525 0.0162247  0.0172545
  0.01728428 0.00810762 0.00873552 0.02251349 0.0225145  0.02078607
  0.0268617  0.02912995 0.02998555 0.02526175 0.04983407 0.06565598
  0.03517086 0.05684861]
 [0.0342486  0.03338354 0.03473969 0.02122943 0.01858899 0.02626947
  0.03451069 0.03019657 0.03032527 0.02229514 0.02675127 0.02658894
  0.0270452  0.01179819 0.01243918 0.04396147 0.03077058 0.0287479
  0.02857768 0.03044636 0.03138811 0.03342827 0.04026043 0.06294812
  0.04869958 0.04286501]
 [0.03440496 0.03264071 0.03228826 0.02370283 0.02004432 0.02905582
  0.03555047 0.03561149 0.03128131 0.0265374  0.03184548 0.03470344
  0.03586125 0.01307398 0.01168969 0.04326317 0.03372739 0.03319809
  0.03006474 0.03179578 0.0352851  0.03456878 0.02966245 0.05746328
  0.03674761 0.03029059]
 [0.03377771 0.02698879 0.02241941 0.01796553 0.01416654 0.01853759
  0.02754457 0.02721773 0.02382814 0.01891187 0.02646629 0.02246774
  0.02747244 0.00851092 0.00858931 0.04611532 0.03321426 0.04415327
  0.03695551 0.04300403 0.05204173 0.03165844 0.02358757 0.0996821
  0.05615161 0.03063099]
 [0.03487728 0.02750216 0.02573178 0.02170373 0.01858194 0.02635924
  0.03242352 0.03408097 0.0271716  0.0234106  0.02956563 0.02961737
  0.03173532 0.01085907 0.00976516 0.0428717  0.02537993 0.04510704
  0.03101765 0.04553848 0.03771221 0.02729118 0.02266929 0.06502394
  0.0372616  0.03114322]
 [0.03498412 0.02228778 0.01944938 0.0157363  0.01280437 0.01778551
  0.02329151 0.02303006 0.02179369 0.01726943 0.027525   0.02250471
  0.02452281 0.0077256  0.00771522 0.04355613 0.02641977 0.04456235
  0.03296377 0.0444104  0.04401881 0.02538375 0.01815926 0.06810941
  0.04828484 0.02632568]
 [0.03482179 0.02151383 0.01881461 0.01400774 0.0115636  0.0164912
  0.02335245 0.02265168 0.02189124 0.01605911 0.03116773 0.02149918
  0.02346839 0.00714157 0.00759515 0.0360265  0.02947512 0.04083006
  0.03622053 0.04121452 0.04093415 0.02690854 0.01866925 0.06100675
  0.06400653 0.03655133]
 [0.03387821 0.02653376 0.02333538 0.01868401 0.01686829 0.0230889
  0.03084798 0.02879643 0.02881761 0.02061229 0.02660952 0.02379711
  0.02733277 0.01018928 0.00973474 0.02463873 0.03246514 0.0301564
  0.04615197 0.03845743 0.03815603 0.0298923  0.02712265 0.0405941
  0.09979282 0.08793239]
 [0.03535212 0.02780357 0.02577254 0.02045122 0.01642929 0.02293969
  0.02834186 0.02888004 0.02775516 0.02193679 0.03224711 0.02741555
  0.02785724 0.01074213 0.00986095 0.02694512 0.02565367 0.02778383
  0.03421886 0.03252776 0.03288309 0.03258241 0.01944223 0.03080495
  0.04105945 0.03441326]
 [0.03555294 0.02886142 0.03100652 0.02750428 0.02164505 0.03041441
  0.03147896 0.0377032  0.03147287 0.03056887 0.03369416 0.04140281
  0.03811935 0.01557877 0.0109717  0.02359027 0.02576128 0.02897123
  0.02836951 0.02700842 0.0263137  0.03361897 0.01887703 0.01862333
  0.02819282 0.02743443]
 [0.03575733 0.03575884 0.03622012 0.03494731 0.0247251  0.03660089
  0.04059574 0.04799736 0.03398091 0.03790455 0.04535918 0.05035426
  0.04862111 0.01849678 0.01238261 0.0271384  0.02602483 0.03171081
  0.02800996 0.02798505 0.02657991 0.03457965 0.02012804 0.01664237
  0.02460086 0.02096999]
 [0.03563454 0.03269321 0.0319286  0.03050468 0.02288582 0.03327717
  0.03715393 0.04179876 0.0341778  0.03466884 0.04142408 0.04441497
  0.04577417 0.01649238 0.01240796 0.03236194 0.02890083 0.03482322
  0.03099751 0.03031756 0.02964289 0.03436803 0.01778657 0.02017893
  0.02305817 0.01830619]
 [0.03539733 0.02512686 0.02310205 0.01878414 0.01382917 0.02065191
  0.02679806 0.02869865 0.02678316 0.02151695 0.02899124 0.02709023
  0.03104515 0.00985049 0.0088249  0.0353932  0.03137848 0.03433895
  0.03287403 0.03144111 0.03651995 0.03244154 0.01558895 0.03220726
  0.03640693 0.02195824]
 [0.03539385 0.02666891 0.02351674 0.01956586 0.0137346  0.01980036
  0.03032746 0.03001518 0.02705454 0.02127454 0.03023453 0.02543332
  0.0315395  0.00948335 0.00863146 0.03800439 0.03446479 0.03908454
  0.03649218 0.03528031 0.04064626 0.02919942 0.01499032 0.03445585
  0.03920496 0.02193609]
 [0.03548875 0.02555272 0.02225944 0.0191425  0.01493161 0.01973728
  0.02579891 0.02765138 0.02647986 0.02229514 0.03073361 0.02723884
  0.02915678 0.0100936  0.00882357 0.03375738 0.03580443 0.03580742
  0.03812575 0.03374191 0.03879836 0.02925847 0.01523951 0.02756808
  0.04282951 0.02332148]
 [0.03578962 0.02191636 0.01992417 0.01429583 0.01188685 0.01611274
  0.02359748 0.0234552  0.02513005 0.01708849 0.03167124 0.02203521
  0.02513355 0.00804171 0.00706259 0.03064869 0.03495262 0.03212437
  0.03944799 0.03488423 0.03781223 0.0274099  0.01487263 0.03175616
  0.04381452 0.02407631]
 [0.03442103 0.0233359  0.02073011 0.01431691 0.01186568 0.01735125
  0.02555007 0.02693713 0.02740219 0.01787722 0.02466633 0.02098976
  0.02590725 0.00833656 0.00730566 0.02136044 0.03111871 0.02649259
  0.04512885 0.03615145 0.03767722 0.02748372 0.02025444 0.03273061
  0.09966841 0.08175757]
 [0.03558126 0.0269499  0.026283   0.02144199 0.01617803 0.02321141
  0.02588016 0.03007895 0.0325034  0.02474564 0.02846558 0.02844696
  0.02785587 0.01278551 0.01034655 0.02250771 0.02822874 0.02650781
  0.03501428 0.03176924 0.03259824 0.03063193 0.01885886 0.02044407
  0.03318083 0.03138096]
 [0.03424573 0.03522602 0.03512279 0.05258082 0.05388112 0.04723313
  0.03190172 0.03279704 0.03870432 0.05367031 0.03880757 0.03999432
  0.03797694 0.08667625 0.10460852 0.02764775 0.03548652 0.03107616
  0.0310085  0.02952992 0.02678414 0.03861657 0.03972864 0.00898841
  0.00829225 0.02740849]
 [0.03408225 0.03828679 0.03587574 0.06159433 0.11409455 0.04866573
  0.02999356 0.03058629 0.03785649 0.06323516 0.04664823 0.03920616
  0.03118072 0.09131586 0.11268688 0.03414337 0.04783477 0.03996625
  0.0367156  0.03223005 0.03187186 0.03591825 0.03975407 0.00770249
  0.0066418  0.02194257]
 [0.03380623 0.03412636 0.03126429 0.04995108 0.10367715 0.0332141
  0.02481245 0.02919182 0.03258322 0.05522492 0.04506386 0.04157434
  0.03112184 0.03999875 0.048714   0.02934684 0.07291868 0.06336389
  0.0515453  0.03922437 0.04963858 0.03195331 0.03407076 0.01510059
  0.01675779 0.03058884]
 [0.03401427 0.04152062 0.03626393 0.04873898 0.06455966 0.03923438
  0.0336385  0.03218767 0.03982886 0.04933319 0.04142999 0.03462286
  0.0344234  0.04035527 0.04341505 0.02523273 0.0487149  0.04185768
  0.04057    0.0378633  0.03656064 0.05757041 0.05260925 0.01110602
  0.01146576 0.02697624]]

-* TASK 10/20 | SAMPLE 29/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 142/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 5, Fred went back to the bedroom, which implies that Fred is in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '5', ',', ' Fred', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.2069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03243139 0.0522108  0.05264828 0.07262766 0.06448617 0.05591552
  0.03723367 0.04516688 0.05836235 0.05604567 0.03834561 0.03889356
  0.03832206 0.11059771 0.10834291 0.03850943 0.03141055 0.02483566
  0.02605995 0.02648648 0.02167199 0.03808772 0.06218898 0.02179001
  0.01122371 0.03852633 0.05037905 0.0455441  0.09892806 0.01377775
  0.00844232 0.04664703]
 [0.03329207 0.05233674 0.05041487 0.08760753 0.08947366 0.08581281
  0.04255917 0.0478373  0.059037   0.07838729 0.05550238 0.06337003
  0.05748308 0.15756059 0.12772241 0.04264094 0.03286774 0.03067923
  0.02840097 0.02789883 0.02325142 0.04091216 0.04937769 0.01958874
  0.01275686 0.03197635 0.04915579 0.03842785 0.09263571 0.01585146
  0.0128072  0.05151595]
 [0.03391051 0.04615044 0.05118438 0.07171722 0.06440558 0.06367078
  0.03818186 0.04427117 0.05423166 0.06042894 0.04005216 0.05290856
  0.04695509 0.11414003 0.08091952 0.03535881 0.03063066 0.02541073
  0.02509834 0.02410392 0.01997668 0.03697989 0.04423087 0.02129714
  0.01439032 0.02951514 0.04538943 0.03175498 0.08351646 0.02671417
  0.01793339 0.04579386]
 [0.03263904 0.04289608 0.04605383 0.04003258 0.03400043 0.03872508
  0.03447377 0.04182259 0.0400358  0.03577053 0.03114909 0.03875292
  0.0369439  0.02960802 0.02818256 0.03623967 0.03404416 0.02784995
  0.02894225 0.02868645 0.02489193 0.03906143 0.05074225 0.0377541
  0.03077449 0.04298504 0.05192422 0.03521291 0.07283068 0.07431312
  0.03095482 0.03111993]
 [0.03414227 0.03127241 0.0358142  0.02916755 0.02175486 0.03047907
  0.02743787 0.02996476 0.03359002 0.02678692 0.02488636 0.02734479
  0.02601986 0.01861971 0.01894203 0.0261052  0.02422848 0.02144667
  0.02635765 0.02660015 0.02307847 0.03323789 0.03575419 0.02820968
  0.02725988 0.03938138 0.04651612 0.02923723 0.05285013 0.06350657
  0.02725893 0.02500204]
 [0.03363187 0.0478028  0.05154308 0.03095942 0.02335927 0.03409212
  0.03693974 0.03849293 0.04555838 0.02866736 0.02495613 0.03097667
  0.03072087 0.0215202  0.0200704  0.03707264 0.03075824 0.02383847
  0.02675515 0.02679884 0.02211608 0.03870896 0.05856347 0.03771288
  0.03013547 0.0396219  0.05514333 0.02717621 0.04665301 0.10759591
  0.02781721 0.02155914]
 [0.03403956 0.0350171  0.03694086 0.02344829 0.01873101 0.02435111
  0.02967966 0.02685276 0.03588853 0.02181227 0.02139633 0.02113719
  0.02141652 0.01442502 0.01619756 0.03362922 0.03102587 0.02421317
  0.03089677 0.03110302 0.0255769  0.03193121 0.0497112  0.04052981
  0.02877322 0.04330912 0.03982037 0.02344029 0.02250402 0.08104374
  0.01512398 0.01496405]
 [0.03461679 0.02047324 0.02054518 0.01523871 0.01284815 0.01676086
  0.01741291 0.01639502 0.021063   0.01695058 0.01849126 0.01606879
  0.01676523 0.00929284 0.01133507 0.02232288 0.02320726 0.02180267
  0.02805506 0.0290024  0.02683326 0.02612898 0.02753843 0.03236404
  0.02634965 0.03328594 0.01942732 0.0216598  0.01524541 0.0344767
  0.01312312 0.0125845 ]
 [0.03444109 0.02654368 0.02971487 0.02104053 0.01737202 0.02373803
  0.02409677 0.02315268 0.02717974 0.02120539 0.02197055 0.02152699
  0.02140231 0.01388412 0.01552141 0.03130308 0.03090487 0.02486705
  0.03080458 0.03054721 0.02693601 0.03317967 0.03642121 0.03899155
  0.0301912  0.03282223 0.03006648 0.0222692  0.02749495 0.05979002
  0.02305382 0.01545902]
 [0.03432698 0.0319038  0.03358692 0.02550124 0.02172921 0.02866259
  0.03115592 0.03066585 0.03089382 0.02745803 0.02760898 0.03194504
  0.03300478 0.01721405 0.01700752 0.03703567 0.03634108 0.03516092
  0.03662415 0.0360373  0.03180103 0.03860109 0.03248114 0.04024391
  0.04134184 0.03561059 0.03112878 0.02564444 0.02707671 0.05404776
  0.03871588 0.01873496]
 [0.03415689 0.02782997 0.02583975 0.02008547 0.01634087 0.02294999
  0.02593504 0.02407352 0.02408113 0.02169931 0.02452859 0.02349583
  0.02617792 0.01238928 0.01419532 0.03758067 0.03247123 0.04344972
  0.04633077 0.05946548 0.04849497 0.03347495 0.02471778 0.04954365
  0.05646902 0.03341027 0.02827987 0.02468453 0.01635544 0.03897059
  0.02778403 0.01358866]
 [0.03483371 0.02669313 0.02743701 0.02025729 0.01880976 0.0256299
  0.0273565  0.0269281  0.02700457 0.02483338 0.03047292 0.03023104
  0.02874421 0.01368582 0.01455306 0.03708416 0.03316958 0.03860268
  0.03732612 0.05461623 0.055863   0.03046389 0.02370882 0.04485695
  0.04848375 0.03510612 0.03006648 0.02686197 0.01619393 0.03949812
  0.03344182 0.0191127 ]
 [0.03565558 0.02134141 0.02145725 0.01506912 0.01476209 0.02025727
  0.0217022  0.02024787 0.02207378 0.01914775 0.0290812  0.02449252
  0.0230149  0.01069967 0.01164638 0.03315211 0.03389357 0.03253202
  0.03491152 0.03820057 0.0510562  0.02748973 0.01806016 0.03944409
  0.04404281 0.03003796 0.02148755 0.02262924 0.01292686 0.02656101
  0.02387898 0.0147136 ]
 [0.03514226 0.02190899 0.02261917 0.01454026 0.01528774 0.01990734
  0.02537874 0.02216697 0.02284074 0.01859624 0.04157268 0.02529761
  0.02490987 0.01053893 0.01252898 0.03714054 0.04556033 0.03574869
  0.04310764 0.04316438 0.04891395 0.03004825 0.02151311 0.04546383
  0.05744241 0.04100996 0.02234061 0.02472397 0.01392626 0.02694696
  0.02290668 0.01625891]
 [0.03351192 0.09124799 0.06269631 0.03687282 0.03598214 0.04316742
  0.14814587 0.08145609 0.05481635 0.04022911 0.08585366 0.05366646
  0.09300265 0.02038793 0.02181539 0.0818724  0.0703655  0.08824661
  0.05984578 0.07353885 0.06461011 0.04364379 0.05838252 0.0989575
  0.09808207 0.06189813 0.04017448 0.04542132 0.02185424 0.0354882
  0.01968396 0.02047742]
 [0.03511782 0.02565368 0.0289377  0.02167204 0.02020356 0.02591013
  0.02780652 0.02959852 0.02704008 0.02625092 0.03032265 0.03256325
  0.03030884 0.01658397 0.0153013  0.03070351 0.03352007 0.02981562
  0.03497833 0.03194435 0.03323491 0.0340021  0.02507864 0.0308477
  0.0348179  0.03205789 0.03016305 0.03132369 0.02643347 0.02805784
  0.08474274 0.03456047]
 [0.03501766 0.02606678 0.03091971 0.02615952 0.0230296  0.02961706
  0.02689984 0.03212663 0.03037541 0.03130531 0.02795065 0.03654907
  0.03218783 0.02022601 0.01595998 0.02340077 0.02279825 0.02388589
  0.02504167 0.02349441 0.02293462 0.03465297 0.02495344 0.02776065
  0.02591373 0.03521312 0.0346698  0.03295979 0.03552097 0.02975275
  0.10703055 0.03317679]
 [0.03522215 0.03302553 0.03765672 0.03445167 0.02859194 0.03820162
  0.03508819 0.04183305 0.03286803 0.04020696 0.03644764 0.04965139
  0.0470208  0.0261455  0.01817248 0.02647743 0.02456122 0.02756008
  0.02686341 0.02455323 0.02407225 0.03467142 0.02695031 0.02757385
  0.02708031 0.02926953 0.04072173 0.02708588 0.03247935 0.03024761
  0.12341534 0.03260485]
 [0.03516845 0.03449654 0.03801081 0.03832327 0.03646567 0.0419754
  0.03875476 0.04883766 0.03793849 0.04740093 0.03887153 0.05456406
  0.05166498 0.03330287 0.02468384 0.02896725 0.02849616 0.02980493
  0.02906488 0.02540082 0.02291293 0.03415285 0.02369725 0.02391762
  0.02491433 0.02618156 0.0335753  0.03224479 0.03276036 0.02862281
  0.09310102 0.04525093]
 [0.03513783 0.02715828 0.0266813  0.02278777 0.01888669 0.02620031
  0.03082214 0.03514445 0.02748748 0.02628192 0.02966436 0.03238109
  0.03570604 0.01539889 0.01394627 0.0315377  0.03132244 0.03244519
  0.03433641 0.03005316 0.03159325 0.03649641 0.02022115 0.03313054
  0.0408118  0.02860506 0.02304882 0.03740879 0.02063732 0.02799726
  0.05734532 0.02801096]
 [0.03508882 0.02678045 0.02509171 0.02244859 0.01630973 0.02361143
  0.02705759 0.02919251 0.02498775 0.02319437 0.02719576 0.0252995
  0.02879038 0.01351217 0.01378679 0.03372379 0.0307076  0.03717201
  0.04165803 0.03969974 0.04337308 0.02975427 0.01992551 0.03942128
  0.04078579 0.02953349 0.02061839 0.04367773 0.01536818 0.02723558
  0.04647982 0.02497007]
 [0.03542768 0.02622462 0.02518368 0.02187734 0.01780792 0.02422167
  0.02804564 0.03067841 0.02549432 0.02467391 0.03301128 0.03086341
  0.03074929 0.0140918  0.01385834 0.03310482 0.0377141  0.03532322
  0.03941596 0.03250194 0.04169033 0.03011844 0.02070616 0.0363737
  0.05607025 0.02946928 0.02430427 0.04329606 0.01683624 0.02551208
  0.04153756 0.04223136]
 [0.03575766 0.0211718  0.02147871 0.01698149 0.01349651 0.0202274
  0.02597821 0.02592146 0.02255431 0.01822857 0.03435649 0.02367988
  0.02635196 0.01115024 0.01128864 0.03114122 0.0380179  0.03112539
  0.03828604 0.03290471 0.04036034 0.02909872 0.01777294 0.03795318
  0.05879971 0.03099594 0.02077935 0.03687827 0.01372787 0.02463059
  0.02438244 0.03642431]
 [0.03468863 0.02787363 0.02979611 0.02270744 0.01607713 0.02986741
  0.03854055 0.03945772 0.03572993 0.02469163 0.03156411 0.02534008
  0.03068713 0.01478759 0.01443127 0.03172017 0.03258367 0.02918711
  0.03458675 0.03390624 0.03650508 0.03441539 0.02463782 0.03800054
  0.04008733 0.03570333 0.03022743 0.03731719 0.01810264 0.02445974
  0.01727269 0.02377409]
 [0.03554022 0.02537493 0.02777271 0.0286253  0.020764   0.03052317
  0.03048338 0.0360318  0.03081807 0.03015799 0.03106144 0.03197713
  0.0312803  0.02190271 0.01943357 0.02620159 0.02914783 0.02972278
  0.03234214 0.03132678 0.02976323 0.03229719 0.02213385 0.02325724
  0.02457501 0.03110601 0.02642888 0.0394889  0.02673222 0.01739559
  0.0299753  0.05426997]
 [0.03441716 0.03641591 0.03756015 0.05470003 0.05365636 0.0496069
  0.03104134 0.03394318 0.04107261 0.05146084 0.03639935 0.03765713
  0.03561547 0.07426059 0.09984407 0.03205906 0.02902486 0.03085823
  0.02738269 0.02589308 0.02402144 0.03627677 0.04154489 0.01742079
  0.01086952 0.03174501 0.03949846 0.04498622 0.04456458 0.00983182
  0.00847947 0.07876757]
 [0.03400586 0.04468279 0.04202389 0.07603288 0.1547016  0.06028532
  0.03473448 0.03750304 0.04323146 0.07489883 0.05607839 0.05536537
  0.03733106 0.09681099 0.1330901  0.04416199 0.05029292 0.05549352
  0.0374606  0.03284563 0.03610837 0.0349719  0.05029301 0.01849775
  0.0125872  0.02879767 0.05214956 0.04260778 0.0418768  0.00816822
  0.00642812 0.0799831 ]
 [0.03426851 0.03248985 0.02844258 0.04283084 0.06514369 0.02967823
  0.02503832 0.0277715  0.02772182 0.04216271 0.0365997  0.03288982
  0.02750812 0.03213305 0.04740149 0.03178322 0.05245306 0.06360932
  0.05179597 0.04310263 0.06216019 0.03226756 0.04086313 0.0282088
  0.02778744 0.03297918 0.0346698  0.04883601 0.02580143 0.01135553
  0.00974966 0.0757107 ]
 [0.03436966 0.03695662 0.03194828 0.04623606 0.04552256 0.03595413
  0.03201943 0.03246566 0.03602346 0.04106634 0.03460872 0.03111069
  0.02991457 0.03512976 0.03982129 0.02796999 0.03848084 0.04531252
  0.0372703  0.03612322 0.03619799 0.04487431 0.04783007 0.02088846
  0.01718294 0.02984636 0.02784529 0.05720095 0.02816667 0.00815052
  0.0071339  0.04273314]]

-* TASK 10/20 | SAMPLE 29/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 143/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's location in the context sentences. Sentence 8 only provides information about Fred's possible locations, which does not relate to Bill.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '8', ' only', ' provides', ' information', ' about', ' Fred', "'s", ' possible', ' locations', ',', ' which', ' does', ' not', ' relate', ' to', ' Bill', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 38), x_tokens=38, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 38)
DEBUG result.interpretability.attn_scores 1520 
 [[0.02297889 0.02906183 0.0275018  ... 0.01696323 0.02884974 0.02488459]
 [0.02341631 0.02903547 0.02721959 ... 0.03147968 0.03684581 0.03026904]
 [0.02407897 0.02686172 0.02856533 ... 0.01372865 0.02111759 0.01852173]
 ...
 [0.02456985 0.02438294 0.0207036  ... 0.01866267 0.02210709 0.03216705]
 [0.02490964 0.02635523 0.02343193 ... 0.01555026 0.02245209 0.02855843]
 [0.02505085 0.02349894 0.02153433 ... 0.01429148 0.02186095 0.02473392]]

-* TASK 10/20 | SAMPLE 29/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 144/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 11, Mary travelled to the office, which implies that Mary is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '11', ',', ' Mary', ' travelled', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 44), x_tokens=44, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 44)
DEBUG result.interpretability.attn_scores 1232 
 [[0.0335205  0.04486977 0.05103779 ... 0.01667375 0.04019631 0.04793443]
 [0.03406125 0.03932978 0.04559917 ... 0.0176653  0.01789562 0.02247504]
 [0.03501431 0.04628201 0.05791775 ... 0.0210966  0.03638178 0.03889185]
 ...
 [0.03521647 0.05472643 0.04744371 ... 0.00884502 0.05606288 0.11601087]
 [0.03558366 0.0443538  0.0357531  ... 0.01135297 0.0208622  0.09905127]
 [0.03549325 0.05008273 0.03880726 ... 0.00931906 0.02301586 0.13195156]]

-* TASK 10/20 | SAMPLE 29/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 145/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's location in the cinema in the context sentences. Sentence 13 states that Bill travelled to the school, and sentence 14 mentions Mary going back to the school, but neither sentence mentions the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '13', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' school', ',', ' and', ' sentence', ' ', '14', ' mentions', ' Mary', ' going', ' back', ' to', ' the', ' school', ',', ' but', ' neither', ' sentence', ' mentions', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 50), x_tokens=50, y_tokens=53, max_supp_attn=0.0, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 50)
DEBUG result.interpretability.attn_scores 2650 
 [[0.01738999 0.02480988 0.023556   ... 0.01462202 0.01772922 0.02234347]
 [0.0178015  0.023132   0.02280012 ... 0.01998888 0.01641944 0.01764829]
 [0.01808656 0.02546719 0.02610448 ... 0.01312954 0.01419164 0.01788291]
 ...
 [0.01835527 0.02268226 0.0209294  ... 0.01138746 0.01621767 0.02292392]
 [0.01875613 0.01801064 0.01635396 ... 0.01583197 0.01615985 0.02880171]
 [0.01858405 0.02091295 0.01891933 ... 0.01436356 0.01602061 0.02299309]]
Model's predictions for the sample 29:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 1, Mary journeyed   |
|          |                 |  to the park, which implies that Mary is   |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 5, Fred went back   |
|          |                 |  to the bedroom, which implies that Fred   |
|          |                 |             is in the bedroom.             |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Bill's    |
|          |                 |     location in the context sentences.     |
|          |                 |    Sentence 8 only provides information    |
|          |                 |   about Fred's possible locations, which   |
|          |                 |          does not relate to Bill.          |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 11, Mary travelled  |
|          |                 |   to the office, which implies that Mary   |
|          |                 |             is in the office.              |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    There is no information about Bill's    |
|          |                 |   location in the cinema in the context    |
|          |                 |  sentences. Sentence 13 states that Bill   |
|          |                 |  travelled to the school, and sentence 14  |
|          |                 |  mentions Mary going back to the school,   |
|          |                 |     but neither sentence mentions the      |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 29:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.11 ± 0.09 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 30/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 146/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Mary moved to the cinema, which means she is not in the bedroom. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' she', ' is', ' not', ' in', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1212, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02804518 0.05004474 0.06130963 0.07485033 0.07995033 0.07575704
  0.06909835 0.08040608 0.06222222 0.06706146 0.05028762 0.06809213
  0.07782385 0.09292892 0.06094827 0.03254903 0.03180887 0.03566077
  0.03090592 0.035166   0.02945124 0.04142698 0.04600938 0.02187912
  0.01768548 0.02582047]
 [0.02791842 0.08114525 0.0614802  0.05018997 0.03673648 0.05078348
  0.13872933 0.0877928  0.0593728  0.04493247 0.0661173  0.04738104
  0.07906041 0.02244189 0.02161019 0.04519351 0.04608485 0.05701336
  0.04374493 0.05022833 0.04527401 0.04488029 0.04485531 0.03930623
  0.0348122  0.0337588 ]
 [0.03050806 0.06388927 0.04184866 0.06123433 0.04456989 0.04033668
  0.03300177 0.0242404  0.02414379 0.03769378 0.02956388 0.01776311
  0.01944607 0.03527499 0.04564131 0.02444082 0.01423419 0.01405331
  0.0163256  0.01740982 0.01692729 0.04580242 0.05784198 0.00744406
  0.00573061 0.01347825]
 [0.02886873 0.02074892 0.02172799 0.02451121 0.01696758 0.02399009
  0.0218816  0.01917365 0.02339481 0.0244797  0.02443753 0.02302385
  0.02190404 0.01741747 0.01640464 0.02156817 0.02560337 0.0313927
  0.03537296 0.03895292 0.04070157 0.02935366 0.03460398 0.07699731
  0.06549504 0.04471827]
 [0.02906532 0.04523778 0.0520006  0.07250617 0.06666004 0.05171346
  0.03515025 0.03136985 0.03655206 0.04942127 0.03595508 0.0280493
  0.02683396 0.11154313 0.11548345 0.03721166 0.02693401 0.02173174
  0.02164322 0.02389169 0.02361135 0.03981617 0.06674864 0.01224892
  0.00866678 0.02857103]
 [0.02967573 0.02978566 0.03192595 0.05547939 0.05034975 0.04665208
  0.02619956 0.02464616 0.03093545 0.04597705 0.03261242 0.03154047
  0.02889256 0.12082218 0.14141142 0.03642456 0.02991035 0.02596391
  0.02427526 0.0253504  0.0226087  0.0341341  0.03973556 0.00924154
  0.00681455 0.01849144]
 [0.03011306 0.03339338 0.04045434 0.05807966 0.05492689 0.05764411
  0.03401605 0.03351443 0.04011009 0.05447291 0.03802657 0.04943905
  0.04394082 0.09499578 0.08844656 0.03099731 0.02768397 0.02627046
  0.02344748 0.02502716 0.02134091 0.03096766 0.03691608 0.01315486
  0.00954591 0.01741907]
 [0.02908317 0.04005658 0.04680686 0.04287277 0.04662721 0.0507341
  0.03671115 0.04129521 0.04205356 0.04652611 0.03790286 0.05253418
  0.04410732 0.05583265 0.05057409 0.03958528 0.03580904 0.03272977
  0.0290055  0.03095011 0.02905368 0.03466892 0.0494966  0.0328375
  0.03156512 0.03198611]
 [0.03029827 0.04180971 0.05035449 0.04923031 0.0458719  0.05921293
  0.04188651 0.04629296 0.04984684 0.05276609 0.03749513 0.05499861
  0.04864718 0.04280507 0.02827083 0.02852839 0.02714628 0.02780244
  0.02526512 0.02757399 0.02381544 0.03491829 0.04025739 0.01820775
  0.01483358 0.02350462]
 [0.02952698 0.05216712 0.0563379  0.03018328 0.02454461 0.03879461
  0.04208637 0.04230785 0.0454008  0.03157462 0.02941113 0.03897202
  0.03809454 0.01831004 0.01557413 0.04228337 0.03433657 0.03047896
  0.03024816 0.03287358 0.03325189 0.03447013 0.06986518 0.04064456
  0.03795745 0.03618407]
 [0.03018089 0.04123836 0.04821201 0.02574656 0.02200469 0.02927881
  0.04487041 0.03508718 0.04210438 0.02575675 0.02470136 0.02818153
  0.02697951 0.01418442 0.01361696 0.0432121  0.0315228  0.02787306
  0.02964591 0.03312303 0.03178342 0.03003739 0.05488712 0.04298683
  0.04312864 0.036387  ]
 [0.03071553 0.0139094  0.01640248 0.0112854  0.01015466 0.01397022
  0.01530522 0.01496871 0.01979642 0.01303667 0.01299321 0.01396469
  0.01344027 0.00626977 0.00625672 0.01731033 0.01670425 0.01660989
  0.01991529 0.02161029 0.02365011 0.0172646  0.02931335 0.0534713
  0.06867994 0.05353301]
 [0.03029578 0.02451132 0.02478467 0.01614244 0.01485495 0.02011999
  0.0215978  0.02100951 0.0235174  0.01761113 0.0205243  0.02057692
  0.01963236 0.00894372 0.00945953 0.03370398 0.02607    0.02400031
  0.02623516 0.02670669 0.02666593 0.02915205 0.02979181 0.04445951
  0.06633497 0.05712018]
 [0.03041665 0.02430756 0.02490379 0.01821392 0.01636181 0.0236074
  0.02466064 0.02701056 0.02526652 0.02145453 0.02514949 0.02814653
  0.02803326 0.01010804 0.00929918 0.03237608 0.03274608 0.02783795
  0.02873188 0.02712354 0.02884204 0.03016756 0.02177043 0.03375654
  0.05968579 0.03667947]
 [0.0298663  0.02043289 0.017721   0.01384951 0.011752   0.01552463
  0.01915352 0.02127144 0.01873798 0.0155189  0.02093203 0.01821296
  0.02110645 0.00682887 0.00703931 0.03761833 0.03504993 0.03531871
  0.03705876 0.03497437 0.03861704 0.02669356 0.01583507 0.04408156
  0.09443131 0.05373097]
 [0.03074722 0.01990562 0.01816953 0.01455306 0.01244825 0.01716032
  0.01989599 0.02143866 0.01994442 0.01703148 0.02513687 0.02192581
  0.02248273 0.00712369 0.00706782 0.04083447 0.02740552 0.03808085
  0.03087073 0.03501457 0.03430496 0.02263575 0.01370042 0.03631289
  0.05912524 0.0390177 ]
 [0.03051816 0.01850595 0.01641512 0.01169066 0.01009936 0.01438068
  0.01836507 0.01893744 0.01833732 0.01403078 0.02717049 0.01840482
  0.01958695 0.0060192  0.00633736 0.04183039 0.03193453 0.03520193
  0.03554744 0.03432569 0.03516593 0.02388896 0.0141677  0.03353214
  0.0445796  0.06604085]
 [0.02996821 0.02061253 0.01777876 0.01339002 0.01164518 0.01616554
  0.02046859 0.01996412 0.02102528 0.01549137 0.02216786 0.01810925
  0.02062324 0.00718415 0.00727586 0.03236751 0.02429682 0.02831691
  0.03096739 0.03026453 0.039678   0.02497398 0.01963446 0.07726896
  0.05538338 0.06676157]
 [0.03107721 0.02080963 0.01891227 0.01439789 0.01209384 0.01729406
  0.01968114 0.02059674 0.02087429 0.01670878 0.02651281 0.02099112
  0.02044509 0.00766097 0.00742826 0.02952779 0.02623926 0.02877181
  0.03325345 0.02919459 0.03073104 0.02566    0.01472963 0.02342783
  0.02420488 0.04398214]
 [0.031335   0.02225504 0.0249787  0.01912386 0.01552481 0.02471226
  0.02472559 0.03134179 0.02780946 0.02425488 0.02718437 0.03319337
  0.02936413 0.01158339 0.0087847  0.02093929 0.02291616 0.02390483
  0.0248091  0.02407947 0.02371494 0.02892478 0.01634113 0.01946451
  0.01789096 0.02285404]
 [0.03161083 0.02553342 0.02699212 0.0211863  0.0165918  0.02790545
  0.03088326 0.04134899 0.02950327 0.0263364  0.03785741 0.04008561
  0.03704312 0.01216867 0.00921059 0.02392947 0.02607732 0.02656991
  0.0267472  0.02478432 0.02451383 0.02763815 0.01660665 0.01690558
  0.0138508  0.01628154]
 [0.03134628 0.02479242 0.02467096 0.02097237 0.01696883 0.02507952
  0.02722084 0.03374829 0.02840895 0.02647863 0.03095876 0.03588337
  0.03533383 0.01185328 0.00972904 0.02654404 0.02758637 0.02863648
  0.02717744 0.0261384  0.026692   0.02933279 0.0157963  0.02014438
  0.01889131 0.01447751]
 [0.03131808 0.01919955 0.01774988 0.014193   0.01082828 0.01569849
  0.01956723 0.02278106 0.02118375 0.01662619 0.02270688 0.0217696
  0.02382874 0.00728263 0.00698297 0.02790861 0.03121781 0.02997869
  0.03049005 0.02860097 0.03226914 0.0237404  0.01297156 0.02663747
  0.02734112 0.02091422]
 [0.03137453 0.01979751 0.01872635 0.01498543 0.0123452  0.01716032
  0.02078537 0.02535712 0.0226249  0.01914818 0.0266542  0.02558746
  0.02533659 0.00825622 0.00751078 0.03029294 0.03752731 0.03247412
  0.03700373 0.02964283 0.03288829 0.0241171  0.01288678 0.01965201
  0.0186597  0.02017112]
 [0.03119905 0.02012518 0.01913518 0.01509089 0.01199582 0.01806664
  0.0205895  0.02429302 0.02328718 0.01929959 0.02445142 0.02657077
  0.02465427 0.00846253 0.00749138 0.0254603  0.03036172 0.02765527
  0.02952695 0.02807399 0.0303671  0.02541665 0.0136393  0.03228607
  0.01983038 0.0161552 ]
 [0.03115588 0.01835043 0.0173591  0.01125828 0.00979271 0.01404737
  0.019885   0.0201559  0.02207625 0.0140369  0.02808694 0.01933952
  0.02123336 0.00666618 0.00599165 0.02991144 0.04196696 0.02906376
  0.03334514 0.03022654 0.0353515  0.02363605 0.01350851 0.03843369
  0.0237714  0.01986523]
 [0.0303842  0.02234154 0.02147529 0.01289738 0.01081194 0.01642272
  0.0242879  0.02471749 0.02752542 0.01610313 0.02863353 0.02066896
  0.02548097 0.00785731 0.00704141 0.02688725 0.03365646 0.0263971
  0.03120184 0.03190771 0.04187744 0.02549005 0.01990984 0.06806525
  0.03722566 0.02867449]
 [0.03141807 0.02066409 0.02007916 0.01558202 0.01209636 0.01742265
  0.01967615 0.0219824  0.02460424 0.01889736 0.02491849 0.0226103
  0.02221842 0.0093177  0.0079182  0.01930003 0.02662446 0.02325977
  0.0268617  0.02930307 0.03017295 0.02618368 0.01591854 0.02563353
  0.01971142 0.01892168]
 [0.03104028 0.02221845 0.02248245 0.02265968 0.01900479 0.02438615
  0.02154883 0.02636976 0.02809501 0.02706287 0.02341252 0.030937
  0.02918482 0.01601754 0.01174161 0.01788968 0.02324249 0.0260223
  0.02606713 0.02885208 0.02615312 0.03118891 0.02258604 0.02714239
  0.02049908 0.01973043]
 [0.0304345  0.03355804 0.03239885 0.04800099 0.0504704  0.04374385
  0.02610462 0.02627855 0.0324678  0.04620493 0.03322212 0.02998999
  0.02952947 0.0812109  0.09420938 0.02797688 0.02527551 0.02327239
  0.02313074 0.02384378 0.02193193 0.03391463 0.03652503 0.00875969
  0.00680982 0.01747328]
 [0.03012005 0.03187894 0.03155413 0.05330848 0.10785803 0.04009802
  0.02299981 0.02519224 0.03195054 0.05661714 0.0396878  0.03599356
  0.02676177 0.0769413  0.09574183 0.03024983 0.04007759 0.04189914
  0.03282865 0.02945451 0.02770116 0.02848742 0.03308514 0.00812356
  0.00559656 0.01663568]
 [0.03013125 0.02506686 0.02455815 0.03312854 0.06265724 0.0229953
  0.0166143  0.02117556 0.02480308 0.03769072 0.03274875 0.02975988
  0.02328847 0.02500427 0.0343111  0.02427483 0.04838748 0.05761621
  0.05816466 0.04333842 0.03809428 0.02534891 0.02682775 0.01529375
  0.01178026 0.02055511]
 [0.03024313 0.03170678 0.03029338 0.03920588 0.05443423 0.02914096
  0.02235226 0.02393403 0.03202379 0.0396973  0.03237888 0.02730323
  0.02566145 0.03068315 0.03518929 0.02087236 0.03356161 0.03814121
  0.04018548 0.04199259 0.03279773 0.04566801 0.04323723 0.01219872
  0.00948103 0.02010547]]

-* TASK 10/20 | SAMPLE 30/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 147/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 5 states that Fred is either in the kitchen or the office, but it does not provide a definitive location. Therefore, we can only conclude that Fred might be in the kitchen.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Fred', ' might', ' be', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 32), x_tokens=32, y_tokens=45, max_supp_attn=0.1111, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 32)
DEBUG result.interpretability.attn_scores 1440 
 [[0.02048381 0.03329625 0.03531413 ... 0.012708   0.00656499 0.06190511]
 [0.02106251 0.03125092 0.03271507 ... 0.01680232 0.00958928 0.07399642]
 [0.02138024 0.03197883 0.03536637 ... 0.0300375  0.01339655 0.05289788]
 ...
 [0.02150211 0.03234823 0.02645973 ... 0.00826447 0.00638709 0.07189667]
 [0.02175247 0.02673311 0.02101165 ... 0.00969759 0.00975714 0.04036706]
 [0.0218991  0.02606514 0.02059777 ... 0.00858591 0.00984749 0.06676228]]

-* TASK 10/20 | SAMPLE 30/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 148/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred's location in the provided context sentences. Sentences 7 and 8 only mention Bill's movements, but do not provide any information about Fred.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' provided', ' context', ' sentences', '.', ' Sent', 'ences', ' ', '7', ' and', ' ', '8', ' only', ' mention', ' Bill', "'s", ' movements', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.2045, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02088508 0.0242677  0.02452118 ... 0.01369842 0.0131336  0.02371018]
 [0.0212043  0.02518621 0.02734875 ... 0.03304451 0.03404071 0.06567963]
 [0.02187738 0.02351394 0.02565286 ... 0.01091839 0.00954469 0.01575083]
 ...
 [0.02222861 0.0227749  0.02004336 ... 0.0228359  0.02192496 0.02238029]
 [0.02262767 0.02354063 0.02260188 ... 0.01824712 0.01545603 0.01707116]
 [0.02271594 0.02049612 0.01999607 ... 0.01525857 0.01307012 0.01603525]]

-* TASK 10/20 | SAMPLE 30/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 149/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 explicitly states that Bill is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 44), x_tokens=44, y_tokens=19, max_supp_attn=0.1053, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 44)
DEBUG result.interpretability.attn_scores 836 
 [[0.049922   0.06166884 0.07081467 0.08737303 0.06385497 0.07937507
  0.05989034 0.07300223 0.07866269 0.071297   0.04612213 0.05316221
  0.06498533 0.10899978 0.09631051 0.03982827 0.03876547 0.03982275
  0.03568354 0.04761196 0.03333016 0.05306414 0.08826148 0.03846782
  0.03526325 0.05834023 0.06693749 0.06151046 0.14807147 0.02280391
  0.017573   0.08139066 0.14639731 0.09165937 0.03631663 0.02834852
  0.03162127 0.0611165  0.10261793 0.04408365 0.15264833 0.01928304
  0.02189727 0.0329745 ]
 [0.05058769 0.04739292 0.04799509 0.05275071 0.03728561 0.05211585
  0.04421937 0.0628842  0.05081284 0.04402098 0.04032566 0.04272246
  0.05837844 0.05789529 0.08681081 0.0394507  0.03144227 0.04069904
  0.03849876 0.05079998 0.03665651 0.04819554 0.05375579 0.04519131
  0.04923807 0.04624457 0.0463329  0.04047891 0.094479   0.04310889
  0.03517332 0.04343586 0.06564688 0.05598712 0.03438512 0.03837993
  0.04025959 0.05117426 0.05331814 0.04527585 0.08695258 0.03119383
  0.03770314 0.03965041]
 [0.05201352 0.06357481 0.07186423 0.10100034 0.08317756 0.10384192
  0.06183819 0.07404366 0.0679547  0.0762818  0.0551142  0.06557161
  0.07654165 0.17284139 0.10645081 0.04237662 0.03409653 0.03495747
  0.03165978 0.03958235 0.02972857 0.05354176 0.06801137 0.03665386
  0.03411351 0.04711184 0.06111843 0.04550996 0.08937913 0.04595209
  0.02551677 0.09053804 0.08532905 0.06840725 0.03082463 0.02471033
  0.02984729 0.04507737 0.09548085 0.04121383 0.10626572 0.03761318
  0.02995583 0.05553511]
 [0.05043553 0.05839682 0.06688999 0.04920375 0.03840148 0.0556207
  0.05342557 0.0640357  0.05417539 0.04415792 0.04178941 0.04755003
  0.05335096 0.0381414  0.03267515 0.04799839 0.03813503 0.03797206
  0.03558283 0.04432087 0.0350964  0.05631049 0.07743999 0.06558993
  0.06123734 0.0572004  0.07118284 0.04842383 0.05434985 0.15177861
  0.04443923 0.04244827 0.05092985 0.04831992 0.06232025 0.04315876
  0.05096263 0.0557912  0.07712838 0.05563338 0.07020824 0.11963795
  0.05003533 0.06794908]
 [0.0521374  0.0560562  0.06264708 0.03695844 0.02775578 0.04612854
  0.06182617 0.05841786 0.05924003 0.03490729 0.03863387 0.03643544
  0.04333733 0.02688781 0.02505531 0.04870064 0.03533457 0.03390646
  0.03605177 0.04417658 0.03338694 0.04946687 0.06674487 0.05869462
  0.05945798 0.04598262 0.06389987 0.03043157 0.03711924 0.13963589
  0.02909529 0.02245571 0.03004356 0.04913352 0.06132152 0.04779339
  0.04692189 0.0516212  0.04965964 0.04363092 0.03694703 0.1399697
  0.05084461 0.06014875]
 [0.05323723 0.03121372 0.03263688 0.02045165 0.01635654 0.02709309
  0.03426771 0.03457064 0.03693897 0.02337994 0.02840608 0.02349553
  0.03202435 0.01417743 0.01570048 0.03400798 0.0291649  0.03089187
  0.0332995  0.03980679 0.03024573 0.03813854 0.04136561 0.04679402
  0.05770599 0.03861266 0.03345045 0.02904102 0.02656044 0.0583192
  0.02373297 0.01467274 0.02470677 0.03729717 0.04359663 0.04439724
  0.03840184 0.04457562 0.01649324 0.03318033 0.02262261 0.05794597
  0.03304666 0.02068995]
 [0.05170329 0.05547846 0.05854932 0.03994917 0.02739665 0.04811898
  0.05351374 0.05515808 0.05222746 0.04251116 0.04316072 0.04648085
  0.04929225 0.02495228 0.02506229 0.05193362 0.04097088 0.04503345
  0.05079193 0.05189014 0.04332526 0.06127187 0.05819537 0.0669504
  0.07299936 0.05197559 0.06119163 0.03927647 0.03987192 0.09172159
  0.05651332 0.02047299 0.02712988 0.04280394 0.07684147 0.05679746
  0.06799781 0.05901252 0.04747054 0.05551265 0.03946035 0.10687945
  0.06190997 0.11728225]
 [0.05338779 0.06593973 0.06919008 0.05749138 0.03653528 0.06530776
  0.0687759  0.07095321 0.060666   0.05981759 0.05793077 0.07408032
  0.07441128 0.03659421 0.0293736  0.05451537 0.04711086 0.05281252
  0.04948739 0.05445751 0.04710089 0.05854695 0.05725581 0.0613536
  0.071877   0.05072248 0.06130142 0.05033999 0.04336324 0.07568528
  0.07754192 0.02722825 0.0379967  0.04513215 0.07501468 0.05535043
  0.06472087 0.05453472 0.05070921 0.05885534 0.04160749 0.07953994
  0.0638678  0.12246566]
 [0.05426088 0.05053535 0.05231616 0.04268319 0.0300741  0.04912219
  0.05730924 0.05066212 0.04880816 0.04687628 0.04902498 0.05012948
  0.05357594 0.02702958 0.02480047 0.04791211 0.03792945 0.03956068
  0.0408655  0.04498733 0.04110852 0.05360488 0.04159089 0.05115992
  0.05761018 0.03955426 0.04823598 0.04124058 0.03395571 0.06679381
  0.07561334 0.02684307 0.02858672 0.04017007 0.06102094 0.04854781
  0.06354314 0.04747649 0.04153297 0.05431291 0.03771268 0.09537586
  0.07670113 0.08522376]
 [0.05357331 0.04308423 0.03695516 0.02747281 0.02067895 0.03245419
  0.04668425 0.03871099 0.03970013 0.03411985 0.04646418 0.0389661
  0.04340161 0.01687731 0.01933367 0.06095443 0.04666772 0.04877649
  0.04876038 0.05178937 0.05286986 0.05519509 0.03339854 0.06461817
  0.06903002 0.03984099 0.03948909 0.04035719 0.02978471 0.05181668
  0.06753026 0.01762718 0.02024707 0.036433   0.07054855 0.06176167
  0.07500505 0.04815954 0.02800852 0.05680798 0.0271869  0.06348324
  0.06772745 0.04488928]
 [0.05309239 0.04473373 0.03663973 0.027875   0.01947971 0.03099411
  0.04760206 0.03831728 0.03923111 0.03257922 0.04325625 0.035848
  0.04309399 0.01585818 0.01744158 0.06921267 0.04359545 0.05130187
  0.0524049  0.05447125 0.06243173 0.05304576 0.02958533 0.06953333
  0.0729218  0.04653484 0.03634168 0.0444901  0.02770546 0.04415708
  0.07044497 0.01235749 0.0197565  0.03472764 0.07599401 0.06056954
  0.08037628 0.0478138  0.02479983 0.053913   0.02129568 0.04425227
  0.05689243 0.03732258]
 [0.05428445 0.04121064 0.0349956  0.02633043 0.02062765 0.03058196
  0.04124149 0.03597616 0.03793374 0.03349333 0.05209732 0.04481407
  0.04089934 0.01604721 0.01685685 0.06142569 0.05625344 0.05270097
  0.06544711 0.05569653 0.06167512 0.05065763 0.02644795 0.05634831
  0.0557122  0.04342331 0.03685405 0.04935517 0.02513408 0.0381803
  0.10046085 0.0139734  0.01807668 0.03184325 0.07226286 0.08273597
  0.07928232 0.05251929 0.02126128 0.06180565 0.02098128 0.05074764
  0.08986439 0.04752805]
 [0.05401185 0.03879443 0.03475834 0.02241552 0.01850172 0.02783112
  0.04334965 0.03478655 0.03771437 0.02959039 0.0570217  0.04286678
  0.04096362 0.01385895 0.01499705 0.07798763 0.05741497 0.06143832
  0.07381565 0.0616672  0.06878573 0.04870803 0.02625289 0.06809681
  0.06286614 0.07511912 0.03012004 0.06488355 0.02529842 0.0372652
  0.11244207 0.01261149 0.01810641 0.03236957 0.05987677 0.11477417
  0.07908522 0.06427457 0.01721294 0.07905982 0.0201167  0.03416606
  0.09994616 0.03600655]
 [0.05263864 0.04604037 0.04297897 0.02711341 0.02280489 0.03795269
  0.05552171 0.04590792 0.05321467 0.03646846 0.06767475 0.06524028
  0.04825921 0.01858065 0.0194096  0.07439564 0.05070736 0.06142085
  0.07662614 0.06254437 0.058213   0.05319838 0.03764306 0.07563715
  0.06715941 0.09442899 0.03711023 0.05558496 0.03822764 0.03653158
  0.06655504 0.0227331  0.03603443 0.04635026 0.04435101 0.08715948
  0.06778099 0.06271451 0.02018172 0.04726788 0.02750592 0.02471408
  0.07269519 0.03785706]
 [0.05457766 0.04379154 0.04660498 0.03715098 0.0247224  0.04122111
  0.04775837 0.04580631 0.04587301 0.04346292 0.05055037 0.05203408
  0.04640432 0.02551732 0.02105906 0.04550941 0.03827322 0.04364778
  0.04918053 0.04457509 0.04342771 0.04953328 0.02960731 0.04108737
  0.03701068 0.05321807 0.03312106 0.04628269 0.03425223 0.03143801
  0.10942355 0.03998596 0.0217485  0.03371868 0.03658812 0.0506025
  0.04071295 0.04829447 0.03091732 0.05181282 0.03673805 0.03112926
  0.09200898 0.08292786]
 [0.05281874 0.05243592 0.05484794 0.08228152 0.06278078 0.07228231
  0.05428326 0.05320221 0.06480396 0.07903782 0.05643312 0.06288239
  0.06329573 0.10814504 0.11267078 0.03786622 0.04288848 0.0452216
  0.04154215 0.04593091 0.03944226 0.0512469  0.053286   0.02891917
  0.02954193 0.05044991 0.05350608 0.05870908 0.07061676 0.01782583
  0.02390507 0.13334392 0.09965958 0.06233738 0.03190868 0.02991915
  0.02956641 0.05152422 0.0800072  0.04286127 0.08121024 0.01885606
  0.02833727 0.03910753]
 [0.05242964 0.0696734  0.06370501 0.10849642 0.22995356 0.08753815
  0.05975407 0.05329535 0.061483   0.10532099 0.08385309 0.08091819
  0.05727194 0.15572162 0.18851045 0.05728821 0.08799037 0.0765207
  0.06322672 0.05724016 0.0704557  0.05030436 0.07096742 0.02999234
  0.0251939  0.0543933  0.08197922 0.06257642 0.07425009 0.01320522
  0.01421848 0.13648717 0.06725238 0.0817651  0.03333404 0.02872187
  0.02788112 0.04898174 0.11569256 0.04649572 0.06835239 0.014405
  0.01754583 0.02293206]
 [0.05220777 0.06233296 0.05566024 0.07652254 0.13566215 0.05080593
  0.04916114 0.05122941 0.04824837 0.0865561  0.07716604 0.07282414
  0.05386978 0.05659672 0.08287042 0.0613691  0.15411392 0.1248268
  0.10272473 0.07767375 0.13388102 0.05005189 0.06508826 0.05321049
  0.04370837 0.05165346 0.07444005 0.09308176 0.04715465 0.01986392
  0.02748905 0.11828432 0.04929462 0.05950815 0.05378941 0.05429991
  0.04735553 0.05389804 0.0617147  0.0752971  0.04185346 0.01768133
  0.02648526 0.02758604]
 [0.05268019 0.06764593 0.0599506  0.07647975 0.08395033 0.06161441
  0.05957772 0.05904019 0.06231135 0.07612089 0.06497528 0.063978
  0.05664293 0.06527782 0.06461109 0.04726737 0.08914504 0.07848832
  0.07435068 0.07077781 0.07883885 0.06591766 0.07510206 0.04170141
  0.03735286 0.05519331 0.0633875  0.09842633 0.06042594 0.01391684
  0.02233161 0.12311034 0.15305713 0.10203629 0.03970453 0.04197178
  0.03867779 0.0514399  0.06579302 0.05297986 0.06033437 0.01312613
  0.02253535 0.02192361]]

-* TASK 10/20 | SAMPLE 30/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 150/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 (from previous context) explicitly stated that Bill is in the cinema, and there is no new information that would change this.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' (', 'from', ' previous', ' context', ')', ' explicitly', ' stated', ' that', ' Bill', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' would', ' change', ' this', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.1714, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02636553 0.0302185  0.03227045 ... 0.03790632 0.02901829 0.02185651]
 [0.02684105 0.02445476 0.02913301 ... 0.02134788 0.02961538 0.02950628]
 [0.02753864 0.02748509 0.03225375 ... 0.04052377 0.02361514 0.01743337]
 ...
 [0.02794279 0.03166749 0.02634479 ... 0.07742868 0.01907168 0.01391301]
 [0.02834308 0.02548466 0.02116487 ... 0.05313619 0.02440295 0.0181936 ]
 [0.028149   0.027273   0.02169914 ... 0.08587668 0.02038616 0.01544858]]
Model's predictions for the sample 30:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 2, Mary moved to   |
|          |                 |   the cinema, which means she is not in    |
|          |                 |                the bedroom.                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  Sentence 5 states that Fred is either in  |
|          |                 |   the kitchen or the office, but it does   |
|          |                 |     not provide a definitive location.     |
|          |                 |    Therefore, we can only conclude that    |
|          |                 |       Fred might be in the kitchen.        |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |    There is no information about Fred's    |
|          |                 |      location in the provided context      |
|          |                 |     sentences. Sentences 7 and 8 only      |
|          |                 |    mention Bill's movements, but do not    |
|          |                 |    provide any information about Fred.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 11 explicitly states that Bill   |
|          |                 |             is in the cinema.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    Sentence 11 (from previous context)     |
|          |                 |   explicitly stated that Bill is in the    |
|          |                 |  cinema, and there is no new information   |
|          |                 |          that would change this.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 30:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.14 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 31/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 151/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, "Bill moved to the office", which implies that Bill is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' "', 'Bill', ' moved', ' to', ' the', ' office', '",', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02646929 0.04121321 0.04977081 0.06801746 0.07986196 0.06898448
  0.05298312 0.05996719 0.04940333 0.06163022 0.04448095 0.05637034
  0.06330433 0.09734908 0.06655932 0.0257276  0.0314762  0.03253815
  0.02976508 0.03202615 0.02463113 0.03612343 0.03935632 0.01911163
  0.01308729 0.02429839]
 [0.02681428 0.05371094 0.04934788 0.06892077 0.06219769 0.05758397
  0.04377779 0.04097646 0.04036568 0.04795559 0.03729912 0.03062554
  0.03228095 0.10258041 0.1031829  0.02709214 0.02594405 0.02267097
  0.02332575 0.02370292 0.01953739 0.03881443 0.04148591 0.01425344
  0.00932498 0.02068014]
 [0.02891555 0.05631451 0.03422035 0.04772925 0.03465889 0.03291594
  0.03050052 0.02117451 0.02116154 0.03150996 0.0265413  0.0160967
  0.01785235 0.02435027 0.03226446 0.01897772 0.01408075 0.01371301
  0.01726659 0.01757151 0.01508511 0.04096178 0.04847629 0.00884277
  0.00594526 0.01124638]
 [0.0271131  0.02785177 0.03159551 0.02385542 0.0167259  0.02548387
  0.02721757 0.02492582 0.03041884 0.0241169  0.02466543 0.02384778
  0.0221997  0.01202537 0.01188327 0.0279227  0.02810031 0.02729436
  0.03123982 0.03210362 0.03481956 0.03278987 0.04579085 0.04699581
  0.05846439 0.06173949]
 [0.02739215 0.0406733  0.04453202 0.06268704 0.05634861 0.04529933
  0.03395825 0.02890234 0.03289338 0.04329019 0.03305573 0.02493267
  0.02516511 0.08892465 0.0929625  0.03070323 0.02764645 0.02142153
  0.02233529 0.02403016 0.02142912 0.03741348 0.06047155 0.01630039
  0.00890566 0.02685242]
 [0.02791655 0.02556028 0.02687234 0.04782918 0.0421149  0.04096726
  0.02503904 0.02236556 0.02774411 0.04047306 0.02911215 0.02848519
  0.02732439 0.10168613 0.12355184 0.03082182 0.03167636 0.02610581
  0.0252709  0.02562878 0.02045764 0.03143436 0.03534818 0.01124256
  0.00701388 0.01711399]
 [0.02829383 0.02882023 0.03481542 0.05070608 0.04648709 0.05215828
  0.03324737 0.0312161  0.0366052  0.04800033 0.03422628 0.04524325
  0.04184857 0.08137339 0.07700617 0.0261002  0.02876399 0.02575981
  0.02430233 0.02529576 0.01938873 0.02834769 0.03303616 0.01531489
  0.00904697 0.01704515]
 [0.02734827 0.03745143 0.04454605 0.04041865 0.04162838 0.04828212
  0.0390311  0.04136414 0.03963305 0.04264707 0.0351464  0.04891468
  0.04344932 0.04975244 0.04497243 0.03477546 0.03513902 0.0315372
  0.02882054 0.03102303 0.02689153 0.03258694 0.04644162 0.0342444
  0.02666733 0.03548197]
 [0.02841523 0.04029016 0.04862663 0.0454677  0.04056649 0.0558397
  0.04460682 0.04745721 0.04799089 0.04843093 0.03590686 0.05116719
  0.04811452 0.03822648 0.02497021 0.02528193 0.02814021 0.0270541
  0.02604244 0.02870634 0.02188704 0.0329508  0.03638495 0.02086953
  0.01478558 0.02419792]
 [0.02775697 0.05083558 0.05444023 0.02914903 0.02328797 0.03741135
  0.04682052 0.04482861 0.04562895 0.03076059 0.0295636  0.0380389
  0.03922289 0.01723721 0.01451479 0.04106374 0.03559854 0.03082835
  0.03054517 0.03324318 0.03096256 0.03258333 0.06299572 0.0420436
  0.03324065 0.03769599]
 [0.02831804 0.06576326 0.06460936 0.02693349 0.02157919 0.0320235
  0.0468254  0.04020782 0.04691488 0.02670615 0.02597383 0.03044534
  0.0310015  0.01427921 0.01364967 0.04429038 0.03636595 0.03018532
  0.03118056 0.03626234 0.02939832 0.02946844 0.06682716 0.03878219
  0.02461323 0.02724545]
 [0.02842282 0.0338098  0.03860081 0.02032109 0.01717125 0.02322094
  0.03520815 0.03007099 0.03574328 0.02139903 0.02089761 0.02363816
  0.02280545 0.01191216 0.01176709 0.03675387 0.03128468 0.02509951
  0.02787653 0.02990429 0.02932918 0.02795168 0.05252617 0.04879721
  0.04116705 0.04221519]
 [0.02866674 0.015072   0.0167406  0.01172325 0.01041089 0.01380465
  0.01663247 0.01642375 0.01960452 0.0134062  0.01436711 0.01499282
  0.01428465 0.00637532 0.00687282 0.01918075 0.01900076 0.0179254
  0.02262842 0.02442215 0.02840139 0.02085327 0.03007394 0.05218176
  0.06156217 0.05941477]
 [0.02853504 0.02195674 0.02292417 0.01595446 0.01450785 0.01969456
  0.02433987 0.02204063 0.02243356 0.01741869 0.02085396 0.02085302
  0.0203099  0.0086595  0.00912231 0.03378602 0.02344663 0.02420676
  0.02517105 0.02709384 0.02678812 0.02696511 0.02487805 0.04602616
  0.06270929 0.0511829 ]
 [0.02870255 0.02234647 0.02323651 0.01883004 0.01615595 0.02327262
  0.02672152 0.02732025 0.02442988 0.02194149 0.02461719 0.02841839
  0.02851056 0.01060243 0.00926013 0.03369248 0.02631046 0.02895603
  0.02722245 0.02741357 0.02838379 0.0280465  0.02029005 0.03389488
  0.05039944 0.03074788]
 [0.02917143 0.02280726 0.02148479 0.01608988 0.01606168 0.01838866
  0.02912368 0.02414262 0.02155496 0.01784231 0.03187943 0.02438777
  0.02361964 0.00859233 0.00964685 0.03351767 0.02660206 0.02626502
  0.02582086 0.02798768 0.02750628 0.02566456 0.02046503 0.03772259
  0.05818361 0.02593379]
 [0.02853654 0.01802208 0.0146267  0.0130644  0.01075329 0.01406306
  0.01963028 0.01911174 0.01700624 0.01403953 0.01996944 0.01588647
  0.0191007  0.0060552  0.00645975 0.03331396 0.02161721 0.0289223
  0.02968285 0.03258523 0.04123836 0.02248831 0.01468242 0.0412701
  0.09092828 0.041991  ]
 [0.02904247 0.01782648 0.01539702 0.01317091 0.0109375  0.01545478
  0.01935589 0.019077   0.01807252 0.01507132 0.02285045 0.01953523
  0.02079703 0.00638886 0.00640728 0.03889799 0.02300374 0.0433384
  0.03018155 0.03646412 0.03308624 0.02058588 0.01196381 0.03548761
  0.05877656 0.02935342]
 [0.02888874 0.01618917 0.01372008 0.01053725 0.00900875 0.0129039
  0.01839015 0.01738847 0.01732599 0.01241496 0.02793241 0.01737895
  0.01872873 0.00540196 0.00568386 0.03970602 0.02541769 0.03652386
  0.03329496 0.03389361 0.03683418 0.02162117 0.0122263  0.04544658
  0.04783273 0.04183099]
 [0.02859181 0.02400648 0.02369605 0.02029085 0.01986282 0.02541189
  0.0300943  0.03189734 0.03049808 0.02582955 0.02915006 0.03107727
  0.02923608 0.01217703 0.01096445 0.02375078 0.02636134 0.027844
  0.02929094 0.03011763 0.03381634 0.02754583 0.02137143 0.03391331
  0.02461046 0.03573035]
 [0.02969599 0.01859055 0.01728971 0.01367844 0.01190729 0.01566151
  0.02058334 0.02047534 0.01907346 0.01521951 0.02424615 0.01981963
  0.02032142 0.0071396  0.00702289 0.02489112 0.02300673 0.02300668
  0.02769659 0.02381913 0.02524935 0.02283658 0.01285133 0.02613696
  0.02291379 0.02923435]
 [0.02933327 0.0251808  0.02638087 0.02523076 0.01933404 0.02807444
  0.02995662 0.03460214 0.02822789 0.02912343 0.03173469 0.03816026
  0.03387133 0.01461558 0.01108349 0.02113072 0.02253092 0.02522828
  0.02630728 0.02543683 0.02375645 0.03055639 0.01723462 0.01809516
  0.01620747 0.02033734]
 [0.02955356 0.02718146 0.02973086 0.02768296 0.02002644 0.03172448
  0.03326593 0.04176974 0.02954441 0.03340016 0.03400342 0.04549823
  0.04197064 0.01525257 0.01026349 0.02193419 0.02290632 0.02809537
  0.02488326 0.02410821 0.02130906 0.02760669 0.01635453 0.01534402
  0.01241837 0.01509812]
 [0.02942423 0.02451196 0.0244025  0.02368843 0.01840759 0.02697896
  0.02993806 0.03496742 0.02760091 0.02915    0.0324469  0.03808119
  0.03955225 0.01357018 0.0098835  0.02625384 0.02461172 0.03047124
  0.02795235 0.02698399 0.0247383  0.0283777  0.01370111 0.01776556
  0.01586389 0.01404692]
 [0.02930857 0.01933558 0.01786842 0.01452389 0.01092233 0.01644413
  0.02236151 0.02418071 0.02156747 0.0171251  0.02267584 0.02195936
  0.02578814 0.00760056 0.0067842  0.02928975 0.02433973 0.02930573
  0.02875379 0.02740721 0.03042041 0.02712833 0.01191864 0.02546448
  0.03008376 0.02048711]
 [0.02923417 0.01905721 0.01692675 0.01397428 0.00993954 0.01484291
  0.02273063 0.02307258 0.02039276 0.0157368  0.02194181 0.01930231
  0.0239778  0.00694244 0.00617022 0.03185928 0.02338944 0.03118503
  0.02994555 0.02934232 0.03543086 0.0235177  0.01115864 0.03193125
  0.03537973 0.0237393 ]
 [0.02946284 0.01909896 0.01702723 0.01430826 0.01109678 0.01548616
  0.02141335 0.02345914 0.02092659 0.01745085 0.02483544 0.02237002
  0.02485072 0.00759839 0.0064769  0.02876647 0.02863265 0.03122535
  0.03436819 0.02877919 0.03242937 0.02375048 0.01121011 0.02388207
  0.02086615 0.01838054]
 [0.02957994 0.02192963 0.01978137 0.01603729 0.01169383 0.01762174
  0.0254267  0.02698972 0.02627745 0.01928793 0.02921554 0.02450301
  0.02795548 0.00820071 0.00685995 0.03019975 0.02794204 0.03286892
  0.03305469 0.03101783 0.03207296 0.02465535 0.01211821 0.02481485
  0.01961143 0.01651258]
 [0.02960037 0.01656059 0.01541727 0.01062929 0.00885814 0.01252552
  0.02032164 0.01995657 0.02012723 0.01328037 0.03299369 0.01772035
  0.02185998 0.00605466 0.00515951 0.03232384 0.03038659 0.03065185
  0.03630212 0.03054894 0.03308969 0.02272454 0.01127644 0.03052508
  0.02227927 0.02279416]
 [0.02841414 0.01916783 0.01823606 0.01143661 0.00937933 0.01397631
  0.02137136 0.02139637 0.02446325 0.01431775 0.02143866 0.01695419
  0.02195556 0.00640457 0.00564302 0.02173731 0.0283743  0.02392001
  0.03254424 0.03363517 0.05007031 0.02435384 0.01999154 0.0747196
  0.0447876  0.05875428]
 [0.02966878 0.01910995 0.01915514 0.01598207 0.01197556 0.01793552
  0.02030406 0.02377062 0.02377093 0.01863782 0.02243805 0.02230995
  0.02261774 0.00981269 0.00784085 0.01775043 0.02244847 0.02041893
  0.02725983 0.02343003 0.02697953 0.02458202 0.01325621 0.01902573
  0.01567548 0.02346348]
 [0.02857837 0.02595    0.02594313 0.03965472 0.04019591 0.03536253
  0.02339561 0.02410901 0.029233   0.041242   0.02971408 0.0298888
  0.02899078 0.06524605 0.07780922 0.02045903 0.02814221 0.02533812
  0.02589935 0.02552933 0.02186001 0.03013053 0.02930765 0.01154249
  0.00856947 0.01925219]
 [0.02834724 0.02739318 0.02641825 0.04480895 0.08476292 0.03562925
  0.02202072 0.02285185 0.02826682 0.04821144 0.03506255 0.03072238
  0.02513747 0.06670636 0.0848166  0.02568458 0.04009628 0.03484861
  0.03054143 0.0280374  0.02504537 0.0273972  0.02928592 0.00948853
  0.00659087 0.016567  ]
 [0.02807745 0.02526798 0.02397567 0.03824388 0.08663207 0.02541281
  0.01858642 0.02246641 0.02505269 0.04421292 0.0350637  0.03391267
  0.02499007 0.03164262 0.04092388 0.02293956 0.06459993 0.05161178
  0.04118394 0.03227649 0.03846661 0.02460023 0.02700993 0.01558219
  0.01131743 0.02066758]
 [0.02840981 0.03114323 0.02764344 0.03842402 0.05454122 0.02915884
  0.0248203  0.02507372 0.03004627 0.03871986 0.03370016 0.02846191
  0.02700424 0.02926365 0.03156023 0.01942362 0.0426163  0.03363414
  0.0320434  0.03017198 0.02920975 0.0425855  0.03823319 0.01294055
  0.01017054 0.01866752]]

-* TASK 10/20 | SAMPLE 31/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 152/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, "Fred journeyed to the kitchen", which implies that Fred is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' "', 'Fred', ' journey', 'ed', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.125, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02936829 0.0454832  0.04470365 ... 0.06175919 0.01001472 0.0073257 ]
 [0.03012693 0.04578529 0.04475895 ... 0.06975308 0.01381071 0.01084552]
 [0.03068615 0.04156064 0.04605075 ... 0.07208846 0.02279482 0.01705611]
 ...
 [0.03071535 0.0384303  0.03656579 ... 0.02558673 0.00799038 0.00568369]
 [0.03082006 0.03136507 0.02678873 ... 0.0150283  0.01156134 0.0088453 ]
 [0.03098508 0.03470657 0.0292688  ... 0.0123965  0.00754816 0.00627033]]

-* TASK 10/20 | SAMPLE 31/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 153/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, "Bill journeyed to the kitchen", which implies that Bill is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' "', 'Bill', ' journey', 'ed', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02954055 0.041202   0.03766724 ... 0.02696173 0.01947547 0.01873284]
 [0.02990114 0.08289143 0.07293207 ... 0.04460619 0.02961415 0.0256233 ]
 [0.03080682 0.03983177 0.04270877 ... 0.02145055 0.0150852  0.01348477]
 ...
 [0.03094103 0.0344263  0.03837463 ... 0.02004627 0.01382707 0.01443754]
 [0.03116968 0.02613701 0.02688768 ... 0.02352709 0.02042301 0.02301081]
 [0.03103594 0.03004549 0.03008047 ... 0.0230762  0.01825595 0.02034306]]

-* TASK 10/20 | SAMPLE 31/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 154/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary being in the school in the context sentences. The possibilities for Mary's location are the office or the kitchen, according to context sentence 10.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' possibilities', ' for', ' Mary', "'s", ' location', ' are', ' the', ' office', ' or', ' the', ' kitchen', ',', ' according', ' to', ' context', ' sentence', ' ', '10', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 44), x_tokens=44, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 44)
DEBUG result.interpretability.attn_scores 1848 
 [[0.02197966 0.02580613 0.03041931 ... 0.01126111 0.01372852 0.04502974]
 [0.0225133  0.01913229 0.02506386 ... 0.01999086 0.01855775 0.02675873]
 [0.02300904 0.02488839 0.03118695 ... 0.01928475 0.02593209 0.04203263]
 ...
 [0.02309967 0.02895152 0.02608963 ... 0.00918732 0.01168289 0.07903122]
 [0.02350857 0.02259119 0.01985382 ... 0.00982734 0.01385041 0.04148836]
 [0.02356821 0.02430924 0.0214635  ... 0.00917798 0.01259309 0.04268088]]

-* TASK 10/20 | SAMPLE 31/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 155/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary or the school in the context sentences. The context sentences only provide information about Julie and Fred's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' or', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' provide', ' information', ' about', ' Julie', ' and', ' Fred', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02654411 0.03128495 0.02785514 ... 0.01757677 0.02563827 0.03704501]
 [0.02722304 0.03071767 0.03330215 ... 0.02403689 0.03189847 0.03067683]
 [0.0278831  0.03035914 0.03102342 ... 0.01593341 0.02247964 0.03361637]
 ...
 [0.02831777 0.03108099 0.02251104 ... 0.03122197 0.02784696 0.04890587]
 [0.02871885 0.03610208 0.02780098 ... 0.02530117 0.0269373  0.04888875]
 [0.02891652 0.02978867 0.02391239 ... 0.02126017 0.0250005  0.03538205]]
Model's predictions for the sample 31:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 2, "Bill   |
|          |                 |  moved to the office", which implies that  |
|          |                 |      Bill is currently in the office.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 5, "Fred   |
|          |                 |  journeyed to the kitchen", which implies  |
|          |                 |   that Fred is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 8, "Bill   |
|          |                 |  journeyed to the kitchen", which implies  |
|          |                 |   that Bill is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Mary being in the  |
|          |                 |    school in the context sentences. The    |
|          |                 |   possibilities for Mary's location are    |
|          |                 |  the office or the kitchen, according to   |
|          |                 |            context sentence 10.            |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |     There is no mention of Mary or the     |
|          |                 |    school in the context sentences. The    |
|          |                 |       context sentences only provide       |
|          |                 |     information about Julie and Fred's     |
|          |                 |                 locations.                 |
+----------+-----------------+--------------------------------------------+

Metrics for sample 31:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 32/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 156/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, Mary is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 26), x_tokens=26, y_tokens=24, max_supp_attn=0.0417, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 26)
DEBUG result.interpretability.attn_scores 624 
 [[0.03909519 0.05581807 0.06998958 0.08954183 0.09312353 0.0911226
  0.06979912 0.08739057 0.07271    0.08091148 0.06467853 0.07950877
  0.08795847 0.11122404 0.07012545 0.04111538 0.03892542 0.04300984
  0.03722111 0.04139052 0.03586831 0.05133076 0.04778848 0.02822977
  0.01996383 0.0324704 ]
 [0.0387605  0.10011229 0.08140811 0.07484315 0.05715498 0.07542413
  0.21819991 0.14945433 0.08912839 0.07268203 0.09306587 0.07351856
  0.11710091 0.03670327 0.02916573 0.05264745 0.04719496 0.06769325
  0.05148051 0.06283907 0.05494796 0.05999643 0.04865178 0.04679365
  0.0286832  0.03652352]
 [0.0426146  0.06911566 0.04454274 0.06346852 0.04629453 0.04333073
  0.0354032  0.02828992 0.02882534 0.04183961 0.03866267 0.02186819
  0.02429762 0.03533664 0.0451324  0.032428   0.01863609 0.01867727
  0.02212375 0.0230337  0.02264981 0.05691288 0.05901143 0.01209257
  0.00705299 0.01488804]
 [0.04013261 0.05311996 0.05106817 0.02850908 0.0191162  0.03457388
  0.03414743 0.03231948 0.04229361 0.0304769  0.03425054 0.03287035
  0.03058283 0.01342656 0.01298852 0.04565344 0.03916707 0.03970473
  0.04646752 0.04751095 0.04321644 0.04374061 0.06421249 0.0681045
  0.09164732 0.07646509]
 [0.04048093 0.04954139 0.05555735 0.07894836 0.07002202 0.05762236
  0.03834847 0.03707049 0.04387188 0.05590682 0.04752133 0.03433982
  0.03361066 0.11723802 0.11857124 0.04990303 0.03570545 0.02930623
  0.02857852 0.0312946  0.03174908 0.05099894 0.06937239 0.02161558
  0.01098569 0.03273695]
 [0.04133097 0.03213127 0.03429185 0.06120744 0.05257951 0.05238838
  0.02883263 0.02909011 0.03729027 0.05219715 0.04208723 0.03886795
  0.0363114  0.12733792 0.14840601 0.04926543 0.03985415 0.03494797
  0.03208936 0.03329347 0.03041217 0.04351175 0.04157602 0.01528813
  0.00880926 0.02130298]
 [0.04198325 0.03586162 0.0435153  0.06369594 0.05668815 0.06577181
  0.03742994 0.03931073 0.04834364 0.06114358 0.04866285 0.06096903
  0.05454586 0.10043483 0.09150164 0.04062854 0.03561852 0.03404021
  0.03051743 0.03246383 0.02827959 0.03917285 0.03854848 0.02060175
  0.01244301 0.02138444]
 [0.04062207 0.04869017 0.05923673 0.05122538 0.05105965 0.06172485
  0.04189279 0.0511174  0.05324468 0.05588573 0.04962585 0.06677803
  0.05587373 0.06160436 0.05419008 0.05124544 0.0448093  0.04214818
  0.03704198 0.03986172 0.03689674 0.04520954 0.05655034 0.04319616
  0.03274052 0.04245302]
 [0.04225228 0.04683232 0.05900241 0.0574549  0.04973343 0.06937451
  0.04708667 0.05644529 0.06126207 0.06173931 0.04997469 0.06735531
  0.06021891 0.04723673 0.02980396 0.03684689 0.03435083 0.03535087
  0.03230942 0.03565564 0.0307696  0.0440567  0.04038134 0.02566069
  0.01880343 0.0300731 ]
 [0.04122824 0.06448929 0.06897978 0.03617238 0.02788388 0.04748528
  0.04914226 0.05370977 0.05916319 0.03909646 0.04034957 0.05110177
  0.04972655 0.02099965 0.01729667 0.05668523 0.04402822 0.03955397
  0.03958203 0.04231359 0.04119607 0.04410975 0.07445658 0.05493929
  0.04759423 0.04925144]
 [0.04194511 0.08248822 0.08140811 0.03372012 0.02636535 0.04018155
  0.05125887 0.05041885 0.06183931 0.03401083 0.03622568 0.04074743
  0.0399889  0.01760705 0.01637968 0.0675074  0.04607034 0.03988476
  0.04021737 0.04671318 0.04159415 0.04022902 0.07838263 0.0507926
  0.03547537 0.03697571]
 [0.04212591 0.04351706 0.04833683 0.02567944 0.02113206 0.02996696
  0.03945448 0.03857782 0.04724944 0.0279499  0.02974014 0.03300729
  0.0308244  0.01490575 0.01437428 0.05389322 0.03980507 0.03409932
  0.03760152 0.03991435 0.03810896 0.03881405 0.05876306 0.06087063
  0.05993236 0.05421449]
 [0.04251369 0.01689079 0.01844199 0.01343465 0.01170128 0.0166217
  0.01692174 0.01878504 0.0235206  0.01638333 0.01872618 0.01928514
  0.01786837 0.00737795 0.00771105 0.02391609 0.02404333 0.02387598
  0.03250533 0.03372424 0.035449   0.02725526 0.03168057 0.0653692
  0.08914673 0.08028767]
 [0.04228568 0.02516613 0.02646251 0.01847924 0.01633644 0.02390461
  0.0246327  0.02646338 0.02830473 0.02212444 0.0278043  0.02884243
  0.02689783 0.01029437 0.01072661 0.04284653 0.03733789 0.03442848
  0.04032069 0.03901205 0.03835694 0.03626309 0.02938817 0.06074815
  0.08935103 0.05881733]
 [0.04274291 0.02722514 0.02949189 0.02288934 0.01962415 0.03057203
  0.02965132 0.03620589 0.03275274 0.02977046 0.03457645 0.04243256
  0.04029948 0.0133573  0.01138195 0.03893118 0.04348671 0.03911583
  0.04148941 0.03739946 0.0380734  0.03830147 0.02322352 0.05481195
  0.0572588  0.03249034]
 [0.04209362 0.02117612 0.01880375 0.01549138 0.0125925  0.01812687
  0.0229332  0.02722205 0.0228502  0.01902456 0.02789765 0.02509578
  0.03053632 0.00762237 0.00764209 0.03691628 0.04761794 0.04403364
  0.05666795 0.05084215 0.06138958 0.03310693 0.01744005 0.08044251
  0.10422924 0.04992308]
 [0.04279331 0.02220105 0.02045276 0.01730091 0.0147569  0.02131655
  0.02314287 0.02957967 0.02503128 0.02221406 0.03100285 0.03191995
  0.03212375 0.00893306 0.0083461  0.0310656  0.04622713 0.03735563
  0.05161067 0.03987728 0.04276896 0.03409094 0.01687625 0.05282123
  0.08005146 0.04339731]
 [0.04292688 0.01735891 0.01599398 0.01227939 0.01093605 0.01562558
  0.02032739 0.02299782 0.02092486 0.01610568 0.03093079 0.02329256
  0.02630517 0.00633633 0.00644022 0.03229866 0.04691048 0.03857736
  0.05997282 0.04708759 0.05070219 0.03025652 0.01434013 0.0550326
  0.05648656 0.064022  ]
 [0.04108154 0.0335585  0.02686937 0.01939719 0.02059362 0.0222259
  0.04118503 0.03768459 0.03423968 0.0215129  0.04051498 0.02943612
  0.03773978 0.008995   0.00986879 0.05515172 0.04911106 0.07512338
  0.07043558 0.08222795 0.07911292 0.03780756 0.03110548 0.07785787
  0.06217145 0.08128848]
 [0.04337902 0.02351856 0.02374293 0.01951255 0.01489616 0.0238618
  0.02353779 0.02890259 0.02719775 0.02267447 0.03013484 0.03226846
  0.02974411 0.01075457 0.00968735 0.02600474 0.02963275 0.03039673
  0.0421583  0.03921445 0.03931979 0.0338079  0.01800386 0.03370523
  0.03678831 0.04245523]
 [0.04226763 0.03148212 0.03220756 0.05020526 0.04971221 0.04628091
  0.02807718 0.03149782 0.03719528 0.05568892 0.04341382 0.04483849
  0.03899262 0.07528999 0.09234355 0.03291155 0.03823002 0.03680631
  0.0331655  0.03274334 0.03252351 0.03947815 0.03333546 0.01606867
  0.01223599 0.02367811]
 [0.04197533 0.03356033 0.0311811  0.05506032 0.10023739 0.04437428
  0.02643204 0.02898275 0.03484797 0.06000309 0.04910013 0.04206683
  0.03278093 0.08077984 0.10422704 0.04011229 0.04999486 0.05109286
  0.03818118 0.0356586  0.03871391 0.03716527 0.03304326 0.0127069
  0.00781604 0.01987769]
 [0.04145005 0.02906197 0.02678015 0.0435143  0.09253866 0.03016827
  0.02205018 0.02748974 0.03029035 0.05056989 0.04611449 0.04216278
  0.031207   0.0318408  0.04427947 0.03297731 0.07432351 0.07750122
  0.05568306 0.04438215 0.06284101 0.03405182 0.03036304 0.02352611
  0.01705193 0.03016066]
 [0.04191875 0.03708313 0.03223501 0.0479689  0.06492135 0.03795445
  0.0301128  0.03099395 0.03762273 0.05008839 0.04493858 0.03742636
  0.03446439 0.03436362 0.03941012 0.02904852 0.04891891 0.05327602
  0.04257895 0.04154622 0.04505994 0.06033184 0.04350517 0.01872426
  0.0132813  0.0248629 ]]

-* TASK 10/20 | SAMPLE 32/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 157/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the given context sentences (4 and 5) that suggests Mary is in the office. In fact, context sentence 1 (from a previous part of the conversation) stated that Mary is in the office, but that information is not relevant to the current context.

Answer: unknown


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' given', ' context', ' sentences', ' (', '4', ' and', ' ', '5', ')', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' office', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '1', ' (', 'from', ' a', ' previous', ' part', ' of', ' the', ' conversation', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' office', ',', ' but', ' that', ' information', ' is', ' not', ' relevant', ' to', ' the', ' current', ' context', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(65, 32), x_tokens=32, y_tokens=65, max_supp_attn=0.0, attn_on_target=0.0154)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (65, 32)
DEBUG result.interpretability.attn_scores 2080 
 [[0.01413731 0.01621979 0.01607744 ... 0.00668144 0.03362536 0.04611066]
 [0.01452726 0.01563666 0.01460592 ... 0.00889589 0.04553523 0.04011216]
 [0.01479871 0.01573892 0.01668465 ... 0.01593116 0.03745265 0.02681473]
 ...
 [0.01491896 0.01522363 0.01194324 ... 0.00419762 0.05347522 0.03441866]
 [0.01527305 0.01457416 0.01124872 ... 0.005611   0.02960029 0.01660818]
 [0.01526896 0.0172314  0.01357402 ... 0.00489482 0.02300242 0.04128727]]

-* TASK 10/20 | SAMPLE 32/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 158/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the given context sentences (7 and 8) that suggests Mary is in the bedroom. In fact, context sentence 7 states that Mary went back to the office, which implies she is in the office, not in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' given', ' context', ' sentences', ' (', '7', ' and', ' ', '8', ')', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '7', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' implies', ' she', ' is', ' in', ' the', ' office', ',', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 38), x_tokens=38, y_tokens=59, max_supp_attn=0.0508, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 38)
DEBUG result.interpretability.attn_scores 2242 
 [[0.01573287 0.0220315  0.02401931 ... 0.01338202 0.02361059 0.01587977]
 [0.01586908 0.01758257 0.02111525 ... 0.02159487 0.025565   0.0219579 ]
 [0.01642109 0.0229521  0.02790326 ... 0.01040026 0.02076726 0.00906255]
 ...
 [0.01649891 0.02242075 0.01949764 ... 0.00930191 0.01981719 0.01563959]
 [0.01682628 0.01816595 0.01526646 ... 0.01207193 0.01663706 0.02143142]
 [0.01679516 0.01830004 0.01516314 ... 0.01064668 0.01569991 0.01747927]]

-* TASK 10/20 | SAMPLE 32/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 159/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 states that Fred is either in the kitchen or the office, but it does not provide a definitive location for Fred. Therefore, we can only conclude that Fred might be in the kitchen, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Fred', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Fred', ' might', ' be', ' in', ' the', ' kitchen', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 44), x_tokens=44, y_tokens=55, max_supp_attn=0.0909, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 44)
DEBUG result.interpretability.attn_scores 2420 
 [[0.01653855 0.02351821 0.02260848 ... 0.01124864 0.0145682  0.01535978]
 [0.01671152 0.02047888 0.02005041 ... 0.01927118 0.02345309 0.028538  ]
 [0.0172819  0.02429147 0.02551058 ... 0.01424879 0.02573291 0.02057973]
 ...
 [0.01745962 0.02142913 0.02275263 ... 0.00690481 0.00885162 0.01464379]
 [0.01784067 0.01688962 0.0172915  ... 0.00871026 0.00797447 0.01209718]
 [0.01784948 0.01620274 0.01673895 ... 0.008192   0.00909057 0.01320205]]

-* TASK 10/20 | SAMPLE 32/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 160/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 14 states that Bill is either in the cinema or the park, but it does not provide a definitive location for Bill. Therefore, we can only conclude that Bill might be in the cinema, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' park', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Bill', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' cinema', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 50), x_tokens=50, y_tokens=55, max_supp_attn=0.0, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 50)
DEBUG result.interpretability.attn_scores 2750 
 [[0.01681618 0.0236251  0.0254369  ... 0.02979408 0.03214258 0.02453444]
 [0.01715866 0.01998325 0.02113933 ... 0.01860218 0.02539809 0.02709989]
 [0.01752375 0.02629066 0.02945624 ... 0.03512511 0.03024312 0.02121124]
 ...
 [0.01777753 0.02818166 0.02590959 ... 0.06072611 0.03071099 0.02189302]
 [0.01815374 0.02129062 0.01808929 ... 0.042184   0.01770799 0.01945808]
 [0.01794059 0.02423182 0.02063074 ... 0.04341966 0.0316533  0.01926328]]
Model's predictions for the sample 32:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 2, Mary is  |
|          |                 |               in the school.               |
+----------+-----------------+--------------------------------------------+
|    no    |     unknown     |    There is no information in the given    |
|          |                 |      context sentences (4 and 5) that      |
|          |                 |  suggests Mary is in the office. In fact,  |
|          |                 |  context sentence 1 (from a previous part  |
|          |                 |  of the conversation) stated that Mary is  |
|          |                 |   in the office, but that information is   |
|          |                 |    not relevant to the current context.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    There is no information in the given    |
|          |                 |      context sentences (7 and 8) that      |
|          |                 |    suggests Mary is in the bedroom. In     |
|          |                 |    fact, context sentence 7 states that    |
|          |                 |    Mary went back to the office, which     |
|          |                 |  implies she is in the office, not in the  |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 10 states that Fred  |
|          |                 |  is either in the kitchen or the office,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |    location for Fred. Therefore, we can    |
|          |                 |  only conclude that Fred might be in the   |
|          |                 |     kitchen, but we cannot be certain.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 14 states that Bill  |
|          |                 |  is either in the cinema or the park, but  |
|          |                 |      it does not provide a definitive      |
|          |                 |    location for Bill. Therefore, we can    |
|          |                 |  only conclude that Bill might be in the   |
|          |                 |     cinema, but we cannot be certain.      |
+----------+-----------------+--------------------------------------------+

Metrics for sample 32:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.95    |
| Max attention distribution | 0.06 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 33/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 161/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Mary journeyed to the park, but there is no mention of her going to the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' park', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' her', ' going', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02580676 0.03907825 0.0486984  0.0670567  0.07028765 0.06753381
  0.0511439  0.06047658 0.04481738 0.05673601 0.04187509 0.05251127
  0.05714262 0.10128424 0.07693629 0.02642847 0.02841926 0.02917893
  0.02313109 0.02729055 0.02429594 0.03454226 0.04530449 0.0261777
  0.01195959 0.02030012]
 [0.02568854 0.07081342 0.05332967 0.04801302 0.03756987 0.04515218
  0.139747   0.07998945 0.05023682 0.04310388 0.07179348 0.04306914
  0.07193734 0.02243477 0.02145607 0.03916118 0.04129324 0.05016384
  0.03455273 0.04148268 0.04203913 0.03779845 0.03956983 0.04480137
  0.02700517 0.02723187]
 [0.02804202 0.05864073 0.03606084 0.05695381 0.03969066 0.03664555
  0.03013689 0.02275973 0.02015059 0.03354405 0.02481676 0.01598496
  0.0165821  0.03368101 0.0432258  0.01985879 0.01374009 0.01233447
  0.01331967 0.01520027 0.01501866 0.04247936 0.05691063 0.00617518
  0.00489454 0.01072799]
 [0.0265345  0.02124084 0.0222392  0.02293304 0.01793256 0.02205784
  0.021532   0.01978625 0.02036327 0.0225329  0.02322553 0.02146812
  0.01902663 0.01331383 0.01362061 0.02526163 0.02854125 0.02910523
  0.03315508 0.03304878 0.02996824 0.02608181 0.02956517 0.03405462
  0.04782813 0.06785155]
 [0.0265998  0.04300676 0.04716641 0.06958671 0.06676366 0.04749534
  0.03266163 0.03003035 0.03190681 0.04589691 0.03205068 0.02554207
  0.02462324 0.10907884 0.11357498 0.03335408 0.02689324 0.01959538
  0.01775588 0.02047024 0.02169134 0.03741086 0.06574342 0.01024818
  0.00685815 0.02405285]
 [0.02721492 0.02810109 0.02786935 0.05179659 0.05121654 0.04051761
  0.02366874 0.02309751 0.02639512 0.04112671 0.02894045 0.02832872
  0.0259211  0.11980621 0.13904436 0.03215772 0.02942006 0.02308147
  0.01979289 0.02104732 0.02079297 0.03200668 0.03730665 0.00878409
  0.00572682 0.0152948 ]
 [0.02761597 0.03164098 0.03524634 0.05510991 0.05546673 0.05106467
  0.03128618 0.03160206 0.03445638 0.04905623 0.03388462 0.04464417
  0.03877726 0.09329643 0.08685723 0.02708844 0.02715348 0.02290667
  0.01902886 0.02065113 0.01981849 0.02925714 0.03407427 0.01267144
  0.00792848 0.01443467]
 [0.0265801  0.03818752 0.04239004 0.04124917 0.04719159 0.04589076
  0.0349749  0.03995144 0.03923651 0.04259745 0.0340634  0.04943284
  0.04088242 0.05307546 0.04905658 0.03475997 0.03484503 0.02948297
  0.02501194 0.02641586 0.02726001 0.03315724 0.04621616 0.02779758
  0.02577743 0.02811228]
 [0.02772691 0.0368266  0.04305543 0.04569027 0.04627828 0.05227648
  0.03722106 0.04119277 0.04473795 0.04821819 0.03478916 0.04922889
  0.04417231 0.04234931 0.02865723 0.02491974 0.0270241  0.0252998
  0.02184135 0.02328169 0.02226158 0.03420129 0.03765699 0.01985464
  0.01183887 0.01876743]
 [0.02700777 0.05101658 0.0538267  0.02834755 0.02517746 0.03502374
  0.03994256 0.04057211 0.04180658 0.02814947 0.02687328 0.03445092
  0.0350287  0.01713184 0.01550443 0.03973187 0.03476143 0.02764487
  0.02593008 0.02796063 0.02905099 0.03244223 0.06803601 0.03879578
  0.03303381 0.03294187]
 [0.02762906 0.03961817 0.04506603 0.02411943 0.02241539 0.02636576
  0.04119297 0.03360021 0.03809753 0.02349027 0.02331314 0.02484065
  0.02570513 0.01367655 0.01383949 0.04100181 0.03313025 0.02606844
  0.0254473  0.02841216 0.02831989 0.02800407 0.05391352 0.02907829
  0.03738593 0.03077379]
 [0.02794074 0.01519639 0.016581   0.0113393  0.01070981 0.01463178
  0.01512729 0.01564111 0.01821087 0.01247357 0.0134319  0.01282101
  0.01371694 0.00620336 0.00692475 0.01792032 0.01882653 0.01715633
  0.01985135 0.02207406 0.02407815 0.01846698 0.03361396 0.03757838
  0.05402741 0.056244  ]
 [0.02758559 0.02332932 0.02442295 0.01603769 0.01525172 0.01973384
  0.0228339  0.02193746 0.02276166 0.01691077 0.02061255 0.01865721
  0.01999437 0.00915253 0.00982478 0.03415643 0.02921092 0.02594561
  0.02467796 0.02549421 0.02497811 0.02700863 0.02990976 0.03900471
  0.05838379 0.04962741]
 [0.0276484  0.02418222 0.0244943  0.01833328 0.01639028 0.02445176
  0.02657044 0.02751181 0.02498453 0.02075968 0.02525245 0.02653471
  0.02801494 0.01030632 0.00941983 0.03081492 0.03389001 0.02772034
  0.02515665 0.02427868 0.02588608 0.02869129 0.02010777 0.03630491
  0.05563652 0.0355324 ]
 [0.02709257 0.01908783 0.01664272 0.01328327 0.01126493 0.01482337
  0.01977682 0.01950336 0.01870797 0.0142898  0.02085881 0.01663265
  0.02010646 0.0070886  0.00695549 0.03789506 0.03506657 0.03687845
  0.03429111 0.03629827 0.03644295 0.0251778  0.01472153 0.04356317
  0.10632455 0.0500938 ]
 [0.02832335 0.01948016 0.01942773 0.01519578 0.0137476  0.019548
  0.02299481 0.02241985 0.02156374 0.01694685 0.02143895 0.01985495
  0.02130765 0.00823813 0.00735182 0.03349337 0.0202403  0.02826718
  0.02244718 0.03209597 0.02654458 0.02095047 0.01603852 0.03066562
  0.07480941 0.02649679]
 [0.02817149 0.01722258 0.01560776 0.01235131 0.01085136 0.01449767
  0.01837102 0.01837287 0.01840304 0.01382638 0.02290941 0.018236
  0.01978663 0.00678238 0.006429   0.03979258 0.02507979 0.03593929
  0.02882474 0.03980957 0.03264575 0.020821   0.01310342 0.03278566
  0.06253883 0.03731688]
 [0.02797643 0.01646981 0.01490309 0.01121495 0.00989497 0.01324946
  0.01765479 0.01756855 0.01808018 0.01283987 0.02431476 0.01658123
  0.01836536 0.00612437 0.00633935 0.03340123 0.02846327 0.03153041
  0.03282681 0.03528362 0.03019307 0.02187944 0.01294615 0.03899024
  0.04612687 0.05851769]
 [0.0274153  0.02117854 0.0190293  0.01398224 0.0131137  0.01693183
  0.02250751 0.02165035 0.02346503 0.01571753 0.02562066 0.01899868
  0.02089834 0.00746833 0.00798007 0.02448642 0.03036297 0.02593778
  0.03300096 0.03011595 0.03142788 0.02529537 0.02071064 0.07509707
  0.03689535 0.05457866]
 [0.02841057 0.01879339 0.01754781 0.01428812 0.01185329 0.01688968
  0.01969407 0.0198137  0.02097568 0.01587987 0.02687091 0.02049167
  0.02012086 0.00791186 0.00758421 0.02259985 0.02317212 0.02280663
  0.03225696 0.02902644 0.0274519  0.02453804 0.01293272 0.02917507
  0.02023938 0.04641924]
 [0.02869045 0.02040574 0.02277632 0.01857342 0.01517171 0.0232275
  0.02224088 0.02794353 0.0263554  0.02281179 0.0251897  0.03144645
  0.02755421 0.01144492 0.00848444 0.01889312 0.02135956 0.02087668
  0.02188345 0.02066647 0.02178697 0.02739374 0.01435329 0.02681986
  0.01589664 0.01983204]
 [0.02850687 0.02465836 0.02539538 0.01852196 0.01536496 0.02355704
  0.02317133 0.02808286 0.02728939 0.0216116  0.02453734 0.03112866
  0.02621625 0.01058945 0.00868633 0.0200445  0.02209983 0.02093008
  0.02303134 0.02133795 0.0227429  0.0270293  0.01774677 0.02547222
  0.01626863 0.01762172]
 [0.02870045 0.02467764 0.02584352 0.01734844 0.01456982 0.02422377
  0.02464333 0.02896425 0.02833741 0.02113014 0.02566328 0.03533146
  0.02716444 0.01027777 0.00851099 0.02029758 0.02479178 0.02380525
  0.02973512 0.02747934 0.02564685 0.02438393 0.02030723 0.02293658
  0.01472179 0.02078933]
 [0.02873567 0.02520199 0.02716147 0.02026724 0.01735528 0.03048208
  0.02346923 0.03055074 0.03309191 0.02608489 0.02276616 0.03707463
  0.0302723  0.01260175 0.00880369 0.01648158 0.02060246 0.01935863
  0.0210303  0.02003359 0.0208208  0.02465032 0.02123041 0.02874364
  0.01576183 0.01694831]
 [0.0282511  0.03756973 0.03458656 0.0220897  0.01750544 0.03180118
  0.03061591 0.03899723 0.03637817 0.0291679  0.02907187 0.04502436
  0.03958045 0.01326522 0.00960146 0.0239505  0.0239245  0.02500075
  0.02686908 0.0264526  0.02667954 0.02826699 0.02576188 0.02753077
  0.01726942 0.01694155]
 [0.02892951 0.0240376  0.02833351 0.02048451 0.01580931 0.02966591
  0.02703016 0.03146378 0.03366717 0.02570332 0.0253448  0.03896976
  0.03203088 0.01241522 0.00841342 0.02015021 0.0205741  0.02004254
  0.02135202 0.02188666 0.02320856 0.02478343 0.01813995 0.02046877
  0.01327734 0.0123908 ]
 [0.02833407 0.01741467 0.0182116  0.01274153 0.01006852 0.01537994
  0.01883901 0.02085869 0.02101796 0.01572585 0.02344101 0.01968682
  0.02269806 0.0081233  0.00630535 0.02802744 0.02632578 0.0266167
  0.02768871 0.02639215 0.03077961 0.02343164 0.01229405 0.02925104
  0.02504625 0.01941   ]
 [0.02849321 0.01881342 0.01891466 0.01373924 0.01002544 0.01435493
  0.0198945  0.02224146 0.02096671 0.01553299 0.02245833 0.01866761
  0.02268674 0.00785232 0.00613583 0.03166322 0.02693429 0.02994792
  0.02851897 0.02973093 0.03456786 0.02329225 0.01192452 0.03127522
  0.03238795 0.01832807]
 [0.02883434 0.01663371 0.01681589 0.01312032 0.00975096 0.01420262
  0.01604212 0.01843304 0.02000966 0.01560514 0.0215905  0.01765186
  0.0201548  0.00786994 0.00576232 0.02601635 0.02132294 0.02683422
  0.02901115 0.04422624 0.04141388 0.02121273 0.01128904 0.02461073
  0.02325796 0.01678736]
 [0.0285211  0.01598403 0.01597894 0.01154085 0.00902598 0.01276473
  0.01549874 0.01628711 0.01862213 0.01450486 0.02427924 0.01549558
  0.01866874 0.00737112 0.00578514 0.031273   0.02609507 0.0281084
  0.03287382 0.03836618 0.03555482 0.02163075 0.01178196 0.03105996
  0.02271363 0.02180831]
 [0.02784909 0.01757783 0.01700508 0.01245137 0.00990359 0.01422944
  0.01546472 0.01786515 0.02082834 0.01625171 0.02364701 0.01625883
  0.01962414 0.00745922 0.00630046 0.03267245 0.02773216 0.02436918
  0.03163518 0.02561744 0.03081447 0.02246084 0.0137616  0.04083985
  0.02392174 0.03203569]
 [0.02868065 0.02068534 0.02118019 0.01628212 0.01246134 0.01789745
  0.01811358 0.02173057 0.02387117 0.01993829 0.02333445 0.020093
  0.02295002 0.01043999 0.00846674 0.02272651 0.02248296 0.02541408
  0.03081392 0.02547655 0.02942646 0.02497508 0.01602701 0.02238169
  0.01405631 0.01780422]
 [0.0278049  0.02613721 0.02762965 0.04331749 0.04581547 0.03572113
  0.0217168  0.02473361 0.02995683 0.04746617 0.03124678 0.03168911
  0.03330714 0.06472757 0.08382285 0.02228129 0.02733958 0.0263771
  0.02322715 0.02162114 0.02284685 0.03040075 0.02965979 0.01043065
  0.00678606 0.01672652]
 [0.0275754  0.02823756 0.02769538 0.04926087 0.09775084 0.03661203
  0.01964626 0.02269007 0.02776087 0.05130952 0.03683502 0.03011985
  0.02515596 0.07369904 0.09476884 0.02775436 0.03814225 0.03645302
  0.02941463 0.02465068 0.02702367 0.02847104 0.03022303 0.00795922
  0.00561655 0.01476503]
 [0.02742671 0.02159831 0.02211494 0.03445817 0.05600708 0.0230953
  0.01500869 0.02019686 0.02398136 0.04198834 0.03339683 0.02910122
  0.02496056 0.02541857 0.02950087 0.02178084 0.04747118 0.05908484
  0.06751363 0.0354208  0.03677908 0.02435995 0.02226098 0.01566339
  0.01039612 0.01672019]
 [0.02765574 0.02725561 0.02675181 0.0389207  0.05034631 0.02800386
  0.01956627 0.02148357 0.02850781 0.04107121 0.03026174 0.02395086
  0.02486492 0.02804027 0.03006881 0.01770318 0.03326761 0.03973654
  0.04310098 0.03090322 0.02974212 0.04304686 0.03485679 0.01295273
  0.0074027  0.01577472]]

-* TASK 10/20 | SAMPLE 33/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 162/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 4, Julie journeyed to the cinema, but there is no mention of her being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0312, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02943316 0.04945279 0.05001273 ... 0.03681229 0.0081714  0.00572028]
 [0.03025774 0.04675833 0.04584547 ... 0.04659308 0.01195242 0.0076861 ]
 [0.03069344 0.04457564 0.0489965  ... 0.06228938 0.02050996 0.01085328]
 ...
 [0.03064732 0.04247206 0.03714853 ... 0.01645708 0.00665043 0.00541557]
 [0.03100727 0.03529113 0.02862641 ... 0.01175444 0.00987102 0.00854809]
 [0.03127242 0.03496664 0.02832794 ... 0.00961739 0.00890611 0.00751606]]

-* TASK 10/20 | SAMPLE 33/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 163/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 8, Fred is explicitly stated to be in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Fred', ' is', ' explicitly', ' stated', ' to', ' be', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(23, 38), x_tokens=38, y_tokens=23, max_supp_attn=0.0, attn_on_target=0.0435)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (23, 38)
DEBUG result.interpretability.attn_scores 874 
 [[0.04103443 0.05914532 0.05556851 0.07477623 0.05891398 0.06271511
  0.0474337  0.05055175 0.05529555 0.07071935 0.04586427 0.04658948
  0.05114125 0.12144217 0.10740177 0.04155765 0.03812645 0.03653963
  0.02809749 0.03058413 0.03081786 0.0420447  0.06607388 0.02753746
  0.0217125  0.03948355 0.04324638 0.05210716 0.12100809 0.04283741
  0.01598528 0.01330799 0.01179566 0.07699385 0.06367644 0.03769115
  0.02764747 0.01954242]
 [0.04139362 0.06475083 0.06137443 0.06769469 0.05269725 0.08066966
  0.1135805  0.11875795 0.07792772 0.06601642 0.04940273 0.07769489
  0.10041546 0.0739145  0.06563262 0.03795329 0.03353124 0.0390784
  0.0343584  0.03888343 0.03218574 0.04421231 0.05319912 0.04575469
  0.03444696 0.03916481 0.03837681 0.04099539 0.0910169  0.07525896
  0.04110254 0.03380257 0.02710429 0.05181159 0.05455518 0.03965492
  0.0409556  0.03778704]
 [0.04275728 0.06293242 0.06281285 0.08684491 0.07423479 0.08589119
  0.05533166 0.05687512 0.05986069 0.07697202 0.05029844 0.06162474
  0.06140057 0.14832444 0.1020209  0.04245239 0.03128707 0.03209129
  0.02432916 0.02792775 0.02597242 0.04462338 0.05587355 0.02807344
  0.02267698 0.03559396 0.04634783 0.03809596 0.07449517 0.08028945
  0.03007337 0.02074767 0.01694753 0.07088055 0.04939395 0.03181437
  0.02438276 0.01801637]
 [0.04156301 0.05125972 0.05106482 0.04212491 0.03316778 0.04487618
  0.04431935 0.04756295 0.0457511  0.04275344 0.03721552 0.04282112
  0.04277575 0.03522722 0.03181748 0.04156781 0.0344713  0.03365699
  0.02988204 0.03169961 0.02999896 0.04517656 0.05914374 0.03813663
  0.03984163 0.04292989 0.05002899 0.03883097 0.04598885 0.11265633
  0.05667457 0.04014229 0.03216063 0.03815876 0.05745911 0.04826903
  0.04560851 0.03108301]
 [0.04302726 0.03939319 0.03693622 0.02736937 0.01992633 0.03012982
  0.03152163 0.0322556  0.03600106 0.02650668 0.03006951 0.02639117
  0.02862699 0.01707039 0.01881763 0.03145816 0.02357919 0.02468807
  0.02639757 0.02978276 0.02666003 0.03472437 0.04358341 0.02745251
  0.03118201 0.03554914 0.04124638 0.02487797 0.03001303 0.0743104
  0.04068062 0.03335619 0.03745214 0.0245998  0.04204148 0.04221945
  0.04395329 0.04045054]
 [0.04257721 0.05727682 0.05816177 0.03554402 0.02569867 0.04310544
  0.04858436 0.04700915 0.05458508 0.03400083 0.03250744 0.03679609
  0.03814432 0.02667826 0.02376451 0.04177773 0.03012786 0.02848251
  0.02816819 0.03171321 0.02824733 0.04512576 0.06975053 0.03833125
  0.04229438 0.0418915  0.05869565 0.02930021 0.03872943 0.11544157
  0.05111014 0.0428164  0.02913271 0.02679622 0.07020217 0.05018435
  0.0474142  0.03857742]
 [0.04315056 0.04663419 0.04316378 0.02816208 0.02096245 0.02929773
  0.03966539 0.03358592 0.04289109 0.02673009 0.03018302 0.02579362
  0.02835377 0.01803701 0.01983149 0.03861016 0.02953829 0.02819168
  0.03066934 0.03487661 0.02900472 0.03845239 0.04716169 0.02969684
  0.04030541 0.03746405 0.0411884  0.02456258 0.02805746 0.06257289
  0.02880617 0.02578579 0.02447324 0.01958992 0.04720272 0.05334318
  0.04857669 0.03986955]
 [0.04388923 0.02818653 0.02659117 0.019662   0.01530418 0.02111967
  0.02306724 0.02362911 0.02828871 0.019465   0.02704183 0.0227347
  0.02545544 0.01211265 0.01442424 0.0328117  0.02663481 0.02932206
  0.03543812 0.03713848 0.03196174 0.03148734 0.02592584 0.03278298
  0.03806263 0.03358193 0.02927536 0.02636423 0.02499974 0.02757327
  0.02753318 0.02551045 0.03530614 0.0150269  0.02950834 0.04346942
  0.0434163  0.04483061]
 [0.04346059 0.0359088  0.03761532 0.02702169 0.02103137 0.03096645
  0.03585146 0.03356541 0.03886409 0.02812994 0.03251485 0.03094268
  0.03066546 0.0182815  0.01917611 0.0376367  0.03330665 0.03485504
  0.03764684 0.03981217 0.03480493 0.04133591 0.03703003 0.03813663
  0.0546135  0.04307681 0.04602899 0.03198577 0.0315428  0.05923425
  0.05797068 0.0455378  0.04594795 0.02316535 0.04332564 0.0515409
  0.05513856 0.04257267]
 [0.0436184  0.04247034 0.04209662 0.03352191 0.02592681 0.03917852
  0.04657746 0.04342259 0.04326295 0.0360087  0.04102788 0.04519605
  0.0456205  0.02346916 0.02132479 0.04399469 0.04144109 0.0417388
  0.04442298 0.04293229 0.03770871 0.05016125 0.03492909 0.04521871
  0.0624217  0.04151799 0.04588406 0.03723506 0.03368278 0.05610565
  0.07651783 0.0661464  0.05238596 0.02590141 0.04120179 0.04427527
  0.06467155 0.04306689]
 [0.04361692 0.03729167 0.03379633 0.02635414 0.02044914 0.02856314
  0.03949792 0.03381447 0.03541757 0.02491452 0.03793604 0.03395456
  0.03681838 0.01579938 0.01610667 0.05047628 0.04315727 0.05311571
  0.06456928 0.07709287 0.05624312 0.04432742 0.02678515 0.05295416
  0.08779371 0.04260368 0.03478261 0.03564999 0.0241833  0.02614421
  0.05161297 0.06536906 0.05238596 0.01528107 0.03118124 0.05396816
  0.07346546 0.06137753]
 [0.04442303 0.03676466 0.03454632 0.02697997 0.02255466 0.03060822
  0.0384391  0.03701132 0.03700781 0.02835618 0.0429649  0.04216382
  0.03864256 0.01709792 0.01664109 0.044947   0.04912814 0.04099162
  0.06089735 0.05248806 0.04833875 0.04441376 0.02631188 0.0600038
  0.06259475 0.03895315 0.03672464 0.03726755 0.02445504 0.02373878
  0.06182287 0.06554984 0.05320908 0.0170987  0.03031045 0.04048177
  0.06038156 0.05598639]
 [0.04434973 0.0545873  0.05251444 0.04133776 0.0323693  0.04749262
  0.05477524 0.05578509 0.0501439  0.04645244 0.05357535 0.06259225
  0.05708523 0.02769669 0.02426961 0.05747169 0.05397059 0.05600749
  0.05186323 0.05058853 0.04560297 0.04995198 0.04413834 0.08054568
  0.07895643 0.04500417 0.05202898 0.04700812 0.03702376 0.03566811
  0.05962657 0.08873105 0.05870637 0.02476394 0.04958184 0.05306702
  0.05445257 0.04692255]
 [0.04603567 0.04248995 0.0438578  0.03418946 0.02751901 0.03890871
  0.04594541 0.04357496 0.04078992 0.03345786 0.04449724 0.04498627
  0.04306772 0.02063732 0.01903976 0.04597633 0.04006814 0.03694934
  0.03866766 0.03707542 0.03570278 0.04298409 0.03289496 0.0546347
  0.04932037 0.03509842 0.0435942  0.0339837  0.02854029 0.03051197
  0.05008713 0.06769275 0.04488965 0.02119565 0.03579824 0.04001183
  0.04090397 0.03842462]
 [0.04507175 0.02887469 0.03027211 0.02530554 0.01931797 0.02675612
  0.02947961 0.03054144 0.03040499 0.02569787 0.03359316 0.03206404
  0.03272269 0.01424179 0.01537065 0.03811835 0.03705418 0.03693197
  0.04283124 0.0431586  0.03790608 0.04116963 0.02300828 0.04934439
  0.04926268 0.03782761 0.03365218 0.03710376 0.02399587 0.01899409
  0.04425538 0.05799057 0.0497402  0.01658652 0.02703851 0.04053668
  0.0428026  0.04757145]
 [0.04487693 0.03311694 0.033287   0.02569772 0.02146863 0.02781494
  0.03932235 0.0362817  0.03159616 0.02569787 0.04859584 0.0391049
  0.03912472 0.0147081  0.01603116 0.05397737 0.05689942 0.04836192
  0.06284365 0.05955687 0.05419221 0.04246679 0.02458213 0.06876333
  0.0569878  0.04759391 0.03495652 0.04194427 0.02346088 0.01863347
  0.04633898 0.06237094 0.05432618 0.01541886 0.02625973 0.04389415
  0.04680198 0.06840789]
 [0.04451966 0.02701055 0.03013218 0.02185099 0.01892348 0.02501032
  0.03452253 0.03111576 0.03091895 0.02290383 0.04476621 0.03420376
  0.03456829 0.0128882  0.01437585 0.04992691 0.05527018 0.04483727
  0.06414618 0.06102233 0.05136187 0.04221809 0.02316975 0.06678621
  0.05065634 0.06191466 0.02936232 0.04834819 0.02299078 0.01744514
  0.05191352 0.05939785 0.07825556 0.01546058 0.02525936 0.04682365
  0.04246035 0.09198895]
 [0.04311118 0.03103066 0.03374222 0.02402052 0.02021863 0.02964463
  0.03704264 0.03533524 0.03743711 0.0262663  0.04184464 0.03376259
  0.03882203 0.01453809 0.01614993 0.04570545 0.04514334 0.04299447
  0.06020646 0.059986   0.0468607  0.04592125 0.03234374 0.06721716
  0.05326599 0.08247569 0.03113043 0.06427881 0.03304163 0.01733292
  0.05592465 0.05866361 0.11047499 0.02194993 0.03435988 0.05749843
  0.04986015 0.10014169]
 [0.04489316 0.03122448 0.03834666 0.03327437 0.02531369 0.03733749
  0.03449552 0.03895404 0.03551734 0.03199014 0.03879475 0.03993256
  0.0395533  0.02313562 0.01972446 0.0349093  0.03034521 0.03079996
  0.03559344 0.03649542 0.03508218 0.04268351 0.02830333 0.03526828
  0.02701025 0.05036044 0.0335942  0.03898528 0.0304995  0.0261797
  0.07831676 0.05379653 0.1005975  0.03704655 0.02857147 0.0355562
  0.03125443 0.04155593]
 [0.0433541  0.04166458 0.04682419 0.06684635 0.05870723 0.05879499
  0.03885777 0.04243804 0.04890739 0.07151684 0.05156183 0.05148299
  0.04933582 0.10075467 0.11681902 0.03949475 0.03864448 0.04243385
  0.03256314 0.03427064 0.03581202 0.04424074 0.05027784 0.02507534
  0.02063495 0.04105731 0.04823188 0.0542215  0.06530807 0.02661801
  0.0247748  0.02015667 0.02245952 0.11438076 0.04659498 0.03320646
  0.02675495 0.02377724]
 [0.04300679 0.05384251 0.05612261 0.09993714 0.20551807 0.07988065
  0.04262038 0.04476755 0.04945158 0.09878708 0.07248908 0.06671912
  0.04822953 0.13068737 0.16558108 0.05435744 0.06644937 0.06849831
  0.04498105 0.04047379 0.05968855 0.04271122 0.06933479 0.02094966
  0.01979275 0.04454848 0.07298551 0.05855575 0.06691184 0.02168006
  0.01373408 0.01331633 0.01397841 0.11970136 0.0581446  0.03421418
  0.02256379 0.01609231]
 [0.04296769 0.04409058 0.04282423 0.06006798 0.0994368  0.04306917
  0.0341903  0.03784642 0.03803875 0.06774997 0.05949252 0.05213902
  0.04189179 0.04567055 0.06760462 0.05115009 0.0977772  0.10191203
  0.07262223 0.05589261 0.12447866 0.04265971 0.05902496 0.03980791
  0.03312021 0.04068877 0.05747826 0.07330196 0.04259449 0.01705239
  0.01902109 0.02196166 0.02561973 0.09249122 0.04727399 0.04134415
  0.03759501 0.02825351]
 [0.04330168 0.05005324 0.04834843 0.07141625 0.08033983 0.05816922
  0.04487848 0.04531842 0.05164042 0.06890662 0.05376288 0.05030951
  0.04753843 0.06758697 0.06807454 0.0436688  0.06404853 0.06752158
  0.04880507 0.04654832 0.06136765 0.0569078  0.06715404 0.02752819
  0.02304617 0.04162008 0.05115942 0.08499578 0.05746028 0.01372094
  0.01611677 0.01784967 0.02265061 0.11570048 0.06105889 0.03693536
  0.0289383  0.02370367]]

-* TASK 10/20 | SAMPLE 33/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 164/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 11, Julie went to the park, which implies that she is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '11', ',', ' Julie', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03229899 0.04171275 0.04233108 ... 0.09160929 0.01405877 0.02117972]
 [0.03327839 0.06282166 0.05973317 ... 0.04035283 0.03091233 0.0325344 ]
 [0.03369724 0.04573599 0.05097573 ... 0.08153831 0.01921677 0.03127224]
 ...
 [0.03397897 0.04917141 0.04259155 ... 0.03110843 0.01033813 0.01222518]
 [0.03434499 0.03679692 0.02961945 ... 0.01544608 0.01247879 0.01278163]
 [0.03400145 0.04233104 0.03236769 ... 0.01602259 0.01006763 0.01182516]]

-* TASK 10/20 | SAMPLE 33/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 165/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 13, Fred travelled to the kitchen, but there is no mention of him being in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Fred', ' travelled', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' him', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03027664 0.04793014 0.04648553 ... 0.0498031  0.02217361 0.0347636 ]
 [0.03098968 0.0343441  0.0330422  ... 0.03184797 0.03055398 0.032192  ]
 [0.03156304 0.04967941 0.04984837 ... 0.0383183  0.01903585 0.02770749]
 ...
 [0.03162569 0.04146015 0.04385688 ... 0.04782802 0.01771542 0.03120828]
 [0.03223231 0.03212835 0.03221599 ... 0.0349184  0.022123   0.03011988]
 [0.03212881 0.03280241 0.03271612 ... 0.03956027 0.02166292 0.03087238]]
Model's predictions for the sample 33:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 2, Mary journeyed   |
|          |                 |  to the park, but there is no mention of   |
|          |                 |          her going to the cinema.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 4, Julie journeyed  |
|          |                 |   to the cinema, but there is no mention   |
|          |                 |        of her being in the kitchen.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |      According to sentence 8, Fred is      |
|          |                 |    explicitly stated to be in the park.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 11, Julie went to   |
|          |                 |    the park, which implies that she is     |
|          |                 |           currently in the park.           |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 13, Fred travelled  |
|          |                 |  to the kitchen, but there is no mention   |
|          |                 |        of him being in the bedroom.        |
+----------+-----------------+--------------------------------------------+

Metrics for sample 33:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 34/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 166/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: From sentence 1, we know that Fred is either in the cinema or the school. We don't have any information that confirms Fred's exact location. Sentence 2 informs us that Julie travelled to the school, but it doesn't provide any information about Fred's location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' that', ' Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' school', '.', ' We', ' don', "'t", ' have', ' any', ' information', ' that', ' confirms', ' Fred', "'s", ' exact', ' location', '.', ' Sentence', ' ', '2', ' informs', ' us', ' that', ' Julie', ' travelled', ' to', ' the', ' school', ',', ' but', ' it', ' doesn', "'t", ' provide', ' any', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(66, 26), x_tokens=26, y_tokens=66, max_supp_attn=0.0303, attn_on_target=0.0152)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (66, 26)
DEBUG result.interpretability.attn_scores 1716 
 [[0.01376673 0.02728396 0.02943342 ... 0.00753708 0.0104274  0.01354957]
 [0.01355462 0.0585843  0.04088807 ... 0.01325165 0.01531693 0.01573643]
 [0.01495035 0.03779547 0.02193491 ... 0.00234555 0.0037374  0.00724045]
 ...
 [0.01475856 0.01674064 0.01705853 ... 0.00266314 0.00410377 0.00909223]
 [0.01475396 0.01348224 0.0133327  ... 0.0093251  0.00922456 0.01072693]
 [0.0149785  0.01368703 0.01314923 ... 0.00609429 0.00685594 0.00862113]]

-* TASK 10/20 | SAMPLE 34/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 167/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From sentence 2 (previous part), we know that Julie travelled to the school. There is no information that suggests Julie left the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '2', ' (', 'previous', ' part', '),', ' we', ' know', ' that', ' Julie', ' travelled', ' to', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Julie', ' left', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 32), x_tokens=32, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 32)
DEBUG result.interpretability.attn_scores 1120 
 [[0.02668881 0.03484292 0.03702778 ... 0.06501999 0.01217872 0.01666214]
 [0.02725875 0.03472707 0.03561579 ... 0.07337426 0.02167415 0.02645252]
 [0.02802147 0.03252136 0.03651893 ... 0.06843509 0.02280039 0.02380919]
 ...
 [0.02803066 0.03668045 0.03292949 ... 0.02376767 0.01047307 0.0141091 ]
 [0.02840183 0.02925122 0.02410181 ... 0.01232141 0.01489915 0.02037479]
 [0.02835316 0.03163243 0.02658876 ... 0.01280986 0.01093517 0.01462932]]

-* TASK 10/20 | SAMPLE 34/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 168/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Bill is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.04981343 0.06326649 0.07260138 0.08579019 0.06448452 0.07036135
  0.05566197 0.06220827 0.06793488 0.07217218 0.04629802 0.05587603
  0.0561532  0.10980469 0.11771461 0.04444768 0.03834721 0.04195473
  0.03480839 0.04421272 0.03547207 0.05134062 0.08123619 0.01938746
  0.03223371 0.06181357 0.06721636 0.06727695 0.14933321 0.09637688
  0.02291321 0.03202372 0.03636667 0.03490223 0.02534843 0.02054683
  0.03784164 0.07852609]
 [0.05074103 0.04926056 0.04991625 0.04822373 0.03566579 0.04730745
  0.0452496  0.06162851 0.04924113 0.04256569 0.04034713 0.05035393
  0.05997514 0.03786873 0.0596848  0.04162484 0.03559367 0.04541812
  0.04200673 0.05164841 0.03964591 0.05025656 0.04440459 0.03647734
  0.04403145 0.05296547 0.05408027 0.04649774 0.0768358  0.08047858
  0.03523296 0.04844456 0.05863917 0.04491268 0.0510791  0.04783382
  0.03952935 0.03950448]
 [0.05194712 0.06890295 0.07742392 0.10105113 0.08592994 0.10482459
  0.06579822 0.07097702 0.07881318 0.09003317 0.05611999 0.07759579
  0.07672622 0.16098677 0.11448572 0.04534576 0.03538605 0.03794046
  0.03217743 0.03945862 0.03138788 0.05558302 0.06676275 0.01959842
  0.02925524 0.05107345 0.06689301 0.04966354 0.09425101 0.11475618
  0.04459366 0.04521997 0.06728112 0.06224489 0.04227839 0.02610989
  0.06302702 0.07828919]
 [0.05052335 0.06410431 0.07192712 0.04874182 0.03844242 0.05506102
  0.05375357 0.06004698 0.05643629 0.04749097 0.04305336 0.05430028
  0.05289252 0.03815303 0.03635532 0.05225931 0.03918816 0.04048573
  0.03667907 0.04436697 0.03570538 0.05857535 0.08007687 0.03577344
  0.05507432 0.06205615 0.06733762 0.04681904 0.05913618 0.12557307
  0.06924702 0.06776848 0.116314   0.06788947 0.08520021 0.0467888
  0.0568292  0.04614953]
 [0.05173096 0.06522524 0.06977002 0.04122783 0.0304062  0.04768233
  0.056749   0.05265514 0.05768112 0.03791839 0.0387072  0.04187601
  0.04337106 0.02843201 0.02569078 0.05176193 0.03640106 0.03618732
  0.03718212 0.04527072 0.03599887 0.04959701 0.07486309 0.03604915
  0.06031738 0.05958569 0.07267289 0.03495454 0.04159456 0.09583292
  0.04998454 0.04784172 0.06687313 0.05131246 0.10853875 0.05846852
  0.06599243 0.03121021]
 [0.05293402 0.03370611 0.03373666 0.02312263 0.0176977  0.0263115
  0.02958386 0.02836523 0.03460696 0.02339703 0.02691803 0.02519444
  0.02922586 0.01553292 0.0147264  0.03379128 0.02921103 0.02988379
  0.03204596 0.03973152 0.03180661 0.0344373  0.038751   0.03516145
  0.05462687 0.04409498 0.03560891 0.02637383 0.02330505 0.03790291
  0.0242649  0.02872584 0.02457207 0.01991435 0.04040189 0.03320163
  0.02212779 0.01560193]
 [0.05182192 0.06169198 0.06590093 0.04155815 0.03158081 0.05268764
  0.05986677 0.05817984 0.05496902 0.04194709 0.0450628  0.05478418
  0.05124213 0.02966059 0.02683816 0.06233858 0.04710171 0.05218807
  0.04807894 0.05381584 0.04514225 0.06190333 0.07107126 0.06046415
  0.07390834 0.06649325 0.07643183 0.04233717 0.04679821 0.06807889
  0.07954717 0.05935711 0.08389741 0.10056785 0.09914728 0.06683838
  0.08306344 0.03045684]
 [0.05345702 0.07740532 0.07937558 0.0612941  0.04374562 0.0718919
  0.07751432 0.08066655 0.0682942  0.06918491 0.06740943 0.09250945
  0.0780158  0.04477924 0.0334135  0.06371113 0.05558358 0.05791259
  0.05425548 0.05658445 0.04900664 0.06022017 0.06564185 0.0743959
  0.06593958 0.06045893 0.07760398 0.05349191 0.05217491 0.06036126
  0.09918424 0.07006636 0.09005433 0.1240975  0.1037029  0.07359602
  0.11452927 0.04261144]
 [0.05451296 0.05602951 0.05708815 0.04263953 0.0348081  0.0506762
  0.06321872 0.05625301 0.04916413 0.04516928 0.05541264 0.05658004
  0.05730914 0.02996723 0.02487239 0.05924164 0.05043406 0.04695144
  0.05105574 0.05043813 0.04662808 0.05526904 0.04787403 0.06306043
  0.06165633 0.04761034 0.05597995 0.04400721 0.03853226 0.05073843
  0.09938243 0.07141861 0.07848228 0.08077859 0.07301082 0.07955534
  0.08139162 0.03386332]
 [0.05363706 0.04100087 0.0348455  0.02828611 0.02380046 0.03291976
  0.04509581 0.03979402 0.036733   0.02972786 0.04770568 0.0377637
  0.04465729 0.01937909 0.01817219 0.06230868 0.05609109 0.04970446
  0.05604613 0.05252646 0.05231599 0.05450212 0.03343048 0.0676389
  0.06863455 0.04141928 0.03674063 0.04266392 0.03068767 0.02951195
  0.08827563 0.06088903 0.05808282 0.05310699 0.04867239 0.08012447
  0.0494395  0.0264513 ]
 [0.0527732  0.03841809 0.02934081 0.02719083 0.02113141 0.02890982
  0.03888823 0.03277305 0.03239964 0.02593015 0.03889372 0.0280996
  0.03826957 0.01744585 0.01578812 0.06279012 0.04601644 0.0512914
  0.05906294 0.05799248 0.06669417 0.04922754 0.02756765 0.07164714
  0.06939282 0.04852463 0.03015238 0.04416151 0.02550133 0.01689401
  0.06655753 0.04492682 0.03445654 0.04426252 0.03655249 0.08210767
  0.03851227 0.02600382]
 [0.05415756 0.03849898 0.0328675  0.02919711 0.02422785 0.03308005
  0.04472182 0.04107715 0.03651056 0.03108251 0.05493755 0.04301502
  0.04587337 0.0200472  0.01712141 0.06136375 0.07127017 0.05775577
  0.08366904 0.06157981 0.0683863  0.05091836 0.02723245 0.10504571
  0.05796056 0.04182978 0.03362839 0.05059114 0.02668863 0.02066925
  0.08579028 0.06852972 0.0353467  0.04818207 0.04779467 0.07622022
  0.04638826 0.02412585]
 [0.05409058 0.03466815 0.03079731 0.02559137 0.02139599 0.02938036
  0.04596264 0.03870698 0.03506896 0.0267445  0.06642056 0.0382214
  0.04557603 0.01731995 0.01493874 0.07361098 0.07878211 0.06567706
  0.08826643 0.06954945 0.07266206 0.04848678 0.02542407 0.1246713
  0.06050866 0.05436116 0.02796977 0.0550494  0.02388967 0.0166028
  0.06170574 0.06670702 0.02344083 0.03447599 0.04446315 0.08034007
  0.03513685 0.02145548]
 [0.0523079  0.03974126 0.03760575 0.02943007 0.02211994 0.03609203
  0.04900351 0.04195104 0.05173505 0.03013504 0.04004448 0.03317099
  0.0441261  0.01987052 0.01626202 0.04584016 0.04963819 0.04613385
  0.05607614 0.0572232  0.05089525 0.05172588 0.04235068 0.08084585
  0.07588261 0.06213451 0.03564933 0.04005359 0.03076893 0.02629063
  0.03261085 0.06305452 0.03746082 0.03736546 0.04178068 0.06723851
  0.04248205 0.026405  ]
 [0.0546913  0.03940902 0.0408875  0.03922155 0.02832446 0.04519518
  0.04906293 0.0493983  0.04537405 0.04147336 0.0479098  0.04743479
  0.05140584 0.03049724 0.02062735 0.03876712 0.03740349 0.0377823
  0.04695853 0.04435115 0.04198885 0.05088092 0.02735415 0.04848537
  0.04174978 0.04253135 0.03249666 0.04947839 0.03320823 0.03030733
  0.04932257 0.08321769 0.07640524 0.07964812 0.06219013 0.07196245
  0.08137255 0.04557589]
 [0.05269824 0.05306539 0.05537616 0.0789751  0.06421704 0.07010282
  0.05523904 0.0572079  0.06778943 0.08298978 0.06126851 0.06391197
  0.06243402 0.11616285 0.12591398 0.04309407 0.04434607 0.04668606
  0.04200244 0.04554363 0.04195079 0.05329761 0.05450547 0.0232683
  0.03377077 0.04967775 0.05028091 0.06694839 0.07467037 0.04676817
  0.02669674 0.04428379 0.0423196  0.03953836 0.03363574 0.02630025
  0.04821265 0.14202571]
 [0.05249286 0.06806225 0.0630722  0.11435447 0.23684448 0.09210964
  0.06237286 0.06263881 0.06644621 0.11936951 0.09529524 0.08593047
  0.06250418 0.15048392 0.18634972 0.05889377 0.08361706 0.0832795
  0.05959599 0.0560327  0.06806458 0.0511719  0.06954043 0.0226751
  0.03031752 0.05371556 0.07331959 0.06824812 0.07218668 0.04067114
  0.01975004 0.02902844 0.02258776 0.02740597 0.01766083 0.01784105
  0.03495886 0.12991469]
 [0.05271691 0.05216113 0.04764326 0.06336297 0.10682584 0.04797189
  0.04675256 0.04944945 0.04555799 0.07227397 0.06865874 0.06004598
  0.04837567 0.05103181 0.07167079 0.05489874 0.1008807  0.10445791
  0.08193556 0.07003593 0.1188051  0.0488928  0.05851721 0.04705251
  0.04765206 0.05106225 0.05905178 0.08126712 0.04582911 0.02303814
  0.0273706  0.04285826 0.02542514 0.02853335 0.02186782 0.02442582
  0.03144994 0.10220537]
 [0.05295264 0.05538238 0.04982406 0.07074135 0.06835145 0.05743441
  0.05550468 0.05602282 0.06524418 0.07039469 0.05953709 0.05333597
  0.05186687 0.06257641 0.05937403 0.04391042 0.06470823 0.06830946
  0.05809688 0.05963783 0.06744323 0.06371371 0.06339578 0.02830211
  0.03708738 0.0485918  0.04688574 0.09011649 0.05460819 0.01914748
  0.0175699  0.02563836 0.02199432 0.02086103 0.01667438 0.02050021
  0.02771536 0.05962388]]

-* TASK 10/20 | SAMPLE 34/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 169/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 explicitly states that Bill went to the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Bill', ' went', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 44), x_tokens=44, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 44)
DEBUG result.interpretability.attn_scores 836 
 [[0.04993712 0.06727877 0.06724399 0.08471666 0.06550501 0.0754682
  0.06612676 0.06495591 0.06890836 0.0682489  0.04815486 0.05559696
  0.06515319 0.10509257 0.10761653 0.04475811 0.04240387 0.03984796
  0.03898688 0.04193054 0.0344278  0.05087344 0.09288646 0.03318979
  0.03892289 0.05628788 0.05066559 0.06732881 0.15343422 0.1062533
  0.03289042 0.03626844 0.03692276 0.03561953 0.02611205 0.02433516
  0.03992341 0.06738549 0.05127805 0.09042278 0.05153339 0.03743058
  0.05744909 0.05107358]
 [0.05066307 0.05318493 0.05922532 0.05621315 0.03912629 0.0492208
  0.0480227  0.06365097 0.05566481 0.04013757 0.0403469  0.04239589
  0.05398142 0.03875447 0.06638696 0.04862192 0.0445867  0.0386444
  0.04223793 0.04009283 0.03570038 0.05501705 0.05294134 0.04923321
  0.05063624 0.05563332 0.06053551 0.04366693 0.07888032 0.10020355
  0.04464103 0.0452777  0.05164129 0.03732388 0.04698585 0.03502771
  0.03645925 0.03584248 0.02550526 0.04199903 0.05254244 0.05533022
  0.06422135 0.06085363]
 [0.05212092 0.06616764 0.07318918 0.1034783  0.09100799 0.10879635
  0.06698053 0.07043511 0.07333684 0.08086463 0.05663366 0.06844252
  0.0766667  0.16680628 0.10786799 0.04876539 0.04076192 0.03639368
  0.03470057 0.03451635 0.03006835 0.05439051 0.07832786 0.03213955
  0.03756496 0.05565849 0.06757098 0.05755144 0.10563219 0.15070578
  0.06497606 0.05923476 0.07849881 0.07043411 0.05148156 0.03138068
  0.07612365 0.09102409 0.05653962 0.08432028 0.04997658 0.02989977
  0.04871184 0.05105721]
 [0.05059345 0.049923   0.05650712 0.04772905 0.03903989 0.05115338
  0.05129143 0.05617787 0.05092    0.04112881 0.04041606 0.04593603
  0.05042907 0.03869224 0.03408837 0.04399295 0.04022253 0.03492901
  0.03702301 0.03761352 0.03281359 0.05873212 0.06078399 0.04541245
  0.05404956 0.05690721 0.05891583 0.04535051 0.05230499 0.115526
  0.08043267 0.07715719 0.12695362 0.06828544 0.09047192 0.05145827
  0.06126338 0.0434088  0.03531497 0.03685498 0.06521076 0.04996145
  0.05238379 0.06133477]
 [0.05220662 0.04995549 0.05746198 0.03891017 0.03063184 0.04698939
  0.0595405  0.05447171 0.05561908 0.03561693 0.03959999 0.03818543
  0.04223165 0.03175564 0.02915325 0.04978192 0.04342916 0.03367921
  0.03969115 0.03912447 0.03297284 0.04825518 0.05621251 0.04160299
  0.05107041 0.05133834 0.05734676 0.03496223 0.03524124 0.08382468
  0.04506495 0.04627082 0.05740731 0.04406184 0.07649388 0.04123037
  0.04810512 0.02668851 0.02150334 0.03672675 0.06551588 0.05282182
  0.05108968 0.04336541]
 [0.05348184 0.02976342 0.03170881 0.02218109 0.01805315 0.02812803
  0.02850382 0.03065832 0.03155203 0.02254312 0.03006653 0.0239371
  0.02839351 0.01704708 0.01778165 0.03467003 0.03303213 0.02706305
  0.03210414 0.03089837 0.02838609 0.03297364 0.02785096 0.04228056
  0.04137087 0.03660047 0.02723086 0.02441333 0.01951466 0.02839247
  0.02356082 0.03017445 0.02101563 0.02117338 0.03190104 0.02785522
  0.02134459 0.01515941 0.01238476 0.02330521 0.04724495 0.05063464
  0.04710413 0.03622676]
 [0.05168747 0.05249291 0.05653151 0.04224833 0.03191995 0.04726223
  0.05649132 0.05593876 0.05193375 0.04144045 0.04488368 0.0482747
  0.05034469 0.03334737 0.02965617 0.05350226 0.04719747 0.047752
  0.05656058 0.05672128 0.04425868 0.06066949 0.05433355 0.06211463
  0.06694072 0.05969668 0.06109227 0.03923857 0.04303316 0.06294098
  0.08167463 0.0629118  0.07627333 0.08699674 0.10614619 0.07400503
  0.09183494 0.03164163 0.024881   0.03399937 0.07699978 0.06967396
  0.06126395 0.05797002]
 [0.05347952 0.06081016 0.06503459 0.06096692 0.04519767 0.070437
  0.06362642 0.07561034 0.06109942 0.06193727 0.0579857  0.07857675
  0.07656544 0.05072238 0.03429229 0.04822585 0.04481107 0.04642061
  0.04640656 0.04647925 0.03957802 0.0569384  0.04804648 0.05594118
  0.05320893 0.05353869 0.06205396 0.04390499 0.04578594 0.04471981
  0.06963258 0.06113201 0.06757372 0.09195308 0.07688802 0.05505667
  0.08950392 0.03779217 0.04142375 0.0406674  0.05275146 0.03800321
  0.04219364 0.04429497]
 [0.05404782 0.05039085 0.05553833 0.04684429 0.03669537 0.05425201
  0.05606443 0.06057905 0.05182704 0.05152553 0.05141913 0.05721818
  0.05804427 0.03940552 0.03036405 0.0503423  0.04583042 0.04416037
  0.04766432 0.04885757 0.0418537  0.05340435 0.04318567 0.05378801
  0.05062701 0.04796479 0.06114289 0.0396946  0.03712002 0.04397258
  0.08490703 0.06879932 0.07541349 0.07972001 0.07152133 0.07511265
  0.08894891 0.03459434 0.02285217 0.03520606 0.04790323 0.04099487
  0.03988726 0.04518853]
 [0.05326466 0.04121588 0.03898172 0.02924958 0.02372789 0.03423109
  0.04309521 0.04400776 0.03947148 0.03440792 0.04770879 0.04028638
  0.04351843 0.02228663 0.02186943 0.05956345 0.05165971 0.05216096
  0.04992424 0.05244783 0.04814584 0.05600126 0.03367168 0.05928012
  0.06284381 0.04351372 0.04707192 0.03823761 0.03012365 0.02690124
  0.08459903 0.06080097 0.06216175 0.05600084 0.05372502 0.08607536
  0.05488544 0.02772957 0.0174011  0.02625124 0.04724735 0.06420742
  0.04408321 0.05291634]
 [0.05261432 0.04427637 0.03977279 0.02969435 0.02313489 0.03308453
  0.04899031 0.04776457 0.04051572 0.03309378 0.04613198 0.03726453
  0.04661514 0.0212167  0.02095446 0.070993   0.05041301 0.05922728
  0.05464819 0.06491569 0.06076279 0.05433664 0.03253477 0.06677106
  0.06580911 0.04281887 0.04221288 0.03939632 0.028028   0.01851212
  0.07302065 0.04943528 0.05336098 0.05616183 0.04467202 0.08484887
  0.04736049 0.02653073 0.01526079 0.02439682 0.04902039 0.08339478
  0.04638164 0.05489003]
 [0.05426288 0.04133284 0.040184   0.03007695 0.0257818  0.03460786
  0.04433928 0.04435628 0.04151422 0.03543671 0.05456237 0.04597457
  0.04583463 0.02363422 0.02234276 0.06473072 0.05718141 0.07360332
  0.06540167 0.10808787 0.08095535 0.0483503  0.03052645 0.08377062
  0.07565183 0.05097077 0.04388318 0.04338299 0.02662764 0.01993893
  0.06283657 0.06341014 0.04251176 0.05430508 0.05166456 0.10161171
  0.0532713  0.0269604  0.02194924 0.02443134 0.04795608 0.07508184
  0.05431305 0.04439316]
 [0.05431776 0.0378435  0.03583838 0.02507449 0.02143443 0.02877114
  0.04196904 0.03698451 0.03744398 0.03028528 0.05914064 0.03853238
  0.03865399 0.01940955 0.02038076 0.06485456 0.06606576 0.06528314
  0.06550649 0.08062331 0.06859564 0.04958154 0.02889256 0.09164929
  0.06739799 0.05189221 0.03882168 0.042339   0.02539728 0.01737517
  0.05635851 0.05967615 0.02837489 0.04216645 0.04545503 0.08485427
  0.03835089 0.02358084 0.01623062 0.02452505 0.03967711 0.07699247
  0.06463023 0.04751898]
 [0.05199094 0.05033237 0.04765904 0.03538549 0.02944977 0.04226025
  0.05715807 0.05118095 0.05656042 0.0407233  0.04780561 0.04299341
  0.05250479 0.02448155 0.02290273 0.05189592 0.05479501 0.05612523
  0.06004332 0.06218489 0.06163522 0.0500421  0.05422122 0.08140288
  0.07361493 0.06896638 0.04555348 0.05944439 0.03692059 0.02429131
  0.03704023 0.05449698 0.04026099 0.04538839 0.04954427 0.05603462
  0.0415838  0.03326026 0.03290713 0.03892148 0.06072291 0.07121308
  0.07732128 0.06483373]
 [0.05441711 0.04455578 0.04579464 0.03668632 0.02752546 0.04041861
  0.04603463 0.04429955 0.04575216 0.04326147 0.05092465 0.05046773
  0.04784285 0.02672673 0.02347221 0.04586661 0.04450646 0.04303025
  0.048729   0.04104931 0.04745987 0.051962   0.03136041 0.05106266
  0.04024387 0.04295482 0.04074505 0.04412296 0.03273258 0.02653192
  0.05344073 0.07587574 0.07546406 0.08269724 0.0715354  0.06987983
  0.07805692 0.04106607 0.02967438 0.02389705 0.03796653 0.04239712
  0.04287246 0.0493192 ]
 [0.05298434 0.05400041 0.05332544 0.06551984 0.05695166 0.06076433
  0.05260055 0.05035421 0.05776091 0.07188718 0.05413705 0.06041137
  0.05866023 0.08817953 0.09638228 0.04363367 0.04568034 0.04641652
  0.04806886 0.04105327 0.04426548 0.05229784 0.0568116  0.03288111
  0.04049791 0.05380052 0.05096928 0.06759555 0.06821357 0.04355925
  0.02961165 0.04648439 0.04013454 0.04104381 0.03469525 0.02822263
  0.04388708 0.13702214 0.07798722 0.06796257 0.04558002 0.03675181
  0.04808067 0.04619992]
 [0.0523591  0.07956621 0.07137705 0.12034128 0.24950813 0.09601531
  0.06519167 0.05783135 0.07093967 0.12685575 0.10268956 0.10320347
  0.06387063 0.15230596 0.18973438 0.06873308 0.09400117 0.09021106
  0.07515483 0.05192899 0.07615764 0.05222941 0.08537059 0.03044185
  0.03707074 0.06390102 0.07946551 0.08872776 0.07890865 0.0460908
  0.02506773 0.03421101 0.02313995 0.03247916 0.02375598 0.02079619
  0.03475723 0.14776236 0.19209203 0.1127679  0.05708314 0.03343054
  0.0519114  0.05918107]
 [0.05299814 0.0608459  0.05001481 0.05980478 0.08346783 0.04586232
  0.04816906 0.04136948 0.04730709 0.07320508 0.06974605 0.06573548
  0.05027297 0.04849395 0.06630033 0.05992272 0.09017045 0.0994941
  0.09379689 0.06334137 0.12083144 0.05080695 0.05963006 0.05314431
  0.04918131 0.05300497 0.05552462 0.07718363 0.04549387 0.02166099
  0.0308238  0.04155795 0.02367103 0.03101093 0.02626161 0.02936806
  0.02966968 0.09334569 0.1883465  0.0572717  0.05514193 0.05131062
  0.05070462 0.07111154]
 [0.05257287 0.06606367 0.05461135 0.06487899 0.06184097 0.0522772
  0.05580423 0.04937347 0.06187307 0.06740033 0.05764683 0.05656712
  0.05041641 0.05164152 0.05845336 0.04714555 0.06325141 0.06555785
  0.06335138 0.05813322 0.07113128 0.06313779 0.07241182 0.03389371
  0.04329692 0.05455076 0.04919775 0.10345836 0.05660744 0.01859908
  0.01942095 0.0268249  0.01922007 0.02317824 0.02068905 0.02284663
  0.02467    0.05920496 0.11646806 0.17607304 0.04992612 0.04046972
  0.05539677 0.05827114]]

-* TASK 10/20 | SAMPLE 34/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 170/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Bill is in the park, but sentence 14 updates the information, stating that Bill went back to the school. This implies that Bill is no longer in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Bill', ' is', ' in', ' the', ' park', ',', ' but', ' sentence', ' ', '14', ' updates', ' the', ' information', ',', ' stating', ' that', ' Bill', ' went', ' back', ' to', ' the', ' school', '.', ' This', ' implies', ' that', ' Bill', ' is', ' no', ' longer', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0217, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.01993141 0.03347541 0.03174295 ... 0.01484379 0.01434404 0.02008627]
 [0.02045254 0.05525537 0.047386   ... 0.03106306 0.03164514 0.02196882]
 [0.02081939 0.03116256 0.03289414 ... 0.02424909 0.02503374 0.02400875]
 ...
 [0.02104346 0.03177911 0.02806445 ... 0.01373896 0.00882991 0.02977345]
 [0.02154359 0.02387622 0.02030789 ... 0.01022784 0.00868508 0.01348476]
 [0.02126888 0.02334663 0.02031208 ... 0.01148279 0.00923179 0.01461059]]
Model's predictions for the sample 34:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   From sentence 1, we know that Fred is    |
|          |                 |   either in the cinema or the school. We   |
|          |                 |  don't have any information that confirms  |
|          |                 |     Fred's exact location. Sentence 2      |
|          |                 |   informs us that Julie travelled to the   |
|          |                 |     school, but it doesn't provide any     |
|          |                 |     information about Fred's location.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  From sentence 2 (previous part), we know  |
|          |                 |    that Julie travelled to the school.     |
|          |                 |   There is no information that suggests    |
|          |                 |           Julie left the school.           |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Bill   |
|          |                 |             is in the school.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 11 explicitly states that Bill   |
|          |                 |            went to the bedroom.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   Sentence 13 states that Bill is in the   |
|          |                 |     park, but sentence 14 updates the      |
|          |                 |  information, stating that Bill went back  |
|          |                 |  to the school. This implies that Bill is  |
|          |                 |           no longer in the park.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 34:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 35/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 171/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 1 explicitly states that Julie is in the school, and there is no information that suggests she has left the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' has', ' left', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 26), x_tokens=26, y_tokens=38, max_supp_attn=0.0526, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 26)
DEBUG result.interpretability.attn_scores 988 
 [[0.02423223 0.03934548 0.04781647 0.06695791 0.08000971 0.06459835
  0.05196433 0.05703316 0.04449114 0.05794931 0.04417363 0.04970443
  0.05547895 0.09180209 0.06109361 0.02776435 0.02729583 0.02931279
  0.02566996 0.02738059 0.02277579 0.03450803 0.03597884 0.01602966
  0.01717031 0.02532427]
 [0.02461437 0.04883832 0.04418417 0.06468746 0.06027677 0.05205067
  0.04095677 0.03860344 0.0351344  0.04372521 0.03561838 0.02642177
  0.02881502 0.09985065 0.10010648 0.02902107 0.02266674 0.02067808
  0.02056843 0.02060043 0.01808519 0.03590185 0.03780532 0.0116916
  0.01162538 0.02067498]
 [0.02651628 0.05072157 0.03071493 0.04657497 0.03547464 0.03010503
  0.02785015 0.0191058  0.01818578 0.02939697 0.02585782 0.01365841
  0.01537365 0.02472255 0.03292653 0.02071436 0.01241357 0.0124264
  0.01518785 0.01515193 0.01411455 0.03896324 0.04427626 0.00706311
  0.00718545 0.01141854]
 [0.02482078 0.03542712 0.0404942  0.02411628 0.01712945 0.02852438
  0.02978842 0.02634228 0.0318216  0.02554215 0.02531918 0.0245156
  0.02289953 0.0126837  0.01256629 0.03381348 0.02883733 0.02820413
  0.02978318 0.03011791 0.02833586 0.02959778 0.04997501 0.0512405
  0.05556801 0.04654596]
 [0.02513547 0.036376   0.03911021 0.05947876 0.05578341 0.0405069
  0.03046145 0.02543723 0.02785798 0.03960621 0.03185786 0.02112834
  0.02138735 0.08772328 0.09292994 0.03311714 0.02412779 0.01935586
  0.01954617 0.02053877 0.01977555 0.03501241 0.05404496 0.0127692
  0.01079763 0.02663059]
 [0.0256487  0.02311403 0.02375995 0.04581108 0.04203626 0.03688289
  0.02262314 0.01977497 0.02354958 0.03714344 0.02812384 0.02414726
  0.02321558 0.09930799 0.12210745 0.03291405 0.0274053  0.0234567
  0.02206833 0.02190102 0.01892121 0.02949296 0.03167569 0.00881104
  0.00840747 0.01693367]
 [0.02600909 0.02610002 0.03068198 0.04825379 0.04604674 0.04682783
  0.02975415 0.02715456 0.03097025 0.04399956 0.03311836 0.0380729
  0.03520798 0.07942396 0.0767774  0.02767533 0.02481852 0.02299427
  0.02103863 0.02143938 0.01775184 0.02654132 0.02964071 0.01193009
  0.01081968 0.01662003]
 [0.02514813 0.03504413 0.04158506 0.03874133 0.04102243 0.04422758
  0.03430637 0.03656139 0.03474624 0.03988183 0.03419894 0.04222624
  0.03666473 0.0491211  0.04476803 0.0353859  0.0315899  0.02853202
  0.02515278 0.02624078 0.02389281 0.03020482 0.04145108 0.02914545
  0.02697205 0.03208254]
 [0.02528289 0.04141891 0.04740456 0.02976559 0.02527325 0.03498496
  0.04040587 0.04174793 0.03666005 0.03063153 0.03038434 0.03457576
  0.03575158 0.02206201 0.01619948 0.03512736 0.02866493 0.0270396
  0.02516906 0.02590589 0.02503193 0.0274733  0.05018813 0.03500367
  0.03854518 0.04341408]
 [0.02606806 0.0571188  0.06283995 0.02689476 0.01985153 0.03297217
  0.04141014 0.03657521 0.04092857 0.02614673 0.02460946 0.02916677
  0.02773072 0.01520569 0.01286805 0.04064238 0.02865344 0.02510314
  0.02503651 0.02712856 0.02345764 0.02662857 0.05661068 0.02571734
  0.02683273 0.0295807 ]
 [0.02603875 0.03333058 0.03874362 0.02118928 0.01718286 0.02364114
  0.03334338 0.02965851 0.03119188 0.02197819 0.02184454 0.02370567
  0.0215799  0.01302246 0.01229112 0.03954206 0.03017539 0.0244378
  0.02635689 0.0270023  0.02499557 0.02617044 0.04678433 0.0410493
  0.04055222 0.03324188]
 [0.02619953 0.01734014 0.02075992 0.0139997  0.01236474 0.01692772
  0.02056976 0.02058824 0.02794241 0.01691548 0.01533566 0.01579621
  0.01491173 0.00894208 0.00903342 0.0253049  0.0242091  0.02011089
  0.02416215 0.02636507 0.02480009 0.02212157 0.04244051 0.05928665
  0.06283319 0.03916315]
 [0.02604218 0.02579561 0.02665082 0.01874407 0.01601412 0.02311977
  0.02679139 0.02491512 0.02392249 0.02048452 0.02309952 0.02460794
  0.02180162 0.01051575 0.01101419 0.03454363 0.02758028 0.02426944
  0.02370683 0.02361937 0.0241389  0.02587077 0.02826622 0.04763457
  0.05092918 0.03774098]
 [0.02658802 0.03277063 0.03551223 0.03134206 0.0236024  0.03831316
  0.03630087 0.0383715  0.03166916 0.03818876 0.03664819 0.05223069
  0.04007224 0.01815706 0.0135052  0.02526039 0.02684185 0.0264419
  0.02422354 0.02405043 0.02167099 0.02811025 0.02084085 0.02099486
  0.01902225 0.01819879]
 [0.02685279 0.02386218 0.0243421  0.02011459 0.01755464 0.02277026
  0.02747673 0.02546092 0.02127695 0.0229257  0.02795496 0.02666062
  0.02505937 0.01117641 0.01052549 0.02629676 0.02562647 0.0223429
  0.02202043 0.02218561 0.02239327 0.02648444 0.01900819 0.03363254
  0.02450678 0.01860263]
 [0.02630075 0.01822828 0.01587543 0.01303984 0.01175686 0.01402422
  0.02006455 0.01860442 0.01619693 0.01514112 0.02327502 0.01749242
  0.01944243 0.00684841 0.00783645 0.02735111 0.03093824 0.02521636
  0.02389519 0.02398582 0.03051695 0.02381227 0.01707978 0.05911618
  0.0428934  0.0282849 ]
 [0.02613977 0.01669501 0.01396764 0.01219482 0.0102548  0.01292529
  0.02087465 0.020303   0.01513684 0.01389513 0.02110612 0.01502755
  0.01903691 0.00604076 0.00665883 0.02394481 0.03215908 0.03118493
  0.02890789 0.02731598 0.04182645 0.0215076  0.0163009  0.06289484
  0.04605307 0.0333884 ]
 [0.02659417 0.01576461 0.01371706 0.0115882  0.01038194 0.01355325
  0.01803314 0.0177428  0.01503833 0.0140666  0.02395824 0.01811045
  0.0188327  0.0061946  0.00635445 0.02298725 0.0327843  0.02630994
  0.02876464 0.02499049 0.03251711 0.02074903 0.0135169  0.05688026
  0.03296814 0.02312051]
 [0.02653175 0.01427689 0.01212231 0.00925159 0.00867903 0.01130581
  0.01791804 0.01587643 0.0143617  0.01140696 0.02982474 0.01511577
  0.01761517 0.0050935  0.00544394 0.02540608 0.03424592 0.02861657
  0.03429079 0.02896183 0.0363551  0.02027811 0.01388601 0.05830502
  0.03550088 0.03206697]
 [0.02559307 0.02441619 0.02140867 0.01601803 0.01837297 0.01829189
  0.03057216 0.02505527 0.0246343  0.01767629 0.02357303 0.01816255
  0.0222402  0.00917336 0.010569   0.02602313 0.03032135 0.03386576
  0.0639377  0.05541617 0.04361077 0.02769035 0.03256988 0.04395978
  0.04656463 0.05089488]
 [0.02687321 0.01678811 0.01579649 0.0140334  0.01115754 0.01481413
  0.01736713 0.01818002 0.01814357 0.01575713 0.01974077 0.01753988
  0.01790011 0.0078199  0.00711368 0.01842006 0.0193197  0.01993849
  0.02531556 0.02320458 0.02424566 0.02293347 0.0142304  0.02217069
  0.03030043 0.03626845]
 [0.02693065 0.01774096 0.0203947  0.02038544 0.01533894 0.0216928
  0.01912001 0.02295697 0.02300194 0.0240777  0.02005755 0.02517799
  0.02220616 0.01202568 0.00857695 0.01572396 0.01914817 0.01954443
  0.02013264 0.01959576 0.0198381  0.0243057  0.01577169 0.01555606
  0.02624934 0.03169701]
 [0.02677802 0.02257718 0.02214803 0.01759823 0.01375569 0.02044266
  0.0240641  0.0280004  0.02566625 0.01937571 0.0190443  0.02380317
  0.02579747 0.0103498  0.008053   0.02092839 0.0193809  0.02238811
  0.0224111  0.02332393 0.02370257 0.02712154 0.01971758 0.01778182
  0.03844287 0.03600471]
 [0.02702575 0.02154377 0.02141553 0.01727246 0.01347045 0.0225546
  0.02618864 0.02909593 0.02952199 0.02024955 0.02100127 0.03078611
  0.02901437 0.00968229 0.0078566  0.0214968  0.02252854 0.02776229
  0.02787261 0.02882965 0.02744806 0.02285933 0.01732894 0.01499609
  0.02444039 0.02556237]
 [0.0274331  0.02157679 0.02206703 0.01984498 0.01518297 0.02913333
  0.02777722 0.0295835  0.03497492 0.02415772 0.02019773 0.03357082
  0.03117129 0.01243767 0.00837188 0.01605036 0.01771298 0.01942496
  0.02281154 0.02197846 0.01886827 0.02427904 0.0176409  0.01084713
  0.01654393 0.02108799]
 [0.02688796 0.03238962 0.02914421 0.02181212 0.01614232 0.02841779
  0.03397952 0.03785531 0.03757004 0.0263944  0.02631588 0.03948486
  0.039904   0.01271742 0.00875341 0.02499479 0.02230816 0.02951533
  0.02687546 0.02945701 0.02497666 0.02573065 0.02039916 0.01401953
  0.02011176 0.02027114]
 [0.02734569 0.02576127 0.02690002 0.02169979 0.01521715 0.03916834
  0.03433448 0.03494868 0.03884238 0.02648331 0.02408628 0.05558442
  0.0450279  0.01300982 0.00816279 0.02086029 0.01998744 0.02278107
  0.02347429 0.024082   0.01973396 0.02437415 0.01653513 0.01056319
  0.01374017 0.0143572 ]
 [0.02754097 0.01830686 0.01822809 0.01604424 0.01133167 0.01837617
  0.02093264 0.0255606  0.02380757 0.02032195 0.02174851 0.02878502
  0.03040596 0.00951001 0.00624406 0.02037482 0.01889963 0.02359124
  0.02188323 0.02304428 0.02292066 0.02256598 0.0107746  0.01421174
  0.01579619 0.01385948]
 [0.02746988 0.01839732 0.01787797 0.01677692 0.01220342 0.01890911
  0.02056449 0.02460916 0.02337485 0.0213825  0.02301342 0.02587442
  0.02918261 0.00995519 0.00683348 0.01996281 0.01986418 0.02440913
  0.02308919 0.02408348 0.02365224 0.02339684 0.01079056 0.01554815
  0.01580381 0.01312459]
 [0.02696771 0.01749994 0.01582326 0.01291877 0.00958497 0.01292446
  0.01881249 0.02074615 0.01915558 0.01484391 0.02097478 0.01844474
  0.02318349 0.00711394 0.0059272  0.0286521  0.0234997  0.03550669
  0.02668756 0.03238175 0.03659974 0.02169689 0.01183147 0.02284863
  0.03029716 0.02209486]
 [0.02701073 0.01860665 0.01696492 0.01358655 0.01009456 0.01446132
  0.02192638 0.02436044 0.02186914 0.01620802 0.02503552 0.02130013
  0.02735243 0.00775405 0.00582466 0.03261635 0.02613963 0.04238358
  0.02998224 0.03839399 0.03866448 0.02139214 0.01116688 0.0206113
  0.02740306 0.01951701]
 [0.0273345  0.01524625 0.0144475  0.01117879 0.00857434 0.01265097
  0.01707191 0.01777142 0.01968328 0.01369572 0.02357634 0.01641011
  0.01991991 0.00690742 0.00529367 0.02285348 0.02273311 0.02551704
  0.02716242 0.03036403 0.03559734 0.02071851 0.01108966 0.02463861
  0.02302219 0.02287188]
 [0.0266082  0.01867598 0.01632372 0.01025763 0.00807116 0.01206928
  0.02037471 0.01805863 0.0206953  0.01249546 0.02738211 0.01454263
  0.02116952 0.00631472 0.00523847 0.02776775 0.02917551 0.03026742
  0.0337578  0.03325868 0.0388361  0.02154829 0.0143313  0.04285508
  0.03082504 0.03925793]
 [0.0274751  0.01701724 0.01705073 0.01305233 0.00958497 0.01429937
  0.0175165  0.01934958 0.02242382 0.01504713 0.01789087 0.01595459
  0.02029236 0.00833463 0.0058992  0.0194895  0.01734521 0.02078946
  0.02445236 0.027024   0.02490481 0.02170876 0.01349168 0.01685832
  0.02514351 0.02956055]
 [0.02626158 0.02442279 0.02323889 0.03758051 0.03811339 0.03204262
  0.02155647 0.02197098 0.02552084 0.03844532 0.02849801 0.02452024
  0.02717836 0.06243438 0.07691175 0.02300574 0.02380052 0.02325636
  0.02273712 0.02215108 0.01959928 0.02841053 0.02709455 0.00908425
  0.01064635 0.01775602]
 [0.02599914 0.02531687 0.02372356 0.0427605  0.08218694 0.03214094
  0.01903918 0.02042933 0.02398464 0.04507662 0.0338656  0.02565363
  0.02256111 0.06550165 0.08474902 0.02815934 0.03400601 0.03233953
  0.02642665 0.02379101 0.02280255 0.0256898  0.02759647 0.00808934
  0.00819632 0.01571068]
 [0.02568781 0.02375916 0.02185833 0.03799241 0.08749222 0.02338417
  0.01635143 0.0196516  0.02100371 0.04247541 0.03482588 0.0281608
  0.02187747 0.03169161 0.04162938 0.02440936 0.05559068 0.04880465
  0.03644833 0.02796406 0.03524012 0.02336833 0.02449073 0.01426847
  0.01457063 0.01957608]
 [0.02601329 0.02838871 0.02490573 0.03644091 0.05342883 0.0259646
  0.02155735 0.02195914 0.02504357 0.03681067 0.03286339 0.02387901
  0.0227381  0.02937245 0.03298535 0.02139854 0.0372045  0.03188078
  0.028993   0.02677394 0.02740181 0.04078096 0.03337811 0.01189594
  0.01271923 0.01749365]]

-* TASK 10/20 | SAMPLE 35/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 172/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Fred is in the cinema, and there is no information that suggests he has moved to the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Fred', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.0294, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02755822 0.0450833  0.04527759 ... 0.05806696 0.01008167 0.0103346 ]
 [0.02818382 0.0468667  0.04397897 ... 0.06348453 0.01805236 0.01605771]
 [0.02882772 0.04305901 0.04469327 ... 0.05846087 0.02082621 0.01977523]
 ...
 [0.02866295 0.03929472 0.03523839 ... 0.02213283 0.00781737 0.00645986]
 [0.02915493 0.02707571 0.0234248  ... 0.01251034 0.01021391 0.00823676]
 [0.02915539 0.02809608 0.02455054 ... 0.01186946 0.00856663 0.00865516]]

-* TASK 10/20 | SAMPLE 35/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 173/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 states that Fred is either in the bedroom or the office, but it does not provide a definitive location. Therefore, we can only conclude that Fred might be in the bedroom, but we are not certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Fred', ' might', ' be', ' in', ' the', ' bedroom', ',', ' but', ' we', ' are', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 38), x_tokens=38, y_tokens=53, max_supp_attn=0.0189, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 38)
DEBUG result.interpretability.attn_scores 2014 
 [[0.01722335 0.03059702 0.02848866 ... 0.02035295 0.01382959 0.03160468]
 [0.01769049 0.02176915 0.02129118 ... 0.01747437 0.01534944 0.02549776]
 [0.01801758 0.03031721 0.03053425 ... 0.01887995 0.0128421  0.02727468]
 ...
 [0.01819186 0.02436933 0.0238599  ... 0.01773173 0.01393823 0.03216352]
 [0.01851172 0.01966598 0.01815063 ... 0.02127907 0.02077335 0.02544808]
 [0.01858866 0.01946092 0.01794318 ... 0.02016921 0.01774209 0.02705217]]

-* TASK 10/20 | SAMPLE 35/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 174/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 explicitly states that Julie is in the cinema, and there is no information that suggests she has left the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' has', ' left', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02757044 0.03858699 0.04163896 ... 0.0105171  0.00980755 0.00491759]
 [0.0280614  0.03158223 0.03423271 ... 0.0201596  0.01695142 0.01204091]
 [0.02874757 0.03944156 0.04236127 ... 0.01530628 0.01403196 0.00669056]
 ...
 [0.02889063 0.04096078 0.03957112 ... 0.00724108 0.00625028 0.00415008]
 [0.02913942 0.03260504 0.02954605 ... 0.00923043 0.00721555 0.00536946]
 [0.02910476 0.03894681 0.03656427 ... 0.00736525 0.00757315 0.00531706]]

-* TASK 10/20 | SAMPLE 35/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 175/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 13 states that Julie went back to the park, and there is no information that suggests she is in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 50), x_tokens=50, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 50)
DEBUG result.interpretability.attn_scores 1700 
 [[0.02754374 0.03568982 0.0433834  ... 0.02399064 0.02004171 0.02100415]
 [0.02785849 0.03221028 0.03591586 ... 0.03169046 0.0263381  0.0265683 ]
 [0.02868875 0.04094214 0.0486693  ... 0.02198231 0.01704597 0.01838239]
 ...
 [0.02877673 0.03843432 0.04024443 ... 0.02259829 0.01796525 0.02289783]
 [0.02933329 0.02991864 0.02991577 ... 0.0254814  0.02296817 0.02578678]
 [0.02914954 0.03242874 0.03188686 ... 0.02325802 0.02246233 0.02562647]]
Model's predictions for the sample 35:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 1 explicitly states  |
|          |                 |   that Julie is in the school, and there   |
|          |                 |  is no information that suggests she has   |
|          |                 |              left the school.              |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 4 states that Fred   |
|          |                 |     is in the cinema, and there is no      |
|          |                 |   information that suggests he has moved   |
|          |                 |                to the park.                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 8 states that Fred   |
|          |                 |  is either in the bedroom or the office,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |      location. Therefore, we can only      |
|          |                 |     conclude that Fred might be in the     |
|          |                 |      bedroom, but we are not certain.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 11 explicitly     |
|          |                 |  states that Julie is in the cinema, and   |
|          |                 |   there is no information that suggests    |
|          |                 |          she has left the cinema.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentence 13 states that     |
|          |                 |   Julie went back to the park, and there   |
|          |                 |   is no information that suggests she is   |
|          |                 |               in the school.               |
+----------+-----------------+--------------------------------------------+

Metrics for sample 35:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 36/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 176/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, Fred moved to the kitchen, which implies that Fred is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02727467 0.04382671 0.05382835 0.07097965 0.08017187 0.07207768
  0.05568676 0.06244242 0.05210654 0.06259334 0.0456729  0.05870541
  0.06416564 0.09620981 0.0636839  0.0288546  0.02972344 0.02989186
  0.02743053 0.02996023 0.02527339 0.03665947 0.03990238 0.02000437
  0.01660573 0.02538593]
 [0.02767065 0.0549082  0.05230373 0.06853491 0.06048769 0.05718055
  0.04440778 0.04276035 0.04296734 0.04796331 0.03731786 0.03144481
  0.0324884  0.10303266 0.10184818 0.03077728 0.02557913 0.02157643
  0.02196413 0.02260271 0.02050439 0.03828521 0.04310724 0.01519702
  0.01048032 0.02123358]
 [0.02982865 0.05768324 0.03590641 0.05004124 0.03670199 0.03406397
  0.02988852 0.02097473 0.0217364  0.03247569 0.02692475 0.01612394
  0.01739086 0.02552491 0.03354116 0.02125296 0.0134451  0.01251597
  0.01593844 0.01643169 0.01591264 0.04141866 0.04957959 0.00914955
  0.00607638 0.0114684 ]
 [0.02791644 0.02631172 0.02857988 0.02209419 0.01604479 0.02527761
  0.02618591 0.02426049 0.02985905 0.02441116 0.02308498 0.02397979
  0.02327316 0.01141731 0.01168508 0.02795001 0.03158247 0.03246572
  0.03953338 0.04090413 0.0336851  0.03217414 0.04769936 0.04981344
  0.06354327 0.06325391]
 [0.02829173 0.04116227 0.04595434 0.064189   0.05802412 0.04622192
  0.0328735  0.02819366 0.03346629 0.04400028 0.03326953 0.02513517
  0.02451253 0.09122963 0.09517577 0.03427883 0.02635135 0.01964296
  0.02065978 0.02239592 0.02237607 0.03733114 0.0605675  0.01630172
  0.00916835 0.02666732]
 [0.02883362 0.02618167 0.02784482 0.04936984 0.04345547 0.04185214
  0.02436485 0.02179103 0.02827648 0.04121273 0.02951202 0.02867838
  0.02638758 0.10274269 0.12442479 0.03404249 0.02986333 0.02373738
  0.02326505 0.02383917 0.02140128 0.03152089 0.03557241 0.01135327
  0.00741222 0.01687986]
 [0.02924147 0.02970784 0.0359537  0.05214423 0.04783405 0.0531887
  0.03244045 0.03035132 0.03706227 0.04874886 0.0345846  0.04536319
  0.04036826 0.0817785  0.07754787 0.02875568 0.02712921 0.02348681
  0.02238274 0.02352227 0.02012675 0.02859424 0.03307626 0.01519064
  0.01046003 0.01669031]
 [0.02818275 0.03790143 0.04483211 0.04083409 0.04237385 0.04901163
  0.03826669 0.04063515 0.04013871 0.0433758  0.03524503 0.05008379
  0.04376079 0.05035289 0.04557942 0.03779021 0.03461613 0.03074187
  0.02835304 0.0304415  0.02767358 0.03338761 0.04606503 0.03450368
  0.03232312 0.03537339]
 [0.02938042 0.0400965  0.04828376 0.04599671 0.04118362 0.05548633
  0.04235507 0.04468416 0.04697164 0.04824447 0.03543273 0.05018533
  0.0455012  0.0376424  0.02479211 0.0274285  0.02686386 0.02523747
  0.02428216 0.0267058  0.02256588 0.032976   0.03615816 0.0210105
  0.0166006  0.0238559 ]
 [0.02863431 0.0499463  0.05388526 0.02920776 0.02321497 0.03783503
  0.04538071 0.04306131 0.04568334 0.03092721 0.02860132 0.03785291
  0.03902074 0.01701225 0.01435248 0.04310772 0.03502765 0.03009589
  0.03060195 0.03285372 0.03091156 0.03320844 0.06374684 0.04315265
  0.03924496 0.03678432]
 [0.02923005 0.06582078 0.06523818 0.02727699 0.02176098 0.03259147
  0.04567287 0.03898524 0.0475109  0.02703482 0.02560157 0.03029982
  0.03036283 0.01431652 0.01365498 0.04793268 0.03496554 0.02831768
  0.02973679 0.03473741 0.03017741 0.02978995 0.06780192 0.03896926
  0.02728168 0.02601867]
 [0.0293404  0.03305762 0.03752081 0.02003156 0.01689701 0.02325409
  0.0340308  0.02882374 0.0353206  0.02140604 0.02049192 0.02360486
  0.02262975 0.01163492 0.01157956 0.03891175 0.03157965 0.02579856
  0.0302451  0.03203676 0.03001335 0.02875599 0.05212213 0.04709354
  0.04960101 0.0394171 ]
 [0.02953644 0.01455011 0.01568471 0.01114733 0.00997951 0.01344896
  0.01574936 0.01550857 0.01911615 0.01300243 0.01379723 0.01460525
  0.01407227 0.00611777 0.00663167 0.01928573 0.02014162 0.01965375
  0.02632961 0.02851537 0.02962548 0.02139266 0.03040148 0.05178176
  0.07395889 0.06101841]
 [0.02947201 0.02141559 0.02184332 0.01556859 0.01412979 0.01938387
  0.02293619 0.02087621 0.0224066  0.01734552 0.02013853 0.02067818
  0.01987622 0.0086318  0.00924353 0.03401279 0.0251764  0.0246667
  0.02700016 0.02807224 0.02769635 0.02788427 0.02562146 0.0443169
  0.06982427 0.05007003]
 [0.0295323  0.0233147  0.02384088 0.01901303 0.01641494 0.02371156
  0.02784906 0.02816551 0.02583222 0.0225561  0.02436066 0.02934628
  0.03003064 0.01103756 0.00962674 0.03286834 0.02867489 0.0313804
  0.03032549 0.03050273 0.02950796 0.02979193 0.02136745 0.03485253
  0.0574348  0.03210878]
 [0.02912272 0.01972277 0.01670272 0.01463079 0.01167287 0.01556978
  0.02143661 0.02134174 0.0188247  0.01608385 0.02015012 0.01880902
  0.02216292 0.00709216 0.00711916 0.03256631 0.02270072 0.03741239
  0.03753004 0.0421132  0.03973721 0.02627168 0.01567457 0.04903491
  0.08888294 0.04590722]
 [0.0297866  0.0193274  0.01822094 0.01509767 0.012729   0.0177514
  0.02397625 0.02469137 0.0212408  0.01807878 0.02569427 0.02453944
  0.0258148  0.00737723 0.00716462 0.03872424 0.02710756 0.04318301
  0.03225334 0.03793062 0.03512567 0.02291846 0.01428963 0.04335615
  0.04872808 0.02972783]
 [0.02959097 0.01711663 0.01496969 0.01163305 0.00993518 0.01416931
  0.02250787 0.02106026 0.01828263 0.01407336 0.03226266 0.02003963
  0.02203159 0.0059736  0.00643483 0.03499616 0.03212792 0.04012662
  0.0378516  0.03697883 0.03670389 0.02376322 0.01410578 0.04951706
  0.045261   0.0443431 ]
 [0.02898184 0.02226164 0.01840851 0.01380063 0.01207515 0.01713115
  0.02862627 0.02449434 0.02312608 0.01599908 0.02721094 0.01944941
  0.02326213 0.00699477 0.00751635 0.02498935 0.03215332 0.03099431
  0.03214207 0.0337432  0.0389169  0.02702291 0.02145851 0.06893079
  0.05087241 0.06953403]
 [0.03025174 0.02165177 0.02045657 0.01663825 0.01346153 0.01906112
  0.02258729 0.02348317 0.02234747 0.01832744 0.02474649 0.02346112
  0.0229807  0.00884017 0.00804066 0.02419953 0.02402058 0.02727332
  0.02872704 0.02735626 0.02783103 0.0263021  0.01576562 0.02673677
  0.02493709 0.02981965]
 [0.03043748 0.02276164 0.02525889 0.02206594 0.01702667 0.0255302
  0.02571315 0.03237908 0.02606735 0.02618429 0.02667217 0.03453784
  0.03067956 0.01254021 0.00903784 0.0200836  0.02057415 0.02308135
  0.02329789 0.02223639 0.02244275 0.02739211 0.01481623 0.0177737
  0.01839319 0.0213804 ]
 [0.03056077 0.0274754  0.02882998 0.02694869 0.01940491 0.0306035
  0.03173794 0.04036017 0.02878898 0.03271022 0.03353139 0.04319616
  0.04027224 0.01440247 0.00996242 0.02304124 0.02227039 0.0261396
  0.02379885 0.02296097 0.02291744 0.02778679 0.01603762 0.01599328
  0.01356433 0.01466482]
 [0.03041059 0.02479901 0.02490539 0.02431828 0.01916443 0.02719823
  0.02873689 0.03462227 0.02802444 0.03047651 0.03132647 0.03844681
  0.03865764 0.01389706 0.01023003 0.02598404 0.02435619 0.02892345
  0.02722025 0.02587326 0.0256923  0.02885363 0.01402226 0.01710365
  0.01729124 0.01394117]
 [0.03024678 0.01954713 0.01825139 0.01521877 0.01161857 0.01712834
  0.02254569 0.02529548 0.02230523 0.018586   0.02289265 0.02384951
  0.02716012 0.00811278 0.00723332 0.02779774 0.02581625 0.02969267
  0.02995394 0.02810931 0.03197086 0.02806608 0.01229688 0.02414379
  0.02986145 0.01961764]
 [0.0301556  0.02053069 0.01855199 0.01597762 0.01138362 0.01658481
  0.02582945 0.02720847 0.02220667 0.01815508 0.02394123 0.02191246
  0.02686987 0.0078141  0.00732259 0.02990139 0.0264078  0.03283097
  0.03570759 0.03240522 0.0360285  0.02458381 0.01195935 0.02751389
  0.02734844 0.02279588]
 [0.03035196 0.02015401 0.0179492  0.0154919  0.01222476 0.01652681
  0.0227641  0.02481587 0.02174063 0.01866088 0.02536057 0.02371801
  0.02563381 0.00816664 0.00727466 0.02824751 0.03046273 0.03078655
  0.03493899 0.02887793 0.03402675 0.02508731 0.01199357 0.0235574
  0.01877419 0.01881308]
 [0.03047059 0.02245072 0.0201167  0.01653196 0.01231342 0.01810315
  0.02661989 0.02754192 0.02656437 0.01994233 0.03045517 0.02522019
  0.02838293 0.00852408 0.00737669 0.03063633 0.02965757 0.03322973
  0.03386944 0.03205233 0.0350811  0.02555942 0.01238794 0.02519601
  0.01765736 0.01681122]
 [0.03049123 0.0171525  0.01564783 0.01106795 0.00944202 0.01285211
  0.0217855  0.02078094 0.02035658 0.01372157 0.03474566 0.01846834
  0.02249732 0.00630166 0.00552629 0.02935119 0.03379373 0.03259566
  0.0375472  0.0320389  0.03457571 0.02362694 0.01159977 0.03232691
  0.02031826 0.02352226]
 [0.02917984 0.02634012 0.02437875 0.01471287 0.01307255 0.01882911
  0.04688691 0.04134103 0.03222867 0.01905789 0.04916972 0.02935485
  0.04035832 0.00809809 0.00784422 0.02756391 0.04081394 0.03856845
  0.03753103 0.03923529 0.04279958 0.02832481 0.02191087 0.05667135
  0.03396115 0.04532448]
 [0.03056819 0.02129302 0.02062009 0.01784515 0.01389706 0.02081989
  0.02279909 0.02718573 0.02599132 0.02129584 0.02522269 0.02619758
  0.02607967 0.01132482 0.00914974 0.01766961 0.02393966 0.02381557
  0.02708888 0.02452132 0.02702723 0.02530791 0.01418697 0.01781199
  0.01487887 0.02122403]
 [0.02946999 0.02687375 0.02689815 0.04133999 0.04358403 0.036907
  0.02303074 0.02362066 0.02948311 0.04254222 0.030118   0.03067659
  0.02865884 0.06906528 0.08254471 0.02313084 0.02669981 0.02324778
  0.02366013 0.02345083 0.02257876 0.03040737 0.03058591 0.01172765
  0.00875422 0.01895899]
 [0.02927835 0.02791935 0.02698151 0.04526477 0.08806793 0.03617169
  0.02146497 0.02224789 0.02858905 0.04875875 0.03532498 0.03135551
  0.02402915 0.06694242 0.08470652 0.02827746 0.03774891 0.03256513
  0.02811825 0.02591676 0.02629143 0.02739589 0.0296661  0.00997896
  0.00677241 0.01621667]
 [0.02898324 0.02544625 0.02377195 0.03707884 0.08535612 0.02491276
  0.01818689 0.02160915 0.02498743 0.04309323 0.03396356 0.03259284
  0.02404239 0.03008835 0.04011339 0.02468379 0.05968463 0.05239425
  0.03950544 0.03118864 0.04113487 0.02501071 0.02680921 0.01646692
  0.01277228 0.02122494]
 [0.02929559 0.03129155 0.0275795  0.03790766 0.05489561 0.02956414
  0.02467592 0.02440664 0.03038985 0.03895501 0.03317568 0.02808754
  0.02658513 0.02976247 0.03203468 0.02090613 0.03894425 0.03392969
  0.03120977 0.02948918 0.03166684 0.04314829 0.03764402 0.01346801
  0.01095555 0.01994674]]

-* TASK 10/20 | SAMPLE 36/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 177/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, Bill is either in the bedroom or the cinema, but we don't have enough information to determine his exact location. 

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' we', ' don', "'t", ' have', ' enough', ' information', ' to', ' determine', ' his', ' exact', ' location', '.', ' \n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.1316, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02442231 0.03738694 0.0363504  ... 0.05507552 0.01028269 0.03274353]
 [0.02520861 0.03461991 0.03385828 ... 0.06192749 0.01541629 0.04004306]
 [0.02557409 0.0346911  0.03834007 ... 0.06326037 0.0244614  0.03756526]
 ...
 [0.02560717 0.03240818 0.02975679 ... 0.01926047 0.00719463 0.0139081 ]
 [0.02592123 0.02567333 0.02171952 ... 0.01065943 0.01102759 0.01301218]
 [0.02625137 0.02511091 0.02204352 ... 0.01090111 0.01015071 0.01612191]]

-* TASK 10/20 | SAMPLE 36/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 178/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Mary was initially in the office, but then according to context sentence 8, Mary travelled to the school, which implies that Mary is currently in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' was', ' initially', ' in', ' the', ' office', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '8', ',', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 38), x_tokens=38, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 38)
DEBUG result.interpretability.attn_scores 1748 
 [[0.02010396 0.03053667 0.02857365 ... 0.0149106  0.01432102 0.01793597]
 [0.02051305 0.02602324 0.02584197 ... 0.01826597 0.01980049 0.02385629]
 [0.02099659 0.03368428 0.03485817 ... 0.01121779 0.01217919 0.01403359]
 ...
 [0.02113915 0.02794288 0.02553298 ... 0.01340653 0.01349618 0.01276292]
 [0.02145591 0.02214306 0.01920865 ... 0.0148582  0.01996524 0.01718626]
 [0.02136867 0.02485486 0.02106992 ... 0.01508162 0.01588461 0.01675402]]

-* TASK 10/20 | SAMPLE 36/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 179/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7 (from previous parts), Mary was initially in the office, but then according to context sentence 8 (from previous parts), Mary travelled to the school, which implies that Mary is no longer in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ' (', 'from', ' previous', ' parts', '),', ' Mary', ' was', ' initially', ' in', ' the', ' office', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '8', ' (', 'from', ' previous', ' parts', '),', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 44), x_tokens=44, y_tokens=55, max_supp_attn=0.1636, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 44)
DEBUG result.interpretability.attn_scores 2420 
 [[0.01683664 0.01916372 0.01832087 ... 0.02628326 0.01279947 0.01799485]
 [0.01708624 0.02077963 0.01969963 ... 0.03923906 0.01645498 0.02223973]
 [0.0175861  0.01975148 0.01936849 ... 0.03806956 0.01372451 0.02670712]
 ...
 [0.01775857 0.02136563 0.02005662 ... 0.01002762 0.00858755 0.00970761]
 [0.01813739 0.01730541 0.01585779 ... 0.00846782 0.01095854 0.00978376]
 [0.01803503 0.01693162 0.01591201 ... 0.00720889 0.00890811 0.00903577]]

-* TASK 10/20 | SAMPLE 36/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 180/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8 (from previous parts), Mary travelled to the school, and there is no information that suggests she left the school. 

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ' (', 'from', ' previous', ' parts', '),', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' left', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 50), x_tokens=50, y_tokens=37, max_supp_attn=0.0, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 50)
DEBUG result.interpretability.attn_scores 1850 
 [[0.02524389 0.03367516 0.02973851 ... 0.0207258  0.0094439  0.01163507]
 [0.0254917  0.02872787 0.02897091 ... 0.02589526 0.01534504 0.01180373]
 [0.02639062 0.03560367 0.03518336 ... 0.01751217 0.00891301 0.00809743]
 ...
 [0.02668436 0.03521909 0.03060935 ... 0.01471324 0.00847349 0.01039512]
 [0.02703169 0.02562695 0.02144636 ... 0.02126731 0.01665666 0.01756364]
 [0.02683581 0.02826675 0.02336954 ... 0.01606815 0.01159524 0.01028833]]
Model's predictions for the sample 36:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 2, Fred    |
|          |                 |  moved to the kitchen, which implies that  |
|          |                 |     Fred is currently in the kitchen.      |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to context sentence 5, Bill is  |
|          |                 |  either in the bedroom or the cinema, but  |
|          |                 |    we don't have enough information to     |
|          |                 |       determine his exact location.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 7, Mary    |
|          |                 |   was initially in the office, but then    |
|          |                 |   according to context sentence 8, Mary    |
|          |                 |   travelled to the school, which implies   |
|          |                 |   that Mary is currently in the school.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 7 (from    |
|          |                 |   previous parts), Mary was initially in   |
|          |                 |     the office, but then according to      |
|          |                 |     context sentence 8 (from previous      |
|          |                 |   parts), Mary travelled to the school,    |
|          |                 |  which implies that Mary is no longer in   |
|          |                 |                the office.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 8 (from    |
|          |                 |   previous parts), Mary travelled to the   |
|          |                 |  school, and there is no information that  |
|          |                 |       suggests she left the school.        |
+----------+-----------------+--------------------------------------------+

Metrics for sample 36:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.12 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 37/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 181/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Mary went back to the bedroom, which implies that Mary is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Mary', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02625154 0.04781843 0.05825188 0.07070605 0.07364815 0.07208789
  0.07508743 0.07925121 0.05884695 0.06198758 0.04652334 0.06183529
  0.07242882 0.0852726  0.05334893 0.03187238 0.03088961 0.03438322
  0.03077552 0.03215722 0.02475565 0.0393981  0.0402933  0.01557541
  0.01972087 0.03415944]
 [0.02661614 0.05260735 0.0502772  0.06115129 0.05565308 0.05654532
  0.05716442 0.05537568 0.0465841  0.04853262 0.04091755 0.03963741
  0.04262817 0.09336691 0.09190034 0.03307648 0.02940635 0.02974842
  0.02772126 0.02773467 0.0213389  0.038157   0.04392242 0.01092732
  0.01431094 0.03205935]
 [0.02874204 0.05689941 0.03580518 0.05448369 0.03935433 0.03656757
  0.0317225  0.02250566 0.02205977 0.03379229 0.02700276 0.01637462
  0.01830943 0.02921712 0.03752664 0.02308401 0.01388301 0.01371028
  0.01659856 0.01608661 0.01373766 0.04234762 0.04811449 0.00485788
  0.00642347 0.01714667]
 [0.02728195 0.02556359 0.02754718 0.02346685 0.01627486 0.02422094
  0.02612021 0.02209304 0.02400078 0.0229417  0.02471473 0.02431685
  0.02258415 0.01257398 0.01181088 0.02855049 0.02507068 0.03042942
  0.03155508 0.03364466 0.03549042 0.0295252  0.03831176 0.06348249
  0.06222729 0.03923737]
 [0.02735139 0.04070329 0.04459825 0.0657091  0.05997749 0.04754003
  0.03415908 0.02877485 0.03315302 0.04490922 0.03324412 0.02548512
  0.02505975 0.09658097 0.10004183 0.0356115  0.02618691 0.0208643
  0.02173455 0.0218634  0.01916346 0.03742103 0.05712974 0.008047
  0.00958819 0.03710628]
 [0.02790914 0.02665209 0.02747616 0.04994088 0.04529883 0.04273234
  0.02539891 0.0228484  0.02823367 0.04177921 0.02995668 0.02874397
  0.02709363 0.10523985 0.12503967 0.03545208 0.02972731 0.02535035
  0.02465727 0.02343138 0.01848636 0.03194985 0.03399681 0.00632129
  0.00778579 0.02386289]
 [0.02830307 0.02999591 0.03541927 0.05222933 0.04862093 0.05292458
  0.03326381 0.03106979 0.0367468  0.04890267 0.03468668 0.04499469
  0.0411428  0.08375112 0.07884055 0.03024129 0.02729603 0.02533694
  0.02367399 0.02305087 0.01746438 0.02887231 0.0324185  0.00961739
  0.01074988 0.02229526]
 [0.02739875 0.04021687 0.04667853 0.04055796 0.04304732 0.0483288
  0.03860709 0.0403427  0.03984489 0.04257678 0.03498172 0.04843485
  0.04231663 0.05061891 0.04601717 0.04149023 0.03563746 0.032603
  0.02982807 0.02974975 0.02474861 0.03301848 0.04789668 0.02829374
  0.03043139 0.0357215 ]
 [0.02846672 0.04060854 0.04833581 0.04727875 0.04318839 0.05669452
  0.04352131 0.04584544 0.04844991 0.049176   0.0358167  0.0512942
  0.04629873 0.03917847 0.02599015 0.02857023 0.0271204  0.02714201
  0.02568252 0.02580683 0.01973217 0.03371764 0.03491498 0.01315411
  0.01704816 0.02882242]
 [0.02783595 0.05137711 0.05371488 0.02873793 0.0233912  0.03682986
  0.04426411 0.0416083  0.04442866 0.03015768 0.02836718 0.03731174
  0.03749894 0.01721541 0.01499457 0.04569132 0.03536536 0.03173183
  0.03212478 0.03284079 0.02965442 0.03261252 0.06381606 0.03515635
  0.04041702 0.03532727]
 [0.02828902 0.0661505  0.06492599 0.02709592 0.02259026 0.03171996
  0.04534703 0.03872659 0.04685561 0.02661136 0.02558002 0.03000714
  0.02980511 0.01451584 0.01427872 0.05015495 0.03578402 0.03061446
  0.03284087 0.03521728 0.02801192 0.03016913 0.06734353 0.02567546
  0.02932601 0.03249573]
 [0.02845915 0.03607477 0.04030747 0.02069016 0.01808836 0.02354431
  0.0353329  0.0299739  0.03646414 0.02160588 0.02100163 0.02428965
  0.02305924 0.01227519 0.0124463  0.04110456 0.0309428  0.02582579
  0.02967144 0.03030941 0.02695024 0.028735   0.05416301 0.0380547
  0.04824982 0.03777945]
 [0.02866234 0.01517551 0.01642366 0.01120086 0.01041454 0.01353358
  0.01561837 0.01533358 0.01869852 0.01302043 0.01378301 0.01417949
  0.01407031 0.0062493  0.007101   0.02079996 0.02030211 0.01954846
  0.02537797 0.02730924 0.02861526 0.02115308 0.03632686 0.0564924
  0.0816464  0.04513351]
 [0.02855637 0.02193105 0.02308436 0.01575185 0.01492782 0.0195539
  0.022847   0.02126225 0.02308597 0.01783249 0.02034857 0.02105921
  0.02057029 0.00906277 0.00970345 0.0338986  0.02359731 0.02311798
  0.02425853 0.02524769 0.02641954 0.02646689 0.02975559 0.05356113
  0.06155816 0.04076347]
 [0.02870077 0.0223742  0.02263926 0.01798166 0.01570828 0.02285723
  0.02518976 0.02591201 0.02373901 0.02139422 0.02442551 0.02770564
  0.02829305 0.01020291 0.00914248 0.03450079 0.02704372 0.02872574
  0.02736603 0.02807387 0.03038191 0.02751944 0.02170653 0.04859627
  0.04071769 0.02396889]
 [0.02814302 0.01738384 0.01493053 0.01297925 0.01047257 0.01377497
  0.01861694 0.0185314  0.01701511 0.01437028 0.01922904 0.01684543
  0.02038337 0.00638576 0.00641989 0.03044834 0.02754803 0.03681642
  0.03289769 0.04133276 0.05171828 0.0243026  0.01665605 0.08082658
  0.05229087 0.02839471]
 [0.02889391 0.01708094 0.01595963 0.01394073 0.01191859 0.01647579
  0.01916036 0.0197493  0.01845625 0.01638172 0.02182028 0.02044817
  0.02109767 0.00707358 0.00669387 0.02442544 0.02034942 0.0304448
  0.02693197 0.03848024 0.04857997 0.02107912 0.01422994 0.06314495
  0.0354007  0.02004391]
 [0.02947835 0.01424369 0.0126711  0.01077809 0.00894463 0.01287026
  0.01552357 0.0153846  0.0154612  0.01276392 0.02083603 0.01630028
  0.01689416 0.00574746 0.00559962 0.02073788 0.01934079 0.02459321
  0.02448375 0.02824012 0.04188922 0.01993553 0.01141232 0.04808003
  0.03010667 0.02070655]
 [0.02911212 0.0157179  0.01433233 0.01067444 0.00924043 0.01289116
  0.01860619 0.01725915 0.01714461 0.01279196 0.03153917 0.01843557
  0.01850191 0.00592244 0.00633326 0.02573188 0.02742837 0.02747028
  0.02825871 0.03086081 0.03960792 0.02186865 0.01349719 0.05054208
  0.0318287  0.02355048]
 [0.02814567 0.0241155  0.02212314 0.01645148 0.0170997  0.02316798
  0.03449041 0.03095111 0.02885051 0.0205574  0.03175258 0.02620918
  0.02831864 0.00945896 0.00963956 0.02510734 0.0348595  0.03362016
  0.03779772 0.03728916 0.04101701 0.02652145 0.02256885 0.03766961
  0.04278085 0.0655357 ]
 [0.02940448 0.0201338  0.01940125 0.01556092 0.01251247 0.01731873
  0.02078475 0.02183127 0.02107396 0.01715266 0.02405933 0.02154332
  0.02190211 0.00846904 0.00768741 0.02222927 0.02274545 0.02366719
  0.02563799 0.02599476 0.02714845 0.025748   0.01531286 0.02617237
  0.02959716 0.02376061]
 [0.02957053 0.02171842 0.02406216 0.02232535 0.01822033 0.02558276
  0.02511548 0.03156228 0.02585963 0.02676135 0.02756136 0.03538194
  0.03224288 0.01316165 0.00906783 0.01845621 0.02037941 0.02356343
  0.02284273 0.02117208 0.01971077 0.02818095 0.01487388 0.01572536
  0.0224477  0.02109024]
 [0.02974843 0.02565983 0.02681798 0.02578258 0.01857871 0.02811633
  0.02954101 0.03738113 0.02692621 0.03088376 0.0329689  0.04146991
  0.03860267 0.0143172  0.00977458 0.02089152 0.02086889 0.02455848
  0.02337455 0.02120461 0.01989912 0.02821096 0.01530951 0.01361653
  0.01600783 0.0159181 ]
 [0.02964974 0.02344629 0.02299992 0.02253538 0.01705874 0.02560842
  0.02667731 0.03110861 0.02725481 0.02746921 0.02960333 0.0353221
  0.0356542  0.01260754 0.00939185 0.0245483  0.02278751 0.0266141
  0.02593589 0.02360588 0.02139183 0.02779754 0.01264883 0.0166361
  0.01794963 0.01438951]
 [0.02945197 0.01839474 0.0171868  0.01389573 0.01064095 0.0160491
  0.0200439  0.02246573 0.02183978 0.0173531  0.02299695 0.0227527
  0.02526447 0.00765686 0.00667422 0.02792937 0.02593027 0.02723434
  0.02761684 0.02597824 0.02810624 0.02563175 0.01098395 0.02862292
  0.02767285 0.01726754]
 [0.02946628 0.01913483 0.01734859 0.0145258  0.01071149 0.01528598
  0.02175919 0.02347732 0.02105168 0.0170209  0.02227742 0.02086097
  0.02481942 0.00756166 0.00646001 0.02638852 0.02784703 0.02956456
  0.02942524 0.02661432 0.02983207 0.02309599 0.01075776 0.027197
  0.02959497 0.01914015]
 [0.02950215 0.01941759 0.01735174 0.01485993 0.01184236 0.01562905
  0.02008495 0.02255114 0.02095699 0.01807078 0.02433572 0.02241364
  0.02365338 0.00809101 0.00680801 0.02475902 0.02874002 0.02874902
  0.03104271 0.0262431  0.02908233 0.02327376 0.01177869 0.02295373
  0.02972071 0.02010032]
 [0.02964919 0.02131555 0.01928524 0.01581595 0.01187763 0.01670197
  0.02285091 0.02479948 0.02457305 0.01879406 0.02793103 0.02271945
  0.02512873 0.00828305 0.0070154  0.02658504 0.02797474 0.02949117
  0.0312408  0.0288163  0.03086644 0.02401471 0.01270468 0.02410899
  0.02279758 0.01643878]
 [0.02965425 0.01584995 0.01541272 0.01046851 0.00898218 0.0122516
  0.01820449 0.01849036 0.01924434 0.01300081 0.02907505 0.01702252
  0.01969576 0.00623279 0.00546956 0.02442097 0.03184135 0.02621836
  0.03072382 0.02826335 0.03125777 0.02172654 0.01168319 0.03209028
  0.02479678 0.01929636]
 [0.02832448 0.02059934 0.01960407 0.01237646 0.01063185 0.01533255
  0.0270233  0.0259464  0.02702368 0.01598364 0.03220856 0.02171134
  0.02791364 0.00732615 0.00673502 0.02399504 0.04128788 0.03908865
  0.04294497 0.04423018 0.04552219 0.02607635 0.02025835 0.04485303
  0.04300936 0.06297566]
 [0.02959691 0.01983761 0.02015728 0.01674061 0.01337713 0.02019442
  0.02109067 0.02543284 0.0240342  0.02023921 0.02456195 0.0245036
  0.0235577  0.01108883 0.00885692 0.01752728 0.02493989 0.02211226
  0.02617647 0.0273872  0.02451691 0.02423493 0.01302358 0.01679859
  0.0202424  0.02324117]
 [0.02857195 0.02662075 0.02668698 0.04083344 0.04252625 0.03621785
  0.02351357 0.02420052 0.02967063 0.04228102 0.03066104 0.02996846
  0.02936229 0.06621766 0.08110595 0.02425628 0.0264621  0.02540559
  0.02497667 0.02325894 0.01905591 0.03047957 0.02897704 0.00679429
  0.00988613 0.02648615]
 [0.02834012 0.02821209 0.02683218 0.04610043 0.08716293 0.03653716
  0.02177776 0.02266316 0.0284119  0.04936664 0.03640212 0.03061575
  0.02519326 0.06844236 0.08743591 0.03014027 0.03703662 0.03443964
  0.02981476 0.02560703 0.02230514 0.02778908 0.02862184 0.00573451
  0.0073274  0.02296595]
 [0.02811263 0.02550316 0.02379936 0.03800083 0.08565206 0.02494319
  0.01782039 0.02164159 0.02445192 0.04374721 0.03506219 0.03208804
  0.02433877 0.03057901 0.04140323 0.02528596 0.05579332 0.05262453
  0.04186904 0.03224034 0.0365476  0.02498848 0.026542   0.01171852
  0.01462255 0.02693308]
 [0.02835953 0.03146563 0.02755192 0.03837179 0.05236511 0.02936981
  0.02367092 0.02364924 0.02950772 0.03979019 0.03376773 0.02771772
  0.02631591 0.03005572 0.0332452  0.02203722 0.03758638 0.03459154
  0.03214116 0.03065688 0.02699388 0.04398075 0.03804926 0.00890169
  0.01171805 0.02588551]]

-* TASK 10/20 | SAMPLE 37/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 182/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Julie's location in the context sentences 4 and 5. The information about Julie's location was provided in context sentence 2, which is not part of the current context.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '4', ' and', ' ', '5', '.', ' The', ' information', ' about', ' Julie', "'s", ' location', ' was', ' provided', ' in', ' context', ' sentence', ' ', '2', ',', ' which', ' is', ' not', ' part', ' of', ' the', ' current', ' context', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 32), x_tokens=32, y_tokens=50, max_supp_attn=0.0, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 32)
DEBUG result.interpretability.attn_scores 1600 
 [[0.01849029 0.01962795 0.0204664  ... 0.04332596 0.01135571 0.0101416 ]
 [0.01909912 0.01738789 0.01738097 ... 0.04854272 0.01781653 0.01370565]
 [0.0194003  0.01773816 0.01983297 ... 0.04645942 0.02375791 0.01687181]
 ...
 [0.01973782 0.02022572 0.01561763 ... 0.00919651 0.01073332 0.01342932]
 [0.02000503 0.0203736  0.01603296 ... 0.00894514 0.01082925 0.01381943]
 [0.02011286 0.01773189 0.01442403 ... 0.00967302 0.0118927  0.01398834]]

-* TASK 10/20 | SAMPLE 37/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 183/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Fred journeyed to the kitchen, which implies that Fred is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03031511 0.03775948 0.04550852 ... 0.02335751 0.01428315 0.04378464]
 [0.0308082  0.03240208 0.04197849 ... 0.02408634 0.02818763 0.04410248]
 [0.03162911 0.0391373  0.05165398 ... 0.01753073 0.01390448 0.0344804 ]
 ...
 [0.03179971 0.04068512 0.03865384 ... 0.01772263 0.01490179 0.04166828]
 [0.03196029 0.03313752 0.02959931 ... 0.02137842 0.02877975 0.03000271]
 [0.03203089 0.03670196 0.03229016 ... 0.02189985 0.02120645 0.03777045]]

-* TASK 10/20 | SAMPLE 37/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 184/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, Bill is either in the bedroom or the bedroom, which means Bill is definitely in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' bedroom', ',', ' which', ' means', ' Bill', ' is', ' definitely', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 44), x_tokens=44, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 44)
DEBUG result.interpretability.attn_scores 1452 
 [[0.02823092 0.03985354 0.03845363 ... 0.01302822 0.02935251 0.01751152]
 [0.0284392  0.0362976  0.03656708 ... 0.04866923 0.05084474 0.05718982]
 [0.02943084 0.04162781 0.04534702 ... 0.01928812 0.04171347 0.02490447]
 ...
 [0.02963199 0.04430309 0.04531108 ... 0.0123476  0.01765124 0.01521145]
 [0.02988159 0.03753719 0.03535131 ... 0.01342307 0.01475776 0.01540269]
 [0.03015257 0.036305   0.03488616 ... 0.01262706 0.01598036 0.01541303]]

-* TASK 10/20 | SAMPLE 37/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 185/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill's location in the context sentences 13 and 14. The information about Bill's location was provided in context sentences 10 and 11, which mentioned Bill's possible location as the bedroom, but did not mention the cinema.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '13', ' and', ' ', '14', '.', ' The', ' information', ' about', ' Bill', "'s", ' location', ' was', ' provided', ' in', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ',', ' which', ' mentioned', ' Bill', "'s", ' possible', ' location', ' as', ' the', ' bedroom', ',', ' but', ' did', ' not', ' mention', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 50), x_tokens=50, y_tokens=61, max_supp_attn=0.082, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 50)
DEBUG result.interpretability.attn_scores 3050 
 [[0.01512271 0.01790419 0.02021008 ... 0.01816723 0.01119567 0.01009953]
 [0.01548164 0.01696379 0.01825801 ... 0.0148301  0.0141005  0.01469996]
 [0.0157963  0.02025346 0.02366342 ... 0.01746815 0.00969806 0.00900513]
 ...
 [0.01646823 0.01634297 0.0149699  ... 0.0112076  0.0087949  0.00864935]
 [0.01654037 0.01898433 0.01819886 ... 0.01336612 0.00847853 0.00843392]
 [0.01646747 0.01685612 0.01596429 ... 0.01573117 0.00917946 0.00878108]]
Model's predictions for the sample 37:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Mary    |
|          |                 |  went back to the bedroom, which implies   |
|          |                 |   that Mary is currently in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |      Julie's location in the context       |
|          |                 |  sentences 4 and 5. The information about  |
|          |                 |  Julie's location was provided in context  |
|          |                 |    sentence 2, which is not part of the    |
|          |                 |              current context.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 7, Fred    |
|          |                 |  journeyed to the kitchen, which implies   |
|          |                 |   that Fred is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|  maybe   |       yes       |   According to context sentence 10, Bill   |
|          |                 |  is either in the bedroom or the bedroom,  |
|          |                 |   which means Bill is definitely in the    |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |  Bill's location in the context sentences  |
|          |                 |  13 and 14. The information about Bill's   |
|          |                 |      location was provided in context      |
|          |                 |    sentences 10 and 11, which mentioned    |
|          |                 |  Bill's possible location as the bedroom,  |
|          |                 |      but did not mention the cinema.       |
+----------+-----------------+--------------------------------------------+

Metrics for sample 37:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.4     |
|    Soft-match accuracy     |     0.4     |
| Max attention distribution | 0.07 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 38/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 186/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Fred is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 26), x_tokens=26, y_tokens=24, max_supp_attn=0.0417, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 26)
DEBUG result.interpretability.attn_scores 624 
 [[0.03895556 0.06149304 0.0772174  0.08977578 0.09754065 0.09433021
  0.06846622 0.09039123 0.07404733 0.08038521 0.06538425 0.08137023
  0.08670861 0.09860178 0.05905648 0.04256533 0.04147933 0.04446413
  0.03862557 0.03938386 0.03424924 0.05194941 0.04495267 0.02504966
  0.03247728 0.04429335]
 [0.03862939 0.09889033 0.08266397 0.08063008 0.06350289 0.08445556
  0.23507428 0.15823509 0.1012423  0.0855283  0.09449965 0.08458823
  0.1220389  0.04665956 0.03344654 0.05272844 0.0461965  0.06349815
  0.04708919 0.05328567 0.04327963 0.06083946 0.04428289 0.03215482
  0.03971991 0.04462447]
 [0.04255449 0.06945867 0.04366913 0.06425477 0.04438408 0.04350891
  0.03426137 0.02771462 0.0274414  0.04121581 0.03654331 0.02100272
  0.02386555 0.03524495 0.04538374 0.03092106 0.01958117 0.01895637
  0.02200717 0.02157325 0.02028092 0.0569004  0.05452359 0.00958536
  0.01215561 0.02288698]
 [0.04013273 0.03658282 0.04304848 0.02825688 0.01960991 0.03345551
  0.03016537 0.02966755 0.03816016 0.03117146 0.03206827 0.03278446
  0.03062239 0.01535513 0.01454608 0.04217776 0.03878819 0.0412367
  0.04618498 0.04923207 0.05038084 0.04188829 0.06754605 0.07723821
  0.0752099  0.06548011]
 [0.04053978 0.04912928 0.05408753 0.07685547 0.06737704 0.0561167
  0.03680437 0.03539914 0.04127239 0.05427058 0.04482617 0.03264711
  0.03253366 0.11467734 0.11772849 0.04746662 0.03702666 0.02869043
  0.02871035 0.02907713 0.02792751 0.04972284 0.06318938 0.01668939
  0.01621142 0.04778473]
 [0.04139154 0.03230167 0.03329906 0.05912819 0.05096313 0.0507752
  0.02733877 0.02799883 0.03504793 0.05047372 0.04052306 0.03691579
  0.03519408 0.12382235 0.14397243 0.04635112 0.04125791 0.03447932
  0.0323772  0.03108497 0.02703472 0.04284222 0.03807588 0.01166108
  0.01402251 0.0316935 ]
 [0.04202273 0.03581064 0.04246005 0.06226039 0.05501921 0.06349879
  0.03540415 0.03777704 0.04594074 0.05973671 0.04703924 0.05790842
  0.05333016 0.09936067 0.09117561 0.03883604 0.03718579 0.03401718
  0.0307161  0.03014449 0.0251707  0.03841086 0.03576608 0.01595359
  0.01820209 0.02954548]
 [0.04065695 0.04924088 0.05866423 0.05071601 0.05002799 0.06119512
  0.0415942  0.05164788 0.05221346 0.05432132 0.04830273 0.06579007
  0.05647166 0.06118274 0.05347839 0.05189781 0.04760905 0.04306262
  0.03856745 0.03831857 0.03521466 0.04403929 0.05352206 0.03675951
  0.04229093 0.04934942]
 [0.04228548 0.04703595 0.0580919  0.05552777 0.04733581 0.06761707
  0.0454202  0.05488789 0.06094356 0.0591008  0.04726323 0.06517161
  0.05865391 0.04495144 0.02903203 0.03669235 0.03672248 0.03568832
  0.03325506 0.03349617 0.02846044 0.04384015 0.03853783 0.02075039
  0.0282145  0.0383194 ]
 [0.04130843 0.06112586 0.065986   0.03458999 0.02686455 0.04612401
  0.0479454  0.05245721 0.05950117 0.03794662 0.03907817 0.04989253
  0.04947429 0.02073907 0.01756358 0.05825287 0.04755146 0.04243007
  0.04219646 0.04295412 0.04204027 0.04331696 0.07323478 0.04982917
  0.05748082 0.04873864]
 [0.0419123  0.08128425 0.08061061 0.03253169 0.02582509 0.03901962
  0.04962818 0.04918472 0.06051619 0.03283397 0.03557322 0.03980865
  0.03983099 0.0171094  0.01667154 0.06649141 0.04983646 0.04175169
  0.04318514 0.04646025 0.0402659  0.04054275 0.0755934  0.04127566
  0.04831019 0.04500535]
 [0.0421437  0.04410925 0.04954778 0.02508474 0.02103361 0.02890438
  0.03897794 0.03830215 0.0476778  0.02699745 0.02932835 0.03223972
  0.0310484  0.01477251 0.01492676 0.05457151 0.04379461 0.0361785
  0.04049752 0.04229909 0.04042114 0.03917809 0.06348734 0.05903405
  0.06458273 0.05232095]
 [0.04240599 0.01957611 0.02099314 0.01386476 0.01243798 0.01680139
  0.01783132 0.0200301  0.02454975 0.01651677 0.0194476  0.01906898
  0.01919967 0.0077516  0.00873125 0.02756189 0.02758335 0.02756393
  0.03526891 0.04009957 0.04334853 0.03089836 0.04692319 0.08344433
  0.08763463 0.05800839]
 [0.04244595 0.02712685 0.02871478 0.01914315 0.01745083 0.02515375
  0.02559216 0.02782695 0.03060016 0.0229858  0.02897186 0.02989005
  0.02902845 0.01123129 0.01194501 0.04530786 0.0352246  0.03404468
  0.03531284 0.03548539 0.03834502 0.03572333 0.03443029 0.06968129
  0.06995897 0.05402632]
 [0.04270381 0.03090131 0.03129782 0.02505118 0.02058449 0.03240205
  0.0330265  0.03820877 0.03334878 0.03138118 0.03813805 0.04347206
  0.04363035 0.01470586 0.01252479 0.04283719 0.0374904  0.03929754
  0.03835255 0.03676374 0.03990024 0.03887471 0.02508846 0.05517679
  0.0449205  0.03250844]
 [0.04197218 0.02447734 0.0205222  0.01725904 0.01320135 0.01922986
  0.0277333  0.03205899 0.02359506 0.0201056  0.0313332  0.02595427
  0.032993   0.00843805 0.00845828 0.04431357 0.03708937 0.05402132
  0.05756194 0.05678008 0.07005702 0.03402485 0.0193215  0.0876453
  0.07446622 0.03901939]
 [0.04278815 0.02503532 0.02203071 0.01840325 0.01500038 0.02221148
  0.02560158 0.03055944 0.02522011 0.02280315 0.03594549 0.03359225
  0.03425801 0.00977698 0.00901936 0.03749834 0.03795457 0.04051842
  0.04624107 0.03982997 0.05286661 0.03410953 0.0188489  0.0709075
  0.05166084 0.02751071]
 [0.04280014 0.01926922 0.01706267 0.01295866 0.01150029 0.01621676
  0.02209894 0.02424589 0.02167016 0.01676031 0.03973437 0.02689708
  0.02766926 0.00707732 0.00717894 0.03885762 0.04228693 0.04543263
  0.05539806 0.04671124 0.05780786 0.02995021 0.01650593 0.07494862
  0.05063777 0.03067697]
 [0.04110814 0.03113891 0.02581715 0.01878199 0.01868114 0.02184046
  0.0308728  0.03034831 0.03553906 0.02312449 0.03270238 0.02498196
  0.02899078 0.01040383 0.01108161 0.0330894  0.04000193 0.0544263
  0.07424252 0.11063804 0.08156571 0.03941368 0.03873439 0.07468522
  0.06550513 0.07414766]
 [0.04353942 0.02483643 0.02481084 0.02077317 0.01582356 0.02374276
  0.02330242 0.02973522 0.02945936 0.02468213 0.03293426 0.03429374
  0.03100638 0.0117152  0.01004658 0.02835795 0.03042381 0.03314359
  0.04100166 0.03541782 0.03784654 0.03275198 0.01713439 0.02999656
  0.03432826 0.03486062]
 [0.04232656 0.0312541  0.03139921 0.04867209 0.04749994 0.04387768
  0.02658843 0.02990846 0.03543739 0.05213622 0.04129913 0.04133888
  0.03732416 0.07643212 0.09193437 0.03188728 0.03907104 0.03574494
  0.03280633 0.02964253 0.02865386 0.03889849 0.03115151 0.01249031
  0.01598852 0.03365193]
 [0.04201312 0.03329253 0.03022803 0.05392332 0.09599481 0.04305582
  0.02536716 0.02734921 0.03316956 0.05778839 0.04775853 0.03986762
  0.03199027 0.07857223 0.1030683  0.03833684 0.05198707 0.04891297
  0.03852083 0.03270255 0.03515697 0.03674261 0.03059816 0.01010279
  0.01282841 0.02870996]
 [0.04144134 0.03031364 0.02709446 0.04550633 0.09638032 0.03086964
  0.02204557 0.02679702 0.02924739 0.05126354 0.04668275 0.04320123
  0.03129619 0.03629354 0.04863206 0.03381253 0.08125643 0.07243628
  0.0575714  0.04085388 0.05770285 0.0344049  0.02854251 0.01917072
  0.02457726 0.03441798]
 [0.04192214 0.03631553 0.03068286 0.04605127 0.06596097 0.03559728
  0.02885933 0.02926831 0.03415872 0.04647053 0.04462269 0.0373224
  0.03284086 0.0351251  0.04039773 0.02918721 0.05260098 0.05000388
  0.04430966 0.03776559 0.04202284 0.06073656 0.04000884 0.01576973
  0.01861553 0.03241922]]

-* TASK 10/20 | SAMPLE 38/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 187/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Julie is either in the bedroom or the kitchen, but there is no mention of the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 32), x_tokens=32, y_tokens=33, max_supp_attn=0.0, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 32)
DEBUG result.interpretability.attn_scores 1056 
 [[0.02836386 0.04594205 0.04649948 ... 0.01158139 0.0738909  0.07847859]
 [0.02907265 0.04357203 0.04223108 ... 0.01618855 0.07905162 0.05493345]
 [0.0295979  0.04283068 0.04629791 ... 0.03005235 0.05143896 0.04641489]
 ...
 [0.02960925 0.03684695 0.03514457 ... 0.00728152 0.11789272 0.04702616]
 [0.0298997  0.02853757 0.02506194 ... 0.00990279 0.0708832  0.02943798]
 [0.03008573 0.02841878 0.02582897 ... 0.00791741 0.10052796 0.04367135]]

-* TASK 10/20 | SAMPLE 38/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 188/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Julie's location in the context sentences 7 and 8. The previous information about Julie's location is in context sentence 4, which states that Julie is either in the bedroom or the kitchen, but there is no mention of the office.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '7', ' and', ' ', '8', '.', ' The', ' previous', ' information', ' about', ' Julie', "'s", ' location', ' is', ' in', ' context', ' sentence', ' ', '4', ',', ' which', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' office', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(62, 38), x_tokens=38, y_tokens=62, max_supp_attn=0.0161, attn_on_target=0.0161)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (62, 38)
DEBUG result.interpretability.attn_scores 2356 
 [[0.01481645 0.02148553 0.02007316 ... 0.00726788 0.01589571 0.01321193]
 [0.01507214 0.02165867 0.02113975 ... 0.01605275 0.02579375 0.01637774]
 [0.01549723 0.02151841 0.02196477 ... 0.00536334 0.01123161 0.00808999]
 ...
 [0.01610909 0.01482874 0.01308356 ... 0.00930949 0.01233589 0.01457903]
 [0.01610314 0.01760411 0.01691497 ... 0.00833294 0.01385912 0.01320106]
 [0.01623525 0.01542853 0.01531244 ... 0.00693382 0.01114563 0.01182661]]

-* TASK 10/20 | SAMPLE 38/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 189/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Bill went back to the bedroom, and there is no information that suggests Bill has moved from the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' has', ' moved', ' from', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 44), x_tokens=44, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 44)
DEBUG result.interpretability.attn_scores 1540 
 [[0.02658284 0.03299293 0.03291262 ... 0.01203784 0.02933419 0.05070005]
 [0.02695898 0.0331403  0.03258908 ... 0.01844448 0.02267478 0.02822747]
 [0.02773415 0.03742381 0.04047577 ... 0.01570991 0.03491472 0.043576  ]
 ...
 [0.02785741 0.03983789 0.03964691 ... 0.01098955 0.05110903 0.06965379]
 [0.02830499 0.0310402  0.02882168 ... 0.015514   0.03131497 0.05420609]
 [0.02821933 0.03252197 0.03129993 ... 0.01430468 0.02360552 0.10071552]]

-* TASK 10/20 | SAMPLE 38/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 190/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 14, Julie went back to the school, which implies that Julie is currently in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Julie', ' went', ' back', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03029026 0.03667025 0.04477364 ... 0.01787048 0.03283876 0.0368283 ]
 [0.03077517 0.03267435 0.03889597 ... 0.02253327 0.02607044 0.03504489]
 [0.03158344 0.04156008 0.05182183 ... 0.01375647 0.03380112 0.02422364]
 ...
 [0.0317086  0.04480907 0.04606486 ... 0.01550722 0.04371662 0.03243115]
 [0.03222045 0.03185977 0.03130124 ... 0.0215207  0.04374551 0.04140187]
 [0.03194867 0.03767389 0.03661869 ... 0.02025144 0.03852334 0.04868316]]
Model's predictions for the sample 38:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 1, Fred is  |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 4, Julie   |
|          |                 |  is either in the bedroom or the kitchen,  |
|          |                 |    but there is no mention of the park.    |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |  There is no mention of Julie's location   |
|          |                 |   in the context sentences 7 and 8. The    |
|          |                 |     previous information about Julie's     |
|          |                 |  location is in context sentence 4, which  |
|          |                 |     states that Julie is either in the     |
|          |                 |  bedroom or the kitchen, but there is no   |
|          |                 |           mention of the office.           |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 7, Bill    |
|          |                 |   went back to the bedroom, and there is   |
|          |                 |   no information that suggests Bill has    |
|          |                 |          moved from the bedroom.           |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 14, Julie   |
|          |                 |   went back to the school, which implies   |
|          |                 |   that Julie is currently in the school.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 38:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 39/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 191/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentences do not mention Fred being in the cinema. Sentence 1 states that Fred travelled to the school, and sentence 2 states that Fred is in the office. There is no information provided about Fred being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '1', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' school', ',', ' and', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' is', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 26), x_tokens=26, y_tokens=58, max_supp_attn=0.1552, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 26)
DEBUG result.interpretability.attn_scores 1508 
 [[0.0158616  0.02801058 0.03134907 ... 0.01001354 0.00706438 0.01378655]
 [0.01600761 0.0382675  0.03379141 ... 0.0087845  0.00508103 0.01261134]
 [0.01724673 0.0401168  0.02397683 ... 0.00538905 0.00312942 0.00661669]
 ...
 [0.01692927 0.01824876 0.01872174 ... 0.00545355 0.00270357 0.00932682]
 [0.01680109 0.01417534 0.01475673 ... 0.00787146 0.00507131 0.01179196]
 [0.01700133 0.0167572  0.01671901 ... 0.00666748 0.00412974 0.00955549]]

-* TASK 10/20 | SAMPLE 39/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 192/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 5 explicitly states that Bill is in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 32), x_tokens=32, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 32)
DEBUG result.interpretability.attn_scores 608 
 [[0.04982452 0.07442994 0.07317062 0.09197557 0.0794056  0.0834919
  0.05999858 0.0553713  0.06509479 0.07388183 0.05373236 0.05260189
  0.05751599 0.12667729 0.12996227 0.05532591 0.03580695 0.03784093
  0.03763999 0.0403351  0.03842298 0.05317432 0.08787057 0.04591719
  0.02787529 0.05794298 0.06297124 0.0704935  0.1676504  0.10291111
  0.02440374 0.0167893 ]
 [0.05119272 0.06725129 0.0687779  0.10579468 0.09455229 0.11302772
  0.06197223 0.05996673 0.07681017 0.09754127 0.0695185  0.07233621
  0.07631171 0.17679495 0.15364127 0.05752401 0.03537653 0.04395009
  0.04004616 0.0428252  0.03953318 0.05683905 0.06252407 0.03859052
  0.02745659 0.0533333  0.0666112  0.05819619 0.12525652 0.11982603
  0.03529314 0.02379409]
 [0.05214306 0.06507303 0.07592943 0.08866939 0.07280841 0.09167565
  0.06401697 0.06525134 0.07039955 0.07856995 0.05806065 0.07047318
  0.07273584 0.12020025 0.09200921 0.04894869 0.03279811 0.03699244
  0.03536719 0.03864463 0.03447275 0.05430238 0.05980815 0.04448699
  0.03306881 0.05083341 0.05730331 0.04989488 0.08668111 0.10922908
  0.05115517 0.04146181]
 [0.05020586 0.07203079 0.0787909  0.05758897 0.0447201  0.0628966
  0.06480832 0.06975254 0.06285626 0.05445741 0.05045982 0.06207398
  0.06356706 0.04045195 0.03603825 0.05990927 0.04290802 0.04318788
  0.04266873 0.04601233 0.04171945 0.06007732 0.08210061 0.07733543
  0.05941349 0.07021853 0.07134315 0.06272022 0.05902768 0.11867455
  0.09051349 0.11327562]
 [0.05183797 0.06431639 0.07157949 0.04142775 0.02763465 0.04678722
  0.06271383 0.05505094 0.05818821 0.03729538 0.04114768 0.04243436
  0.04611773 0.02470533 0.02460578 0.06081289 0.0411676  0.03751496
  0.04440667 0.04750086 0.04132379 0.05128491 0.06860711 0.07153124
  0.06143489 0.0564195  0.06213925 0.038209   0.03666257 0.05876457
  0.05729764 0.14948136]
 [0.05323073 0.02782634 0.03040257 0.02240393 0.01439963 0.02504014
  0.02954556 0.02846098 0.0318822  0.0214433  0.02852351 0.02502307
  0.02812831 0.0127442  0.01296382 0.03592056 0.03007703 0.02847681
  0.0356666  0.03749973 0.03376035 0.03638811 0.02998313 0.04465379
  0.04797278 0.0394004  0.03062763 0.02512265 0.02235431 0.02088827
  0.03287441 0.06610995]
 [0.05207909 0.05146768 0.0541348  0.03467936 0.02267603 0.04381878
  0.05221059 0.04946481 0.04581601 0.03497751 0.03925472 0.04579377
  0.04365021 0.02014596 0.01955783 0.05399054 0.04863958 0.04136243
  0.05046837 0.05215861 0.04784529 0.05888058 0.05851046 0.07601169
  0.07909229 0.06237954 0.06349124 0.03920105 0.03429748 0.06411585
  0.06906468 0.10784079]
 [0.05323013 0.06694582 0.07061712 0.05734944 0.03397229 0.06327792
  0.06723689 0.07279462 0.06138849 0.06169148 0.0606434  0.08905073
  0.07220598 0.03378341 0.02678459 0.05674937 0.04947514 0.0518291
  0.05217909 0.05494185 0.04925303 0.06014988 0.05410394 0.0621409
  0.06815068 0.0615347  0.07316312 0.05083738 0.03962691 0.06990377
  0.10236304 0.08916374]
 [0.05417766 0.04800173 0.05249234 0.03923053 0.02562818 0.04293489
  0.05517699 0.05152696 0.04550771 0.03898446 0.04719254 0.04978907
  0.04990862 0.02299229 0.02029043 0.05249238 0.04355691 0.03990033
  0.04650799 0.04889167 0.04510871 0.05442772 0.04148704 0.06237335
  0.06856661 0.0491345  0.05662732 0.04088064 0.03087369 0.04602101
  0.07397316 0.09259076]
 [0.05359729 0.03710805 0.03434832 0.02534045 0.01803565 0.02786974
  0.04050372 0.03845409 0.03611462 0.02641191 0.04113715 0.03524606
  0.03841822 0.01510652 0.01531414 0.05601562 0.05282962 0.04387435
  0.05425183 0.0523866  0.05195121 0.05126745 0.03074233 0.06148436
  0.06858048 0.04253276 0.03655556 0.03801083 0.02295355 0.02684271
  0.05866569 0.0561485 ]
 [0.05337228 0.0383182  0.03309295 0.0252399  0.017424   0.02679031
  0.04849311 0.04580623 0.03737798 0.02634409 0.04816404 0.0359266
  0.04694451 0.01470646 0.01416869 0.07030442 0.06074506 0.05792101
  0.06517487 0.0642378  0.07208307 0.04934117 0.02795597 0.06107623
  0.08517588 0.04331297 0.02878165 0.0388325  0.01990648 0.02011147
  0.06166531 0.04722165]
 [0.05414807 0.03510367 0.0325583  0.02489095 0.01944401 0.02748842
  0.04267877 0.04291222 0.03730761 0.02803934 0.05159454 0.04083786
  0.04280551 0.0155197  0.014418   0.05155573 0.07317254 0.05342159
  0.07317186 0.05970871 0.06043823 0.04822747 0.02517274 0.04432197
  0.09108479 0.04542968 0.03083563 0.03902221 0.0187599  0.01916154
  0.05804926 0.03526141]
 [0.05396487 0.03348701 0.03053731 0.02193373 0.01825909 0.0244574
  0.04378998 0.03982975 0.03669436 0.02443618 0.05667844 0.03549771
  0.0409907  0.01406636 0.0133779  0.05697822 0.07618546 0.05752121
  0.07145298 0.06316131 0.06174146 0.04950338 0.02575036 0.04901359
  0.07666329 0.05126045 0.03127762 0.04021122 0.01859904 0.01589493
  0.05436447 0.02721749]
 [0.05287829 0.04558143 0.04615776 0.02981769 0.02247516 0.04808958
  0.07200872 0.07420529 0.06112376 0.03402818 0.04969894 0.0510825
  0.0583786  0.01975902 0.01585624 0.04938437 0.05668218 0.05333818
  0.05651646 0.05986994 0.05015741 0.05230819 0.03969    0.05308948
  0.0525341  0.05725049 0.03918153 0.04213007 0.02931238 0.02934066
  0.05226771 0.03497612]
 [0.05452051 0.0388986  0.0402124  0.03203265 0.0219899  0.03542773
  0.04851206 0.05622469 0.04497489 0.03507306 0.04537329 0.04270225
  0.04717488 0.02197312 0.01686326 0.03685956 0.03761585 0.04095399
  0.04349211 0.04762789 0.04359005 0.05013124 0.03188662 0.03792511
  0.0391219  0.04555663 0.04763143 0.04174219 0.02931649 0.03293322
  0.06033621 0.03195717]
 [0.05276611 0.05030688 0.05291792 0.07181913 0.06027757 0.06628744
  0.04784154 0.0497421  0.060162   0.07657264 0.05448533 0.06272341
  0.0626123  0.0945807  0.1063978  0.04131316 0.03850929 0.04635176
  0.04226044 0.04776469 0.04314    0.05123718 0.05739591 0.03645055
  0.02773942 0.05432126 0.06572721 0.06677542 0.07732762 0.05400427
  0.04448679 0.02020277]
 [0.05226578 0.06508712 0.05715666 0.09531427 0.19586203 0.07410942
  0.04876795 0.05012707 0.06115057 0.10156671 0.07431541 0.07117403
  0.05518924 0.12175984 0.1575787  0.05762782 0.06731788 0.07943729
  0.05883146 0.0598504  0.06603722 0.05051968 0.07666094 0.03833323
  0.02228803 0.05593937 0.08023503 0.07243893 0.07524518 0.04392721
  0.01980119 0.01536107]
 [0.05197925 0.05596755 0.04701107 0.0642309  0.12308297 0.04200798
  0.0400417  0.04536742 0.04827235 0.07451369 0.06814419 0.05879575
  0.04664759 0.0459085  0.06945789 0.05571756 0.11104517 0.12891553
  0.08871535 0.07414772 0.10908657 0.0469539  0.06359792 0.05406187
  0.03744988 0.05502067 0.05257137 0.088122   0.04339194 0.02414067
  0.027935   0.01743841]
 [0.0525859  0.06279843 0.05011206 0.07026067 0.08735248 0.05452121
  0.04968251 0.04969095 0.05887853 0.07417157 0.06187554 0.05643754
  0.050697   0.0581241  0.06071386 0.04256989 0.06609104 0.07721011
  0.06118183 0.06243496 0.07033512 0.06498613 0.0761522  0.0412025
  0.02633082 0.04817887 0.04292548 0.09715919 0.06275674 0.02330904
  0.02548993 0.01370805]]

-* TASK 10/20 | SAMPLE 39/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 193/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Julie travelled to the school, which implies that she is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Julie', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.1071, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.03330481 0.05058089 0.04835404 ... 0.01687308 0.06323384 0.06477048]
 [0.03390231 0.04696164 0.03952909 ... 0.0447437  0.02879008 0.03707346]
 [0.0347223  0.05311946 0.05220706 ... 0.02526536 0.06183473 0.04985534]
 ...
 [0.0349813  0.04684471 0.046918   ... 0.01229727 0.12197401 0.06044725]
 [0.03554516 0.03684508 0.03460644 ... 0.01775703 0.07827699 0.0374987 ]
 [0.03535623 0.0402531  0.0358026  ... 0.01252437 0.09670743 0.07175852]]

-* TASK 10/20 | SAMPLE 39/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 194/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Julie's location. The sentences only mention Mary's locations, which are the cinema and the bedroom.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.', ' The', ' sentences', ' only', ' mention', ' Mary', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ' and', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 44), x_tokens=44, y_tokens=37, max_supp_attn=0.0811, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 44)
DEBUG result.interpretability.attn_scores 1628 
 [[0.02502277 0.03024295 0.03292399 ... 0.02470635 0.02437186 0.04773317]
 [0.0257007  0.0266311  0.03144048 ... 0.01964314 0.01710863 0.02546821]
 [0.02619082 0.02805854 0.03335278 ... 0.02049121 0.02148076 0.03271728]
 ...
 [0.02670762 0.03179439 0.02643019 ... 0.0282969  0.03901212 0.02868516]
 [0.02707929 0.03672843 0.03134949 ... 0.02470635 0.03646689 0.03391046]
 [0.02719275 0.03198327 0.02821426 ... 0.02074678 0.02921401 0.03930806]]

-* TASK 10/20 | SAMPLE 39/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 195/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 states that Bill journeyed to the park, which implies that he is in the park. There is no information provided about Bill being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' he', ' is', ' in', ' the', ' park', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.0, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02317168 0.04144115 0.03851994 ... 0.04366235 0.04142543 0.01483591]
 [0.02369057 0.03585256 0.0336194  ... 0.01747061 0.03545856 0.01967686]
 [0.02414344 0.04167483 0.04200344 ... 0.03478946 0.03192824 0.01336826]
 ...
 [0.02435507 0.03627041 0.0291618  ... 0.09349648 0.03182066 0.01167515]
 [0.02491255 0.03059468 0.02237131 ... 0.08202442 0.02794369 0.01568893]
 [0.02469998 0.03220472 0.02225641 ... 0.08552039 0.03303396 0.01387231]]
Model's predictions for the sample 39:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Fred being in the cinema. Sentence 1    |
|          |                 |     states that Fred travelled to the      |
|          |                 |  school, and sentence 2 states that Fred   |
|          |                 |       is in the office. There is no        |
|          |                 |  information provided about Fred being in  |
|          |                 |                the cinema.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 5 explicitly states that Bill   |
|          |                 |             is in the kitchen.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 8 explicitly states that Julie   |
|          |                 |   travelled to the school, which implies   |
|          |                 |         that she is in the school.         |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |  The context sentences do not provide any  |
|          |                 |  information about Julie's location. The   |
|          |                 |  sentences only mention Mary's locations,  |
|          |                 |   which are the cinema and the bedroom.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   Sentence 14 states that Bill journeyed   |
|          |                 |  to the park, which implies that he is in  |
|          |                 |     the park. There is no information      |
|          |                 |  provided about Bill being in the cinema.  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 39:
+----------------------------+------------+
|           Metric           |   Before   |
+----------------------------+------------+
|    Exact-match accuracy    |    0.8     |
|    Soft-match accuracy     |    0.8     |
| Max attention distribution | 0.1 ± 0.04 |
+----------------------------+------------+

-* TASK 10/20 | SAMPLE 40/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 196/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 2 explicitly states that Julie is in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.08, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03740204 0.05964039 0.07365672 0.09387125 0.09582573 0.09148908
  0.06950484 0.08833607 0.07324226 0.08119318 0.05969826 0.07608856
  0.08604607 0.10418338 0.06101413 0.03924801 0.03264431 0.04029248
  0.03780831 0.04231515 0.03588435 0.04981244 0.04696597 0.0330282
  0.01845245 0.03282545]
 [0.03723582 0.09217786 0.07101254 0.06300788 0.04710904 0.06365583
  0.19166157 0.1293598  0.07639799 0.05970412 0.07751963 0.06134644
  0.10274367 0.02992131 0.0248314  0.05036132 0.04522761 0.06213394
  0.05123374 0.06235721 0.05504995 0.05821216 0.04670234 0.05255739
  0.03677629 0.03956435]
 [0.04081258 0.06611336 0.04133796 0.06156342 0.04413775 0.04153318
  0.03322997 0.0262805  0.0278151  0.04023936 0.03318608 0.01940104
  0.02294674 0.03543374 0.04489689 0.0301217  0.01508627 0.01675652
  0.02265683 0.02407692 0.02270443 0.05543687 0.05887895 0.01473855
  0.00664793 0.01555173]
 [0.03837105 0.04893785 0.05261129 0.02989775 0.02030334 0.03691863
  0.03429977 0.03191516 0.04181132 0.03190403 0.03189612 0.03326854
  0.03155458 0.01566291 0.01482043 0.04565734 0.04202188 0.04311191
  0.04808943 0.04720057 0.04179943 0.04327199 0.06716303 0.06648563
  0.07098727 0.06601318]
 [0.03885888 0.04705892 0.05110008 0.07593197 0.06631041 0.05437735
  0.03561581 0.03400826 0.04143025 0.05300064 0.04043565 0.03011654
  0.03131028 0.11569011 0.11767319 0.046337   0.028715   0.02589077
  0.02893303 0.03215989 0.0312345  0.04900059 0.06742934 0.0244622
  0.00958553 0.03311665]
 [0.03965202 0.03078582 0.03161848 0.05881084 0.04956959 0.04978475
  0.02693016 0.02678719 0.03547176 0.04960948 0.03602512 0.0341721
  0.03394276 0.12426132 0.1450244  0.0456275  0.03208417 0.03119728
  0.03281925 0.03463917 0.03021451 0.04227993 0.04131278 0.01750503
  0.00787137 0.02172141]
 [0.0402775  0.0343606  0.04057419 0.06155073 0.05411834 0.06258503
  0.03492468 0.03645817 0.04623673 0.05826682 0.04212479 0.05379741
  0.05116685 0.1001087  0.09073187 0.03800537 0.0291335  0.03068873
  0.0311415  0.03365867 0.02817779 0.03804008 0.03846668 0.02297914
  0.01103627 0.02097965]
 [0.03890194 0.04847313 0.05739801 0.05011075 0.04953688 0.05991789
  0.04127105 0.04965081 0.05248675 0.05382075 0.04481116 0.06250176
  0.05478071 0.0619357  0.05426779 0.05167337 0.04118521 0.04050331
  0.03795049 0.04084984 0.03696936 0.04302365 0.05510344 0.04308635
  0.03260568 0.03876182]
 [0.03924695 0.05687735 0.06612241 0.03869931 0.03112299 0.04867115
  0.0494518  0.05680026 0.05489613 0.04141335 0.04035161 0.05097385
  0.05270843 0.02872805 0.01996885 0.05098566 0.03860874 0.03804893
  0.03795325 0.03959541 0.03701534 0.03839347 0.06462628 0.05429146
  0.04401423 0.05113442]
 [0.040324   0.07539732 0.08232306 0.03382523 0.02364824 0.04295398
  0.04858272 0.0482899  0.05887198 0.03405578 0.03188071 0.0411829
  0.03984371 0.01883188 0.01527103 0.05805454 0.03645111 0.03457943
  0.03782005 0.04273226 0.03726848 0.03753284 0.07320897 0.0460407
  0.03039346 0.03648037]
 [0.04030158 0.04424007 0.05126063 0.02703735 0.02049078 0.03183121
  0.04052509 0.04051173 0.04563614 0.0289875  0.02874895 0.03415185
  0.03195893 0.01611804 0.01434865 0.05631431 0.04313039 0.03571462
  0.0404709  0.04280618 0.03887649 0.03724823 0.05624537 0.05885464
  0.05145409 0.04653941]
 [0.04066677 0.02318637 0.02754292 0.01785525 0.01484383 0.02245289
  0.02493541 0.02765468 0.04059258 0.0218748  0.02025704 0.02238665
  0.02202152 0.01124983 0.01072054 0.03718187 0.03495396 0.02975071
  0.03696289 0.04049732 0.03705993 0.03109085 0.0470386  0.06830534
  0.07274373 0.07190026]
 [0.04032604 0.03253485 0.03502279 0.02372032 0.01991589 0.03136164
  0.03136145 0.03376818 0.03387193 0.02704539 0.02962993 0.03536071
  0.03115444 0.01302471 0.01265837 0.04907878 0.04112782 0.03604307
  0.03946605 0.03895419 0.03665398 0.0374724  0.03479877 0.05610153
  0.07062853 0.05232215]
 [0.04108078 0.0428494  0.04694378 0.04092389 0.02964112 0.05331313
  0.04389485 0.05394711 0.0484951  0.05276584 0.04974411 0.08012749
  0.06076309 0.02359641 0.01620221 0.034766   0.03597153 0.038638
  0.03772412 0.0384616  0.03382719 0.03947849 0.02671376 0.02722387
  0.02575694 0.02367211]
 [0.04153426 0.03011795 0.031672   0.02555008 0.02162922 0.03112356
  0.03305512 0.03495135 0.03173123 0.03051034 0.03714281 0.03961883
  0.03654294 0.01382282 0.01225514 0.03545639 0.03916854 0.0329191
  0.03585796 0.03584847 0.03520993 0.03771657 0.02310839 0.03277611
  0.04664497 0.02810891]
 [0.04076945 0.02236242 0.02007121 0.016211   0.01417712 0.01885758
  0.02354799 0.02527772 0.02367418 0.01968614 0.03134708 0.02624761
  0.02789439 0.00839515 0.00907073 0.0370179  0.05277511 0.0383769
  0.04019139 0.03744996 0.04357836 0.03368483 0.01893407 0.04234134
  0.08535258 0.04994669]
 [0.04025137 0.02198838 0.01831961 0.01565287 0.01273047 0.0178131
  0.02467676 0.0278165  0.02251866 0.01840985 0.02993947 0.02274692
  0.02831839 0.00761856 0.00797031 0.03367794 0.05462868 0.04901481
  0.04776575 0.04424193 0.06327996 0.0314293  0.01743705 0.05203823
  0.10462855 0.05484781]
 [0.04103149 0.02184452 0.01913962 0.01573532 0.01393182 0.01979014
  0.02444293 0.02736021 0.0236373  0.02026978 0.04058832 0.03228033
  0.02974203 0.00811738 0.00806552 0.03305461 0.05552777 0.0415365
  0.04988727 0.04090353 0.04719012 0.03053109 0.014673   0.03484201
  0.08181597 0.04219317]
 [0.04089627 0.02003184 0.01731093 0.01314131 0.01224365 0.0167017
  0.02511544 0.02554698 0.02242382 0.01705808 0.05145286 0.02849894
  0.02827487 0.00701411 0.00728763 0.03492158 0.05491227 0.0445331
  0.05213645 0.04525356 0.05277449 0.03049724 0.01517201 0.04451215
  0.05749285 0.06542161]
 [0.03980422 0.02790246 0.02456312 0.01798209 0.01544639 0.02213143
  0.03590033 0.03443139 0.03436364 0.02123246 0.0364313  0.02532162
  0.03284905 0.00943257 0.00956299 0.03566495 0.03600543 0.04149648
  0.04681749 0.04840286 0.05958043 0.03657529 0.02992167 0.10248154
  0.06695767 0.07447979]
 [0.04171718 0.02431983 0.02439259 0.02168284 0.01603511 0.02502129
  0.02465814 0.02959524 0.02984341 0.02511333 0.03211042 0.03207704
  0.03038365 0.01198795 0.01056273 0.02493555 0.02890831 0.03492399
  0.03628861 0.03476913 0.03495354 0.03232334 0.01792395 0.02751609
  0.02451264 0.03920779]
 [0.04055186 0.03074397 0.02982697 0.04969533 0.04692915 0.04596013
  0.02659081 0.02885775 0.03526453 0.0522996  0.03845098 0.03930631
  0.03773914 0.08013183 0.09357493 0.03133282 0.02913015 0.03211626
  0.03225746 0.03238245 0.0309507  0.03901499 0.0346219  0.01798833
  0.00996006 0.02395758]
 [0.04029059 0.03175973 0.02862961 0.05268574 0.09524456 0.04200495
  0.02467366 0.02648079 0.03311154 0.05682449 0.04275506 0.03641475
  0.03072201 0.08029614 0.10371254 0.0375564  0.03989177 0.04643598
  0.03795739 0.03609904 0.0361844  0.03604585 0.03304148 0.01491998
  0.00735441 0.0201949 ]
 [0.03958033 0.02999588 0.02697145 0.04684604 0.11019783 0.03172588
  0.02213159 0.02649273 0.03030702 0.0548002  0.04801295 0.04369611
  0.03133977 0.03775831 0.05329066 0.03408131 0.06951963 0.08095635
  0.05618485 0.04372833 0.05194912 0.03329122 0.02957062 0.02470572
  0.0147782  0.02587675]
 [0.04011505 0.0362997  0.03057804 0.04801144 0.07486071 0.03802454
  0.02901803 0.02942148 0.03586864 0.04991472 0.04545964 0.03891566
  0.033252   0.03667916 0.04221711 0.02888778 0.04319081 0.05434084
  0.04362556 0.04061638 0.04161318 0.05859632 0.04094155 0.02021854
  0.01154843 0.025182  ]]

-* TASK 10/20 | SAMPLE 40/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 197/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences 4 and 5 do not mention the kitchen as a possible location for Fred. They only mention the bedroom, park, and office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ' do', ' not', ' mention', ' the', ' kitchen', ' as', ' a', ' possible', ' location', ' for', ' Fred', '.', ' They', ' only', ' mention', ' the', ' bedroom', ',', ' park', ',', ' and', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.1842, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02451275 0.038253   0.03844829 ... 0.01171447 0.07315916 0.07638028]
 [0.02505313 0.04102827 0.03880829 ... 0.02201582 0.07683756 0.05114235]
 [0.02564066 0.03686112 0.03866474 ... 0.02341592 0.06301814 0.04584371]
 ...
 [0.02555088 0.03364006 0.03029837 ... 0.00804452 0.09526836 0.0531285 ]
 [0.02570225 0.02623973 0.02249948 ... 0.01159258 0.05497295 0.0320195 ]
 [0.02586628 0.02741962 0.02433874 ... 0.00932665 0.08128052 0.05199324]]

-* TASK 10/20 | SAMPLE 40/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 198/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred's location in the context sentences 7 and 8. They only mention Julie and Mary's movements.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '7', ' and', ' ', '8', '.', ' They', ' only', ' mention', ' Julie', ' and', ' Mary', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 38), x_tokens=38, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 38)
DEBUG result.interpretability.attn_scores 1368 
 [[0.02586485 0.02994183 0.02733562 ... 0.01756679 0.02677415 0.02186159]
 [0.0261467  0.03291307 0.03163765 ... 0.02823622 0.03240285 0.0312789 ]
 [0.02695807 0.03184507 0.03290751 ... 0.01386709 0.02302359 0.01669358]
 ...
 [0.02733531 0.02671445 0.02154051 ... 0.03398591 0.03982216 0.04600914]
 [0.02784281 0.029532   0.02637907 ... 0.02076219 0.02370336 0.03388231]
 [0.02801327 0.02508294 0.02316479 ... 0.01719931 0.02128615 0.03016956]]

-* TASK 10/20 | SAMPLE 40/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 199/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 states that Julie went back to the cinema, and there is no information that suggests she left the cinema afterwards.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' left', ' the', ' cinema', ' afterwards', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02725824 0.03089627 0.03791538 ... 0.01254452 0.01493316 0.03138641]
 [0.0277144  0.02813559 0.03258007 ... 0.02108781 0.02294536 0.0240693 ]
 [0.02839144 0.03581118 0.04660944 ... 0.02124916 0.02652496 0.04042561]
 ...
 [0.0286562  0.04153173 0.03617064 ... 0.00951902 0.01030068 0.02040781]
 [0.02923214 0.03314923 0.02624602 ... 0.01244272 0.01127886 0.01582653]
 [0.02903508 0.03804299 0.03026711 ... 0.01117546 0.01161502 0.02006714]]

-* TASK 10/20 | SAMPLE 40/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 200/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 14 explicitly states that Mary went back to the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' explicitly', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(22, 50), x_tokens=50, y_tokens=22, max_supp_attn=0.0909, attn_on_target=0.0455)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (22, 50)
DEBUG result.interpretability.attn_scores 1100 
 [[0.0432259  0.06193344 0.05728503 ... 0.02390695 0.01771461 0.04235483]
 [0.04373655 0.05015527 0.04396392 ... 0.04584995 0.04369588 0.05368297]
 [0.04491631 0.06791192 0.06894833 ... 0.02299444 0.01678276 0.03833204]
 ...
 [0.04519684 0.05497004 0.05763152 ... 0.02020795 0.0154744  0.06038241]
 [0.04577147 0.03903893 0.03985138 ... 0.03014458 0.02717432 0.05530396]
 [0.04550188 0.04580785 0.04507535 ... 0.02288866 0.01965361 0.05427327]]
Model's predictions for the sample 40:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 2 explicitly states  |
|          |                 |       that Julie is in the kitchen.        |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences 4 and 5 do not    |
|          |                 |     mention the kitchen as a possible      |
|          |                 |  location for Fred. They only mention the  |
|          |                 |         bedroom, park, and office.         |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |   There is no information provided about   |
|          |                 |  Fred's location in the context sentences  |
|          |                 |    7 and 8. They only mention Julie and    |
|          |                 |             Mary's movements.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 7 states that Julie  |
|          |                 |  went back to the cinema, and there is no  |
|          |                 |   information that suggests she left the   |
|          |                 |             cinema afterwards.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 14 explicitly     |
|          |                 |     states that Mary went back to the      |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 40:
+----------------------------+------------+
|           Metric           |   Before   |
+----------------------------+------------+
|    Exact-match accuracy    |    0.8     |
|    Soft-match accuracy     |    0.8     |
| Max attention distribution | 0.1 ± 0.06 |
+----------------------------+------------+

-* TASK 10/20 | SAMPLE 41/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 201/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the cinema. According to the context sentences, Mary travelled to the kitchen, but there is no mention of her being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' cinema', '.', ' According', ' to', ' the', ' context', ' sentences', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 26), x_tokens=26, y_tokens=43, max_supp_attn=0.0, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 26)
DEBUG result.interpretability.attn_scores 1118 
 [[0.02165597 0.03669662 0.03919313 ... 0.01697742 0.00820582 0.02271649]
 [0.02235194 0.02294201 0.02303302 ... 0.01157197 0.00657153 0.01486104]
 [0.02272155 0.02589143 0.02956967 ... 0.01521108 0.00884424 0.01412928]
 ...
 [0.02277591 0.02412839 0.02317313 ... 0.0107221  0.00569047 0.01399616]
 [0.02268969 0.01943089 0.01948575 ... 0.01404194 0.00919556 0.01530155]
 [0.02284903 0.02214278 0.02124219 ... 0.01241188 0.00799736 0.01427509]]

-* TASK 10/20 | SAMPLE 41/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 202/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary's location. The context sentences only mention Fred's locations, which are the park and the school, but do not provide any information about Mary.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', "'s", ' locations', ',', ' which', ' are', ' the', ' park', ' and', ' the', ' school', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 32), x_tokens=32, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 32)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02091946 0.0315794  0.03404022 ... 0.00828678 0.01840975 0.00787619]
 [0.02158997 0.02937404 0.02980249 ... 0.01004404 0.02469328 0.01030898]
 [0.02205227 0.02690608 0.02985145 ... 0.01414611 0.02875681 0.01277794]
 ...
 [0.02218739 0.02902492 0.02280332 ... 0.00949733 0.01018675 0.00865796]
 [0.02258473 0.03042038 0.02504317 ... 0.01001188 0.01162447 0.00760158]
 [0.02271382 0.02676522 0.02313568 ... 0.00943559 0.01256769 0.00822607]]

-* TASK 10/20 | SAMPLE 41/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 203/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only provide information about Bill's locations, which are the cinema and the office. There is no information provided about Fred's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' provide', ' information', ' about', ' Bill', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ' and', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 38), x_tokens=38, y_tokens=37, max_supp_attn=0.1351, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 38)
DEBUG result.interpretability.attn_scores 1406 
 [[0.02517417 0.03445065 0.03580253 ... 0.06413224 0.03248287 0.01993742]
 [0.0256099  0.03052768 0.03141424 ... 0.03744771 0.02808687 0.02226101]
 [0.02631143 0.03710439 0.04071327 ... 0.04881565 0.02755397 0.01469617]
 ...
 [0.02683076 0.02804457 0.02412499 ... 0.03081071 0.0322267  0.02617189]
 [0.02704448 0.03127755 0.02822957 ... 0.03957615 0.03044287 0.0175003 ]
 [0.02695909 0.02882139 0.02575858 ... 0.0658071  0.02451267 0.01603114]]

-* TASK 10/20 | SAMPLE 41/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 204/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any new information about Bill's location. The previous information about Bill's location was that he was in the cinema and the office, but there is no update or change to that information.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' was', ' that', ' he', ' was', ' in', ' the', ' cinema', ' and', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' update', ' or', ' change', ' to', ' that', ' information', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 44), x_tokens=44, y_tokens=50, max_supp_attn=0.0, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 44)
DEBUG result.interpretability.attn_scores 2200 
 [[0.018358   0.02218034 0.02313913 ... 0.0723988  0.06290985 0.00971385]
 [0.01861834 0.0219186  0.0223018  ... 0.0337632  0.04353061 0.0221594 ]
 [0.01924321 0.02420417 0.02627036 ... 0.0414399  0.07241371 0.01395027]
 ...
 [0.0193921  0.02686564 0.02622272 ... 0.03031419 0.02006211 0.00585477]
 [0.01986091 0.02268764 0.02108234 ... 0.02053508 0.01207529 0.00775135]
 [0.01984157 0.02299784 0.02017833 ... 0.02685809 0.01245791 0.00773171]]

-* TASK 10/20 | SAMPLE 41/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 205/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to the context sentence 13, Fred is in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' the', ' context', ' sentence', ' ', '13', ',', ' Fred', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 50), x_tokens=50, y_tokens=21, max_supp_attn=0.0, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 50)
DEBUG result.interpretability.attn_scores 1050 
 [[0.04502434 0.04875353 0.05997151 ... 0.05570611 0.05736759 0.05817252]
 [0.04550035 0.04713888 0.04824244 ... 0.03299709 0.02822432 0.03345286]
 [0.04716107 0.05549113 0.06199946 ... 0.06988554 0.05678944 0.05747442]
 ...
 [0.04750516 0.05433975 0.05242992 ... 0.08245986 0.16159569 0.06836242]
 [0.04735674 0.04664311 0.0421457  ... 0.0333057  0.10950446 0.04435948]
 [0.04767942 0.0490109  0.04546369 ... 0.03728653 0.13575242 0.07936213]]
Model's predictions for the sample 41:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the cinema. According to   |
|          |                 |  the context sentences, Mary travelled to  |
|          |                 |  the kitchen, but there is no mention of   |
|          |                 |          her being in the cinema.          |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |   Mary's location. The context sentences   |
|          |                 |  only mention Fred's locations, which are  |
|          |                 |    the park and the school, but do not     |
|          |                 |    provide any information about Mary.     |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |     The context sentences only provide     |
|          |                 |    information about Bill's locations,     |
|          |                 |    which are the cinema and the office.    |
|          |                 |   There is no information provided about   |
|          |                 |              Fred's location.              |
+----------+-----------------+--------------------------------------------+
|   yes    |      maybe      |  The context sentences do not provide any  |
|          |                 |   new information about Bill's location.   |
|          |                 |   The previous information about Bill's    |
|          |                 |   location was that he was in the cinema   |
|          |                 |   and the office, but there is no update   |
|          |                 |       or change to that information.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to the context sentence 13,    |
|          |                 |          Fred is in the bedroom.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 41:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.4     |
|    Soft-match accuracy     |     0.4     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 42/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 206/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 2, Bill went to the park, which means Bill is not in the bedroom. 
Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' went', ' to', ' the', ' park', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' bedroom', '.', ' \n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 26), x_tokens=26, y_tokens=29, max_supp_attn=0.1724, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 26)
DEBUG result.interpretability.attn_scores 754 
 [[0.03240329 0.06313236 0.06810551 0.09608173 0.08308257 0.06767734
  0.05017006 0.04338962 0.0470308  0.06346978 0.04603268 0.0341279
  0.03620831 0.13730206 0.13841952 0.04686055 0.03627046 0.0274862
  0.02601551 0.02815425 0.02671244 0.04972337 0.08219158 0.00803948
  0.00939677 0.02966751]
 [0.03344003 0.03895764 0.0404019  0.06985939 0.05926231 0.05761965
  0.03561013 0.03155664 0.037815   0.05514369 0.03898795 0.03659033
  0.03624025 0.14300878 0.16415696 0.04450531 0.03899781 0.03187884
  0.02879377 0.0294363  0.0253225  0.0414386  0.04913555 0.00677937
  0.00753313 0.01936931]
 [0.03399242 0.04353802 0.05083472 0.07356387 0.0657749  0.07200418
  0.04686397 0.0436886  0.04901627 0.06475668 0.04551575 0.05775746
  0.05572664 0.11308239 0.10151292 0.03786894 0.03582171 0.03209793
  0.02798417 0.02934165 0.02389558 0.03734696 0.04460312 0.00948519
  0.01090753 0.01830542]
 [0.03281697 0.05051246 0.05737153 0.05375662 0.05497261 0.06218357
  0.05051299 0.05321689 0.05070875 0.05512929 0.045101   0.06027419
  0.05536656 0.0674337  0.05763212 0.04794661 0.04269834 0.03899065
  0.0334168  0.03575649 0.03289938 0.04130345 0.06008415 0.02565778
  0.03640532 0.03653944]
 [0.03409407 0.05807825 0.06521075 0.06448698 0.05726489 0.07770292
  0.06321224 0.06696846 0.06429951 0.06764543 0.04959862 0.06940217
  0.06867062 0.05388069 0.03333044 0.03561192 0.03501564 0.03492
  0.03078229 0.03441634 0.02748908 0.04301323 0.04737767 0.01873796
  0.01906742 0.02414202]
 [0.03334594 0.06657348 0.06814934 0.03736291 0.02869242 0.04525529
  0.05582444 0.05338966 0.05250859 0.03683206 0.03533335 0.04441054
  0.04610613 0.0214979  0.01803887 0.04995121 0.04040438 0.03484862
  0.03416264 0.03668408 0.03745212 0.04067655 0.08469144 0.03847497
  0.04660143 0.04452422]
 [0.03424485 0.05291181 0.06090345 0.0321694  0.02559222 0.0357792
  0.05876616 0.04437821 0.0510618  0.03091416 0.02959598 0.03270926
  0.03333203 0.01719049 0.01617946 0.05115079 0.03853448 0.03298709
  0.03392566 0.03743934 0.03573897 0.03505876 0.06977207 0.02812742
  0.04537464 0.04002181]
 [0.03475571 0.01827173 0.02121063 0.01454146 0.01185593 0.01803593
  0.0208841  0.01986487 0.02577294 0.01651179 0.01550502 0.01692028
  0.01689905 0.00777088 0.00764281 0.01993677 0.02037174 0.01955957
  0.02307845 0.02449413 0.02557792 0.02029083 0.04488165 0.03761553
  0.0707022  0.06822252]
 [0.03437314 0.03158155 0.03204238 0.0215836  0.0180838  0.02619198
  0.03202273 0.02816119 0.02934352 0.0222803  0.02608263 0.02554219
  0.02517362 0.011586   0.01168619 0.04052732 0.02846475 0.03048306
  0.02977841 0.03250501 0.03226373 0.03464096 0.03471723 0.03379487
  0.07033453 0.06236042]
 [0.03445005 0.0303469  0.03042195 0.02318466 0.01956091 0.0278837
  0.03434155 0.03390941 0.03069386 0.025745   0.03075607 0.03294231
  0.03452987 0.01268805 0.01109391 0.04029574 0.03179907 0.0345025
  0.03037809 0.0311159  0.03436945 0.03556015 0.02565236 0.03271974
  0.06413864 0.04394994]
 [0.03380501 0.02454882 0.02110275 0.01773094 0.01415977 0.01872496
  0.02599059 0.02520895 0.02290484 0.01885699 0.02570545 0.02239721
  0.02665168 0.00862715 0.00856426 0.04442595 0.02882165 0.04394012
  0.03739202 0.04644701 0.05267097 0.03192306 0.02019072 0.04445092
  0.10418215 0.06089668]
 [0.03490762 0.02309374 0.0212185  0.01782671 0.01525676 0.02039075
  0.02637505 0.02635078 0.02359092 0.02047325 0.02994461 0.02715766
  0.02773192 0.00880478 0.00852041 0.03734428 0.02718889 0.04389531
  0.03726331 0.0588243  0.048547   0.02660145 0.01712766 0.0328209
  0.07051649 0.0476404 ]
 [0.03462416 0.02054178 0.01774501 0.01409873 0.011973   0.01606761
  0.02160747 0.02113741 0.020721   0.01622202 0.02908656 0.02044989
  0.02207809 0.00704368 0.00744845 0.03451448 0.02818068 0.03719608
  0.04005    0.04960122 0.04405743 0.02741896 0.01722511 0.05042436
  0.05498174 0.07359552]
 [0.03397315 0.0272979  0.0242335  0.01832908 0.01578286 0.02259245
  0.03052508 0.03006324 0.02747816 0.02086202 0.02826157 0.02500143
  0.02832866 0.00925285 0.00940396 0.02860605 0.03438601 0.03180203
  0.03856552 0.03669061 0.03820565 0.03132759 0.02653782 0.08925965
  0.05785083 0.05390847]
 [0.0351184  0.02401787 0.0212421  0.01783575 0.01412363 0.02003018
  0.02471129 0.02442169 0.02394398 0.0198883  0.02884312 0.02425026
  0.02423567 0.00922457 0.00884172 0.02458285 0.02523766 0.02864517
  0.03723985 0.03590205 0.03495347 0.03050269 0.01780288 0.04556786
  0.03030978 0.05634021]
 [0.03541747 0.02739964 0.02973759 0.02430866 0.01890908 0.02988165
  0.03186332 0.03730636 0.03207514 0.02913951 0.03129856 0.03911008
  0.03600213 0.014497   0.01066458 0.02361356 0.02489573 0.02777323
  0.02882385 0.02753999 0.02707958 0.03487389 0.01901752 0.02858891
  0.02365994 0.02714702]
 [0.03563184 0.03143424 0.03157041 0.02649521 0.01980373 0.03148693
  0.0386175  0.04805761 0.03463023 0.03171689 0.04126907 0.04533894
  0.04356815 0.01473916 0.01094069 0.02569493 0.02742966 0.03051556
  0.03048034 0.02893693 0.02854657 0.03364168 0.01982778 0.03081358
  0.02063609 0.02276906]
 [0.0354119  0.03016356 0.02857114 0.02527002 0.02003209 0.02857644
  0.03479701 0.03905967 0.03204602 0.02982345 0.03597501 0.03852785
  0.04047263 0.01406125 0.01148073 0.03334808 0.02907456 0.03345382
  0.03077688 0.02976987 0.03161615 0.03447356 0.01871443 0.02718103
  0.02416173 0.01913164]
 [0.03528074 0.02542421 0.022558   0.01914768 0.01442137 0.02003265
  0.02997451 0.03041781 0.02673747 0.02123639 0.03124897 0.02624886
  0.03111928 0.00942251 0.00894215 0.04013831 0.03056408 0.03628131
  0.03469857 0.03152911 0.0398433  0.02910245 0.01636957 0.03737977
  0.03344806 0.02644983]
 [0.03523755 0.02413233 0.02173317 0.01886578 0.0154302  0.02055251
  0.02862957 0.03068974 0.02659916 0.02322882 0.03231289 0.02939309
  0.0304964  0.01003008 0.00913922 0.03219144 0.03534665 0.03675101
  0.04408958 0.03671999 0.04614966 0.02898373 0.01687905 0.04368428
  0.02672506 0.02928806]
 [0.03524734 0.02378684 0.02180284 0.01830016 0.01410051 0.02088098
  0.02618617 0.02858637 0.02659916 0.02159096 0.0281669  0.0286585
  0.02907351 0.01000036 0.00875402 0.02916258 0.03205279 0.03129542
  0.03410791 0.02960537 0.03619933 0.02893505 0.01597211 0.05380443
  0.02491394 0.02221825]
 [0.03531179 0.02095298 0.0194958  0.01357288 0.0112171  0.01618986
  0.02476621 0.02363442 0.02458457 0.01588544 0.03195374 0.02113092
  0.02443749 0.00760268 0.00682342 0.03285856 0.03773975 0.03044417
  0.03479721 0.03167206 0.04065423 0.0266526  0.01452498 0.06244147
  0.02674288 0.02402879]
 [0.03464219 0.02619785 0.02327045 0.01485951 0.01186749 0.01853974
  0.02901269 0.02699682 0.029662   0.01735592 0.03340687 0.02225316
  0.02721358 0.00851404 0.00747633 0.02947418 0.03628746 0.02560548
  0.03290794 0.03091093 0.03884554 0.0288231  0.01942035 0.09381101
  0.03284404 0.02859546]
 [0.03543924 0.02638331 0.02477065 0.01985063 0.01509488 0.02168609
  0.02619822 0.02836401 0.02956918 0.02309383 0.02985595 0.02759509
  0.02770143 0.01140982 0.00973989 0.02169092 0.0284688  0.02541494
  0.02949992 0.03030188 0.03112189 0.03103551 0.01854256 0.04597667
  0.02292461 0.02160725]
 [0.0349375  0.03036386 0.02977242 0.03136887 0.0254737  0.03398623
  0.0304581  0.03661375 0.0361298  0.03718663 0.03164568 0.04280864
  0.041126   0.02112668 0.01539065 0.02212222 0.03073443 0.03119055
  0.02959976 0.02940301 0.02719476 0.03690164 0.02777087 0.03054522
  0.02551327 0.02322093]
 [0.03471284 0.04233517 0.03830387 0.05352531 0.05539031 0.05155046
  0.03458401 0.03274354 0.03659387 0.04996373 0.03849957 0.03500502
  0.03487688 0.0860264  0.10042337 0.03278993 0.03210539 0.0263041
  0.02554995 0.02600531 0.02258577 0.0397697  0.04364936 0.00657977
  0.0081681  0.01785916]
 [0.03408341 0.04176501 0.03916129 0.06469298 0.12606917 0.04918699
  0.03127926 0.03203741 0.03816805 0.06587438 0.0469854  0.04198732
  0.03340898 0.09170701 0.11362978 0.03752188 0.05381855 0.04907913
  0.03965722 0.03374985 0.03177333 0.03452019 0.04222526 0.00668678
  0.00671222 0.01792495]
 [0.03409848 0.03405084 0.03171875 0.04604045 0.08735348 0.03102264
  0.02413795 0.02860891 0.03093044 0.04957857 0.04201893 0.03836721
  0.03067499 0.03357257 0.04206632 0.02920909 0.065169   0.06828126
  0.06891715 0.04361918 0.04248411 0.02997029 0.03226954 0.01728744
  0.01435391 0.02133796]
 [0.03420297 0.04220587 0.0373397  0.05128997 0.06939831 0.03828714
  0.03207765 0.03117803 0.03878499 0.04959477 0.04101211 0.0336422
  0.03254943 0.03889647 0.04205685 0.02605565 0.04411988 0.04437682
  0.04726723 0.04342791 0.03575014 0.05548988 0.0528255  0.01326363
  0.01089346 0.01893784]]

-* TASK 10/20 | SAMPLE 42/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 207/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred being in the park. Sentence 5 only mentions Fred journeying to the office, which does not imply Fred being in the park. 
Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' Sentence', ' ', '5', ' only', ' mentions', ' Fred', ' journey', 'ing', ' to', ' the', ' office', ',', ' which', ' does', ' not', ' imply', ' Fred', ' being', ' in', ' the', ' park', '.', ' \n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 32), x_tokens=32, y_tokens=41, max_supp_attn=0.1463, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 32)
DEBUG result.interpretability.attn_scores 1312 
 [[0.02248958 0.03449467 0.03679306 ... 0.01475636 0.01062575 0.04851754]
 [0.02308804 0.03425052 0.03324397 ... 0.01822921 0.01490939 0.06076119]
 [0.02352285 0.03333243 0.0352916  ... 0.02772437 0.01851074 0.05042884]
 ...
 [0.02357577 0.03028002 0.02779052 ... 0.00800887 0.00724172 0.05444827]
 [0.02408236 0.02503701 0.02172134 ... 0.01002184 0.01198264 0.02366557]
 [0.02418482 0.02953294 0.02591214 ... 0.00914205 0.01111868 0.0198968 ]]

-* TASK 10/20 | SAMPLE 42/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 208/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Mary is in the school. 
Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.', ' \n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(20, 38), x_tokens=38, y_tokens=20, max_supp_attn=0.1, attn_on_target=0.05)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (20, 38)
DEBUG result.interpretability.attn_scores 760 
 [[0.04695136 0.06200305 0.0615292  0.08136456 0.06631781 0.07476856
  0.05677566 0.06227866 0.06558879 0.07957369 0.0509673  0.05497921
  0.06578658 0.12754461 0.10968041 0.04470303 0.04144178 0.04274568
  0.03712672 0.04122323 0.03799766 0.05034041 0.07753302 0.02141072
  0.03492875 0.05691979 0.05940902 0.06507825 0.12708263 0.02353791
  0.01979282 0.06807442 0.0482543  0.08354694 0.05549569 0.03132576
  0.03389561 0.07129214]
 [0.04817813 0.05441743 0.05199518 0.04514559 0.03523538 0.04877594
  0.05012511 0.05822324 0.04505396 0.04277388 0.0407124  0.04240192
  0.05282508 0.0433686  0.05788724 0.04015362 0.03386582 0.03607585
  0.03725103 0.04186337 0.03810551 0.04673502 0.05517061 0.05319783
  0.06110133 0.04773445 0.04102298 0.05232764 0.08933228 0.07689562
  0.03445715 0.04105565 0.02676881 0.04106189 0.05482854 0.04164662
  0.04045643 0.05282455]
 [0.04908186 0.0665621  0.06909017 0.0939216  0.08319363 0.09789094
  0.06550861 0.06860302 0.06887653 0.08762287 0.05663496 0.07180839
  0.07623463 0.16793106 0.11044994 0.04776021 0.03403189 0.03714855
  0.031889   0.03591576 0.03247747 0.05158616 0.06373516 0.02037702
  0.03076802 0.04560708 0.05453603 0.04663619 0.12192291 0.04338714
  0.03318666 0.08174536 0.04376348 0.06285562 0.0475749  0.02784367
  0.03235766 0.06436502]
 [0.04776435 0.06215653 0.06218754 0.04725368 0.03733166 0.05301272
  0.05417841 0.05876163 0.05211664 0.04840366 0.04295395 0.04964076
  0.05035435 0.03706469 0.03345645 0.05020786 0.03881205 0.03925775
  0.03712948 0.03995592 0.03782834 0.05397969 0.06818097 0.04241125
  0.05558567 0.05638046 0.05819941 0.04768088 0.09147257 0.13122317
  0.06266563 0.04532677 0.02995348 0.03303717 0.07028715 0.05403427
  0.05383049 0.06444529]
 [0.04939547 0.06867235 0.06703335 0.04027347 0.02654138 0.04411213
  0.06121265 0.05219955 0.05715472 0.03774586 0.03811678 0.03903129
  0.03992929 0.02684824 0.02742221 0.05460984 0.03731648 0.03659355
  0.0383436  0.04235441 0.03880945 0.04665379 0.07310595 0.03852749
  0.06043233 0.04981855 0.0596855  0.03338291 0.04399974 0.13703112
  0.04894612 0.02525055 0.01523357 0.02879346 0.07806813 0.05400806
  0.04748938 0.05642741]
 [0.05050225 0.03531682 0.03398051 0.02247822 0.01519404 0.02368141
  0.03035709 0.0292165  0.03254177 0.02236091 0.02701056 0.02378926
  0.02580143 0.0135612  0.01640791 0.03604272 0.02886582 0.0293797
  0.0328766  0.03762712 0.03285786 0.03521719 0.03679777 0.04852813
  0.06777432 0.04280387 0.03224469 0.02721245 0.01923768 0.0588705
  0.02942529 0.01548107 0.00826252 0.01765418 0.04960373 0.0477328
  0.03582155 0.03334175]
 [0.04936205 0.05492073 0.05529688 0.03722268 0.02527411 0.04567795
  0.05263054 0.05218207 0.04953986 0.04047544 0.04041301 0.04634057
  0.04521903 0.02324878 0.0244446  0.05234553 0.04330251 0.04482307
  0.04720159 0.04811564 0.0439017  0.05640097 0.05496645 0.05646137
  0.06546813 0.05612744 0.0600311  0.0372371  0.04406704 0.08180882
  0.06814843 0.024663   0.01636361 0.02296527 0.07005008 0.06551957
  0.06917958 0.05599299]
 [0.05066413 0.06785985 0.06899441 0.05537183 0.03681947 0.06456614
  0.06833871 0.0722494  0.06235519 0.06233075 0.05781952 0.07981608
  0.07101718 0.0368825  0.03167725 0.05936809 0.0497877  0.0535319
  0.05043648 0.0522579  0.04676501 0.05573932 0.05709768 0.07001761
  0.06131021 0.05531177 0.0657681  0.0464534  0.04729484 0.0687559
  0.0808104  0.03355256 0.02257151 0.02775558 0.06490581 0.05254034
  0.06333164 0.05751818]
 [0.05165713 0.04828303 0.04904261 0.03701523 0.02706149 0.04211409
  0.05123353 0.04732955 0.04472915 0.03938051 0.04718192 0.04538887
  0.04701294 0.02250059 0.02295772 0.05340869 0.0459483  0.0426305
  0.04557032 0.04740744 0.0435306  0.05190454 0.04104775 0.05882576
  0.05611917 0.04476146 0.04828063 0.03681323 0.03624064 0.06546526
  0.07878477 0.0283503  0.01700935 0.02367686 0.05138332 0.05523241
  0.05517444 0.04549371]
 [0.05098189 0.03956892 0.03771511 0.02780185 0.02086771 0.03058137
  0.03926057 0.03740775 0.03815367 0.02955709 0.04322471 0.03518106
  0.03906848 0.01572795 0.01850013 0.05423276 0.05576241 0.04343009
  0.04953314 0.04913986 0.04668267 0.05008285 0.03163945 0.06230916
  0.0585665  0.04110597 0.04067738 0.03673129 0.02626038 0.04608577
  0.06157051 0.02491627 0.01243781 0.01949859 0.04695941 0.06277508
  0.0556419  0.03873895]
 [0.05078395 0.03839531 0.03442738 0.02692627 0.01970869 0.02884732
  0.04106094 0.03703367 0.03721895 0.02670654 0.04071761 0.03382322
  0.0410661  0.01447035 0.01573965 0.05584311 0.06210228 0.0516311
  0.06287467 0.05899312 0.05940809 0.04569255 0.02677906 0.07968517
  0.06200743 0.04114592 0.03673752 0.03761999 0.0175592  0.03712127
  0.0616063  0.02238265 0.00824051 0.01741545 0.04857184 0.09237103
  0.0779959  0.03280345]
 [0.05161524 0.03612481 0.03431167 0.02671271 0.02134294 0.03004045
  0.03815543 0.03689034 0.03741745 0.02881266 0.0451955  0.03964127
  0.03928533 0.01544318 0.01600972 0.04906909 0.0604331  0.04461358
  0.06331114 0.0521477  0.05005857 0.04510886 0.02425407 0.07563569
  0.04852032 0.03687119 0.03884569 0.03616561 0.01711095 0.03216592
  0.06815917 0.02728508 0.01076476 0.01739609 0.03149472 0.05087043
  0.05592005 0.03042122]
 [0.05155584 0.03267844 0.03141496 0.02260025 0.01904337 0.0253844
  0.03813247 0.03343624 0.0354614  0.02282928 0.04695542 0.03436725
  0.03745528 0.0129722  0.01367351 0.05392846 0.06364409 0.0480324
  0.06959447 0.05947119 0.05616208 0.04537254 0.02247074 0.09208465
  0.05107209 0.04206478 0.03134612 0.04009227 0.01456691 0.02779752
  0.04723006 0.0286464  0.00807174 0.01657113 0.03212997 0.06619353
  0.06622523 0.02836953]
 [0.04969532 0.044866   0.04107466 0.02667305 0.02319896 0.03485438
  0.07161152 0.05605569 0.05214551 0.02766499 0.06910538 0.04752756
  0.05953089 0.01595082 0.01752115 0.06020634 0.06834686 0.06525483
  0.0822951  0.0781     0.06410024 0.05157024 0.041579   0.10575248
  0.0769906  0.06597529 0.03614999 0.05169262 0.02035449 0.03117249
  0.04142159 0.02983639 0.00932652 0.02680526 0.05291064 0.08852387
  0.08875218 0.04106688]
 [0.05154881 0.03637534 0.04076544 0.03621592 0.02763704 0.03775309
  0.04033292 0.04317623 0.04182396 0.03570797 0.04523455 0.04602583
  0.04309656 0.02402527 0.02052791 0.03898083 0.0336856  0.03682498
  0.04426228 0.04608827 0.04082617 0.04772117 0.02874572 0.0412512
  0.04075774 0.04495122 0.03663383 0.04265595 0.03186888 0.02736237
  0.10429481 0.05818297 0.02387766 0.0257471  0.03163758 0.04423947
  0.04421481 0.0384273 ]
 [0.05046638 0.04308075 0.05115131 0.05090852 0.03624128 0.0552851
  0.050699   0.05818478 0.05819409 0.05287956 0.0471741  0.06179092
  0.05741499 0.03852746 0.02812883 0.03709549 0.03180223 0.03728236
  0.03338214 0.03802416 0.03312343 0.05249026 0.04173941 0.02995762
  0.03883545 0.04568032 0.04351132 0.04935113 0.05288218 0.04532931
  0.06635901 0.0735644  0.0348699  0.04109415 0.04395036 0.037616
  0.03810744 0.05035969]
 [0.05061998 0.05170457 0.05169793 0.07755717 0.07192813 0.07472456
  0.04940037 0.04702888 0.0546032  0.06925088 0.05784816 0.05659484
  0.05425429 0.12788068 0.13419175 0.04722155 0.0350217  0.04002992
  0.03402581 0.03897708 0.03633117 0.05102492 0.05776852 0.01546941
  0.02386921 0.04964876 0.05906342 0.0568121  0.06677129 0.01586538
  0.02302631 0.14380836 0.08729215 0.08622    0.03591863 0.02454129
  0.02599318 0.05438989]
 [0.04959446 0.05792022 0.05805194 0.10658543 0.23108138 0.08154688
  0.05103021 0.05158075 0.05812552 0.10163061 0.07751705 0.0756811
  0.05366618 0.1331357  0.17297122 0.06185542 0.07088885 0.0833646
  0.05700158 0.05500968 0.0708358  0.04936692 0.07281637 0.01895281
  0.02490233 0.06162732 0.08702264 0.07224771 0.05927484 0.01495629
  0.01852591 0.11789393 0.2707407  0.12808934 0.04260845 0.02707049
  0.03018631 0.0704115 ]
 [0.0497208  0.04923321 0.04818876 0.0666506  0.10389765 0.0483049
  0.03987709 0.04482288 0.04543289 0.07508538 0.06837121 0.06077778
  0.04826145 0.04635783 0.06978386 0.05641485 0.09804869 0.11398809
  0.08529519 0.07060149 0.11857612 0.04849425 0.0568456  0.04091484
  0.04327846 0.05470585 0.05965094 0.08073289 0.03267203 0.02009632
  0.0281047  0.06403795 0.24350226 0.09767176 0.04700805 0.04038857
  0.04717384 0.05456696]
 [0.04986064 0.04986064 0.05205105 0.07132136 0.07208389 0.05807769
  0.0500792  0.05333926 0.06346674 0.06920746 0.05684584 0.05539286
  0.05271994 0.05655836 0.05856854 0.04655246 0.06689187 0.0733615
  0.06059974 0.06672663 0.07162207 0.06451831 0.06772681 0.02822986
  0.03771199 0.06075839 0.05118369 0.10307641 0.04002848 0.01507182
  0.0234844  0.04594598 0.06269537 0.18214415 0.04461296 0.03552675
  0.03825235 0.05874353]]

-* TASK 10/20 | SAMPLE 42/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 209/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 (from previous context) stated that Mary is in the bedroom, and there is no new information that suggests Mary has moved. 
Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' (', 'from', ' previous', ' context', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', '.', ' \n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02573566 0.02701455 0.02888322 ... 0.01707582 0.01090565 0.01660332]
 [0.0260333  0.03467829 0.03553946 ... 0.03030682 0.0265701  0.02567055]
 [0.02674016 0.02880013 0.03182851 ... 0.02393974 0.01828838 0.02535663]
 ...
 [0.02709333 0.03089666 0.02466668 ... 0.00793001 0.00949831 0.01377703]
 [0.02773002 0.02337006 0.01867328 ... 0.01015664 0.01132268 0.01411424]
 [0.02750662 0.02593641 0.02001348 ... 0.00794772 0.00854249 0.01316134]]

-* TASK 10/20 | SAMPLE 42/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 210/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred being in the school. The context only mentions Fred moving to the kitchen and then journeying to the cinema (sentences 10 and 11), but not about being in the school. 
Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' only', ' mentions', ' Fred', ' moving', ' to', ' the', ' kitchen', ' and', ' then', ' journey', 'ing', ' to', ' the', ' cinema', ' (', 'sent', 'ences', ' ', '10', ' and', ' ', '11', '),', ' but', ' not', ' about', ' being', ' in', ' the', ' school', '.', ' \n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 50), x_tokens=50, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 50)
DEBUG result.interpretability.attn_scores 2650 
 [[0.01740921 0.02508768 0.02487317 ... 0.0251113  0.00946371 0.01304756]
 [0.01765856 0.02341551 0.02150398 ... 0.01587593 0.01099749 0.01176868]
 [0.01805497 0.02800596 0.02858043 ... 0.01962747 0.00810797 0.01027873]
 ...
 [0.01875589 0.02265707 0.01713787 ... 0.02143912 0.01125131 0.01345538]
 [0.01879428 0.0270101  0.02296703 ... 0.02472974 0.0109229  0.0110323 ]
 [0.01884699 0.02324611 0.02071822 ... 0.02328683 0.01053795 0.00956432]]
Model's predictions for the sample 42:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 2, Bill went to    |
|          |                 |  the park, which means Bill is not in the  |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no information about Fred being  |
|          |                 |   in the park. Sentence 5 only mentions    |
|          |                 |    Fred journeying to the office, which    |
|          |                 |   does not imply Fred being in the park.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Mary   |
|          |                 |             is in the school.              |
+----------+-----------------+--------------------------------------------+
|    no    |       yes       |     Sentence 7 (from previous context)     |
|          |                 |  stated that Mary is in the bedroom, and   |
|          |                 |      there is no new information that      |
|          |                 |          suggests Mary has moved.          |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |  There is no information about Fred being  |
|          |                 |  in the school. The context only mentions  |
|          |                 |    Fred moving to the kitchen and then     |
|          |                 |   journeying to the cinema (sentences 10   |
|          |                 |    and 11), but not about being in the     |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 42:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.11 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 43/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 211/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the cinema. In fact, sentence 2 states that Bill is in the park, which is a different location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' cinema', '.', ' In', ' fact', ',', ' sentence', ' ', '2', ' states', ' that', ' Bill', ' is', ' in', ' the', ' park', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 26), x_tokens=26, y_tokens=40, max_supp_attn=0.075, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 26)
DEBUG result.interpretability.attn_scores 1040 
 [[0.02313252 0.03795306 0.04431748 ... 0.0179236  0.01083871 0.01736704]
 [0.02362428 0.04248384 0.04416915 ... 0.01515913 0.0065838  0.0188236 ]
 [0.02410086 0.02633056 0.02659504 ... 0.01131356 0.00586923 0.01364839]
 ...
 [0.02452796 0.02794122 0.02615225 ... 0.01079578 0.00531885 0.01257939]
 [0.02448113 0.02189311 0.02120965 ... 0.01393458 0.00877147 0.01462912]
 [0.02460229 0.02678025 0.02448171 ... 0.01228042 0.00719418 0.01432069]]

-* TASK 10/20 | SAMPLE 43/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 212/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Julie being in the bedroom. In fact, sentence 4 states that Julie journeyed to the park, which is a different location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '4', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02332934 0.03748137 0.03950094 ... 0.0102406  0.01333396 0.00586568]
 [0.0240904  0.03556288 0.03521958 ... 0.0108283  0.01562118 0.00775128]
 [0.02446394 0.03434705 0.0374254  ... 0.01737425 0.02357913 0.01095099]
 ...
 [0.02439168 0.03404433 0.02853198 ... 0.00616224 0.00759089 0.00535655]
 [0.02476419 0.02812149 0.02339658 ... 0.00850592 0.00839517 0.00809361]
 [0.02484349 0.02783599 0.02239444 ... 0.00674283 0.00802104 0.00626202]]

-* TASK 10/20 | SAMPLE 43/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 213/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Mary is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.04957327 0.07376296 0.06656519 0.08677184 0.06990305 0.07630324
  0.06107762 0.06122589 0.06918602 0.08000507 0.05526105 0.05599285
  0.06016463 0.13207527 0.11870225 0.05017141 0.03953225 0.04670531
  0.0356851  0.04594142 0.04046334 0.05143317 0.08762174 0.04358972
  0.02873935 0.06550924 0.06971104 0.06349488 0.14221951 0.02716318
  0.03291195 0.01397145 0.01921981 0.0587775  0.08582456 0.08327452
  0.04211066 0.03890909]
 [0.05049269 0.07456941 0.0690444  0.07708633 0.06417943 0.09188797
  0.12057549 0.12721412 0.09220049 0.07887229 0.06208029 0.10258388
  0.14912166 0.08052744 0.07068764 0.04606805 0.04140796 0.05603441
  0.0524543  0.06352245 0.04764022 0.05360514 0.06436989 0.05079047
  0.04343452 0.06774025 0.06454854 0.05754923 0.11280964 0.06580965
  0.07371201 0.04186767 0.06217951 0.05935648 0.05573376 0.07459878
  0.05181659 0.05696934]
 [0.05196038 0.07062981 0.06950352 0.09553131 0.08220604 0.09565748
  0.06364353 0.06203428 0.06946436 0.08284812 0.05906916 0.06697946
  0.06825164 0.16679123 0.11666159 0.04974007 0.03278237 0.03876698
  0.03116469 0.03978204 0.03378806 0.05216206 0.06473491 0.04018435
  0.02629431 0.0529039  0.0643753  0.0461035  0.11912445 0.04074535
  0.05448269 0.02219382 0.02199263 0.07085879 0.06320839 0.06332976
  0.03648664 0.03388352]
 [0.05051688 0.06624691 0.06650805 0.05280273 0.04029597 0.05657205
  0.05651706 0.06048269 0.06047428 0.05231076 0.04731651 0.05359691
  0.05150433 0.04045229 0.03696248 0.05139323 0.03828719 0.04116432
  0.03741466 0.04430951 0.03924735 0.05671407 0.07048121 0.06559861
  0.04564596 0.05983863 0.06416742 0.05026678 0.08065864 0.1011287
  0.1359323  0.0534213  0.03578076 0.04997712 0.03613874 0.07378464
  0.05930844 0.05747635]
 [0.05198766 0.06844337 0.06803435 0.04053037 0.02937906 0.04555969
  0.06235738 0.05128723 0.06077348 0.03663277 0.0414486  0.0410741
  0.03940134 0.02732984 0.02821053 0.05730353 0.03835886 0.037663
  0.03963371 0.0463062  0.04086107 0.04897705 0.07166807 0.07386947
  0.05568776 0.05196642 0.06499896 0.03685617 0.04004085 0.08171386
  0.12191386 0.085355   0.03866753 0.03529707 0.02789703 0.07529976
  0.07246076 0.07281489]
 [0.05339903 0.03571187 0.03487215 0.02099843 0.016825   0.02367694
  0.03073987 0.02777869 0.03489222 0.01970776 0.03018985 0.02541089
  0.02423495 0.01317067 0.01545454 0.03919568 0.02969505 0.02885876
  0.03304749 0.03742754 0.03216674 0.03613777 0.03163633 0.05686877
  0.05048309 0.03715293 0.03603354 0.02456365 0.0178739  0.03415745
  0.04811615 0.05299959 0.03752801 0.02094856 0.01510194 0.03873906
  0.05808296 0.05886925]
 [0.05193284 0.0584178  0.05871539 0.03757917 0.02857202 0.04803435
  0.05269692 0.05240855 0.05352297 0.04039599 0.04363468 0.04810776
  0.04231127 0.02416977 0.02471133 0.05337364 0.04268359 0.04471214
  0.05009336 0.05078131 0.04667249 0.05883643 0.05673949 0.07195038
  0.07061652 0.05670608 0.06988428 0.04166893 0.04149783 0.10557545
  0.06645846 0.12323187 0.04926501 0.0417175  0.02341432 0.06360322
  0.0768274  0.0741075 ]
 [0.05333661 0.07017399 0.07060335 0.05661317 0.04000134 0.06370475
  0.06642327 0.07002366 0.06468751 0.06425726 0.06354235 0.07956893
  0.06557913 0.0371734  0.03186513 0.06024414 0.05193122 0.05404235
  0.05455134 0.05596155 0.05022927 0.05912606 0.05702145 0.06186982
  0.06506924 0.05996603 0.07525466 0.05442677 0.04438502 0.10844481
  0.0778622  0.10494567 0.05059445 0.05318255 0.03107649 0.06193252
  0.06613061 0.05625061]
 [0.05423506 0.05080658 0.05362842 0.03988669 0.03182838 0.04376795
  0.05242246 0.04913261 0.04732664 0.04011359 0.05041182 0.04886058
  0.04551364 0.02456241 0.02423883 0.05220902 0.04439686 0.04174787
  0.04846738 0.04836224 0.04509551 0.05490151 0.042106   0.05767969
  0.06203552 0.04774939 0.05287229 0.04564476 0.03567842 0.07271819
  0.0638206  0.11127552 0.05086033 0.0481685  0.027064   0.04454175
  0.05754994 0.05625339]
 [0.05346213 0.04046043 0.03947347 0.02840678 0.02263062 0.03084391
  0.04084075 0.03885821 0.03781817 0.02944265 0.04541947 0.0373545
  0.03890911 0.01558679 0.01880465 0.05600576 0.05755357 0.04504102
  0.05650223 0.05163305 0.04971121 0.0554135  0.03133688 0.06011482
  0.07334188 0.04186973 0.03752339 0.04195174 0.02524767 0.05361459
  0.04174498 0.07534517 0.05549436 0.0355235  0.01890146 0.03302596
  0.05285073 0.05800565]
 [0.05328236 0.0402776  0.03703712 0.02790581 0.02121124 0.03021239
  0.04346092 0.04055649 0.03736588 0.02844632 0.04532125 0.03625444
  0.04169743 0.01464652 0.01716864 0.06242803 0.07216556 0.05481415
  0.0741199  0.06169855 0.06295283 0.05224403 0.02721896 0.06021469
  0.08946048 0.04298033 0.03357356 0.03910881 0.01805526 0.04963296
  0.02684069 0.06023119 0.06179967 0.03147443 0.01621767 0.02951166
  0.06582993 0.06970596]
 [0.0541555  0.03564926 0.03597402 0.02714675 0.02175439 0.03037639
  0.03800676 0.03914832 0.03654481 0.02892862 0.04724073 0.04095466
  0.03886278 0.015003   0.01699747 0.05560442 0.06955696 0.04715266
  0.07361196 0.05489163 0.05792167 0.05039868 0.02454581 0.04701887
  0.10157666 0.04143529 0.03967154 0.04305175 0.0179518  0.04789702
  0.03152469 0.06700169 0.07292894 0.04188757 0.01671146 0.02749518
  0.05210132 0.05137269]
 [0.0540323  0.03118621 0.03293367 0.022975   0.01906424 0.02702789
  0.03699189 0.03373405 0.03386935 0.02415954 0.04917145 0.03478354
  0.03623081 0.01254211 0.0146318  0.05881697 0.06648493 0.04551162
  0.06951863 0.05537859 0.0545169  0.05060844 0.0222486  0.05068345
  0.07901687 0.045244   0.03603354 0.04155383 0.01543464 0.04014047
  0.02763622 0.04835071 0.10886163 0.04575415 0.01487578 0.02328619
  0.05014692 0.049236  ]
 [0.05310014 0.03638558 0.04027947 0.02520358 0.02027353 0.0358789
  0.05097035 0.0519685  0.04168696 0.02618394 0.05130421 0.03854205
  0.05014926 0.01515799 0.01534332 0.05138573 0.05319635 0.0527014
  0.05579991 0.05547633 0.04802022 0.05093001 0.03513787 0.05691633
  0.05318042 0.05541909 0.03565241 0.04344638 0.02401343 0.04417613
  0.04126789 0.04185892 0.16576138 0.05456695 0.01742575 0.03840429
  0.05839958 0.06298385]
 [0.05459619 0.03313974 0.03883888 0.0320138  0.02386552 0.03628522
  0.03700784 0.03900816 0.03814173 0.03187955 0.04172922 0.03938931
  0.03963876 0.01939781 0.01826037 0.0399299  0.0349457  0.03434992
  0.0426913  0.04164608 0.04181486 0.04947517 0.02940469 0.04122831
  0.03604022 0.04098452 0.0330192  0.04060509 0.02911287 0.03820368
  0.04784403 0.03464045 0.05089832 0.07065529 0.0221007  0.02988572
  0.03820869 0.04317969]
 [0.0526133  0.04841477 0.05518125 0.07647302 0.06212723 0.06990486
  0.04887678 0.05236618 0.0631393  0.081214   0.05880537 0.06453768
  0.0631817  0.11323714 0.11371535 0.04595834 0.04058047 0.0492488
  0.04144131 0.04765362 0.04418858 0.05214651 0.06056235 0.03484799
  0.02564957 0.05651009 0.05100132 0.06695934 0.07345042 0.02856203
  0.0455825  0.01785574 0.02649371 0.12496906 0.07820857 0.05612826
  0.03652992 0.03623194]
 [0.05231944 0.06073197 0.06152516 0.10816497 0.22182769 0.08562666
  0.0483087  0.04894029 0.05589922 0.1047548  0.07920975 0.07243805
  0.05042722 0.13913591 0.18057957 0.06263151 0.0713782  0.08339608
  0.05778628 0.05703145 0.07121016 0.0504693  0.08135961 0.03565653
  0.02172505 0.06026654 0.07185919 0.07300859 0.07297084 0.01681211
  0.01954892 0.01236638 0.02233449 0.08244327 0.14313391 0.06418004
  0.03742284 0.03304221]
 [0.05242463 0.05083413 0.04883733 0.06913146 0.10441904 0.04809065
  0.03908866 0.04315769 0.04424065 0.07617521 0.06820076 0.05816656
  0.04445969 0.04739755 0.07067265 0.05919861 0.10693926 0.12026513
  0.08499811 0.07353385 0.11898085 0.04979715 0.06503217 0.05104967
  0.04240978 0.05641862 0.05366918 0.08518929 0.04012849 0.02364431
  0.0224207  0.01880273 0.03564781 0.03650759 0.12858418 0.05259981
  0.04693059 0.04844761]
 [0.05257954 0.05415762 0.05244493 0.07477881 0.0796363  0.06058878
  0.04999378 0.05067442 0.05876603 0.07367168 0.06064348 0.05540393
  0.05036063 0.06164282 0.06633178 0.04834197 0.06812366 0.07782409
  0.06101838 0.06866255 0.07451867 0.0666239  0.07677394 0.03986807
  0.02959278 0.05933886 0.04615065 0.1045505  0.04934631 0.01986
  0.02037919 0.01428517 0.03369165 0.03793404 0.17838119 0.06637883
  0.04080544 0.04226038]]

-* TASK 10/20 | SAMPLE 43/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 214/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the cinema. In fact, sentence 10 states that Fred is in the cinema, which is a different person.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' cinema', '.', ' In', ' fact', ',', ' sentence', ' ', '10', ' states', ' that', ' Fred', ' is', ' in', ' the', ' cinema', ',', ' which', ' is', ' a', ' different', ' person', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 44), x_tokens=44, y_tokens=40, max_supp_attn=0.025, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 44)
DEBUG result.interpretability.attn_scores 1760 
 [[0.02324273 0.03051241 0.03366794 ... 0.0940842  0.01047212 0.01179844]
 [0.02358742 0.03007999 0.03450256 ... 0.04672302 0.02723354 0.01605607]
 [0.0242465  0.03176872 0.03727452 ... 0.06764098 0.01409038 0.0179471 ]
 ...
 [0.02490935 0.03108443 0.02694556 ... 0.01981167 0.00816053 0.00776696]
 [0.02495883 0.03801686 0.03395271 ... 0.02474846 0.00964848 0.00868355]
 [0.02517523 0.03247273 0.02998714 ... 0.02889856 0.0112437  0.01087284]]

-* TASK 10/20 | SAMPLE 43/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 215/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Julie moved to the office, but sentence 14 states that Julie went to the bedroom, which implies that Julie is no longer in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' office', ',', ' but', ' sentence', ' ', '14', ' states', ' that', ' Julie', ' went', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0244, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02244382 0.03688972 0.03285217 ... 0.04762544 0.03425894 0.02849203]
 [0.02303878 0.03613627 0.03526831 ... 0.02402231 0.02648736 0.02846863]
 [0.02342893 0.03923627 0.03849327 ... 0.04262074 0.03529658 0.02451973]
 ...
 [0.02361965 0.03472937 0.02787109 ... 0.08277984 0.0329091  0.02129334]
 [0.0241974  0.03051385 0.02248338 ... 0.050856   0.02218529 0.01999751]
 [0.02398115 0.03073626 0.02069779 ... 0.07723715 0.03139243 0.01960994]]
Model's predictions for the sample 43:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |     Bill being in the cinema. In fact,     |
|          |                 |   sentence 2 states that Bill is in the    |
|          |                 |    park, which is a different location.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Julie being in the bedroom. In fact,    |
|          |                 |   sentence 4 states that Julie journeyed   |
|          |                 |     to the park, which is a different      |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Mary   |
|          |                 |             is in the office.              |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |    The context sentences do not mention    |
|          |                 |     Bill being in the cinema. In fact,     |
|          |                 |   sentence 10 states that Fred is in the   |
|          |                 |    cinema, which is a different person.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   Sentence 13 states that Julie moved to   |
|          |                 |  the office, but sentence 14 states that   |
|          |                 |  Julie went to the bedroom, which implies  |
|          |                 |   that Julie is no longer in the office.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 43:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.04 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 44/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 216/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences do not mention Mary being in the office. Sentence 1 only mentions Mary being in the park or the bedroom, and sentence 2 is about Fred's location, which is not related to Mary's location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Mary', ' being', ' in', ' the', ' office', '.', ' Sentence', ' ', '1', ' only', ' mentions', ' Mary', ' being', ' in', ' the', ' park', ' or', ' the', ' bedroom', ',', ' and', ' sentence', ' ', '2', ' is', ' about', ' Fred', "'s", ' location', ',', ' which', ' is', ' not', ' related', ' to', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 26), x_tokens=26, y_tokens=54, max_supp_attn=0.0741, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 26)
DEBUG result.interpretability.attn_scores 1404 
 [[0.01767095 0.0385417  0.02875737 ... 0.00283473 0.00500708 0.01580839]
 [0.0181294  0.03533459 0.03017368 ... 0.00252067 0.00446515 0.0166668 ]
 [0.01707666 0.03310888 0.03773383 ... 0.00383459 0.00790601 0.02542865]
 ...
 [0.01809075 0.02060332 0.02057341 ... 0.0028164  0.00450665 0.01313541]
 [0.01792311 0.01694078 0.01683851 ... 0.00850873 0.00891223 0.01403119]
 [0.01812246 0.01943394 0.01842235 ... 0.00550572 0.00700575 0.01299423]]

-* TASK 10/20 | SAMPLE 44/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 217/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 4 explicitly states that Mary is in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.0952, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.04470441 0.08106225 0.06792019 0.09971656 0.08965085 0.12208726
  0.08268034 0.07545679 0.07686298 0.09604556 0.08011231 0.08681026
  0.09822453 0.10037336 0.07558583 0.04670275 0.0311638  0.05064547
  0.04292213 0.04451025 0.04200965 0.05559031 0.10921266 0.01877109
  0.02973861 0.05342277 0.0575164  0.05282546 0.1103775  0.03902854
  0.03066876 0.0147783 ]
 [0.0470528  0.07061258 0.0558835  0.06537776 0.04338239 0.04601591
  0.04814817 0.03711509 0.03748534 0.04254976 0.03745072 0.02373971
  0.03127948 0.05127086 0.07854284 0.05357998 0.0304221  0.02755873
  0.03076195 0.0304196  0.0311072  0.05135005 0.11785149 0.0108442
  0.01780815 0.04913584 0.06715199 0.04909116 0.12556703 0.01539035
  0.01119653 0.0086058 ]
 [0.04536531 0.05892981 0.06710107 0.07782161 0.06469762 0.06998926
  0.0547597  0.05332856 0.06228425 0.06395812 0.04751295 0.0475899
  0.05154282 0.11783377 0.12028838 0.05497998 0.03798945 0.03891548
  0.03997129 0.04028967 0.03878663 0.04927268 0.06692286 0.01464478
  0.0286939  0.06294055 0.06685485 0.06157905 0.12764423 0.03939753
  0.02408241 0.01354787]
 [0.04686186 0.05078428 0.0573632  0.08612727 0.08342066 0.09152441
  0.05320453 0.05590446 0.06708889 0.08469244 0.0609198  0.07103501
  0.07462467 0.1545074  0.1331794  0.04971948 0.03586304 0.04490097
  0.03993788 0.03952149 0.03622321 0.04977458 0.04038901 0.0143844
  0.02734328 0.04901348 0.05543647 0.04718706 0.09853588 0.05410196
  0.03560787 0.01961853]
 [0.04750474 0.05081781 0.06592964 0.07459733 0.06308231 0.07808923
  0.05404416 0.05814917 0.06090905 0.06660939 0.0508481  0.06388198
  0.06288242 0.09866527 0.07440121 0.04376529 0.03193682 0.03652814
  0.03439571 0.03530239 0.03169481 0.04844516 0.04381574 0.01744058
  0.03376353 0.04747962 0.05297451 0.04200505 0.08506424 0.08453551
  0.05933592 0.03387926]
 [0.04560322 0.06186727 0.07157365 0.04827904 0.03591587 0.05398693
  0.05633968 0.06012649 0.05403025 0.04617377 0.04328842 0.05456895
  0.05267158 0.03203038 0.02904556 0.05732336 0.04150135 0.04093448
  0.04127965 0.04294151 0.03993229 0.05335732 0.06689109 0.04030021
  0.06618221 0.06123408 0.06282233 0.05027139 0.05286763 0.12525953
  0.12024366 0.06712234]
 [0.04697955 0.05624196 0.06651271 0.03644933 0.02499174 0.04149118
  0.05840152 0.05256069 0.05432006 0.03391134 0.0357311  0.04049402
  0.04040454 0.02197276 0.02225095 0.06232435 0.04488245 0.03964824
  0.04597453 0.04668822 0.04078414 0.0457022  0.06240542 0.03483215
  0.0654665  0.05504839 0.0591294  0.03457573 0.03084852 0.0725294
  0.11797892 0.10513018]
 [0.04791716 0.02691396 0.02860057 0.01836358 0.01344743 0.02020721
  0.02651851 0.02627912 0.02815449 0.01870952 0.02346199 0.0221359
  0.02293934 0.01084949 0.01211477 0.03568375 0.03226577 0.02891158
  0.03808425 0.03811905 0.0334409  0.0353588  0.03228071 0.03135323
  0.05851332 0.03847313 0.02699663 0.02582308 0.01694151 0.02691828
  0.04851655 0.0624714 ]
 [0.04714141 0.05206767 0.05157474 0.03281805 0.02308863 0.04076106
  0.04867345 0.0481056  0.04262241 0.03441358 0.03927677 0.04754291
  0.04110578 0.01897325 0.01785903 0.05062358 0.04650448 0.04231673
  0.04770789 0.04825107 0.04493196 0.0527338  0.04558523 0.06117173
  0.07042839 0.04955535 0.048942   0.03276983 0.02786845 0.07835495
  0.05261011 0.1006266 ]
 [0.04861441 0.05927627 0.06307063 0.04726277 0.03008494 0.05424147
  0.05812854 0.06473122 0.05328583 0.05247812 0.05442926 0.08535375
  0.06436406 0.02808958 0.02157655 0.0510367  0.04489733 0.04812197
  0.04797517 0.04885737 0.04483731 0.05329669 0.04134523 0.06537156
  0.06548382 0.04820067 0.05212556 0.03954264 0.02998237 0.0851772
  0.06990882 0.09107552]
 [0.0494512  0.04274493 0.04473287 0.03202355 0.02289406 0.03555311
  0.0459912  0.04647175 0.04013343 0.03346462 0.04293834 0.04411053
  0.04427715 0.0192143  0.01678182 0.04931547 0.04223678 0.0404819
  0.04470894 0.04434542 0.04273332 0.05046891 0.03264922 0.06082761
  0.05981199 0.0399764  0.04227773 0.03638349 0.02401107 0.06099252
  0.05607126 0.07012832]
 [0.04880103 0.03238094 0.02982309 0.0212613  0.0164389  0.02307577
  0.03475759 0.0345907  0.03146461 0.02326927 0.03682626 0.02955051
  0.03429025 0.01292297 0.01325987 0.04890375 0.04825103 0.04146642
  0.04579411 0.04451613 0.04497238 0.04624582 0.02588895 0.0684451
  0.06082591 0.03495095 0.03344865 0.03615343 0.01825189 0.04683738
  0.04305819 0.05934082]
 [0.04822987 0.03176625 0.02844908 0.02052529 0.01550051 0.02185333
  0.03739228 0.03490471 0.03190217 0.02247099 0.03593215 0.02706797
  0.03431514 0.01216382 0.01203826 0.04695806 0.05503595 0.04552989
  0.04939179 0.04740342 0.05170335 0.0435719  0.02243999 0.09579659
  0.0587692  0.03577032 0.03105036 0.04137472 0.01464171 0.04085056
  0.04181442 0.06317707]
 [0.04899606 0.0324331  0.03118125 0.0212808  0.01751915 0.02358318
  0.03844491 0.0398112  0.03414964 0.02461209 0.05053824 0.03702481
  0.03968069 0.01359704 0.0125414  0.05442096 0.06865356 0.05127831
  0.05571577 0.05072337 0.05483172 0.04217624 0.02263907 0.12765731
  0.05785725 0.03708786 0.03007407 0.04477609 0.01462433 0.03787395
  0.05453277 0.07649969]
 [0.04904277 0.02794402 0.02695352 0.0168867  0.01528973 0.01977349
  0.03784104 0.03538065 0.03138221 0.02045941 0.05984356 0.03105401
  0.03663599 0.01152684 0.01077206 0.0489816  0.06852512 0.05011452
  0.05597504 0.0559461  0.05985801 0.0396243  0.02135563 0.13104944
  0.05524644 0.03919636 0.02328247 0.04837666 0.01286809 0.02733599
  0.05144178 0.06334959]
 [0.04734793 0.03891897 0.03954158 0.02345469 0.02065654 0.03551124
  0.06585475 0.06166467 0.05730059 0.02992519 0.04211756 0.03889909
  0.05305839 0.01595193 0.01368093 0.04530346 0.05659688 0.05647521
  0.06136887 0.06886534 0.0577698  0.04754404 0.03802969 0.07600746
  0.07591166 0.06489173 0.03198421 0.0411643  0.01967177 0.03704637
  0.04330905 0.04687362]
 [0.04974802 0.02955525 0.02991117 0.0243613  0.01926215 0.0251037
  0.03334926 0.03694091 0.03667272 0.028474   0.03470453 0.03080258
  0.03592344 0.01726735 0.01361658 0.03116042 0.0331508  0.03403501
  0.03994323 0.04577288 0.03996187 0.042927   0.02187557 0.03851428
  0.03659944 0.03595385 0.03068956 0.03877202 0.0190351  0.03168332
  0.04473    0.03768675]
 [0.04812826 0.040994   0.04352973 0.05666755 0.04826076 0.05364699
  0.04092656 0.04510774 0.05332277 0.06299067 0.04485428 0.05047879
  0.05268515 0.07717789 0.08727195 0.03627573 0.03487385 0.04274286
  0.04096693 0.04450877 0.03960792 0.04610141 0.0410032  0.01687285
  0.03108153 0.05046212 0.05280472 0.0522129  0.05168478 0.03176955
  0.03353346 0.0193873 ]
 [0.04748283 0.0551914  0.04943269 0.08469182 0.17501517 0.06570735
  0.04426232 0.04753646 0.05464966 0.09180037 0.06936885 0.07056643
  0.04964497 0.10287658 0.12894809 0.04984362 0.06457932 0.07421225
  0.05861716 0.05480709 0.06275666 0.04501664 0.0536014  0.01539632
  0.02496142 0.05363908 0.07678757 0.05842551 0.05241128 0.02347636
  0.01776095 0.01324356]
 [0.04724526 0.04909296 0.0412908  0.05670654 0.1082908  0.03690282
  0.03635205 0.04119483 0.04213939 0.06406914 0.05872947 0.05076578
  0.03883243 0.03909941 0.0603043  0.0482788  0.09493172 0.10005271
  0.08188708 0.06717447 0.09866732 0.04353511 0.04490751 0.03732673
  0.04158826 0.04644395 0.05552136 0.07878976 0.03062428 0.02343437
  0.02347895 0.01908419]
 [0.04778187 0.0504043  0.03962437 0.05532714 0.06910984 0.04089503
  0.04392936 0.04463918 0.04983933 0.05892257 0.05111539 0.04652704
  0.04061718 0.04363576 0.04594037 0.03481892 0.05573848 0.06512918
  0.05662054 0.0610364  0.06338962 0.05790707 0.0489103  0.02299237
  0.03392514 0.04712347 0.04212917 0.08790059 0.03647821 0.01800637
  0.02011955 0.01437335]]

-* TASK 10/20 | SAMPLE 44/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 218/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: There is no mention of Mary or the kitchen in the context sentences. The sentences only talk about Bill's locations, which are the cinema, school, or office.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' or', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Bill', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ',', ' school', ',', ' or', ' office', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 38), x_tokens=38, y_tokens=43, max_supp_attn=0.0698, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 38)
DEBUG result.interpretability.attn_scores 1634 
 [[0.02146992 0.0298939  0.03091218 ... 0.01423382 0.03979234 0.02737152]
 [0.02230692 0.0379725  0.03010727 ... 0.01921833 0.06955924 0.02197607]
 [0.02149983 0.03038634 0.03067687 ... 0.03825189 0.04078482 0.02628113]
 ...
 [0.02280196 0.02324794 0.02050653 ... 0.02432817 0.02709245 0.02152849]
 [0.02318881 0.02589779 0.02416205 ... 0.02536401 0.03500874 0.0212774 ]
 [0.02336975 0.02189373 0.02107526 ... 0.0218077  0.04267449 0.01920258]]

-* TASK 10/20 | SAMPLE 44/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 219/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 11 states that Fred is either in the cinema or the kitchen, but it does not provide a definitive location for Fred. Therefore, we cannot conclude that Fred is definitely in the kitchen.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Fred', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 44), x_tokens=44, y_tokens=48, max_supp_attn=0.0833, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 44)
DEBUG result.interpretability.attn_scores 2112 
 [[0.01916217 0.02108257 0.02007224 ... 0.01239827 0.04363218 0.02554496]
 [0.0196107  0.03167984 0.02713688 ... 0.0132557  0.11289524 0.00866823]
 [0.01907144 0.02629781 0.02691651 ... 0.01645853 0.10324346 0.01604498]
 ...
 [0.02014854 0.0282034  0.02814778 ... 0.02101966 0.03678343 0.00851664]
 [0.02053734 0.02187657 0.02088493 ... 0.02542602 0.0151546  0.00780081]
 [0.02069561 0.02227528 0.02176757 ... 0.01789211 0.02118018 0.00682193]]

-* TASK 10/20 | SAMPLE 44/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 220/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 10 states that Bill travelled to the cinema, which implies that Bill is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03236004 0.04194893 0.03691835 ... 0.01707862 0.01243728 0.01756865]
 [0.03321959 0.06240771 0.0485732  ... 0.01452116 0.00740822 0.0106174 ]
 [0.0322852  0.04480908 0.0439481  ... 0.01748125 0.0124028  0.01885299]
 ...
 [0.03400306 0.04530716 0.04497348 ... 0.01326027 0.01152291 0.01340413]
 [0.03447642 0.03723735 0.03551967 ... 0.01847508 0.02339828 0.03034068]
 [0.03432917 0.04142067 0.03891092 ... 0.01526832 0.01527874 0.0205221 ]]
Model's predictions for the sample 44:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Mary being in the office. Sentence 1    |
|          |                 |  only mentions Mary being in the park or   |
|          |                 |    the bedroom, and sentence 2 is about    |
|          |                 |  Fred's location, which is not related to  |
|          |                 |              Mary's location.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 4 explicitly states that Mary   |
|          |                 |             is in the bedroom.             |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |     There is no mention of Mary or the     |
|          |                 |   kitchen in the context sentences. The    |
|          |                 |      sentences only talk about Bill's      |
|          |                 |  locations, which are the cinema, school,  |
|          |                 |                 or office.                 |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 11 states that Fred is either   |
|          |                 |    in the cinema or the kitchen, but it    |
|          |                 |   does not provide a definitive location   |
|          |                 |  for Fred. Therefore, we cannot conclude   |
|          |                 |  that Fred is definitely in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 10 states that Bill travelled   |
|          |                 |   to the cinema, which implies that Bill   |
|          |                 |             is in the cinema.              |
+----------+-----------------+--------------------------------------------+

Metrics for sample 44:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 45/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 221/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: There is no mention of Mary going to the cinema in the context sentences. She went to the park and the kitchen, but there is no information about her going to the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' going', ' to', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' She', ' went', ' to', ' the', ' park', ' and', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' her', ' going', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 26), x_tokens=26, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 26)
DEBUG result.interpretability.attn_scores 1170 
 [[0.02130907 0.03898193 0.03020721 ... 0.00912717 0.00600112 0.01490963]
 [0.02187734 0.03605786 0.0322912  ... 0.00928195 0.00516924 0.0157242 ]
 [0.02059584 0.034306   0.0405036  ... 0.01551557 0.00945477 0.0236578 ]
 ...
 [0.02178028 0.02246642 0.02194213 ... 0.00778031 0.00540505 0.01309298]
 [0.02161221 0.01791206 0.01773781 ... 0.01117282 0.01004965 0.01476312]
 [0.02184679 0.02160195 0.02023848 ... 0.00905082 0.00849149 0.0127211 ]]

-* TASK 10/20 | SAMPLE 45/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 222/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: There is no mention of Bill going to the kitchen in the context sentences. He was in the cinema and then went back to the office, but there is no information about him going to the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' going', ' to', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' He', ' was', ' in', ' the', ' cinema', ' and', ' then', ' went', ' back', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' him', ' going', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 32), x_tokens=32, y_tokens=49, max_supp_attn=0.1429, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 32)
DEBUG result.interpretability.attn_scores 1568 
 [[0.01870274 0.03925717 0.03341326 ... 0.015714   0.01246975 0.00604407]
 [0.01968043 0.03595074 0.03068113 ... 0.00566916 0.00384074 0.00299968]
 [0.01901094 0.03061535 0.03619667 ... 0.01640277 0.01038753 0.00464661]
 ...
 [0.01987853 0.02951417 0.02535078 ... 0.00851171 0.00514212 0.00354773]
 [0.02014666 0.02220186 0.01891503 ... 0.00964464 0.00682701 0.00586205]
 [0.02021234 0.02425104 0.01971083 ... 0.00671481 0.0060738  0.00473762]]

-* TASK 10/20 | SAMPLE 45/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 223/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: There is no mention of Bill in the context sentences. The sentences only talk about Mary's journeys to the park and the cinema, but do not provide any information about Bill's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' journeys', ' to', ' the', ' park', ' and', ' the', ' cinema', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.1277, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01969454 0.0215621  0.02688746 ... 0.05845781 0.01891679 0.01475085]
 [0.02043737 0.03209708 0.03059785 ... 0.09165574 0.01505789 0.00728657]
 [0.01970548 0.02418951 0.03013917 ... 0.04715265 0.02138264 0.01190101]
 ...
 [0.02097322 0.02230959 0.01907602 ... 0.02427127 0.02191152 0.02071452]
 [0.02123831 0.02421777 0.02265648 ... 0.03308432 0.01796392 0.01167797]
 [0.02133068 0.02113817 0.02043635 ... 0.0467301  0.01616753 0.01134084]]

-* TASK 10/20 | SAMPLE 45/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 224/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentence states that Julie is either in the office or the bedroom, but it does not provide a definitive location. Therefore, it is possible that Julie is in the bedroom, but it is also possible that she is in the office.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' it', ' is', ' possible', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' but', ' it', ' is', ' also', ' possible', ' that', ' she', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 44), x_tokens=44, y_tokens=57, max_supp_attn=0.0175, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 44)
DEBUG result.interpretability.attn_scores 2508 
 [[0.01601553 0.02378923 0.02094089 ... 0.04132804 0.01687432 0.02041741]
 [0.01649179 0.03378614 0.02604583 ... 0.0863101  0.00892583 0.00612383]
 [0.01592362 0.0261231  0.02594509 ... 0.09143588 0.02173442 0.01019556]
 ...
 [0.01673756 0.02173844 0.0233166  ... 0.02982953 0.01206284 0.0083182 ]
 [0.01713475 0.01765514 0.01855144 ... 0.01283679 0.01141436 0.0101136 ]
 [0.01721368 0.01726905 0.01863844 ... 0.01757941 0.0107022  0.00987391]]

-* TASK 10/20 | SAMPLE 45/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 225/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentence 13 states that Julie is in the cinema, which contradicts the possibility of her being in the office. Sentence 14 also does not mention the office as a possible location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' which', ' contrad', 'icts', ' the', ' possibility', ' of', ' her', ' being', ' in', ' the', ' office', '.', ' Sentence', ' ', '14', ' also', ' does', ' not', ' mention', ' the', ' office', ' as', ' a', ' possible', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.125, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01900405 0.03396893 0.03052371 ... 0.01276643 0.02859234 0.03722061]
 [0.01951889 0.0336847  0.03126978 ... 0.01254861 0.04850077 0.05647092]
 [0.01917108 0.02817929 0.02952016 ... 0.01611374 0.03254401 0.03780491]
 ...
 [0.02028107 0.02971542 0.02547804 ... 0.01167732 0.06457951 0.03296221]
 [0.02062947 0.02308132 0.01859125 ... 0.01261157 0.05325459 0.02568906]
 [0.02056632 0.02549148 0.01975921 ... 0.01640985 0.08697415 0.03190045]]
Model's predictions for the sample 45:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Mary going to the  |
|          |                 |    cinema in the context sentences. She    |
|          |                 |   went to the park and the kitchen, but    |
|          |                 |  there is no information about her going   |
|          |                 |               to the cinema.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Bill going to the  |
|          |                 |  kitchen in the context sentences. He was  |
|          |                 |  in the cinema and then went back to the   |
|          |                 |    office, but there is no information     |
|          |                 |      about him going to the kitchen.       |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |     There is no mention of Bill in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |   talk about Mary's journeys to the park   |
|          |                 |   and the cinema, but do not provide any   |
|          |                 |     information about Bill's location.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   The context sentence states that Julie   |
|          |                 |  is either in the office or the bedroom,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |  location. Therefore, it is possible that  |
|          |                 |  Julie is in the bedroom, but it is also   |
|          |                 |    possible that she is in the office.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentence 13 states that     |
|          |                 |       Julie is in the cinema, which        |
|          |                 |  contradicts the possibility of her being  |
|          |                 |  in the office. Sentence 14 also does not  |
|          |                 |      mention the office as a possible      |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 45:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 46/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 226/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 2 states that Bill is either in the school or the kitchen, but it does not provide a definitive location for Bill. Therefore, we can only conclude that Bill might be in the school, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Bill', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 26), x_tokens=26, y_tokens=55, max_supp_attn=0.0727, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 26)
DEBUG result.interpretability.attn_scores 1430 
 [[0.01670156 0.03398238 0.03502898 ... 0.0122799  0.00365799 0.02140075]
 [0.01723619 0.02113615 0.02054396 ... 0.00988674 0.00319442 0.01393386]
 [0.01752323 0.02398954 0.02687147 ... 0.0140712  0.00447517 0.01366829]
 ...
 [0.01763175 0.02000958 0.02008802 ... 0.00854375 0.00299953 0.01274937]
 [0.01768178 0.01604044 0.01661198 ... 0.01412728 0.00770672 0.01408496]
 [0.01778653 0.01795446 0.01802238 ... 0.01185828 0.00605492 0.0140279 ]]

-* TASK 10/20 | SAMPLE 46/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 227/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Mary journeyed to the cinema, which implies that Mary has moved to the cinema. 

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Mary', ' has', ' moved', ' to', ' the', ' cinema', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0625, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02921307 0.03948822 0.04703056 ... 0.01153923 0.01458458 0.02057527]
 [0.02995373 0.03972175 0.04575175 ... 0.01396671 0.01679158 0.03222548]
 [0.0305825  0.03597335 0.04851702 ... 0.02249539 0.01824671 0.0336462 ]
 ...
 [0.03081354 0.04191286 0.03648075 ... 0.00807221 0.01196074 0.01548644]
 [0.0307145  0.03675266 0.0297345  ... 0.01095957 0.01946231 0.01665076]
 [0.03106706 0.03742254 0.02955444 ... 0.00788705 0.0157209  0.01409514]]

-* TASK 10/20 | SAMPLE 46/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 228/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 states that Bill travelled to the cinema, which implies that Bill has moved to the cinema. The context sentence 8 is contradictory, but since Bill travelled to the cinema, we can conclude that Bill is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' has', ' moved', ' to', ' the', ' cinema', '.', ' The', ' context', ' sentence', ' ', '8', ' is', ' contradictory', ',', ' but', ' since', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' we', ' can', ' conclude', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 38), x_tokens=38, y_tokens=56, max_supp_attn=0.0357, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 38)
DEBUG result.interpretability.attn_scores 2128 
 [[0.01642617 0.02393171 0.02779179 ... 0.03033599 0.02851004 0.02234433]
 [0.01680293 0.01763168 0.02253899 ... 0.01944944 0.02084601 0.016927  ]
 [0.01720961 0.02483617 0.03030948 ... 0.03073663 0.02519265 0.01748145]
 ...
 [0.01740468 0.02430749 0.02227959 ... 0.04894913 0.02629639 0.01769574]
 [0.01776402 0.01796547 0.01614369 ... 0.0269969  0.01868076 0.01654062]
 [0.01764248 0.01994129 0.01763714 ... 0.01769379 0.02970058 0.01581139]]

-* TASK 10/20 | SAMPLE 46/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 229/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 states that Bill is in the cinema, and there is no mention of Bill being in the office. The context sentence 11 is irrelevant to the office location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Bill', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' office', '.', ' The', ' context', ' sentence', ' ', '11', ' is', ' irrelevant', ' to', ' the', ' office', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 44), x_tokens=44, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 44)
DEBUG result.interpretability.attn_scores 1936 
 [[0.02111166 0.0303285  0.03080106 ... 0.02765546 0.1068489  0.00960772]
 [0.02161677 0.01963732 0.02099056 ... 0.01891489 0.05969512 0.03313644]
 [0.02206118 0.0299229  0.0313191  ... 0.02257497 0.07897694 0.01877328]
 ...
 [0.02212742 0.02880448 0.0267946  ... 0.03351812 0.03676542 0.00593166]
 [0.02249028 0.02316988 0.02141189 ... 0.03375857 0.01929339 0.00639802]
 [0.02253961 0.02343947 0.02212669 ... 0.02731112 0.02279731 0.00519119]]

-* TASK 10/20 | SAMPLE 46/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 230/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill in the context sentences. The context sentences only talk about Mary's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03225274 0.03437958 0.03680522 ... 0.05311695 0.0376261  0.0263329 ]
 [0.03301166 0.02629499 0.02806855 ... 0.03295791 0.02964387 0.02596138]
 [0.03373292 0.03529803 0.03772683 ... 0.06096824 0.02816033 0.02220457]
 ...
 [0.03418886 0.03404352 0.02860077 ... 0.05073614 0.03106765 0.03471126]
 [0.03474781 0.03673393 0.03312214 ... 0.05558995 0.02584643 0.02549378]
 [0.03495509 0.03112398 0.02929114 ... 0.07128934 0.02468228 0.02310134]]
Model's predictions for the sample 46:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 2 states that Bill   |
|          |                 |  is either in the school or the kitchen,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |    location for Bill. Therefore, we can    |
|          |                 |  only conclude that Bill might be in the   |
|          |                 |     school, but we cannot be certain.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 4 states that Mary   |
|          |                 |   journeyed to the cinema, which implies   |
|          |                 |     that Mary has moved to the cinema.     |
+----------+-----------------+--------------------------------------------+
|    no    |       yes       |  The context sentence 7 states that Bill   |
|          |                 |   travelled to the cinema, which implies   |
|          |                 |   that Bill has moved to the cinema. The   |
|          |                 |  context sentence 8 is contradictory, but  |
|          |                 |   since Bill travelled to the cinema, we   |
|          |                 |  can conclude that Bill is in the cinema.  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 10 states that Bill  |
|          |                 |     is in the cinema, and there is no      |
|          |                 |  mention of Bill being in the office. The  |
|          |                 |  context sentence 11 is irrelevant to the  |
|          |                 |              office location.              |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     There is no mention of Bill in the     |
|          |                 |  context sentences. The context sentences  |
|          |                 |      only talk about Mary's location.      |
+----------+-----------------+--------------------------------------------+

Metrics for sample 46:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.06 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 47/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 231/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Julie moved to the kitchen, which implies that she is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02794649 0.05124142 0.06347863 0.076828   0.081429   0.07688028
  0.06851795 0.07667425 0.06136046 0.06663485 0.04686136 0.06316529
  0.07116187 0.09744753 0.06160155 0.03231341 0.03183528 0.03217303
  0.03093002 0.03431723 0.02801788 0.04131738 0.04722448 0.02229048
  0.01581738 0.02578609]
 [0.02789784 0.07502666 0.05889071 0.04510625 0.03405541 0.04836541
  0.10703167 0.08262715 0.05728914 0.03983986 0.05071613 0.04431161
  0.06969132 0.02091944 0.0197901  0.04162571 0.03738928 0.05298001
  0.04417492 0.05403351 0.04251389 0.04392333 0.04962293 0.0479741
  0.03583536 0.03723861]
 [0.03049011 0.06049876 0.03900031 0.05714956 0.04100186 0.03808783
  0.03144057 0.02289124 0.02349498 0.03575151 0.02702457 0.01691669
  0.01848436 0.03255863 0.04316124 0.02317681 0.01432126 0.01281618
  0.0170738  0.01786586 0.01675683 0.04460327 0.05587849 0.0080206
  0.00545921 0.01236421]
 [0.02882579 0.03652831 0.03541256 0.02497403 0.01729963 0.02658714
  0.02800769 0.02477266 0.02876916 0.0245376  0.02494821 0.0254642
  0.02343875 0.01381434 0.01352166 0.03308885 0.03175267 0.03436511
  0.03740622 0.03881309 0.03174629 0.03141429 0.04936869 0.05644003
  0.06444487 0.05549894]
 [0.02901028 0.04293467 0.04857708 0.06809515 0.06220694 0.04949
  0.03374918 0.02959829 0.03519872 0.04663441 0.03310175 0.02637388
  0.02540024 0.10671514 0.11203419 0.03614824 0.02729067 0.01966125
  0.0225157  0.02442037 0.02344075 0.03936718 0.06636799 0.01298339
  0.00822566 0.02678224]
 [0.02962043 0.02827539 0.02993475 0.05272263 0.04724535 0.04499362
  0.02527748 0.02340682 0.030193   0.04433378 0.03032698 0.02999571
  0.02759593 0.11658829 0.13987681 0.03553673 0.03047493 0.02350996
  0.02525401 0.02583027 0.02234325 0.03361056 0.03916262 0.010207
  0.00660524 0.01717604]
 [0.03007336 0.03187432 0.03820361 0.05532146 0.05129923 0.05576184
  0.0330126  0.03180307 0.03898231 0.05170982 0.03501794 0.04663962
  0.04157968 0.09219462 0.0860546  0.03002345 0.0276306  0.02343147
  0.02402453 0.0252842  0.02099902 0.03047865 0.03681345 0.01492439
  0.0092522  0.01673304]
 [0.02910948 0.04036073 0.0464263  0.04141258 0.04434447 0.04884311
  0.03630009 0.03964529 0.04100684 0.04409819 0.03450444 0.04934114
  0.04154253 0.054412   0.04892221 0.03906802 0.03496088 0.03044819
  0.02955955 0.03192934 0.02870429 0.03397534 0.05084486 0.0410784
  0.02915236 0.03355515]
 [0.03027875 0.04123612 0.05029359 0.04878695 0.04436228 0.05808069
  0.04205127 0.04600975 0.04943869 0.05086143 0.03518872 0.05181367
  0.04636742 0.04244142 0.02802282 0.02776616 0.02728184 0.02517135
  0.02586533 0.02777878 0.02326019 0.03464634 0.03960235 0.02004841
  0.01486907 0.02382041]
 [0.02964406 0.05123667 0.05571669 0.02998296 0.02407271 0.03850383
  0.0429061  0.04222319 0.04549048 0.03163333 0.02824943 0.03880786
  0.03799902 0.01893951 0.01582241 0.0437107  0.03435828 0.02906553
  0.03089793 0.03322051 0.03115464 0.0336744  0.06652365 0.04387212
  0.03680656 0.0361479 ]
 [0.03015833 0.03844848 0.04606556 0.02477235 0.02104359 0.0283626
  0.04427944 0.03368787 0.04083034 0.02486562 0.02307088 0.02703831
  0.02610623 0.01431866 0.01381556 0.04238859 0.03129984 0.02587661
  0.03030029 0.03365243 0.03095719 0.02963473 0.05336395 0.04900191
  0.04387689 0.0366143 ]
 [0.03066203 0.01372691 0.016377   0.01130141 0.01007651 0.01400863
  0.01559235 0.01550354 0.02102253 0.01342508 0.01255949 0.01426773
  0.0135525  0.00653571 0.00654599 0.01822563 0.01768998 0.01637661
  0.02126307 0.02326399 0.02356963 0.01712622 0.03025241 0.05672665
  0.06688338 0.06415581]
 [0.03020793 0.02413745 0.02634357 0.01651922 0.01512664 0.02117815
  0.02405727 0.02238245 0.02442345 0.0182992  0.02143617 0.02191306
  0.02076338 0.00963997 0.0101894  0.03792683 0.02743857 0.02544788
  0.02791341 0.02852847 0.02815296 0.02890814 0.03010064 0.05367867
  0.06740809 0.04607544]
 [0.03041363 0.02350663 0.02414065 0.018634   0.01652542 0.02359055
  0.02531528 0.02721035 0.02533412 0.02202077 0.02499061 0.02890897
  0.02863748 0.01102641 0.00986766 0.0356651  0.03098199 0.03041518
  0.02892087 0.02902808 0.03014431 0.02904581 0.02130459 0.05181644
  0.051533   0.02748643]
 [0.0299842  0.02109177 0.01842092 0.01575427 0.01293108 0.01695248
  0.02240964 0.02265833 0.02003177 0.01723611 0.02362206 0.02055855
  0.0236313  0.00791913 0.00784907 0.03488391 0.03062471 0.03903277
  0.03180491 0.03465967 0.04274855 0.02760665 0.01711735 0.05676748
  0.09294562 0.04107448]
 [0.03064379 0.01919139 0.01754129 0.01511321 0.01306526 0.01759737
  0.02154319 0.02244351 0.02007775 0.0176193  0.02756399 0.02350406
  0.02397923 0.00771366 0.00765989 0.03685413 0.0270094  0.04409103
  0.03230049 0.03770949 0.03626518 0.02346141 0.01401389 0.03723452
  0.06561642 0.03368323]
 [0.03056697 0.01710738 0.01522297 0.01202459 0.01042917 0.01439975
  0.02019213 0.01947214 0.01798499 0.01423321 0.03483893 0.01964949
  0.02074424 0.00635133 0.00702929 0.0331929  0.03337695 0.0384643
  0.03518505 0.03445833 0.03714043 0.02468713 0.01433623 0.03889103
  0.04771973 0.05454273]
 [0.03009468 0.01924996 0.01773278 0.01363661 0.01220319 0.01741525
  0.02080951 0.0208979  0.0220919  0.01570335 0.02332056 0.0200474
  0.0213275  0.00749374 0.00737198 0.02477945 0.0264235  0.02951444
  0.03548072 0.03455986 0.03779204 0.02506823 0.0183756  0.05525659
  0.05137845 0.06535028]
 [0.03108617 0.02105853 0.01930141 0.01515354 0.01238843 0.01757448
  0.0208318  0.02135016 0.02094837 0.01660392 0.02451126 0.02065114
  0.02090976 0.00822703 0.00775586 0.023147   0.02404903 0.02743568
  0.02923127 0.0276503  0.02870842 0.02603456 0.01571901 0.02665596
  0.02917621 0.03797861]
 [0.03133402 0.02364514 0.02707873 0.02360691 0.01851674 0.02709072
  0.0258464  0.03235935 0.0278481  0.028453   0.02779718 0.03677328
  0.03200083 0.01399088 0.01007203 0.02154881 0.02284035 0.02487905
  0.02505778 0.02333741 0.02321298 0.02850021 0.01568658 0.01772621
  0.01853685 0.01912794]
 [0.03146297 0.02926001 0.03095543 0.02834357 0.02087259 0.03188566
  0.03305136 0.0419213  0.03007732 0.03369689 0.03703896 0.04418086
  0.04107636 0.01554121 0.01096246 0.02477762 0.02311248 0.02721783
  0.02489048 0.02402974 0.02324296 0.0291449  0.01738132 0.01618758
  0.01535324 0.01377076]
 [0.03134297 0.02685544 0.02689922 0.02545951 0.01998321 0.02860345
  0.02944016 0.03542343 0.02950778 0.03138135 0.03424063 0.03951608
  0.03895048 0.01460547 0.01100296 0.02770707 0.0247188  0.02950673
  0.02747938 0.02679219 0.0260503  0.02978731 0.0154252  0.01962619
  0.01691117 0.01278608]
 [0.03122109 0.02040871 0.01940826 0.01544742 0.01187665 0.01747596
  0.02192117 0.02493095 0.02305597 0.01864213 0.02414263 0.0238369
  0.02651272 0.00835055 0.00759683 0.03053823 0.02733451 0.02931529
  0.02849526 0.02712201 0.03103885 0.02781308 0.01307085 0.02947511
  0.02727673 0.01770762]
 [0.03134606 0.02032561 0.0183551  0.01535523 0.01110601 0.01598413
  0.02240286 0.02299413 0.02182345 0.0172212  0.02410023 0.02160712
  0.02533155 0.00775464 0.0072263  0.03052594 0.02729067 0.03186752
  0.03023663 0.02989421 0.03573452 0.02398544 0.01237622 0.03072636
  0.03095071 0.02043717]
 [0.03150304 0.02022746 0.01822004 0.0159329  0.01256773 0.01681912
  0.02111868 0.02336838 0.0220652  0.01933694 0.02584447 0.0237587
  0.02467509 0.00871207 0.00791121 0.02760694 0.03114186 0.02977263
  0.03261141 0.0277088  0.03072528 0.02514171 0.01202729 0.01991512
  0.01971507 0.0167436 ]
 [0.0315054  0.0230808  0.02092987 0.01721502 0.01288596 0.01862145
  0.02584445 0.02705997 0.02706054 0.0204388  0.03140815 0.02513448
  0.02761507 0.00915132 0.00816483 0.02968226 0.03021225 0.03121947
  0.03307227 0.03073855 0.03345784 0.02614032 0.01292816 0.02256476
  0.02063619 0.01824977]
 [0.03152988 0.01784823 0.01655737 0.01176096 0.01004207 0.01346525
  0.02155772 0.02061184 0.02115602 0.01434951 0.03798822 0.01870227
  0.02221592 0.00684963 0.006117   0.02825061 0.03541213 0.03011811
  0.03502354 0.03037087 0.03359085 0.02489688 0.01193875 0.02377825
  0.02112132 0.02956228]
 [0.03024864 0.02236133 0.02113076 0.01305317 0.01123187 0.01601498
  0.0253996  0.02598811 0.02763601 0.01625055 0.03281673 0.0207087
  0.02722322 0.00755399 0.00694115 0.02802655 0.03959063 0.03600889
  0.04168019 0.04095203 0.04869712 0.02771153 0.02163666 0.04840095
  0.03583345 0.05889182]
 [0.03151496 0.02132685 0.02055717 0.01735476 0.01354142 0.01961965
  0.02109639 0.02458836 0.02613207 0.02037469 0.02388941 0.02483981
  0.02409295 0.01078238 0.00849002 0.01793882 0.02406637 0.02314467
  0.02732576 0.02515515 0.02723119 0.02491898 0.01514826 0.01737642
  0.01636928 0.02374191]
 [0.03027424 0.0285065  0.0289363  0.04383277 0.0466742  0.03941744
  0.02373937 0.02497504 0.03128314 0.04448735 0.0310242  0.03250203
  0.03003934 0.07690106 0.09152213 0.02461134 0.02756375 0.02366289
  0.025768   0.02522742 0.02355343 0.03215264 0.03396813 0.01063056
  0.00786099 0.01923398]
 [0.03009405 0.02981405 0.02899785 0.04882008 0.09551308 0.03870387
  0.02210435 0.02337856 0.03025382 0.05188128 0.03651604 0.03242632
  0.02465933 0.07556222 0.09639198 0.02994736 0.03845732 0.03265971
  0.03097316 0.02794398 0.02733525 0.02913595 0.03272545 0.00919325
  0.00566552 0.01633045]
 [0.02985189 0.02621275 0.02482965 0.03925746 0.08516227 0.02705489
  0.01829349 0.02223207 0.02616618 0.04558623 0.03618038 0.03576474
  0.02510185 0.03372755 0.04252743 0.02640222 0.06108797 0.0543425
  0.04341524 0.03261938 0.04016691 0.02600317 0.02764771 0.0170428
  0.01157527 0.02145168]
 [0.03005646 0.03339557 0.03006383 0.0412714  0.05892014 0.03257037
  0.02485879 0.0249106  0.0319654  0.0418587  0.03515927 0.03088036
  0.02759255 0.0352604  0.03818138 0.02291458 0.04098126 0.03600816
  0.03386877 0.0311045  0.03154678 0.04608417 0.04204621 0.01348824
  0.00918852 0.01990099]]

-* TASK 10/20 | SAMPLE 47/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 232/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred being in the park in the context sentences. Sentence 4 states that Fred moved to the kitchen, and sentence 5 provides alternative locations (bedroom or office), but neither of them mentions the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' park', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '4', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' and', ' sentence', ' ', '5', ' provides', ' alternative', ' locations', ' (', 'bed', 'room', ' or', ' office', '),', ' but', ' neither', ' of', ' them', ' mentions', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 32), x_tokens=32, y_tokens=54, max_supp_attn=0.0741, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 32)
DEBUG result.interpretability.attn_scores 1728 
 [[0.01701405 0.02505431 0.02686458 ... 0.04778284 0.00769539 0.03591237]
 [0.01753357 0.02433948 0.02504042 ... 0.05144205 0.01102505 0.04389946]
 [0.01779667 0.02361199 0.02710581 ... 0.0514363  0.01704099 0.03570208]
 ...
 [0.01785106 0.02467155 0.02135419 ... 0.01728246 0.00576039 0.03330537]
 [0.01803987 0.01852373 0.01557916 ... 0.01047819 0.00802925 0.01489113]
 [0.01815084 0.01921236 0.01577764 ... 0.00935444 0.00680958 0.0150563 ]]

-* TASK 10/20 | SAMPLE 47/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 233/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the context sentences that suggests Mary is in the bedroom. Sentence 8 explicitly states that Mary is in the kitchen, which implies that she is not in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' bedroom', '.', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02044355 0.02777733 0.02983944 ... 0.01876023 0.00986564 0.0271787 ]
 [0.02071784 0.02375735 0.02819823 ... 0.02651083 0.01832116 0.03071606]
 [0.02136085 0.02765525 0.03338044 ... 0.01754736 0.01015407 0.02106739]
 ...
 [0.02154455 0.02827936 0.02551846 ... 0.01321833 0.00835158 0.02047038]
 [0.0220031  0.0212634  0.018961   ... 0.01409635 0.01294313 0.01839865]
 [0.02195176 0.02275952 0.01896628 ... 0.01257045 0.00870758 0.0165174 ]]

-* TASK 10/20 | SAMPLE 47/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 234/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred being in the school in the context sentences. Sentence 10 states that Fred journeyed to the park, which implies that he is currently in the park, not in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '10', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' park', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 44), x_tokens=44, y_tokens=49, max_supp_attn=0.0408, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 44)
DEBUG result.interpretability.attn_scores 2156 
 [[0.01891587 0.02950507 0.02646135 ... 0.00886856 0.01378343 0.00558548]
 [0.0192962  0.02184667 0.02065609 ... 0.01012104 0.02648497 0.01965928]
 [0.0197193  0.02945175 0.02889253 ... 0.01207435 0.0159719  0.00837757]
 ...
 [0.01982773 0.02897699 0.02878295 ... 0.00508247 0.00575589 0.00407577]
 [0.02039292 0.02256135 0.02160792 ... 0.00718717 0.00545008 0.00453302]
 [0.02019164 0.02561049 0.02315735 ... 0.00586104 0.00523963 0.00368263]]

-* TASK 10/20 | SAMPLE 47/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 235/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred in the context sentences. The sentences only mention Julie's locations, which are the cinema and the office. There is no mention of Fred or the kitchen.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Julie', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ' and', ' the', ' office', '.', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' or', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 50), x_tokens=50, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 50)
DEBUG result.interpretability.attn_scores 2250 
 [[0.02048902 0.02893235 0.02531477 ... 0.03291165 0.04088052 0.03219195]
 [0.02090391 0.02226496 0.02166772 ... 0.01874367 0.02135975 0.02254454]
 [0.02142513 0.02795339 0.02826837 ... 0.03810576 0.03430982 0.02447544]
 ...
 [0.02179137 0.02763355 0.02330011 ... 0.03978693 0.05681496 0.02811954]
 [0.02217254 0.03091119 0.02863857 ... 0.03932941 0.05383455 0.02615189]
 [0.02226784 0.02552916 0.02500627 ... 0.03453499 0.06139252 0.02694206]]
Model's predictions for the sample 47:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Julie moved to   |
|          |                 |   the kitchen, which implies that she is   |
|          |                 |         currently in the kitchen.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Fred being in the  |
|          |                 |  park in the context sentences. Sentence   |
|          |                 |  4 states that Fred moved to the kitchen,  |
|          |                 |    and sentence 5 provides alternative     |
|          |                 |     locations (bedroom or office), but     |
|          |                 |     neither of them mentions the park.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information in the context   |
|          |                 |   sentences that suggests Mary is in the   |
|          |                 |   bedroom. Sentence 8 explicitly states    |
|          |                 |     that Mary is in the kitchen, which     |
|          |                 |  implies that she is not in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Fred being in the  |
|          |                 |      school in the context sentences.      |
|          |                 |   Sentence 10 states that Fred journeyed   |
|          |                 |   to the park, which implies that he is    |
|          |                 |     currently in the park, not in the      |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information about Fred in    |
|          |                 |    the context sentences. The sentences    |
|          |                 |   only mention Julie's locations, which    |
|          |                 |  are the cinema and the office. There is   |
|          |                 |     no mention of Fred or the kitchen.     |
+----------+-----------------+--------------------------------------------+

Metrics for sample 47:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 48/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 236/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred going to the bedroom. In fact, sentence 2 states that Fred went back to the kitchen, implying that Fred was in the kitchen previously and is now back there.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' going', ' to', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' went', ' back', ' to', ' the', ' kitchen', ',', ' implying', ' that', ' Fred', ' was', ' in', ' the', ' kitchen', ' previously', ' and', ' is', ' now', ' back', ' there', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 26), x_tokens=26, y_tokens=48, max_supp_attn=0.0417, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 26)
DEBUG result.interpretability.attn_scores 1248 
 [[0.01923376 0.0397314  0.04301922 ... 0.01397813 0.00501058 0.01871535]
 [0.01985173 0.02491688 0.02538276 ... 0.00968051 0.00427403 0.01215551]
 [0.02017942 0.02815832 0.03236752 ... 0.01286797 0.00584588 0.0114752 ]
 ...
 [0.02022611 0.02730724 0.02589473 ... 0.00877968 0.00418172 0.01149959]
 [0.02027714 0.0212051  0.02019557 ... 0.01249913 0.00741773 0.0123656 ]
 [0.02036598 0.02672017 0.02358378 ... 0.01046653 0.00574917 0.01107752]]

-* TASK 10/20 | SAMPLE 48/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 237/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred going to the cinema. In fact, sentence 5 states that Fred journeyed to the school, which is a different location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' going', ' to', ' the', ' cinema', '.', ' In', ' fact', ',', ' sentence', ' ', '5', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' school', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.15, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02339827 0.03587855 0.04114482 ... 0.011103   0.01262121 0.00665834]
 [0.02401917 0.03594436 0.03878569 ... 0.01368187 0.01726625 0.0096538 ]
 [0.0244793  0.03199212 0.03885996 ... 0.01725274 0.02150084 0.01137698]
 ...
 [0.02446503 0.03539595 0.0309703  ... 0.00661343 0.0071383  0.00536521]
 [0.02486938 0.02495168 0.02175545 ... 0.00831483 0.00730904 0.00647968]
 [0.02490451 0.02786194 0.02328836 ... 0.00687626 0.00709816 0.00522739]]

-* TASK 10/20 | SAMPLE 48/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 238/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill going to the office. The previous context sentences (4 and 5) mentioned Bill going to the bedroom, but there is no information about Bill going to the office.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' going', ' to', ' the', ' office', '.', ' The', ' previous', ' context', ' sentences', ' (', '4', ' and', ' ', '5', ')', ' mentioned', ' Bill', ' going', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' going', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 38), x_tokens=38, y_tokens=49, max_supp_attn=0.0408, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 38)
DEBUG result.interpretability.attn_scores 1862 
 [[0.01889466 0.02764073 0.02863108 ... 0.04834374 0.03090026 0.0076739 ]
 [0.01917315 0.02071224 0.02368725 ... 0.02496886 0.0245816  0.00951857]
 [0.01970566 0.02716921 0.03138276 ... 0.0395838  0.02176941 0.00609573]
 ...
 [0.02028017 0.02359569 0.02079952 ... 0.04583469 0.02006746 0.00620927]
 [0.02038705 0.02602205 0.02442403 ... 0.05137194 0.02421881 0.00606615]
 [0.02053148 0.02275917 0.02188984 ... 0.06966797 0.02503633 0.0060799 ]]

-* TASK 10/20 | SAMPLE 48/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 239/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 (from previous context) states that Fred travelled to the cinema, and there is no information about Fred leaving the cinema. Sentence 10 states that Mary is in the cinema, but it does not imply that Fred is not in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' (', 'from', ' previous', ' context', ')', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Fred', ' leaving', ' the', ' cinema', '.', ' Sentence', ' ', '10', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' imply', ' that', ' Fred', ' is', ' not', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 44), x_tokens=44, y_tokens=58, max_supp_attn=0.0517, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 44)
DEBUG result.interpretability.attn_scores 2552 
 [[0.01565376 0.02111967 0.01986603 ... 0.02456667 0.08041812 0.00931514]
 [0.01606311 0.01717479 0.0167935  ... 0.01148576 0.03622021 0.00921042]
 [0.0164478  0.02419141 0.02356267 ... 0.01491584 0.06494646 0.01169953]
 ...
 [0.01662143 0.02181878 0.02127051 ... 0.02155503 0.02282643 0.00681477]
 [0.01708323 0.01859562 0.01699212 ... 0.02075241 0.01166421 0.00927013]
 [0.01688993 0.01959265 0.0190047  ... 0.0277563  0.01376602 0.00765342]]

-* TASK 10/20 | SAMPLE 48/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 240/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Mary moved to the office, which implies that Mary is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.0336054  0.0495908  0.05080318 ... 0.03425377 0.05616798 0.04234469]
 [0.03379868 0.03713714 0.03731715 ... 0.01762402 0.02905602 0.05009431]
 [0.03488526 0.05223486 0.05702769 ... 0.03637868 0.05227715 0.03999623]
 ...
 [0.0350849  0.05415985 0.0498285  ... 0.07215124 0.05880405 0.02995787]
 [0.03532816 0.04165582 0.03751658 ... 0.05428128 0.03749738 0.03144806]
 [0.0354806  0.04282257 0.0381298  ... 0.03997109 0.06670956 0.03034771]]
Model's predictions for the sample 48:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Fred going to the bedroom. In fact,     |
|          |                 |  sentence 2 states that Fred went back to  |
|          |                 |   the kitchen, implying that Fred was in   |
|          |                 |   the kitchen previously and is now back   |
|          |                 |                   there.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |     Fred going to the cinema. In fact,     |
|          |                 |  sentence 5 states that Fred journeyed to  |
|          |                 |      the school, which is a different      |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    The context sentences do not mention    |
|          |                 |   Bill going to the office. The previous   |
|          |                 |   context sentences (4 and 5) mentioned    |
|          |                 |  Bill going to the bedroom, but there is   |
|          |                 |   no information about Bill going to the   |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     Sentence 8 (from previous context)     |
|          |                 |     states that Fred travelled to the      |
|          |                 |    cinema, and there is no information     |
|          |                 |  about Fred leaving the cinema. Sentence   |
|          |                 |   10 states that Mary is in the cinema,    |
|          |                 |   but it does not imply that Fred is not   |
|          |                 |               in the cinema.               |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 13 states that Mary moved to    |
|          |                 |   the office, which implies that Mary is   |
|          |                 |          currently in the office.          |
+----------+-----------------+--------------------------------------------+

Metrics for sample 48:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.07 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 49/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 241/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: Sentence 2 explicitly states that Julie is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '2', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(23, 26), x_tokens=26, y_tokens=23, max_supp_attn=0.087, attn_on_target=0.0435)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (23, 26)
DEBUG result.interpretability.attn_scores 598 
 [[0.04074095 0.06281726 0.07757201 0.09438065 0.10107198 0.09648325
  0.07676531 0.09469493 0.080657   0.08515908 0.06504714 0.0827248
  0.09443258 0.11897102 0.07540029 0.04395192 0.04106706 0.04624864
  0.04181096 0.04729914 0.03761475 0.05427925 0.05630556 0.0294443
  0.01755708 0.03266513]
 [0.04043894 0.11286794 0.08371561 0.06354575 0.04627221 0.0639854
  0.18614453 0.13375998 0.08163952 0.05643073 0.09515154 0.06561046
  0.11567304 0.02605122 0.02346779 0.06319299 0.05475896 0.08831279
  0.06266366 0.07917871 0.06364154 0.06117544 0.05616607 0.06299606
  0.03783755 0.0439335 ]
 [0.04439706 0.08067784 0.05128615 0.06752507 0.04818965 0.04698285
  0.04077538 0.03162485 0.03296803 0.04496329 0.03896009 0.02316887
  0.02647817 0.03569165 0.04491521 0.0334588  0.01904785 0.01976495
  0.02487104 0.0265044  0.02397333 0.06045754 0.06944961 0.01437017
  0.00668832 0.01459575]
 [0.04173079 0.0497181  0.0474362  0.02978057 0.01972663 0.03318353
  0.03675279 0.03355852 0.03952587 0.03056973 0.03584156 0.03380897
  0.03381194 0.01459787 0.01405932 0.04989708 0.03913613 0.04663179
  0.04818366 0.05278008 0.0473894  0.04467183 0.0674663  0.1025668
  0.08898363 0.07622438]
 [0.04216332 0.05658447 0.0631939  0.08296633 0.0729005  0.0622328
  0.04402361 0.04140163 0.04969188 0.05883345 0.04748308 0.03571587
  0.03636289 0.11988817 0.11949385 0.05233207 0.03674332 0.0308218
  0.03203282 0.03584281 0.03334064 0.05419618 0.08225538 0.024244
  0.01010896 0.03270438]
 [0.04304948 0.03683048 0.03907144 0.06471645 0.05472128 0.05692847
  0.03312504 0.03249055 0.04242713 0.05589595 0.04245933 0.04093272
  0.03962071 0.13179389 0.15268892 0.05188757 0.04113922 0.03692901
  0.03604205 0.03818946 0.03195342 0.04606058 0.04916676 0.0173083
  0.00824786 0.02121395]
 [0.04368006 0.04159401 0.04988277 0.06733642 0.05998161 0.07119582
  0.04321858 0.04407156 0.05506312 0.06461554 0.04887185 0.06364114
  0.05930671 0.10437591 0.09376889 0.04320601 0.03686344 0.03606185
  0.03424819 0.03730033 0.02975153 0.04174355 0.04601382 0.02294918
  0.01172516 0.02221732]
 [0.04225332 0.05546043 0.06686036 0.0518458  0.0522544  0.06329216
  0.04701372 0.05470271 0.05849037 0.05633591 0.0482147  0.06538066
  0.05716319 0.06186562 0.05347078 0.05532983 0.04580213 0.04350574
  0.04041582 0.04477536 0.03912674 0.04716792 0.06835616 0.0532224
  0.03362058 0.05074312]
 [0.04339894 0.0521188  0.06460634 0.03597611 0.02829483 0.04343614
  0.05628945 0.05120268 0.05946237 0.03862937 0.03841054 0.0449659
  0.0429178  0.02174958 0.01846688 0.0598839  0.04295046 0.03953048
  0.04303978 0.04767748 0.04140951 0.03998745 0.06422759 0.06387722
  0.05413326 0.05794206]
 [0.04415185 0.02230836 0.02876867 0.01868536 0.01534231 0.02588001
  0.02580822 0.02929959 0.03962896 0.02354741 0.02140595 0.02654735
  0.02600528 0.01117821 0.00976354 0.03277508 0.0283443  0.02750098
  0.03205637 0.0342374  0.03238887 0.02693074 0.04196382 0.0688497
  0.07477225 0.08747661]
 [0.04346006 0.03785454 0.04549141 0.02840535 0.0217576  0.03848912
  0.03551586 0.04086926 0.04062199 0.03320001 0.03447431 0.04246673
  0.03606509 0.01507162 0.01378652 0.05060293 0.04166375 0.03938731
  0.04369216 0.04266261 0.04093411 0.04283985 0.04156459 0.05576465
  0.07678971 0.06161573]
 [0.0445453  0.048553   0.0562597  0.04515659 0.03093831 0.05871755
  0.0495502  0.06004903 0.05464024 0.05695983 0.05274021 0.08159228
  0.06279197 0.02407555 0.0172224  0.04051844 0.04126884 0.0424983
  0.04115327 0.04220428 0.03769759 0.04407374 0.03291626 0.02959565
  0.03128112 0.03002065]
 [0.0450361  0.0352244  0.03943842 0.0286945  0.02268688 0.03547713
  0.03915638 0.03988543 0.0382488  0.03377652 0.04003932 0.04421841
  0.03913474 0.01469924 0.01307439 0.04294656 0.04170394 0.03649021
  0.03921738 0.03914823 0.03831206 0.04207657 0.02760284 0.042406
  0.04875832 0.02894522]
 [0.04426109 0.02645619 0.02550998 0.01788668 0.01505217 0.02096822
  0.02624268 0.02802288 0.02803229 0.02126986 0.03084761 0.02799551
  0.02901766 0.00878879 0.00933221 0.04152875 0.04713896 0.03840306
  0.04320838 0.03962891 0.0473608  0.03823663 0.02252992 0.06514405
  0.08721014 0.04896974]
 [0.04400144 0.02674246 0.02390159 0.01789197 0.01442424 0.02034292
  0.03111119 0.0342705  0.02834787 0.02095316 0.0324317  0.02672078
  0.032858   0.0081654  0.00834303 0.04434109 0.05082279 0.05104062
  0.05034814 0.04658887 0.06907354 0.03586275 0.02111659 0.06633653
  0.10687447 0.04920634]
 [0.04472378 0.024507   0.02267378 0.01709152 0.01493163 0.02026743
  0.02548749 0.02980768 0.02659323 0.02150311 0.03515131 0.03108435
  0.03078157 0.00814678 0.0082245  0.03780721 0.0529434  0.04053908
  0.05563707 0.04268496 0.0534265  0.03430449 0.01715558 0.03548376
  0.09013044 0.04469221]
 [0.04444648 0.0221326  0.02032916 0.01420356 0.01291468 0.01730828
  0.02501086 0.02700345 0.02484279 0.01799101 0.04078916 0.02635136
  0.02874768 0.00674554 0.00729108 0.04186833 0.05272909 0.04330634
  0.05985895 0.04800338 0.06133509 0.03368503 0.01782897 0.04759283
  0.06560019 0.07326426]
 [0.04372367 0.02783073 0.02632551 0.0170686  0.01435135 0.02279882
  0.02970559 0.03148893 0.0321454  0.0201472  0.03044538 0.02654301
  0.03133463 0.00832745 0.00829677 0.04241889 0.03761222 0.04184561
  0.04800442 0.0488564  0.0536282  0.03705893 0.03030765 0.09138522
  0.07290094 0.07629321]
 [0.04525232 0.02495325 0.02523814 0.02108671 0.01544603 0.02378017
  0.02502747 0.02907952 0.02917681 0.02418839 0.02872059 0.03020677
  0.02911257 0.01087755 0.00979529 0.02561394 0.02758299 0.02883128
  0.03893182 0.03558484 0.03970026 0.03506225 0.02061555 0.02860891
  0.03033369 0.04589293]
 [0.0439942  0.03682522 0.0367404  0.05476021 0.05317247 0.0539429
  0.03297298 0.0348773  0.04154771 0.05883535 0.04442414 0.04745812
  0.04362467 0.08864436 0.09828247 0.03542144 0.03665518 0.03683395
  0.03524309 0.03629855 0.03306498 0.04260023 0.04083348 0.0177233
  0.01054831 0.02326264]
 [0.04368942 0.03882914 0.03565417 0.05871661 0.10813343 0.0480032
  0.0304365  0.03206336 0.03926498 0.06469518 0.05001398 0.04440485
  0.03535986 0.0849199  0.10830905 0.04268558 0.05183773 0.05408959
  0.04312029 0.04119821 0.04020426 0.03932381 0.03883734 0.01443615
  0.00744317 0.02023477]
 [0.04319543 0.03462554 0.03193562 0.04937569 0.10035153 0.03452094
  0.02555138 0.03077533 0.03487626 0.05610266 0.04909034 0.04583046
  0.0332147  0.03728804 0.04915574 0.03635468 0.08008351 0.07793703
  0.05982781 0.0484084  0.05843046 0.03562145 0.03587439 0.02511117
  0.0162858  0.03323619]
 [0.04366586 0.04448833 0.03810867 0.05290366 0.07708438 0.04178294
  0.0343147  0.03500028 0.04210734 0.05539721 0.04898606 0.04263063
  0.03618454 0.03808659 0.04339119 0.03197689 0.05210475 0.05348965
  0.04639283 0.04494733 0.04624235 0.06258387 0.05144588 0.0205836
  0.01216915 0.02464995]]

-* TASK 10/20 | SAMPLE 49/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 242/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 4 explicitly states that Mary journeyed to the office, implying that she is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' explicitly', ' states', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' office', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03220696 0.05190782 0.05142857 0.0705935  0.05962449 0.0519978
  0.04022171 0.04239381 0.05145426 0.05655939 0.03787075 0.03379089
  0.03864905 0.09995251 0.10087388 0.02495985 0.02769691 0.02554541
  0.02508386 0.02863427 0.02608811 0.03635333 0.06649353 0.02245864
  0.01242958 0.03643583 0.05813915 0.04024807 0.11081631 0.03350046
  0.06680235 0.08700824]
 [0.03306468 0.05412187 0.05143936 0.08775956 0.08992324 0.08735119
  0.04779977 0.04922398 0.05950725 0.08019411 0.05622249 0.05831325
  0.0606228  0.17195414 0.1332202  0.02914229 0.02925444 0.03070669
  0.02764159 0.03039711 0.02732111 0.04076554 0.05061698 0.01937724
  0.01168945 0.03184849 0.05595769 0.03559452 0.08762489 0.04537347
  0.07956646 0.06720833]
 [0.03363836 0.0473735  0.05178735 0.06994502 0.06323013 0.06335899
  0.04216253 0.04608255 0.05406509 0.06132859 0.0419989  0.04877973
  0.04819178 0.11223873 0.08087861 0.0245288  0.02750299 0.02524957
  0.02436717 0.02605677 0.02312281 0.03583193 0.04713247 0.02097007
  0.01325499 0.0290503  0.04690134 0.03077267 0.05952991 0.06369661
  0.06239049 0.05597029]
 [0.03243516 0.04462997 0.04498595 0.03667823 0.03234483 0.03750474
  0.03672259 0.04185095 0.03944631 0.03257871 0.03328519 0.03680711
  0.03617225 0.02958587 0.02990333 0.03125576 0.0324702  0.0264497
  0.02771713 0.02929386 0.02702505 0.03720456 0.05335793 0.0417928
  0.03381865 0.04059072 0.04541398 0.03433207 0.04386175 0.09426634
  0.03831059 0.03714822]
 [0.03357422 0.04257612 0.04500751 0.0300522  0.02354259 0.03095172
  0.041023   0.0380799  0.04254506 0.02587536 0.02928421 0.02767796
  0.02808542 0.02069794 0.02193783 0.02848881 0.03075293 0.02375219
  0.02769996 0.02837908 0.02615043 0.03154378 0.0466026  0.03298225
  0.03030223 0.03249717 0.04465378 0.02276685 0.03027479 0.08175183
  0.02424029 0.0400396 ]
 [0.03416764 0.02279135 0.0247773  0.01842365 0.01415577 0.01843035
  0.02069471 0.02007004 0.02355144 0.01691511 0.02106778 0.0182946
  0.01840748 0.0116645  0.01408161 0.02174273 0.02307527 0.01930263
  0.02390112 0.02478568 0.02273462 0.02455737 0.02547312 0.03116218
  0.03889429 0.03266039 0.02409519 0.02255241 0.02291051 0.03983108
  0.01598097 0.02750325]
 [0.03341603 0.04037894 0.04073912 0.02887337 0.02149652 0.03160641
  0.03674876 0.03650473 0.03448737 0.02707346 0.03085575 0.03455059
  0.03086594 0.01952329 0.01909834 0.04132261 0.03672017 0.03264853
  0.03379475 0.03601835 0.03113866 0.0379566  0.03952128 0.04836284
  0.04531438 0.03670929 0.04319947 0.02703992 0.030221   0.08138454
  0.01944569 0.02663887]
 [0.03453599 0.04522016 0.04648728 0.04353586 0.03159349 0.04486774
  0.04410335 0.0519516  0.0448744  0.04419058 0.04055262 0.05613035
  0.05011208 0.03145367 0.02452412 0.02790295 0.02974731 0.02942771
  0.02990236 0.03214326 0.02756364 0.0372584  0.03341031 0.03006555
  0.02703428 0.02910542 0.04534788 0.02978996 0.03296087 0.08235055
  0.03258769 0.03094203]
 [0.0348316  0.03399142 0.03533433 0.03078637 0.02383489 0.03064113
  0.03304631 0.03395509 0.03169122 0.02881722 0.03152765 0.03311953
  0.03166345 0.02047571 0.01917955 0.03021482 0.02924636 0.02595081
  0.02929125 0.02990045 0.02751486 0.0340882  0.03004136 0.0348871
  0.03489884 0.02631041 0.03366386 0.02673712 0.02775847 0.06243334
  0.02886295 0.02926475]
 [0.03421529 0.02630212 0.02370097 0.02002399 0.01627835 0.02053298
  0.0242804  0.02412364 0.02394318 0.01970372 0.02733307 0.02272422
  0.0243036  0.01179678 0.01367494 0.03855745 0.03209791 0.02784032
  0.02925091 0.02934392 0.02878173 0.03312191 0.02318028 0.04225564
  0.04248756 0.02462089 0.02088911 0.02519606 0.02208688 0.03732717
  0.01729262 0.02477912]
 [0.03361425 0.02788551 0.02334681 0.02030886 0.0157938  0.02030612
  0.0247354  0.02378325 0.02407219 0.01999861 0.02570079 0.02123917
  0.02423109 0.01166715 0.01394784 0.04763854 0.03965376 0.03780283
  0.04048007 0.03959997 0.04095795 0.03255707 0.02366436 0.05780997
  0.05388538 0.03455235 0.01986448 0.03476546 0.02116223 0.0253116
  0.01489289 0.02411359]
 [0.03498611 0.03049245 0.0294984  0.02582553 0.02027241 0.02796907
  0.03132091 0.02934083 0.02846111 0.02495588 0.03222421 0.02886463
  0.02688033 0.01514216 0.01624451 0.05031384 0.02982252 0.03950953
  0.03196314 0.0458965  0.03549007 0.02961095 0.02614473 0.06196854
  0.05119437 0.03497208 0.02331846 0.02604145 0.0240318  0.02111131
  0.01507211 0.02828575]
 [0.03500583 0.02545394 0.02419525 0.02009579 0.01556036 0.02201746
  0.02561119 0.02411697 0.02445221 0.02036082 0.02923296 0.0248551
  0.02493651 0.01214203 0.01366658 0.05324982 0.03411226 0.04601957
  0.0356856  0.04789392 0.03923243 0.02859438 0.02167352 0.06068775
  0.05816193 0.03762188 0.02348372 0.03022053 0.02050416 0.01946859
  0.01338592 0.02082335]
 [0.03493765 0.02336299 0.02277399 0.01805309 0.01423816 0.02007165
  0.02395827 0.02170972 0.02320661 0.01860082 0.0297625  0.02181435
  0.02310831 0.01096209 0.01253914 0.04465273 0.03422538 0.03609892
  0.03592334 0.0407886  0.03597717 0.03039796 0.02148382 0.05194461
  0.04307503 0.03958697 0.02328541 0.02717444 0.01828729 0.01621125
  0.01489502 0.01977417]
 [0.03406411 0.03921879 0.03652    0.03171045 0.02793292 0.03612227
  0.04166524 0.03964172 0.03888098 0.03495867 0.03835095 0.040425
  0.04047725 0.01988441 0.02016247 0.04273856 0.04114914 0.03907344
  0.04245158 0.03991602 0.03906238 0.03718489 0.03944824 0.03874754
  0.04050194 0.05385033 0.03483722 0.04397688 0.03569117 0.02217375
  0.02799844 0.03200174]
 [0.03523235 0.02848582 0.02955846 0.02548971 0.01964858 0.02713624
  0.02846001 0.02970793 0.02809517 0.02664855 0.03139858 0.0310387
  0.0284832  0.01661841 0.01687511 0.02900128 0.03052048 0.02802593
  0.03319566 0.03126675 0.03152889 0.03571989 0.02688176 0.02469221
  0.03125609 0.03744275 0.02564865 0.03045186 0.02607893 0.02350453
  0.03068614 0.02221056]
 [0.03546216 0.03461196 0.03872503 0.03514042 0.02757981 0.03868471
  0.0374353  0.04432272 0.03729759 0.03922634 0.03710586 0.04827227
  0.04355562 0.02592434 0.02052077 0.02780064 0.03014384 0.03080228
  0.03006801 0.03059636 0.02828583 0.03863567 0.03094629 0.02504733
  0.02824713 0.03352211 0.03184598 0.03312309 0.03190533 0.03096678
  0.02563699 0.02354982]
 [0.03564107 0.03694067 0.03853563 0.0359487  0.02792311 0.04019963
  0.04125453 0.04538173 0.03598162 0.04056143 0.04065891 0.04926459
  0.04868361 0.02579074 0.0221737  0.03756322 0.03569652 0.0394593
  0.0367559  0.03574941 0.03485459 0.03805525 0.03113818 0.02931014
  0.03778567 0.02996396 0.03229218 0.03478459 0.02996877 0.02939115
  0.0204232  0.0227872 ]
 [0.03546416 0.02760897 0.02757362 0.02041076 0.01751619 0.02551778
  0.03088805 0.03136763 0.02675105 0.0247562  0.02997698 0.03072167
  0.03394039 0.01386168 0.01544791 0.04277548 0.03812046 0.03781749
  0.03790945 0.03419564 0.03879274 0.03554308 0.02473392 0.03857519
  0.05200715 0.03219933 0.02897042 0.04060885 0.02350642 0.02533341
  0.01460249 0.01849457]
 [0.03575699 0.02861734 0.02693768 0.01992672 0.01692375 0.02371509
  0.03162491 0.02949657 0.02552656 0.02300316 0.02897104 0.02795868
  0.03227874 0.01296879 0.01486866 0.04715899 0.04041885 0.04285735
  0.0409178  0.03924956 0.04400928 0.03143338 0.02375594 0.04002416
  0.05270832 0.0318273  0.03103619 0.03660313 0.02043005 0.01750136
  0.01146645 0.01795068]
 [0.03589427 0.02721776 0.02632329 0.01938247 0.01811844 0.02414597
  0.02961765 0.0284954  0.0251747  0.02380654 0.02983273 0.0288077
  0.03061317 0.01371749 0.01493256 0.03845336 0.03739701 0.03453526
  0.03797297 0.03299228 0.0392453  0.03245131 0.02338525 0.03286966
  0.05946426 0.03457461 0.03121798 0.04292888 0.02061235 0.01794663
  0.01522582 0.01797466]
 [0.03597835 0.03194431 0.03001886 0.02122599 0.0194014  0.02699616
  0.03639241 0.03338777 0.03124084 0.02587536 0.0368743  0.03150591
  0.03540609 0.01480219 0.0159734  0.0468694  0.04214234 0.04081782
  0.04309102 0.04005638 0.04442118 0.03305196 0.02548185 0.03786217
  0.05275781 0.03459475 0.02968104 0.03422063 0.02029497 0.01593411
  0.01208977 0.01890863]
 [0.03596716 0.02368338 0.02357624 0.01434057 0.01525629 0.02000009
  0.02968208 0.02412809 0.02342711 0.01821538 0.03799412 0.02273992
  0.0273996  0.01075176 0.01180882 0.04354151 0.03960901 0.03229687
  0.04212114 0.03497007 0.04217266 0.03046218 0.02253484 0.04236544
  0.04371936 0.04511764 0.02017848 0.03414296 0.01783901 0.01432577
  0.01304966 0.01853317]
 [0.03421881 0.03128836 0.03516496 0.02115419 0.02201637 0.03328578
  0.04759642 0.0428143  0.04115637 0.02769806 0.03107782 0.03254534
  0.04044982 0.01712901 0.01673478 0.02897904 0.03747284 0.03143724
  0.04501533 0.03744354 0.03826364 0.03659271 0.03438501 0.0321219
  0.02359367 0.03882595 0.02989588 0.03071414 0.0233307  0.01690767
  0.01562132 0.03068237]
 [0.03570695 0.02623973 0.02818494 0.02290971 0.02098843 0.02850652
  0.03272015 0.032925   0.02924929 0.0267275  0.02870722 0.03134494
  0.03172028 0.01764358 0.01654907 0.02143489 0.02815062 0.02582033
  0.0324704  0.02972083 0.03114137 0.03376902 0.02375703 0.02048499
  0.0202257  0.03500918 0.02221121 0.03467765 0.02562109 0.02032308
  0.03617999 0.02447267]
 [0.03403278 0.03586822 0.03709435 0.05106975 0.0523112  0.04505654
  0.03661991 0.03507195 0.04065672 0.04905498 0.03625176 0.03826369
  0.03888614 0.07066163 0.09206101 0.02178143 0.02730597 0.0313242
  0.02916165 0.03029699 0.02957235 0.03636672 0.04357709 0.01924173
  0.01428359 0.03303455 0.04174517 0.04150602 0.05275197 0.02074528
  0.09093328 0.05420411]
 [0.0337637  0.04376155 0.04220195 0.07610322 0.16579665 0.05807121
  0.03983314 0.03844921 0.04311508 0.07800687 0.05559615 0.05617255
  0.03992664 0.09864029 0.12740326 0.03073306 0.04964224 0.05708034
  0.04097445 0.03693118 0.04335281 0.03492386 0.052924   0.01938419
  0.01211584 0.03158139 0.05870104 0.04535246 0.05020994 0.01640663
  0.09656504 0.0635169 ]
 [0.03410633 0.03287344 0.03095662 0.04172708 0.06153913 0.02975044
  0.02826472 0.02870676 0.0284963  0.04161094 0.0357412  0.03353569
  0.02947862 0.02934512 0.04308024 0.0264839  0.05005929 0.06045258
  0.04790523 0.04013    0.05894348 0.03156482 0.04144125 0.02477213
  0.02158279 0.03436475 0.04161296 0.05282134 0.03275705 0.01472408
  0.07051554 0.03701956]
 [0.0340811  0.03515156 0.03312623 0.04250525 0.04515877 0.03520418
  0.03551662 0.0329161  0.03919297 0.04269759 0.03454356 0.03044193
  0.03247076 0.033004   0.03763773 0.02071425 0.03579286 0.04189515
  0.03728718 0.03735324 0.03725488 0.04440331 0.04681302 0.01777608
  0.01330974 0.02752932 0.03191208 0.0508559  0.03697145 0.00979761
  0.07527976 0.07819372]]

-* TASK 10/20 | SAMPLE 49/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 243/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 explicitly states that Mary is in the bedroom, and there is no information suggesting she has left the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' suggesting', ' she', ' has', ' left', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.02985072 0.03827863 0.03792391 ... 0.01996769 0.04462583 0.03192014]
 [0.03050891 0.06291334 0.05424444 ... 0.04136209 0.05475308 0.03670362]
 [0.03116057 0.03940887 0.04448776 ... 0.01672454 0.03665671 0.02460351]
 ...
 [0.031365   0.04011309 0.03959341 ... 0.01779501 0.03863429 0.03086849]
 [0.0317801  0.03145087 0.02899572 ... 0.02735516 0.03229427 0.04090818]
 [0.03177315 0.03329112 0.03077941 ... 0.02250895 0.03464554 0.03917449]]

-* TASK 10/20 | SAMPLE 49/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 244/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 explicitly states that Bill travelled to the cinema, implying that he is currently in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' implying', ' that', ' he', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 44), x_tokens=44, y_tokens=28, max_supp_attn=0.1786, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 44)
DEBUG result.interpretability.attn_scores 1232 
 [[0.03332895 0.05062455 0.05287177 ... 0.00891023 0.02799915 0.04864928]
 [0.03414994 0.04411785 0.04586493 ... 0.01601831 0.02190206 0.03303058]
 [0.03481004 0.05377997 0.05954526 ... 0.01184251 0.02923199 0.04743354]
 ...
 [0.03490718 0.04978794 0.04672949 ... 0.00643141 0.04671108 0.0765833 ]
 [0.03537579 0.03816729 0.03330079 ... 0.00918661 0.02780423 0.07023809]
 [0.0351949  0.04171442 0.03576114 ... 0.00666713 0.0167108  0.10628416]]

-* TASK 10/20 | SAMPLE 49/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 245/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's current location in the provided sentences. The previous information about Bill's location (sentence 11) is not relevant in this context.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' current', ' location', ' in', ' the', ' provided', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' (', 'sentence', ' ', '11', ')', ' is', ' not', ' relevant', ' in', ' this', ' context', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0732, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02238652 0.02404122 0.02190388 ... 0.0266621  0.0214839  0.06624339]
 [0.02293173 0.02164068 0.02462305 ... 0.02134353 0.0181715  0.03242554]
 [0.02352458 0.02256633 0.02332755 ... 0.02308709 0.01755992 0.03771441]
 ...
 [0.02411588 0.02199425 0.01996322 ... 0.02515031 0.03033893 0.02308372]
 [0.02439411 0.02329434 0.02426003 ... 0.02787686 0.02687456 0.02743802]
 [0.02457954 0.0185439  0.02000967 ... 0.02337613 0.0241481  0.03269256]]
Model's predictions for the sample 49:

+----------+-----------------+-------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef               |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |  Sentence 2 explicitly states that Julie  |
|          |                 |             is in the office.             |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |   Sentence 4 explicitly states that Mary  |
|          |                 |   journeyed to the office, implying that  |
|          |                 |      she is currently in the office.      |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |   Sentence 7 explicitly states that Mary  |
|          |                 |     is in the bedroom, and there is no    |
|          |                 |  information suggesting she has left the  |
|          |                 |                  bedroom.                 |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |  Sentence 11 explicitly states that Bill  |
|          |                 |   travelled to the cinema, implying that  |
|          |                 |       he is currently in the cinema.      |
+----------+-----------------+-------------------------------------------+
|   yes    |  not mentioned  |    There is no information about Bill's   |
|          |                 |      current location in the provided     |
|          |                 |    sentences. The previous information    |
|          |                 |   about Bill's location (sentence 11) is  |
|          |                 |       not relevant in this context.       |
+----------+-----------------+-------------------------------------------+

Metrics for sample 49:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 50/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 246/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences do not mention Julie being in the office. Sentence 1 only mentions Julie being in either the school or the bedroom, and sentence 2 talks about Bill's journey to the cinema, which does not provide any information about Julie's location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' office', '.', ' Sentence', ' ', '1', ' only', ' mentions', ' Julie', ' being', ' in', ' either', ' the', ' school', ' or', ' the', ' bedroom', ',', ' and', ' sentence', ' ', '2', ' talks', ' about', ' Bill', "'s", ' journey', ' to', ' the', ' cinema', ',', ' which', ' does', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(60, 26), x_tokens=26, y_tokens=60, max_supp_attn=0.0667, attn_on_target=0.0167)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (60, 26)
DEBUG result.interpretability.attn_scores 1560 
 [[0.01588287 0.03390913 0.02493092 ... 0.00259857 0.00492774 0.01433872]
 [0.01629609 0.03172749 0.02625329 ... 0.00231625 0.00441001 0.01497348]
 [0.01533924 0.02979909 0.03346279 ... 0.00387836 0.00710494 0.02316551]
 ...
 [0.01626559 0.01715231 0.01801723 ... 0.0029056  0.00409112 0.01227819]
 [0.0161152  0.01465745 0.01488848 ... 0.00841935 0.00736444 0.01248424]
 [0.01630974 0.01646491 0.01643959 ... 0.0055702  0.00570007 0.01148301]]

-* TASK 10/20 | SAMPLE 50/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 247/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences 4 and 5 do not provide any information about Julie's location. However, we can refer back to the previous context sentence 1, which mentions Julie being either in the school or the bedroom. Since sentence 5 mentions Fred journeying to the school, it does not provide any new information about Julie's location. Therefore, we can still consider the possibility of Julie being in the bedroom.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' back', ' to', ' the', ' previous', ' context', ' sentence', ' ', '1', ',', ' which', ' mentions', ' Julie', ' being', ' either', ' in', ' the', ' school', ' or', ' the', ' bedroom', '.', ' Since', ' sentence', ' ', '5', ' mentions', ' Fred', ' journey', 'ing', ' to', ' the', ' school', ',', ' it', ' does', ' not', ' provide', ' any', ' new', ' information', ' about', ' Julie', "'s", ' location', '.', ' Therefore', ',', ' we', ' can', ' still', ' consider', ' the', ' possibility', ' of', ' Julie', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(92, 32), x_tokens=32, y_tokens=92, max_supp_attn=0.0543, attn_on_target=0.0109)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (92, 32)
DEBUG result.interpretability.attn_scores 2944 
 [[0.00976587 0.01727204 0.01297319 ... 0.00685739 0.00551223 0.00281241]
 [0.01030196 0.01633719 0.01302719 ... 0.00362962 0.00225952 0.00183891]
 [0.00991383 0.01468079 0.01585137 ... 0.01051556 0.00605126 0.00267553]
 ...
 [0.01052419 0.01305269 0.01165025 ... 0.00497273 0.00306868 0.00210071]
 [0.01073233 0.01072437 0.00912435 ... 0.00553408 0.00456826 0.00477819]
 [0.01074176 0.01081433 0.00920535 ... 0.00467302 0.00403929 0.00279606]]

-* TASK 10/20 | SAMPLE 50/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 248/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 8 explicitly states that Bill journeyed to the bedroom, which implies that Bill is now in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' now', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02903008 0.03054922 0.03290498 ... 0.02006167 0.02088188 0.08773571]
 [0.03024703 0.05115747 0.04686394 ... 0.01209365 0.0477901  0.14435075]
 [0.02920161 0.03964037 0.04748134 ... 0.01855597 0.06350006 0.07128622]
 ...
 [0.03075053 0.04446263 0.0396912  ... 0.0163609  0.10667272 0.05805355]
 [0.03075252 0.03968813 0.03245689 ... 0.01749384 0.07645616 0.03403086]
 [0.03093515 0.04241218 0.03413293 ... 0.01669089 0.09191935 0.07690735]]

-* TASK 10/20 | SAMPLE 50/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 249/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 10 only mentions Mary being in either the park or the park (which is essentially the same location), and sentence 11 talks about Fred's location in the cinema. Neither of these sentences provides any information about Mary being in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' only', ' mentions', ' Mary', ' being', ' in', ' either', ' the', ' park', ' or', ' the', ' park', ' (', 'which', ' is', ' essentially', ' the', ' same', ' location', '),', ' and', ' sentence', ' ', '11', ' talks', ' about', ' Fred', "'s", ' location', ' in', ' the', ' cinema', '.', ' Neither', ' of', ' these', ' sentences', ' provides', ' any', ' information', ' about', ' Mary', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 44), x_tokens=44, y_tokens=58, max_supp_attn=0.0345, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 44)
DEBUG result.interpretability.attn_scores 2552 
 [[0.01597741 0.02536102 0.02233341 ... 0.01494657 0.01122888 0.04263834]
 [0.01650988 0.0395184  0.03169882 ... 0.02203427 0.00964251 0.10325583]
 [0.01590011 0.02863251 0.02907274 ... 0.02765469 0.01886175 0.07320461]
 ...
 [0.01669511 0.02395786 0.02403896 ... 0.02615406 0.01963559 0.03705   ]
 [0.01699283 0.01832618 0.01750793 ... 0.02004038 0.02955364 0.02358556]
 [0.01692569 0.02062918 0.01981932 ... 0.01946514 0.02493991 0.02927659]]

-* TASK 10/20 | SAMPLE 50/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 250/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: Sentence 14 explicitly states that Bill is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 50), x_tokens=50, y_tokens=21, max_supp_attn=0.0, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 50)
DEBUG result.interpretability.attn_scores 1050 
 [[0.0454216  0.04268684 0.04218804 ... 0.05615715 0.06458174 0.0362522 ]
 [0.0463823  0.0736734  0.06597305 ... 0.06189647 0.05737774 0.03258309]
 [0.04545813 0.06203611 0.0685964  ... 0.06744236 0.04523761 0.03305589]
 ...
 [0.04787709 0.06756178 0.06234656 ... 0.02886103 0.02573859 0.01646283]
 [0.04787725 0.05831558 0.04953341 ... 0.02552228 0.02673225 0.01910424]
 [0.04774002 0.06261577 0.05443362 ... 0.02736575 0.02771129 0.0159051 ]]
Model's predictions for the sample 50:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |   Julie being in the office. Sentence 1    |
|          |                 |  only mentions Julie being in either the   |
|          |                 |   school or the bedroom, and sentence 2    |
|          |                 |     talks about Bill's journey to the      |
|          |                 |     cinema, which does not provide any     |
|          |                 |    information about Julie's location.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentences 4 and 5 do not    |
|          |                 |   provide any information about Julie's    |
|          |                 |  location. However, we can refer back to   |
|          |                 |   the previous context sentence 1, which   |
|          |                 |     mentions Julie being either in the     |
|          |                 |  school or the bedroom. Since sentence 5   |
|          |                 |  mentions Fred journeying to the school,   |
|          |                 |  it does not provide any new information   |
|          |                 |   about Julie's location. Therefore, we    |
|          |                 |   can still consider the possibility of    |
|          |                 |        Julie being in the bedroom.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Bill   |
|          |                 |  journeyed to the bedroom, which implies   |
|          |                 |      that Bill is now in the bedroom.      |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  Sentence 10 only mentions Mary being in   |
|          |                 |   either the park or the park (which is    |
|          |                 |    essentially the same location), and     |
|          |                 |  sentence 11 talks about Fred's location   |
|          |                 |      in the cinema. Neither of these       |
|          |                 |  sentences provides any information about  |
|          |                 |         Mary being in the office.          |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 14 explicitly states that Bill   |
|          |                 |             is in the school.              |
+----------+-----------------+--------------------------------------------+

Metrics for sample 50:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.06 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 51/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 251/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Fred being in the kitchen or the school, and Julie being in the school or the office. There is no mention of Fred being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' kitchen', ' or', ' the', ' school', ',', ' and', ' Julie', ' being', ' in', ' the', ' school', ' or', ' the', ' office', '.', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02217722 0.04624623 0.04871532 ... 0.00498365 0.00359362 0.02411126]
 [0.02292463 0.02931483 0.02826516 ... 0.00446212 0.00326834 0.01575041]
 [0.02331575 0.03279006 0.03533145 ... 0.00638757 0.00417198 0.01487274]
 ...
 [0.02334325 0.02991825 0.0286321  ... 0.00418897 0.0029527  0.01529821]
 [0.02310992 0.02258637 0.02307338 ... 0.00999641 0.00667874 0.01637816]
 [0.02334842 0.02835905 0.02711673 ... 0.00736323 0.005161   0.01543278]]

-* TASK 10/20 | SAMPLE 51/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 252/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Julie is in the park, not in the kitchen. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' is', ' in', ' the', ' park', ',', ' not', ' in', ' the', ' kitchen', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 32), x_tokens=32, y_tokens=26, max_supp_attn=0.0385, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 32)
DEBUG result.interpretability.attn_scores 832 
 [[0.03609671 0.04952745 0.05389304 0.07308794 0.07099909 0.06391761
  0.04413272 0.04466261 0.05156532 0.06257969 0.03782639 0.0468483
  0.04699199 0.10793376 0.11003699 0.03707468 0.02983457 0.02888829
  0.02767905 0.03058804 0.02961584 0.03999879 0.05818065 0.01755086
  0.01312596 0.04860956 0.05209713 0.05078789 0.11976091 0.01542538
  0.0167835  0.01974019]
 [0.03692285 0.05139014 0.05215592 0.08728961 0.09582861 0.10197007
  0.05782833 0.06099534 0.06359019 0.09425727 0.06014967 0.0890595
  0.09425458 0.136888   0.10191251 0.03693302 0.03000861 0.0389217
  0.03282801 0.03680103 0.0341543  0.04536198 0.0455406  0.02400559
  0.01663378 0.04584891 0.05247071 0.04522335 0.10470305 0.02544159
  0.02685844 0.03000998]
 [0.0377643  0.04497804 0.05268232 0.07138436 0.07272586 0.07071997
  0.04593595 0.04536386 0.05059508 0.06611655 0.04244216 0.05773214
  0.05253178 0.11833883 0.08969722 0.0353415  0.02774941 0.02757585
  0.02604604 0.02795956 0.0269134  0.03973816 0.04188214 0.01878534
  0.0137807  0.0391933  0.04747835 0.03652729 0.09087968 0.02840603
  0.02610795 0.02396687]
 [0.03639917 0.05347562 0.05951201 0.0431038  0.04034647 0.0478048
  0.05049044 0.05137329 0.04538564 0.04217878 0.03764755 0.04993374
  0.04710252 0.03260229 0.03179927 0.04519057 0.03709356 0.03302809
  0.03112133 0.03398043 0.03346005 0.04222128 0.05793024 0.03568911
  0.03081684 0.05191284 0.05488198 0.04435258 0.07413653 0.08263969
  0.05383115 0.03281523]
 [0.03822704 0.05328395 0.06376684 0.05229447 0.0437521  0.06467067
  0.06147407 0.06332269 0.08782497 0.06227149 0.04027192 0.05710641
  0.05826786 0.04572493 0.03537233 0.04316546 0.03363712 0.0318533
  0.03368229 0.03802599 0.03329898 0.04333482 0.05174206 0.03146838
  0.0217437  0.05138708 0.06469689 0.03654352 0.05879721 0.06413897
  0.04383671 0.03573334]
 [0.03744738 0.07213525 0.0734     0.03729217 0.0295407  0.04300798
  0.05723738 0.0520246  0.05210145 0.03543813 0.0351779  0.04109774
  0.04347793 0.0260742  0.0276799  0.06280855 0.04475449 0.03542428
  0.03621993 0.03924079 0.03797946 0.0441671  0.08701013 0.04730063
  0.03706433 0.05348707 0.06659874 0.03873549 0.05243678 0.08554351
  0.04337273 0.04030799]
 [0.03831853 0.09610606 0.08613893 0.03918248 0.0289538  0.04243696
  0.05918165 0.05112579 0.05852784 0.03456075 0.0344344  0.03533874
  0.0391349  0.02405079 0.02765371 0.0735873  0.04934644 0.03642792
  0.03802547 0.04324001 0.03851821 0.04038114 0.10591993 0.03948256
  0.0283332  0.05030795 0.07729665 0.03530961 0.03965168 0.0826003
  0.03024475 0.03278702]
 [0.03838284 0.05956662 0.05615507 0.03123241 0.02376351 0.03300514
  0.04757849 0.03985593 0.04300392 0.02783004 0.02981059 0.0284347
  0.03090811 0.01984519 0.02411696 0.05938808 0.045029   0.03323785
  0.03650718 0.03978321 0.03722887 0.03831818 0.07079984 0.03848209
  0.03010357 0.05089043 0.06272712 0.03416842 0.0305782  0.05952105
  0.03392363 0.038153  ]
 [0.03878488 0.02068449 0.02206828 0.01704865 0.01407166 0.01917948
  0.02112993 0.01976731 0.02209502 0.0167025  0.02041628 0.01693883
  0.01887569 0.01042106 0.01290265 0.02656663 0.02363819 0.02138217
  0.0251927  0.02684646 0.02675471 0.02584617 0.0264373  0.02734997
  0.0271682  0.03837476 0.02552216 0.02282454 0.01645175 0.02532707
  0.02622654 0.03271313]
 [0.03859942 0.03066141 0.03241283 0.0246048  0.0178945  0.0274615
  0.03157081 0.02857738 0.02863765 0.02330894 0.03050386 0.02475408
  0.02627161 0.01573067 0.01862823 0.04215894 0.03813713 0.03238207
  0.03386228 0.03686092 0.03727727 0.03662238 0.03325435 0.03750057
  0.03475444 0.03569075 0.03192393 0.0278521  0.02416112 0.03611742
  0.03577952 0.03913645]
 [0.03866881 0.03250444 0.03454702 0.028278   0.02107854 0.03042237
  0.03655558 0.03569405 0.03043818 0.02810345 0.03770783 0.03324667
  0.03613537 0.01793624 0.0179248  0.04148104 0.04114371 0.03738785
  0.03301733 0.03402903 0.03864357 0.04034247 0.02593648 0.046411
  0.04682696 0.03286571 0.02888436 0.03450298 0.02620438 0.04505273
  0.04848335 0.03846738]
 [0.03820096 0.02919846 0.02714731 0.02385276 0.014425   0.02393274
  0.03209749 0.03042711 0.02499389 0.02171822 0.0346253  0.02491841
  0.03034213 0.01377742 0.01454337 0.04308919 0.04430265 0.04787209
  0.03743233 0.04000696 0.05417114 0.03623889 0.02138735 0.0604858
  0.07765843 0.03142484 0.02643912 0.03427582 0.01887867 0.04560925
  0.05003281 0.05287249]
 [0.03900604 0.02852677 0.02811288 0.02478641 0.01654902 0.0253237
  0.03179219 0.03217262 0.02583841 0.02408689 0.04088682 0.0310008
  0.03209153 0.01498359 0.01477844 0.0404682  0.04327878 0.03900182
  0.03980023 0.03625069 0.04453643 0.03540058 0.02068639 0.0629396
  0.07018557 0.0270777  0.02959755 0.03462506 0.01866085 0.04484443
  0.04540694 0.04981735]
 [0.03904583 0.02297148 0.02266537 0.01989052 0.01403972 0.02080073
  0.03017107 0.02837765 0.02374847 0.01964781 0.04358354 0.02646377
  0.02879662 0.01225001 0.01267829 0.04175919 0.0485485  0.04058301
  0.04651879 0.04096298 0.04996672 0.03249617 0.01870777 0.06849808
  0.07844485 0.03075499 0.02246561 0.03744673 0.01491362 0.03941609
  0.05168614 0.05875976]
 [0.03815155 0.02836787 0.02541319 0.02166061 0.01532531 0.02412878
  0.03634133 0.0338834  0.03032431 0.02313744 0.05452916 0.03184669
  0.03211821 0.01373311 0.01428152 0.03969911 0.04450624 0.0419814
  0.05114828 0.04811503 0.04884321 0.03565004 0.02182841 0.06214283
  0.0818978  0.04017892 0.02367125 0.0416893  0.01832274 0.0342116
  0.0560506  0.06137422]
 [0.03954485 0.02437382 0.02403401 0.02375556 0.01510572 0.02436839
  0.02961404 0.03066592 0.02675647 0.02356494 0.037744   0.02941015
  0.02854508 0.01550175 0.01413929 0.03069196 0.03144885 0.03130415
  0.04223622 0.03960918 0.04036136 0.03564947 0.01795653 0.03974026
  0.04517365 0.02826872 0.02125998 0.02998767 0.01847165 0.02991287
  0.05330831 0.04879897]
 [0.03991694 0.02416576 0.02773387 0.02680207 0.01878284 0.0294935
  0.03289734 0.03893541 0.03222684 0.03110095 0.03186829 0.03867279
  0.03670707 0.01953134 0.01513789 0.0250359  0.02830961 0.02821022
  0.03030716 0.02985125 0.02864071 0.03972413 0.01817754 0.03240158
  0.03366991 0.02833156 0.02328069 0.0328109  0.02442915 0.03356803
  0.05797574 0.0408857 ]
 [0.03983659 0.02471622 0.02460854 0.02362255 0.0172557  0.02542484
  0.03173863 0.03572879 0.02781685 0.02482508 0.03673726 0.0355863
  0.0320782  0.01653315 0.01445292 0.03077627 0.03585298 0.03341265
  0.03447408 0.03398608 0.03453515 0.03863809 0.01728877 0.05044226
  0.04768289 0.02628368 0.0229241  0.03497583 0.0185026  0.03932282
  0.04925029 0.04269943]
 [0.03949691 0.02421164 0.02288646 0.01884176 0.01526542 0.02007724
  0.03047102 0.03073106 0.02696522 0.01937192 0.03601987 0.02623202
  0.02794669 0.01312264 0.01215221 0.03032319 0.0405927  0.03250297
  0.03466526 0.03442567 0.03797788 0.03319098 0.01916401 0.06104383
  0.0739092  0.03594367 0.01922228 0.03675599 0.01525523 0.03894974
  0.05083784 0.06000116]
 [0.03868781 0.02228014 0.02066805 0.01811787 0.01411957 0.01914992
  0.02892666 0.02835594 0.02706486 0.01838021 0.02731683 0.02118408
  0.02871659 0.01273125 0.01182668 0.02729844 0.03839326 0.03244398
  0.03762818 0.03784293 0.03831033 0.03754832 0.02065509 0.06054738
  0.06280782 0.04061884 0.01947699 0.03247171 0.01563071 0.03482511
  0.05298284 0.05998772]
 [0.03999303 0.02192956 0.02114933 0.02179618 0.0151197  0.02193497
  0.02725912 0.02863817 0.02585976 0.02182013 0.02867122 0.02470879
  0.02768752 0.01588083 0.01360726 0.02261163 0.02596241 0.02713667
  0.02721461 0.02986481 0.0300316  0.03588747 0.01771181 0.03519456
  0.03281033 0.02932944 0.01889964 0.02762494 0.01942174 0.03109222
  0.05189735 0.04602865]
 [0.03903235 0.02767325 0.02843473 0.03203049 0.02407693 0.03407404
  0.03812671 0.04273256 0.03650636 0.03647955 0.03117904 0.04144115
  0.04516064 0.02425756 0.01962564 0.02571954 0.03041251 0.03323275
  0.03100382 0.03518167 0.03100595 0.04331992 0.02632253 0.02743808
  0.02624278 0.03470206 0.02759382 0.03830591 0.03228918 0.03181766
  0.04286375 0.03334054]
 [0.03877109 0.04480111 0.04135264 0.06407633 0.05814914 0.06342439
  0.0427544  0.0410652  0.0445862  0.05982577 0.04259287 0.04241661
  0.04534549 0.09614529 0.11556619 0.03769064 0.03167477 0.03478409
  0.03160536 0.03633771 0.03389564 0.04350064 0.04546757 0.0145684
  0.01234685 0.03747038 0.04431992 0.04212429 0.05176232 0.01111732
  0.01289773 0.02221225]
 [0.03800402 0.04347249 0.03954633 0.08161354 0.16405289 0.05775939
  0.03674661 0.03868574 0.04345939 0.08288367 0.05648438 0.05864966
  0.04196673 0.0983361  0.1301298  0.04004322 0.05421554 0.07482231
  0.05455792 0.05035929 0.0508268  0.03690019 0.04930435 0.01591752
  0.01448483 0.0410649  0.06004415 0.05238185 0.04440682 0.01063749
  0.01069213 0.02175009]
 [0.03827477 0.03348247 0.0290965  0.04554151 0.08112014 0.02978134
  0.02653605 0.03162335 0.03187101 0.04948115 0.04731715 0.04334782
  0.03281188 0.0365408  0.05168319 0.03361405 0.06180488 0.08681054
  0.09208538 0.06759021 0.06015525 0.03319385 0.03778925 0.02661288
  0.0248199  0.03585936 0.04306334 0.05664218 0.02477778 0.01364236
  0.01539764 0.01948761]
 [0.03842532 0.03551554 0.03041852 0.04881312 0.05765807 0.03572951
  0.03141191 0.03521425 0.03821674 0.05032871 0.04405577 0.04363014
  0.03573328 0.04112917 0.04767272 0.02748369 0.04032409 0.05939201
  0.0551408  0.05226003 0.04289719 0.04632888 0.04291888 0.01800088
  0.01751347 0.03412265 0.03316353 0.06105395 0.02651562 0.01081937
  0.01327168 0.01815351]]

-* TASK 10/20 | SAMPLE 51/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 253/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Fred journeyed to the park, which implies that Fred is now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Fred', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0645, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03019538 0.04267772 0.04080822 ... 0.05600288 0.03651305 0.02021726]
 [0.03079091 0.04073159 0.03854974 ... 0.03902501 0.03175797 0.02396501]
 [0.03145726 0.04577355 0.04638156 ... 0.04173118 0.02830357 0.01514164]
 ...
 [0.0316153  0.04196014 0.03872186 ... 0.05277847 0.02517615 0.01595831]
 [0.03180661 0.03298648 0.0285205  ... 0.03844747 0.02957847 0.03006094]
 [0.03192535 0.03744177 0.03184507 ... 0.06440514 0.02655729 0.02500714]]

-* TASK 10/20 | SAMPLE 51/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 254/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no new information about Mary, but context sentence 5 mentioned that Mary is in the kitchen, and there is no update to change this information.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Mary', ',', ' but', ' context', ' sentence', ' ', '5', ' mentioned', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 44), x_tokens=44, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 44)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02422946 0.0276431  0.03284447 ... 0.08198414 0.01216523 0.01014777]
 [0.02462224 0.02802467 0.03336835 ... 0.04005346 0.0363199  0.02009912]
 [0.02530575 0.02733813 0.03378089 ... 0.06295379 0.02717614 0.01314645]
 ...
 [0.02554625 0.03505885 0.03154691 ... 0.03513353 0.00725727 0.00826114]
 [0.02623769 0.02601612 0.02176594 ... 0.02644331 0.00964992 0.01595518]
 [0.02616128 0.02857361 0.02379151 ... 0.03064029 0.00612718 0.01030084]]

-* TASK 10/20 | SAMPLE 51/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 255/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 13, Mary travelled to the office, and there is no mention of Mary being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Mary', ' travelled', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02929088 0.04490262 0.04475927 ... 0.03618659 0.02225847 0.02908748]
 [0.0299717  0.03436076 0.03282662 ... 0.0331507  0.02949481 0.02695832]
 [0.03047551 0.04748341 0.0510294  ... 0.03105644 0.02058058 0.0260074 ]
 ...
 [0.0307077  0.04758376 0.03945659 ... 0.03576635 0.01618014 0.02866886]
 [0.03138758 0.0362005  0.02728046 ... 0.036143   0.02048696 0.02348457]
 [0.0310822  0.03963812 0.02861421 ... 0.0336965  0.01855776 0.02623196]]
Model's predictions for the sample 51:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Fred   |
|          |                 |  being in the kitchen or the school, and   |
|          |                 |  Julie being in the school or the office.  |
|          |                 |  There is no mention of Fred being in the  |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 4, Julie   |
|          |                 |    is in the park, not in the kitchen.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 7, Fred    |
|          |                 |    journeyed to the park, which implies    |
|          |                 |       that Fred is now in the park.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  There is no new information about Mary,   |
|          |                 |   but context sentence 5 mentioned that    |
|          |                 |  Mary is in the kitchen, and there is no   |
|          |                 |     update to change this information.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 13, Mary   |
|          |                 |  travelled to the office, and there is no  |
|          |                 |    mention of Mary being in the school.    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 51:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 52/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 256/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From sentence 1, we know that Bill is either in the office or the kitchen, but we don't have any additional information to confirm his exact location. 

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' that', ' Bill', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' kitchen', ',', ' but', ' we', ' don', "'t", ' have', ' any', ' additional', ' information', ' to', ' confirm', ' his', ' exact', ' location', '.', ' \n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 26), x_tokens=26, y_tokens=41, max_supp_attn=0.0488, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 26)
DEBUG result.interpretability.attn_scores 1066 
 [[0.02239363 0.04032538 0.04640267 ... 0.01103553 0.01836535 0.0276387 ]
 [0.02289289 0.04261974 0.04458068 ... 0.00439428 0.00824738 0.03199996]
 [0.02339541 0.02645853 0.02697252 ... 0.00405531 0.00728279 0.02305991]
 ...
 [0.0238297  0.02631093 0.02680782 ... 0.00434705 0.00652145 0.02035354]
 [0.02375605 0.02286171 0.02218961 ... 0.01541609 0.01652613 0.02268235]
 [0.02413209 0.02284002 0.02206903 ... 0.01073056 0.01324361 0.02137954]]

-* TASK 10/20 | SAMPLE 52/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 257/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill's location in the context sentences 4 and 5, which only talk about Julie's movements. The original information about Bill's location is in sentence 1, but it doesn't mention the bedroom. 

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ',', ' which', ' only', ' talk', ' about', ' Julie', "'s", ' movements', '.', ' The', ' original', ' information', ' about', ' Bill', "'s", ' location', ' is', ' in', ' sentence', ' ', '1', ',', ' but', ' it', ' doesn', "'t", ' mention', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 32), x_tokens=32, y_tokens=57, max_supp_attn=0.1053, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 32)
DEBUG result.interpretability.attn_scores 1824 
 [[0.01608617 0.02081966 0.02344644 ... 0.01071099 0.00537147 0.01575361]
 [0.01664949 0.01932704 0.0197654  ... 0.01345595 0.00586104 0.02149284]
 [0.01699825 0.01880611 0.02113895 ... 0.02118097 0.00656283 0.0213264 ]
 ...
 [0.01733876 0.01688636 0.01489276 ... 0.00750066 0.00923227 0.01295406]
 [0.0174513  0.01984662 0.01862915 ... 0.00635989 0.0084382  0.01213124]
 [0.01764873 0.01668258 0.01600356 ... 0.00655324 0.00732038 0.01057277]]

-* TASK 10/20 | SAMPLE 52/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 258/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Bill went back to the bedroom, which implies that Bill is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.0309501  0.04267193 0.04865412 ... 0.0624436  0.03504385 0.02731771]
 [0.03134843 0.03783183 0.04044425 ... 0.04003088 0.0369579  0.035135  ]
 [0.03231476 0.05091037 0.05664171 ... 0.04849226 0.02954039 0.0222855 ]
 ...
 [0.03258542 0.04693837 0.04481909 ... 0.06164984 0.03093578 0.02039205]
 [0.03254135 0.04179054 0.03778584 ... 0.04704086 0.03253009 0.02919307]
 [0.03282634 0.04485454 0.03904184 ... 0.07466331 0.02900994 0.0250459 ]]

-* TASK 10/20 | SAMPLE 52/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 259/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences 10 and 11 do not provide any new information about Bill's location. The last information about Bill's location was in sentence 8, which stated that Bill went back to the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' The', ' last', ' information', ' about', ' Bill', "'s", ' location', ' was', ' in', ' sentence', ' ', '8', ',', ' which', ' stated', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 44), x_tokens=44, y_tokens=49, max_supp_attn=0.0, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 44)
DEBUG result.interpretability.attn_scores 2156 
 [[0.01901977 0.02373444 0.02184216 ... 0.07538371 0.01043848 0.00543462]
 [0.01927505 0.01879126 0.01859874 ... 0.02811212 0.00987798 0.00947974]
 [0.01980419 0.02473715 0.02413208 ... 0.06015834 0.01774567 0.00757329]
 ...
 [0.02008027 0.0236708  0.02420651 ... 0.02991521 0.00571497 0.00403094]
 [0.02039005 0.01952598 0.01869473 ... 0.01555328 0.0063787  0.00441157]
 [0.02027065 0.02312143 0.02165772 ... 0.02451361 0.00569845 0.00418686]]

-* TASK 10/20 | SAMPLE 52/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 260/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences 13 and 14 provide information about Bill's movements, but they do not mention the park. The last information about Bill's location was in sentence 14, which stated that Bill went to the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ' provide', ' information', ' about', ' Bill', "'s", ' movements', ',', ' but', ' they', ' do', ' not', ' mention', ' the', ' park', '.', ' The', ' last', ' information', ' about', ' Bill', "'s", ' location', ' was', ' in', ' sentence', ' ', '14', ',', ' which', ' stated', ' that', ' Bill', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0385, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01780215 0.02834578 0.0247493  ... 0.00911796 0.01127373 0.03168429]
 [0.01822562 0.02490308 0.02076365 ... 0.01980991 0.01526749 0.01238081]
 [0.01860067 0.03135937 0.02872757 ... 0.01264619 0.01993343 0.03151403]
 ...
 [0.01882105 0.02623627 0.02532099 ... 0.00651666 0.00955515 0.07618179]
 [0.01916298 0.02079379 0.01903973 ... 0.00703857 0.00930908 0.05885125]
 [0.01909114 0.0211885  0.01920329 ... 0.00661706 0.00925248 0.0456716 ]]
Model's predictions for the sample 52:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   From sentence 1, we know that Bill is    |
|          |                 |  either in the office or the kitchen, but  |
|          |                 |  we don't have any additional information  |
|          |                 |       to confirm his exact location.       |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |  Bill's location in the context sentences  |
|          |                 |   4 and 5, which only talk about Julie's   |
|          |                 |    movements. The original information     |
|          |                 |  about Bill's location is in sentence 1,   |
|          |                 |    but it doesn't mention the bedroom.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Bill   |
|          |                 |  went back to the bedroom, which implies   |
|          |                 |   that Bill is currently in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   The context sentences 10 and 11 do not   |
|          |                 |  provide any new information about Bill's  |
|          |                 |    location. The last information about    |
|          |                 |  Bill's location was in sentence 8, which  |
|          |                 |     stated that Bill went back to the      |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences 13 and 14 provide   |
|          |                 |  information about Bill's movements, but   |
|          |                 |   they do not mention the park. The last   |
|          |                 |  information about Bill's location was in  |
|          |                 |  sentence 14, which stated that Bill went  |
|          |                 |              to the kitchen.               |
+----------+-----------------+--------------------------------------------+

Metrics for sample 52:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.06 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 53/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 261/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Fred being in the cinema. Sentence 2 only mentions the bedroom or the kitchen as possible locations for Fred.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '2', ' only', ' mentions', ' the', ' bedroom', ' or', ' the', ' kitchen', ' as', ' possible', ' locations', ' for', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02678405 0.04915697 0.05272162 0.08295225 0.07657585 0.05518552
  0.03853662 0.03234734 0.03610513 0.05196088 0.03604381 0.0278125
  0.02656428 0.12523292 0.13165872 0.04164007 0.02631056 0.02042221
  0.01705697 0.0213952  0.02149662 0.03960579 0.06881622 0.01461118
  0.00365187 0.02535588]
 [0.02765869 0.03066381 0.03116008 0.05982039 0.05503306 0.04660296
  0.02703951 0.0236097  0.02882081 0.04504387 0.03112994 0.0298167
  0.02654856 0.13116013 0.15475592 0.03896384 0.02815728 0.02380225
  0.01881347 0.02220973 0.02028211 0.03287747 0.04034533 0.01164731
  0.00332484 0.0166763 ]
 [0.02811785 0.03446358 0.03948228 0.06361769 0.06039145 0.05837287
  0.03574244 0.03281846 0.03800944 0.05344279 0.03624576 0.04747711
  0.04138125 0.10296424 0.09512424 0.03280171 0.02595291 0.02423942
  0.01840324 0.02224299 0.01914785 0.02989849 0.03683855 0.01574956
  0.00449737 0.01614537]
 [0.02712824 0.04046105 0.04601084 0.04690675 0.05075487 0.05264146
  0.03914997 0.0408538  0.04150158 0.0458797  0.03566021 0.05185566
  0.04220815 0.06014989 0.05381141 0.04091027 0.03171942 0.03062733
  0.02397706 0.02903493 0.02690989 0.03388486 0.0513659  0.03631816
  0.01272776 0.03054306]
 [0.02727195 0.0547865  0.05889267 0.03600648 0.03071851 0.04475337
  0.04628137 0.04778804 0.04404842 0.03419684 0.03066627 0.04312284
  0.04115802 0.02466176 0.01891296 0.0376977  0.02869319 0.02897598
  0.02526978 0.029287   0.02770804 0.03136719 0.06116869 0.03903503
  0.02781861 0.04272638]
 [0.02817633 0.07145155 0.07758112 0.0334687  0.02485532 0.04144057
  0.04813873 0.04294864 0.050234   0.03014079 0.025707   0.03641061
  0.03238711 0.01846807 0.01601939 0.04340792 0.02894343 0.02690562
  0.02326559 0.02972512 0.0266244  0.03038958 0.07393686 0.03360723
  0.01372133 0.0291916 ]
 [0.02822786 0.04388051 0.05300573 0.02930619 0.02182249 0.03825824
  0.0434282  0.04091406 0.04337164 0.02713931 0.02361573 0.03613574
  0.02843605 0.01626831 0.01446759 0.03705232 0.02728532 0.02617653
  0.02303833 0.02854573 0.0273602  0.03114882 0.05494342 0.04281312
  0.01696599 0.03727184]
 [0.02841562 0.03389931 0.03499345 0.04468893 0.03812809 0.05134785
  0.03767914 0.03783644 0.04523622 0.05074842 0.03444369 0.05381253
  0.04164536 0.02905736 0.01965882 0.02107761 0.02036234 0.02499066
  0.02183073 0.0247825  0.02395249 0.03482286 0.03570692 0.02160733
  0.00945125 0.02327874]
 [0.02853717 0.03408575 0.03613422 0.03113382 0.02451301 0.04087556
  0.03737297 0.04742976 0.04009048 0.03534701 0.02981184 0.05558009
  0.04026197 0.01700308 0.0131764  0.02728095 0.02383722 0.02664129
  0.02419816 0.02586838 0.02585959 0.02937727 0.0268596  0.02625577
  0.02046308 0.02438509]
 [0.02813574 0.02626512 0.02580165 0.02063779 0.01795188 0.02595844
  0.03314051 0.03232871 0.02815088 0.02354536 0.0295107  0.03268921
  0.03280527 0.01138285 0.01094319 0.03475215 0.02881615 0.03261817
  0.03231121 0.03514489 0.04223151 0.02967308 0.02314835 0.03975603
  0.03084768 0.0258717 ]
 [0.02828282 0.02036582 0.01777566 0.01591964 0.01338599 0.01607524
  0.02420363 0.0237598  0.01905267 0.01629663 0.02110622 0.01880723
  0.02202948 0.00797675 0.00847069 0.03149751 0.02493984 0.03736236
  0.04111954 0.04672281 0.04891022 0.0258265  0.01697709 0.04299807
  0.04035072 0.02857127]
 [0.02872732 0.02110663 0.01825062 0.01646122 0.01402399 0.01743509
  0.0230115  0.0242375  0.01909651 0.01777998 0.02348906 0.02259356
  0.02385304 0.00825629 0.00838134 0.03332603 0.02694984 0.03391769
  0.03661272 0.03794032 0.03847719 0.02397032 0.01463923 0.03561496
  0.04226268 0.02093844]
 [0.02863739 0.01751393 0.01525318 0.01234084 0.01125888 0.01381821
  0.02022242 0.0187221  0.01690724 0.01374856 0.02366473 0.0172478
  0.0190227  0.00665219 0.00718874 0.03257733 0.02956803 0.03074207
  0.04074667 0.03767042 0.04344972 0.02382758 0.01423673 0.03615398
  0.04417618 0.02541422]
 [0.02806553 0.01986177 0.01708567 0.01322267 0.01190487 0.01552629
  0.02220183 0.01857091 0.02035966 0.01428598 0.02488722 0.01726236
  0.01914741 0.00724785 0.00781931 0.03582196 0.02917496 0.02896363
  0.03664353 0.03533189 0.03979941 0.02522425 0.02033148 0.06421968
  0.04860623 0.03873074]
 [0.02897667 0.02191015 0.01905806 0.01643781 0.0142078  0.0180573
  0.02245918 0.02256447 0.02096383 0.01809432 0.02440205 0.02225072
  0.02182407 0.00943651 0.00886583 0.02658835 0.02302977 0.0289295
  0.03837192 0.03394863 0.03623397 0.02554706 0.01625117 0.02426584
  0.02629717 0.0225795 ]
 [0.02850976 0.02804621 0.02672135 0.0276237  0.02318373 0.03359864
  0.02823672 0.03054941 0.03152246 0.03358408 0.02648136 0.04221327
  0.03585397 0.01967376 0.01443986 0.02511415 0.02766861 0.02777414
  0.02662761 0.02590549 0.02391792 0.03140026 0.02776747 0.02459519
  0.02329266 0.0330546 ]
 [0.02878045 0.0341501  0.03487946 0.02311313 0.02065305 0.02475014
  0.03865867 0.02957102 0.03205676 0.02209967 0.02207178 0.02357655
  0.02414334 0.01373479 0.01376256 0.03563764 0.02763808 0.02462793
  0.02462843 0.02863104 0.02628644 0.02792036 0.04410416 0.04186563
  0.01642279 0.03526311]
 [0.02902484 0.01539048 0.01587927 0.01142    0.01123491 0.01280259
  0.01548137 0.01385861 0.01698122 0.01168577 0.01350956 0.01205313
  0.01278485 0.00680894 0.00762778 0.02084837 0.0205763  0.01944222
  0.02522664 0.02876166 0.02763706 0.01941477 0.03180021 0.05447378
  0.02557443 0.04689996]
 [0.02885287 0.02478184 0.02417124 0.01847303 0.01544117 0.02197425
  0.0270273  0.02753096 0.02482176 0.018526   0.020584   0.02397702
  0.02564936 0.01120977 0.01045639 0.02742062 0.02749352 0.02245699
  0.02465616 0.02310042 0.02221792 0.02899438 0.0245809  0.03378723
  0.04059317 0.0427759 ]
 [0.0295033  0.02550038 0.0238923  0.02001349 0.01578747 0.02569851
  0.02892433 0.03386588 0.02643426 0.0217607  0.02352611 0.02876636
  0.0308266  0.01174338 0.00946046 0.02000666 0.027683   0.02125479
  0.02459646 0.02141496 0.01953582 0.02764076 0.016527   0.01906553
  0.03823927 0.02523207]
 [0.02911774 0.01999046 0.01852264 0.01565275 0.01284522 0.01860024
  0.02429823 0.02535613 0.02189269 0.01720344 0.02447972 0.02098255
  0.02529827 0.0095593  0.00815591 0.02169809 0.02872774 0.02121557
  0.02631791 0.02375445 0.02369168 0.02584876 0.01344137 0.02775613
  0.0648303  0.03551535]
 [0.0288893  0.01947569 0.01776443 0.01314775 0.01103645 0.01561962
  0.02358315 0.02434487 0.02055557 0.01533042 0.02784606 0.01792315
  0.02621843 0.00860964 0.00681825 0.02231685 0.03271636 0.0213216
  0.0275101  0.02430775 0.02551884 0.02459221 0.01244283 0.03098037
  0.08201649 0.04616757]
 [0.02927604 0.01514794 0.01381793 0.01177585 0.00995625 0.01318796
  0.01555766 0.01473073 0.01685244 0.01292576 0.02061507 0.01432918
  0.01556841 0.00712114 0.00604646 0.01543637 0.02702875 0.01818737
  0.02409685 0.02548184 0.02529353 0.02077624 0.01084247 0.02569499
  0.07385766 0.05023833]
 [0.02950587 0.01645468 0.01511069 0.01184609 0.01044107 0.01402294
  0.01906182 0.01885905 0.0186951  0.01399916 0.02543334 0.01829147
  0.01950374 0.00755286 0.00628857 0.01843172 0.03549926 0.02227944
  0.02727551 0.02397905 0.02242255 0.02343978 0.01128548 0.02312253
  0.05132072 0.04575206]
 [0.02820371 0.02365164 0.02232925 0.03503726 0.05509167 0.0306381
  0.02142064 0.02186436 0.02889205 0.0446542  0.03247312 0.03326019
  0.02931744 0.03144    0.02732228 0.01863005 0.03196419 0.04539
  0.03897591 0.03347437 0.03338336 0.02675941 0.02209387 0.0184093
  0.01848897 0.02774696]
 [0.02953311 0.0192282  0.01810295 0.01456335 0.0113348  0.01619467
  0.02196687 0.0238102  0.021294   0.01605181 0.02586235 0.01934424
  0.02268554 0.00921444 0.00701158 0.01991937 0.02775068 0.02320424
  0.02675472 0.02383301 0.02365495 0.02518955 0.01326713 0.02170821
  0.0371989  0.0333698 ]
 [0.02950965 0.0219316  0.02110989 0.01581975 0.01229646 0.01889027
  0.02671198 0.03136018 0.02381892 0.0193459  0.03572713 0.02396974
  0.03152773 0.01153438 0.00755871 0.02337578 0.03089526 0.02254196
  0.0288398  0.02350094 0.02397039 0.02789253 0.01431967 0.02395628
  0.04100364 0.01941448]
 [0.02924288 0.02842239 0.02507107 0.01885853 0.01400534 0.02067462
  0.03542203 0.03732916 0.02775906 0.02315135 0.04473988 0.02600732
  0.03738723 0.01321098 0.00902039 0.03049467 0.03713346 0.02982017
  0.03122264 0.02781699 0.02722008 0.02732073 0.01731143 0.02959573
  0.0382738  0.01828252]
 [0.029576   0.02440153 0.02476451 0.01851985 0.01363639 0.02048394
  0.03501313 0.0345386  0.02803032 0.02133482 0.04477453 0.02509714
  0.03525031 0.01095047 0.00810841 0.02820509 0.03021134 0.02753922
  0.02690456 0.02677545 0.02794539 0.0257674  0.01552654 0.0246931
  0.02468367 0.01533155]
 [0.02916682 0.02120975 0.01973769 0.01517829 0.01103112 0.01613044
  0.02690423 0.02495294 0.02253111 0.01682681 0.02093533 0.01623205
  0.0266628  0.00913084 0.00736923 0.02590749 0.03143376 0.02813869
  0.03014139 0.028191   0.03059909 0.02895559 0.01685878 0.03299205
  0.03352075 0.02387515]
 [0.02949723 0.02175588 0.02118243 0.01864627 0.01319552 0.01794992
  0.02466034 0.02451031 0.02419978 0.02003688 0.02179215 0.01860275
  0.02564412 0.01078588 0.00900396 0.02378161 0.02236629 0.02539842
  0.02614341 0.02695763 0.03128582 0.02594747 0.01693465 0.02657127
  0.02107764 0.02137284]
 [0.02839169 0.03175441 0.03142779 0.04996582 0.05128632 0.04281647
  0.02621865 0.02733155 0.03381859 0.0490188  0.03187443 0.03049023
  0.03335758 0.08886304 0.10298105 0.0285345  0.02403909 0.02387996
  0.01922563 0.0211894  0.02059446 0.03210579 0.03499708 0.01160231
  0.00350265 0.01924701]
 [0.02813927 0.03277901 0.03045368 0.05623067 0.10541632 0.04077219
  0.02264024 0.0237346  0.02993737 0.05499278 0.0376487  0.03100478
  0.02628551 0.08340022 0.10671394 0.03375646 0.03531841 0.03838447
  0.02677129 0.02571077 0.02621051 0.02948532 0.03466916 0.01082963
  0.00350917 0.0164677 ]
 [0.02798418 0.02559773 0.0240702  0.03930122 0.06141705 0.02750294
  0.01765609 0.02178877 0.02625616 0.0456769  0.03574745 0.03269103
  0.0285964  0.02948386 0.03180051 0.02404434 0.03914346 0.06808881
  0.05205763 0.04292005 0.03750311 0.02661077 0.02649825 0.01828963
  0.01048971 0.01865355]
 [0.02815207 0.03045757 0.0277844  0.04189207 0.05518357 0.03134261
  0.02194856 0.02338291 0.03170193 0.0441443  0.03349366 0.02831309
  0.02816566 0.03005404 0.03079919 0.02104442 0.03097215 0.04373937
  0.0403684  0.03444314 0.03266792 0.04649683 0.03916612 0.0153579
  0.00694084 0.01765925]]

-* TASK 10/20 | SAMPLE 53/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 262/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the kitchen. Sentence 5 mentions Bill travelling to the cinema, but there is no information about Bill being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' kitchen', '.', ' Sentence', ' ', '5', ' mentions', ' Bill', ' travelling', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 32), x_tokens=32, y_tokens=41, max_supp_attn=0.122, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 32)
DEBUG result.interpretability.attn_scores 1312 
 [[0.02265668 0.03700276 0.03887115 ... 0.01035456 0.01242664 0.00961814]
 [0.02317416 0.03908975 0.03808942 ... 0.01505811 0.01930145 0.0129302 ]
 [0.02367677 0.03367768 0.0374131  ... 0.01657467 0.02246583 0.01125963]
 ...
 [0.02375736 0.03203217 0.02771617 ... 0.00611464 0.00728463 0.01100666]
 [0.02408177 0.02648996 0.02221663 ... 0.00806862 0.00864425 0.01327549]
 [0.02421495 0.02769886 0.02207281 ... 0.00670461 0.00802123 0.01007052]]

-* TASK 10/20 | SAMPLE 53/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 263/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie being in the school in the context sentences. The context sentences only mention Bill being in the bedroom and Fred being in either the park or the office, but do not mention Julie or the school.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' being', ' in', ' the', ' bedroom', ' and', ' Fred', ' being', ' in', ' either', ' the', ' park', ' or', ' the', ' office', ',', ' but', ' do', ' not', ' mention', ' Julie', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 38), x_tokens=38, y_tokens=53, max_supp_attn=0.0566, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 38)
DEBUG result.interpretability.attn_scores 2014 
 [[0.01739756 0.02453259 0.02502163 ... 0.01886664 0.01349833 0.02585642]
 [0.01765975 0.02125552 0.02329307 ... 0.02345819 0.01947944 0.02501794]
 [0.01817822 0.02371559 0.02636126 ... 0.01540136 0.01016049 0.01852132]
 ...
 [0.01858432 0.01804479 0.01702786 ... 0.01632991 0.01282748 0.01710079]
 [0.01876183 0.02087837 0.01988158 ... 0.01596007 0.01099107 0.01883771]
 [0.01891471 0.01901355 0.01859397 ... 0.01442735 0.01072638 0.01826673]]

-* TASK 10/20 | SAMPLE 53/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 264/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Bill being in the kitchen. Sentence 10 mentions Bill travelling to the cinema, and sentence 11 mentions Bill going back to the school, but there is no information about Bill being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' kitchen', '.', ' Sentence', ' ', '10', ' mentions', ' Bill', ' travelling', ' to', ' the', ' cinema', ',', ' and', ' sentence', ' ', '11', ' mentions', ' Bill', ' going', ' back', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 44), x_tokens=44, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 44)
DEBUG result.interpretability.attn_scores 2332 
 [[0.01743966 0.02554684 0.02394878 ... 0.00776301 0.00733188 0.0048608 ]
 [0.01782313 0.02245973 0.02208425 ... 0.01641287 0.02367325 0.00974214]
 [0.01826624 0.02763136 0.02733524 ... 0.01138025 0.01200332 0.00661255]
 ...
 [0.01843861 0.02568889 0.02515723 ... 0.00497065 0.00406448 0.00323019]
 [0.01876598 0.01999642 0.01942146 ... 0.00728118 0.00539293 0.0046772 ]
 [0.01858734 0.02312734 0.02108439 ... 0.00569733 0.00471001 0.00410502]]

-* TASK 10/20 | SAMPLE 53/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 265/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 explicitly states that Bill travelled to the kitchen, which implies that Bill is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' explicitly', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03212065 0.04628953 0.04772004 ... 0.04966407 0.03042161 0.02360079]
 [0.03281036 0.0321812  0.03431514 ... 0.03346517 0.03389981 0.03308986]
 [0.03357311 0.04608861 0.05015881 ... 0.04355343 0.02689509 0.022324  ]
 ...
 [0.03389582 0.04720999 0.04053877 ... 0.03731325 0.02239732 0.0184144 ]
 [0.03379533 0.04031819 0.03340736 ... 0.03525449 0.0323514  0.03056066]
 [0.03400441 0.04419395 0.03536003 ... 0.04056028 0.0225397  0.02285117]]
Model's predictions for the sample 53:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Fred being in the cinema. Sentence 2    |
|          |                 |  only mentions the bedroom or the kitchen  |
|          |                 |      as possible locations for Fred.       |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |   Bill being in the kitchen. Sentence 5    |
|          |                 |  mentions Bill travelling to the cinema,   |
|          |                 |   but there is no information about Bill   |
|          |                 |           being in the kitchen.            |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Julie     |
|          |                 |     being in the school in the context     |
|          |                 |   sentences. The context sentences only    |
|          |                 |   mention Bill being in the bedroom and    |
|          |                 |    Fred being in either the park or the    |
|          |                 |  office, but do not mention Julie or the   |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |   Bill being in the kitchen. Sentence 10   |
|          |                 |  mentions Bill travelling to the cinema,   |
|          |                 |  and sentence 11 mentions Bill going back  |
|          |                 |       to the school, but there is no       |
|          |                 |    information about Bill being in the     |
|          |                 |                  kitchen.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 13 explicitly states that Bill   |
|          |                 |  travelled to the kitchen, which implies   |
|          |                 |   that Bill is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 53:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 54/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 266/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences only mention two possible locations for Bill: the office or the bedroom. There is no mention of the school as a possible location for Bill.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' two', ' possible', ' locations', ' for', ' Bill', ':', ' the', ' office', ' or', ' the', ' bedroom', '.', ' There', ' is', ' no', ' mention', ' of', ' the', ' school', ' as', ' a', ' possible', ' location', ' for', ' Bill', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 26), x_tokens=26, y_tokens=41, max_supp_attn=0.1707, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 26)
DEBUG result.interpretability.attn_scores 1066 
 [[0.02249869 0.03687872 0.04269944 ... 0.01241735 0.01765332 0.02913912]
 [0.02350051 0.04574257 0.03473939 ... 0.00461791 0.00507911 0.02074681]
 [0.02415317 0.0414732  0.03647701 ... 0.00402692 0.0041729  0.02181618]
 ...
 [0.02393585 0.0253506  0.02451183 ... 0.00487499 0.00569245 0.01906931]
 [0.02361633 0.01944478 0.0193458  ... 0.01222783 0.01436813 0.02237185]
 [0.02401653 0.02480597 0.02310531 ... 0.0080365  0.0095812  0.01986585]]

-* TASK 10/20 | SAMPLE 54/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 267/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentence 5 mentions that Bill is either in the bedroom or the kitchen, but it does not provide a definitive location for Bill. Therefore, we can only conclude that Bill might be in the bedroom, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' mentions', ' that', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Bill', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' bedroom', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 32), x_tokens=32, y_tokens=57, max_supp_attn=0.1053, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 32)
DEBUG result.interpretability.attn_scores 1824 
 [[0.015892   0.03185124 0.02908033 ... 0.01264302 0.00899094 0.00649596]
 [0.01669988 0.02768885 0.02372623 ... 0.00617571 0.00449379 0.00391397]
 [0.01607448 0.02449427 0.03018903 ... 0.01532298 0.00933221 0.00702593]
 ...
 [0.01691184 0.02363619 0.02342557 ... 0.00711414 0.00552855 0.00477329]
 [0.0171975  0.02045229 0.018872   ... 0.00736325 0.00816043 0.00745233]
 [0.01729559 0.01936863 0.01806847 ... 0.00624096 0.00777713 0.00673782]]

-* TASK 10/20 | SAMPLE 54/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 268/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences 7 and 8 only provide information about Mary's locations, but they do not mention Bill's location. The previous information about Bill's location (sentence 5) is no longer relevant, as it is not mentioned again.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' only', ' provide', ' information', ' about', ' Mary', "'s", ' locations', ',', ' but', ' they', ' do', ' not', ' mention', ' Bill', "'s", ' location', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' (', 'sentence', ' ', '5', ')', ' is', ' no', ' longer', ' relevant', ',', ' as', ' it', ' is', ' not', ' mentioned', ' again', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 38), x_tokens=38, y_tokens=59, max_supp_attn=0.1017, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 38)
DEBUG result.interpretability.attn_scores 2242 
 [[0.01555484 0.01887698 0.0164967  ... 0.03341285 0.02390597 0.02335845]
 [0.01617659 0.02976281 0.02083576 ... 0.0118205  0.0058847  0.004754  ]
 [0.01557651 0.0220882  0.02037894 ... 0.01333711 0.00862822 0.00684584]
 ...
 [0.01654067 0.01998811 0.01533315 ... 0.01212103 0.01236025 0.01638239]
 [0.01686023 0.02119601 0.01829803 ... 0.01138574 0.01035274 0.00920717]
 [0.01696916 0.01705734 0.01522043 ... 0.01098026 0.00868471 0.00730265]]

-* TASK 10/20 | SAMPLE 54/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 269/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentence 11 explicitly states that Fred journeyed to the park, which implies that Fred is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' explicitly', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0294, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02725624 0.0403984  0.03594017 ... 0.0725924  0.0210968  0.01596591]
 [0.02843019 0.05466006 0.04402146 ... 0.12705858 0.00761371 0.00807642]
 [0.02751205 0.03981271 0.04289723 ... 0.1295927  0.01828821 0.01139486]
 ...
 [0.02878322 0.03495807 0.03848647 ... 0.04435907 0.01007568 0.00891278]
 [0.02897076 0.02821639 0.02961969 ... 0.02395981 0.00976934 0.01399065]
 [0.02908424 0.02858127 0.03074246 ... 0.03922196 0.00765926 0.01058741]]

-* TASK 10/20 | SAMPLE 54/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 270/1000 *-


DEBUG starting interpretability
The output of the model:
*TASK*

Reasoning: The context sentences 13 and 14 only mention Fred and Bill going to the bedroom, but there is no mention of the school as a location for Fred or anyone else.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ' only', ' mention', ' Fred', ' and', ' Bill', ' going', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' school', ' as', ' a', ' location', ' for', ' Fred', ' or', ' anyone', ' else', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02105528 0.02927107 0.03068015 ... 0.01218396 0.01420957 0.0161991 ]
 [0.021561   0.03435222 0.03281206 ... 0.0142412  0.01708087 0.04753294]
 [0.02117447 0.03164094 0.03241334 ... 0.01775538 0.01844896 0.05400559]
 ...
 [0.02222959 0.03286881 0.02960791 ... 0.01675699 0.02064297 0.1030857 ]
 [0.02266113 0.02229321 0.01876335 ... 0.02399379 0.02648185 0.06887311]
 [0.02256994 0.02677341 0.02131733 ... 0.01848073 0.02306838 0.08078443]]
Model's predictions for the sample 54:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   The context sentences only mention two   |
|          |                 |  possible locations for Bill: the office   |
|          |                 |   or the bedroom. There is no mention of   |
|          |                 |   the school as a possible location for    |
|          |                 |                   Bill.                    |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentence 5 mentions that    |
|          |                 |    Bill is either in the bedroom or the    |
|          |                 |     kitchen, but it does not provide a     |
|          |                 |  definitive location for Bill. Therefore,  |
|          |                 |  we can only conclude that Bill might be   |
|          |                 |      in the bedroom, but we cannot be      |
|          |                 |                  certain.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     The context sentences 7 and 8 only     |
|          |                 |      provide information about Mary's      |
|          |                 |     locations, but they do not mention     |
|          |                 |       Bill's location. The previous        |
|          |                 |     information about Bill's location      |
|          |                 |   (sentence 5) is no longer relevant, as   |
|          |                 |         it is not mentioned again.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 11 explicitly     |
|          |                 |  states that Fred journeyed to the park,   |
|          |                 |  which implies that Fred is currently in   |
|          |                 |                 the park.                  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences 13 and 14 only    |
|          |                 |     mention Fred and Bill going to the     |
|          |                 |  bedroom, but there is no mention of the   |
|          |                 |  school as a location for Fred or anyone   |
|          |                 |                   else.                    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 54:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 55/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 271/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Mary travelled to the park, which implies that she is now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' travelled', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1515, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02809705 0.04548492 0.05585502 0.071889   0.07190279 0.07360745
  0.06389    0.07231645 0.05544922 0.06240925 0.0470797  0.06260949
  0.06867389 0.0855896  0.05780983 0.0296599  0.03011132 0.03199484
  0.02803531 0.03034795 0.02730199 0.03942989 0.04561869 0.02689201
  0.02007321 0.02514629]
 [0.0284062  0.05826809 0.05589386 0.06558733 0.05704115 0.05862091
  0.05750599 0.05646681 0.04598517 0.04872005 0.04040308 0.03766631
  0.04058977 0.10280563 0.09628069 0.03411573 0.02974914 0.02614612
  0.02384645 0.02543784 0.02406053 0.03853546 0.05121449 0.01660148
  0.01318217 0.02318788]
 [0.03069882 0.06167891 0.0376576  0.05559722 0.03709238 0.03728577
  0.03411605 0.02461704 0.02245665 0.03370786 0.02666419 0.01665424
  0.01792073 0.0280423  0.03677834 0.02241468 0.01405278 0.01268517
  0.01530127 0.01595513 0.01603096 0.04499862 0.05571244 0.00633976
  0.00556729 0.0123671 ]
 [0.02886654 0.02913803 0.02884502 0.02476804 0.01771146 0.02777529
  0.03131733 0.02690056 0.02811285 0.02538016 0.02785063 0.02887736
  0.02566894 0.01220712 0.01110219 0.03009801 0.02987399 0.03620047
  0.03883046 0.04446117 0.03454294 0.03038009 0.03166882 0.03980861
  0.07630829 0.05890878]
 [0.02910706 0.04560835 0.04968879 0.06800529 0.0627502  0.04905472
  0.03722939 0.03267742 0.03506904 0.04678847 0.03521015 0.02620552
  0.0262696  0.09627111 0.10096755 0.03728847 0.0271502  0.01965179
  0.02018048 0.02154529 0.02294945 0.03982427 0.06705475 0.00967546
  0.00886273 0.02803239]
 [0.02969424 0.02978388 0.02991789 0.05122256 0.04819071 0.04247827
  0.02710916 0.02561071 0.02971408 0.04302527 0.03171618 0.02971359
  0.02839984 0.10867589 0.12836355 0.0372561  0.03095134 0.02399285
  0.02293091 0.02264725 0.02241213 0.03380003 0.0390043  0.00866875
  0.00718563 0.01821855]
 [0.03011292 0.0336303  0.03794588 0.05401119 0.05121688 0.05335777
  0.035973   0.03461459 0.03842212 0.05085016 0.03687578 0.04734444
  0.04288186 0.08534963 0.08020642 0.03152548 0.02854948 0.02411777
  0.02192139 0.02209453 0.02125566 0.03082518 0.03575881 0.01217988
  0.01065066 0.01731117]
 [0.02901771 0.04359117 0.04700014 0.04206435 0.04629905 0.04891841
  0.04121222 0.04291621 0.04178542 0.04430914 0.0372845  0.05338828
  0.04530731 0.05165309 0.04765259 0.04171553 0.03939049 0.03299157
  0.02932489 0.02962547 0.0296902  0.03593698 0.04936438 0.0280679
  0.03518675 0.03193088]
 [0.03023461 0.04248821 0.05009275 0.04758361 0.04515513 0.05549785
  0.04511001 0.0475967  0.04933531 0.04957499 0.03713844 0.05165425
  0.04764271 0.03930733 0.02665468 0.02869986 0.02770123 0.02544724
  0.02407307 0.02445072 0.02359437 0.03642042 0.03921867 0.02013085
  0.01764012 0.0229858 ]
 [0.02955229 0.05584238 0.05681654 0.02861779 0.02464909 0.03705296
  0.04716892 0.04384419 0.0440403  0.02963168 0.02987885 0.0373067
  0.03892455 0.01630178 0.01459527 0.04509654 0.03618347 0.02967989
  0.03061113 0.03130611 0.03215439 0.03487787 0.06956617 0.04148559
  0.04124332 0.03413793]
 [0.03014614 0.04438275 0.05017043 0.02462938 0.0221649  0.02833046
  0.04936708 0.03777711 0.04296404 0.02482517 0.02554693 0.02744384
  0.02871214 0.01312416 0.01335285 0.04644573 0.03490934 0.02804242
  0.03007297 0.03178095 0.0308917  0.03064001 0.05746121 0.03098892
  0.04199288 0.03448662]
 [0.0304287  0.01751356 0.01962159 0.01217462 0.01121354 0.01598743
  0.01856421 0.01882944 0.02273887 0.01448763 0.01512905 0.01468869
  0.01597285 0.00624332 0.00706603 0.02219617 0.02142534 0.01973995
  0.02494233 0.02659222 0.02796067 0.02229964 0.0394954  0.03945729
  0.06812824 0.06226096]
 [0.03018674 0.02599718 0.02737856 0.01685772 0.01557175 0.0220495
  0.0265373  0.02417396 0.02538273 0.01860584 0.02234636 0.02188709
  0.02281037 0.00889253 0.00953517 0.03552688 0.03021526 0.02887447
  0.02997755 0.02972483 0.02749107 0.02919552 0.03287581 0.03957152
  0.06342843 0.0504273 ]
 [0.03031721 0.02435827 0.02417374 0.01804334 0.01580218 0.02490294
  0.027613   0.02694714 0.02599836 0.02163291 0.02649378 0.02913168
  0.0296308  0.00977004 0.00896217 0.03417436 0.03571989 0.0326637
  0.03118841 0.03001243 0.02875032 0.03018855 0.02164588 0.03827563
  0.06040443 0.03468969]
 [0.02981704 0.02129707 0.01782109 0.0138229  0.01118062 0.01618045
  0.02343565 0.02157037 0.02045914 0.01531069 0.02279736 0.01917337
  0.02263371 0.00675389 0.00676016 0.03877319 0.03617522 0.04576902
  0.04054131 0.04873268 0.04126686 0.0267301  0.01679065 0.04309344
  0.09188109 0.04802807]
 [0.03073801 0.01998466 0.01793157 0.01426009 0.01191189 0.01738629
  0.02296371 0.02093978 0.02084519 0.01658586 0.02737656 0.02201949
  0.02283431 0.00723552 0.00686434 0.03677125 0.02662419 0.0494716
  0.03595026 0.05485659 0.03778372 0.02251733 0.0137394  0.03520774
  0.05258116 0.03319488]
 [0.03062239 0.0169561  0.01505907 0.01088288 0.00934658 0.01353892
  0.01938373 0.01742852 0.0190407  0.01327332 0.0267859  0.01799971
  0.01920298 0.00570378 0.0058193  0.03414975 0.03047477 0.04040235
  0.04141343 0.0476487  0.03636564 0.02308753 0.01391479 0.04119377
  0.04329734 0.0558097 ]
 [0.02990412 0.02493723 0.02371111 0.01572161 0.01521787 0.02086355
  0.02946251 0.02868605 0.02836729 0.0188971  0.02897685 0.02328121
  0.02568603 0.00810968 0.00853662 0.02684728 0.03100806 0.03136536
  0.04008569 0.0370166  0.03382755 0.02718014 0.02227081 0.07327603
  0.04318156 0.05746053]
 [0.03108816 0.02190787 0.02076696 0.01618001 0.01320512 0.01880108
  0.02288186 0.02318268 0.02361041 0.01816533 0.02651684 0.02308293
  0.02349424 0.00842149 0.00786504 0.02393785 0.02415864 0.02524242
  0.03255719 0.03092265 0.03087107 0.02723651 0.01643336 0.03036402
  0.0219244  0.03746435]
 [0.03124154 0.02299889 0.02630827 0.02297969 0.0179854  0.02690971
  0.02647671 0.03180438 0.02799441 0.02831594 0.02938941 0.04029814
  0.03594289 0.01327672 0.00906936 0.02116782 0.02350146 0.02702243
  0.02591131 0.02376319 0.02462845 0.02922927 0.01552844 0.02754379
  0.02020828 0.02052714]
 [0.03143249 0.02728171 0.02868965 0.02677144 0.01934212 0.03010043
  0.03315728 0.0397716  0.02927392 0.03217477 0.03666053 0.04520955
  0.04294569 0.0147667  0.00969811 0.02360456 0.02315354 0.02760239
  0.02508117 0.02416862 0.02423517 0.02980601 0.01604878 0.02588794
  0.01664227 0.01476286]
 [0.03132448 0.02491811 0.02541406 0.02367296 0.01837337 0.02727783
  0.0298239  0.03374752 0.02942015 0.02982875 0.03379565 0.03943297
  0.04005863 0.01325166 0.00974374 0.02676624 0.02543847 0.02925523
  0.02724382 0.0255392  0.02671517 0.02937929 0.01397521 0.02492562
  0.01870229 0.01410956]
 [0.03115525 0.01981982 0.01890087 0.01444826 0.0111865  0.01709578
  0.02136824 0.02306206 0.02330332 0.01848412 0.02399662 0.02479293
  0.02668334 0.00790813 0.00654189 0.02812096 0.02947284 0.02921134
  0.03000523 0.02788191 0.03168514 0.02747204 0.01213224 0.03300954
  0.03112588 0.02086543]
 [0.03128646 0.02007624 0.01825956 0.01453173 0.01060101 0.01533974
  0.02157657 0.02172324 0.02201942 0.01706984 0.0231369  0.02127809
  0.02454625 0.00718764 0.00607545 0.03024654 0.02913981 0.03300808
  0.03228477 0.03264374 0.03712711 0.02311915 0.01209587 0.03579041
  0.03070307 0.02211407]
 [0.03144494 0.01971231 0.0181042  0.01476377 0.01196479 0.01602225
  0.02015755 0.02270735 0.02244056 0.01906664 0.02538421 0.02410511
  0.02440834 0.00798218 0.00652596 0.02636131 0.02993832 0.02853235
  0.03312302 0.02829283 0.03243938 0.0235934  0.0120309  0.03344342
  0.02032663 0.01928443]
 [0.03149873 0.02139263 0.01995562 0.01520802 0.01181901 0.01736043
  0.02363973 0.02501356 0.02597057 0.0189681  0.02801463 0.02441115
  0.02591057 0.00818095 0.00681096 0.02967843 0.02883118 0.03117742
  0.03215786 0.03150134 0.03339473 0.02412808 0.01348864 0.03411728
  0.02156033 0.02027156]
 [0.03164068 0.01653881 0.01635895 0.01105266 0.00954879 0.01327228
  0.01996516 0.01978727 0.02134237 0.01411522 0.0299237  0.01907423
  0.02063682 0.0065451  0.00527536 0.02557801 0.03128152 0.02640459
  0.03830852 0.03393093 0.03217948 0.02253376 0.0115216  0.03196323
  0.01887424 0.03059605]
 [0.03019907 0.02337875 0.02330112 0.01368991 0.01176963 0.01708682
  0.02551476 0.02762909 0.02897123 0.01698869 0.02693453 0.02039938
  0.02387607 0.00784911 0.00705247 0.02453279 0.02603704 0.02364285
  0.03416546 0.03037292 0.0423635  0.02645498 0.02256899 0.09379133
  0.0449517  0.04776556]
 [0.03144865 0.02182426 0.02228349 0.01887244 0.01465943 0.02254497
  0.02280108 0.02637745 0.02810846 0.02345437 0.02647584 0.0283478
  0.02718826 0.01188362 0.00874864 0.01928841 0.02452178 0.02478063
  0.03101618 0.02779903 0.02989991 0.02609188 0.01452608 0.02247592
  0.01397333 0.0223008 ]
 [0.03026895 0.02939366 0.02989286 0.04476102 0.04711026 0.03937411
  0.02583151 0.02660915 0.03141328 0.0449728  0.03354068 0.0314082
  0.03245745 0.07105063 0.08672249 0.02608555 0.02762898 0.0248429
  0.02371048 0.02266223 0.02368203 0.03224334 0.033224   0.01044699
  0.00886637 0.020226  ]
 [0.03012102 0.03055157 0.02996881 0.04860512 0.09293317 0.03805285
  0.02356852 0.02531452 0.03032825 0.05174712 0.03954976 0.0314162
  0.02681669 0.06908516 0.08948588 0.03213204 0.03906665 0.0348965
  0.02893988 0.02513975 0.02862244 0.02935296 0.03279071 0.009016
  0.00650725 0.01733246]
 [0.02985636 0.02608876 0.02541752 0.03795427 0.08186424 0.02590981
  0.01912756 0.02349559 0.02645606 0.04554083 0.03672075 0.03282263
  0.02636534 0.02894375 0.03802378 0.02641884 0.0585103  0.05737044
  0.04281178 0.03116381 0.04877423 0.02631062 0.02852403 0.02231033
  0.01450549 0.02200511]
 [0.03004532 0.03317557 0.03079742 0.04076978 0.05321904 0.03196292
  0.02615039 0.02586151 0.03318121 0.04309193 0.03440553 0.02687548
  0.02890704 0.03163083 0.03505311 0.02332576 0.03905397 0.03777378
  0.03345603 0.02998147 0.03505208 0.04618106 0.04273569 0.01399963
  0.01033313 0.02179015]]

-* TASK 10/20 | SAMPLE 55/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 272/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's location in the context sentences provided (4 and 5). The context sentences only mention Fred and Mary's movements, but not Bill's.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' provided', ' (', '4', ' and', ' ', '5', ').', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' and', ' Mary', "'s", ' movements', ',', ' but', ' not', ' Bill', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 32), x_tokens=32, y_tokens=43, max_supp_attn=0.1163, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 32)
DEBUG result.interpretability.attn_scores 1376 
 [[0.0214481  0.02667587 0.02674204 ... 0.05630813 0.00961025 0.00980704]
 [0.02203629 0.02412857 0.02360709 ... 0.06415754 0.01642039 0.01741411]
 [0.02250072 0.02336014 0.02572423 ... 0.0603441  0.01941092 0.01918187]
 ...
 [0.02267076 0.02567452 0.02052449 ... 0.01182274 0.01394488 0.01357618]
 [0.02312702 0.02542087 0.020695   ... 0.01077805 0.01271825 0.01346845]
 [0.02320004 0.02256188 0.01880745 ... 0.01228179 0.01205856 0.01288569]]

-* TASK 10/20 | SAMPLE 55/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 273/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 7, Bill is either in the cinema or the school, but it doesn't specify which one. There is no additional information to determine his exact location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' school', ',', ' but', ' it', ' doesn', "'t", ' specify', ' which', ' one', '.', ' There', ' is', ' no', ' additional', ' information', ' to', ' determine', ' his', ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 38), x_tokens=38, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 38)
DEBUG result.interpretability.attn_scores 1596 
 [[0.02186164 0.03304197 0.03324843 ... 0.01749304 0.01463428 0.04279937]
 [0.02214312 0.02715372 0.02965096 ... 0.03198421 0.0270818  0.04022902]
 [0.02281928 0.0341897  0.03752663 ... 0.01616049 0.013404   0.03708972]
 ...
 [0.02296146 0.02959083 0.02765725 ... 0.016394   0.01488395 0.04145888]
 [0.0234635  0.02641239 0.02333172 ... 0.02069657 0.02344765 0.02657845]
 [0.02360282 0.02468748 0.02167161 ... 0.01882367 0.01843728 0.02649656]]

-* TASK 10/20 | SAMPLE 55/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 274/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 implies that Bill is in the kitchen, as it lists the kitchen as both options. Sentence 11 confirms that Mary is also in the kitchen. There is no information about Bill being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' implies', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', ',', ' as', ' it', ' lists', ' the', ' kitchen', ' as', ' both', ' options', '.', ' Sentence', ' ', '11', ' confirms', ' that', ' Mary', ' is', ' also', ' in', ' the', ' kitchen', '.', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 44), x_tokens=44, y_tokens=50, max_supp_attn=0.08, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 44)
DEBUG result.interpretability.attn_scores 2200 
 [[0.01836795 0.02550811 0.02490216 ... 0.01309739 0.02928702 0.00752555]
 [0.0187746  0.01953137 0.01929881 ... 0.02417458 0.02974042 0.01453466]
 [0.01915006 0.02856651 0.0294638  ... 0.01721317 0.02937396 0.01138667]
 ...
 [0.01934821 0.02546313 0.02690638 ... 0.00803144 0.01275978 0.00583725]
 [0.01969736 0.02178534 0.02122909 ... 0.00742294 0.00968693 0.00620104]
 [0.01963768 0.0230858  0.02311976 ... 0.00822559 0.01219233 0.00667191]]

-* TASK 10/20 | SAMPLE 55/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 275/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Mary being in the kitchen in the context sentences provided (13 and 14). Sentence 13 mentions Mary being either in the park or the cinema, but not the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', ' provided', ' (', '13', ' and', ' ', '14', ').', ' Sentence', ' ', '13', ' mentions', ' Mary', ' being', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', ',', ' but', ' not', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 50), x_tokens=50, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 50)
DEBUG result.interpretability.attn_scores 2350 
 [[0.0197448  0.02768386 0.02333216 ... 0.01907229 0.00930492 0.01223989]
 [0.02008646 0.02496594 0.02216548 ... 0.0244542  0.01053254 0.02196241]
 [0.02051325 0.029811   0.02865181 ... 0.01605864 0.00677733 0.01136467]
 ...
 [0.02078163 0.02781648 0.02571446 ... 0.01327899 0.00720619 0.01110166]
 [0.02122058 0.02115775 0.0193214  ... 0.01680525 0.01155778 0.01410969]
 [0.0211261  0.02387395 0.02120522 ... 0.01315709 0.00961049 0.01185974]]
Model's predictions for the sample 55:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Mary travelled   |
|          |                 |   to the park, which implies that she is   |
|          |                 |              now in the park.              |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Bill's    |
|          |                 |     location in the context sentences      |
|          |                 |      provided (4 and 5). The context       |
|          |                 |   sentences only mention Fred and Mary's   |
|          |                 |         movements, but not Bill's.         |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to sentence 7, Bill is either   |
|          |                 |    in the cinema or the school, but it     |
|          |                 |   doesn't specify which one. There is no   |
|          |                 |  additional information to determine his   |
|          |                 |              exact location.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  Sentence 10 implies that Bill is in the   |
|          |                 |  kitchen, as it lists the kitchen as both  |
|          |                 |  options. Sentence 11 confirms that Mary   |
|          |                 |    is also in the kitchen. There is no     |
|          |                 |    information about Bill being in the     |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no information about Mary being  |
|          |                 |  in the kitchen in the context sentences   |
|          |                 |     provided (13 and 14). Sentence 13      |
|          |                 |   mentions Mary being either in the park   |
|          |                 |    or the cinema, but not the kitchen.     |
+----------+-----------------+--------------------------------------------+

Metrics for sample 55:
+----------------------------+------------+
|           Metric           |   Before   |
+----------------------------+------------+
|    Exact-match accuracy    |    0.8     |
|    Soft-match accuracy     |    0.8     |
| Max attention distribution | 0.1 ± 0.05 |
+----------------------------+------------+

-* TASK 10/20 | SAMPLE 56/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 276/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 1, Fred is in the kitchen, and there is no information about Fred moving to the school. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Fred', ' moving', ' to', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.0284019  0.04979007 0.05448314 0.08416517 0.08057003 0.05465404
  0.0387454  0.03305457 0.03734348 0.05541635 0.04184132 0.02699023
  0.02857059 0.1293952  0.12924048 0.03968681 0.02855406 0.02103515
  0.02027043 0.02149604 0.02271484 0.04180096 0.06401203 0.01395178
  0.01010201 0.03248848]
 [0.02928043 0.03135321 0.03237582 0.06229432 0.05720438 0.04661154
  0.02723275 0.02402875 0.03007431 0.04768771 0.03625301 0.02902487
  0.02836761 0.13205461 0.15477313 0.0380901  0.0309729  0.02476167
  0.02244923 0.02238929 0.02143382 0.03569277 0.03797572 0.00959784
  0.0081016  0.02135464]
 [0.02976567 0.03517062 0.04143053 0.06454507 0.06364933 0.05932388
  0.03671044 0.03434128 0.03937874 0.05626661 0.04167376 0.04675653
  0.04570205 0.105274   0.09615131 0.03209703 0.02838661 0.02543077
  0.02165988 0.02253782 0.02031369 0.03233413 0.03518397 0.01361847
  0.01104894 0.02007177]
 [0.02878645 0.0412223  0.04846558 0.04936858 0.05155159 0.05371523
  0.04153056 0.04286231 0.04199712 0.04851773 0.04017723 0.04909565
  0.04518271 0.06175306 0.05568067 0.04101875 0.03508962 0.03239294
  0.02709182 0.02943826 0.0281195  0.03588571 0.05176749 0.03462608
  0.03358077 0.03411709]
 [0.029871   0.04485467 0.05416799 0.05959181 0.0522913  0.06771968
  0.05089885 0.05092694 0.05261932 0.05905565 0.04336854 0.05529265
  0.05363052 0.04890216 0.03170355 0.03076101 0.02813926 0.02829615
  0.02379642 0.02714798 0.02308896 0.03707676 0.03968513 0.0190742
  0.01856896 0.02616606]
 [0.02928945 0.05421745 0.06127868 0.0356985  0.02677239 0.04310665
  0.04969122 0.04526472 0.04627773 0.03487465 0.03246565 0.0382264
  0.03985549 0.02202594 0.01879713 0.04383906 0.03468409 0.03058576
  0.02840575 0.03258299 0.03165643 0.03539727 0.07105747 0.04191247
  0.04171472 0.03688961]
 [0.02992393 0.07157832 0.0724494  0.03298473 0.02489082 0.03696196
  0.0495047  0.04066866 0.04866315 0.03101111 0.02961585 0.02999596
  0.03079083 0.01863827 0.01723574 0.04988698 0.03524845 0.02940389
  0.02855364 0.03491971 0.0302656  0.03189853 0.07179745 0.03470344
  0.03076599 0.03091786]
 [0.03003842 0.03810993 0.04499893 0.02527431 0.01993606 0.02718418
  0.03772427 0.03104844 0.03697187 0.02526329 0.02475918 0.02346684
  0.02355406 0.01556659 0.01493112 0.04049168 0.03020305 0.02450279
  0.02629753 0.03069697 0.02973697 0.03064456 0.0585931  0.0511776
  0.0484622  0.03789183]
 [0.03021988 0.01509662 0.01666423 0.01345787 0.01112535 0.01515324
  0.01634423 0.01562211 0.01763982 0.01419746 0.01585038 0.01354887
  0.01439188 0.00780262 0.00770738 0.01865809 0.01805613 0.01795699
  0.02103191 0.02476328 0.02869824 0.01947912 0.03695224 0.06579269
  0.0786308  0.05181899]
 [0.03024071 0.02396167 0.02490406 0.01958635 0.01580306 0.02202778
  0.02495189 0.02222193 0.02324106 0.02024115 0.02406976 0.02016205
  0.01992775 0.01143033 0.01223431 0.03316068 0.02586039 0.02467333
  0.02406209 0.02608732 0.02800107 0.0289018  0.03067681 0.05971143
  0.06015428 0.04030329]
 [0.03019858 0.02803181 0.02757743 0.02441581 0.01937388 0.02724878
  0.0371043  0.03516684 0.02816054 0.02660097 0.03151529 0.03117842
  0.03406563 0.01453456 0.01286349 0.03375646 0.02956423 0.03042482
  0.02690662 0.02826224 0.03156577 0.03251213 0.02410827 0.05092376
  0.03884059 0.02448549]
 [0.02998125 0.02249501 0.01832012 0.01773269 0.01313469 0.01775668
  0.02928646 0.02687342 0.01907336 0.01790995 0.0262071  0.02020469
  0.02421855 0.00920556 0.00924819 0.02969545 0.02788967 0.03675745
  0.03758395 0.03813795 0.04765175 0.0288792  0.01840945 0.07053344
  0.04969689 0.03179535]
 [0.03048308 0.02357701 0.02063242 0.01877125 0.01585954 0.02024807
  0.03088378 0.03023584 0.02054978 0.02051056 0.0360637  0.02745806
  0.02831318 0.01047492 0.00984257 0.02933185 0.02994036 0.02994355
  0.02917802 0.02640736 0.0365098  0.02835616 0.01831335 0.06271096
  0.03660863 0.02153572]
 [0.03047959 0.018711   0.0159574  0.01330193 0.01279442 0.01499072
  0.0252947  0.02174311 0.01733825 0.01519878 0.03900048 0.02019028
  0.02260383 0.00754088 0.00791414 0.02858509 0.03392958 0.03120032
  0.0338314  0.02921061 0.03815983 0.02512459 0.01615887 0.06649377
  0.03701532 0.02775528]
 [0.0292237  0.03462148 0.02558388 0.02097699 0.02616179 0.02187837
  0.03717724 0.03149189 0.02744449 0.02260818 0.03766767 0.02329869
  0.02712709 0.01179784 0.01428924 0.02806209 0.05199146 0.04280508
  0.06116325 0.04921213 0.04889733 0.03260148 0.03531371 0.06063734
  0.05087028 0.0537906 ]
 [0.03084969 0.01971676 0.01725492 0.01552374 0.0134252  0.0168532
  0.02148945 0.02152846 0.01821724 0.01735557 0.03440985 0.02075959
  0.02091427 0.00861021 0.00864441 0.02353456 0.03029732 0.02965509
  0.03017145 0.02702752 0.0301826  0.02604151 0.0160952  0.03785044
  0.03323147 0.03023403]
 [0.03123511 0.02207095 0.02387847 0.02141588 0.01750306 0.02618884
  0.02670655 0.03315363 0.02733872 0.0264141  0.02594873 0.03219094
  0.02921012 0.01281903 0.01025584 0.0203159  0.02457955 0.02248551
  0.02383643 0.02186406 0.02234902 0.02886668 0.01698174 0.01817488
  0.02298523 0.02245588]
 [0.03102987 0.02358558 0.02293752 0.0193677  0.01556769 0.02333
  0.02639084 0.03024292 0.02598522 0.02146983 0.02266533 0.02844475
  0.02746614 0.01152593 0.00969448 0.02066945 0.02654875 0.02452737
  0.02884403 0.02803051 0.02757651 0.03036192 0.01892119 0.01973902
  0.03111918 0.03309955]
 [0.03121045 0.02556111 0.02449887 0.02035964 0.01688574 0.02693383
  0.03093692 0.03665405 0.03010004 0.02423239 0.03122494 0.04272508
  0.03403841 0.01185616 0.01021749 0.02448254 0.03107421 0.02904745
  0.03053735 0.0278197  0.027656   0.02656003 0.01872899 0.01749798
  0.01904473 0.02186724]
 [0.03143072 0.02557139 0.02535247 0.02110882 0.01710092 0.03014396
  0.02878527 0.03170181 0.03251404 0.02540967 0.02299149 0.03500028
  0.03160159 0.01269697 0.00959567 0.0190923  0.02424272 0.02208028
  0.0257226  0.02517417 0.02409481 0.02659028 0.02126607 0.01573621
  0.02244912 0.02673829]
 [0.03058592 0.04284658 0.03482318 0.02435311 0.01919096 0.03155622
  0.03862557 0.04475522 0.04030489 0.02898512 0.02963376 0.04352861
  0.04414063 0.01448845 0.01093049 0.0357203  0.02833196 0.03740389
  0.03162742 0.03742642 0.0317972  0.02968261 0.02609637 0.01928513
  0.02649956 0.02524043]
 [0.03134478 0.0326965  0.03455395 0.02722603 0.01961462 0.04932199
  0.03828797 0.04157679 0.04489136 0.03406643 0.02834317 0.06667175
  0.05147831 0.01665151 0.01107502 0.02518558 0.02434594 0.02618783
  0.0240095  0.02598881 0.02248149 0.02802329 0.02114113 0.01298448
  0.01531732 0.01740539]
 [0.03080475 0.02232881 0.02231443 0.01745135 0.01313873 0.01904074
  0.02595738 0.03012852 0.02598522 0.02036106 0.02506616 0.02501445
  0.03576539 0.0095941  0.00844324 0.03292172 0.02757841 0.03352834
  0.03141301 0.03481661 0.03617749 0.02879107 0.0155198  0.02772649
  0.02974244 0.02180815]
 [0.0305599  0.02263208 0.02044423 0.01704139 0.01227931 0.01669673
  0.02604387 0.02825684 0.02438017 0.01847212 0.02279707 0.02025394
  0.02810681 0.00890382 0.00837872 0.03917548 0.02808653 0.04245402
  0.0372095  0.04518641 0.04239935 0.02687396 0.01511377 0.02800752
  0.03899919 0.02938499]
 [0.03116643 0.01927385 0.0180644  0.01543693 0.01155573 0.01676336
  0.02260851 0.0243578  0.02382133 0.01752375 0.02282777 0.02037945
  0.02481386 0.0086197  0.0074902  0.03536701 0.02622438 0.03977801
  0.03129973 0.0370783  0.03352831 0.02307433 0.01195263 0.01945435
  0.03996826 0.02916288]
 [0.03110739 0.0174174  0.01581513 0.01253024 0.00990549 0.01343108
  0.0192586  0.01993039 0.02043687 0.01484061 0.02336498 0.01659482
  0.02113538 0.00735509 0.00652852 0.03072055 0.02878128 0.0317611
  0.03420764 0.03443124 0.03420122 0.02486733 0.01169315 0.02230642
  0.03125734 0.03463133]
 [0.0304103  0.01951116 0.01752775 0.01429065 0.01190676 0.01467778
  0.01948054 0.01966503 0.02267507 0.01609731 0.02026577 0.01659362
  0.02091994 0.00811182 0.00722222 0.02796542 0.02870266 0.027783
  0.04311254 0.0390072  0.0341294  0.02671491 0.01652946 0.0268864
  0.03161733 0.05492631]
 [0.0313828  0.02067968 0.01939073 0.01604463 0.01188793 0.01685724
  0.019765   0.02129612 0.0245574  0.01773709 0.01974007 0.01953328
  0.02158329 0.00961647 0.00773125 0.01996343 0.02157813 0.02140312
  0.03024337 0.02997727 0.02597883 0.02732903 0.01756796 0.01692442
  0.02535341 0.03923433]
 [0.03087421 0.02428978 0.02501571 0.02557816 0.01940884 0.02713875
  0.02610117 0.03094111 0.03418484 0.03077285 0.02507767 0.0366752
  0.03466888 0.01758251 0.01222872 0.02082206 0.0258949  0.02455157
  0.02370652 0.02416353 0.02431699 0.03192825 0.02288298 0.01620582
  0.0349254  0.03400112]
 [0.03010949 0.03532312 0.03333477 0.05304052 0.05546268 0.04707389
  0.02932084 0.02833939 0.03298998 0.05193122 0.03633487 0.03074844
  0.03170364 0.08800545 0.10189292 0.02907497 0.02746496 0.02371769
  0.02157402 0.0223801  0.02087775 0.03509863 0.03714564 0.00987041
  0.00856643 0.02094543]
 [0.02984445 0.03422655 0.03211739 0.05865132 0.1170677  0.04149754
  0.0246591  0.02557138 0.03083753 0.0589591  0.04118899 0.03370732
  0.02670527 0.08647774 0.10637134 0.03181217 0.04235253 0.03982179
  0.02998579 0.02661204 0.02704661 0.02969826 0.03437912 0.0088611
  0.00729623 0.01986936]
 [0.02986733 0.02593977 0.02448536 0.03729171 0.07157911 0.02450503
  0.01832083 0.02206272 0.02436302 0.04095571 0.03411566 0.02981339
  0.02427411 0.02881755 0.03620178 0.02468131 0.05089852 0.05666182
  0.05224578 0.03598446 0.03719867 0.02574306 0.02722076 0.0146985
  0.01504538 0.02400845]
 [0.03000242 0.03353777 0.02890106 0.0411228  0.05540081 0.02940906
  0.02418084 0.02428704 0.0296441  0.03905587 0.03347484 0.02647497
  0.02517219 0.03187093 0.03448519 0.02137412 0.03450736 0.03698138
  0.03797143 0.03374165 0.0311942  0.0471697  0.04075906 0.0123251
  0.01241984 0.02360471]]

-* TASK 10/20 | SAMPLE 56/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 277/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, Julie went back to the cinema, which implies that Julie is now in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Julie', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.1935, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.03019334 0.04677182 0.04904974 0.06817653 0.05924265 0.05151175
  0.03716691 0.04238744 0.0524728  0.05150942 0.03461113 0.03553291
  0.03692419 0.10682851 0.09945868 0.02995512 0.02537325 0.02087709
  0.02124642 0.02230169 0.01712616 0.03521835 0.05278182 0.02339315
  0.01601744 0.0346746  0.046725   0.04160209 0.09736719 0.01545785
  0.01530874 0.01126978]
 [0.03103161 0.04667374 0.04360313 0.0788477  0.07972822 0.08126309
  0.04278293 0.04301681 0.05313671 0.06790198 0.0495793  0.05262078
  0.05105264 0.15672629 0.12782887 0.03533965 0.02501628 0.02278904
  0.02186745 0.02262036 0.01745529 0.0384444  0.04244336 0.01831992
  0.01343636 0.02808914 0.04746128 0.03374449 0.08996026 0.0172368
  0.01692859 0.014014  ]
 [0.03159154 0.04410843 0.04831691 0.06756681 0.06060501 0.06053665
  0.03916387 0.04281301 0.05002477 0.05594845 0.03761262 0.04730299
  0.04528506 0.11206434 0.07794537 0.02910124 0.02423044 0.01983626
  0.02009986 0.02021882 0.01542142 0.03435693 0.03953044 0.02051753
  0.01607314 0.02568209 0.0401835  0.02894511 0.08140596 0.03071684
  0.02649921 0.01970795]
 [0.03038906 0.03856403 0.04116498 0.0369365  0.03152291 0.03445002
  0.03254937 0.03923861 0.03815005 0.0336272  0.0287521  0.03498018
  0.03487118 0.02841659 0.02676431 0.03078933 0.02873486 0.02446096
  0.02519694 0.02547353 0.02121534 0.03565593 0.04779084 0.03802256
  0.04327019 0.03999417 0.04570555 0.03669271 0.07590202 0.09502599
  0.05180037 0.03828135]
 [0.03154799 0.0301509  0.03381054 0.02820006 0.02175445 0.03016132
  0.02906663 0.03062725 0.03299879 0.02588401 0.02424251 0.02571762
  0.02631015 0.01782876 0.01896841 0.0231548  0.02025026 0.01828077
  0.02169717 0.02226901 0.01875999 0.03127351 0.0356517  0.02848112
  0.02863896 0.04189137 0.03497295 0.03783152 0.05663726 0.06755909
  0.04975621 0.04380581]
 [0.03142248 0.04454211 0.04700278 0.03004645 0.02223742 0.03353697
  0.03568623 0.03869715 0.04511787 0.02832046 0.02303047 0.02924433
  0.03012037 0.02224442 0.01998962 0.03002703 0.02429215 0.01918045
  0.02081771 0.02168664 0.01697604 0.03493951 0.05603397 0.03395724
  0.03231159 0.0380751  0.05522046 0.02510102 0.05067322 0.12066714
  0.04874786 0.04069771]
 [0.03149663 0.06109561 0.05301003 0.0280277  0.02086641 0.03034893
  0.03886739 0.03504681 0.04615159 0.02533902 0.0236095  0.02644021
  0.02728972 0.0164045  0.01781583 0.03996428 0.03323928 0.02791631
  0.02915081 0.0348509  0.0270027  0.03246636 0.074581   0.04841188
  0.04546227 0.05100313 0.05352136 0.02706688 0.02568409 0.08665743
  0.0294394  0.03225053]
 [0.03179901 0.03376594 0.03318792 0.02201884 0.01710477 0.02325853
  0.02813119 0.024905   0.03167961 0.02063497 0.01995047 0.02016835
  0.02009441 0.0142809  0.01589695 0.02729089 0.02442321 0.01968741
  0.02338529 0.02475671 0.01938237 0.02877454 0.04424223 0.03621029
  0.03553502 0.03834644 0.04230737 0.02096692 0.02220828 0.07194402
  0.02983126 0.02309466]
 [0.0320681  0.0219615  0.02549325 0.01899394 0.01489592 0.02061665
  0.0234881  0.02237354 0.02649591 0.01960269 0.02053277 0.01935158
  0.01981277 0.01228624 0.01357399 0.02134638 0.0204063  0.02019821
  0.02372051 0.02483991 0.02115538 0.02614765 0.02888004 0.02861168
  0.02890129 0.03568118 0.03035709 0.02859864 0.01987117 0.03315049
  0.03333803 0.02638285]
 [0.03189805 0.0250739  0.02788595 0.02163965 0.01765352 0.02407847
  0.02439286 0.02338652 0.02688734 0.0216352  0.0220556  0.02230004
  0.02173116 0.01420074 0.01527355 0.02535781 0.02756095 0.02349428
  0.02737454 0.03063093 0.02801985 0.03171629 0.03376371 0.03624539
  0.04688891 0.03616478 0.03369864 0.02409985 0.02769104 0.05004682
  0.0407035  0.03200688]
 [0.03184728 0.02884372 0.03108173 0.02609943 0.02215086 0.02817817
  0.03000547 0.02991996 0.03029772 0.02851708 0.0275924  0.03197803
  0.03241783 0.01818541 0.01707466 0.03124048 0.03646372 0.03470892
  0.03364423 0.03609141 0.03622404 0.03383785 0.03028785 0.036251
  0.06209151 0.03076424 0.02936596 0.02893511 0.02714526 0.0437622
  0.04691834 0.04343504]
 [0.03161579 0.02483484 0.02266388 0.01942484 0.01546891 0.02101272
  0.02316606 0.02062929 0.02150684 0.0207055  0.02272459 0.02134069
  0.02369384 0.01175883 0.01347297 0.03108563 0.03220204 0.04291695
  0.03709927 0.06424949 0.06862675 0.03105957 0.02380266 0.03550279
  0.07518289 0.03497877 0.02721377 0.02555395 0.01588038 0.02606031
  0.03249441 0.04419141]
 [0.03257816 0.02418968 0.02416672 0.02022631 0.0181088  0.02497206
  0.02668118 0.02491498 0.024688   0.0244542  0.02908251 0.02931386
  0.02810632 0.0137105  0.01449313 0.03004861 0.02929071 0.03492752
  0.03555806 0.05849114 0.0657683  0.02779538 0.02142267 0.02941463
  0.04056153 0.02717009 0.02979073 0.02481396 0.01564552 0.0212115
  0.03264916 0.04671263]
 [0.03334422 0.01949886 0.01928627 0.01494351 0.0141931  0.01994958
  0.02115206 0.0194225  0.02049692 0.01914746 0.02607775 0.02371795
  0.02232634 0.01054136 0.01168181 0.0282186  0.02809895 0.03021603
  0.03493035 0.04018583 0.05315543 0.02583421 0.01679273 0.02703173
  0.0331444  0.02710882 0.02578371 0.0234422  0.01304563 0.01606216
  0.02700588 0.03969557]
 [0.03278792 0.02046277 0.02065825 0.01423899 0.01463972 0.01943816
  0.02407594 0.01991201 0.02086023 0.01830539 0.03580518 0.02497126
  0.02366904 0.01033922 0.01201994 0.03579751 0.03732299 0.0364539
  0.04606608 0.0463713  0.04847627 0.02883733 0.01937371 0.03384494
  0.0387926  0.03491531 0.02568459 0.02576984 0.01249986 0.01792608
  0.02866192 0.03671459]
 [0.03138033 0.048882   0.03880671 0.02373381 0.02346129 0.03077141
  0.07169449 0.04980599 0.04138959 0.02777546 0.05694152 0.0353428
  0.04829462 0.01419145 0.01619792 0.06495581 0.05126767 0.06494417
  0.05546026 0.06244741 0.05354408 0.03422924 0.03965685 0.0741023
  0.06321271 0.07006913 0.029281   0.04511501 0.01787963 0.02196517
  0.03530607 0.04752197]
 [0.03284013 0.02580947 0.02687763 0.0209416  0.01989008 0.02613666
  0.02807837 0.0281877  0.02602231 0.02543519 0.0292608  0.03055221
  0.02958718 0.01575162 0.0151181  0.03104343 0.02812598 0.02922188
  0.0344963  0.02992525 0.03058243 0.03232706 0.02335976 0.02989894
  0.02539037 0.02727075 0.0234333  0.0307351  0.02305918 0.02351784
  0.05551181 0.04694569]
 [0.03293591 0.02708141 0.03195368 0.02781871 0.0247821  0.03248772
  0.03253915 0.04094889 0.03243003 0.03645476 0.03272028 0.04340398
  0.03910652 0.02190288 0.01737511 0.02507734 0.02655736 0.0272995
  0.02633082 0.02314479 0.02133089 0.03454694 0.02406185 0.02525245
  0.02183723 0.02590092 0.02572707 0.03394331 0.0300936  0.0260949
  0.06387565 0.04931331]
 [0.03333043 0.03453216 0.03904501 0.03351086 0.02711386 0.03942665
  0.04004989 0.05024955 0.03493213 0.04324261 0.0387854  0.05460637
  0.04892522 0.02489312 0.01911497 0.03109425 0.02779808 0.02937677
  0.02861058 0.0249179  0.02237036 0.03641121 0.02684836 0.0261256
  0.02013208 0.02247744 0.03140486 0.02568454 0.02750238 0.02509675
  0.04146476 0.04784189]
 [0.0333565  0.03181054 0.03331327 0.02938502 0.02572381 0.03583837
  0.03587877 0.03867517 0.03298365 0.03752979 0.03478288 0.04505864
  0.04472176 0.02221073 0.01803201 0.03371964 0.02915354 0.03120963
  0.03034211 0.02764183 0.02471367 0.03473386 0.02256219 0.03024426
  0.02623396 0.02144132 0.02674652 0.02808688 0.02301635 0.02395431
  0.03283885 0.0427168 ]
 [0.03332428 0.02491146 0.02448768 0.01971785 0.01623577 0.02373382
  0.02811074 0.02786203 0.02520269 0.02367839 0.02932459 0.02917656
  0.03167563 0.01341078 0.01282497 0.0356556  0.03352435 0.03355329
  0.03274675 0.02944836 0.03032026 0.03156088 0.01664085 0.03446611
  0.03587462 0.02382648 0.02239968 0.03003275 0.0155483  0.02050969
  0.02872807 0.03689997]
 [0.03328189 0.02731127 0.025912   0.02209425 0.01664777 0.02387418
  0.03134472 0.03032156 0.02485019 0.02354802 0.02877991 0.02735555
  0.03198208 0.01348513 0.01357399 0.0397332  0.03597366 0.04233145
  0.03511065 0.03231491 0.03750029 0.02834147 0.01743479 0.03720627
  0.03837125 0.02468864 0.02184748 0.0303251  0.01321408 0.018929
  0.02459357 0.03531308]
 [0.03335894 0.02650214 0.02546983 0.02252514 0.01827325 0.02416741
  0.02851286 0.02950038 0.02418844 0.0253091  0.03088504 0.03027937
  0.03074566 0.01465381 0.01478468 0.03613599 0.03994415 0.03750791
  0.03919873 0.03163597 0.0351443  0.03058646 0.01952376 0.04081045
  0.02820145 0.02150477 0.02443859 0.03730564 0.0164146  0.02198246
  0.03026805 0.03458743]
 [0.03357852 0.02901229 0.02704155 0.02307454 0.01740079 0.0253459
  0.03218815 0.03202185 0.02789726 0.02539459 0.03283641 0.02984194
  0.03214681 0.01466194 0.01494641 0.03732835 0.03473498 0.03693669
  0.03550196 0.03128982 0.03431709 0.03076864 0.02034408 0.04075149
  0.03013119 0.02506502 0.02462266 0.03247038 0.01540439 0.01945252
  0.02736779 0.03405989]
 [0.03351731 0.02236913 0.02250684 0.01669726 0.01354914 0.02025393
  0.02951986 0.02590399 0.02183555 0.01809808 0.03803789 0.024562
  0.0274208  0.01128717 0.01162999 0.03817504 0.04012008 0.03466552
  0.042792   0.03391791 0.03639035 0.02901525 0.0170601  0.04058024
  0.03185521 0.02744143 0.01854841 0.02989628 0.01361354 0.01736559
  0.02805666 0.03108949]
 [0.03225078 0.02326715 0.02287326 0.01721434 0.01200675 0.02070698
  0.02968003 0.02684904 0.0252481  0.01791    0.02978095 0.02136182
  0.02776444 0.01103044 0.01175352 0.03478159 0.03474467 0.0349039
  0.04360134 0.03546967 0.03514036 0.0314455  0.02052869 0.04080765
  0.03634358 0.04716936 0.021182   0.03565624 0.01501503 0.01457508
  0.03317954 0.03023779]
 [0.03342232 0.02462643 0.02627429 0.02595077 0.01863332 0.02867431
  0.03105847 0.03424562 0.02783455 0.02760876 0.03178957 0.03139274
  0.0325684  0.01901138 0.01680091 0.02776937 0.02712494 0.02930208
  0.03408496 0.0258598  0.02658472 0.03087146 0.01866253 0.0215114
  0.01845209 0.02052007 0.01874664 0.02784335 0.02154218 0.01523574
  0.03956286 0.03249948]
 [0.03210379 0.03446167 0.03565914 0.0555534  0.05297442 0.04658376
  0.03227164 0.03320267 0.03688494 0.0516633  0.03640711 0.03812844
  0.03810038 0.07284037 0.09843695 0.02620785 0.02714279 0.02803165
  0.02442233 0.02267384 0.02018112 0.03374973 0.0373778  0.0182736
  0.01457822 0.02810227 0.03163141 0.04016974 0.0440373  0.01060485
  0.01548969 0.01067337]
 [0.03177298 0.04084431 0.03818546 0.07266647 0.15151772 0.05425368
  0.0336569  0.03439147 0.03701253 0.06876116 0.05083878 0.04869009
  0.03497923 0.09509292 0.12861453 0.03471207 0.04479738 0.04393417
  0.03138249 0.02749623 0.03015395 0.03263789 0.04515894 0.01759909
  0.01306622 0.02953993 0.0457905  0.03878681 0.0416126  0.00835724
  0.00918562 0.00758699]
 [0.03194087 0.03105198 0.02823997 0.04352276 0.07710563 0.02790856
  0.02534193 0.02755833 0.02627749 0.04209705 0.0374147  0.03277808
  0.02702224 0.0318901  0.04708944 0.02993929 0.05980531 0.05715961
  0.04687942 0.0352639  0.05209013 0.02960256 0.0377243  0.02645969
  0.02189024 0.02925656 0.03616232 0.04719617 0.02347116 0.01084187
  0.01268802 0.01089319]
 [0.03199386 0.03698868 0.03297165 0.05020597 0.05451162 0.0365235
  0.03369779 0.03298488 0.03404547 0.04396072 0.03615522 0.03248851
  0.03125404 0.03786942 0.04144849 0.02495365 0.04227974 0.04367766
  0.03718474 0.03151489 0.03487075 0.04281403 0.04567641 0.02169459
  0.01812148 0.03118657 0.03004559 0.05358848 0.02695853 0.00803227
  0.0118001  0.00955895]]

-* TASK 10/20 | SAMPLE 56/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 278/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie's location in the context sentences. Julie was mentioned in context sentence 5, but it didn't mention the office. 

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Julie', ' was', ' mentioned', ' in', ' context', ' sentence', ' ', '5', ',', ' but', ' it', ' didn', "'t", ' mention', ' the', ' office', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 38), x_tokens=38, y_tokens=39, max_supp_attn=0.0513, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 38)
DEBUG result.interpretability.attn_scores 1482 
 [[0.02380257 0.02815501 0.02666538 ... 0.01544437 0.00941763 0.01391068]
 [0.02412834 0.021716   0.02079624 ... 0.01441285 0.01266518 0.01545376]
 [0.02485423 0.0287411  0.02881749 ... 0.01198921 0.00803639 0.01004368]
 ...
 [0.02553412 0.02404644 0.02056209 ... 0.01184141 0.01013911 0.01251786]
 [0.02577488 0.02617324 0.0246527  ... 0.01254027 0.008844   0.01275828]
 [0.0259237  0.02239845 0.02200904 ... 0.01162658 0.00770589 0.01171135]]

-* TASK 10/20 | SAMPLE 56/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 279/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 11, Fred went to the cinema, which implies that Fred is now in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' went', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Fred', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.1333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03140176 0.04083686 0.04593998 ... 0.01546946 0.01035039 0.00510115]
 [0.03153941 0.03027845 0.03538372 ... 0.02797815 0.01260314 0.00793948]
 [0.03279654 0.04174999 0.05148532 ... 0.0255466  0.0146823  0.00629626]
 ...
 [0.0330103  0.04997679 0.04480841 ... 0.00691919 0.00548004 0.0046485 ]
 [0.03334628 0.03651633 0.03020187 ... 0.01002044 0.00842377 0.00950581]
 [0.03311535 0.04593605 0.03680737 ... 0.00673733 0.00575643 0.00563934]]

-* TASK 10/20 | SAMPLE 56/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 280/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred's location in the context sentences. The context sentences mention Bill's movements, but not Fred's.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' mention', ' Bill', "'s", ' movements', ',', ' but', ' not', ' Fred', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 50), x_tokens=50, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 50)
DEBUG result.interpretability.attn_scores 1700 
 [[0.02739814 0.03229246 0.03074389 ... 0.02520909 0.01480587 0.02926826]
 [0.02807415 0.03836377 0.02878233 ... 0.03061478 0.02574678 0.02354609]
 [0.02857104 0.03639022 0.03587289 ... 0.02231483 0.01396096 0.02372104]
 ...
 [0.02927262 0.02617322 0.02584431 ... 0.03104344 0.02074254 0.03791514]
 [0.02967496 0.03270498 0.03045998 ... 0.01968888 0.01298716 0.0244774 ]
 [0.02945392 0.02812625 0.02740867 ... 0.02057728 0.01112867 0.02540518]]
Model's predictions for the sample 56:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to context sentence 1, Fred is  |
|          |                 |      in the kitchen, and there is no       |
|          |                 |    information about Fred moving to the    |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 5, Julie   |
|          |                 |   went back to the cinema, which implies   |
|          |                 |      that Julie is now in the cinema.      |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information about Julie's    |
|          |                 |  location in the context sentences. Julie  |
|          |                 |  was mentioned in context sentence 5, but  |
|          |                 |       it didn't mention the office.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 11, Fred   |
|          |                 |   went to the cinema, which implies that   |
|          |                 |         Fred is now in the cinema.         |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Fred's    |
|          |                 |   location in the context sentences. The   |
|          |                 |      context sentences mention Bill's      |
|          |                 |         movements, but not Fred's.         |
+----------+-----------------+--------------------------------------------+

Metrics for sample 56:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.11 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 57/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 281/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 2, Bill journeyed to the kitchen, which implies that Bill is now in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 26), x_tokens=26, y_tokens=30, max_supp_attn=0.1333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 26)
DEBUG result.interpretability.attn_scores 780 
 [[0.03131693 0.05477686 0.05840094 0.08729773 0.07550617 0.0628152
  0.04374602 0.03791966 0.04233418 0.05872803 0.03879085 0.03083899
  0.03254361 0.12987424 0.13102202 0.03510442 0.03171948 0.02262226
  0.0255091  0.02768303 0.02654945 0.04714666 0.07951782 0.01067011
  0.0090536  0.02953154]
 [0.03233865 0.03421765 0.03475313 0.06310889 0.05398217 0.05286353
  0.03090585 0.02795055 0.03430162 0.05125652 0.03350195 0.03308681
  0.03265666 0.13748014 0.15684296 0.03351749 0.03426554 0.02618915
  0.02820636 0.02893034 0.02519215 0.03936164 0.04701597 0.00886192
  0.00707377 0.01930796]
 [0.03283666 0.03823609 0.04518718 0.06707727 0.05861775 0.06640917
  0.04103342 0.0391699  0.04503551 0.06039151 0.03925294 0.05308852
  0.05093114 0.10827866 0.09455701 0.02849034 0.03134666 0.02666123
  0.02726125 0.02860709 0.02382048 0.03557856 0.04330195 0.01438579
  0.00994659 0.01866606]
 [0.03162614 0.05077411 0.05852264 0.05227527 0.05147787 0.06017482
  0.04844957 0.05062433 0.04809735 0.05191092 0.03965325 0.05658893
  0.05142935 0.0652656  0.05461851 0.04043572 0.0400581  0.03377597
  0.03279265 0.03463631 0.03194139 0.03990423 0.05888085 0.03349698
  0.03253736 0.03667533]
 [0.03289765 0.0529873  0.06117968 0.0612177  0.0524209  0.07176987
  0.05661188 0.06036624 0.05892926 0.06200504 0.04159684 0.06070672
  0.05989881 0.04879472 0.0308859  0.02803633 0.03202257 0.02962778
  0.0303275  0.03315653 0.0273521  0.04094864 0.04649628 0.02601406
  0.0174373  0.02508748]
 [0.03223114 0.06450085 0.0665865  0.03599192 0.02808998 0.04516395
  0.05506466 0.05112337 0.05156788 0.03565411 0.03196123 0.04228615
  0.04418502 0.02172985 0.01828106 0.04794325 0.04177848 0.03248881
  0.03467038 0.03608388 0.03417393 0.03878502 0.0805139  0.04248947
  0.03805026 0.0406499 ]
 [0.03293237 0.0502988  0.05681212 0.02971757 0.02407918 0.03348438
  0.05615881 0.04172817 0.04851934 0.0287987  0.02610341 0.03019696
  0.03126458 0.01680517 0.01633786 0.04713695 0.03935586 0.02985699
  0.03506437 0.03744454 0.03529873 0.03414867 0.06964213 0.03020572
  0.03776989 0.04197145]
 [0.03342656 0.01968888 0.02286354 0.01450573 0.01244328 0.01751649
  0.0214357  0.02049111 0.02797192 0.01634341 0.0147855  0.01607557
  0.01651302 0.0081046  0.00854517 0.02174171 0.02377182 0.0197513
  0.02605843 0.02750144 0.02823123 0.02446815 0.04994747 0.0320533
  0.06605598 0.06932046]
 [0.03307816 0.03195001 0.03328987 0.0200822  0.01760189 0.02534284
  0.03218917 0.02721905 0.0284155  0.02060618 0.02310306 0.02360684
  0.02338008 0.01110845 0.01149935 0.0410102  0.02885895 0.0262057
  0.02873545 0.03044103 0.02937855 0.03256088 0.03732247 0.04034209
  0.06586906 0.05487886]
 [0.03326759 0.02892095 0.02969305 0.02258239 0.01923621 0.02830184
  0.0320759  0.03181159 0.02972795 0.02578645 0.02848078 0.03292596
  0.03218869 0.0126758  0.01113447 0.04130547 0.03141283 0.03143046
  0.02947583 0.02945902 0.02980044 0.03328334 0.02497747 0.03983603
  0.06291807 0.03448534]
 [0.03249805 0.02686467 0.02182816 0.01800008 0.01424064 0.01917586
  0.02829368 0.02704307 0.0236973  0.01876619 0.02658609 0.02252879
  0.02698056 0.00855466 0.00864459 0.05928008 0.02999982 0.04808529
  0.03801398 0.04328057 0.04810479 0.03121766 0.01900919 0.04602708
  0.11317489 0.05018191]
 [0.03384065 0.02597588 0.02438475 0.02153063 0.0189323  0.0257848
  0.0292839  0.0289749  0.02566433 0.02308225 0.02650629 0.02831123
  0.02805321 0.01075155 0.00987817 0.03795732 0.02226312 0.0353784
  0.02864023 0.0414022  0.0313196  0.02626411 0.02000453 0.03400877
  0.0742494  0.03100859]
 [0.03372236 0.02249828 0.01967721 0.01613028 0.01330283 0.01866081
  0.02462239 0.02408687 0.02225028 0.01795693 0.02923119 0.02523247
  0.02556876 0.00809638 0.00809688 0.04867919 0.02783192 0.04841008
  0.03632015 0.04720089 0.03746219 0.02507267 0.01511521 0.03664312
  0.06880479 0.03757855]
 [0.03356981 0.02213003 0.01916531 0.01450738 0.01227111 0.01714076
  0.02486177 0.02317283 0.02206587 0.0164583  0.03755905 0.02407297
  0.02375472 0.00741751 0.00785259 0.04126819 0.03139006 0.04331938
  0.03834786 0.04049488 0.03628381 0.02680215 0.01569016 0.04333927
  0.05025142 0.05802473]
 [0.03252542 0.03020014 0.02543367 0.01931189 0.01749363 0.0243093
  0.03362545 0.03034728 0.03094738 0.02150869 0.03469128 0.02502165
  0.02820438 0.0102919  0.01059037 0.02531871 0.03516627 0.03227408
  0.04291809 0.03932484 0.0400029  0.03154377 0.02876094 0.0877021
  0.04554816 0.07000607]
 [0.0341543  0.02782175 0.02596488 0.02007891 0.01596235 0.02258597
  0.02814771 0.02856122 0.02642854 0.02091923 0.03119023 0.02662879
  0.0270384  0.0103926  0.00977617 0.02742679 0.02675686 0.03163154
  0.03252959 0.03043073 0.03123537 0.03074809 0.0189293  0.03254503
  0.02270489 0.03747621]
 [0.03428895 0.02852779 0.03175321 0.02932584 0.02227921 0.03198261
  0.03176529 0.03855659 0.03188935 0.03275841 0.03226371 0.0426277
  0.03827887 0.01637428 0.0113816  0.02307855 0.02571489 0.02906757
  0.02808733 0.02734367 0.02647881 0.03305221 0.01949528 0.03122976
  0.0189757  0.02100063]
 [0.03448273 0.03406999 0.03549876 0.0340316  0.02401396 0.03622755
  0.03935309 0.04809495 0.03360884 0.03766394 0.0398682  0.04873116
  0.04734907 0.01790533 0.01231485 0.02448772 0.02516563 0.03031128
  0.0275618  0.02754587 0.02538    0.03333004 0.02030171 0.03040432
  0.01590969 0.01549982]
 [0.03438397 0.0309957  0.03086946 0.03050598 0.0227905  0.03273064
  0.03532214 0.04050813 0.0332583  0.03509462 0.03697468 0.04275296
  0.04469505 0.01665926 0.01246282 0.02941859 0.02677323 0.03264438
  0.03007575 0.02983186 0.0290626  0.03287927 0.01756733 0.0267784
  0.01926775 0.01435217]
 [0.03417443 0.02411341 0.02253709 0.0183556  0.01333544 0.02005523
  0.02625135 0.02835635 0.02643519 0.02099582 0.02699154 0.02653502
  0.03017747 0.00941985 0.00855421 0.03533031 0.02941925 0.03301013
  0.03234985 0.03033929 0.03554597 0.030943   0.01480683 0.03656864
  0.03181039 0.01998612]
 [0.03413648 0.02623153 0.02324892 0.01960652 0.01349196 0.01962925
  0.03013516 0.0302107  0.02662956 0.02093755 0.03012189 0.02555759
  0.0312304  0.00930545 0.0084943  0.04207597 0.03020152 0.03789313
  0.03464181 0.03318422 0.03994313 0.02832188 0.01398846 0.0401855
  0.03376394 0.02186261]
 [0.03428613 0.02502988 0.0220194  0.01941394 0.01504802 0.01973432
  0.02583915 0.02829725 0.02608963 0.02245782 0.03024289 0.02794983
  0.02898652 0.01004323 0.00880031 0.03170937 0.03343523 0.03381817
  0.03698733 0.03125368 0.036899   0.02800349 0.01385779 0.04041084
  0.02380747 0.02076315]
 [0.03445799 0.0275421  0.0247199  0.02028465 0.01489672 0.02175343
  0.02987593 0.03121667 0.03113344 0.02316551 0.03373364 0.02908879
  0.03136317 0.01052275 0.00908436 0.03369203 0.03032497 0.03523483
  0.03416152 0.03296979 0.03583436 0.02901881 0.0157484  0.03566633
  0.02474201 0.02202408]
 [0.03452152 0.02227678 0.02034655 0.01424073 0.01204546 0.0161038
  0.02561495 0.02476847 0.02507289 0.01685461 0.04112188 0.02323106
  0.02549383 0.00808267 0.00704019 0.03161703 0.03474543 0.03301468
  0.03951795 0.034201   0.03669097 0.02709165 0.01422292 0.03724751
  0.0219923  0.03318815]
 [0.03303644 0.02842719 0.02583642 0.01617143 0.01360022 0.01978228
  0.03141614 0.03126001 0.0312946  0.01909256 0.0394576  0.02485464
  0.02940716 0.00915201 0.00845092 0.02325655 0.03071558 0.02827773
  0.03837524 0.03675101 0.04444043 0.03158611 0.02638423 0.07877644
  0.03553778 0.06642697]
 [0.03445403 0.02650195 0.02654825 0.02415756 0.01792406 0.0268035
  0.0274576  0.03387081 0.03173983 0.0273417  0.03011031 0.03181027
  0.02985936 0.01485283 0.01163906 0.01891892 0.02880772 0.02744734
  0.03142378 0.02789811 0.03016452 0.02994252 0.01840736 0.02648574
  0.01376383 0.02506562]
 [0.03304366 0.03466897 0.03371678 0.05300772 0.05449999 0.04737378
  0.0296167  0.0297563  0.03573036 0.05184765 0.0350195  0.03607523
  0.03602578 0.09242088 0.10846748 0.02423443 0.03151066 0.02648291
  0.02888365 0.02834049 0.02659835 0.03807047 0.04153379 0.01108928
  0.00839875 0.02229832]
 [0.03293862 0.03612074 0.03380756 0.05761802 0.10859825 0.04502462
  0.02722172 0.02771941 0.03463222 0.05899945 0.04071128 0.03542018
  0.02968321 0.08792845 0.11086388 0.02933515 0.04469237 0.03695725
  0.03535362 0.03184675 0.03184164 0.03450605 0.03987763 0.00917056
  0.00666109 0.01856223]
 [0.03267403 0.0328591  0.0303025  0.04960884 0.10997561 0.03261644
  0.02314407 0.02738058 0.03065664 0.05450023 0.04198299 0.04079262
  0.03037991 0.04066067 0.05032462 0.02584999 0.07238092 0.05941939
  0.04873457 0.03711484 0.0482321  0.03052864 0.03498085 0.02192743
  0.01383303 0.02275739]
 [0.03285862 0.04079261 0.03505254 0.0502557  0.07184232 0.03868292
  0.0304808  0.02941354 0.0358749  0.04811772 0.038406   0.03337566
  0.0324792  0.04105045 0.04355815 0.02234335 0.04811426 0.03871276
  0.03897456 0.03530214 0.03674103 0.05489172 0.05370182 0.01543848
  0.01009081 0.02136231]]

-* TASK 10/20 | SAMPLE 57/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 282/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's location in the context sentences. Sentences 4 and 5 only mention Julie and Fred travelling to the park, but do not provide any information about Bill.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sent', 'ences', ' ', '4', ' and', ' ', '5', ' only', ' mention', ' Julie', ' and', ' Fred', ' travelling', ' to', ' the', ' park', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Bill', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0638, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01956752 0.02520947 0.02633344 ... 0.01103934 0.01149212 0.03161732]
 [0.02015803 0.02446938 0.02323314 ... 0.01723005 0.02115111 0.04159452]
 [0.02059486 0.02267939 0.02456163 ... 0.0232485  0.02046524 0.03523862]
 ...
 [0.02078397 0.02391531 0.01932499 ... 0.00909307 0.01208458 0.01393573]
 [0.02113311 0.02388781 0.01989203 ... 0.00769772 0.01116905 0.01348878]
 [0.02135439 0.0218673  0.01831316 ... 0.00790705 0.01149934 0.01564225]]

-* TASK 10/20 | SAMPLE 57/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 283/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 7, Bill is either in the bedroom or the cinema. Sentence 8 mentions Julie moving to the bedroom, but it does not provide any new information about Bill's location. Since Bill could be in either the bedroom or the cinema, and Julie's movement does not affect Bill's location, we cannot determine Bill's exact location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', '.', ' Sentence', ' ', '8', ' mentions', ' Julie', ' moving', ' to', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' Since', ' Bill', ' could', ' be', ' in', ' either', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' and', ' Julie', "'s", ' movement', ' does', ' not', ' affect', ' Bill', "'s", ' location', ',', ' we', ' cannot', ' determine', ' Bill', "'s", ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(77, 38), x_tokens=38, y_tokens=77, max_supp_attn=0.0, attn_on_target=0.013)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (77, 38)
DEBUG result.interpretability.attn_scores 2926 
 [[0.01173144 0.02112003 0.02086466 ... 0.00995777 0.0167384  0.01493329]
 [0.01194777 0.01620393 0.01632348 ... 0.0140816  0.01439804 0.01513443]
 [0.01226825 0.02164942 0.02411826 ... 0.00948032 0.01392351 0.01426219]
 ...
 [0.01241339 0.01882684 0.01688364 ... 0.00929052 0.01550366 0.01542035]
 [0.01270309 0.01618736 0.0133251  ... 0.0114318  0.01394934 0.01870096]
 [0.01272786 0.01545251 0.01282837 ... 0.01151247 0.01431088 0.01395062]]

-* TASK 10/20 | SAMPLE 57/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 284/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 mentions Mary going to the school, but sentence 11 overrides this information, stating that Mary is either in the park or the cinema. There is no information about Mary leaving the school or going back to the school, so we can conclude that Mary is no longer in the school. However, we cannot determine Mary's exact location between the park and the cinema.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' mentions', ' Mary', ' going', ' to', ' the', ' school', ',', ' but', ' sentence', ' ', '11', ' overrides', ' this', ' information', ',', ' stating', ' that', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', '.', ' There', ' is', ' no', ' information', ' about', ' Mary', ' leaving', ' the', ' school', ' or', ' going', ' back', ' to', ' the', ' school', ',', ' so', ' we', ' can', ' conclude', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', '.', ' However', ',', ' we', ' cannot', ' determine', ' Mary', "'s", ' exact', ' location', ' between', ' the', ' park', ' and', ' the', ' cinema', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(82, 44), x_tokens=44, y_tokens=82, max_supp_attn=0.0366, attn_on_target=0.0122)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (82, 44)
DEBUG result.interpretability.attn_scores 3608 
 [[0.01097564 0.02019562 0.01953889 ... 0.00848427 0.00643543 0.0069488 ]
 [0.01123969 0.01637715 0.01464389 ... 0.01646058 0.01100552 0.00804637]
 [0.01151247 0.02063747 0.02179394 ... 0.01226649 0.00897016 0.01081849]
 ...
 [0.01170665 0.01646299 0.01686687 ... 0.00530422 0.00477013 0.00558638]
 [0.01199963 0.01287673 0.01231975 ... 0.00486333 0.00611894 0.0045976 ]
 [0.01194522 0.01425467 0.01344234 ... 0.00480116 0.00508733 0.00499289]]

-* TASK 10/20 | SAMPLE 57/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 285/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 explicitly states that Mary is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 50), x_tokens=50, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 50)
DEBUG result.interpretability.attn_scores 950 
 [[0.04995134 0.06570832 0.07198527 0.09116433 0.07134447 0.07838043
  0.06168023 0.06986631 0.07981171 0.07858984 0.05080084 0.05824602
  0.06040918 0.12346623 0.12332982 0.04892692 0.03883255 0.04312562
  0.03765683 0.04998117 0.03856862 0.04998825 0.09741459 0.03366253
  0.04442704 0.07082443 0.07091209 0.08023357 0.1502482  0.02796087
  0.02576831 0.07964166 0.14066939 0.06279793 0.08163339 0.03663083
  0.07255564 0.05535553 0.02921134 0.15671219 0.07942329 0.03577335
  0.02223342 0.03637483 0.04707792 0.06601715 0.0760278  0.08639197
  0.03763782 0.03371354]
 [0.05060687 0.05163982 0.05612398 0.04505135 0.03133101 0.04724123
  0.04601334 0.05004522 0.05522458 0.03706496 0.03762246 0.0416807
  0.04569723 0.03002112 0.05892561 0.04445847 0.03184284 0.0324217
  0.03541549 0.04435248 0.03267511 0.05298422 0.06580078 0.02916859
  0.04857178 0.04815067 0.05996281 0.03084733 0.08070575 0.08716033
  0.03656657 0.02999741 0.03258587 0.03072027 0.05872958 0.04888438
  0.05268658 0.04100515 0.02951198 0.05785963 0.06277768 0.08713853
  0.05497194 0.04296466 0.03386439 0.03400248 0.03202657 0.06930371
  0.04085905 0.04407745]
 [0.05206283 0.06706072 0.0786726  0.1107261  0.08883445 0.10723772
  0.06474391 0.07304598 0.07709662 0.07781494 0.05467593 0.06781725
  0.06933127 0.17114878 0.10433448 0.04583748 0.02990084 0.03199978
  0.02854408 0.03596953 0.0298232  0.0520231  0.07273705 0.02812761
  0.03793875 0.05948215 0.07783287 0.05628251 0.1550394  0.05513527
  0.04230509 0.09491821 0.16944651 0.05271884 0.06101633 0.03166635
  0.05551019 0.05199511 0.02655577 0.0934475  0.11837193 0.05153215
  0.03481515 0.05176516 0.09136213 0.0797288  0.06331744 0.0652713
  0.03405063 0.02902292]
 [0.05066162 0.05468361 0.06432279 0.04952416 0.03812428 0.05515183
  0.05305061 0.06121438 0.06129445 0.04464978 0.04271019 0.05123211
  0.05096031 0.03648768 0.03171773 0.04851335 0.03252917 0.03251745
  0.0327856  0.03927834 0.03163359 0.05706508 0.06594513 0.0358375
  0.05400212 0.05908246 0.07055056 0.04373275 0.08857101 0.12525564
  0.06137724 0.04584264 0.0576389  0.03284442 0.06635934 0.05012086
  0.05596003 0.05735578 0.03226776 0.04894401 0.10496233 0.10196905
  0.05884481 0.05544821 0.05579885 0.05228988 0.03661657 0.06743407
  0.04925044 0.04496862]
 [0.05212577 0.05335286 0.05823182 0.03681708 0.02726798 0.04545472
  0.06261918 0.05655433 0.06586028 0.03452546 0.03911435 0.04132197
  0.04411688 0.02593024 0.02477273 0.05877036 0.0354385  0.03387897
  0.03759558 0.04441025 0.03375559 0.04856842 0.06335395 0.02940259
  0.05245538 0.04943613 0.05784526 0.03085843 0.03337605 0.11257619
  0.03783609 0.02283303 0.01895905 0.02648885 0.06207622 0.05397869
  0.04225723 0.04209672 0.02249724 0.03244492 0.03959433 0.07737077
  0.06594844 0.04831415 0.04873905 0.03057122 0.0322385  0.06464148
  0.04665898 0.04694592]
 [0.05332823 0.03142604 0.03118249 0.02263884 0.01727432 0.02838921
  0.03689972 0.03778737 0.04465237 0.0247928  0.02961597 0.02901737
  0.03566463 0.01510912 0.01525964 0.037662   0.02618713 0.03052142
  0.03220756 0.03842341 0.03152012 0.03566033 0.03399207 0.0283676
  0.04114607 0.0473189  0.02949076 0.02785691 0.0177603  0.04889244
  0.02656084 0.01917424 0.0097546  0.01948748 0.03954991 0.04799411
  0.0401326  0.04173096 0.02981261 0.02923101 0.02650009 0.03943278
  0.06225032 0.04090165 0.02287828 0.02037784 0.02194375 0.05267494
  0.04581644 0.04605873]
 [0.05175465 0.0560324  0.05914322 0.04061627 0.02849724 0.04974938
  0.0539944  0.05483777 0.05627936 0.0418997  0.04328017 0.05187254
  0.04922335 0.02496256 0.02249707 0.05404173 0.03938621 0.03952303
  0.04713516 0.05946629 0.03872104 0.0614003  0.05494164 0.05821418
  0.07310541 0.0557932  0.05996281 0.03396535 0.03793301 0.081971
  0.0733753  0.03176318 0.01807035 0.02884428 0.06568421 0.06806843
  0.05398074 0.0549612  0.03777933 0.03561699 0.06601934 0.06385017
  0.11153691 0.06530342 0.06897463 0.04940298 0.03688018 0.06261735
  0.06657787 0.05218955]
 [0.05319792 0.06950945 0.07312921 0.05953676 0.03947    0.06939324
  0.06862555 0.07328215 0.06467365 0.06005526 0.06142005 0.08004262
  0.0706506  0.03533056 0.02783316 0.0568696  0.04433364 0.04791123
  0.04662028 0.04897373 0.04303956 0.05700586 0.05730907 0.07732091
  0.07314559 0.05603625 0.06770995 0.04694786 0.04436576 0.08118128
  0.10651856 0.0523838  0.03286094 0.0321933  0.06692921 0.06333888
  0.05282499 0.07029455 0.06653973 0.03978452 0.08304787 0.08277743
  0.1068716  0.07973185 0.08275446 0.06795587 0.04512115 0.05739263
  0.08010536 0.05748489]
 [0.05420434 0.050612   0.05280845 0.03987261 0.0299551  0.04970647
  0.05644341 0.05229173 0.05010206 0.04250194 0.05078936 0.05516712
  0.05420643 0.0246784  0.02229928 0.05270106 0.04394921 0.040005
  0.04588529 0.04578507 0.04042982 0.0529216  0.04288797 0.05871817
  0.05592383 0.04560676 0.05769032 0.03880328 0.03505213 0.07281353
  0.08922227 0.04966762 0.03233195 0.02877846 0.04717967 0.0613605
  0.0463127  0.06325939 0.06894478 0.03364423 0.06144123 0.0627927
  0.07430782 0.07581677 0.08033827 0.0525286  0.03626853 0.04396048
  0.06643745 0.04989795]
 [0.05351425 0.03811227 0.03470806 0.02471897 0.02039276 0.03078423
  0.0409072  0.03722286 0.03661943 0.02950541 0.04565573 0.03877566
  0.04342874 0.01536256 0.0160189  0.05411979 0.06224511 0.04392728
  0.05889119 0.05266381 0.04574245 0.05445113 0.0298202  0.05795018
  0.06281387 0.03886621 0.04131804 0.03569635 0.02282494 0.05030253
  0.06203034 0.04725267 0.01761541 0.02629849 0.03858802 0.06926163
  0.04638883 0.05820732 0.0777132  0.02772596 0.0408069  0.04476588
  0.0634004  0.05367208 0.04832377 0.03410733 0.02871158 0.03365761
  0.0630843  0.05388438]
 [0.05299953 0.0415744  0.03615579 0.02605003 0.02000026 0.03131863
  0.04709265 0.03915831 0.03666338 0.02988865 0.04597706 0.03792396
  0.04760029 0.01571072 0.01592426 0.06132434 0.06866444 0.05208829
  0.06630618 0.056511   0.05126846 0.05166438 0.026648   0.06469709
  0.06436062 0.03798043 0.03522363 0.03390987 0.01694933 0.04084546
  0.04990386 0.04795897 0.01129926 0.02327147 0.03351724 0.07282271
  0.04547531 0.04792602 0.06959615 0.02666315 0.03453382 0.04204268
  0.0632094  0.05282831 0.04081093 0.02789627 0.02704719 0.0284131
  0.06784169 0.04807183]
 [0.05419856 0.03638842 0.03341785 0.02472974 0.02095779 0.03101047
  0.03992953 0.03596136 0.03322558 0.03101311 0.05097298 0.04443388
  0.04344772 0.0158592  0.0152203  0.05192734 0.07222146 0.04867231
  0.07663817 0.05388613 0.04954274 0.04941498 0.02416508 0.08373782
  0.04720582 0.03257394 0.0348621  0.03468383 0.01698572 0.03650284
  0.06124515 0.06628149 0.01194463 0.02321366 0.03025408 0.05441147
  0.043323   0.04247963 0.09900792 0.02534373 0.03173891 0.04246806
  0.04494638 0.05554102 0.04398218 0.02633234 0.0282705  0.02528381
  0.07443735 0.05394007]
 [0.05398078 0.03531011 0.0324727  0.0224179  0.01903842 0.02818247
  0.0436466  0.03569639 0.03184851 0.02834726 0.05790454 0.04030961
  0.04481926 0.01392384 0.01421858 0.0611518  0.07709786 0.05036002
  0.07291345 0.05943163 0.05413731 0.05131197 0.02381502 0.08776076
  0.04779506 0.04010846 0.03057535 0.0375827  0.01574733 0.03055309
  0.05584785 0.06114776 0.00920974 0.02353388 0.02989111 0.06310394
  0.0522229  0.03978214 0.11744664 0.03023376 0.02768075 0.04922438
  0.04165465 0.05756607 0.04028239 0.02198638 0.02680253 0.02583441
  0.06884593 0.08336881]
 [0.05216714 0.04278254 0.03830488 0.02519319 0.01953012 0.03492286
  0.05438644 0.04397966 0.04172242 0.03180486 0.05428575 0.03878887
  0.05322405 0.01572864 0.01595935 0.06586126 0.07258186 0.06370097
  0.07960877 0.07168026 0.06998374 0.05668112 0.03826499 0.1490919
  0.10245337 0.09401669 0.03666976 0.05112557 0.02046387 0.03063939
  0.05251261 0.04521943 0.01748846 0.02855608 0.04889292 0.08573778
  0.06950365 0.04101087 0.04003407 0.04849996 0.03305472 0.05090204
  0.04891271 0.06779253 0.04077318 0.02617841 0.03081705 0.05013983
  0.0832883  0.15902336]
 [0.0546065  0.03992989 0.04072777 0.03390168 0.02422718 0.0402668
  0.04688453 0.04323658 0.03731285 0.03896853 0.0454568  0.04834688
  0.04786131 0.02291712 0.01791493 0.03840697 0.03419537 0.03416134
  0.04052981 0.03923906 0.03827564 0.04817912 0.02483995 0.03910145
  0.029281   0.03274678 0.03098853 0.03156026 0.02764228 0.0303235
  0.10603424 0.06582187 0.05856992 0.02386389 0.02976043 0.03754583
  0.0410392  0.03227834 0.04439323 0.03494363 0.04793779 0.05382004
  0.04309325 0.0764496  0.07048475 0.04897463 0.03018128 0.02904687
  0.03109322 0.04243434]
 [0.0529048  0.05407413 0.05657781 0.07894226 0.06398616 0.07045813
  0.05513179 0.05812112 0.06299382 0.08145363 0.05757938 0.06522471
  0.06219834 0.11825919 0.11482057 0.04321914 0.03818382 0.04558253
  0.03821573 0.04314864 0.0425586  0.05085374 0.05502465 0.0281726
  0.03378062 0.05853696 0.05846503 0.07577846 0.07309245 0.02680316
  0.03567497 0.12399897 0.22141463 0.09299694 0.05005807 0.03470191
  0.05310182 0.05000629 0.0374787  0.08070648 0.05038357 0.03944669
  0.02681746 0.04044601 0.05515705 0.13385925 0.06942537 0.05217188
  0.03106344 0.0350503 ]
 [0.05267106 0.07378303 0.06574802 0.11385167 0.21789801 0.08830378
  0.0591683  0.05879507 0.05845241 0.1118982  0.08440284 0.07482455
  0.0603902  0.17190655 0.20224714 0.06477667 0.07075164 0.0894741
  0.05959747 0.0574468  0.08809443 0.05109888 0.07623045 0.02487865
  0.03357974 0.06095124 0.07561202 0.08278015 0.07539847 0.01831655
  0.02160385 0.03898209 0.05713107 0.15372053 0.06219238 0.03237732
  0.05712961 0.0559556  0.03161639 0.07248969 0.03326119 0.02246344
  0.02092892 0.03052752 0.04990939 0.11385175 0.11110748 0.06186077
  0.02969324 0.0295083 ]
 [0.05232327 0.06743939 0.05724916 0.07547718 0.14667432 0.05207029
  0.04865111 0.05618567 0.0463322  0.09359524 0.08126987 0.07306832
  0.05631831 0.05931519 0.09498516 0.06364278 0.11321328 0.1564174
  0.09991483 0.08714759 0.15778181 0.05188184 0.06712524 0.0497513
  0.05569618 0.05395684 0.05722549 0.10122751 0.04100054 0.02406927
  0.0293237  0.03885485 0.03764303 0.15757836 0.05883847 0.04518111
  0.0563891  0.08797677 0.07836457 0.04920607 0.02902471 0.0249521
  0.02671587 0.03118144 0.0326563  0.06678238 0.10661913 0.05478225
  0.04916108 0.04935688]
 [0.05274052 0.07058056 0.0590382  0.07876982 0.07519614 0.06197803
  0.06013145 0.06271782 0.05983436 0.08163051 0.06646571 0.06190593
  0.06045189 0.06388223 0.06172127 0.04778892 0.06844506 0.08371158
  0.06353848 0.07220478 0.08244818 0.06684566 0.07968415 0.0360385
  0.04231784 0.05853156 0.04710257 0.12612729 0.04684349 0.01869757
  0.026293   0.0382602  0.0453663  0.13209288 0.06884936 0.04281325
  0.0632059  0.06632262 0.06122858 0.07650254 0.02943953 0.02727775
  0.02854054 0.0373747  0.04583208 0.04715638 0.1605774  0.0691215
  0.03409744 0.04100209]]
Model's predictions for the sample 57:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Bill journeyed   |
|          |                 |  to the kitchen, which implies that Bill   |
|          |                 |           is now in the kitchen.           |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Bill's    |
|          |                 |     location in the context sentences.     |
|          |                 |  Sentences 4 and 5 only mention Julie and  |
|          |                 |  Fred travelling to the park, but do not   |
|          |                 |    provide any information about Bill.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to sentence 7, Bill is either   |
|          |                 |  in the bedroom or the cinema. Sentence 8  |
|          |                 |   mentions Julie moving to the bedroom,    |
|          |                 |      but it does not provide any new       |
|          |                 |  information about Bill's location. Since  |
|          |                 |   Bill could be in either the bedroom or   |
|          |                 |   the cinema, and Julie's movement does    |
|          |                 |   not affect Bill's location, we cannot    |
|          |                 |      determine Bill's exact location.      |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 10 mentions Mary going to the   |
|          |                 |   school, but sentence 11 overrides this   |
|          |                 |  information, stating that Mary is either  |
|          |                 |   in the park or the cinema. There is no   |
|          |                 |     information about Mary leaving the     |
|          |                 |   school or going back to the school, so   |
|          |                 |   we can conclude that Mary is no longer   |
|          |                 |     in the school. However, we cannot      |
|          |                 |  determine Mary's exact location between   |
|          |                 |          the park and the cinema.          |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 14 explicitly states that Mary   |
|          |                 |             is in the office.              |
+----------+-----------------+--------------------------------------------+

Metrics for sample 57:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 58/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 286/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, "Bill went back to the kitchen", which implies that Bill was not in the kitchen previously, but now he is.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' "', 'Bill', ' went', ' back', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Bill', ' was', ' not', ' in', ' the', ' kitchen', ' previously', ',', ' but', ' now', ' he', ' is', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02174633 0.0402614  0.05078376 ... 0.02135676 0.00985692 0.02152884]
 [0.02167463 0.07047483 0.05235102 ... 0.03611391 0.01783737 0.02971105]
 [0.02369703 0.05038748 0.03261217 ... 0.00874406 0.00403593 0.01066235]
 ...
 [0.02339853 0.02460636 0.02486875 ... 0.00944767 0.00440047 0.01401483]
 [0.02337808 0.02015486 0.02012023 ... 0.01465668 0.00856365 0.01740173]
 [0.02353869 0.02523312 0.02389299 ... 0.01212806 0.00663746 0.01632248]]

-* TASK 10/20 | SAMPLE 58/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 287/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Context sentence 5 explicitly states "Bill is in the school", which contradicts the possibility mentioned in sentence 4.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Context', ' sentence', ' ', '5', ' explicitly', ' states', ' "', 'Bill', ' is', ' in', ' the', ' school', '",', ' which', ' contrad', 'icts', ' the', ' possibility', ' mentioned', ' in', ' sentence', ' ', '4', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.1935, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.02989385 0.04762046 0.0486643  0.06532893 0.06618192 0.05578006
  0.0400136  0.03771882 0.04935674 0.05418879 0.0366644  0.03772291
  0.03808515 0.10640232 0.10702935 0.03523376 0.02996931 0.02850078
  0.02490732 0.02884592 0.02594231 0.0350077  0.06099243 0.0214746
  0.01924682 0.04638416 0.04661746 0.05137446 0.11379806 0.01328638
  0.01428842 0.01151249]
 [0.03091473 0.04315536 0.04346868 0.07222485 0.08500194 0.07547133
  0.04225426 0.0387996  0.04910807 0.07077581 0.04910107 0.05670634
  0.05280104 0.15067244 0.13564163 0.03722905 0.03064283 0.03350873
  0.02649361 0.02902119 0.02635314 0.0363322  0.04045891 0.0173475
  0.01693228 0.03894545 0.05189766 0.04219708 0.08349736 0.01671093
  0.01835785 0.01815738]
 [0.03141737 0.04263866 0.04802739 0.06335672 0.06768487 0.06366578
  0.04294135 0.04059315 0.0476734  0.05851631 0.03965674 0.05437862
  0.04919061 0.10167045 0.08063193 0.03232484 0.02818457 0.02803225
  0.02389073 0.02562485 0.02330543 0.034809   0.0408631  0.02098929
  0.01903908 0.03528017 0.04527553 0.03637002 0.05633827 0.03060655
  0.02576269 0.0231933 ]
 [0.03020565 0.03771444 0.04169175 0.03397396 0.03637853 0.03856537
  0.0348249  0.03742054 0.03589639 0.03390801 0.03047066 0.03914174
  0.03643501 0.02810638 0.02883899 0.03361155 0.03057308 0.02846148
  0.02786242 0.02920665 0.02765197 0.03703996 0.04646972 0.03610711
  0.03245368 0.04229843 0.04332098 0.03940528 0.04104252 0.07939028
  0.03958761 0.0384558 ]
 [0.03133261 0.06138927 0.05417767 0.02791385 0.02683975 0.03469155
  0.03942806 0.0368724  0.04091453 0.02874635 0.02921428 0.03269529
  0.03197638 0.02146056 0.02237009 0.04395667 0.0346042  0.02912195
  0.03010626 0.03159621 0.029791   0.0328705  0.06383097 0.03702544
  0.03444796 0.03709453 0.04346685 0.03013018 0.03132083 0.09191759
  0.03642336 0.03196567]
 [0.03161006 0.03955558 0.04090293 0.02168522 0.02178768 0.02570421
  0.03559491 0.0283908  0.03178156 0.02122382 0.02455771 0.02449994
  0.02438197 0.01530707 0.01769743 0.03902979 0.03263813 0.02601079
  0.02805602 0.02919034 0.02789019 0.02849488 0.04754506 0.04093565
  0.03787042 0.03430368 0.03736982 0.0267967  0.02645461 0.07860792
  0.0370045  0.02761817]
 [0.0319971  0.01728611 0.0188801  0.01352992 0.0137257  0.01712405
  0.01828231 0.01612841 0.01818731 0.01476847 0.01917969 0.01656387
  0.01641229 0.00952022 0.01123375 0.0205703  0.01939304 0.01804961
  0.02188143 0.02188613 0.0213875  0.0204325  0.01885283 0.02461953
  0.02627178 0.02408479 0.02090201 0.01894446 0.0160694  0.03411056
  0.02302673 0.02027449]
 [0.03154215 0.02828    0.03011869 0.02169205 0.02054026 0.02631498
  0.02861572 0.02487923 0.02500144 0.02182057 0.02613176 0.02641723
  0.02402212 0.01469483 0.01710661 0.0340891  0.03235318 0.0274209
  0.03285924 0.03324393 0.03401558 0.03630957 0.03565694 0.04950057
  0.04788853 0.03982444 0.03725313 0.03110234 0.02806638 0.05565849
  0.05160991 0.03604513]
 [0.03216655 0.0455412  0.04906986 0.0390548  0.0317369  0.0448837
  0.04659679 0.04528234 0.03862332 0.04162874 0.04289503 0.05748894
  0.04648321 0.02656253 0.02533058 0.04366926 0.03773596 0.03809802
  0.03739296 0.03626018 0.03599413 0.03799765 0.03805793 0.04993435
  0.0397262  0.03664361 0.04405029 0.03712399 0.0330602  0.04138774
  0.04764263 0.05752895]
 [0.03269723 0.03155762 0.03418403 0.02609195 0.02279166 0.03072429
  0.03544937 0.03001778 0.02700997 0.02615245 0.03360032 0.03129847
  0.03131324 0.01700887 0.01881935 0.0400396  0.03307053 0.03094165
  0.03380504 0.03255203 0.03357336 0.03430417 0.02943292 0.05255397
  0.04166854 0.02872198 0.03176872 0.03097176 0.02572931 0.04919524
  0.05434588 0.04906848]
 [0.03254372 0.02305074 0.02279214 0.01881799 0.01606563 0.0210676
  0.02540705 0.02027914 0.02038925 0.01763896 0.03501246 0.02233582
  0.02161631 0.01108137 0.01548837 0.0375032  0.03461416 0.03204345
  0.03774603 0.03772143 0.03810678 0.02841704 0.02202417 0.04939443
  0.05032251 0.02575594 0.02046442 0.02373954 0.01829231 0.0341828
  0.04727633 0.02858818]
 [0.03199434 0.02110067 0.01940551 0.01730126 0.01255674 0.01914742
  0.02455919 0.02041085 0.02009807 0.01630608 0.02644534 0.0176201
  0.02286377 0.0099549  0.0120304  0.0479959  0.03727301 0.04170189
  0.0511843  0.05240016 0.05418913 0.02336823 0.01690516 0.06704573
  0.07722615 0.03205516 0.01427988 0.03345439 0.01543342 0.02304147
  0.04017298 0.03329464]
 [0.03279468 0.01940271 0.01991142 0.01680251 0.0134742  0.01919205
  0.02433918 0.02191    0.01953908 0.01678086 0.02792922 0.02080027
  0.02360231 0.01038957 0.01182515 0.03694496 0.04575833 0.03897839
  0.0669568  0.04801947 0.04770355 0.02366143 0.0148963  0.06266022
  0.04457686 0.02347848 0.01395898 0.02559035 0.01483606 0.01628764
  0.03966157 0.03016445]
 [0.03250324 0.01720518 0.01738887 0.01513775 0.01143808 0.0167601
  0.02150114 0.01915575 0.01849549 0.0146465  0.02612766 0.01711399
  0.02149979 0.00945219 0.01036578 0.03895517 0.03970602 0.03591559
  0.05019671 0.04174343 0.04356884 0.02581256 0.01382745 0.07564757
  0.04617297 0.03211305 0.01270457 0.0350828  0.01605563 0.01261079
  0.03738771 0.03992358]
 [0.03232969 0.02132011 0.0228005  0.01940783 0.01406773 0.02299057
  0.02498058 0.02485793 0.02340524 0.0180201  0.02503935 0.02036687
  0.02370683 0.01192189 0.01158511 0.02399822 0.02355833 0.02415935
  0.0280654  0.02737142 0.02729106 0.02949509 0.01831145 0.02398116
  0.03194126 0.02918052 0.01610315 0.02232764 0.01886449 0.0169314
  0.02600431 0.02292925]
 [0.0328773  0.02028671 0.02131485 0.02145065 0.01431118 0.0219001
  0.02399395 0.02366481 0.02080584 0.02008041 0.02851129 0.02123366
  0.02362801 0.01351648 0.01372054 0.02610959 0.02516041 0.02545384
  0.03268781 0.03094302 0.03098284 0.02837974 0.01629147 0.03629324
  0.02989679 0.02932524 0.01600105 0.03114193 0.02105449 0.01538756
  0.05872736 0.03552663]
 [0.03250222 0.02835781 0.03313599 0.03592568 0.02378155 0.03595493
  0.03416827 0.0396034  0.03312483 0.03745802 0.03819131 0.04354269
  0.03913213 0.02488378 0.02106089 0.02674741 0.02755623 0.03063408
  0.02862401 0.02864619 0.02851643 0.03662888 0.02412944 0.02204298
  0.02739875 0.03161642 0.02837014 0.0374576  0.02991186 0.02486036
  0.05616116 0.05122388]
 [0.03281541 0.03467805 0.04063813 0.04796391 0.02875717 0.04538292
  0.04239472 0.05446316 0.03898252 0.05483128 0.04207111 0.05894318
  0.05243434 0.03222946 0.02205293 0.02577851 0.02598536 0.02973028
  0.02488429 0.02553212 0.0245044  0.0354991  0.02584072 0.01870577
  0.02354697 0.03013721 0.03395665 0.0309903  0.02981315 0.02215155
  0.04738199 0.07819272]
 [0.03365258 0.02991414 0.03128658 0.03674325 0.0248982  0.04202086
  0.03566092 0.03924121 0.04024715 0.04091002 0.03348964 0.04097483
  0.04187208 0.02478001 0.0178389  0.02430664 0.02617267 0.03217267
  0.02872977 0.03069541 0.02668338 0.03061716 0.02304946 0.01672528
  0.02366468 0.02733417 0.02624056 0.02491052 0.0247421  0.01670236
  0.0232923  0.03540458]
 [0.03266275 0.02790803 0.02578854 0.02328166 0.01636943 0.02501673
  0.02704354 0.03274103 0.02843188 0.02243909 0.02707045 0.02751555
  0.02896398 0.01690972 0.01422671 0.02436688 0.02461376 0.0238412
  0.02442631 0.02569211 0.02497158 0.03390826 0.02494058 0.02220911
  0.03065503 0.02936942 0.03302313 0.02557772 0.02550635 0.04035174
  0.02945173 0.04635787]
 [0.03239369 0.03675263 0.03288095 0.02429054 0.01874155 0.02666918
  0.03354549 0.04291935 0.03457012 0.02512447 0.0336987  0.03307894
  0.03668176 0.01834865 0.01498683 0.03261391 0.0366978  0.03108977
  0.03041072 0.02847093 0.02720904 0.03677685 0.02717192 0.0257163
  0.03592116 0.0350471  0.04154147 0.02550695 0.02475016 0.03074087
  0.03627332 0.05037034]
 [0.03335796 0.03049309 0.02743447 0.02559548 0.01894677 0.02535559
  0.02970897 0.03694213 0.0303639  0.02612631 0.03316377 0.03166106
  0.03325297 0.0181757  0.01519614 0.02747755 0.0324196  0.03035599
  0.02902229 0.02797263 0.02672902 0.03539291 0.02084222 0.01933337
  0.02650895 0.02623276 0.03130196 0.02334192 0.02034531 0.02146927
  0.0289051  0.05041341]
 [0.0336931  0.03297855 0.03252277 0.02589837 0.02032699 0.0281515
  0.03598753 0.03985133 0.03658078 0.02564499 0.03122489 0.03214039
  0.03416628 0.01897126 0.01612557 0.02872336 0.02891986 0.0267166
  0.02648593 0.02740199 0.02542734 0.03450013 0.02794413 0.02010018
  0.02767401 0.02821012 0.03596954 0.0192351  0.02240905 0.03378146
  0.0270398  0.03696888]
 [0.03296271 0.03233734 0.03129773 0.02049187 0.01805144 0.021168
  0.03135223 0.03182489 0.03269337 0.01913737 0.02356777 0.02090264
  0.02518733 0.01582937 0.01508076 0.02929763 0.02781129 0.02422207
  0.02431715 0.02642273 0.02423907 0.03522207 0.03934093 0.0279329
  0.03364298 0.03165908 0.03661134 0.02112044 0.02392614 0.0589736
  0.02274003 0.02596373]
 [0.03270327 0.04797219 0.04894582 0.02742649 0.02363266 0.02775407
  0.05436462 0.03924314 0.04202401 0.02378069 0.02727541 0.02481088
  0.02902052 0.01981986 0.02043991 0.04517485 0.03471446 0.02915974
  0.02736692 0.03149634 0.02775325 0.03430318 0.05423074 0.03783917
  0.03889699 0.03724992 0.04927215 0.02513797 0.02663728 0.05232519
  0.02126709 0.01836159]
 [0.0330767  0.02203291 0.02246881 0.02032107 0.01781604 0.0246207
  0.027228   0.02658369 0.02920766 0.02278974 0.02359237 0.02451525
  0.02882861 0.01731788 0.01493465 0.02199298 0.02285094 0.0257531
  0.02456447 0.02846175 0.02367346 0.02875575 0.02530212 0.02341278
  0.02861401 0.02916986 0.02644476 0.02360307 0.02545934 0.02462009
  0.0227351  0.02086479]
 [0.03316602 0.02172475 0.02116433 0.01831014 0.01629298 0.01888666
  0.02343378 0.02504387 0.02568582 0.0191635  0.0252525  0.02043479
  0.02369827 0.01449421 0.01300738 0.02538332 0.0277887  0.02475408
  0.0262821  0.02867371 0.02532035 0.03105659 0.02183228 0.02295285
  0.02870403 0.02553048 0.03001838 0.02129904 0.01856161 0.02577597
  0.03188761 0.02896629]
 [0.03236635 0.03128059 0.03020509 0.04323607 0.03869633 0.03624359
  0.02979866 0.03148981 0.03552657 0.04313368 0.03290142 0.03360131
  0.03906187 0.05875856 0.07132372 0.0262754  0.02718493 0.03330847
  0.02801338 0.03248783 0.02920614 0.03343054 0.03720044 0.01784743
  0.01859245 0.03498616 0.03699058 0.04306731 0.04684625 0.01207941
  0.01494424 0.01633622]
 [0.03147867 0.04102008 0.03596793 0.07338403 0.15185586 0.04984661
  0.03310718 0.03573351 0.04122484 0.07670847 0.05270008 0.04892813
  0.03928292 0.09057757 0.1193137  0.03622533 0.05312579 0.06554385
  0.04042226 0.04082938 0.04985756 0.03192599 0.05038175 0.01797587
  0.01886943 0.03875502 0.04559643 0.0576202  0.05327791 0.00898798
  0.01148554 0.00991389]
 [0.03213533 0.03098178 0.02530215 0.03806186 0.05922049 0.02591198
  0.02364871 0.0267309  0.02846376 0.04180079 0.0366521  0.02970359
  0.02734125 0.02982203 0.04307555 0.02930205 0.05089868 0.06278332
  0.04731495 0.04284497 0.06752618 0.02845385 0.0339744  0.02354892
  0.02286144 0.03009151 0.02685318 0.04693151 0.03080573 0.00987362
  0.01606144 0.0139072 ]
 [0.03221298 0.03446328 0.02816197 0.04529937 0.04802988 0.03303352
  0.02977497 0.03120703 0.03658716 0.04574936 0.03861147 0.03286272
  0.03305763 0.04135998 0.0416214  0.02507325 0.03802489 0.04353595
  0.03504337 0.03874553 0.04063596 0.0407966  0.03940211 0.01814662
  0.01876729 0.02912111 0.02237521 0.05844746 0.03709434 0.00799318
  0.01309373 0.01250803]]

-* TASK 10/20 | SAMPLE 58/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 288/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill in the provided context sentences. The sentences only talk about Julie and Fred.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' provided', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', ' and', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 38), x_tokens=38, y_tokens=29, max_supp_attn=0.1034, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 38)
DEBUG result.interpretability.attn_scores 1102 
 [[0.03209835 0.03603439 0.03117658 ... 0.03852868 0.02400497 0.02384883]
 [0.0329918  0.02619353 0.0233448  ... 0.03533836 0.04284463 0.05106469]
 [0.03362023 0.03713241 0.03756526 ... 0.02618299 0.01726777 0.01572444]
 ...
 [0.03429905 0.03138721 0.02595067 ... 0.03103913 0.03780294 0.03766424]
 [0.03474082 0.03652337 0.03296109 ... 0.03189828 0.02626039 0.02373043]
 [0.03484851 0.02831953 0.02708181 ... 0.03441695 0.02225856 0.02257464]]

-* TASK 10/20 | SAMPLE 58/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 289/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, "Bill journeyed to the office", which implies that Bill has moved to the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' "', 'Bill', ' journey', 'ed', ' to', ' the', ' office', '",', ' which', ' implies', ' that', ' Bill', ' has', ' moved', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 44), x_tokens=44, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 44)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02918728 0.03548232 0.04206173 ... 0.12116489 0.02278777 0.0156992 ]
 [0.02971988 0.03254809 0.03995126 ... 0.06139437 0.04865835 0.02783292]
 [0.0304699  0.03678944 0.04933178 ... 0.08513807 0.04026737 0.01920494]
 ...
 [0.03067122 0.04373425 0.03931579 ... 0.0494133  0.01062698 0.00951284]
 [0.03104405 0.03582947 0.02981672 ... 0.02537379 0.00962796 0.01517672]
 [0.03092792 0.04190157 0.03309903 ... 0.04152745 0.00759947 0.01124808]]

-* TASK 10/20 | SAMPLE 58/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 290/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred in the provided context sentences. The sentences only talk about Mary's movements.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' provided', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03251826 0.04165114 0.03727708 ... 0.03725713 0.02446921 0.01644716]
 [0.03280414 0.03682867 0.03179136 ... 0.04438165 0.09229729 0.0758893 ]
 [0.03386185 0.04306763 0.04149435 ... 0.03717361 0.02089506 0.01453265]
 ...
 [0.03447688 0.03031724 0.02845677 ... 0.03305658 0.02870321 0.02708257]
 [0.03456616 0.04046105 0.03639276 ... 0.03786757 0.02149506 0.01842988]
 [0.03475302 0.03275352 0.0299083  ... 0.03290148 0.02029182 0.01696209]]
Model's predictions for the sample 58:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 2, "Bill   |
|          |                 |  went back to the kitchen", which implies  |
|          |                 |      that Bill was not in the kitchen      |
|          |                 |         previously, but now he is.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    Context sentence 5 explicitly states    |
|          |                 |       "Bill is in the school", which       |
|          |                 |  contradicts the possibility mentioned in  |
|          |                 |                sentence 4.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |     There is no mention of Bill in the     |
|          |                 |      provided context sentences. The       |
|          |                 |    sentences only talk about Julie and     |
|          |                 |                   Fred.                    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 10, "Bill   |
|          |                 |  journeyed to the office", which implies   |
|          |                 |     that Bill has moved to the office.     |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |     There is no mention of Fred in the     |
|          |                 |      provided context sentences. The       |
|          |                 |      sentences only talk about Mary's      |
|          |                 |                 movements.                 |
+----------+-----------------+--------------------------------------------+

Metrics for sample 58:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.15 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 59/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 291/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence "Fred is either in the cinema or the cinema" implies that Fred is definitely in the cinema, as the two options are the same.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' cinema', '"', ' implies', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' cinema', ',', ' as', ' the', ' two', ' options', ' are', ' the', ' same', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02172082 0.0423467  0.05349888 ... 0.02346051 0.00660609 0.01971896]
 [0.02162448 0.06123099 0.04877673 ... 0.06384479 0.01827783 0.0267045 ]
 [0.02369141 0.05495115 0.03436885 ... 0.00898972 0.0021959  0.00791235]
 ...
 [0.02337032 0.02637669 0.02718814 ... 0.01059351 0.00238743 0.01114575]
 [0.02319548 0.02268802 0.02302808 ... 0.01875529 0.0067801  0.01609293]
 [0.02347645 0.02833126 0.02696879 ... 0.01420904 0.0045188  0.01354099]]

-* TASK 10/20 | SAMPLE 59/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 292/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred's location in the context sentences. The sentences only mention Julie and Bill, but not Fred.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Julie', ' and', ' Bill', ',', ' but', ' not', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 32), x_tokens=32, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 32)
DEBUG result.interpretability.attn_scores 1056 
 [[0.0281952  0.03299731 0.03530929 ... 0.01264866 0.01736639 0.01191614]
 [0.02902756 0.0324825  0.03375448 ... 0.01629709 0.02719305 0.01703337]
 [0.02965373 0.03017335 0.03467603 ... 0.02236426 0.03339161 0.01966057]
 ...
 [0.02976339 0.03055732 0.02404885 ... 0.01620518 0.02045038 0.02222576]
 [0.03026556 0.03224011 0.02633931 ... 0.01295487 0.01766103 0.01759442]
 [0.03046209 0.02915445 0.02506683 ... 0.01171192 0.01656586 0.01582593]]

-* TASK 10/20 | SAMPLE 59/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 293/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence "Mary is either in the park or the kitchen" does not mention the cinema as a possible location for Mary.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' kitchen', '"', ' does', ' not', ' mention', ' the', ' cinema', ' as', ' a', ' possible', ' location', ' for', ' Mary', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.02824993 0.04026486 0.04280147 ... 0.02747211 0.01051915 0.02497463]
 [0.02881407 0.0350245  0.03384213 ... 0.03287924 0.02066851 0.03212983]
 [0.02944374 0.04514485 0.051312   ... 0.02359644 0.00876976 0.01874441]
 ...
 [0.02965108 0.03863168 0.03634415 ... 0.02221098 0.00949563 0.01579828]
 [0.03005407 0.02936519 0.02644599 ... 0.02676772 0.01797504 0.02255628]
 [0.03007152 0.0301942  0.0278611  ... 0.02330972 0.01362257 0.01909882]]

-* TASK 10/20 | SAMPLE 59/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 294/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence "Mary is in the bedroom" explicitly states that Mary is in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Mary', ' is', ' in', ' the', ' bedroom', '"', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 44), x_tokens=44, y_tokens=26, max_supp_attn=0.0769, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 44)
DEBUG result.interpretability.attn_scores 1144 
 [[0.03617743 0.04383767 0.05183202 ... 0.13561088 0.01857895 0.02648327]
 [0.03681717 0.03711066 0.04044636 ... 0.0834311  0.04068697 0.03845019]
 [0.03770057 0.04664302 0.05452746 ... 0.10396204 0.02971979 0.03739512]
 ...
 [0.03790954 0.05174742 0.04662128 ... 0.04975663 0.01103146 0.01475305]
 [0.03801182 0.04398707 0.03811752 ... 0.02835711 0.01500478 0.01415029]
 [0.03825717 0.0487408  0.04050145 ... 0.0370874  0.01222125 0.01439801]]

-* TASK 10/20 | SAMPLE 59/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 295/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence "Fred is in the office" explicitly states that Fred is in the office, and there is no mention of Fred being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Fred', ' is', ' in', ' the', ' office', '"', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 50), x_tokens=50, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 50)
DEBUG result.interpretability.attn_scores 1900 
 [[0.02443214 0.03767258 0.03705642 ... 0.03721778 0.01380568 0.01801245]
 [0.02499737 0.03812051 0.03401108 ... 0.02953169 0.02168457 0.01982662]
 [0.02540059 0.03940669 0.04289848 ... 0.03213276 0.01427708 0.01565074]
 ...
 [0.0255938  0.03948135 0.03398116 ... 0.02655337 0.01150929 0.01460501]
 [0.02618715 0.02917055 0.0242095  ... 0.02726479 0.01706247 0.01722756]
 [0.02601335 0.03147843 0.02573685 ... 0.02626742 0.01358269 0.01622883]]
Model's predictions for the sample 59:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |       yes       |  The context sentence "Fred is either in   |
|          |                 |   the cinema or the cinema" implies that   |
|          |                 |  Fred is definitely in the cinema, as the  |
|          |                 |         two options are the same.          |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |    There is no information about Fred's    |
|          |                 |   location in the context sentences. The   |
|          |                 |   sentences only mention Julie and Bill,   |
|          |                 |               but not Fred.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence "Mary is either in   |
|          |                 |     the park or the kitchen" does not      |
|          |                 |      mention the cinema as a possible      |
|          |                 |             location for Mary.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    The context sentence "Mary is in the    |
|          |                 |  bedroom" explicitly states that Mary is   |
|          |                 |              in the bedroom.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentence "Fred is in the    |
|          |                 |   office" explicitly states that Fred is   |
|          |                 |   in the office, and there is no mention   |
|          |                 |        of Fred being in the school.        |
+----------+-----------------+--------------------------------------------+

Metrics for sample 59:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.05 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 60/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 296/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentences only mention Mary being in the bedroom or the bedroom, which is the same location. There is no mention of Mary being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' being', ' in', ' the', ' bedroom', ' or', ' the', ' bedroom', ',', ' which', ' is', ' the', ' same', ' location', '.', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0952, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02192206 0.04062008 0.04662716 ... 0.0103459  0.01404486 0.02751691]
 [0.02177962 0.0450099  0.03440039 ... 0.02496096 0.03434858 0.04039817]
 [0.02386133 0.05256871 0.03274965 ... 0.00294065 0.00512144 0.01384103]
 ...
 [0.02347357 0.02552808 0.02525594 ... 0.0035996  0.00548407 0.01840287]
 [0.02318009 0.02159032 0.02205485 ... 0.00903956 0.01110316 0.02094867]
 [0.02354471 0.02632444 0.02525311 ... 0.00615549 0.00920662 0.01934173]]

-* TASK 10/20 | SAMPLE 60/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 297/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Julie went back to the park, which implies that Julie is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.03011542 0.04287948 0.0460638  0.05868074 0.06218798 0.05511903
  0.03772211 0.03544785 0.04342465 0.0525534  0.03154342 0.037409
  0.03718714 0.09460721 0.10319509 0.02983671 0.02601992 0.02123734
  0.02178105 0.02129686 0.01921326 0.03313875 0.05280856 0.01250494
  0.01492906 0.04042673 0.0392362  0.0428851  0.10861111 0.04154336
  0.00976439 0.01448673]
 [0.03082203 0.04508199 0.04689218 0.07792135 0.09143603 0.09361244
  0.04724807 0.04663011 0.0535293  0.08157449 0.05074338 0.06863534
  0.06593094 0.13887443 0.11416384 0.03187019 0.02697114 0.02706712
  0.0247052  0.02396486 0.0210205  0.03746464 0.04067822 0.01381989
  0.01614954 0.03719462 0.04193455 0.03577808 0.08504605 0.05627443
  0.01201622 0.02129709]
 [0.03150758 0.04026044 0.04894193 0.06297888 0.06645228 0.06514653
  0.04078654 0.03926823 0.04500723 0.05807803 0.03659698 0.05246539
  0.04722644 0.10445189 0.08028655 0.02929401 0.02534236 0.02170562
  0.0215146  0.02030692 0.01778974 0.03359757 0.0373854  0.01457319
  0.01552103 0.03375924 0.04017236 0.03011904 0.05806495 0.06518739
  0.01332721 0.02694211]
 [0.03025673 0.04714273 0.05030021 0.03639054 0.03469234 0.0404131
  0.04129703 0.04127137 0.03868947 0.03519765 0.03063929 0.03970687
  0.03866224 0.02871103 0.02806159 0.03956779 0.03327237 0.02866456
  0.02801139 0.02795467 0.0253681  0.03619695 0.0576811  0.03176634
  0.02996043 0.04752618 0.05203959 0.03779817 0.04244412 0.08597897
  0.02948135 0.04818181]
 [0.0307624  0.05295811 0.05530477 0.02700603 0.02192353 0.03429088
  0.04165268 0.03874876 0.04052116 0.02581071 0.02608487 0.03076149
  0.03233139 0.02080706 0.02040843 0.0379472  0.02956787 0.02456234
  0.02706269 0.02691117 0.02359626 0.03523455 0.06073853 0.03677313
  0.03255122 0.04464473 0.06140121 0.02899417 0.02975456 0.08641074
  0.03610696 0.04653759]
 [0.03157926 0.06377919 0.06102132 0.02756519 0.02030821 0.03436263
  0.03984836 0.0347534  0.04152388 0.02463231 0.02383964 0.027582
  0.02919245 0.01740545 0.01863646 0.04161533 0.03369241 0.02736517
  0.03118472 0.03409397 0.02755075 0.03138961 0.08409165 0.03315596
  0.02814248 0.04627857 0.06063026 0.02834262 0.02604566 0.08230028
  0.02941244 0.03637972]
 [0.03166985 0.04782672 0.05184745 0.02882724 0.02085097 0.03176497
  0.03916925 0.03501769 0.03843618 0.02564717 0.02524646 0.02858525
  0.02732664 0.01959793 0.02069163 0.04356586 0.03567731 0.02591388
  0.02827783 0.02795629 0.02517701 0.03252911 0.0653533  0.03502594
  0.03202502 0.04728225 0.0696064  0.0323641  0.0293506  0.07035629
  0.03639496 0.04123583]
 [0.03216108 0.02737569 0.03232216 0.02042182 0.0170294  0.02364692
  0.0264133  0.02551961 0.03327604 0.02043619 0.02086079 0.01942677
  0.02037164 0.0140998  0.01726411 0.03436529 0.03309432 0.02376791
  0.02854278 0.02880262 0.02366395 0.02793415 0.04701593 0.02575239
  0.02285492 0.03948658 0.04243017 0.02514359 0.02558741 0.02887369
  0.02068694 0.02204661]
 [0.03156026 0.03518166 0.03667632 0.02739901 0.01925788 0.03118951
  0.03336844 0.03114445 0.03123502 0.02517222 0.02811162 0.02943859
  0.02856003 0.0183075  0.01970546 0.0405693  0.03595574 0.03294447
  0.03230155 0.03476827 0.03066696 0.03553329 0.04051801 0.03726177
  0.03406221 0.03697356 0.03962168 0.02633188 0.02760976 0.04425025
  0.03437724 0.03607361]
 [0.03265294 0.03415276 0.03858093 0.032427   0.02305351 0.03749623
  0.03753049 0.0356611  0.03298298 0.03139583 0.03333925 0.03750141
  0.03646863 0.02262584 0.02004575 0.03718751 0.03172963 0.03043453
  0.02853227 0.02833118 0.02656512 0.03592326 0.02933729 0.03757289
  0.03500864 0.03126656 0.0327106  0.02708224 0.02682582 0.0404186
  0.03737202 0.04193358]
 [0.03219863 0.02399667 0.02299082 0.02001311 0.01343939 0.02115615
  0.0246427  0.02148233 0.02181071 0.01850279 0.02712756 0.02086376
  0.0239642  0.01286244 0.01357857 0.0380578  0.03551061 0.03621731
  0.03167709 0.03473582 0.03456366 0.03285241 0.02169553 0.0378367
  0.03794658 0.02655307 0.02315624 0.02425572 0.02029799 0.02551884
  0.03597622 0.02634114]
 [0.03179179 0.02349829 0.02188859 0.02126618 0.01290033 0.02046646
  0.02378423 0.0214477  0.02128319 0.01881868 0.02560527 0.01954746
  0.0236662  0.01272471 0.01270601 0.03642736 0.0308047  0.04711626
  0.03165907 0.04475539 0.04786574 0.03039073 0.01926552 0.03951835
  0.05202604 0.02955395 0.02387213 0.02568567 0.01895859 0.02373748
  0.04843061 0.02607892]
 [0.03261674 0.02051533 0.020544   0.02116737 0.01402846 0.02199519
  0.02390994 0.02301522 0.02194469 0.0203757  0.02941365 0.02451848
  0.02555685 0.01339306 0.01239147 0.03221278 0.02711275 0.03978361
  0.03337634 0.05802394 0.05480732 0.02596874 0.01645244 0.04052137
  0.04016283 0.02174176 0.02182084 0.02388588 0.01775112 0.01506939
  0.04317076 0.02884516]
 [0.03336434 0.01712753 0.01682653 0.01755414 0.0110053  0.01810163
  0.01990272 0.01914745 0.01917308 0.01692785 0.0251239  0.02003023
  0.02060838 0.01133945 0.01046727 0.02644039 0.02359228 0.02862215
  0.02955077 0.03645118 0.04291    0.02484847 0.01383358 0.03648774
  0.03667494 0.01998468 0.0161901  0.0206922  0.01684945 0.01177498
  0.04036856 0.02659661]
 [0.03290584 0.01847797 0.01828476 0.01663792 0.01181481 0.01757595
  0.02258697 0.02028664 0.01999996 0.01644618 0.03288985 0.02165109
  0.02066136 0.01136203 0.01143888 0.0325099  0.02965451 0.0325954
  0.03752539 0.04038339 0.03794646 0.02784341 0.0167129  0.04493249
  0.05188536 0.02604233 0.0174842  0.02570169 0.01803547 0.01272673
  0.04843238 0.03035995]
 [0.03166096 0.03316769 0.03114325 0.02399912 0.01819829 0.02774695
  0.05780725 0.04937326 0.03495073 0.02496835 0.05594437 0.03572025
  0.04273823 0.01484041 0.01501752 0.04037153 0.03892532 0.04733521
  0.05491796 0.05095636 0.04511973 0.03348006 0.02730558 0.05624525
  0.06028626 0.04083075 0.02241282 0.04053924 0.02984482 0.01934576
  0.05217099 0.043822  ]
 [0.03297672 0.02415013 0.02384659 0.02234184 0.01588275 0.02270391
  0.02677508 0.02751911 0.02525638 0.02186103 0.03088086 0.02616103
  0.02675713 0.01651694 0.01431847 0.02824142 0.02601096 0.02703559
  0.03304985 0.03216195 0.02963812 0.03271156 0.01919392 0.0313872
  0.03180943 0.02553796 0.01916379 0.02365623 0.02333467 0.01933713
  0.04020601 0.04475383]
 [0.03305372 0.02514834 0.02917976 0.02913714 0.02204023 0.03026993
  0.03073631 0.03820559 0.03071587 0.03228972 0.03188802 0.04062338
  0.03782453 0.02250053 0.01618783 0.02349866 0.02468033 0.02712673
  0.02573571 0.02435272 0.02362437 0.03518468 0.02047113 0.02847024
  0.02745002 0.02661024 0.02077454 0.02954559 0.02664529 0.02706951
  0.0336334  0.0539146 ]
 [0.03331973 0.03243839 0.03645451 0.03919759 0.02502079 0.03767926
  0.03719017 0.04949174 0.03379101 0.04252573 0.04168606 0.05190058
  0.04744001 0.02781463 0.01857545 0.02574819 0.02406072 0.02657648
  0.02323787 0.02239068 0.02121107 0.03634753 0.02296736 0.02940606
  0.02689094 0.02346707 0.02427138 0.02461688 0.02790137 0.02928757
  0.03451505 0.06765687]
 [0.0334134  0.02941305 0.03013001 0.03197113 0.02209395 0.03295545
  0.03241953 0.03791031 0.03189233 0.03445611 0.03435174 0.04169358
  0.04205282 0.02362386 0.01744936 0.02920778 0.0262398  0.03011814
  0.02709271 0.02717732 0.02550295 0.03567391 0.02061254 0.03126939
  0.03013765 0.02374657 0.02085714 0.02682322 0.02516703 0.02327117
  0.03170225 0.03677586]
 [0.03334373 0.02294291 0.02205426 0.02043529 0.01488799 0.02051039
  0.02587215 0.02685929 0.02552643 0.02184759 0.02708315 0.02564432
  0.02961296 0.01503121 0.01267131 0.03255723 0.02913648 0.03229563
  0.02867713 0.02890161 0.02944859 0.03235298 0.01672453 0.03665781
  0.03445503 0.02455714 0.01781461 0.02885198 0.01997356 0.01864876
  0.03459279 0.03095416]
 [0.0332661  0.0252375  0.02352482 0.02203868 0.01627732 0.02098922
  0.02953905 0.02960792 0.02652705 0.0228871  0.02735315 0.02503614
  0.03104833 0.01536764 0.01353267 0.03689976 0.03137472 0.03984781
  0.03260702 0.03272022 0.03533737 0.02950886 0.01741549 0.0380383
  0.03707141 0.02447329 0.02045789 0.02793006 0.01889295 0.01769948
  0.03807345 0.02731574]
 [0.03332331 0.02442489 0.02247462 0.02137846 0.01746102 0.02038593
  0.02634278 0.02801853 0.02473933 0.02365105 0.02868892 0.02570466
  0.02858486 0.0158023  0.01374367 0.03130265 0.03302859 0.03278513
  0.03371184 0.03060481 0.03489689 0.02956652 0.01887887 0.04704554
  0.04261477 0.0247312  0.02439528 0.03617396 0.02034154 0.01941361
  0.04835994 0.03336815]
 [0.03351202 0.02769577 0.02546777 0.02253047 0.01775926 0.02188976
  0.03035613 0.03216152 0.02981782 0.02506693 0.0348349  0.02732741
  0.03158473 0.01618164 0.01454906 0.03672729 0.03384179 0.03622419
  0.03437232 0.03354463 0.03435695 0.0306486  0.02047113 0.04695843
  0.03915793 0.0263841  0.02665308 0.02939138 0.01940864 0.01788021
  0.04608249 0.03390271]
 [0.03364884 0.02067171 0.01944176 0.01607202 0.0150473  0.01637669
  0.02452926 0.02459185 0.02407573 0.01834373 0.03531449 0.02132485
  0.02342283 0.01246166 0.01132806 0.0301254  0.03129525 0.02912425
  0.03634027 0.03152741 0.03111266 0.02729386 0.01757302 0.04280699
  0.04512152 0.02738651 0.01930146 0.02888803 0.01704102 0.01396776
  0.04802954 0.03340416]
 [0.03197812 0.02561018 0.02322907 0.01939557 0.0171776  0.02226901
  0.03324887 0.03228546 0.03412595 0.0232097  0.02753077 0.02244502
  0.02907822 0.01498041 0.01484178 0.02546981 0.03500453 0.02984129
  0.05193301 0.04392691 0.03425542 0.03196374 0.02555132 0.03799682
  0.0427317  0.03983469 0.02274323 0.03851114 0.02502565 0.01657997
  0.04018834 0.02789982]
 [0.03345992 0.02366052 0.02193788 0.02280893 0.01849838 0.02259116
  0.02666164 0.03024586 0.02897838 0.02464127 0.0268842  0.02553683
  0.02687136 0.01875006 0.01553747 0.02168311 0.02467196 0.02446318
  0.03138587 0.02768609 0.02829375 0.02957381 0.01832574 0.0226554
  0.02357479 0.02599279 0.01937029 0.02693403 0.02228058 0.0174065
  0.030022   0.03872506]
 [0.03199051 0.0314621  0.03195657 0.04913453 0.04448059 0.04248948
  0.030629   0.03282316 0.03908721 0.04964323 0.03247064 0.03707898
  0.03660439 0.06683887 0.08801527 0.02260307 0.0266467  0.0261529
  0.02489209 0.02487529 0.02230239 0.03276898 0.03222556 0.01490587
  0.0167068  0.03480104 0.03397717 0.04391651 0.0499989  0.02421798
  0.01277596 0.02103712]
 [0.03163094 0.04216187 0.0357959  0.07379162 0.16227856 0.05566961
  0.03363518 0.03432142 0.04121616 0.07433602 0.05009858 0.05086433
  0.03483459 0.10220071 0.1340081  0.03242086 0.04929612 0.04345309
  0.03426499 0.02949396 0.03498592 0.03201142 0.04156161 0.01349219
  0.0156069  0.03470956 0.05049768 0.04292716 0.05068375 0.01924769
  0.00855411 0.00943255]
 [0.03167696 0.03400514 0.02658232 0.04341489 0.07912661 0.02702798
  0.0242242  0.02659864 0.02961685 0.04464284 0.03556317 0.03288304
  0.02501382 0.03522298 0.05199381 0.02883004 0.06542324 0.05809259
  0.05154047 0.03693642 0.06898569 0.02966918 0.03555059 0.02699517
  0.02555169 0.03327138 0.03995209 0.05322453 0.03217268 0.01437609
  0.0142866  0.01198215]
 [0.03178018 0.03755517 0.02829524 0.04609619 0.05338893 0.03210762
  0.03017064 0.03114445 0.03684522 0.04406035 0.03226104 0.03193258
  0.02881664 0.04069626 0.04518913 0.02284583 0.04236572 0.04153008
  0.04053811 0.03400715 0.04222324 0.04039877 0.04160368 0.0181663
  0.02093283 0.03495095 0.03505101 0.06300986 0.04005505 0.01182926
  0.01148882 0.0117188 ]]

-* TASK 10/20 | SAMPLE 60/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 298/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Julie's current location. The sentences only mention Bill's movements and possible locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' current', ' location', '.', ' The', ' sentences', ' only', ' mention', ' Bill', "'s", ' movements', ' and', ' possible', ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.028167   0.03524051 0.03529602 ... 0.04932471 0.01502169 0.01871504]
 [0.02891867 0.02530431 0.02658379 ... 0.02905972 0.01528548 0.01968545]
 [0.02950293 0.03625373 0.0399602  ... 0.03492338 0.01328686 0.0152785 ]
 ...
 [0.02977879 0.03227263 0.02554571 ... 0.04200148 0.0303082  0.03249577]
 [0.03035636 0.03516873 0.02967886 ... 0.04693008 0.01916995 0.0156443 ]
 [0.03053937 0.02988452 0.02733778 ... 0.05492163 0.01623927 0.01575303]]

-* TASK 10/20 | SAMPLE 60/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 299/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that Fred went back to the bedroom, which implies that Fred is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Fred', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0968, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03022847 0.03776571 0.04363903 ... 0.08298808 0.00991445 0.00884317]
 [0.03082223 0.03169636 0.03412782 ... 0.05187698 0.01522009 0.01164522]
 [0.03163224 0.04160976 0.05120803 ... 0.07013426 0.02091679 0.01320449]
 ...
 [0.0317563  0.04841418 0.04671746 ... 0.02811444 0.00568445 0.00492126]
 [0.03204672 0.03639398 0.03171417 ... 0.01722328 0.00760533 0.00746374]
 [0.032028   0.04323254 0.03774504 ... 0.01932067 0.00451505 0.00498247]]

-* TASK 10/20 | SAMPLE 60/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 300/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 14 states that Bill is either in the kitchen or the cinema, but it does not provide a definitive answer. Bill could be in either location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' answer', '.', ' Bill', ' could', ' be', ' in', ' either', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.0, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02303432 0.03300079 0.03684058 ... 0.02907885 0.01377649 0.00981828]
 [0.02363734 0.02512592 0.02965878 ... 0.02761913 0.02322563 0.01519023]
 [0.02415048 0.03369255 0.04081346 ... 0.02584564 0.01277952 0.0083184 ]
 ...
 [0.02421109 0.03449275 0.03216339 ... 0.02701771 0.01253847 0.00814394]
 [0.02466304 0.03029731 0.02620004 ... 0.02867277 0.02087796 0.01611221]
 [0.0249008  0.02865952 0.02528781 ... 0.0278314  0.01497457 0.0115217 ]]
Model's predictions for the sample 60:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Mary   |
|          |                 |    being in the bedroom or the bedroom,    |
|          |                 |  which is the same location. There is no   |
|          |                 |   mention of Mary being in the kitchen.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 4 states that Julie  |
|          |                 |    went back to the park, which implies    |
|          |                 |    that Julie is currently in the park.    |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |  The context sentences do not provide any  |
|          |                 |     information about Julie's current      |
|          |                 |    location. The sentences only mention    |
|          |                 |  Bill's movements and possible locations.  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 11 states that Fred  |
|          |                 |  went back to the bedroom, which implies   |
|          |                 |   that Fred is currently in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 14 states that Bill  |
|          |                 |  is either in the kitchen or the cinema,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |      answer. Bill could be in either       |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 60:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.06 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 61/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 301/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: Sentence 2 explicitly states that Mary is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '2', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(23, 26), x_tokens=26, y_tokens=23, max_supp_attn=0.0435, attn_on_target=0.0435)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (23, 26)
DEBUG result.interpretability.attn_scores 598 
 [[0.04052964 0.06848034 0.08555776 0.09352919 0.09536543 0.09621982
  0.0886413  0.10655323 0.08878512 0.08381271 0.06684262 0.08475633
  0.10043781 0.10695031 0.06402872 0.04702727 0.04081216 0.04762812
  0.04132643 0.04807764 0.04066236 0.05561447 0.05870886 0.03381612
  0.02069265 0.03373925]
 [0.04043857 0.11340877 0.09180732 0.08187827 0.06527798 0.08417474
  0.23158537 0.16544303 0.0988761  0.08130593 0.10458715 0.08070432
  0.12681484 0.04509064 0.03366911 0.05629482 0.04653079 0.06857591
  0.05063891 0.06380698 0.05358584 0.06232246 0.0571914  0.05121887
  0.02680988 0.03328755]
 [0.04435586 0.08048423 0.05133465 0.06751311 0.04882053 0.04638283
  0.03830072 0.03006065 0.03164683 0.04361493 0.03919528 0.02189106
  0.02533776 0.03657079 0.04646874 0.03512605 0.01858471 0.01923553
  0.02320535 0.02517768 0.02451301 0.06067348 0.07091759 0.01444116
  0.00709297 0.01460306]
 [0.04203549 0.03858354 0.03800511 0.02740294 0.01809623 0.03062663
  0.02889352 0.02682531 0.03668833 0.02931319 0.03087253 0.02932303
  0.0285785  0.01259545 0.01206995 0.03966813 0.03760549 0.0447086
  0.05143783 0.05413258 0.04775674 0.04360413 0.05776948 0.07815509
  0.08371618 0.08744153]
 [0.04217817 0.05684326 0.06302706 0.08238719 0.07292282 0.0607801
  0.0410891  0.03903232 0.04753924 0.05703548 0.04760601 0.03403973
  0.0348017  0.12075926 0.12159332 0.05431416 0.03579158 0.03009756
  0.02995453 0.03404378 0.03407178 0.05406647 0.08233789 0.0244285
  0.01050889 0.03185915]
 [0.04306462 0.03711843 0.03923607 0.06433018 0.05481126 0.05564086
  0.03106266 0.03075849 0.04062394 0.0537223  0.04249848 0.03878511
  0.03770326 0.13095444 0.15247154 0.05349386 0.03976718 0.03598031
  0.03374869 0.03637191 0.03278796 0.04623511 0.04974701 0.01770261
  0.00880364 0.02102922]
 [0.04371975 0.04155509 0.0498047  0.06650227 0.05937503 0.06953039
  0.04043272 0.04162759 0.05301069 0.06247047 0.04883599 0.06064421
  0.05660157 0.1036949  0.09444823 0.04474386 0.03585417 0.03532007
  0.03226589 0.03559776 0.03050755 0.04168825 0.04625926 0.02342824
  0.01230525 0.02095537]
 [0.04227301 0.05899745 0.06846087 0.05232073 0.05264573 0.06321753
  0.04503332 0.05398359 0.05886811 0.05611779 0.04938376 0.06574693
  0.05749616 0.06292312 0.05513117 0.05862574 0.04631193 0.04443621
  0.03973776 0.04404345 0.04020768 0.04735655 0.06812675 0.05068228
  0.03324614 0.04366687]
 [0.04342115 0.05632274 0.06713852 0.03663693 0.02869812 0.04381815
  0.05400213 0.05083947 0.06026397 0.038886   0.03965507 0.04524425
  0.0429961  0.02205745 0.01905343 0.06452727 0.04415273 0.04050392
  0.04308588 0.0477109  0.0423387  0.0406851  0.06514803 0.06265599
  0.05476449 0.05077974]
 [0.04404817 0.02269532 0.02789794 0.01832983 0.01512246 0.02503894
  0.02341018 0.02701992 0.03661634 0.02298605 0.02163185 0.02621681
  0.02530198 0.01051379 0.00951644 0.03404226 0.02948185 0.02921481
  0.03420391 0.03624912 0.03485782 0.0273677  0.04083815 0.06933453
  0.08392345 0.08430985]
 [0.04344674 0.03901395 0.04370294 0.02675061 0.0208972  0.03759054
  0.0332833  0.03992325 0.04090391 0.03233993 0.03456083 0.04460169
  0.03765037 0.01469286 0.01348895 0.05468642 0.04619089 0.04436391
  0.04705225 0.04472734 0.04135215 0.04249711 0.04162338 0.05845904
  0.07966557 0.06055535]
 [0.04448686 0.05049731 0.05609601 0.04386673 0.03064904 0.0586824
  0.04666466 0.05878338 0.05457454 0.05648085 0.0538738  0.08676185
  0.06510247 0.02412678 0.01703634 0.04287433 0.0420184  0.04512952
  0.04159461 0.0424976  0.03780245 0.04406459 0.033238   0.03303355
  0.02935539 0.03000709]
 [0.04509917 0.0347448  0.03823528 0.02730675 0.02202317 0.03455888
  0.03640107 0.03799696 0.03714228 0.03283982 0.04002689 0.0444427
  0.03954378 0.01434752 0.01274874 0.04357251 0.04329759 0.03785398
  0.0397794  0.0388269  0.03744953 0.04181376 0.02758326 0.04290225
  0.04898797 0.02980442]
 [0.04427232 0.02568808 0.02441945 0.01723155 0.01462219 0.02089544
  0.02401385 0.0260925  0.02708729 0.02100654 0.03076464 0.02859606
  0.02930039 0.00872335 0.00937306 0.04199434 0.05128029 0.04052185
  0.04750676 0.04206255 0.04485221 0.03855859 0.02286628 0.06605839
  0.08957398 0.05277734]
 [0.04391439 0.02484845 0.02227232 0.01656173 0.01370804 0.01929066
  0.02742268 0.03010778 0.02608739 0.01974768 0.03146843 0.02623566
  0.03254734 0.00777914 0.00797761 0.04179643 0.05312984 0.0477845
  0.05662093 0.05168572 0.0655333  0.03528129 0.02089037 0.07998472
  0.11266922 0.05335408]
 [0.04466225 0.02316178 0.02110906 0.01610878 0.01437414 0.01931908
  0.02186987 0.02622325 0.02520748 0.0206453  0.03196806 0.03010164
  0.02899078 0.00795318 0.00800393 0.03578025 0.0585894  0.04207212
  0.05932892 0.04558931 0.05022062 0.03351064 0.01712884 0.03903618
  0.08445721 0.05883158]
 [0.04453409 0.02066941 0.01911651 0.01345051 0.01232288 0.01652461
  0.02150216 0.02429543 0.02360364 0.01748721 0.03598337 0.02583571
  0.02709737 0.00656838 0.00703687 0.03804127 0.05172547 0.04439586
  0.06109332 0.05313887 0.05799477 0.03188257 0.01754313 0.04810708
  0.05988804 0.07984085]
 [0.04393292 0.02770551 0.02592119 0.01628541 0.01360353 0.02168238
  0.02728853 0.0307068  0.03038696 0.01864937 0.0295861  0.02498334
  0.0298138  0.00828756 0.0077277  0.03613405 0.03159712 0.04011662
  0.04280993 0.04707336 0.05450372 0.03595166 0.03063423 0.09616408
  0.07815641 0.06818353]
 [0.04515322 0.02617786 0.02631045 0.02254459 0.01652295 0.0250723
  0.02475527 0.02983564 0.03078692 0.02613685 0.03113811 0.03239729
  0.03079084 0.01194587 0.01079858 0.02649895 0.02840246 0.03250648
  0.04201384 0.04215037 0.04151306 0.03540488 0.02124525 0.02914789
  0.02751433 0.04356337]
 [0.04398682 0.03708769 0.03666922 0.0542165  0.05291468 0.05222253
  0.03076682 0.03274105 0.03972403 0.05703183 0.04437749 0.04479348
  0.04171567 0.08707524 0.09929831 0.03665984 0.03639469 0.03659179
  0.03335276 0.03480573 0.03403619 0.04276209 0.04133273 0.01826369
  0.01108871 0.02323596]
 [0.04370565 0.0389143  0.03557028 0.0576915  0.1061429  0.04660273
  0.0284252  0.03025982 0.03748425 0.06184833 0.05013736 0.04213721
  0.03353216 0.08331689 0.10756595 0.04395419 0.05036711 0.05301822
  0.04103212 0.03925301 0.04124787 0.03936649 0.03928376 0.01498373
  0.00783332 0.020073  ]
 [0.04315963 0.03401436 0.03130762 0.04678383 0.09735677 0.03259955
  0.02351319 0.0286984  0.03333867 0.05320416 0.04774212 0.04283222
  0.0322673  0.03593903 0.04818904 0.03756888 0.08045747 0.08291401
  0.06070727 0.04765641 0.06238514 0.03587183 0.03658605 0.02651282
  0.01644899 0.03210818]
 [0.04358158 0.04298733 0.03699981 0.05037076 0.07372688 0.03952887
  0.03164238 0.0321922  0.04075392 0.05331728 0.04726407 0.03892936
  0.03557804 0.03713403 0.04230421 0.03257522 0.05165666 0.05703011
  0.04750252 0.04532096 0.04981958 0.06342082 0.05300032 0.02148323
  0.01249728 0.02599357]]

-* TASK 10/20 | SAMPLE 61/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 302/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 4 states that Mary is either in the bedroom or the cinema, but it does not provide a definitive location for Mary. Therefore, we can only conclude that Mary might be in the bedroom.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Mary', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01949382 0.03376862 0.03300254 ... 0.0090747  0.05160189 0.05257156]
 [0.02004341 0.03370775 0.03215381 ... 0.01483693 0.05163648 0.03726779]
 [0.02037964 0.03150912 0.03347245 ... 0.022195   0.0367292  0.03466198]
 ...
 [0.02049837 0.0286189  0.02532276 ... 0.00600146 0.07054584 0.0341791 ]
 [0.02078453 0.02394773 0.02007503 ... 0.00837798 0.05118828 0.02704631]
 [0.02092656 0.02250052 0.01900094 ... 0.00721024 0.08630484 0.03950455]]

-* TASK 10/20 | SAMPLE 61/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 303/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 explicitly states that Fred is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.0501515  0.077672   0.06874344 0.08901962 0.06688252 0.07749035
  0.06630855 0.06532998 0.0638807  0.0808433  0.05700273 0.05802658
  0.06336516 0.11658829 0.10900573 0.04700038 0.04269691 0.04358824
  0.03555918 0.04194339 0.03582325 0.05469752 0.08197663 0.03458834
  0.02625416 0.05089927 0.06765163 0.05710766 0.13924582 0.01478912
  0.05883979 0.0776365  0.04584264 0.04325634 0.02982856 0.02430583
  0.04851214 0.08008073]
 [0.05066604 0.06231619 0.06120697 0.06745633 0.05848139 0.07788038
  0.07854966 0.08950661 0.07133245 0.07633246 0.06083243 0.08630145
  0.12082553 0.07947059 0.07178321 0.04206886 0.04342663 0.05080262
  0.0444007  0.04978152 0.03913919 0.05360939 0.05605794 0.03642063
  0.03518732 0.05211388 0.06110679 0.04851693 0.10159167 0.06111829
  0.04551583 0.05564502 0.06008964 0.04538792 0.04464671 0.03962387
  0.05678655 0.07115645]
 [0.05227686 0.0724497  0.07209218 0.09691866 0.08479557 0.09658692
  0.06323676 0.06604575 0.07035308 0.0870977  0.05963077 0.06790706
  0.06928138 0.1751683  0.1210112  0.05063025 0.03990702 0.04073605
  0.03244799 0.03854427 0.03097715 0.0549452  0.06399902 0.03304067
  0.0260209  0.04348964 0.0629212  0.04354417 0.08354854 0.02925235
  0.04828609 0.05527196 0.04311594 0.03650408 0.02895081 0.02161302
  0.04617387 0.05602054]
 [0.05076527 0.06299886 0.065726   0.05039298 0.03962538 0.0537554
  0.05738882 0.05783109 0.05597758 0.04899945 0.0475229  0.05324722
  0.05120151 0.04055036 0.03883798 0.05337215 0.04353539 0.04269128
  0.03866882 0.04340347 0.03721021 0.05721004 0.07558435 0.06110719
  0.0528456  0.05597116 0.06674442 0.04559967 0.05740794 0.07346057
  0.03050197 0.06222526 0.09509365 0.07047138 0.05702052 0.04141515
  0.0654994  0.05932668]
 [0.05215862 0.06640935 0.06645295 0.04156822 0.03106862 0.04780292
  0.06637383 0.056269   0.06579261 0.0394379  0.04206817 0.04386926
  0.04361399 0.02949732 0.02982622 0.05859419 0.04544885 0.04132068
  0.04123968 0.04591588 0.03667649 0.04908435 0.07095488 0.06125601
  0.0520355  0.04531664 0.0621436  0.03027452 0.04049913 0.0662982
  0.02586547 0.05417767 0.07014435 0.08475737 0.06638155 0.04521919
  0.04991557 0.04858997]
 [0.05310548 0.03628246 0.03580656 0.02475865 0.02032689 0.02851734
  0.03670796 0.03522918 0.04081007 0.02562144 0.03388445 0.03250291
  0.03155695 0.01757139 0.01984844 0.03699259 0.03450936 0.03405985
  0.03819077 0.04169946 0.03293452 0.04087935 0.03861425 0.04459057
  0.04224496 0.03661871 0.03687144 0.02748582 0.03002167 0.0371132
  0.02127006 0.03366597 0.02982328 0.06080608 0.06066362 0.04873708
  0.03836108 0.04258117]
 [0.05196853 0.05637089 0.05618266 0.03901265 0.03033928 0.04685784
  0.05490067 0.05279955 0.05256681 0.03970183 0.04715491 0.05159324
  0.04588301 0.02837347 0.02611038 0.06376182 0.05078075 0.05229195
  0.05075234 0.05233665 0.04671661 0.05565995 0.05242004 0.07307378
  0.07574903 0.05739413 0.06424961 0.04075971 0.04193342 0.14688422
  0.02244459 0.051529   0.08064214 0.06417881 0.05617286 0.05175522
  0.05644092 0.04156005]
 [0.05333853 0.05413564 0.05248355 0.04543553 0.03323222 0.04743089
  0.0486918  0.04933853 0.04890906 0.04465657 0.04895578 0.05089007
  0.04653403 0.02878809 0.02406068 0.03905697 0.03218235 0.03553499
  0.03686719 0.04201996 0.03820429 0.05090068 0.04193645 0.049907
  0.05314505 0.04955507 0.06450881 0.04549795 0.0397224  0.1521972
  0.03331333 0.05356214 0.07852895 0.06266356 0.06220178 0.06141915
  0.0673482  0.05441693]
 [0.0543168  0.04632667 0.04903232 0.03759726 0.02946041 0.04098336
  0.04924089 0.04723328 0.04531519 0.03655064 0.04499255 0.04580884
  0.04443632 0.02413338 0.02182831 0.04451512 0.03564378 0.03751345
  0.04050315 0.04378096 0.04018532 0.04906441 0.03906978 0.0528461
  0.05955335 0.04333718 0.05109513 0.04085153 0.03450397 0.10167336
  0.02493663 0.03882861 0.05020535 0.04796896 0.05056695 0.05114964
  0.05205666 0.03662632]
 [0.05317564 0.04046779 0.03785871 0.02851516 0.02333274 0.03119056
  0.04504021 0.04172596 0.03796137 0.02834874 0.04447802 0.03844819
  0.04210258 0.01736626 0.01881164 0.06450606 0.05095654 0.05389228
  0.05680967 0.05606163 0.05248814 0.05458341 0.0333428  0.07213438
  0.07634164 0.04157117 0.03612623 0.04215264 0.02988676 0.06135293
  0.02082661 0.03576543 0.04478604 0.0493378  0.0652714  0.06659507
  0.04988773 0.03252786]
 [0.0526599  0.04066942 0.03722471 0.0299234  0.02303674 0.03215063
  0.04841534 0.04398699 0.03880448 0.02936448 0.04143314 0.03613081
  0.04327516 0.01726806 0.01887189 0.0686954  0.05121074 0.07233991
  0.08472011 0.08619443 0.08148662 0.04949715 0.03454837 0.09773244
  0.1048874  0.06185617 0.03755184 0.05890181 0.03016707 0.05317543
  0.02025903 0.03882861 0.04475196 0.05486253 0.08249877 0.08950549
  0.0589578  0.03654039]
 [0.05390298 0.03661371 0.03644056 0.02794328 0.02263392 0.03187761
  0.04045171 0.04015124 0.03625811 0.0284887  0.04450733 0.04068784
  0.04110512 0.01697127 0.01779014 0.06134841 0.05216937 0.05189703
  0.07029619 0.05991659 0.06504066 0.0481748  0.02957989 0.07236505
  0.10790399 0.06053483 0.04247667 0.0530687  0.02813615 0.05722073
  0.02094218 0.0333012  0.04386578 0.0561173  0.06332697 0.08648736
  0.04769096 0.03369885]
 [0.05381401 0.03523685 0.03763466 0.02581662 0.02237453 0.03121756
  0.04517459 0.04271122 0.03812743 0.0289166  0.06032116 0.04397772
  0.04548327 0.01597399 0.01737121 0.07093326 0.06241076 0.05888684
  0.07802123 0.06886936 0.06756844 0.0497453  0.03001636 0.07414339
  0.08915823 0.08927891 0.04011146 0.05922674 0.02665406 0.03861932
  0.01960071 0.03283696 0.04461562 0.04890025 0.07005808 0.09628651
  0.04166899 0.03827289]
 [0.05304316 0.05849092 0.05533892 0.03496306 0.03125172 0.04806094
  0.06718785 0.05983528 0.05508763 0.0363147  0.05327072 0.05192584
  0.05730809 0.02277821 0.02115687 0.05474361 0.05739124 0.05301339
  0.05632384 0.06046145 0.04588703 0.05525317 0.05678043 0.07626958
  0.06563383 0.06543647 0.04484189 0.04058029 0.03334344 0.02604295
  0.02270141 0.04907514 0.06649739 0.08168088 0.09888851 0.10246194
  0.04440393 0.05325793]
 [0.05441039 0.03437559 0.04314758 0.03794396 0.0288806  0.04284951
  0.03857024 0.04282069 0.0446935  0.04237715 0.04707024 0.04868477
  0.04661017 0.02751367 0.02325248 0.03943475 0.03963764 0.0412355
  0.05011079 0.04851552 0.0465959  0.04686543 0.03033841 0.03054987
  0.03322354 0.05556713 0.03661224 0.05460856 0.03707651 0.03463703
  0.03104473 0.03537372 0.03677636 0.03023194 0.04075785 0.04600508
  0.04168523 0.03908219]
 [0.05277565 0.04969971 0.05367289 0.07217788 0.06335179 0.06452329
  0.04687944 0.04992379 0.05663759 0.07192559 0.05587596 0.0532888
  0.05064568 0.09091207 0.10683457 0.04048285 0.04126908 0.04319461
  0.03878872 0.04248825 0.04053443 0.05403008 0.05550282 0.02795677
  0.02280887 0.04484401 0.05326594 0.06587499 0.06943495 0.01363658
  0.08250857 0.06254857 0.03338503 0.03869524 0.03150215 0.02988547
  0.04941451 0.07559761]
 [0.05242351 0.0632437  0.0658118  0.1100575  0.20759612 0.09094646
  0.05262754 0.05638268 0.06329308 0.11115155 0.086201   0.08077735
  0.05825605 0.14790341 0.18535985 0.06140282 0.08483989 0.07867926
  0.0607337  0.0539837  0.07296364 0.05406022 0.07389782 0.02860412
  0.02000347 0.04868858 0.07063245 0.06746712 0.07371683 0.00928658
  0.15007006 0.08031833 0.03657186 0.03696547 0.0234101  0.02433522
  0.05501893 0.06529053]
 [0.05241024 0.05279911 0.04993565 0.06832486 0.1124067  0.05037713
  0.04218344 0.04530067 0.04559197 0.07458091 0.06784054 0.06054099
  0.04738681 0.0512106  0.07247664 0.05831394 0.12256786 0.10277451
  0.08727384 0.06651187 0.12706834 0.05253147 0.06529781 0.04227464
  0.0336144  0.0501827  0.05333074 0.0855626  0.05030464 0.01416451
  0.16962625 0.06333198 0.05930571 0.04495377 0.03572873 0.03813832
  0.06934083 0.05269242]
 [0.05263691 0.05344145 0.05520783 0.0721743  0.07092287 0.05950087
  0.05207078 0.05757846 0.06860724 0.06929026 0.05695713 0.05539106
  0.05112918 0.05196129 0.05576252 0.04414659 0.06941583 0.06554756
  0.05829208 0.05757157 0.06249985 0.06920817 0.07008195 0.03113955
  0.02338886 0.04734438 0.0477579  0.09291862 0.05280514 0.00907747
  0.15144664 0.08607786 0.03595835 0.04226036 0.0321241  0.03506138
  0.06083677 0.08268048]]

-* TASK 10/20 | SAMPLE 61/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 304/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill in the context sentences, so we cannot determine Bill's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', ',', ' so', ' we', ' cannot', ' determine', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 44), x_tokens=44, y_tokens=27, max_supp_attn=0.0741, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 44)
DEBUG result.interpretability.attn_scores 1188 
 [[0.03451873 0.03652583 0.03759239 ... 0.01756039 0.01903072 0.02269844]
 [0.0351635  0.04693529 0.05090867 ... 0.02715905 0.02731865 0.02754728]
 [0.03607069 0.03295208 0.03654832 ... 0.03572696 0.03342589 0.03088885]
 ...
 [0.03679443 0.03612448 0.02787641 ... 0.02004646 0.01737622 0.02920844]
 [0.03728769 0.03765313 0.03058428 ... 0.02196389 0.01771021 0.02674159]
 [0.03733658 0.0324372  0.02687462 ... 0.01670129 0.01710943 0.01942024]]

-* TASK 10/20 | SAMPLE 61/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 305/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 explicitly states that Mary is in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 50), x_tokens=50, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 50)
DEBUG result.interpretability.attn_scores 950 
 [[0.05001575 0.05933071 0.06103634 0.07563835 0.05740436 0.06702749
  0.05233117 0.05944978 0.06340706 0.05930069 0.0509492  0.05485274
  0.05918624 0.0917965  0.09643813 0.04494566 0.04024553 0.04016444
  0.04342796 0.04328827 0.03899564 0.05227374 0.08021516 0.02766764
  0.02306681 0.0538208  0.06182688 0.06906538 0.14972222 0.020865
  0.05814802 0.07831158 0.05098142 0.04044833 0.03079892 0.03239612
  0.04912869 0.08350574 0.06365014 0.10749026 0.01518692 0.02856717
  0.03335357 0.03716217 0.0234004  0.06613553 0.06227925 0.04175616
  0.03000076 0.02707215]
 [0.05106628 0.06345246 0.07472259 0.06415161 0.05043082 0.06433985
  0.06835747 0.08854476 0.07101201 0.05571864 0.05450307 0.06911115
  0.07951467 0.05565235 0.07117134 0.05936911 0.05047479 0.06213659
  0.05845825 0.06811072 0.0553473  0.05905447 0.06015512 0.04747413
  0.05136117 0.06720161 0.04797994 0.06382429 0.10500135 0.04029131
  0.03330829 0.0580929  0.07677513 0.04555103 0.04542634 0.05214233
  0.04713842 0.05869306 0.08313487 0.05846716 0.03253877 0.03980364
  0.04642611 0.05149299 0.05008028 0.03600755 0.05722953 0.05058715
  0.04412461 0.04994219]
 [0.0521796  0.05643853 0.06399208 0.08994475 0.07781547 0.09287554
  0.05389204 0.05883896 0.06931063 0.07604448 0.05355093 0.06383485
  0.0652196  0.14662264 0.09993647 0.04484241 0.03520032 0.03295503
  0.03521926 0.0360931  0.03024169 0.05321844 0.06495886 0.02549982
  0.01901591 0.03907105 0.06678443 0.04661668 0.09251817 0.03734687
  0.05356556 0.05991125 0.04605454 0.03712983 0.02527745 0.02507945
  0.04377573 0.05802906 0.05252552 0.10651949 0.0184256  0.04969302
  0.05205507 0.0527465  0.02603081 0.07048199 0.05914189 0.03527749
  0.02494079 0.02312027]
 [0.050814   0.04924592 0.05685227 0.04574736 0.03593999 0.04976576
  0.04473777 0.0501873  0.05175877 0.04355328 0.04252493 0.04908193
  0.04688537 0.0361733  0.03324863 0.0468946  0.0387889  0.03483616
  0.04099998 0.04106025 0.0362173  0.05596587 0.06453352 0.04338619
  0.04346338 0.05085225 0.06137102 0.04500206 0.0582787  0.07342496
  0.02881189 0.05559616 0.08035832 0.05633219 0.04482319 0.03956294
  0.05739867 0.05835691 0.09412627 0.11402485 0.03687612 0.06551474
  0.06461076 0.05915397 0.03627916 0.04015274 0.05212197 0.05950555
  0.04740439 0.03863013]
 [0.0521318  0.05443066 0.06110012 0.04134376 0.0314646  0.04870778
  0.05508167 0.05087447 0.06150582 0.04124463 0.03856748 0.04364217
  0.04329111 0.03327185 0.02969602 0.04891324 0.03738275 0.03207844
  0.04227928 0.04356705 0.03536436 0.05075392 0.06353274 0.04106379
  0.03902997 0.04189824 0.06672745 0.02903104 0.04389146 0.07856274
  0.02662759 0.05022502 0.06091424 0.06437694 0.05058937 0.03841696
  0.04607492 0.04412873 0.05082685 0.10776319 0.03872715 0.06306992
  0.04657102 0.04266304 0.02596249 0.03124595 0.05644179 0.06664249
  0.05376179 0.0425173 ]
 [0.05347332 0.03815567 0.04115856 0.02631545 0.02171533 0.03003913
  0.03327596 0.03645821 0.04316477 0.03027004 0.03262348 0.03202191
  0.03198929 0.01954223 0.02134921 0.0474625  0.03962072 0.03261112
  0.045462   0.04322411 0.03589891 0.04227127 0.04452074 0.04727672
  0.05071273 0.04305144 0.03373412 0.02658562 0.0339454  0.05170693
  0.02011512 0.03409413 0.03137926 0.056019   0.05216102 0.04122462
  0.03468533 0.03471659 0.05125985 0.05846341 0.03371716 0.03034493
  0.02492622 0.02383125 0.01954019 0.01972497 0.03739647 0.04825528
  0.04355737 0.0370209 ]
 [0.05214582 0.04517566 0.0494047  0.0363414  0.02699682 0.04299099
  0.04078921 0.04284794 0.04611655 0.03888251 0.03964501 0.04616652
  0.04229986 0.02695866 0.02260926 0.04928109 0.04122883 0.03988451
  0.05097939 0.05270704 0.04339943 0.05266581 0.04648893 0.05196435
  0.06761212 0.05206125 0.04957547 0.03742874 0.04075322 0.13813193
  0.02312359 0.050802   0.07303385 0.06876469 0.05775487 0.05538635
  0.05961176 0.04552934 0.07594051 0.08379518 0.06126089 0.10027006
  0.0650616  0.0643779  0.0547262  0.02854957 0.04965156 0.06247711
  0.05647733 0.05001553]
 [0.05344018 0.04861902 0.05283735 0.05188777 0.03645331 0.05622499
  0.04631973 0.05360406 0.05150767 0.05419737 0.04519327 0.05966968
  0.05315288 0.03706269 0.02692183 0.03676527 0.03522557 0.03655254
  0.04045259 0.04223732 0.03738025 0.05184055 0.03958913 0.0346069
  0.03874947 0.03889249 0.04592854 0.03608323 0.03634094 0.12673153
  0.03002597 0.04543086 0.0569095  0.04307402 0.03534156 0.03956735
  0.05117972 0.04146029 0.06131863 0.05697866 0.0503565  0.09305217
  0.07942062 0.08525319 0.06172924 0.04594379 0.05074725 0.04787035
  0.03867844 0.0469567 ]
 [0.05416736 0.04458813 0.05036129 0.0423714  0.0303505  0.04646933
  0.0468133  0.04793968 0.04442542 0.04348037 0.04053445 0.05022409
  0.04652633 0.02897557 0.02308048 0.0423901  0.03694097 0.03375803
  0.03947808 0.04071509 0.03714564 0.04993551 0.03832425 0.04179757
  0.0501153  0.03577885 0.04684028 0.03543184 0.03126673 0.09783794
  0.0244772  0.03927993 0.04832038 0.04831908 0.04063211 0.04156841
  0.05488678 0.03414182 0.04909487 0.06047153 0.07564063 0.08213952
  0.0808182  0.07590143 0.07816076 0.03037139 0.04566691 0.05478973
  0.05160745 0.0483157 ]
 [0.05319515 0.03891278 0.03760391 0.029581   0.02262029 0.03230357
  0.03618255 0.03746033 0.03511909 0.03304042 0.03834414 0.03912318
  0.04068029 0.02019105 0.01839139 0.05796097 0.04989289 0.04595341
  0.05099598 0.04832622 0.048874   0.0555552  0.03250584 0.08237714
  0.08912706 0.04356851 0.04057211 0.04473296 0.02856813 0.0732953
  0.02027943 0.03516416 0.04294559 0.06218464 0.06287999 0.0606667
  0.06094874 0.03566901 0.05052709 0.03754839 0.10431541 0.05162945
  0.06996924 0.06610365 0.09045879 0.02493543 0.04046067 0.06083699
  0.06428    0.06280308]
 [0.05292176 0.04150515 0.03762609 0.02982305 0.02288265 0.03284184
  0.04177213 0.0419842  0.03621577 0.03355075 0.03768196 0.03848589
  0.04379454 0.02011572 0.01749399 0.06121222 0.0522634  0.05223345
  0.05544763 0.05441291 0.05536908 0.05111417 0.0285194  0.10963506
  0.1110427  0.0465817  0.04307938 0.05325027 0.0251697  0.06171874
  0.01801819 0.03388781 0.0428929  0.06556641 0.0659716  0.06690791
  0.06985682 0.03551339 0.03893617 0.02276933 0.11452971 0.04557406
  0.06242262 0.07198057 0.11949578 0.02324006 0.04366608 0.07208168
  0.09717131 0.08813226]
 [0.05356605 0.03873108 0.03664731 0.0287317  0.02421729 0.03224046
  0.03324643 0.03541791 0.03513959 0.0337646  0.038399   0.0399467
  0.04016906 0.02016432 0.0172145  0.05025814 0.04816993 0.04494726
  0.05384487 0.05083302 0.05260247 0.04837457 0.03120204 0.07214146
  0.09601212 0.06408054 0.0399453  0.04871397 0.02557843 0.05556966
  0.01955568 0.03404517 0.04402582 0.06372526 0.06816709 0.07265987
  0.05189379 0.03917781 0.04240012 0.02275807 0.12131101 0.05882791
  0.05881274 0.05745736 0.10917911 0.02774561 0.04249042 0.06264075
  0.08042544 0.09022469]
 [0.05393885 0.03880073 0.03677209 0.02663819 0.02345301 0.03063308
  0.03607708 0.03617189 0.03520621 0.03243288 0.0518504  0.04023017
  0.04211644 0.01885454 0.01698928 0.05972276 0.05831967 0.04985964
  0.05831726 0.05361639 0.05381402 0.05091055 0.03424052 0.09800258
  0.09221259 0.0632361  0.03094193 0.04546124 0.02276119 0.03832865
  0.01833378 0.03352764 0.04257673 0.05727491 0.08146411 0.08834665
  0.04513802 0.0401821  0.03480607 0.01788644 0.09859043 0.04490376
  0.05349613 0.0388238  0.07481297 0.02626518 0.04001321 0.04853979
  0.07760429 0.10129515]
 [0.05268384 0.1069776  0.07806929 0.0459427  0.03816437 0.05289514
  0.19921704 0.12323732 0.07954965 0.05136866 0.13883981 0.06760688
  0.11567971 0.02633414 0.02679132 0.12010893 0.10856348 0.12515777
  0.08219071 0.09496206 0.08832209 0.05727326 0.08163016 0.13839406
  0.09805943 0.10934164 0.04695424 0.05662046 0.03745448 0.02629965
  0.02658586 0.07982572 0.11603215 0.0981598  0.15782036 0.16230679
  0.06037141 0.07738453 0.03274102 0.01447047 0.05641532 0.03466627
  0.05790785 0.03517988 0.03795306 0.0235667  0.06975854 0.1012115
  0.13078979 0.14079246]
 [0.05407591 0.03878862 0.04119183 0.03950927 0.02978015 0.0418365
  0.03390452 0.03929755 0.04313914 0.04462741 0.04286974 0.04746386
  0.04389991 0.03298025 0.02390742 0.03463435 0.04054595 0.04105702
  0.04492083 0.04620218 0.04305926 0.04622136 0.03315356 0.03053944
  0.03266219 0.04280219 0.03607043 0.04609129 0.03487152 0.03104222
  0.03115138 0.0376539  0.03443551 0.0343776  0.04536086 0.0558756
  0.04641929 0.04610411 0.06278415 0.03134769 0.0607701  0.10502046
  0.10179802 0.0789769  0.07802412 0.05973335 0.04219268 0.03582792
  0.03926379 0.04334133]
 [0.05266499 0.05199274 0.05133729 0.07324758 0.0619672  0.06603634
  0.04159073 0.04636491 0.05724725 0.0720736  0.05015379 0.05648942
  0.04925422 0.10051784 0.1206828  0.03878778 0.04415724 0.04388672
  0.04412464 0.0456579  0.0434363  0.05235793 0.05438396 0.02105802
  0.01910698 0.04213632 0.05795202 0.06213706 0.06370382 0.01239561
  0.07266481 0.05558567 0.02827032 0.03386828 0.02832426 0.02600946
  0.04245395 0.06349457 0.04150083 0.03452917 0.01809675 0.03108485
  0.03424557 0.04162233 0.02213644 0.11256401 0.05269704 0.03335472
  0.02710116 0.02460007]
 [0.05243317 0.06837675 0.0650679  0.11462106 0.23312321 0.0959344
  0.04998566 0.05504998 0.06709679 0.11491727 0.08353741 0.08439377
  0.05664567 0.16241048 0.19709876 0.05983634 0.08063748 0.07936912
  0.06399222 0.05893533 0.0764781  0.0520804  0.07285389 0.02285336
  0.01734746 0.04934938 0.09368055 0.06502885 0.06968421 0.00999481
  0.15415029 0.07599669 0.03282835 0.03695584 0.02741435 0.02517201
  0.05649216 0.06329952 0.02857761 0.02982636 0.01620835 0.02422154
  0.02070288 0.03412168 0.01991596 0.12509969 0.07077938 0.03424544
  0.02363431 0.02079918]
 [0.05252171 0.05458208 0.04898879 0.06400724 0.10234456 0.05139913
  0.03702204 0.04175037 0.04559384 0.07043567 0.06384029 0.06042699
  0.04725611 0.05701073 0.0745207  0.0527169  0.09494129 0.10240181
  0.0853983  0.06998695 0.11894248 0.05076126 0.05813132 0.03743586
  0.03751817 0.06043122 0.06877885 0.09296425 0.04756204 0.01716679
  0.18670093 0.06200586 0.05696219 0.04831908 0.04548149 0.04282459
  0.07234846 0.06084273 0.05429081 0.01870994 0.02789251 0.02965034
  0.0269453  0.05299137 0.04680081 0.096685   0.04940486 0.04684016
  0.03944784 0.03709856]
 [0.05256443 0.06189583 0.05523022 0.07415633 0.07287619 0.06543867
  0.0494035  0.05452029 0.06348392 0.07109668 0.05639168 0.0572281
  0.05243871 0.06536514 0.06245842 0.04389762 0.06740028 0.070157
  0.06401089 0.06606412 0.06911165 0.06737167 0.07106082 0.02682584
  0.02378446 0.05584448 0.06125705 0.09593078 0.05292834 0.00928933
  0.15435633 0.08056355 0.03430378 0.03955306 0.03431102 0.0338859
  0.05019725 0.07977076 0.03155861 0.01618033 0.0191406  0.02196615
  0.02045653 0.03016001 0.02531343 0.11155143 0.07786055 0.03725977
  0.0297292  0.02732238]]
Model's predictions for the sample 61:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 2 explicitly states that Mary   |
|          |                 |              is in the park.               |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  Sentence 4 states that Mary is either in  |
|          |                 |   the bedroom or the cinema, but it does   |
|          |                 |   not provide a definitive location for    |
|          |                 |   Mary. Therefore, we can only conclude    |
|          |                 |     that Mary might be in the bedroom.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 7 explicitly states that Fred   |
|          |                 |              is in the park.               |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     There is no mention of Bill in the     |
|          |                 |      context sentences, so we cannot       |
|          |                 |         determine Bill's location.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 13 explicitly states that Mary   |
|          |                 |             is in the kitchen.             |
+----------+-----------------+--------------------------------------------+

Metrics for sample 61:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.06 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 62/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 306/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Julie is in the kitchen, but there is no mention of Julie being in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02584241 0.03798989 0.04598817 0.06796603 0.07626163 0.06522221
  0.04504707 0.05294434 0.04419491 0.05881665 0.0396586  0.04841846
  0.05686249 0.10296416 0.07464983 0.02759351 0.02669613 0.02918812
  0.02510613 0.02872028 0.0225037  0.03466913 0.03758051 0.01507619
  0.01619213 0.02790241]
 [0.02548521 0.06224132 0.04572439 0.04138079 0.0321649  0.03904928
  0.09905439 0.05954244 0.04735918 0.03679082 0.05909485 0.03467641
  0.05842695 0.01934848 0.02040818 0.04155072 0.03922333 0.05261008
  0.03832281 0.04835983 0.04119938 0.03824813 0.03781214 0.04133015
  0.04093163 0.04312437]
 [0.02797953 0.05345944 0.03456498 0.05272054 0.03975359 0.03374393
  0.02807342 0.02019478 0.01999573 0.0325507  0.02434451 0.01453512
  0.0165263  0.03145574 0.04038634 0.02140294 0.01231973 0.01249647
  0.01491626 0.01620177 0.01452608 0.04061183 0.04697296 0.00725654
  0.00626615 0.01561572]
 [0.02639771 0.02872548 0.0332702  0.02404159 0.01755246 0.02439311
  0.02712744 0.02460639 0.02397569 0.02308212 0.02741783 0.02415428
  0.02299925 0.01474417 0.01595369 0.03494757 0.03271026 0.03201435
  0.03112097 0.03155216 0.03089163 0.02947846 0.04265941 0.05678081
  0.06136228 0.04261348]
 [0.02660806 0.03826083 0.04332776 0.06603914 0.06048011 0.04502183
  0.03038927 0.02653062 0.03056307 0.04335289 0.02977924 0.02276303
  0.02302055 0.10408796 0.10712769 0.03311867 0.02366408 0.01964243
  0.0193077  0.02197838 0.02026692 0.03612025 0.05488914 0.01255092
  0.00933908 0.03357048]
 [0.02716577 0.02465575 0.02634485 0.05043399 0.04511133 0.04063693
  0.02261996 0.02063289 0.02577752 0.04024927 0.02635252 0.02565381
  0.02469763 0.11348855 0.13442972 0.03270322 0.02659101 0.02364934
  0.02179036 0.0234674  0.01937924 0.03081912 0.03284851 0.0088752
  0.00750661 0.02183058]
 [0.02758003 0.02767383 0.03332145 0.05281217 0.04995371 0.05048433
  0.02922787 0.0278419  0.0333258  0.04728171 0.03071164 0.03999296
  0.03693738 0.08975217 0.08433689 0.0275429  0.02432741 0.02346505
  0.02095048 0.02316418 0.01835774 0.02774412 0.03074244 0.01219503
  0.01039034 0.02044976]
 [0.0266822  0.03501232 0.04192219 0.04094591 0.04344533 0.04653765
  0.03393688 0.03598609 0.03658855 0.04228437 0.03196034 0.04474597
  0.03856374 0.05383342 0.04808104 0.03572712 0.03060391 0.02961426
  0.02553757 0.02871352 0.02534901 0.0312819  0.04362224 0.03190253
  0.02804306 0.03446747]
 [0.02773611 0.03490967 0.0418408  0.04536721 0.04151875 0.05305978
  0.03644818 0.03926532 0.04266455 0.04777383 0.03213652 0.04627961
  0.04230648 0.0417983  0.02710658 0.02579326 0.02401976 0.02527317
  0.02277585 0.02592741 0.02035968 0.03210605 0.03320611 0.01560157
  0.01653139 0.02727027]
 [0.02709756 0.04774172 0.05411787 0.02955146 0.02388674 0.03749485
  0.04075501 0.03963634 0.04169986 0.03006154 0.02607538 0.03505589
  0.03479563 0.01859908 0.01612331 0.04027264 0.03143355 0.02813634
  0.02663396 0.03078867 0.02841262 0.03136178 0.06106858 0.03762488
  0.03982648 0.03634623]
 [0.02761349 0.06125811 0.06142608 0.02717602 0.02217577 0.03091614
  0.04020428 0.03545446 0.04250798 0.02601309 0.02316484 0.02727135
  0.02743088 0.01537433 0.01464687 0.04472169 0.03132213 0.02770078
  0.0276722  0.03371728 0.02777633 0.02857397 0.06294729 0.03141375
  0.02887703 0.03153868]
 [0.02771932 0.03425046 0.03884275 0.02112322 0.01847366 0.02307396
  0.03212833 0.02802589 0.03234344 0.02130939 0.01953928 0.0221172
  0.0212826  0.01325968 0.01346749 0.03941334 0.02938429 0.02452842
  0.02588876 0.02965696 0.02714919 0.02779737 0.05032794 0.04461873
  0.04591278 0.03633917]
 [0.02786996 0.01501565 0.0165262  0.01163925 0.01073047 0.01336485
  0.01543265 0.01548737 0.01711557 0.01266601 0.01344929 0.01372689
  0.01378392 0.00683522 0.0076852  0.01993695 0.01983067 0.01852222
  0.02119618 0.02511243 0.0273666  0.02067963 0.03503144 0.06083409
  0.07694793 0.04517029]
 [0.0278442  0.02116912 0.02204372 0.01562703 0.01501482 0.01860734
  0.02125355 0.02013786 0.02068642 0.01691973 0.01969279 0.01910895
  0.01863965 0.00962118 0.01052919 0.03153091 0.0244811  0.02283181
  0.02224704 0.0250313  0.02640005 0.02581372 0.02681211 0.05585168
  0.0616119  0.04169999]
 [0.02790155 0.02391765 0.02425646 0.0195861  0.01727114 0.02316825
  0.02849819 0.02961061 0.02350092 0.02232491 0.02678215 0.02797835
  0.02940827 0.01178353 0.01059236 0.03010098 0.02824371 0.0273503
  0.02356478 0.02576774 0.02911774 0.0275216  0.02002636 0.04782283
  0.03842177 0.02410958]
 [0.02761448 0.01960352 0.01655032 0.01429503 0.01197335 0.01493364
  0.02259129 0.02267301 0.01695016 0.01542433 0.02292478 0.01778536
  0.0217493  0.00746002 0.00772473 0.0270532  0.029934   0.03570917
  0.02852244 0.03018641 0.0459515  0.02453789 0.01665536 0.06545386
  0.0531882  0.02891595]
 [0.02813296 0.02050084 0.01848043 0.01578567 0.01417548 0.01774526
  0.02422351 0.02545618 0.01844264 0.01812964 0.03061686 0.02500311
  0.02549914 0.00884436 0.00830095 0.02558292 0.02912302 0.02830216
  0.02597351 0.02543593 0.03379012 0.02428494 0.01604478 0.05519396
  0.03789869 0.02084647]
 [0.02805059 0.017716   0.01539044 0.01192096 0.01154215 0.0141928
  0.02218215 0.02073454 0.01672793 0.01398875 0.0370829  0.01953607
  0.02139521 0.0066516  0.0069853  0.02672132 0.03295095 0.03051796
  0.0303406  0.02820903 0.03683423 0.02205532 0.01494424 0.0581458
  0.03687637 0.0248818 ]
 [0.02705349 0.02429263 0.02001714 0.0145494  0.01434035 0.01840888
  0.02700583 0.02486051 0.02464491 0.01781696 0.03436605 0.02104101
  0.02450081 0.00804845 0.00903045 0.02807533 0.05278381 0.03873381
  0.04654215 0.04136361 0.03948044 0.02691015 0.02703627 0.05990383
  0.05264584 0.0546818 ]
 [0.0283907  0.0178787  0.01594211 0.01364271 0.01193184 0.01625549
  0.02054212 0.02081688 0.01818127 0.01560106 0.03699945 0.02159156
  0.02011483 0.00799241 0.00761077 0.02219921 0.02686793 0.02776957
  0.02592031 0.02500529 0.02721831 0.02346286 0.01309916 0.03238006
  0.03109529 0.02627439]
 [0.02876458 0.01959374 0.02175959 0.01862197 0.01582995 0.02380582
  0.0232645  0.02890923 0.02549721 0.02320855 0.02481226 0.03076627
  0.02653197 0.01186938 0.00905474 0.01777999 0.02044405 0.02056097
  0.02243683 0.02129291 0.02031684 0.02602166 0.01418369 0.01525751
  0.02166628 0.0215304 ]
 [0.0286403  0.02096242 0.02146039 0.01792042 0.01518084 0.02199188
  0.02260779 0.02833084 0.02596945 0.02115714 0.02230249 0.02917851
  0.02562292 0.01072948 0.00910201 0.01935032 0.02099046 0.02056641
  0.02359859 0.02241318 0.02259498 0.02600993 0.01675463 0.01469271
  0.02014925 0.02282529]
 [0.02868087 0.02165793 0.02247406 0.01716279 0.01472312 0.02373129
  0.02570979 0.03067692 0.02795564 0.02091787 0.02686252 0.03805603
  0.0301621  0.01022392 0.00883433 0.02129216 0.02599602 0.0255668
  0.0271524  0.02521489 0.02465836 0.02345984 0.01805959 0.01626042
  0.02095712 0.02379998]
 [0.0289023  0.02198474 0.02355707 0.01973379 0.0162404  0.02821677
  0.02380481 0.02892041 0.03376647 0.02454761 0.0193497  0.03327216
  0.02869909 0.01210905 0.00908765 0.01633406 0.01943849 0.01952766
  0.02299179 0.02224571 0.02001021 0.02400093 0.01896531 0.01238902
  0.0197907  0.02590829]
 [0.02838171 0.03162554 0.02882965 0.02147058 0.01706015 0.02991577
  0.03028416 0.03831286 0.03425387 0.0274378  0.02785364 0.04329084
  0.03915624 0.01288408 0.01011773 0.02368812 0.02258058 0.02437201
  0.02571023 0.02597422 0.02427877 0.02785585 0.02138521 0.0152699
  0.01958419 0.0219224 ]
 [0.02896541 0.02298261 0.02556406 0.02019603 0.01538376 0.02858046
  0.0287223  0.03117703 0.03250759 0.02464549 0.02371707 0.03556259
  0.03181686 0.01187654 0.00890566 0.02052956 0.01953592 0.02060985
  0.02310945 0.02453826 0.02259025 0.02513222 0.01577151 0.01274491
  0.01591811 0.01698771]
 [0.02834054 0.01778653 0.01719695 0.01341843 0.01051718 0.01537097
  0.02124573 0.02357871 0.02182661 0.01644936 0.02404882 0.02087752
  0.02535    0.00814921 0.0071748  0.02817776 0.02563952 0.02610736
  0.02885335 0.02880974 0.03352337 0.0248547  0.01209149 0.02390916
  0.02591898 0.02017666]
 [0.02840546 0.01896177 0.01805989 0.01430461 0.01058866 0.01476123
  0.0222169  0.02530879 0.02227991 0.01620737 0.02155348 0.01903965
  0.02431818 0.0079316  0.00682783 0.03156577 0.0266964  0.03275585
  0.02979285 0.0316671  0.04079704 0.02352055 0.01253929 0.02460629
  0.02730894 0.02187002]
 [0.02865278 0.01906931 0.01766874 0.01439623 0.01148911 0.01519675
  0.01967693 0.02387247 0.02199834 0.01746759 0.02379537 0.02228989
  0.02419745 0.00828394 0.00694599 0.02979178 0.02704522 0.0277826
  0.03088699 0.02912179 0.03447456 0.02265424 0.01156524 0.01853201
  0.02057871 0.01762809]
 [0.02851091 0.01681728 0.01677717 0.01175549 0.01017821 0.01332174
  0.01843127 0.02099985 0.02127988 0.0150097  0.02493486 0.01872405
  0.01993525 0.0072919  0.00638501 0.02840769 0.02838697 0.02347844
  0.03071794 0.02749911 0.03274469 0.02289039 0.0118764  0.01977142
  0.02288604 0.02212193]
 [0.02770822 0.01933048 0.01847365 0.01303552 0.01119626 0.01509169
  0.01966564 0.02140848 0.02462218 0.01630933 0.0249668  0.01969685
  0.01987438 0.00814861 0.00742967 0.03387888 0.03229667 0.02521452
  0.03528293 0.02894392 0.03427221 0.02486009 0.01580674 0.02330719
  0.02776734 0.03797308]
 [0.02884277 0.01967125 0.01984983 0.01520856 0.01176466 0.01829034
  0.01961439 0.02280617 0.02533812 0.01773948 0.02109191 0.02142807
  0.02160016 0.00986561 0.00767637 0.02076497 0.02220597 0.020137
  0.02870187 0.02479518 0.02570526 0.02438463 0.01561353 0.0139235
  0.01767229 0.02183175]
 [0.02778547 0.02471371 0.02512995 0.04244475 0.04365285 0.03598262
  0.02217433 0.02305623 0.02914129 0.04616832 0.02896223 0.03152199
  0.03149321 0.06479005 0.08071526 0.0222589  0.02459801 0.02582966
  0.02359093 0.02377269 0.020339   0.0293214  0.02677261 0.00877891
  0.0097382  0.02320845]
 [0.02755799 0.02684703 0.02570424 0.04731597 0.09277298 0.03508912
  0.01953708 0.0209968  0.02628765 0.04835431 0.03251154 0.02797347
  0.02354914 0.07286532 0.09191034 0.02796909 0.03408357 0.0360629
  0.02938847 0.02681208 0.02329479 0.02679223 0.02751555 0.00739141
  0.00685503 0.02057748]
 [0.02741833 0.02339741 0.02246879 0.03797285 0.06944887 0.02563504
  0.01626743 0.02029033 0.02332288 0.04350651 0.03203762 0.0313807
  0.02475343 0.02816482 0.03323518 0.02303367 0.04344535 0.05700259
  0.05668604 0.03657256 0.03178522 0.02327631 0.02320628 0.01236593
  0.01303892 0.02292535]
 [0.02767719 0.02832535 0.02512769 0.03843782 0.05621536 0.02870797
  0.02003569 0.0209165  0.02670686 0.03843576 0.0290498  0.02550602
  0.0239986  0.02887367 0.03142083 0.01918892 0.03010607 0.03636956
  0.03676928 0.03196719 0.02628396 0.04088665 0.03356584 0.00998735
  0.01030496 0.02106424]]

-* TASK 10/20 | SAMPLE 62/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 307/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Julie in the context sentences. The sentences only talk about Mary's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.1429, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03340549 0.0402723  0.04051293 0.06898121 0.06351647 0.04994522
  0.032793   0.03634994 0.04668669 0.0543239  0.03805292 0.0372152
  0.03571206 0.09966173 0.09733085 0.03647519 0.03182515 0.029237
  0.02967309 0.0315125  0.02761082 0.03705804 0.04690108 0.0215606
  0.0183228  0.03814672 0.03632502 0.04800689 0.11364461 0.0704807
  0.01795247 0.01079681]
 [0.03457598 0.0368641  0.03615136 0.07417627 0.08020308 0.06981414
  0.03335086 0.03413353 0.04393921 0.06660296 0.04643291 0.04958097
  0.04353086 0.16481087 0.14346002 0.04085554 0.03093085 0.0307014
  0.02858736 0.03074628 0.02657385 0.0387507  0.03362781 0.01621063
  0.01439336 0.03264134 0.04059712 0.03535197 0.08693518 0.07932508
  0.02127734 0.01270369]
 [0.03509771 0.03715851 0.03993138 0.06739778 0.06565052 0.05901688
  0.03450291 0.03664334 0.04433304 0.05741699 0.03947506 0.04985277
  0.04262433 0.1073069  0.07893449 0.03371494 0.02917567 0.02722918
  0.02669601 0.02819361 0.02397067 0.03601448 0.03385012 0.01942091
  0.0173302  0.03096626 0.03605649 0.03118471 0.05917273 0.07430931
  0.03356674 0.01806117]
 [0.03384809 0.03446383 0.03717665 0.03693164 0.03362856 0.03710545
  0.03140467 0.03561291 0.03601406 0.03474955 0.03171946 0.03838878
  0.03467307 0.02869123 0.02868931 0.03230244 0.03209697 0.02831166
  0.02986298 0.03222052 0.03006288 0.03788886 0.04168953 0.0424917
  0.03665788 0.04278461 0.03986476 0.03927558 0.04336066 0.07506067
  0.06136649 0.03872711]
 [0.0353319  0.02919276 0.03106462 0.02611942 0.02238984 0.03036089
  0.02703972 0.02958581 0.0308532  0.02729877 0.02674664 0.03417866
  0.02855401 0.01811291 0.01960193 0.02896075 0.03026097 0.02594593
  0.0305163  0.03111034 0.03039804 0.03195516 0.03281978 0.03356064
  0.0371808  0.0388076  0.03503118 0.02808257 0.0278099  0.03422545
  0.07403478 0.06451527]
 [0.03595134 0.03126905 0.03256518 0.02744547 0.02498984 0.03515996
  0.02856228 0.03107049 0.03379853 0.0313144  0.02819487 0.03903767
  0.03262859 0.02093793 0.01949903 0.02759316 0.02759546 0.02485327
  0.02910531 0.02876616 0.0273795  0.03187027 0.03043561 0.02893885
  0.02891643 0.0311752  0.03742356 0.02474903 0.0278918  0.03434455
  0.06638506 0.0753527 ]
 [0.0350314  0.04567708 0.04285428 0.03407158 0.02949838 0.04174541
  0.04065186 0.04153749 0.04122532 0.03760838 0.03390393 0.04907608
  0.04396497 0.02514326 0.02380915 0.03505627 0.03562004 0.03202685
  0.03409313 0.03436149 0.03331774 0.03655786 0.04193607 0.04275336
  0.0399224  0.0383498  0.04691982 0.03378457 0.03279025 0.03891841
  0.04975755 0.08788662]
 [0.03612432 0.03438669 0.03660912 0.02831028 0.02514454 0.03769014
  0.03638059 0.03579672 0.03663374 0.03262253 0.03109879 0.0429319
  0.03833269 0.02161107 0.0203351  0.03272875 0.0324997  0.02873796
  0.03274982 0.03308411 0.03135767 0.03325489 0.03134624 0.03579303
  0.03286907 0.03136772 0.04123183 0.03033805 0.02941801 0.03662647
  0.04938256 0.09277359]
 [0.03509152 0.03155445 0.02628383 0.02246249 0.02218855 0.02542471
  0.03403174 0.02919696 0.02462283 0.02535419 0.03478554 0.02910456
  0.03580303 0.01613601 0.01727498 0.03746486 0.04232422 0.03828818
  0.03797171 0.03796824 0.04572417 0.0359789  0.02416665 0.06181318
  0.04892268 0.03218589 0.02763436 0.03941851 0.02528527 0.02102816
  0.03729863 0.06341176]
 [0.03554532 0.03060695 0.02781126 0.01995454 0.01865478 0.02462012
  0.03709923 0.0304448  0.02645946 0.02258451 0.0290243  0.02845207
  0.03375218 0.01405096 0.01530993 0.03416341 0.03842847 0.03709658
  0.03634451 0.03636489 0.04595119 0.0323862  0.02688429 0.05996357
  0.05658767 0.03961521 0.02699965 0.04625301 0.02473862 0.02188138
  0.044214   0.05737156]
 [0.03584447 0.03674196 0.04223186 0.02132588 0.02275328 0.02894963
  0.03874622 0.03295462 0.0396276  0.02244147 0.0280234  0.02900646
  0.02838643 0.01580916 0.01759596 0.03762174 0.03485331 0.02763293
  0.034346   0.03337197 0.03743197 0.03401151 0.04856415 0.04243937
  0.03769963 0.03855874 0.03874181 0.04000245 0.02401646 0.04483804
  0.0450546  0.04467151]
 [0.0351923  0.05477804 0.05639556 0.02466365 0.02385106 0.0338884
  0.0478522  0.03473801 0.05189795 0.02443788 0.02815387 0.03046983
  0.03095599 0.01789542 0.02075371 0.04152504 0.03412065 0.02714771
  0.03568649 0.03376884 0.03416852 0.03603151 0.06543292 0.03729574
  0.02848225 0.04227281 0.04596775 0.03728145 0.0232566  0.03392435
  0.03486434 0.0277672 ]
 [0.03593032 0.07341707 0.07061414 0.02532873 0.02435988 0.03467617
  0.0473307  0.03853808 0.05117562 0.0253998  0.02578302 0.02992894
  0.0305937  0.01865726 0.0216424  0.05193153 0.03724432 0.02766712
  0.03261822 0.03385879 0.03160259 0.03509826 0.08553379 0.04307484
  0.03193382 0.04389743 0.06171348 0.03040203 0.02620438 0.05901155
  0.03073325 0.02587426]
 [0.0359213  0.03981847 0.04604692 0.0244948  0.02379887 0.03083174
  0.03816739 0.03342123 0.04200552 0.02484213 0.0252369  0.02853847
  0.026642   0.01897439 0.02084901 0.04126261 0.03425156 0.02682617
  0.03297167 0.03375296 0.03109914 0.03364247 0.05419041 0.04623578
  0.03466449 0.04232446 0.05058162 0.03053815 0.02684139 0.05157917
  0.03916106 0.02708448]
 [0.03570382 0.02668835 0.02906542 0.02749694 0.02572418 0.03120946
  0.03061752 0.0321787  0.03525066 0.03369848 0.03006434 0.0374627
  0.03574398 0.02285044 0.0211162  0.03037149 0.03125878 0.02971058
  0.03027096 0.03099075 0.03097812 0.03696095 0.02784765 0.0397599
  0.0373542  0.03460521 0.03114968 0.0431917  0.03460117 0.04534563
  0.04218907 0.03224793]
 [0.03595159 0.04473343 0.04250862 0.02991842 0.02528619 0.03465418
  0.04087836 0.04515375 0.03617458 0.03017833 0.03318447 0.03482755
  0.03959193 0.02311167 0.02131323 0.03656208 0.03259588 0.0288318
  0.03212094 0.03132835 0.02969479 0.03660259 0.033957   0.03195625
  0.03511095 0.03430469 0.04167124 0.0279587  0.02673349 0.03226411
  0.03105824 0.02901259]
 [0.03642169 0.04221617 0.04396715 0.02802407 0.0223302  0.03322092
  0.04693363 0.0443195  0.03510508 0.02627466 0.02916782 0.0319467
  0.03421342 0.01935349 0.0194657  0.04263953 0.03482727 0.03034785
  0.03412415 0.0339678  0.03184966 0.03783143 0.03860421 0.03999316
  0.04221479 0.03513344 0.04103653 0.02494709 0.02542112 0.04006549
  0.03166446 0.02940549]
 [0.03723584 0.03106977 0.03224522 0.02524225 0.01860073 0.03168807
  0.04080286 0.04583423 0.02910989 0.02570455 0.02830298 0.03117451
  0.03746766 0.01716638 0.01615126 0.0326302  0.03075854 0.02847025
  0.03001527 0.02974405 0.02956374 0.0360981  0.02470248 0.03398678
  0.04588618 0.03289607 0.02946526 0.02170066 0.02475356 0.02208007
  0.03109105 0.03338055]
 [0.03769685 0.03056581 0.03498945 0.02747635 0.02088948 0.03367108
  0.0415914  0.04346404 0.03208695 0.02878105 0.0311137  0.03142921
  0.03674467 0.01933162 0.01738139 0.03231294 0.02693827 0.02706696
  0.02843131 0.0289175  0.02773829 0.03541062 0.02534234 0.02824955
  0.03150101 0.02710193 0.02983144 0.02181024 0.02734384 0.02210234
  0.02954266 0.02741189]
 [0.0363455  0.02346271 0.02276305 0.01809313 0.01373808 0.02070196
  0.03144102 0.03057383 0.02189774 0.01792415 0.0303812  0.02025232
  0.03088736 0.01274963 0.01358401 0.03532338 0.03804912 0.03109205
  0.03400101 0.03214008 0.03650672 0.03371974 0.01824184 0.04970473
  0.07862145 0.03748232 0.0187606  0.02573589 0.02026982 0.01538682
  0.02848645 0.02833229]
 [0.03655288 0.01956469 0.01920023 0.01770602 0.01260861 0.01921826
  0.02613793 0.0272386  0.02016937 0.01745355 0.02963752 0.01972223
  0.02635313 0.01264878 0.01278478 0.03195311 0.04067389 0.03167839
  0.0389484  0.03476154 0.03699513 0.03236002 0.01458435 0.04119234
  0.06379665 0.03499727 0.01514763 0.02618917 0.02135078 0.01402379
  0.03729082 0.03342784]
 [0.0362975  0.03387244 0.03007553 0.02341585 0.01568948 0.02425146
  0.04515941 0.05205752 0.02836702 0.02365839 0.05865622 0.02908926
  0.04644994 0.01560381 0.01653129 0.05049571 0.06015461 0.05060569
  0.05173568 0.04759154 0.04660932 0.03648594 0.01939972 0.05987385
  0.06375842 0.03891325 0.02027415 0.02990383 0.02387736 0.01423083
  0.03651741 0.03766119]
 [0.03706019 0.02399111 0.0259265  0.02266222 0.01587213 0.02449594
  0.03431976 0.0375589  0.02765962 0.02359205 0.05396671 0.02811547
  0.03682766 0.01605946 0.01514389 0.03883828 0.04740411 0.03783714
  0.04425207 0.04091566 0.04016405 0.03164788 0.01635289 0.03950422
  0.0408044  0.03319775 0.01581896 0.02938726 0.02120323 0.01548366
  0.04503585 0.02761562]
 [0.03552848 0.02894849 0.03110199 0.05218736 0.04827803 0.04511123
  0.03276924 0.03415651 0.04087256 0.05491474 0.04047969 0.04121833
  0.04201306 0.06907014 0.08866618 0.03080072 0.03045666 0.04110639
  0.03619317 0.03655539 0.0360133  0.0377689  0.03252978 0.01873235
  0.01849483 0.03141467 0.02924555 0.04824101 0.05276366 0.02803588
  0.01807043 0.01206281]
 [0.03497782 0.03671754 0.03274035 0.07525728 0.13980743 0.05412856
  0.03153469 0.03275666 0.0378451  0.07597344 0.05638788 0.05061865
  0.03969887 0.08329365 0.10674039 0.03857584 0.0461131  0.08104302
  0.05316547 0.05189043 0.05079803 0.03713225 0.04028155 0.01834583
  0.0151716  0.03391498 0.04399038 0.04784219 0.05023384 0.02587195
  0.01194487 0.0093192 ]
 [0.03535566 0.03595902 0.02886924 0.04698201 0.05877123 0.0348909
  0.02948644 0.03079653 0.0330762  0.0495433  0.05051481 0.04671632
  0.03975473 0.0337714  0.0402849  0.03584942 0.04786161 0.07685134
  0.05739656 0.05741486 0.05549735 0.03416755 0.03523958 0.0248419
  0.02358889 0.03383985 0.0381071  0.04820903 0.02906311 0.01580647
  0.01663376 0.01532726]
 [0.03591144 0.03533548 0.03180147 0.05878053 0.06317353 0.03947265
  0.03095168 0.03414413 0.03883994 0.06067592 0.04460631 0.04622763
  0.03666328 0.0361104  0.03449968 0.02737855 0.03362441 0.05623485
  0.04149213 0.04420492 0.0481791  0.0382495  0.03825079 0.02234186
  0.02024382 0.03634486 0.04657805 0.05264989 0.03185489 0.01695633
  0.01781575 0.01902462]
 [0.03606921 0.0306738  0.02849673 0.04509383 0.03860304 0.03405656
  0.02946267 0.02974311 0.03427262 0.04463001 0.03690477 0.03543684
  0.03143638 0.03108004 0.0312513  0.02461247 0.0280563  0.03742176
  0.03663028 0.04049657 0.04276365 0.04506538 0.03728743 0.01996518
  0.01956935 0.0327599  0.033835   0.05756444 0.03916422 0.01679326
  0.01761029 0.018773  ]]

-* TASK 10/20 | SAMPLE 62/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 308/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, Mary journeyed to the cinema, which implies that Mary is currently in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.0300621  0.03921674 0.04033665 ... 0.02951797 0.02035984 0.02643058]
 [0.03061793 0.03333037 0.03114679 ... 0.02818779 0.03117759 0.0383811 ]
 [0.03128774 0.04372052 0.04944995 ... 0.02157403 0.01830246 0.01854025]
 ...
 [0.03153666 0.03687435 0.04090162 ... 0.02161017 0.01697205 0.01778552]
 [0.03180325 0.02956535 0.03030067 ... 0.02631149 0.02839581 0.02705716]
 [0.03180834 0.03224299 0.03323768 ... 0.02655644 0.02105496 0.02465979]]

-* TASK 10/20 | SAMPLE 62/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 309/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary's current location in the context sentences. The sentences only talk about Bill and Julie being in the cinema.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', "'s", ' current', ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Bill', ' and', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 44), x_tokens=44, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 44)
DEBUG result.interpretability.attn_scores 1540 
 [[0.02676414 0.03020536 0.03336153 ... 0.03237899 0.01323602 0.01351551]
 [0.02721537 0.0290933  0.03194968 ... 0.03200087 0.03003286 0.01449327]
 [0.02788563 0.0329955  0.03803848 ... 0.04417664 0.01616353 0.01449807]
 ...
 [0.02841758 0.03142896 0.02635764 ... 0.0148193  0.00989885 0.00927576]
 [0.02901668 0.03492329 0.02999339 ... 0.01313895 0.00975865 0.00891098]
 [0.02876236 0.0307281  0.02718199 ... 0.01396344 0.01171168 0.01027185]]

-* TASK 10/20 | SAMPLE 62/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 310/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 13, Bill went to the park, which implies that Bill is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Bill', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 50), x_tokens=50, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 50)
DEBUG result.interpretability.attn_scores 1500 
 [[0.03123933 0.04412443 0.04130626 ... 0.02279956 0.02040853 0.02818211]
 [0.03211806 0.04023015 0.03757362 ... 0.02197433 0.02361697 0.02750874]
 [0.03271823 0.04793566 0.04984029 ... 0.01884931 0.01720979 0.0214044 ]
 ...
 [0.03292793 0.04212654 0.0445145  ... 0.0159954  0.01468702 0.02279514]
 [0.0332773  0.03095585 0.03125685 ... 0.02053547 0.02061067 0.02544271]
 [0.03301919 0.03568759 0.03533045 ... 0.01698064 0.01621847 0.02254645]]
Model's predictions for the sample 62:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 1, Julie   |
|          |                 |     is in the kitchen, but there is no     |
|          |                 |   mention of Julie being in the office.    |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no mention of Julie in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |        talk about Mary's locations.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 8, Mary    |
|          |                 |   journeyed to the cinema, which implies   |
|          |                 |   that Mary is currently in the cinema.    |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no mention of Mary's current    |
|          |                 |   location in the context sentences. The   |
|          |                 |  sentences only talk about Bill and Julie  |
|          |                 |            being in the cinema.            |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 13, Bill   |
|          |                 |    went to the park, which implies that    |
|          |                 |       Bill is currently in the park.       |
+----------+-----------------+--------------------------------------------+

Metrics for sample 62:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 63/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 311/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the park. The context sentences only mention Fred going to the kitchen, but not the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' going', ' to', ' the', ' kitchen', ',', ' but', ' not', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02678757 0.0464577  0.0499487  0.07858317 0.07706419 0.0479445
  0.03491832 0.03083831 0.0331291  0.05003469 0.03838016 0.02341835
  0.02515892 0.12456378 0.12997645 0.04111891 0.0279401  0.01802579
  0.0166317  0.01650968 0.01985081 0.03983327 0.0628809  0.01478461
  0.00935858 0.02625952]
 [0.02761493 0.02909814 0.02946735 0.05853707 0.05478735 0.04134151
  0.0245092  0.02225303 0.02638449 0.04314832 0.03320467 0.02522714
  0.02499872 0.12714131 0.15501913 0.03915134 0.0301795  0.02143668
  0.0183537  0.01709061 0.01869834 0.03369563 0.0376252  0.01145833
  0.00773541 0.01723386]
 [0.02807116 0.0328307  0.03774578 0.06172298 0.06203562 0.05345635
  0.03330002 0.03189392 0.03543762 0.05151646 0.03836465 0.04096663
  0.03982606 0.10199714 0.09540201 0.03263503 0.0278632  0.02206598
  0.01797518 0.01743503 0.01793579 0.03070034 0.0346358  0.01532212
  0.0105766  0.01653535]
 [0.02710462 0.03823659 0.04434418 0.04701428 0.05025455 0.04862502
  0.03898792 0.04182545 0.04037286 0.04605849 0.03790185 0.04739801
  0.04311927 0.06036402 0.05535094 0.04024385 0.03605459 0.03008801
  0.02453728 0.02451367 0.02561204 0.03499373 0.04893239 0.03310816
  0.03020043 0.03054138]
 [0.02814353 0.03338268 0.03928185 0.03586136 0.03227216 0.04193474
  0.03738831 0.04089301 0.03718336 0.03675072 0.03182821 0.0424927
  0.03779476 0.02312156 0.01763646 0.02892904 0.02787002 0.02649337
  0.02364997 0.02372456 0.0238878  0.02808872 0.03612327 0.03016523
  0.02647473 0.03133202]
 [0.02851767 0.03194659 0.03491473 0.02974514 0.02449977 0.04043296
  0.03758464 0.03907678 0.03842496 0.03426612 0.03109345 0.04503926
  0.0378353  0.02003312 0.01494452 0.02770791 0.02747436 0.02442072
  0.0234765  0.02305753 0.02275123 0.02807395 0.03309895 0.02917141
  0.0236134  0.02855049]
 [0.02791491 0.04983045 0.04380775 0.03382562 0.02863881 0.04561969
  0.04583883 0.05192985 0.04704884 0.04187582 0.03833245 0.06064409
  0.05270419 0.02340919 0.01666489 0.03435118 0.03085299 0.03050229
  0.02742204 0.02676313 0.02568428 0.0297856  0.03823464 0.0308131
  0.0237331  0.02598718]
 [0.02862389 0.03875535 0.04319645 0.03372038 0.0243694  0.05546317
  0.04563221 0.04745029 0.0465784  0.03892633 0.03384878 0.06975307
  0.05461781 0.02176483 0.01514277 0.03324448 0.02989174 0.02704659
  0.02416349 0.02448191 0.02425317 0.02868804 0.03096831 0.02574488
  0.01880923 0.01888042]
 [0.02877311 0.04613348 0.05606003 0.03895555 0.02621834 0.07780895
  0.06783409 0.05035995 0.06216277 0.04149098 0.03283372 0.05907417
  0.0446828  0.02174316 0.01584762 0.03000957 0.02432735 0.02083671
  0.01976541 0.02115097 0.02125821 0.02903792 0.03704828 0.02314974
  0.01635766 0.0195369 ]
 [0.02811502 0.02360685 0.0235362  0.02017389 0.01624143 0.02259162
  0.03202014 0.03226235 0.02596022 0.02352715 0.02967165 0.02931833
  0.03897359 0.01209828 0.0106975  0.03039267 0.03499163 0.03437193
  0.0359373  0.03339747 0.03802981 0.0294372  0.01965269 0.03234742
  0.04014716 0.02668838]
 [0.02802452 0.02089363 0.01788313 0.01745858 0.01350358 0.01611333
  0.02559087 0.02491851 0.01977589 0.01726017 0.02346084 0.01976362
  0.02302477 0.00903283 0.00918867 0.03326369 0.02866537 0.04151707
  0.04263077 0.04881113 0.04588066 0.02672958 0.01695236 0.04590214
  0.0534743  0.03338999]
 [0.02866236 0.02100276 0.01794072 0.01814568 0.01565014 0.01805869
  0.02515428 0.02621937 0.02051212 0.0206535  0.02843593 0.02640755
  0.02622897 0.01020044 0.00975735 0.03289117 0.03345177 0.03401086
  0.03653283 0.03456008 0.03752135 0.02470547 0.01425865 0.0314784
  0.0283888  0.01962097]
 [0.02865705 0.01708278 0.01515327 0.01339614 0.01321913 0.01364868
  0.02211494 0.02098241 0.0179141  0.01566323 0.02753777 0.0199251
  0.02065425 0.00778052 0.00820662 0.02933803 0.0372208  0.03211553
  0.04551371 0.0403039  0.04301985 0.0246674  0.01366848 0.03017349
  0.02647243 0.02344133]
 [0.02811001 0.02018429 0.0178206  0.01421103 0.01399874 0.01512284
  0.02454192 0.0223373  0.0209838  0.01594554 0.02846933 0.01846764
  0.02162046 0.00809442 0.00901724 0.0325877  0.03702886 0.03195304
  0.04437273 0.0361406  0.03803428 0.02687055 0.02101189 0.0514659
  0.04196455 0.04289012]
 [0.02877918 0.02501368 0.02255384 0.01884932 0.01640078 0.01952661
  0.0248654  0.02554409 0.02381142 0.02137542 0.02611001 0.02433048
  0.02399196 0.01122422 0.01059148 0.02361103 0.02530472 0.025797
  0.03744555 0.04283349 0.03859879 0.02695014 0.02278782 0.02540626
  0.02171199 0.02228444]
 [0.02838831 0.02929347 0.02818305 0.03008493 0.02636188 0.03312719
  0.02948097 0.03093339 0.03119244 0.03650493 0.02855521 0.04162184
  0.03918819 0.02275381 0.01600602 0.02514816 0.02959283 0.03170222
  0.02574976 0.02419106 0.02438622 0.03156124 0.03612568 0.02531083
  0.028802   0.03023372]
 [0.02824383 0.0442933  0.04255142 0.02414312 0.02025669 0.0278594
  0.03808948 0.03675164 0.03412488 0.02347799 0.02526194 0.02725881
  0.03190159 0.01526683 0.01357798 0.03313395 0.02943251 0.02623159
  0.02539919 0.02814542 0.02732345 0.03002717 0.05390669 0.0369559
  0.04006544 0.04125072]
 [0.02866173 0.06826629 0.07101667 0.02902948 0.02275618 0.03266668
  0.04732624 0.04186866 0.0442599  0.02601034 0.02561262 0.02749149
  0.02973876 0.0157935  0.0144512  0.04283729 0.03043965 0.02250282
  0.02015009 0.02273952 0.02252113 0.03052047 0.06589438 0.03067912
  0.02397366 0.02404816]
 [0.02874619 0.03872846 0.04195247 0.02487532 0.01977075 0.02820857
  0.03836995 0.03677    0.03492351 0.02332068 0.0230863  0.02561769
  0.02573647 0.01410055 0.01276991 0.03365375 0.02708087 0.02183354
  0.0201167  0.02194773 0.0237079  0.0311838  0.04639827 0.03981257
  0.0360048  0.03349463]
 [0.02947437 0.02892733 0.02821349 0.02127595 0.01678664 0.02509012
  0.02947349 0.03217807 0.02691607 0.02098637 0.02307676 0.02451776
  0.02560395 0.01199321 0.01019524 0.02424721 0.02053848 0.02055527
  0.01880116 0.0199761  0.02115166 0.02848635 0.02374414 0.02917325
  0.02683613 0.02829917]
 [0.02887174 0.02102648 0.0190687  0.01492068 0.01287805 0.01627544
  0.0223552  0.0221439  0.020144   0.01555929 0.02231338 0.0157364
  0.020677   0.00876096 0.00820534 0.02821435 0.02480363 0.02468669
  0.02518979 0.02712363 0.03038145 0.02585423 0.0204428  0.06161335
  0.05847413 0.04012827]
 [0.02856467 0.01769565 0.0154182  0.01354649 0.01125035 0.01290759
  0.01909242 0.017042   0.01687215 0.01373061 0.01875293 0.01235716
  0.01754894 0.00771616 0.00762261 0.02413918 0.02376238 0.03542551
  0.03449148 0.04571822 0.04025164 0.02545003 0.01700595 0.04551948
  0.08866421 0.05052994]
 [0.02899215 0.01507179 0.01392903 0.01227754 0.01070515 0.01252725
  0.01713756 0.01634943 0.01582021 0.01307469 0.01908571 0.0129128
  0.01670735 0.00728603 0.00689041 0.02428034 0.02328486 0.029892
  0.02515785 0.04119634 0.03931225 0.02142003 0.01433513 0.03914727
  0.07663652 0.0425127 ]
 [0.0288249  0.01497531 0.01307585 0.01094243 0.00963319 0.01122232
  0.01690477 0.01495564 0.01526492 0.0116786  0.02368866 0.01182938
  0.01616342 0.00667727 0.00647297 0.02883661 0.03118726 0.03270873
  0.03146809 0.03847884 0.03662214 0.02268268 0.01461395 0.04462017
  0.05505919 0.0602094 ]
 [0.02818626 0.02039306 0.01746518 0.01568596 0.01419496 0.01511215
  0.02133243 0.01822077 0.02052958 0.01592026 0.02430294 0.01473036
  0.01960102 0.00904991 0.00868513 0.02395988 0.02946538 0.03216808
  0.03899698 0.05100969 0.03834582 0.02827187 0.02336113 0.04281055
  0.04123023 0.06822977]
 [0.02930406 0.01702664 0.015071   0.01314355 0.01107389 0.01308662
  0.01657849 0.01565469 0.0173613  0.01367162 0.02226925 0.01330283
  0.01637407 0.00813579 0.00743126 0.01971655 0.02515124 0.02565741
  0.02591633 0.02420714 0.0257303  0.02441533 0.01722516 0.0309379
  0.03296162 0.05182859]
 [0.02999567 0.01915704 0.01948419 0.0164768  0.01355758 0.01774337
  0.02014885 0.02326649 0.02366293 0.01870823 0.0215834  0.02032648
  0.02136135 0.01126428 0.00797874 0.01890887 0.01792047 0.01691355
  0.01915609 0.01782461 0.01934068 0.02644452 0.01493192 0.02402244
  0.0201225  0.01969073]
 [0.03014453 0.0217129  0.02156655 0.0200025  0.01600308 0.02003522
  0.02084628 0.02844078 0.0276211  0.02291337 0.02375545 0.02719587
  0.02665719 0.01237278 0.00862841 0.01667263 0.01706372 0.01634066
  0.01786813 0.01692108 0.01855805 0.02685282 0.01371424 0.012894
  0.0104825  0.01132825]
 [0.03003359 0.01748372 0.01684236 0.01455684 0.01191802 0.01470775
  0.01826597 0.02190944 0.02094262 0.01705371 0.02282389 0.02006955
  0.02125257 0.00953192 0.00704191 0.01988666 0.02081042 0.02175907
  0.02425821 0.02631921 0.02484698 0.02365961 0.01132104 0.01719552
  0.01494599 0.01157152]
 [0.02960514 0.01757703 0.01644498 0.01253614 0.01075256 0.01293164
  0.01965242 0.01997219 0.01948639 0.01460141 0.02811865 0.01666659
  0.01946949 0.00878854 0.00693614 0.02442567 0.02880305 0.02503423
  0.0369872  0.03328113 0.0301282  0.02333533 0.01288198 0.02289647
  0.0169999  0.01724862]
 [0.02959148 0.01960226 0.01948583 0.01979201 0.01563302 0.01731404
  0.01960755 0.02158207 0.0232162  0.02264089 0.02521303 0.02180251
  0.02263413 0.01490631 0.01408484 0.01911991 0.02198873 0.02167525
  0.02941113 0.02961112 0.02885524 0.02630996 0.01544682 0.01540104
  0.01327074 0.01513832]
 [0.02815988 0.03100238 0.02961626 0.05472721 0.06149042 0.04185636
  0.02610974 0.02614482 0.0313035  0.05299121 0.03651464 0.02995085
  0.03285396 0.08826894 0.10274819 0.02729196 0.02739157 0.02411219
  0.01910419 0.01746527 0.01959672 0.03322563 0.03408537 0.01157625
  0.00866655 0.01952572]
 [0.02809616 0.03113523 0.02904693 0.05478435 0.10937717 0.0364799
  0.02178492 0.0231336  0.02707704 0.05274963 0.03875231 0.02726913
  0.02408987 0.08411009 0.10576688 0.03271132 0.03863446 0.03627565
  0.02548665 0.02074723 0.02323347 0.0291121  0.03348316 0.01049938
  0.00702584 0.01682781]
 [0.0280039  0.02433122 0.02316761 0.03863832 0.06266905 0.02534309
  0.01700574 0.02139298 0.02510794 0.04492925 0.03500577 0.03000966
  0.02860839 0.03108595 0.03262619 0.02334041 0.04123107 0.06769997
  0.05638207 0.0331824  0.03442207 0.02538521 0.02759229 0.01519228
  0.01108849 0.01819711]
 [0.02821193 0.02784473 0.02474563 0.03836017 0.05377728 0.02781665
  0.02015633 0.02250477 0.02849335 0.04098395 0.0327538  0.02710661
  0.02860047 0.02956833 0.02843692 0.0199997  0.03230045 0.04614401
  0.04150068 0.02914041 0.03026822 0.04354408 0.03561018 0.01325097
  0.00967107 0.01653445]]

-* TASK 10/20 | SAMPLE 63/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 312/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 1, Bill journeyed to the school, and there is no information provided about Bill leaving the school. 

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' leaving', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02725643 0.03820011 0.04091962 ... 0.01300201 0.01790308 0.01045899]
 [0.02803489 0.03885719 0.03804903 ... 0.01659447 0.02178132 0.01297545]
 [0.02859204 0.03812768 0.04187219 ... 0.02216422 0.0292046  0.0156044 ]
 ...
 [0.02882877 0.03675918 0.03249744 ... 0.00771717 0.00824265 0.00718155]
 [0.02921852 0.02719654 0.02361886 ... 0.01157882 0.01010983 0.01097605]
 [0.02918384 0.03205612 0.02699382 ... 0.00923976 0.00949007 0.00952528]]

-* TASK 10/20 | SAMPLE 63/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 313/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, Fred moved to the cinema, which implies that Fred is now in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Fred', ' moved', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Fred', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03123566 0.04243198 0.04072431 ... 0.03265668 0.02586943 0.02070476]
 [0.03155786 0.0365921  0.03523922 ... 0.04614625 0.04430722 0.03156148]
 [0.03252799 0.04827701 0.05085884 ... 0.02824009 0.01687303 0.01470392]
 ...
 [0.03274842 0.04243026 0.04759125 ... 0.02685069 0.01591575 0.01480833]
 [0.03329562 0.03258707 0.033812   ... 0.029718   0.02320662 0.02052337]
 [0.03304154 0.03480196 0.03622513 ... 0.0249531  0.02023439 0.01979693]]

-* TASK 10/20 | SAMPLE 63/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 314/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the school. According to context sentence 11, Mary moved to the bedroom, but there is no mention of the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' school', '.', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Mary', ' moved', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.122, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02269877 0.02934027 0.03416929 ... 0.01014484 0.00901868 0.00675932]
 [0.02299869 0.03499111 0.03832749 ... 0.02720235 0.01552238 0.01122867]
 [0.02355602 0.03176512 0.03765307 ... 0.01892996 0.01678703 0.01269934]
 ...
 [0.02372172 0.03541542 0.03118128 ... 0.0075117  0.00669424 0.00444761]
 [0.02420012 0.02744848 0.02327579 ... 0.0083027  0.0095844  0.00689995]
 [0.02410942 0.03089505 0.02552536 ... 0.00736984 0.00852209 0.00600802]]

-* TASK 10/20 | SAMPLE 63/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 315/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill being in the park. The context sentences only mention Bill's possible locations as the cinema or the office (sentence 10), but not the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', "'s", ' possible', ' locations', ' as', ' the', ' cinema', ' or', ' the', ' office', ' (', 'sentence', ' ', '10', '),', ' but', ' not', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02115477 0.02963252 0.02935665 ... 0.0191743  0.01290027 0.03173999]
 [0.02148871 0.02411541 0.02563841 ... 0.01892652 0.01782922 0.02464085]
 [0.02204673 0.03047811 0.03286012 ... 0.01546191 0.01140512 0.02743404]
 ...
 [0.02220544 0.02899486 0.02709215 ... 0.0149718  0.01102881 0.03415935]
 [0.02281995 0.02179428 0.02006776 ... 0.01824539 0.01641135 0.02969095]
 [0.02253266 0.02600065 0.02347056 ... 0.01432669 0.01287843 0.02768034]]
Model's predictions for the sample 63:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |    Fred being in the park. The context     |
|          |                 |  sentences only mention Fred going to the  |
|          |                 |         kitchen, but not the park.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Bill    |
|          |                 |  journeyed to the school, and there is no  |
|          |                 |  information provided about Bill leaving   |
|          |                 |                the school.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 8, Fred    |
|          |                 |  moved to the cinema, which implies that   |
|          |                 |         Fred is now in the cinema.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the school. According to   |
|          |                 |   context sentence 11, Mary moved to the   |
|          |                 |  bedroom, but there is no mention of the   |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |    Bill being in the park. The context     |
|          |                 |   sentences only mention Bill's possible   |
|          |                 |   locations as the cinema or the office    |
|          |                 |      (sentence 10), but not the park.      |
+----------+-----------------+--------------------------------------------+

Metrics for sample 63:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.08 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 64/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 316/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 2 states that Mary is either in the school or the cinema, but it does not provide a definitive location for Mary. Therefore, we can only conclude that Mary might be in the school, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Mary', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 26), x_tokens=26, y_tokens=55, max_supp_attn=0.0545, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 26)
DEBUG result.interpretability.attn_scores 1430 
 [[0.01670257 0.03444625 0.03530074 ... 0.01789871 0.00659016 0.02206115]
 [0.01722786 0.0213384  0.0207884  ... 0.01263773 0.00603263 0.01443202]
 [0.01751444 0.02414918 0.02694441 ... 0.01681704 0.00705522 0.01399514]
 ...
 [0.01762317 0.02026096 0.02016171 ... 0.01069977 0.00531522 0.01312285]
 [0.01766254 0.01625703 0.01659148 ... 0.01450629 0.00896617 0.01447371]
 [0.01778184 0.01774905 0.01774962 ... 0.01354433 0.0084538  0.014771  ]]

-* TASK 10/20 | SAMPLE 64/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 317/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Mary moved to the bedroom, which implies that Mary is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03120216 0.04363352 0.05135456 0.07107671 0.05767754 0.06216336
  0.04337168 0.04269555 0.04546272 0.05146734 0.03674497 0.04050833
  0.04286367 0.1036443  0.10255097 0.03307577 0.02733351 0.02645708
  0.02679091 0.02759322 0.02530255 0.03798731 0.05739456 0.01823862
  0.03206    0.04143317 0.04380856 0.04750406 0.10699634 0.01252682
  0.02339604 0.00895317]
 [0.03197194 0.0431562  0.04810723 0.08865927 0.08634743 0.0936389
  0.04674336 0.0472656  0.04912499 0.0740758  0.0528575  0.06538475
  0.06119201 0.13743544 0.11531169 0.03332107 0.02754734 0.03093929
  0.02808445 0.02876846 0.02592254 0.03963965 0.04274689 0.01389234
  0.0374397  0.03748759 0.04408671 0.04150001 0.098308   0.01604723
  0.03699397 0.01566046]
 [0.03266737 0.04098764 0.05119045 0.07308055 0.06267367 0.0691938
  0.04426218 0.04334193 0.04369847 0.05551175 0.04049881 0.05092788
  0.04789647 0.11154473 0.09013183 0.03201134 0.02579477 0.02500628
  0.02409391 0.02465665 0.02207685 0.03711068 0.04154178 0.01642598
  0.0280305  0.03318235 0.03866279 0.03288316 0.08150128 0.02391512
  0.0346809  0.01660009]
 [0.03130713 0.04171687 0.04849209 0.03978035 0.03291609 0.04273487
  0.04253579 0.04377043 0.03766368 0.0349336  0.03109853 0.04106728
  0.04069953 0.03017637 0.02782236 0.03724577 0.03046992 0.02855359
  0.02871274 0.02993049 0.02762274 0.03909702 0.0592386  0.03910577
  0.03152639 0.04923104 0.04686821 0.04202505 0.07481241 0.07468154
  0.0430251  0.03186358]
 [0.03187125 0.04655784 0.04913255 0.02663875 0.02017347 0.0320262
  0.04048829 0.03888445 0.03635303 0.02414389 0.02625732 0.03021762
  0.03242595 0.02005268 0.01814882 0.03587421 0.02601042 0.02419228
  0.02666487 0.02733826 0.02579677 0.03668746 0.06363839 0.03362547
  0.03016915 0.04503867 0.05663821 0.02914657 0.06391723 0.09461881
  0.037818   0.03645368]
 [0.03269249 0.05973423 0.06649618 0.03244545 0.02304046 0.04002689
  0.05016304 0.04274821 0.05144735 0.0300521  0.02699202 0.03710476
  0.03798804 0.02042199 0.01866926 0.04149354 0.03271274 0.02915602
  0.03065067 0.03259789 0.02718291 0.03335781 0.08162029 0.02811056
  0.02739412 0.04471062 0.06021939 0.02729318 0.04401861 0.10351513
  0.03250388 0.03270609]
 [0.03279299 0.03708216 0.04242731 0.02413335 0.0185912  0.02691286
  0.03619299 0.03142022 0.03642619 0.02221071 0.02188045 0.02482343
  0.0259245  0.01673526 0.01639898 0.03458244 0.02806006 0.02329308
  0.02759357 0.0278045  0.0246071  0.03013326 0.05400949 0.03223481
  0.02355328 0.04643814 0.05799419 0.02684681 0.02953225 0.09948502
  0.03664999 0.02671869]
 [0.03306307 0.02078993 0.02503609 0.016271   0.01412384 0.01869689
  0.02195316 0.02126153 0.02569859 0.01658924 0.01786995 0.01732227
  0.01956215 0.01106654 0.01194543 0.02419085 0.02253382 0.02002261
  0.02515527 0.02645861 0.02308773 0.02468644 0.03589702 0.03630355
  0.01966035 0.04543443 0.03570746 0.02430275 0.01948853 0.05752017
  0.02424376 0.01593361]
 [0.03254679 0.03224561 0.03589925 0.02538841 0.01896917 0.02895632
  0.03499131 0.03138935 0.03065269 0.02416933 0.02706256 0.03118695
  0.03118491 0.01694266 0.01606813 0.0419926  0.03352615 0.03416442
  0.03343391 0.0359042  0.03084912 0.03589016 0.03784971 0.03955341
  0.03109275 0.03909772 0.04147906 0.02384147 0.02791332 0.06998881
  0.03832862 0.04616559]
 [0.03348938 0.03181396 0.03858164 0.0303427  0.02339431 0.03661541
  0.0407283  0.03765887 0.03395542 0.02993879 0.03073803 0.03896447
  0.0392905  0.02181562 0.01661973 0.03630597 0.02648001 0.02837292
  0.02794609 0.03044548 0.02707142 0.03476458 0.03149524 0.03774017
  0.03383118 0.03537184 0.03751543 0.02702817 0.02978132 0.06710419
  0.06112155 0.0616998 ]
 [0.03309644 0.023701   0.02274002 0.01745777 0.01484963 0.01930993
  0.0269006  0.02413211 0.02419773 0.01829118 0.02545797 0.02149466
  0.02759006 0.01180304 0.01092657 0.03953069 0.03126694 0.0337454
  0.0304185  0.03340745 0.03129848 0.03275483 0.022595   0.04222253
  0.03615426 0.02936166 0.02294734 0.02475823 0.01724172 0.04271736
  0.03421614 0.03647067]
 [0.03289202 0.02589902 0.02331658 0.01832665 0.01549702 0.01895896
  0.02843333 0.02616203 0.02450919 0.01934332 0.02516996 0.02027598
  0.02900813 0.01178293 0.01125634 0.0433806  0.03244423 0.03915703
  0.03501743 0.03799363 0.03824614 0.0305825  0.02191818 0.04362036
  0.04149736 0.02966864 0.02355579 0.02980246 0.01422687 0.02991637
  0.026433   0.03403419]
 [0.03393162 0.02513737 0.02438692 0.01934624 0.0171195  0.02171373
  0.02893818 0.02782156 0.02734787 0.02151468 0.03221723 0.02560887
  0.03268608 0.01299773 0.01198088 0.05312505 0.031516   0.05183087
  0.03481084 0.04392568 0.04199598 0.02698415 0.02080378 0.04147647
  0.0365161  0.02548078 0.02804096 0.02194998 0.01282399 0.01937429
  0.02648193 0.03274979]
 [0.03384117 0.02234122 0.02067631 0.01543508 0.01385443 0.01697165
  0.02572705 0.02252887 0.02358317 0.01714653 0.0357732  0.01938353
  0.0248894  0.01064326 0.01097705 0.04227878 0.03451087 0.03940089
  0.03383761 0.03710077 0.04025226 0.028836   0.02065526 0.05808926
  0.04171982 0.02722334 0.02762373 0.0234688  0.01162442 0.01615941
  0.02597666 0.02895365]
 [0.0329441  0.02607875 0.02372322 0.01964293 0.01726225 0.02373848
  0.03139121 0.03008026 0.03090353 0.02111    0.02895319 0.02440058
  0.02906774 0.0133226  0.01258349 0.02992435 0.0353662  0.0332405
  0.04268578 0.04117805 0.04219992 0.03188184 0.02600797 0.05205628
  0.04984358 0.04723116 0.03061384 0.03521936 0.01857162 0.02215578
  0.03792196 0.02570501]
 [0.03417002 0.0252022  0.02464397 0.02081793 0.01657465 0.02248276
  0.02852934 0.02727322 0.02768441 0.02147305 0.02844184 0.02457512
  0.02698309 0.01470777 0.01297449 0.02598419 0.02588042 0.02582923
  0.02933913 0.03082132 0.02992254 0.03296268 0.02064829 0.02903687
  0.02706889 0.02677491 0.02303427 0.02365265 0.01729501 0.01875765
  0.04700763 0.03932962]
 [0.03407937 0.02562943 0.02942638 0.02590173 0.01984374 0.03146463
  0.03132004 0.03598483 0.03282873 0.03090307 0.03108873 0.04063404
  0.03750391 0.01961459 0.01429359 0.02302571 0.02309392 0.02697434
  0.02661654 0.02758509 0.02462274 0.03443943 0.0215095  0.02134643
  0.02747014 0.02881843 0.02280827 0.02823643 0.02381358 0.02328733
  0.06244243 0.05572697]
 [0.03443328 0.03578573 0.03694345 0.03661092 0.02524398 0.03958856
  0.03954316 0.04630692 0.03682127 0.04230788 0.04152739 0.05350549
  0.04805544 0.02468966 0.01688988 0.02731037 0.02479486 0.02917251
  0.02679186 0.02773847 0.0250381  0.0346275  0.02518862 0.0216735
  0.02888371 0.02443495 0.02738035 0.02437397 0.02376609 0.02486342
  0.04550941 0.07318899]
 [0.03449537 0.03381605 0.03155834 0.03215818 0.02419851 0.03358297
  0.03558553 0.03989941 0.034501   0.03633723 0.03833193 0.04310465
  0.04358264 0.02219128 0.01709774 0.03075595 0.02752365 0.03274798
  0.03138605 0.03216213 0.03001704 0.03547604 0.02287908 0.0270207
  0.02808259 0.0238541  0.02491177 0.0286091  0.02152102 0.02280796
  0.03658579 0.05501315]
 [0.0343235  0.02654576 0.02294043 0.01949929 0.01459832 0.02007896
  0.02647025 0.02975343 0.02660789 0.02302237 0.02617895 0.02578445
  0.02882387 0.01261467 0.01223975 0.03291972 0.0304596  0.03156234
  0.03106953 0.03139726 0.03307482 0.03361482 0.01899762 0.03859725
  0.03327364 0.0238872  0.02213028 0.03440363 0.01678935 0.02261356
  0.02918332 0.04550882]
 [0.03436051 0.0291224  0.02415746 0.02180219 0.0158569  0.02108821
  0.0301051  0.03168349 0.02659953 0.02492548 0.02876707 0.02625509
  0.02989871 0.01324429 0.01359859 0.035427   0.03321208 0.03715257
  0.03610912 0.03518707 0.03759352 0.03096749 0.01883614 0.04052926
  0.03556434 0.02334246 0.02359056 0.03302974 0.0143068  0.01882663
  0.02560745 0.04292545]
 [0.03443236 0.02715567 0.02264126 0.02059894 0.01605192 0.02076999
  0.02646031 0.02896362 0.02520109 0.02465956 0.02990341 0.02660106
  0.02687831 0.01361571 0.01346808 0.0311907  0.03266718 0.03240795
  0.03600393 0.03232566 0.03693411 0.03158478 0.01805566 0.04382986
  0.04370641 0.02336955 0.0247727  0.03332373 0.01557993 0.02013307
  0.03003486 0.04408724]
 [0.03470559 0.03068548 0.02554875 0.02174804 0.01612229 0.02245312
  0.03162791 0.03218825 0.0305858  0.02583657 0.03723869 0.02822077
  0.03000168 0.01426227 0.01417328 0.03844132 0.03575924 0.03775157
  0.03775234 0.03755075 0.04143446 0.03138214 0.01918202 0.0473686
  0.04054279 0.02520691 0.02466839 0.02862318 0.01436704 0.01560896
  0.02630305 0.04366234]
 [0.03486545 0.02361702 0.02000099 0.01484405 0.01275468 0.01654268
  0.0261061  0.02334774 0.02383192 0.01884615 0.04019513 0.02029572
  0.02157635 0.01091098 0.01093946 0.03100174 0.03476784 0.02981754
  0.03432659 0.0331911  0.03818224 0.02844217 0.01660734 0.06034178
  0.04239844 0.02347037 0.01769727 0.0263259  0.01323437 0.01363363
  0.02639784 0.03513043]
 [0.03358337 0.02706875 0.02367529 0.01683142 0.01404543 0.02090415
  0.02984358 0.02848428 0.03106448 0.02274488 0.02797163 0.02215543
  0.02438901 0.01275012 0.01237564 0.02397896 0.03270727 0.02557644
  0.0363792  0.0337518  0.03490284 0.03116493 0.01982694 0.04286176
  0.03960651 0.03409125 0.02122629 0.02894284 0.01709808 0.01625696
  0.03074117 0.02543065]
 [0.03464893 0.02624228 0.02369417 0.02110049 0.01563574 0.02424388
  0.02661591 0.03025456 0.02899505 0.02663436 0.02620442 0.02677456
  0.02556863 0.01591304 0.01382632 0.01959309 0.02557365 0.02338994
  0.02971535 0.03078577 0.02921418 0.02982553 0.01760412 0.02243509
  0.02544132 0.02474042 0.02009631 0.0283913  0.01958178 0.0148049
  0.03894778 0.03740909]
 [0.03314901 0.03463221 0.03524281 0.05125247 0.04258464 0.04559728
  0.03245552 0.03470114 0.04162904 0.05369188 0.03476225 0.04076391
  0.03816326 0.07815676 0.09116142 0.02353524 0.02800295 0.02720514
  0.02954477 0.0299437  0.02606666 0.03413612 0.03455834 0.01432207
  0.0272308  0.034326   0.03682005 0.04367388 0.04671315 0.01173076
  0.02648269 0.0158547 ]
 [0.03279275 0.0459273  0.03905508 0.07383171 0.15632327 0.05644166
  0.03188281 0.03382236 0.04092042 0.07476952 0.05421915 0.04973517
  0.03344841 0.10876592 0.14381616 0.03510394 0.05547193 0.04941837
  0.04551546 0.03765334 0.04308028 0.03371159 0.04525977 0.01439369
  0.02980309 0.03592259 0.0512143  0.04682912 0.04656082 0.00826156
  0.01747651 0.00988491]
 [0.03258213 0.04441727 0.03543016 0.05590536 0.11309125 0.03453138
  0.02787718 0.03230809 0.03333041 0.06087886 0.05273016 0.04374256
  0.03079833 0.04287146 0.06966975 0.03763415 0.08979206 0.07451396
  0.06483417 0.04765557 0.0700878  0.0330415  0.03912758 0.02509526
  0.03722429 0.03557649 0.03591607 0.06185912 0.028441   0.01073787
  0.02015421 0.01465164]
 [0.03306852 0.043277   0.03348118 0.04907201 0.06058474 0.03857151
  0.03275676 0.03386775 0.03837439 0.05247093 0.0428675  0.03918057
  0.03205924 0.04530635 0.05208434 0.02576482 0.05472048 0.04894783
  0.04871944 0.04714769 0.04631618 0.04422962 0.04430684 0.01845229
  0.0332145  0.03579318 0.02797142 0.07215545 0.03017403 0.00794976
  0.01733433 0.01152804]]

-* TASK 10/20 | SAMPLE 64/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 318/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill's location in the context sentences 7 and 8. The previous information about Bill's location (if any) is not provided in this task.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '7', ' and', ' ', '8', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' (', 'if', ' any', ')', ' is', ' not', ' provided', ' in', ' this', ' task', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.1333, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02041245 0.02172976 0.02220542 ... 0.04926633 0.02989148 0.01757941]
 [0.02075887 0.01341661 0.01498536 ... 0.02934612 0.02518815 0.02833874]
 [0.02140531 0.02007254 0.02306745 ... 0.04648514 0.02482414 0.01176159]
 ...
 [0.02197573 0.0221352  0.01819591 ... 0.04822164 0.02195285 0.01591743]
 [0.0222888  0.02258203 0.01963544 ... 0.0506749  0.02417004 0.0152115 ]
 [0.02232228 0.01850062 0.01637653 ... 0.06619929 0.03231074 0.01428355]]

-* TASK 10/20 | SAMPLE 64/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 319/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 (from a previous task) states that Julie travelled to the office, and there is no information provided about Julie moving to the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' (', 'from', ' a', ' previous', ' task', ')', ' states', ' that', ' Julie', ' travelled', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' moving', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02386706 0.02761444 0.02494861 ... 0.02209666 0.04325104 0.07643048]
 [0.02418559 0.02340225 0.02098561 ... 0.02128769 0.0285807  0.05858629]
 [0.02484304 0.03051074 0.02968457 ... 0.02212734 0.03195708 0.07579604]
 ...
 [0.02504979 0.02928604 0.0283673  ... 0.02930588 0.03611645 0.02306318]
 [0.02538197 0.02614871 0.02335546 ... 0.03567417 0.03185456 0.01205736]
 [0.02546049 0.02438983 0.0227018  ... 0.02563673 0.04000244 0.01211427]]

-* TASK 10/20 | SAMPLE 64/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 320/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 13 states that Julie is either in the kitchen or the bedroom, but it does not provide a definitive location for Julie. Therefore, we can only conclude that Julie might be in the bedroom, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Julie', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' bedroom', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 50), x_tokens=50, y_tokens=55, max_supp_attn=0.0, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 50)
DEBUG result.interpretability.attn_scores 2750 
 [[0.01680369 0.02698639 0.02326273 ... 0.02248429 0.02293975 0.01599992]
 [0.01713941 0.02158243 0.02218868 ... 0.01326817 0.01610195 0.01775996]
 [0.01753665 0.02779592 0.02663969 ... 0.02259217 0.02085499 0.01451686]
 ...
 [0.01778746 0.02482055 0.02439345 ... 0.05400405 0.02369478 0.01459326]
 [0.01803926 0.02001804 0.0180086  ... 0.04166576 0.01976862 0.0172224 ]
 [0.01795168 0.02162495 0.01924715 ... 0.05144752 0.02772357 0.01781044]]
Model's predictions for the sample 64:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 2 states that Mary   |
|          |                 |   is either in the school or the cinema,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |    location for Mary. Therefore, we can    |
|          |                 |  only conclude that Mary might be in the   |
|          |                 |     school, but we cannot be certain.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 4 states that Mary   |
|          |                 |  moved to the bedroom, which implies that  |
|          |                 |     Mary is currently in the bedroom.      |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |   There is no information provided about   |
|          |                 |  Bill's location in the context sentences  |
|          |                 |  7 and 8. The previous information about   |
|          |                 |  Bill's location (if any) is not provided  |
|          |                 |               in this task.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 7 (from a previous   |
|          |                 |  task) states that Julie travelled to the  |
|          |                 |    office, and there is no information     |
|          |                 |     provided about Julie moving to the     |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentence 13 states that     |
|          |                 |   Julie is either in the kitchen or the    |
|          |                 |     bedroom, but it does not provide a     |
|          |                 |       definitive location for Julie.       |
|          |                 |    Therefore, we can only conclude that    |
|          |                 |   Julie might be in the bedroom, but we    |
|          |                 |             cannot be certain.             |
+----------+-----------------+--------------------------------------------+

Metrics for sample 64:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 65/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 321/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the cinema. The context sentences only mention Fred going back to the park and Mary being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' going', ' back', ' to', ' the', ' park', ' and', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0541, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.02532526 0.04485856 0.04767094 0.07717759 0.07606524 0.04737812
  0.03559545 0.03094064 0.03223599 0.04940153 0.03860839 0.02430322
  0.02585249 0.12293359 0.12829795 0.03744032 0.02703822 0.01933294
  0.01695116 0.01750153 0.01737928 0.03852665 0.05813097 0.00899876
  0.00815276 0.02584589]
 [0.02613984 0.02815288 0.02818058 0.05734474 0.05399831 0.0407573
  0.02485392 0.02222108 0.02552471 0.04228524 0.03301518 0.02610637
  0.02559486 0.12492379 0.15238518 0.03550805 0.02895746 0.02281553
  0.01863959 0.01800892 0.01621136 0.03248665 0.03465303 0.00654619
  0.00637238 0.01699524]
 [0.02657056 0.0316333  0.03606993 0.05947088 0.06013946 0.051704
  0.03339969 0.03148703 0.03377127 0.04943705 0.03765357 0.04126404
  0.03985015 0.09896594 0.09421671 0.02993152 0.02675215 0.02328054
  0.01809954 0.01824548 0.01550756 0.02941459 0.03234513 0.00956056
  0.00849099 0.01606526]
 [0.02566315 0.03614239 0.04192351 0.04414226 0.04749925 0.04529158
  0.03650878 0.03865457 0.03725835 0.04286984 0.03628802 0.04431026
  0.03964607 0.05730094 0.0528726  0.03913336 0.03426506 0.03169761
  0.02473515 0.02601391 0.02348662 0.03297461 0.04719882 0.02605648
  0.02448334 0.02757106]
 [0.02663461 0.03071816 0.03604807 0.03307174 0.02936034 0.03853878
  0.03535158 0.03859326 0.03449269 0.03403663 0.03052013 0.0406566
  0.0358514  0.02122785 0.01656471 0.02741788 0.02553719 0.02656112
  0.02265396 0.02389488 0.02228215 0.0268191  0.03382504 0.02384039
  0.02590339 0.02827359]
 [0.02695971 0.02989763 0.03300614 0.02749862 0.02243643 0.03703489
  0.03490245 0.03641848 0.03471476 0.03107811 0.02885125 0.04163318
  0.03496739 0.01818512 0.01389548 0.02579843 0.02490331 0.02443255
  0.02260486 0.02309934 0.02122342 0.02674822 0.03113045 0.02304457
  0.02542664 0.02685622]
 [0.02651215 0.04650642 0.04233098 0.03131258 0.02572458 0.04203284
  0.04277782 0.04799903 0.03959788 0.03713993 0.03614757 0.05635788
  0.04900647 0.02072917 0.01548334 0.03403021 0.02786957 0.02970175
  0.0255779  0.02519056 0.02337429 0.02859215 0.03511885 0.02238574
  0.02164154 0.02261027]
 [0.02709177 0.03768428 0.0422295  0.03199119 0.02297201 0.05312281
  0.04432577 0.04514234 0.0432422  0.03661679 0.03250531 0.06676724
  0.05183733 0.02009637 0.01448567 0.03075212 0.02808226 0.02799304
  0.02385845 0.02504185 0.02193763 0.02705707 0.02948673 0.01654368
  0.01681881 0.01872348]
 [0.02720294 0.04505461 0.05487493 0.03773761 0.02520574 0.07652619
  0.06813925 0.04939834 0.05948924 0.03978976 0.03223031 0.05908548
  0.044054   0.02069324 0.01551116 0.02803541 0.02327968 0.02200925
  0.01971747 0.02185243 0.01886242 0.02774819 0.03481128 0.01439965
  0.01443166 0.01977026]
 [0.02665394 0.02279602 0.02308494 0.01884259 0.0149898  0.02099819
  0.0283839  0.02943594 0.02332443 0.02103608 0.02764503 0.02671594
  0.03408035 0.01051701 0.01016342 0.03625633 0.0284238  0.03235497
  0.02914376 0.02945481 0.03325702 0.02727209 0.0196723  0.03536022
  0.02921344 0.02213166]
 [0.02664798 0.01997187 0.01768565 0.01645432 0.01260416 0.01524654
  0.02388786 0.02346442 0.01860097 0.01623771 0.02219227 0.01871185
  0.02161126 0.00850179 0.00869561 0.03745372 0.02637212 0.03821259
  0.03564353 0.03905976 0.04388883 0.02551202 0.01663225 0.04218205
  0.03328919 0.02488912]
 [0.02716032 0.01998777 0.01755295 0.01683586 0.01413107 0.01644654
  0.02272783 0.02398392 0.01858416 0.01823054 0.02602691 0.02372717
  0.02350456 0.00907427 0.00896627 0.03877705 0.02825616 0.03319433
  0.03197357 0.03058888 0.0344765  0.02371002 0.01371144 0.02890737
  0.02470514 0.01612673]
 [0.02708173 0.01690324 0.01484902 0.01216854 0.01174542 0.01227173
  0.01984566 0.0186599  0.01588573 0.01358105 0.02544858 0.01763634
  0.01899055 0.00692427 0.00745936 0.03947955 0.03140081 0.03360247
  0.04002298 0.03481808 0.04000643 0.02383391 0.013259   0.02899853
  0.02504592 0.01880691]
 [0.02658887 0.01909155 0.01770907 0.0133685  0.01284105 0.01423323
  0.02159982 0.02004522 0.02015065 0.01452898 0.0225912  0.01663902
  0.01927748 0.00755644 0.00828135 0.03644042 0.03009188 0.03039048
  0.03528953 0.03142836 0.03359476 0.02565253 0.02341331 0.04227375
  0.04040389 0.0396222 ]
 [0.02728317 0.02577987 0.02243315 0.0167878  0.01472459 0.01741122
  0.02308375 0.02450664 0.02185518 0.01854333 0.02402402 0.0216086
  0.021684   0.00971028 0.00964767 0.03058623 0.02420858 0.02899993
  0.03515738 0.0301359  0.03166445 0.02501916 0.02164477 0.02193489
  0.02114609 0.01891756]
 [0.02688389 0.02892118 0.02899551 0.02901314 0.02508085 0.03145517
  0.02791217 0.03046094 0.03048585 0.03469226 0.02786102 0.03973482
  0.03494112 0.02166234 0.01585449 0.0257218  0.02674768 0.02900131
  0.02394446 0.02529051 0.02252547 0.02962076 0.03677037 0.02888172
  0.02619233 0.01956916]
 [0.02674853 0.04328488 0.04134588 0.02295654 0.01918818 0.02616372
  0.03531392 0.03519126 0.03369085 0.02236236 0.02428014 0.02673721
  0.0292774  0.01461933 0.01327247 0.03098502 0.02609828 0.02602338
  0.02462847 0.02835782 0.02692427 0.02837665 0.05353858 0.03382533
  0.03405913 0.02814538]
 [0.0271431  0.06580991 0.0686124  0.0282253  0.02201028 0.0314352
  0.04597918 0.04120256 0.04452661 0.02542196 0.02490331 0.02763294
  0.0295037  0.01547997 0.01421125 0.03783431 0.02824214 0.02345186
  0.02042178 0.02429064 0.02036879 0.02894277 0.06327053 0.01923956
  0.01950764 0.02152836]
 [0.02729739 0.03585627 0.03834689 0.02358564 0.01866677 0.02618369
  0.03605306 0.03472554 0.03331033 0.02211514 0.0218559  0.02505001
  0.02519175 0.01360338 0.0122976  0.02855508 0.02491047 0.02299167
  0.02095187 0.02442    0.02215069 0.02943579 0.04412534 0.02515749
  0.02827864 0.03037418]
 [0.02789824 0.02733387 0.02685749 0.02084204 0.01640085 0.02458602
  0.0288481  0.03184089 0.02620893 0.02056075 0.02267263 0.02538511
  0.02613133 0.01195719 0.0100925  0.02092718 0.01912918 0.02144979
  0.01956169 0.0225722  0.02093338 0.02735738 0.02275247 0.02298671
  0.02296981 0.02259095]
 [0.02732709 0.01969332 0.01827812 0.01461506 0.01270586 0.01582223
  0.02180697 0.02210492 0.01950005 0.01526793 0.02230558 0.01616509
  0.02066764 0.00873155 0.00822822 0.02392559 0.02265862 0.02476071
  0.02474401 0.02921059 0.03161845 0.02524099 0.0199275  0.05212497
  0.03822325 0.02770102]
 [0.02717107 0.01623183 0.01413088 0.0128923  0.01068714 0.01209894
  0.01753597 0.01599251 0.01583651 0.01297186 0.01758221 0.01216837
  0.01652745 0.0073517  0.00715537 0.0202578  0.01897824 0.02798235
  0.02859079 0.04020592 0.03987763 0.02264471 0.01699443 0.07080996
  0.03979712 0.0247249 ]
 [0.02745136 0.01380811 0.01268446 0.01170399 0.01007045 0.01157275
  0.01456999 0.01428021 0.01473577 0.01229302 0.01619895 0.01194869
  0.01497563 0.00694994 0.00637999 0.01769334 0.01509978 0.02198443
  0.01989133 0.03841776 0.04119008 0.01955208 0.01445474 0.07914048
  0.0375213  0.01785146]
 [0.02769961 0.0136113  0.0121685  0.0111375  0.00954259 0.01109692
  0.0145973  0.0137661  0.01474897 0.01180949 0.01815109 0.01243059
  0.01510293 0.00683699 0.00640655 0.01882675 0.01700709 0.0232178
  0.02267241 0.03281874 0.04343488 0.02102751 0.01247391 0.06468679
  0.02921854 0.01556251]
 [0.02752666 0.01433721 0.0125986  0.01063364 0.00952457 0.01087029
  0.01561797 0.01442434 0.01528674 0.01158958 0.02330407 0.01297314
  0.01575659 0.00671762 0.00652659 0.02134064 0.02050253 0.0239372
  0.02693447 0.03418051 0.03776526 0.02210248 0.01423186 0.06210172
  0.02808998 0.02000342]
 [0.02691417 0.03339545 0.02731101 0.04461409 0.05314473 0.04424441
  0.03348631 0.02960803 0.03116046 0.05152959 0.05004149 0.0387992
  0.03585342 0.04705155 0.0333066  0.02345675 0.02641329 0.02695202
  0.02666464 0.02363696 0.02235575 0.03636691 0.02699607 0.01938748
  0.01121934 0.01769953]
 [0.02776478 0.01690853 0.01513003 0.01311074 0.01089313 0.01297419
  0.01567258 0.01624526 0.01770789 0.01381872 0.01892652 0.01379705
  0.01640621 0.007946   0.0068792  0.01720325 0.01827485 0.01842429
  0.02535161 0.02736964 0.02709399 0.02228174 0.01546771 0.03656542
  0.03757738 0.03396194]
 [0.02778324 0.01993932 0.01881438 0.01357092 0.01113646 0.01431225
  0.02005092 0.02166931 0.02105093 0.01476255 0.01818296 0.01574276
  0.02034334 0.00831054 0.0067747  0.01714028 0.02503814 0.01765008
  0.0210663  0.02166059 0.02415338 0.02631121 0.01658935 0.01893662
  0.05891639 0.04625765]
 [0.02753471 0.01622729 0.0149138  0.01167486 0.00953229 0.01210155
  0.01674504 0.01740149 0.01713771 0.01310026 0.01703811 0.01308537
  0.01748622 0.00720088 0.00605445 0.01764529 0.03309334 0.02065007
  0.02807031 0.02512245 0.02838683 0.02180217 0.01389921 0.01761898
  0.07864753 0.05484968]
 [0.02789329 0.01622805 0.01539464 0.01177098 0.01013225 0.01278751
  0.01793049 0.0195752  0.01808841 0.01356466 0.02021535 0.01583371
  0.0200059  0.00761099 0.00605144 0.01758561 0.03331229 0.01946083
  0.02701125 0.02388763 0.02426983 0.01981568 0.01245329 0.01480411
  0.06016987 0.05168255]
 [0.02761479 0.01344023 0.01268212 0.0092429  0.00826158 0.01020083
  0.01472912 0.01456094 0.01533595 0.01071814 0.01780174 0.01145934
  0.01620213 0.00631521 0.00498786 0.01890008 0.03785476 0.02164697
  0.03707911 0.03101648 0.02813843 0.02025111 0.01254523 0.01718013
  0.04677584 0.08047866]
 [0.02698936 0.02116254 0.02379605 0.01929549 0.01676649 0.02214174
  0.02444904 0.02826142 0.04171053 0.02504634 0.02158326 0.02280432
  0.02456739 0.0127068  0.01056841 0.02050487 0.02679153 0.0263674
  0.02965723 0.02791693 0.02717824 0.02605979 0.02525428 0.02131427
  0.0284877  0.04714461]
 [0.02826818 0.018813   0.01913129 0.01614705 0.01234795 0.01653511
  0.02059798 0.02372579 0.02277586 0.01802293 0.02190783 0.01795707
  0.02334897 0.01045989 0.00789492 0.0177338  0.02149169 0.01873625
  0.02451367 0.02209504 0.01931297 0.02499337 0.01433828 0.01134025
  0.016116   0.03006945]
 [0.02675738 0.02998695 0.0292492  0.05136532 0.0555484  0.03956078
  0.02679169 0.02698043 0.03165141 0.04962281 0.03446689 0.02916695
  0.03286395 0.08490946 0.09876451 0.02513689 0.02630739 0.02404406
  0.0191298  0.01811007 0.01661301 0.03126833 0.03229164 0.00677844
  0.0075139  0.01866552]
 [0.02660953 0.03016408 0.02780668 0.05403902 0.10581826 0.03529654
  0.0210603  0.023074   0.02607448 0.05195029 0.03798876 0.02788506
  0.02510386 0.08018717 0.10294591 0.02982581 0.03848088 0.0358217
  0.02683075 0.02160941 0.02085276 0.02816431 0.03170046 0.00610652
  0.00588097 0.01611575]
 [0.02647715 0.02346591 0.02240974 0.03875699 0.05916486 0.02424998
  0.01625542 0.02144345 0.02371575 0.04405407 0.03561055 0.03019778
  0.02728408 0.0292714  0.0312055  0.02237669 0.04257471 0.05867756
  0.05723179 0.03399392 0.03125481 0.02521092 0.02485867 0.01052395
  0.01019998 0.01693026]
 [0.02673049 0.02620225 0.02369301 0.03660173 0.04893863 0.02531626
  0.01861313 0.0225147  0.02653183 0.03991269 0.03337397 0.0275223
  0.02665062 0.02677997 0.02721507 0.01938258 0.03555489 0.04218914
  0.04498344 0.02948141 0.02644829 0.0418063  0.03003277 0.0094563
  0.00911221 0.01488763]]

-* TASK 10/20 | SAMPLE 65/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 322/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 5 states that Fred is either in the park or the office, but it does not provide a definitive location. Therefore, based on the given information, it is possible that Fred is in the park.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' based', ' on', ' the', ' given', ' information', ',', ' it', ' is', ' possible', ' that', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 32), x_tokens=32, y_tokens=51, max_supp_attn=0.0784, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 32)
DEBUG result.interpretability.attn_scores 1632 
 [[0.01798216 0.02752877 0.03147653 ... 0.01136206 0.01135697 0.04621582]
 [0.01854053 0.02491736 0.02731178 ... 0.01434773 0.01453964 0.05579273]
 [0.01882069 0.02536181 0.03028375 ... 0.02172518 0.01706347 0.04425222]
 ...
 [0.01894194 0.02593425 0.02169177 ... 0.00666706 0.00820045 0.04515373]
 [0.01922631 0.02085497 0.01738581 ... 0.00918403 0.00911748 0.01499379]
 [0.01937977 0.02069068 0.01728613 ... 0.00945951 0.00914469 0.01950445]]

-* TASK 10/20 | SAMPLE 65/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 323/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 states that Julie journeyed to the bedroom, which implies that Julie has arrived at the bedroom. 

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Julie', ' has', ' arrived', ' at', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02904957 0.03656199 0.04657748 ... 0.01463568 0.02510296 0.02156762]
 [0.02936932 0.03660656 0.04846502 ... 0.02350716 0.03377892 0.02886998]
 [0.03040893 0.03632877 0.04905145 ... 0.0127423  0.02045497 0.0151364 ]
 ...
 [0.03075194 0.03726614 0.03552182 ... 0.01336876 0.01771956 0.01432048]
 [0.03067979 0.03381375 0.03059089 ... 0.02880103 0.027993   0.02215656]
 [0.0309675  0.03336809 0.03025972 ... 0.01902589 0.02339315 0.02300315]]

-* TASK 10/20 | SAMPLE 65/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 324/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the kitchen. The context sentences only mention Mary being either in the office or the park, and Bill being either in the park or the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' kitchen', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' being', ' either', ' in', ' the', ' office', ' or', ' the', ' park', ',', ' and', ' Bill', ' being', ' either', ' in', ' the', ' park', ' or', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 44), x_tokens=44, y_tokens=45, max_supp_attn=0.0, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 44)
DEBUG result.interpretability.attn_scores 1980 
 [[0.02062934 0.03145666 0.03233911 ... 0.01028781 0.00863361 0.01266578]
 [0.02102953 0.02379088 0.02371762 ... 0.02831637 0.01702875 0.01737976]
 [0.02149048 0.03243897 0.03280819 ... 0.0198662  0.01261232 0.0212839 ]
 ...
 [0.02152207 0.03130911 0.03196793 ... 0.00621813 0.006461   0.00908814]
 [0.02177904 0.02752075 0.02677817 ... 0.00671065 0.00843115 0.01046384]
 [0.02184993 0.03013007 0.02990399 ... 0.00583455 0.00819269 0.01117373]]

-* TASK 10/20 | SAMPLE 65/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 325/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 13 states that Bill went to the cinema, which implies that Bill has arrived at the cinema. The context sentence 14 is contradictory, but since Bill has already arrived at the cinema, it takes precedence.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' has', ' arrived', ' at', ' the', ' cinema', '.', ' The', ' context', ' sentence', ' ', '14', ' is', ' contradictory', ',', ' but', ' since', ' Bill', ' has', ' already', ' arrived', ' at', ' the', ' cinema', ',', ' it', ' takes', ' precedence', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01758633 0.02685272 0.02426461 ... 0.03492324 0.02246901 0.00847547]
 [0.01792399 0.02317357 0.02049125 ... 0.01745504 0.02545349 0.01130096]
 [0.01844765 0.02750451 0.0274057  ... 0.03535085 0.01844159 0.00859866]
 ...
 [0.01867746 0.02482161 0.02367548 ... 0.06815388 0.01877304 0.00835923]
 [0.01907291 0.01816411 0.01636065 ... 0.04497823 0.01633655 0.01117677]
 [0.01888991 0.02259898 0.01998436 ... 0.05371469 0.01686391 0.0085162 ]]
Model's predictions for the sample 65:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Fred being in the cinema. The context    |
|          |                 |   sentences only mention Fred going back   |
|          |                 |     to the park and Mary being in the      |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 5 states that Fred   |
|          |                 |  is either in the park or the office, but  |
|          |                 |      it does not provide a definitive      |
|          |                 |  location. Therefore, based on the given   |
|          |                 |  information, it is possible that Fred is  |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 7 states that Julie  |
|          |                 |  journeyed to the bedroom, which implies   |
|          |                 |   that Julie has arrived at the bedroom.   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the kitchen. The context   |
|          |                 |  sentences only mention Mary being either  |
|          |                 |    in the office or the park, and Bill     |
|          |                 |  being either in the park or the office.   |
+----------+-----------------+--------------------------------------------+
|    no    |       yes       |  The context sentence 13 states that Bill  |
|          |                 |   went to the cinema, which implies that   |
|          |                 |    Bill has arrived at the cinema. The     |
|          |                 |   context sentence 14 is contradictory,    |
|          |                 |   but since Bill has already arrived at    |
|          |                 |      the cinema, it takes precedence.      |
+----------+-----------------+--------------------------------------------+

Metrics for sample 65:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.07 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 66/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 326/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill being in the bedroom. The context sentences only mention Bill traveling to the park, and Julie being in the park. There is no connection to the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' traveling', ' to', ' the', ' park', ',', ' and', ' Julie', ' being', ' in', ' the', ' park', '.', ' There', ' is', ' no', ' connection', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 26), x_tokens=26, y_tokens=45, max_supp_attn=0.1333, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 26)
DEBUG result.interpretability.attn_scores 1170 
 [[0.02067814 0.03677028 0.03897522 ... 0.01176641 0.00806968 0.02110754]
 [0.02134262 0.02290869 0.02288031 ... 0.00802726 0.00633179 0.01370017]
 [0.02170657 0.02566698 0.02890758 ... 0.0104319  0.0080387  0.01297272]
 ...
 [0.02175534 0.02401789 0.02302694 ... 0.00753521 0.00538626 0.01301309]
 [0.0216625  0.02031325 0.0197114  ... 0.01040173 0.00885377 0.01402707]
 [0.02185258 0.02309533 0.02142872 ... 0.00941292 0.00809642 0.01217903]]

-* TASK 10/20 | SAMPLE 66/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 327/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not provide any information about Mary being in the school. The information only mentions Mary being either in the bedroom or the park, and Fred moving to the cinema, but there is no mention of the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', '.', ' The', ' information', ' only', ' mentions', ' Mary', ' being', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' park', ',', ' and', ' Fred', ' moving', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0385, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01776543 0.02830224 0.03258153 ... 0.00979801 0.00606535 0.00814885]
 [0.0183218  0.02542627 0.02856185 ... 0.01187683 0.00766169 0.01054849]
 [0.01860731 0.02504367 0.02979116 ... 0.01699278 0.01055451 0.01218993]
 ...
 [0.01858847 0.02668589 0.02492504 ... 0.00595451 0.0046813  0.00557164]
 [0.01888955 0.02052917 0.01973345 ... 0.00827228 0.00554877 0.00567418]
 [0.01891041 0.02347907 0.02238304 ... 0.00808515 0.0054716  0.00568627]]

-* TASK 10/20 | SAMPLE 66/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 328/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 explicitly states that Bill moved to the cinema, which implies that Bill is currently in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03004114 0.03791426 0.04223517 ... 0.04191473 0.01976487 0.02477143]
 [0.03049638 0.03967191 0.04624104 ... 0.03107678 0.03151831 0.03780835]
 [0.03137108 0.04079341 0.04550626 ... 0.03029912 0.01757812 0.02125308]
 ...
 [0.03164871 0.0380195  0.03577496 ... 0.03282114 0.01743272 0.0170728 ]
 [0.03177338 0.03102818 0.02859107 ... 0.03275663 0.02829948 0.02687873]
 [0.03184075 0.03700795 0.03219413 ... 0.03633045 0.02127593 0.02296007]]

-* TASK 10/20 | SAMPLE 66/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 329/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the school. The context sentences only mention Bill and Mary moving to the bedroom, but there is no mention of Fred or the school.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' and', ' Mary', ' moving', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 44), x_tokens=44, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 44)
DEBUG result.interpretability.attn_scores 1936 
 [[0.02112802 0.03082356 0.02897669 ... 0.09108604 0.01197702 0.01194069]
 [0.02133201 0.02844384 0.02629322 ... 0.03843294 0.01822435 0.00988361]
 [0.02203509 0.03087473 0.0302064  ... 0.06751037 0.0171085  0.0124712 ]
 ...
 [0.02245047 0.02620974 0.02413124 ... 0.01811684 0.00826539 0.00896815]
 [0.02271447 0.03064646 0.03071588 ... 0.0189811  0.00831568 0.00808697]
 [0.02282496 0.02766066 0.02844453 ... 0.02442483 0.00842829 0.00910709]]

-* TASK 10/20 | SAMPLE 66/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 330/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 (from previous parts) explicitly stated that Bill went back to the bedroom. Although the current context sentences do not mention Bill, the previous information is still valid.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' (', 'from', ' previous', ' parts', ')', ' explicitly', ' stated', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', '.', ' Although', ' the', ' current', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ',', ' the', ' previous', ' information', ' is', ' still', ' valid', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02099436 0.02242114 0.01778141 ... 0.01301801 0.02855175 0.02991107]
 [0.02119235 0.02238909 0.0200483  ... 0.01643799 0.01589418 0.01693132]
 [0.02195635 0.0238623  0.02029132 ... 0.0233997  0.03857387 0.02985852]
 ...
 [0.02226227 0.02179981 0.01869768 ... 0.01149125 0.06345203 0.04846015]
 [0.02266875 0.01609682 0.01379885 ... 0.00998605 0.03029226 0.03682058]
 [0.02248644 0.02030317 0.01646285 ... 0.01079635 0.02181067 0.06238755]]
Model's predictions for the sample 66:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Bill being in the bedroom. The context   |
|          |                 |  sentences only mention Bill traveling to  |
|          |                 |   the park, and Julie being in the park.   |
|          |                 |   There is no connection to the bedroom.   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences do not provide any  |
|          |                 |    information about Mary being in the     |
|          |                 |   school. The information only mentions    |
|          |                 |  Mary being either in the bedroom or the   |
|          |                 |  park, and Fred moving to the cinema, but  |
|          |                 |     there is no mention of the school.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 8 explicitly states  |
|          |                 |    that Bill moved to the cinema, which    |
|          |                 |   implies that Bill is currently in the    |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |   Fred being in the school. The context    |
|          |                 |    sentences only mention Bill and Mary    |
|          |                 |   moving to the bedroom, but there is no   |
|          |                 |       mention of Fred or the school.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   The context sentence 10 (from previous   |
|          |                 |  parts) explicitly stated that Bill went   |
|          |                 |     back to the bedroom. Although the      |
|          |                 |  current context sentences do not mention  |
|          |                 |  Bill, the previous information is still   |
|          |                 |                   valid.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 66:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.06 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 67/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 331/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 2 explicitly states that Mary is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.08, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03724033 0.06197111 0.07527774 0.08762129 0.08824337 0.08944459
  0.08795661 0.10323042 0.07687326 0.07983859 0.06464061 0.07903796
  0.09521002 0.09044618 0.05255575 0.0413367  0.0369601  0.04505895
  0.03850024 0.04391631 0.0390285  0.05092786 0.04880573 0.03563105
  0.02333091 0.03358318]
 [0.03761547 0.07002336 0.06310432 0.07295836 0.06119479 0.06805274
  0.08665388 0.08421624 0.06805837 0.06305536 0.05862699 0.05435743
  0.06792887 0.09605102 0.09540174 0.04468521 0.03525486 0.04379129
  0.03707216 0.04319834 0.03644774 0.05105808 0.05089699 0.0330856
  0.01875512 0.02960282]
 [0.04078238 0.06789947 0.04180175 0.0619874  0.04546108 0.04212953
  0.03893419 0.02788346 0.02806048 0.04062385 0.0366242  0.02039909
  0.02437582 0.03381652 0.04214178 0.03037828 0.01637877 0.01809425
  0.02131755 0.02300638 0.0224255  0.05573181 0.0581994  0.0135815
  0.00693212 0.01561507]
 [0.03843052 0.0442138  0.04397218 0.02762702 0.01879262 0.03468443
  0.03443025 0.03020277 0.03883618 0.0302465  0.03126681 0.03050396
  0.03024157 0.01284179 0.01207121 0.03836526 0.0388171  0.04375679
  0.05746642 0.05343805 0.04452755 0.04331267 0.0660593  0.0727598
  0.07658371 0.06754144]
 [0.03881169 0.04856116 0.0520701  0.07689689 0.06832454 0.05531197
  0.04181395 0.03625954 0.04240579 0.05418815 0.04470946 0.0319051
  0.03351769 0.11048417 0.11074477 0.04666326 0.03138403 0.02818582
  0.02744195 0.03098158 0.03111313 0.04919209 0.06676991 0.02314136
  0.01009076 0.03320402]
 [0.03960311 0.03171011 0.03209156 0.05930233 0.05089956 0.05035784
  0.03145986 0.02843255 0.0359108  0.04999781 0.03949039 0.0358745
  0.03610136 0.11922531 0.13713238 0.04597853 0.0349394  0.03379277
  0.03097867 0.03319376 0.02990294 0.04247657 0.04075542 0.01640174
  0.008271   0.02203117]
 [0.04020555 0.03510993 0.04104136 0.06139249 0.05482529 0.06272814
  0.0404206  0.03853833 0.04693644 0.05864111 0.04572531 0.05644248
  0.05432254 0.0950058  0.08590851 0.03863753 0.03188053 0.03337771
  0.02977272 0.03264533 0.0281794  0.03824478 0.03825781 0.02237363
  0.01188728 0.02122741]
 [0.03888246 0.05033061 0.05911117 0.0510419  0.05034095 0.06143426
  0.04835777 0.05391426 0.05384508 0.05507201 0.04880358 0.06521589
  0.05860235 0.05852009 0.0512706  0.0512943  0.04289571 0.04241282
  0.03672319 0.04009199 0.03725317 0.04381292 0.05465551 0.04352017
  0.03242204 0.03848728]
 [0.03924908 0.0612129  0.06996513 0.03947921 0.03168445 0.05056478
  0.05694509 0.05993051 0.05767342 0.04279057 0.04310808 0.05323577
  0.05496734 0.02690938 0.01870718 0.05010377 0.04004028 0.03989528
  0.03780938 0.03989075 0.03812539 0.03873714 0.06404656 0.05367155
  0.04450155 0.04883131]
 [0.04025701 0.07931028 0.08435839 0.03437629 0.02446097 0.0440264
  0.05613783 0.0516215  0.06099837 0.03500251 0.03484916 0.04358304
  0.04248384 0.01791242 0.01449408 0.05752295 0.03869207 0.03744414
  0.03678371 0.04215306 0.03767565 0.03786159 0.0740985  0.04610547
  0.03043362 0.03607833]
 [0.04028091 0.04689938 0.05210578 0.02718003 0.02095902 0.03256839
  0.04646652 0.0444442  0.04766691 0.02996704 0.0311746  0.03640315
  0.03453775 0.0150426  0.01336111 0.05515704 0.04300014 0.03725177
  0.0393276  0.04132819 0.03862873 0.03781029 0.05620629 0.06005982
  0.05372061 0.04330285]
 [0.04064528 0.02458476 0.02731425 0.01770273 0.01502356 0.02239758
  0.02803992 0.02920938 0.04005598 0.02195675 0.0219444  0.02320592
  0.02313983 0.01007354 0.00971315 0.03513265 0.03229898 0.02982567
  0.03546702 0.03856241 0.03627875 0.03161431 0.0448928  0.07111528
  0.08224601 0.06608769]
 [0.04039146 0.03377567 0.03598863 0.02380778 0.0192973  0.03262735
  0.03648826 0.03676531 0.03503952 0.02728011 0.03058906 0.03742181
  0.03335686 0.01221227 0.01165216 0.04706392 0.03888864 0.03624026
  0.0378493  0.03823733 0.03736538 0.03787211 0.03494294 0.05919456
  0.06802405 0.05281983]
 [0.04107966 0.04452426 0.04825172 0.04049725 0.02914821 0.05323042
  0.05005444 0.05690003 0.04906448 0.05239518 0.05068005 0.08038153
  0.06291343 0.02202372 0.0150827  0.0362595  0.03666921 0.0405414
  0.03695562 0.03801029 0.03416726 0.03989177 0.02694169 0.02985109
  0.02223422 0.02351055]
 [0.04159899 0.03104074 0.03271744 0.02536825 0.02116706 0.03130121
  0.03813419 0.03718866 0.03221798 0.03060005 0.0381349  0.04009686
  0.03866715 0.01287941 0.01140877 0.03563172 0.03718052 0.03310537
  0.03444135 0.03446977 0.03366164 0.03804946 0.02288546 0.03678054
  0.04148326 0.02584262]
 [0.04083552 0.02239717 0.02044062 0.01592117 0.01370985 0.01890199
  0.0256665  0.02606853 0.02383962 0.01961494 0.02981451 0.02565981
  0.02872562 0.00767021 0.00840971 0.03575876 0.04580823 0.03638349
  0.04120703 0.03751419 0.04081791 0.03496287 0.0192107  0.04627223
  0.08433881 0.04862164]
 [0.0402721  0.02136709 0.01834156 0.01459931 0.01197365 0.01686828
  0.02673115 0.0294469  0.02247197 0.01757954 0.02773825 0.02144199
  0.02846204 0.00665007 0.00701708 0.03588445 0.05380068 0.04495753
  0.05663713 0.04984003 0.06318707 0.03127759 0.01690547 0.05490389
  0.10845836 0.05533361]
 [0.04111709 0.02135183 0.01880273 0.01468679 0.01263371 0.0183702
  0.02451725 0.02606434 0.02279056 0.01875802 0.03295732 0.02741085
  0.02780979 0.00707079 0.00696718 0.03308587 0.05256051 0.03674366
  0.04770808 0.03889929 0.0442836  0.0306491  0.01383139 0.04303876
  0.0863387  0.04442578]
 [0.04096027 0.02018177 0.01792249 0.01243916 0.01122883 0.01586699
  0.02630215 0.02541744 0.02216922 0.01645157 0.04497533 0.02636492
  0.02770555 0.00614595 0.00630813 0.04323083 0.05008775 0.04369301
  0.05375908 0.04595527 0.05340871 0.02998969 0.01385494 0.04521818
  0.05263093 0.06961665]
 [0.03960167 0.02617924 0.02195772 0.01614704 0.01483607 0.01893759
  0.02996862 0.0266735  0.02899865 0.01873276 0.02982373 0.02251065
  0.02780979 0.00790534 0.0081688  0.03711643 0.03545144 0.04703283
  0.06206358 0.06935234 0.07072629 0.03490631 0.03230857 0.09179141
  0.07143059 0.09098211]
 [0.04167156 0.02573059 0.02579714 0.02241752 0.01680343 0.0247684
  0.02682178 0.03063171 0.02992801 0.02585751 0.03239638 0.03168622
  0.03062726 0.01132505 0.01002111 0.02905498 0.02874903 0.03487224
  0.03896318 0.03540226 0.0379614  0.03295593 0.01732032 0.02643828
  0.02242645 0.03735036]
 [0.04050291 0.03155129 0.03002819 0.04973435 0.04777773 0.0459611
  0.03077708 0.03012593 0.03569958 0.05291202 0.04187708 0.0403536
  0.03961723 0.07653408 0.08861722 0.03129047 0.03213456 0.03475462
  0.03077328 0.03130077 0.0309396  0.03922863 0.03400789 0.01691251
  0.01047488 0.02410522]
 [0.04024339 0.03288017 0.02911866 0.05321159 0.09680753 0.04232088
  0.02882541 0.02812796 0.03349058 0.0572303  0.04650602 0.03808224
  0.03268972 0.07659177 0.09769704 0.03792348 0.04383596 0.04843849
  0.03578186 0.03446535 0.03619834 0.03629199 0.03264556 0.01395907
  0.00743782 0.02026989]
 [0.03962757 0.03042968 0.02728588 0.0461251  0.10397323 0.03076163
  0.02520607 0.02774654 0.03022548 0.05207867 0.04766478 0.04187895
  0.03193622 0.03406357 0.04781568 0.03439097 0.07513904 0.07671265
  0.05280102 0.04294107 0.05394794 0.03379466 0.03023825 0.02470146
  0.01410612 0.02620839]
 [0.04009392 0.03676363 0.03113354 0.04747877 0.07043315 0.03638328
  0.03289068 0.03096004 0.03674335 0.04912911 0.04587899 0.03654629
  0.03425035 0.03259888 0.03733217 0.02805315 0.04715247 0.05363717
  0.04239881 0.04120582 0.04374846 0.05934978 0.04126253 0.01949099
  0.01144109 0.02532076]]

-* TASK 10/20 | SAMPLE 67/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 332/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred's location in the given context sentences. The context sentences only mention Bill and Mary's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' and', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 32), x_tokens=32, y_tokens=33, max_supp_attn=0.1212, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 32)
DEBUG result.interpretability.attn_scores 1056 
 [[0.02830332 0.03188643 0.03309185 ... 0.03230631 0.01038001 0.07524675]
 [0.02899605 0.03218211 0.03117429 ... 0.04639596 0.0179392  0.08610096]
 [0.02958971 0.029925   0.03285844 ... 0.05379227 0.02152468 0.06660485]
 ...
 [0.02989185 0.02877156 0.02409991 ... 0.01257945 0.01631254 0.04161774]
 [0.03030265 0.02928778 0.02798171 ... 0.01197444 0.01463338 0.04478284]
 [0.03054411 0.02423392 0.02453011 ... 0.01118444 0.01374483 0.07207597]]

-* TASK 10/20 | SAMPLE 67/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 333/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 explicitly states that Mary went back to the cinema, which implies that Mary is currently in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' explicitly', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02907471 0.03732571 0.03908863 ... 0.01728204 0.04135973 0.02959106]
 [0.02957281 0.03249345 0.03490986 ... 0.02664991 0.03716724 0.03788494]
 [0.03040755 0.04110157 0.0466333  ... 0.01257824 0.03165507 0.01910729]
 ...
 [0.03070113 0.03725101 0.03955945 ... 0.01136131 0.03945394 0.02467042]
 [0.03106588 0.02743255 0.02749971 ... 0.02029125 0.03410519 0.03880826]
 [0.03088865 0.03156969 0.03213356 ... 0.01665619 0.04018628 0.04046368]]

-* TASK 10/20 | SAMPLE 67/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 334/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 (from previous parts of the conversation) explicitly states that Julie journeyed to the office, and there is no information about Julie leaving the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' (', 'from', ' previous', ' parts', ' of', ' the', ' conversation', ')', ' explicitly', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Julie', ' leaving', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.0732, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02265532 0.01896283 0.01862703 ... 0.01709272 0.00828686 0.05955519]
 [0.02298128 0.02507995 0.02443345 ... 0.03943065 0.03135937 0.02490333]
 [0.02359135 0.02133651 0.02293519 ... 0.02218664 0.01190648 0.04893447]
 ...
 [0.02384799 0.02452056 0.01900481 ... 0.0071931  0.00620122 0.07690587]
 [0.02435577 0.01989869 0.01464426 ... 0.0079208  0.00991556 0.05414793]
 [0.0242459  0.02213093 0.01542096 ... 0.00667962 0.00707541 0.06551813]]

-* TASK 10/20 | SAMPLE 67/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 335/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Mary being in the school in the given context sentences. The context sentences only mention Mary's possible locations as the bedroom or the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', "'s", ' possible', ' locations', ' as', ' the', ' bedroom', ' or', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02386478 0.03183807 0.03130734 ... 0.0172454  0.03095361 0.02227812]
 [0.02418883 0.02893733 0.02555415 ... 0.02324019 0.0264049  0.01595765]
 [0.02487068 0.0355619  0.03569693 ... 0.01629175 0.02711084 0.01438065]
 ...
 [0.0250606  0.03054213 0.02807941 ... 0.01488274 0.03732102 0.02228595]
 [0.02546029 0.0241102  0.02118071 ... 0.02100939 0.03009612 0.02877539]
 [0.02544581 0.02663362 0.02236392 ... 0.01888592 0.03110318 0.0272203 ]]
Model's predictions for the sample 67:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 2 explicitly states  |
|          |                 |        that Mary is in the cinema.         |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Fred's    |
|          |                 |  location in the given context sentences.  |
|          |                 |  The context sentences only mention Bill   |
|          |                 |           and Mary's locations.            |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 7 explicitly states  |
|          |                 |  that Mary went back to the cinema, which  |
|          |                 |   implies that Mary is currently in the    |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   The context sentence 8 (from previous    |
|          |                 |   parts of the conversation) explicitly    |
|          |                 |     states that Julie journeyed to the     |
|          |                 |    office, and there is no information     |
|          |                 |      about Julie leaving the office.       |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no information about Mary being  |
|          |                 |     in the school in the given context     |
|          |                 |   sentences. The context sentences only    |
|          |                 |  mention Mary's possible locations as the  |
|          |                 |            bedroom or the park.            |
+----------+-----------------+--------------------------------------------+

Metrics for sample 67:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.09 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 68/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 336/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Mary is either in the park or the bedroom, but there is no mention of the office. Sentence 1 only mentions Mary traveling to the school, which does not imply she is in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' office', '.', ' Sentence', ' ', '1', ' only', ' mentions', ' Mary', ' traveling', ' to', ' the', ' school', ',', ' which', ' does', ' not', ' imply', ' she', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 26), x_tokens=26, y_tokens=57, max_supp_attn=0.1228, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 26)
DEBUG result.interpretability.attn_scores 1482 
 [[0.01604681 0.03315518 0.03684462 ... 0.01080545 0.00575913 0.01677225]
 [0.01595304 0.04001702 0.03101745 ... 0.03418842 0.01710398 0.02645627]
 [0.01742081 0.04532349 0.02680118 ... 0.00539901 0.00189572 0.00737916]
 ...
 [0.01720061 0.0204761  0.02099905 ... 0.00528281 0.00191723 0.01005106]
 [0.0170814  0.01625454 0.01706538 ... 0.00773624 0.00609921 0.01278047]
 [0.01726594 0.01979775 0.01969876 ... 0.00641476 0.00356229 0.01073045]]

-* TASK 10/20 | SAMPLE 68/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 337/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 4 states that Mary went back to the office, which implies she is currently in the office. There is no recent information suggesting she is in the bedroom. Sentence 5 is about Julie's movement and does not provide any information about Mary's location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' implies', ' she', ' is', ' currently', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' recent', ' information', ' suggesting', ' she', ' is', ' in', ' the', ' bedroom', '.', ' Sentence', ' ', '5', ' is', ' about', ' Julie', "'s", ' movement', ' and', ' does', ' not', ' provide', ' any', ' information', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 32), x_tokens=32, y_tokens=59, max_supp_attn=0.0169, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 32)
DEBUG result.interpretability.attn_scores 1888 
 [[0.0155515  0.02219325 0.02501346 ... 0.02732118 0.00466429 0.0084176 ]
 [0.01594185 0.02255082 0.02482477 ... 0.03763095 0.00600597 0.01209814]
 [0.01628555 0.02058904 0.02502059 ... 0.04543217 0.00665774 0.01401248]
 ...
 [0.01633125 0.02380713 0.02220608 ... 0.01271749 0.00408881 0.00721648]
 [0.01672011 0.01727189 0.01604825 ... 0.00947687 0.00801741 0.01017493]
 [0.01674186 0.01877946 0.01663177 ... 0.00733838 0.00545829 0.0083218 ]]

-* TASK 10/20 | SAMPLE 68/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 338/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 states that Julie is either in the bedroom or the school, but there is no mention of the cinema. Sentence 8 is about Fred's location and does not provide any information about Julie's location.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' cinema', '.', ' Sentence', ' ', '8', ' is', ' about', ' Fred', "'s", ' location', ' and', ' does', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 38), x_tokens=38, y_tokens=50, max_supp_attn=0.08, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 38)
DEBUG result.interpretability.attn_scores 1900 
 [[0.01856412 0.03212906 0.03301489 ... 0.04640343 0.05065664 0.02597629]
 [0.01893238 0.02365687 0.0265206  ... 0.02354309 0.02961456 0.02459848]
 [0.01928806 0.03241216 0.03593092 ... 0.04240349 0.03879688 0.0230957 ]
 ...
 [0.01938171 0.03217972 0.02762879 ... 0.09805012 0.04350013 0.02139394]
 [0.01981447 0.02332162 0.01926659 ... 0.05569839 0.02370327 0.021003  ]
 [0.01975095 0.02668457 0.02150167 ... 0.07354213 0.03260564 0.01921325]]

-* TASK 10/20 | SAMPLE 68/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 339/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 (from previous context) states that Julie is either in the bedroom or the school. There is no new information that suggests Julie's location has changed. Sentences 10 and 11 are about Fred and Bill's locations, respectively, and do not provide any new information about Julie's location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' (', 'from', ' previous', ' context', ')', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', '.', ' There', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Julie', "'s", ' location', ' has', ' changed', '.', ' Sent', 'ences', ' ', '10', ' and', ' ', '11', ' are', ' about', ' Fred', ' and', ' Bill', "'s", ' locations', ',', ' respectively', ',', ' and', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(69, 44), x_tokens=44, y_tokens=69, max_supp_attn=0.0435, attn_on_target=0.0145)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (69, 44)
DEBUG result.interpretability.attn_scores 3036 
 [[0.01324345 0.01856852 0.01856351 ... 0.0234731  0.06099414 0.01186435]
 [0.01353926 0.01479536 0.01422837 ... 0.01076893 0.04393349 0.01150756]
 [0.01381638 0.02076937 0.02075367 ... 0.0124262  0.05441906 0.01166692]
 ...
 [0.01401233 0.01907532 0.01858046 ... 0.02303138 0.01583584 0.00523975]
 [0.01427897 0.01506999 0.01354591 ... 0.02960367 0.01013835 0.00920393]
 [0.01431211 0.0157193  0.01454943 ... 0.02351404 0.01083082 0.00663025]]

-* TASK 10/20 | SAMPLE 68/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 340/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Fred is either in the bedroom or the office, which implies that Fred's location is one of these two options. There is no new information that suggests Fred's location has changed.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' which', ' implies', ' that', ' Fred', "'s", ' location', ' is', ' one', ' of', ' these', ' two', ' options', '.', ' There', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Fred', "'s", ' location', ' has', ' changed', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0833, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01909277 0.02718236 0.02641013 ... 0.0156138  0.01063954 0.01900106]
 [0.01925669 0.0197198  0.01987541 ... 0.02317257 0.0132431  0.01499203]
 [0.01994831 0.03008509 0.03266689 ... 0.02491226 0.01738268 0.02736852]
 ...
 [0.02018997 0.03100191 0.03296676 ... 0.00949564 0.00694616 0.0339402 ]
 [0.02074046 0.02372564 0.02218168 ... 0.01036643 0.00732654 0.01114245]
 [0.02062604 0.02688107 0.02614396 ... 0.01024001 0.00750502 0.0133469 ]]
Model's predictions for the sample 68:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 2, Mary is either   |
|          |                 |  in the park or the bedroom, but there is  |
|          |                 |    no mention of the office. Sentence 1    |
|          |                 |    only mentions Mary traveling to the     |
|          |                 |   school, which does not imply she is in   |
|          |                 |                the office.                 |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  Sentence 4 states that Mary went back to  |
|          |                 |      the office, which implies she is      |
|          |                 |    currently in the office. There is no    |
|          |                 |  recent information suggesting she is in   |
|          |                 |  the bedroom. Sentence 5 is about Julie's  |
|          |                 |     movement and does not provide any      |
|          |                 |     information about Mary's location.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   Sentence 7 states that Julie is either   |
|          |                 |  in the bedroom or the school, but there   |
|          |                 |  is no mention of the cinema. Sentence 8   |
|          |                 |   is about Fred's location and does not    |
|          |                 |   provide any information about Julie's    |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |     Sentence 7 (from previous context)     |
|          |                 |     states that Julie is either in the     |
|          |                 |   bedroom or the school. There is no new   |
|          |                 |     information that suggests Julie's      |
|          |                 |   location has changed. Sentences 10 and   |
|          |                 |  11 are about Fred and Bill's locations,   |
|          |                 |  respectively, and do not provide any new  |
|          |                 |    information about Julie's location.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 13 states that Fred is either   |
|          |                 |    in the bedroom or the office, which     |
|          |                 |   implies that Fred's location is one of   |
|          |                 |     these two options. There is no new     |
|          |                 |      information that suggests Fred's      |
|          |                 |           location has changed.            |
+----------+-----------------+--------------------------------------------+

Metrics for sample 68:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.07 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 69/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 341/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Fred journeyed to the bedroom, which implies that Fred is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.0272468  0.0458406  0.05522672 0.07179555 0.08004538 0.07433557
  0.05866662 0.06555493 0.05509292 0.06422033 0.0479648  0.06087548
  0.06651193 0.09600656 0.06525867 0.03024998 0.03115947 0.03175405
  0.02887861 0.02986315 0.02535957 0.03872961 0.04281286 0.02049853
  0.01370077 0.02381906]
 [0.02766283 0.05706124 0.05259018 0.07127708 0.06231934 0.05990817
  0.04600946 0.04284345 0.04265448 0.04914025 0.03896113 0.03235617
  0.03323261 0.10383267 0.10394959 0.03081802 0.02541955 0.02185969
  0.02185236 0.02157235 0.01995041 0.03976607 0.04577315 0.01556506
  0.00812584 0.02060325]
 [0.02978158 0.06078837 0.03758869 0.05290686 0.03732759 0.03561478
  0.03241666 0.02252756 0.02263015 0.03370431 0.02766059 0.0166628
  0.01807136 0.02602648 0.03467515 0.02185109 0.01388429 0.01298334
  0.01584199 0.01576542 0.01537202 0.04303508 0.05268177 0.0097167
  0.00510105 0.01119036]
 [0.02789021 0.03517551 0.03244013 0.02316913 0.01609029 0.02581354
  0.02915667 0.02620154 0.0295829  0.02416851 0.02461361 0.02525496
  0.02436215 0.01171018 0.01108415 0.03035665 0.02850148 0.03325565
  0.03995947 0.04286104 0.03368622 0.03225475 0.04785438 0.05609453
  0.06156363 0.05276135]
 [0.02826584 0.04315707 0.04764184 0.06589888 0.0599437  0.04827946
  0.03577235 0.02976653 0.03476228 0.04563532 0.03458064 0.02612248
  0.0256178  0.09360911 0.09801669 0.03495273 0.0266866  0.01994473
  0.02098944 0.0216809  0.02160009 0.03829455 0.06480346 0.01728703
  0.0070013  0.02521246]
 [0.02880755 0.02776675 0.02907758 0.05013204 0.04524942 0.0429372
  0.02621127 0.02324509 0.02939383 0.04262715 0.03117087 0.02974857
  0.02760155 0.10574435 0.12687683 0.0348704  0.03060016 0.02419977
  0.02360535 0.02298043 0.0207193  0.03227883 0.03769808 0.01162416
  0.00590619 0.01636209]
 [0.02921585 0.03171515 0.03795549 0.05386636 0.04980798 0.05510805
  0.0352409  0.03252315 0.03915318 0.05119703 0.0368334  0.04772366
  0.04266139 0.08387298 0.07850283 0.02929928 0.02777081 0.02428403
  0.02274489 0.02277767 0.01959835 0.02934589 0.03525934 0.01579354
  0.00885929 0.01609418]
 [0.02820232 0.04158931 0.04833253 0.04199699 0.04421245 0.05103467
  0.04154097 0.04337366 0.04332278 0.04530414 0.03746829 0.05313512
  0.04560795 0.05141592 0.04598853 0.03914078 0.03591933 0.03259443
  0.02973759 0.03084983 0.02820491 0.03426117 0.05016226 0.03850683
  0.0269017  0.03113986]
 [0.02933412 0.04257171 0.05031034 0.04706411 0.04315827 0.05790578
  0.04615913 0.04759715 0.05008061 0.05018752 0.03712878 0.05313638
  0.04834031 0.03773997 0.02509671 0.02791595 0.02790045 0.02664233
  0.02541803 0.02642435 0.02274285 0.03414298 0.03958834 0.02219379
  0.0142602  0.02298507]
 [0.02865316 0.05517648 0.05803655 0.03020642 0.02429201 0.03911798
  0.04841628 0.04574086 0.04771075 0.03180296 0.03001753 0.04009213
  0.04036772 0.01761633 0.01471183 0.04277711 0.03457552 0.03104197
  0.03181127 0.0333767  0.03162035 0.03403657 0.06660418 0.04453005
  0.03390845 0.03374775]
 [0.02921811 0.03939933 0.04581293 0.02415076 0.02069932 0.02785941
  0.04752848 0.03516851 0.04133691 0.02463186 0.02394441 0.02756562
  0.02723009 0.01332431 0.01280333 0.04181165 0.03178408 0.02722383
  0.03025909 0.03230092 0.03031343 0.02969542 0.0544299  0.05050781
  0.03969697 0.03535521]
 [0.02962534 0.01437183 0.01667309 0.01124169 0.01006231 0.01424185
  0.01715619 0.01676113 0.02269463 0.01416644 0.0133719  0.01495733
  0.01438758 0.00626331 0.00635229 0.01837503 0.01875945 0.01798613
  0.02322643 0.02419958 0.02456503 0.01926379 0.03071997 0.0575632
  0.06319319 0.06050047]
 [0.02924528 0.0236465  0.02434882 0.01527188 0.01409091 0.01920336
  0.02421068 0.02214835 0.02363407 0.01724288 0.02083247 0.02100103
  0.02067495 0.0084234  0.0088632  0.03364552 0.02604511 0.0257006
  0.02784103 0.02822619 0.02746264 0.02837526 0.03023535 0.05134446
  0.06685774 0.04984015]
 [0.02946233 0.02367318 0.02417047 0.01765544 0.01572781 0.0225616
  0.02693209 0.02829739 0.02548804 0.02130558 0.02477172 0.02837903
  0.02937906 0.00993817 0.00885626 0.03428087 0.03001888 0.03137942
  0.02957181 0.02928302 0.02893629 0.02940381 0.02235375 0.04706727
  0.05348105 0.02879453]
 [0.02887643 0.02008336 0.0173175  0.01445478 0.01185063 0.01558322
  0.02222537 0.02254686 0.01974733 0.01624355 0.02219294 0.01955851
  0.02352125 0.00696494 0.00688641 0.0353952  0.02701307 0.03715768
  0.03639034 0.03914677 0.04290039 0.02738426 0.01677815 0.05512679
  0.10591199 0.04270805]
 [0.03007001 0.01880515 0.01826393 0.01491656 0.01371695 0.01838288
  0.02277413 0.0221983  0.02058711 0.01724434 0.02188776 0.02116145
  0.02145774 0.00735357 0.0070669  0.03219979 0.02013128 0.02918889
  0.02530998 0.03136545 0.02559748 0.0215172  0.01527421 0.03423646
  0.08032541 0.02956711]
 [0.02987357 0.01741631 0.01598325 0.01263947 0.01092034 0.01494056
  0.02042433 0.02097327 0.0185265  0.01488544 0.02403633 0.02073807
  0.02197846 0.00628705 0.00623441 0.03652222 0.02475736 0.0370271
  0.02954517 0.03576327 0.03174091 0.02217231 0.01259817 0.03533228
  0.06786139 0.03510688]
 [0.02971972 0.01628326 0.01512263 0.01089881 0.00946467 0.01316431
  0.01971369 0.02020691 0.01767792 0.01328331 0.0252007  0.01838148
  0.02030806 0.00557825 0.00590789 0.03043251 0.03114514 0.03513948
  0.03375717 0.03559994 0.03514737 0.02301802 0.01309531 0.03619545
  0.04263276 0.05355795]
 [0.02924773 0.01874787 0.01651072 0.01224405 0.01115434 0.01512708
  0.02022376 0.01876161 0.02067798 0.01407203 0.02245646 0.01706856
  0.0199309  0.00649627 0.00643886 0.02359378 0.0285706  0.02758671
  0.03293174 0.04014011 0.0376198  0.02371606 0.01876608 0.06094767
  0.04317562 0.06362193]
 [0.03020122 0.02152871 0.02024595 0.01500366 0.01242074 0.01737589
  0.02232107 0.0230816  0.02145621 0.01661539 0.02398117 0.02105827
  0.02207189 0.00770742 0.00731358 0.02222366 0.02417385 0.02487768
  0.0282757  0.02853136 0.03045804 0.02566524 0.01552403 0.02317973
  0.02182315 0.03634407]
 [0.03032608 0.0248847  0.02775511 0.02291197 0.01828239 0.0265712
  0.02894694 0.03607111 0.02807187 0.0274512  0.03023815 0.03739268
  0.03396754 0.0126558  0.00913194 0.02312594 0.02376552 0.02699457
  0.02541803 0.02325591 0.02380801 0.02845338 0.01599863 0.01726714
  0.01801918 0.01867982]
 [0.03044956 0.02983668 0.0317301  0.02800122 0.02076241 0.03144476
  0.03513298 0.04319768 0.02997567 0.03291123 0.03767543 0.04539161
  0.04264202 0.0147789  0.01015101 0.02474461 0.02374863 0.02872011
  0.02439821 0.02364198 0.02266493 0.02889787 0.01755266 0.01582802
  0.01581461 0.01433719]
 [0.03034434 0.02625    0.02660931 0.02429593 0.01911747 0.02733369
  0.03104526 0.03606203 0.02900252 0.02988127 0.03400581 0.03911074
  0.03989371 0.01350869 0.00999111 0.0280397  0.0252087  0.03134108
  0.02709701 0.02564555 0.02525024 0.02871081 0.01494048 0.01945803
  0.01721774 0.013359  ]
 [0.03022452 0.01996802 0.01918091 0.01463313 0.01104078 0.01652353
  0.02253589 0.0251116  0.02250117 0.01780937 0.02320166 0.02312862
  0.02656922 0.00771791 0.00687632 0.03126748 0.0273679  0.03030484
  0.02929354 0.02752931 0.03126893 0.02714955 0.01276472 0.02965386
  0.02546792 0.01843461]
 [0.03014017 0.02175234 0.01997759 0.01593275 0.01143997 0.01672647
  0.02590278 0.02621857 0.02322518 0.01837004 0.0255733  0.02244983
  0.02790919 0.00785702 0.00709527 0.03339568 0.02760009 0.03539265
  0.03332792 0.03202955 0.03517526 0.02484024 0.01246355 0.03039957
  0.02693483 0.02032956]
 [0.03035353 0.02052434 0.01868288 0.01520967 0.01221426 0.01607801
  0.02223555 0.02476646 0.02208934 0.01872591 0.02511246 0.02333496
  0.02511303 0.00808722 0.00710451 0.02743801 0.03218827 0.03075577
  0.03430581 0.02805363 0.03291284 0.02445351 0.01242473 0.02007717
  0.01881715 0.01941145]
 [0.03043903 0.02315138 0.02150617 0.01651481 0.01241615 0.01764745
  0.02648515 0.02826219 0.0271295  0.01988357 0.03002488 0.02469947
  0.02778613 0.0084107  0.00731253 0.02978162 0.03128942 0.03229343
  0.03338367 0.03089028 0.03405816 0.02538339 0.01357617 0.02176031
  0.01927102 0.02034291]
 [0.03054234 0.01717385 0.01654269 0.01073981 0.00916528 0.01243275
  0.02103621 0.02140583 0.02053142 0.01360432 0.02920002 0.01787758
  0.02179159 0.00616064 0.00540361 0.02640264 0.03397099 0.02846466
  0.03540161 0.03060559 0.03394529 0.02347985 0.01214611 0.02322141
  0.01856105 0.03109847]
 [0.02916692 0.02238242 0.02104348 0.01246388 0.01154206 0.01544212
  0.0278545  0.02730396 0.02620471 0.01599952 0.03269436 0.02129859
  0.02704664 0.0073613  0.00712888 0.02588484 0.03688793 0.03820606
  0.0443629  0.04797366 0.05272987 0.02670322 0.02344946 0.05016073
  0.02587334 0.05842261]
 [0.03053714 0.02232827 0.0219899  0.01722684 0.01325812 0.02024127
  0.02326079 0.02633097 0.02630584 0.02033094 0.02431088 0.02509139
  0.02505264 0.010451   0.00830912 0.01820285 0.02500167 0.02151693
  0.02695146 0.02677612 0.03010117 0.02570884 0.01535685 0.01659646
  0.01306521 0.02331172]
 [0.02944355 0.02828463 0.02850216 0.04204123 0.0441161  0.03797183
  0.02491216 0.02514566 0.0312947  0.04319944 0.03187194 0.03175601
  0.03050253 0.06688873 0.08131967 0.02376802 0.02750358 0.0241842
  0.02454228 0.0231873  0.02244049 0.03121577 0.03272606 0.01212129
  0.00666239 0.01842081]
 [0.02921858 0.02940198 0.02850636 0.04653873 0.09034628 0.03718325
  0.02301237 0.02340404 0.02999033 0.05049109 0.03760924 0.03195606
  0.02527597 0.06874685 0.08693402 0.02979741 0.03933538 0.03349516
  0.02908583 0.02547812 0.02622722 0.02836263 0.03183697 0.00997209
  0.00537643 0.01578132]
 [0.02896847 0.0261425  0.02476525 0.03725062 0.07909788 0.02516701
  0.01884524 0.0222721  0.02581194 0.04343039 0.03522166 0.03304753
  0.02526799 0.02999722 0.03864701 0.02569376 0.06126212 0.05310094
  0.04260745 0.03204542 0.0435593  0.02576272 0.02939134 0.01666467
  0.01096497 0.02049466]
 [0.02924579 0.03312127 0.02955879 0.03944891 0.05464642 0.03074122
  0.02569407 0.02492995 0.03165524 0.04023339 0.03418476 0.02848787
  0.02786703 0.03146672 0.03371092 0.0217452  0.04005331 0.03340217
  0.03187689 0.03017907 0.03226291 0.04452141 0.04235955 0.01350793
  0.00766653 0.01826416]]

-* TASK 10/20 | SAMPLE 69/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 342/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred in the given context sentences. The sentences only mention Bill and Julie, but not Fred.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Bill', ' and', ' Julie', ',', ' but', ' not', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0312, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02904242 0.03382997 0.03363248 ... 0.01409285 0.01369201 0.03884513]
 [0.03012254 0.02958238 0.02860602 ... 0.01977519 0.02221755 0.05240498]
 [0.03054271 0.03003141 0.03233867 ... 0.03357559 0.03187934 0.05057054]
 ...
 [0.03066669 0.03088243 0.026058   ... 0.01539165 0.01729869 0.02330445]
 [0.03129384 0.0312224  0.02755473 ... 0.01254627 0.01559391 0.02159753]
 [0.03143933 0.02697588 0.02506952 ... 0.01266921 0.01601175 0.02514803]]

-* TASK 10/20 | SAMPLE 69/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 343/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 7, Bill moved to the school, but then according to sentence 8, Bill went back to the cinema, which implies that Bill is no longer in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' moved', ' to', ' the', ' school', ',', ' but', ' then', ' according', ' to', ' sentence', ' ', '8', ',', ' Bill', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' no', ' longer', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.0222, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02041218 0.03247131 0.03164245 ... 0.01499462 0.0182756  0.02612068]
 [0.02087851 0.03127554 0.03074597 ... 0.01886806 0.02328011 0.02242135]
 [0.02135623 0.03414514 0.03715471 ... 0.01248432 0.01447991 0.02040985]
 ...
 [0.02153931 0.03137017 0.02667027 ... 0.0148234  0.01188182 0.02396227]
 [0.02201703 0.02599597 0.02075132 ... 0.02061184 0.01593136 0.01899816]
 [0.02186944 0.02482355 0.01987342 ... 0.01657969 0.01482356 0.02336247]]

-* TASK 10/20 | SAMPLE 69/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 344/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 11, Fred went to the school, but there is no information about Fred going to the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '11', ',', ' Fred', ' went', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Fred', ' going', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.129, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03011615 0.03887821 0.04505657 ... 0.02672778 0.0294091  0.01550533]
 [0.03071365 0.03125254 0.03419795 ... 0.02475544 0.03688002 0.02462467]
 [0.03140333 0.04162978 0.05100573 ... 0.03917074 0.03556424 0.02035275]
 ...
 [0.03149288 0.04689964 0.04444612 ... 0.01331788 0.01446568 0.01094513]
 [0.0321007  0.04025295 0.03493782 ... 0.01390535 0.01210314 0.0117299 ]
 [0.03215516 0.04062372 0.0354512  ... 0.0121965  0.01268644 0.01134445]]

-* TASK 10/20 | SAMPLE 69/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 345/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 13, Mary travelled to the kitchen, which implies that Mary is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03250748 0.04728829 0.04482863 ... 0.03443212 0.02591242 0.02400264]
 [0.03282588 0.05658941 0.05263788 ... 0.04254341 0.03575869 0.04052311]
 [0.03387803 0.04743955 0.05052579 ... 0.02871745 0.02121944 0.01795442]
 ...
 [0.03401775 0.04748997 0.04120501 ... 0.02681634 0.01635525 0.01798646]
 [0.03415271 0.03766785 0.03019414 ... 0.03424913 0.02588997 0.02692662]
 [0.03419865 0.04194387 0.03175437 ... 0.02911419 0.02123348 0.02339582]]
Model's predictions for the sample 69:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Fred journeyed   |
|          |                 |  to the bedroom, which implies that Fred   |
|          |                 |        is currently in the bedroom.        |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |   There is no information about Fred in    |
|          |                 |      the given context sentences. The      |
|          |                 |   sentences only mention Bill and Julie,   |
|          |                 |               but not Fred.                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 7, Bill moved to   |
|          |                 |     the school, but then according to      |
|          |                 |     sentence 8, Bill went back to the      |
|          |                 |   cinema, which implies that Bill is no    |
|          |                 |           longer in the school.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 11, Fred went to   |
|          |                 |  the school, but there is no information   |
|          |                 |      about Fred going to the cinema.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 13, Mary travelled  |
|          |                 |  to the kitchen, which implies that Mary   |
|          |                 |        is currently in the kitchen.        |
+----------+-----------------+--------------------------------------------+

Metrics for sample 69:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.06 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 70/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 346/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Mary journeying to the cinema and moving to the park, but there is no mention of Mary being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' journey', 'ing', ' to', ' the', ' cinema', ' and', ' moving', ' to', ' the', ' park', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.1667, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02598282 0.04749677 0.05107415 0.08088483 0.07815501 0.05122136
  0.03530411 0.03051972 0.03497983 0.05111762 0.03424912 0.02413134
  0.0257782  0.12891516 0.13054232 0.03743168 0.02577103 0.01865777
  0.01972008 0.02084088 0.02187566 0.04003104 0.0665736  0.00998676
  0.00806379 0.02424795]
 [0.02680083 0.02960879 0.0300586  0.06017449 0.05546441 0.04410749
  0.02472091 0.02199382 0.02799528 0.04415748 0.02941607 0.02596628
  0.02564137 0.13165976 0.15651834 0.0358708  0.02780815 0.02211902
  0.02178607 0.02151402 0.02045012 0.03383243 0.03969208 0.00786886
  0.0068352  0.0159592 ]
 [0.02724295 0.03350317 0.0385473  0.06311627 0.06272716 0.05695374
  0.03360483 0.03150084 0.03688591 0.05249289 0.03424169 0.04198455
  0.04075456 0.1045679  0.09668222 0.02994703 0.0258291  0.02303495
  0.02116593 0.02178532 0.01952328 0.03054319 0.03683713 0.01123985
  0.00931841 0.01520478]
 [0.02634734 0.03986039 0.04691328 0.04904975 0.0512237  0.05411371
  0.04066376 0.04181118 0.04236258 0.04754365 0.03543458 0.04956893
  0.04412745 0.06203268 0.05572875 0.03722636 0.0336487  0.02978892
  0.02624118 0.02795605 0.02645909 0.03408644 0.0522394  0.0287779
  0.02743285 0.02679459]
 [0.02646378 0.05862333 0.06622492 0.04068213 0.03302209 0.04916721
  0.05411061 0.05315513 0.05112446 0.03869829 0.03348037 0.04246793
  0.04623003 0.0287617  0.0210939  0.03707185 0.03073043 0.02811447
  0.02569943 0.02798917 0.02692667 0.03211646 0.06664574 0.03365319
  0.03454695 0.03571567]
 [0.0273996  0.07227849 0.0818432  0.03543318 0.02451529 0.0424206
  0.04924335 0.04197077 0.05056299 0.03150556 0.02515454 0.0322897
  0.03170911 0.01994717 0.01656228 0.04049444 0.02821408 0.02399865
  0.02421657 0.02821322 0.02434203 0.03044938 0.07354519 0.02461901
  0.02341866 0.02650256]
 [0.02731097 0.04317494 0.05401948 0.03055815 0.0214372  0.03825427
  0.04511139 0.04181011 0.04405098 0.02921007 0.02456817 0.03321863
  0.03021821 0.01789383 0.01492821 0.03890241 0.02830032 0.02594892
  0.02612491 0.02942847 0.02673015 0.03102479 0.05176485 0.0340973
  0.03672142 0.03437924]
 [0.02786849 0.03495554 0.03639757 0.02869316 0.02046011 0.03922188
  0.03998613 0.0439041  0.03600986 0.02983703 0.02827196 0.03864617
  0.03382904 0.01601314 0.01280102 0.02818236 0.02520554 0.02576224
  0.02354112 0.02489918 0.02280159 0.02909742 0.02849503 0.02616781
  0.02742274 0.02645801]
 [0.02744998 0.02600714 0.02415624 0.01940547 0.01498869 0.02315598
  0.0306618  0.02976032 0.025095   0.0206623  0.02728584 0.02327436
  0.02710265 0.01088288 0.01012064 0.03470908 0.03022906 0.02857732
  0.02836814 0.0297928  0.03331881 0.02820542 0.02559073 0.05719603
  0.04976427 0.03174598]
 [0.02732467 0.02455477 0.02069164 0.0175017  0.01328012 0.01734653
  0.032483   0.03240163 0.02190404 0.01713166 0.0235969  0.01874803
  0.02605494 0.00899537 0.00888915 0.04081852 0.03392583 0.03578001
  0.03341857 0.03450085 0.04315314 0.02825463 0.02092234 0.06623084
  0.05382195 0.02800315]
 [0.02822002 0.01788798 0.01601984 0.01523485 0.01270881 0.01542368
  0.01797764 0.01669298 0.01782507 0.01474372 0.01586593 0.01521406
  0.01554004 0.00817649 0.00787585 0.02906444 0.01709904 0.02229359
  0.02090811 0.02681776 0.02558645 0.02168921 0.01666017 0.06205893
  0.05409098 0.03489484]
 [0.02796907 0.01825608 0.01538453 0.01380586 0.01203206 0.01383003
  0.01789542 0.01694683 0.01667956 0.01377727 0.01782439 0.01550664
  0.01646521 0.0076333  0.0074173  0.03534855 0.02032721 0.02849054
  0.02521603 0.03625967 0.03266765 0.02255578 0.01589898 0.06984824
  0.0549365  0.03269097]
 [0.0278699  0.01730093 0.01463567 0.01194553 0.01120047 0.01246948
  0.01642296 0.01580505 0.01608623 0.0126577  0.01885822 0.01406022
  0.01605879 0.00673799 0.00685558 0.03122009 0.02232351 0.02605791
  0.02816128 0.03223499 0.03322209 0.02365373 0.0175612  0.06695035
  0.04371213 0.04829172]
 [0.02738658 0.02081116 0.01726209 0.01532329 0.01492862 0.01534091
  0.01911081 0.01826749 0.01896527 0.01569861 0.01946792 0.01650379
  0.01852591 0.00807549 0.00840764 0.02805646 0.02335299 0.02320381
  0.02879797 0.0279765  0.03291992 0.02476457 0.02068    0.06584007
  0.04469115 0.05460223]
 [0.02796424 0.01882067 0.01604405 0.01418599 0.01294908 0.01418777
  0.01669609 0.01694683 0.01686274 0.01474372 0.01888155 0.01466299
  0.01638249 0.00787282 0.00807314 0.02707938 0.02056381 0.02447462
  0.0295357  0.02935102 0.03268397 0.02455713 0.01869381 0.04712042
  0.05058349 0.05536449]
 [0.0282488  0.01729532 0.01622438 0.01412548 0.01216688 0.01552739
  0.01819879 0.01846993 0.01811576 0.01509187 0.01652228 0.01587011
  0.01781927 0.00807549 0.00742606 0.02199529 0.0192063  0.0238382
  0.02405282 0.03072798 0.02833927 0.02362598 0.01528964 0.03246476
  0.07518648 0.04623304]
 [0.02830127 0.01677484 0.01464235 0.01402928 0.01210548 0.01485187
  0.01868646 0.01888444 0.0166424  0.01483328 0.01902576 0.01602041
  0.01856165 0.00766128 0.00745418 0.02481697 0.01997907 0.0310271
  0.02737521 0.03364214 0.03226629 0.02081867 0.01326486 0.02741207
  0.06223973 0.04649661]
 [0.02802661 0.01556467 0.01343015 0.01177951 0.01045564 0.01277965
  0.01707129 0.01677331 0.01589642 0.01296829 0.02211348 0.01458411
  0.01750067 0.00678917 0.00713515 0.02469899 0.02622439 0.02973779
  0.03412451 0.03671801 0.03520239 0.02306941 0.01496694 0.0297269
  0.03916696 0.06530315]
 [0.02738361 0.02259876 0.02277958 0.01946133 0.01803074 0.02797594
  0.03304816 0.03163366 0.02927485 0.02794603 0.0422579  0.03934379
  0.0339914  0.01185871 0.01136089 0.02419079 0.03009538 0.02880504
  0.03070152 0.03082734 0.02834205 0.02841665 0.02377095 0.02440005
  0.02612412 0.03828706]
 [0.02854593 0.0207847  0.01845258 0.01637681 0.01383006 0.01791549
  0.02224948 0.02183316 0.02140761 0.01724434 0.02478342 0.01910884
  0.02102265 0.0093509  0.00860081 0.02034835 0.02187302 0.02213987
  0.02936412 0.02888831 0.02696979 0.02578506 0.01684113 0.01955825
  0.02250537 0.03837946]
 [0.02869389 0.02347612 0.02677766 0.02320371 0.01933486 0.03156475
  0.03144717 0.03488335 0.03102829 0.0277279  0.02827832 0.03590841
  0.03229219 0.01508304 0.01072439 0.01766125 0.02089183 0.02013746
  0.02022526 0.01965632 0.01862538 0.02835571 0.01960876 0.0133897
  0.01475512 0.01648923]
 [0.02879918 0.02277279 0.02270779 0.02224329 0.01849659 0.0266525
  0.02711295 0.03028408 0.02698649 0.02569533 0.02734097 0.0346304
  0.03022536 0.01323033 0.0106269  0.01680497 0.02046204 0.01898169
  0.01971181 0.01906599 0.01942224 0.02727344 0.01755044 0.01202759
  0.01254423 0.01389062]
 [0.02862813 0.0219243  0.02074507 0.01733257 0.01488591 0.0214101
  0.02629544 0.02738356 0.02466361 0.02010323 0.02679808 0.02818227
  0.02736202 0.0107116  0.00961927 0.01926708 0.02448769 0.02323946
  0.02396311 0.02302833 0.02386028 0.0245388  0.0200251  0.01568406
  0.01656348 0.01843778]
 [0.02867188 0.02675939 0.02669501 0.0259112  0.02197913 0.03819243
  0.03255199 0.03470234 0.0385982  0.0337606  0.02715966 0.05116244
  0.0439947  0.01919107 0.01245028 0.0168305  0.02030824 0.02030935
  0.02069472 0.02031631 0.01871224 0.02677979 0.02174111 0.01147617
  0.01108935 0.013262  ]
 [0.0281969  0.03740957 0.03228429 0.02513386 0.02068436 0.03312034
  0.03735308 0.0418733  0.03606295 0.03064024 0.03282826 0.04677308
  0.04388339 0.0158173  0.01206033 0.02375511 0.02504657 0.02444871
  0.02415124 0.02495616 0.02452037 0.02881781 0.02603618 0.01679682
  0.01718649 0.01672764]
 [0.02882462 0.02635199 0.02844818 0.02417499 0.01878625 0.03193961
  0.03409344 0.03441314 0.03362194 0.02912773 0.02800263 0.03985862
  0.03567122 0.01466882 0.01075379 0.01900684 0.02005554 0.01904762
  0.02085019 0.02164358 0.02097315 0.02721168 0.01896146 0.01254179
  0.01255232 0.01167809]
 [0.02798278 0.01938045 0.01810946 0.0146856  0.01217756 0.01629805
  0.02387789 0.02382325 0.02161998 0.01748559 0.02898557 0.02128113
  0.02630614 0.00930586 0.00798442 0.0258791  0.0317855  0.02805023
  0.0278978  0.02775148 0.03330403 0.02510842 0.01560032 0.02712923
  0.02666319 0.02105867]
 [0.02811095 0.02201332 0.01954957 0.01644042 0.01279558 0.01591843
  0.02556772 0.0258112  0.02188147 0.01766328 0.02734416 0.0205931
  0.02567302 0.00933384 0.0079607  0.0289416  0.0327641  0.03099582
  0.02831632 0.02905488 0.03684694 0.02437447 0.01546112 0.02954702
  0.02984602 0.01902185]
 [0.02829835 0.02198926 0.01945606 0.01623251 0.0136819  0.01624287
  0.02270218 0.02439628 0.02153503 0.01857339 0.02750215 0.02268918
  0.02486426 0.00975215 0.00830732 0.02989212 0.03953064 0.032235
  0.03235161 0.02959602 0.03491808 0.02344316 0.01508337 0.02151705
  0.02209121 0.01623061]
 [0.02836842 0.01730254 0.01615676 0.01220619 0.01109368 0.01335812
  0.01898606 0.01829748 0.0190635  0.01432334 0.02763151 0.01720089
  0.0189742  0.0082263  0.00700542 0.02644399 0.03931646 0.02836272
  0.03179418 0.02825121 0.03337487 0.02252209 0.01429623 0.02124662
  0.0198252  0.01904412]
 [0.02772732 0.02040857 0.01896184 0.01514176 0.01452417 0.01631708
  0.02299233 0.02224874 0.02353138 0.01872796 0.03987106 0.02266999
  0.02181303 0.0100756  0.00917748 0.02622539 0.04143379 0.02959181
  0.03183947 0.02852836 0.03023733 0.02538935 0.01923987 0.02267075
  0.01787424 0.0248147 ]
 [0.02857874 0.02148883 0.02072336 0.01757152 0.01426788 0.01976507
  0.02517645 0.02496182 0.02493572 0.02012201 0.03134483 0.02265774
  0.02574757 0.01227906 0.00966183 0.01994179 0.03054989 0.02827223
  0.02795573 0.02660052 0.02516969 0.02570513 0.01786745 0.01439949
  0.01506865 0.01804015]
 [0.02743334 0.02997529 0.02962615 0.05261059 0.05549778 0.04062334
  0.02462451 0.02507214 0.03104554 0.05187171 0.03150707 0.03199498
  0.03354005 0.08436687 0.09885429 0.02476028 0.02660933 0.02507773
  0.02310344 0.02248427 0.02115119 0.03223405 0.0347883  0.00800423
  0.00815835 0.01778276]
 [0.02726806 0.03220879 0.02965119 0.05595267 0.11073795 0.03889649
  0.02163422 0.02306813 0.02851427 0.05389128 0.03454601 0.02849831
  0.02520533 0.08546621 0.10617925 0.03031222 0.03550901 0.03655332
  0.02983968 0.0261568  0.02477942 0.02948323 0.0357602  0.00707058
  0.0061816  0.01543741]
 [0.02699736 0.02724137 0.02599207 0.04393422 0.07190672 0.02977129
  0.01890667 0.02372578 0.02773379 0.05249867 0.03707599 0.03662576
  0.03228402 0.0354724  0.03815342 0.02588191 0.04761501 0.07113586
  0.06754352 0.03958394 0.03291653 0.02564501 0.02878546 0.01218576
  0.01086381 0.01723664]
 [0.0273126  0.03313907 0.02931392 0.04545786 0.06346799 0.03366456
  0.02343085 0.02397427 0.03045089 0.04572633 0.03248364 0.02810286
  0.02884986 0.03511823 0.03600741 0.02092193 0.03292739 0.04171021
  0.04124268 0.03296218 0.02740781 0.04654048 0.04326076 0.00909559
  0.00815355 0.01529304]]

-* TASK 10/20 | SAMPLE 70/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 347/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Mary being in the bedroom. In fact, sentence 5 states that Mary travelled to the school, which implies that Mary is not in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Mary', ' being', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '5', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 32), x_tokens=32, y_tokens=43, max_supp_attn=0.0698, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 32)
DEBUG result.interpretability.attn_scores 1376 
 [[0.0215147  0.03413242 0.03552509 ... 0.00945018 0.00757361 0.01343986]
 [0.02207451 0.0369329  0.03465013 ... 0.01256472 0.00996103 0.01787563]
 [0.02255038 0.0323878  0.03499327 ... 0.01543626 0.00970024 0.02175451]
 ...
 [0.02267984 0.02988867 0.02631415 ... 0.00511136 0.00573239 0.0070194 ]
 [0.02307418 0.02202538 0.01857945 ... 0.00606388 0.00787302 0.00955291]
 [0.02293023 0.02402491 0.0189848  ... 0.00505191 0.00705202 0.00823462]]

-* TASK 10/20 | SAMPLE 70/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 348/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Fred travelled to the bedroom, which implies that Fred is indeed in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' indeed', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 38), x_tokens=38, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 38)
DEBUG result.interpretability.attn_scores 1102 
 [[0.03229024 0.0483952  0.04807266 ... 0.0341251  0.02101267 0.0403739 ]
 [0.03270738 0.04433502 0.04106416 ... 0.03709967 0.03989046 0.03780027]
 [0.03357982 0.05067929 0.05305173 ... 0.03130292 0.01776287 0.03198971]
 ...
 [0.03386644 0.04709236 0.04053589 ... 0.02836676 0.01643021 0.03419284]
 [0.03391756 0.04077732 0.03278224 ... 0.03359858 0.02442029 0.03251383]
 [0.03405972 0.04580048 0.03515093 ... 0.03214908 0.02127569 0.03436634]]

-* TASK 10/20 | SAMPLE 70/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 349/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary in the context sentences. The sentences only talk about Fred and Bill, but not Mary.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Fred', ' and', ' Bill', ',', ' but', ' not', ' Mary', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 44), x_tokens=44, y_tokens=32, max_supp_attn=0.0625, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 44)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02902205 0.03302913 0.03680432 ... 0.01556643 0.02026641 0.01003642]
 [0.029679   0.02719142 0.03377943 ... 0.03297431 0.02581153 0.02751453]
 [0.03035817 0.03062743 0.03579751 ... 0.02521494 0.03215938 0.02022303]
 ...
 [0.03074465 0.03721804 0.0312111  ... 0.01326844 0.01454536 0.01173068]
 [0.03130262 0.03974903 0.03451855 ... 0.01392465 0.01421754 0.01018286]
 [0.03147244 0.03418055 0.03110551 ... 0.01308404 0.01636233 0.01099545]]

-* TASK 10/20 | SAMPLE 70/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 350/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill being in the cinema in the context sentences. The sentences only talk about Julie's movements, but not Bill's.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', "'s", ' movements', ',', ' but', ' not', ' Bill', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 50), x_tokens=50, y_tokens=37, max_supp_attn=0.0, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 50)
DEBUG result.interpretability.attn_scores 1850 
 [[0.02515791 0.03398183 0.02999933 ... 0.0423319  0.0351065  0.01771952]
 [0.02556788 0.0333748  0.03209871 ... 0.0241978  0.03704138 0.02499184]
 [0.02626199 0.03520465 0.03536794 ... 0.03891632 0.03013959 0.0140777 ]
 ...
 [0.02690442 0.02721171 0.02211293 ... 0.03691503 0.02824698 0.02902627]
 [0.02714845 0.03094665 0.02476682 ... 0.04236419 0.02649463 0.0150439 ]
 [0.02691277 0.02945267 0.0226689  ... 0.06801902 0.02555121 0.01156204]]
Model's predictions for the sample 70:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Mary   |
|          |                 |   journeying to the cinema and moving to   |
|          |                 |    the park, but there is no mention of    |
|          |                 |         Mary being in the kitchen.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |    Mary being in the bedroom. In fact,     |
|          |                 |  sentence 5 states that Mary travelled to  |
|          |                 |   the school, which implies that Mary is   |
|          |                 |            not in the bedroom.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Fred   |
|          |                 |  travelled to the bedroom, which implies   |
|          |                 |    that Fred is indeed in the bedroom.     |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |     There is no mention of Mary in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |  talk about Fred and Bill, but not Mary.   |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |  There is no mention of Bill being in the  |
|          |                 |    cinema in the context sentences. The    |
|          |                 |     sentences only talk about Julie's      |
|          |                 |         movements, but not Bill's.         |
+----------+-----------------+--------------------------------------------+

Metrics for sample 70:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.08 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 71/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 351/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: From sentence 1, we know that Bill is either in the bedroom or the office. There is no information that suggests Bill has moved or changed locations. Sentence 2 mentions Fred going back to the office, but it does not provide any information about Bill's current location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' that', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' has', ' moved', ' or', ' changed', ' locations', '.', ' Sentence', ' ', '2', ' mentions', ' Fred', ' going', ' back', ' to', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' any', ' information', ' about', ' Bill', "'s", ' current', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(66, 26), x_tokens=26, y_tokens=66, max_supp_attn=0.0303, attn_on_target=0.0152)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (66, 26)
DEBUG result.interpretability.attn_scores 1716 
 [[0.01376077 0.02701144 0.0294397  ... 0.00695552 0.0078158  0.0134595 ]
 [0.01361506 0.04669816 0.03267077 ... 0.02136655 0.01795176 0.02012339]
 [0.01496399 0.03866981 0.02213791 ... 0.00233725 0.00305979 0.00721421]
 ...
 [0.01476689 0.01703849 0.016995   ... 0.00285803 0.00348102 0.00902692]
 [0.01479346 0.01306759 0.01271512 ... 0.01079007 0.00750096 0.01061145]
 [0.01495454 0.01426528 0.01338992 ... 0.00700049 0.00567822 0.0087622 ]]

-* TASK 10/20 | SAMPLE 71/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 352/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 4 states that Bill went back to the kitchen, which means Bill is currently in the kitchen. Sentence 5 provides alternative locations for Bill, but it does not update Bill's current location. Since Bill is in the kitchen, the alternatives in sentence 5 do not apply.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.', ' Sentence', ' ', '5', ' provides', ' alternative', ' locations', ' for', ' Bill', ',', ' but', ' it', ' does', ' not', ' update', ' Bill', "'s", ' current', ' location', '.', ' Since', ' Bill', ' is', ' in', ' the', ' kitchen', ',', ' the', ' alternatives', ' in', ' sentence', ' ', '5', ' do', ' not', ' apply', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(64, 32), x_tokens=32, y_tokens=64, max_supp_attn=0.1406, attn_on_target=0.0156)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (64, 32)
DEBUG result.interpretability.attn_scores 2048 
 [[0.01419314 0.0235134  0.024648   ... 0.02906597 0.00619036 0.00885774]
 [0.01465562 0.02311696 0.02334737 ... 0.03934255 0.00728469 0.01282636]
 [0.01493457 0.02179777 0.02372758 ... 0.04994128 0.00716013 0.01735048]
 ...
 [0.01503794 0.02114681 0.02200559 ... 0.01141554 0.00850803 0.0055087 ]
 [0.01535598 0.01461995 0.01462696 ... 0.00677128 0.01071944 0.00613351]
 [0.01528563 0.01496908 0.01567311 ... 0.00655702 0.00916048 0.00667578]]

-* TASK 10/20 | SAMPLE 71/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 353/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Fred went to the bedroom, which means Fred is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' went', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Fred', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.0334236  0.05059356 0.05237352 ... 0.0204407  0.05380566 0.06877925]
 [0.03363642 0.04950805 0.05150404 ... 0.03680713 0.03506036 0.03557158]
 [0.03486615 0.05365802 0.06199981 ... 0.02966684 0.05659687 0.05245224]
 ...
 [0.03514048 0.05563463 0.04839992 ... 0.0210917  0.08106551 0.10637964]
 [0.03513771 0.04589967 0.03669389 ... 0.01831205 0.04527053 0.09832267]
 [0.03531968 0.05118145 0.03959149 ... 0.017075   0.02784247 0.16180588]]

-* TASK 10/20 | SAMPLE 71/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 354/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 states that Bill moved to the park, but sentence 11 updates Bill's location to the bedroom. There is no information about Bill being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' park', ',', ' but', ' sentence', ' ', '11', ' updates', ' Bill', "'s", ' location', ' to', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.0244, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02256142 0.03773303 0.03657785 ... 0.01126505 0.0242621  0.02833615]
 [0.02327105 0.02570292 0.02400371 ... 0.01760832 0.02235596 0.02367067]
 [0.02354872 0.03721341 0.03784732 ... 0.01032118 0.01904251 0.02483119]
 ...
 [0.02373022 0.03125756 0.03369512 ... 0.01197651 0.02505404 0.03494623]
 [0.02428681 0.02485608 0.02568457 ... 0.01818006 0.02519117 0.0376164 ]
 [0.02421207 0.02636889 0.02735221 ... 0.01294746 0.02229083 0.02803968]]

-* TASK 10/20 | SAMPLE 71/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 355/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's location in the context sentences. The sentences only provide information about Fred's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' provide', ' information', ' about', ' Fred', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03007904 0.03333158 0.03205014 ... 0.01771804 0.02206733 0.01172903]
 [0.03077519 0.02379166 0.02301547 ... 0.03038017 0.03538316 0.02269439]
 [0.03141772 0.0316891  0.03432157 ... 0.02486974 0.02815947 0.01701223]
 ...
 [0.03208766 0.03380408 0.02772127 ... 0.02123791 0.01833547 0.01482839]
 [0.03246432 0.03693905 0.03240896 ... 0.0196168  0.0167429  0.01458276]
 [0.03260165 0.03143785 0.02862819 ... 0.02008925 0.01754109 0.01213841]]
Model's predictions for the sample 71:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   From sentence 1, we know that Bill is    |
|          |                 |    either in the bedroom or the office.    |
|          |                 |   There is no information that suggests    |
|          |                 |    Bill has moved or changed locations.    |
|          |                 |   Sentence 2 mentions Fred going back to   |
|          |                 |  the office, but it does not provide any   |
|          |                 |      information about Bill's current      |
|          |                 |                 location.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |        no       |  Sentence 4 states that Bill went back to  |
|          |                 |      the kitchen, which means Bill is      |
|          |                 |    currently in the kitchen. Sentence 5    |
|          |                 |  provides alternative locations for Bill,  |
|          |                 |   but it does not update Bill's current    |
|          |                 |  location. Since Bill is in the kitchen,   |
|          |                 |   the alternatives in sentence 5 do not    |
|          |                 |                   apply.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 8 explicitly states that Fred   |
|          |                 |  went to the bedroom, which means Fred is  |
|          |                 |         currently in the bedroom.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   Sentence 10 states that Bill moved to    |
|          |                 |  the park, but sentence 11 updates Bill's  |
|          |                 |    location to the bedroom. There is no    |
|          |                 |    information about Bill being in the     |
|          |                 |                  kitchen.                  |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Bill's    |
|          |                 |   location in the context sentences. The   |
|          |                 |  sentences only provide information about  |
|          |                 |             Fred's locations.              |
+----------+-----------------+--------------------------------------------+

Metrics for sample 71:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.07 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 72/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 356/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 1 explicitly states that Julie is in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.0373102  0.05827586 0.07151993 0.08800513 0.09307948 0.0900999
  0.07852791 0.0922046  0.07123909 0.0788065  0.06202024 0.07540624
  0.08854698 0.09723938 0.05870711 0.0402735  0.03838108 0.04332097
  0.03883961 0.04206569 0.03544033 0.04999756 0.04392146 0.02374483
  0.02946537 0.04218338]
 [0.03788204 0.07139346 0.06090093 0.0774186  0.06467278 0.06706651
  0.06386299 0.06364437 0.05647781 0.05766042 0.04941813 0.04271964
  0.05143884 0.11071786 0.10529074 0.04309791 0.03568102 0.034505
  0.03356322 0.03504281 0.02945412 0.05038567 0.04810928 0.01770571
  0.01960218 0.03829186]
 [0.04086627 0.06770182 0.04104866 0.06010315 0.04300603 0.04159399
  0.03952467 0.02901864 0.02792465 0.04015986 0.03556122 0.02028032
  0.0249172  0.03004882 0.03697651 0.02911947 0.01741998 0.01842615
  0.0228353  0.02349897 0.02133625 0.0560273  0.05423791 0.00942673
  0.00984447 0.02033719]
 [0.03837294 0.04120262 0.04936295 0.02967315 0.02007047 0.03507635
  0.03899828 0.03474808 0.04362871 0.03212148 0.03296596 0.03375926
  0.03321319 0.01466623 0.01376706 0.04469783 0.03940381 0.042422
  0.04469863 0.04719062 0.04639328 0.04249464 0.06749645 0.07365459
  0.08734046 0.06461192]
 [0.03886213 0.04864722 0.05115298 0.07498888 0.06508616 0.05490661
  0.04294195 0.03774472 0.04204144 0.05326588 0.04350178 0.03118016
  0.03397926 0.10087688 0.10110002 0.04540394 0.03325224 0.02833273
  0.02906761 0.03137714 0.02938679 0.04948169 0.06362841 0.01648046
  0.01505805 0.04404345]
 [0.03958622 0.03144064 0.0314789  0.05778735 0.04903999 0.05013977
  0.03221327 0.02965983 0.03587699 0.04979917 0.03846905 0.03562958
  0.03696816 0.11254171 0.13162063 0.04550217 0.03810299 0.03476937
  0.03321295 0.03403214 0.02864054 0.04234251 0.03829347 0.01180529
  0.01210463 0.02858885]
 [0.04016458 0.03505583 0.04057198 0.06040433 0.05315768 0.06301247
  0.04171946 0.04017829 0.04691688 0.0584904  0.04493541 0.0561097
  0.05558145 0.09053697 0.08333406 0.03831531 0.0346839  0.0340756
  0.03171628 0.0332195  0.02684026 0.0380259  0.03615943 0.01592495
  0.01656922 0.0272573 ]
 [0.03883756 0.05092549 0.06036546 0.05086491 0.04914209 0.06109682
  0.04955355 0.05527795 0.05391758 0.0547116  0.0478177  0.06451248
  0.05845497 0.05655057 0.04918497 0.05171716 0.04543894 0.04358643
  0.03882008 0.04104436 0.03646988 0.04344318 0.05293539 0.03854057
  0.03860466 0.04591262]
 [0.03920595 0.06053368 0.06997863 0.0398118  0.0308833  0.05009522
  0.05857792 0.06207014 0.06049215 0.04344438 0.04240777 0.05423557
  0.05626445 0.02654548 0.01884013 0.05096732 0.04145527 0.04085153
  0.03879426 0.04055464 0.03816655 0.0392091  0.06281231 0.04601075
  0.05279251 0.05636482]
 [0.04019061 0.07852605 0.08522332 0.03447017 0.02378349 0.04431042
  0.05803542 0.0539543  0.06319088 0.03531658 0.034081   0.04359631
  0.04325514 0.01736097 0.01427337 0.05791903 0.04149288 0.03837447
  0.03913267 0.04355466 0.03710597 0.03808209 0.07063979 0.03537064
  0.03940171 0.04506941]
 [0.04021379 0.04595205 0.05234242 0.02722003 0.02056978 0.03223184
  0.04758171 0.04519726 0.04864265 0.03003976 0.03065472 0.03654879
  0.03463303 0.01515798 0.01364481 0.05484265 0.04333227 0.03780827
  0.04124965 0.04352191 0.039816   0.03780989 0.05789855 0.05540485
  0.05899879 0.04742616]
 [0.04044563 0.02598631 0.02952786 0.01809259 0.01518951 0.02280397
  0.03003955 0.03126354 0.0418266  0.02280775 0.02207549 0.02391689
  0.02420344 0.01042976 0.01043897 0.03798329 0.03638084 0.03278795
  0.03974041 0.04521194 0.04269785 0.03345178 0.05414284 0.07986984
  0.09115984 0.05378361]
 [0.04036684 0.03431448 0.03629182 0.02349352 0.01892992 0.03148785
  0.03690629 0.03636211 0.03595156 0.02730182 0.03066073 0.03707676
  0.03354085 0.01228475 0.01207213 0.0494034  0.03707986 0.03576279
  0.03534807 0.03743658 0.03752565 0.03671252 0.03765085 0.06231432
  0.0709571  0.05244145]
 [0.04105921 0.04439202 0.0474689  0.03981804 0.02848142 0.05180594
  0.05148699 0.05769088 0.04814196 0.05130563 0.05145286 0.08019144
  0.06410664 0.02143152 0.01496824 0.0374003  0.03733595 0.04181455
  0.03802534 0.03877093 0.03411001 0.04011571 0.02606768 0.02738721
  0.02820897 0.02718602]
 [0.04153594 0.03246022 0.03311155 0.0257469  0.02106161 0.03058906
  0.0386589  0.03770639 0.03196207 0.03069936 0.0384976  0.03985566
  0.03886487 0.01308796 0.01176327 0.03787665 0.03379562 0.03344046
  0.03315922 0.03480062 0.03454719 0.03740839 0.0238145  0.04357805
  0.03794371 0.02596973]
 [0.04079614 0.02478451 0.02171377 0.01670841 0.01414857 0.0190395
  0.02734809 0.02632711 0.02408607 0.02003101 0.0317322  0.02629848
  0.02930902 0.00803091 0.00879932 0.03897802 0.03818782 0.03783922
  0.03594604 0.03760032 0.04666345 0.03386009 0.0219916  0.07601164
  0.06474572 0.03464451]
 [0.04039162 0.02346004 0.01928424 0.01580487 0.01253362 0.01765178
  0.02996399 0.03133724 0.02309003 0.0187506  0.03047138 0.0232499
  0.03076885 0.00719475 0.00753311 0.03714195 0.04185539 0.05197247
  0.04388715 0.04486921 0.06624357 0.03140894 0.0200977  0.08325487
  0.06565081 0.04470694]
 [0.04116694 0.02268224 0.01940725 0.01543503 0.01330063 0.01870761
  0.02683407 0.0274621  0.02323562 0.01959577 0.03733898 0.02936225
  0.03027198 0.00744213 0.00734497 0.0348329  0.04115557 0.04098344
  0.0428168  0.039988   0.05197467 0.02995859 0.01697967 0.07212079
  0.04956688 0.02894903]
 [0.04095991 0.02055864 0.01747612 0.01271974 0.01168941 0.01599229
  0.02702853 0.02587754 0.02257514 0.01698435 0.05185109 0.0286831
  0.02859833 0.00635441 0.00674156 0.03647587 0.04485275 0.04498591
  0.05233342 0.04648231 0.05700129 0.02950726 0.01697597 0.07162536
  0.04618642 0.03896673]
 [0.03969275 0.02695966 0.02380229 0.01946272 0.02153476 0.0240625
  0.03356705 0.03192979 0.03615219 0.02532638 0.03435601 0.02700118
  0.03148416 0.01448175 0.01983802 0.03273511 0.04403249 0.04821971
  0.07567738 0.07415266 0.06292062 0.03874372 0.03857064 0.0529944
  0.06078343 0.07883734]
 [0.04164347 0.02465117 0.02451957 0.02149138 0.01584695 0.02374843
  0.027005   0.03118247 0.0300055  0.02513407 0.03090268 0.03176967
  0.03127033 0.01121739 0.00964786 0.02497906 0.02680298 0.03119466
  0.039402   0.03677168 0.03734554 0.03250983 0.01737228 0.02873929
  0.03704373 0.0358517 ]
 [0.04052572 0.03101397 0.02932977 0.04743647 0.04464588 0.04510564
  0.03135245 0.03127828 0.03530529 0.05154686 0.0404572  0.04002051
  0.0400555  0.07316882 0.08395004 0.03086136 0.03426336 0.0349116
  0.03268894 0.03174805 0.02912274 0.03891056 0.03174136 0.01242051
  0.01599163 0.03070522]
 [0.04020005 0.03255533 0.02852204 0.05193074 0.09305832 0.04261419
  0.02962462 0.02926185 0.03359551 0.05730616 0.0459092  0.03827174
  0.03363315 0.073412   0.09412849 0.0375833  0.04751841 0.04837551
  0.03842166 0.03514944 0.03524273 0.03629565 0.03070428 0.0104076
  0.01121103 0.02606755]
 [0.03961056 0.03074996 0.02652668 0.04605853 0.10661668 0.03119828
  0.02588779 0.02809886 0.029535   0.0523313  0.04726919 0.04250845
  0.03277016 0.03568207 0.04770461 0.03321851 0.07806178 0.07126991
  0.05627571 0.0422104  0.05400621 0.03404207 0.02899002 0.01918796
  0.02155695 0.03152037]
 [0.04011294 0.03577673 0.02907199 0.04505357 0.07047141 0.03556306
  0.0327595  0.03052359 0.03418852 0.04706291 0.04519238 0.03781593
  0.03387004 0.03353898 0.03833006 0.02867408 0.05003281 0.04996933
  0.04434766 0.03970544 0.04154852 0.05977536 0.03876818 0.01601877
  0.01921174 0.03028286]]

-* TASK 10/20 | SAMPLE 72/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 357/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 5 explicitly states that Bill travelled to the office, which implies that Bill is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' explicitly', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Bill', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.1333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03127972 0.04696045 0.04684323 0.0641015  0.05460944 0.04798942
  0.03840679 0.0396681  0.05070228 0.05196018 0.0329324  0.02927107
  0.03597414 0.1009941  0.10203181 0.02607877 0.026121   0.02233484
  0.02021792 0.02240453 0.02026234 0.03278268 0.05771109 0.02282462
  0.01723644 0.04208054 0.04651163 0.04397042 0.11244635 0.05492401
  0.01010353 0.06668465]
 [0.03189616 0.04946072 0.04627063 0.07998417 0.08006449 0.08535375
  0.04839167 0.04945127 0.05595097 0.07287182 0.05102025 0.05398862
  0.05895598 0.14831081 0.11799739 0.03009842 0.02796474 0.0278413
  0.02300151 0.02545007 0.02258085 0.03775379 0.04765167 0.02216318
  0.01657082 0.03854851 0.04922184 0.03920573 0.09252182 0.06450943
  0.01743292 0.07352316]
 [0.03258476 0.04293046 0.04683124 0.0641822  0.0572147  0.05940115
  0.04120686 0.04390877 0.05080107 0.05679322 0.0367474  0.04375446
  0.04655246 0.10808446 0.07804323 0.02506078 0.0260324  0.02240806
  0.02032179 0.02151783 0.01911828 0.03294585 0.04177551 0.02335595
  0.01771696 0.0329555  0.04552609 0.03251239 0.06239571 0.06585009
  0.02716336 0.05998909]
 [0.03140763 0.04255864 0.04588713 0.03751688 0.0309486  0.03743951
  0.03837154 0.04497353 0.04315821 0.0356019  0.03063276 0.03672744
  0.03945861 0.03120865 0.02790043 0.02973495 0.03046538 0.02613083
  0.02584126 0.02734401 0.02530867 0.03700412 0.05145095 0.04288819
  0.04118742 0.04548525 0.05497077 0.03859011 0.04562376 0.09213512
  0.0516366  0.03842682]
 [0.03206364 0.04475589 0.04522266 0.0255414  0.02006412 0.02913006
  0.03510572 0.03813329 0.03825845 0.02371247 0.02718493 0.02682674
  0.02994187 0.02084342 0.01905829 0.02838031 0.02729485 0.021955
  0.02485935 0.02624952 0.02442193 0.03461937 0.05111311 0.03991523
  0.03705676 0.04222802 0.05688709 0.02859452 0.03025871 0.08644006
  0.0477003  0.02045269]
 [0.03262808 0.05915875 0.05672108 0.02802349 0.02191131 0.03189674
  0.04279895 0.04087184 0.0508326  0.02606259 0.02754888 0.02896595
  0.03222025 0.01966419 0.01866067 0.03611962 0.03549036 0.0284944
  0.02900175 0.03210346 0.02784467 0.03190494 0.06667947 0.04327305
  0.03785297 0.04121707 0.04700439 0.02907363 0.02895609 0.07609613
  0.03855387 0.01816896]
 [0.03273511 0.03969973 0.04204811 0.02425212 0.01933915 0.02505588
  0.03468079 0.03170996 0.03889116 0.02151325 0.02424597 0.02164213
  0.02238058 0.01814722 0.01873179 0.03031302 0.02955451 0.02127153
  0.02451052 0.0247101  0.02278419 0.03065547 0.04711629 0.04123343
  0.03546307 0.03555221 0.04607362 0.0257804  0.02775293 0.07246818
  0.03637687 0.02142451]
 [0.03312502 0.02392817 0.02622864 0.01767191 0.01423457 0.01794653
  0.02143751 0.02175104 0.0274689  0.0161953  0.01986089 0.01587812
  0.01704414 0.01170584 0.01423234 0.02290454 0.02396348 0.0182745
  0.02338052 0.0243183  0.0233502  0.02530354 0.03294282 0.04412848
  0.04264672 0.03420218 0.03071574 0.02512227 0.02163825 0.03934992
  0.02020983 0.01768593]
 [0.03273407 0.02971918 0.03165093 0.02501584 0.01916867 0.02587474
  0.02707662 0.02677239 0.02770643 0.02165812 0.02632015 0.02575881
  0.02374368 0.01731265 0.01666945 0.03109182 0.03138584 0.0295726
  0.03174675 0.03695173 0.0320247  0.03575632 0.03228838 0.0433494
  0.04506705 0.03454378 0.03873688 0.02779343 0.02635506 0.06094559
  0.08848511 0.01823755]
 [0.03349439 0.03680423 0.03947545 0.03906007 0.02900045 0.04194594
  0.03824165 0.04554985 0.04422182 0.04175688 0.03619504 0.05392109
  0.04862031 0.03167895 0.02366156 0.02533931 0.02820854 0.02736442
  0.02742607 0.02811729 0.02356087 0.03447794 0.02784665 0.02587782
  0.02774059 0.02868732 0.04062581 0.03012844 0.0306029  0.05396049
  0.10534646 0.03216703]
 [0.03362873 0.03000902 0.03192525 0.0299702  0.02351518 0.02990597
  0.03089912 0.03059819 0.0306219  0.02854953 0.03015609 0.03257658
  0.03088748 0.02147857 0.01953014 0.03065905 0.03052464 0.02928504
  0.032257   0.03203446 0.02777759 0.03375024 0.02628208 0.03132746
  0.03688687 0.02632255 0.03534227 0.02818754 0.02634723 0.03178097
  0.07661259 0.02840597]
 [0.03316858 0.02442441 0.02184632 0.01919344 0.01570934 0.01896004
  0.02269189 0.02078028 0.02226646 0.01788747 0.02586602 0.02007233
  0.02187744 0.01140267 0.01329227 0.03839703 0.03194398 0.03465516
  0.0372241  0.04130907 0.03739437 0.032862   0.02152005 0.03834305
  0.04820371 0.02602507 0.0213395  0.02412027 0.0185773  0.0159428
  0.04456482 0.01579358]
 [0.03277265 0.02599659 0.02126974 0.02011267 0.01549747 0.01912113
  0.02378482 0.02136886 0.02212562 0.01831604 0.02535875 0.01930285
  0.02203623 0.0113531  0.01350873 0.05499692 0.03301737 0.04823706
  0.0438862  0.05521544 0.0625542  0.03256121 0.02150897 0.04714818
  0.06596884 0.03935147 0.01893042 0.02865698 0.01662186 0.01248821
  0.03377665 0.01236856]
 [0.03391818 0.02570089 0.02380378 0.02264004 0.01805804 0.02307584
  0.02572576 0.02443441 0.02460388 0.02208469 0.03264092 0.02574714
  0.02578655 0.01359514 0.01538004 0.04595706 0.0351224  0.05657384
  0.04349947 0.06990699 0.04405119 0.02980832 0.02074745 0.03458167
  0.03881907 0.02780495 0.01977908 0.02475006 0.01737896 0.0125768
  0.02732864 0.01298532]
 [0.03399802 0.02181729 0.02080368 0.01841004 0.01441167 0.01968225
  0.02330423 0.02083137 0.02162115 0.01798204 0.03330117 0.0222899
  0.02234133 0.0107341  0.0129777  0.04607107 0.03780533 0.04555556
  0.0469351  0.05334767 0.04336413 0.03125082 0.01874351 0.03486915
  0.0399183  0.03090587 0.01858823 0.02298367 0.0157011  0.01010304
  0.02412954 0.01205615]
 [0.03295847 0.03238778 0.03047113 0.03081265 0.02689837 0.03283508
  0.03629329 0.03547649 0.03410491 0.03443087 0.03944318 0.03949939
  0.03651296 0.01988321 0.02107079 0.03531936 0.04279533 0.04266272
  0.04801597 0.04119328 0.04415967 0.03663525 0.03176778 0.03829008
  0.04365212 0.04683907 0.02931957 0.04266253 0.03113999 0.01720752
  0.02606587 0.02672919]
 [0.03414676 0.02543154 0.02635115 0.02529929 0.01896012 0.0267379
  0.02769268 0.02900206 0.02706952 0.02587949 0.03112554 0.03208555
  0.02781515 0.01704637 0.01676237 0.03134844 0.03149983 0.0300727
  0.036584   0.03106131 0.03472473 0.03414873 0.02231941 0.02737832
  0.02954221 0.02936549 0.02446035 0.03046459 0.02528632 0.01985931
  0.03006579 0.03155546]
 [0.03429453 0.03266152 0.03726898 0.03629256 0.02731051 0.03942223
  0.03763673 0.04413971 0.0363057  0.04053755 0.04127098 0.05192111
  0.04585485 0.02744618 0.02050758 0.02959591 0.03066064 0.03202726
  0.03035916 0.02998031 0.02755014 0.0371207  0.02694298 0.02730197
  0.02742489 0.0297613  0.02967546 0.03195858 0.02788132 0.02517132
  0.0338624  0.02351053]
 [0.034567   0.03851109 0.04069787 0.04147131 0.02979991 0.04363468
  0.0454246  0.05503668 0.03513699 0.04628609 0.04784779 0.05849295
  0.05483099 0.02873146 0.02093012 0.03277282 0.03163302 0.03477424
  0.03039636 0.0307401  0.02699671 0.03616198 0.02926631 0.02693503
  0.02362641 0.02702845 0.03107163 0.02667293 0.02635928 0.02303505
  0.03499239 0.01704266]
 [0.03452556 0.03380626 0.0345818  0.03530838 0.02717479 0.0374677
  0.03886883 0.04252519 0.03275542 0.03969449 0.04009217 0.04567691
  0.04695925 0.02534939 0.0212831  0.03704105 0.03259919 0.03539638
  0.03217489 0.03155304 0.03008038 0.03591304 0.02640023 0.02990409
  0.02905028 0.02562926 0.02628085 0.03012457 0.02475406 0.01980869
  0.03666041 0.01916845]
 [0.03454902 0.02582825 0.02522993 0.02117558 0.01702355 0.02401015
  0.02985628 0.02886718 0.02463541 0.02425372 0.02866326 0.02773378
  0.03149945 0.01342223 0.01493778 0.04042719 0.03253937 0.03312629
  0.0333491  0.03099152 0.03508425 0.03381188 0.02162712 0.03494161
  0.0375322  0.0248805  0.02291362 0.03055732 0.01919335 0.01341799
  0.0303597  0.01425371]
 [0.03443083 0.02775029 0.02565471 0.02124447 0.01707321 0.02373093
  0.03232606 0.02923504 0.02374416 0.02332212 0.02943786 0.02603892
  0.03103556 0.01301763 0.01545271 0.04975183 0.0357556  0.04005148
  0.04069974 0.03690097 0.04440913 0.03137505 0.02091083 0.03994016
  0.0400248  0.02624062 0.0240634  0.0305058  0.01735967 0.01097966
  0.02909486 0.01208007]
 [0.0346175  0.02574334 0.02424987 0.01993945 0.01797032 0.02363696
  0.02917714 0.02798021 0.02342045 0.02343279 0.03056996 0.02788301
  0.02967425 0.01355364 0.01522276 0.03961307 0.03877827 0.03493736
  0.04185149 0.03359688 0.04139098 0.03086643 0.02061269 0.03984667
  0.04163371 0.02755032 0.02877205 0.03481005 0.01736811 0.01235322
  0.03059414 0.01519642]
 [0.0347655  0.02261655 0.02222716 0.0152213  0.01569113 0.0209629
  0.02989154 0.02329811 0.02253762 0.01868225 0.03691649 0.02366796
  0.02688738 0.01111795 0.01260344 0.04042093 0.03968519 0.03225647
  0.04461474 0.03522196 0.03866054 0.03041012 0.01898996 0.03554227
  0.03675881 0.03018862 0.02362539 0.02701616 0.0142514  0.00937449
  0.02195669 0.01218008]
 [0.03323274 0.02682513 0.02717275 0.01656175 0.01712286 0.0241068
  0.03520963 0.0273201  0.02857876 0.02154142 0.02629116 0.02300269
  0.02889992 0.0119894  0.01427594 0.02795514 0.02959007 0.02538723
  0.03414221 0.03009134 0.03179987 0.0342818  0.029198   0.04216677
  0.03859086 0.04937653 0.02803291 0.03533294 0.02013309 0.01325641
  0.01875966 0.01620629]
 [0.0345939  0.02825532 0.02996379 0.02533472 0.02315931 0.03109667
  0.03470677 0.0350003  0.03056935 0.02981111 0.03569904 0.03689167
  0.03390094 0.01918005 0.01837414 0.02997235 0.03273915 0.02992922
  0.03512412 0.0288763  0.03481907 0.03363437 0.02399937 0.02645278
  0.02329677 0.02805327 0.02216078 0.03232177 0.02322298 0.01645746
  0.02018079 0.03212034]
 [0.0330697  0.03369207 0.03394129 0.05131702 0.05601303 0.04504688
  0.03331879 0.03115816 0.03551325 0.05030423 0.03636574 0.03736353
  0.03552096 0.06943157 0.0943867  0.02278249 0.02757703 0.02724832
  0.02442068 0.02370602 0.02396546 0.03284551 0.03927127 0.02067203
  0.01727828 0.03316223 0.03307007 0.04609098 0.05403747 0.02445754
  0.01010941 0.0930386 ]
 [0.03272333 0.03811438 0.03672302 0.06455029 0.15276341 0.05161524
  0.03564198 0.03345118 0.03624264 0.06738084 0.04844363 0.04869814
  0.03417748 0.0908744  0.12033847 0.03162429 0.04696701 0.04572584
  0.03289149 0.02891913 0.03489401 0.03058548 0.04638247 0.02220993
  0.0154792  0.0332845  0.04369191 0.04618436 0.05201993 0.02123709
  0.00783767 0.0916166 ]
 [0.03302763 0.0306414  0.02823936 0.04006393 0.06859408 0.02890185
  0.02765371 0.02694815 0.02587769 0.04092186 0.03418044 0.03284169
  0.0281131  0.02999944 0.0443202  0.02764487 0.05332104 0.0575163
  0.0470853  0.03563517 0.05999409 0.02957945 0.03596674 0.02921851
  0.02542929 0.03018484 0.03457574 0.05001143 0.03527149 0.01310033
  0.01159313 0.06776599]
 [0.03306283 0.03381065 0.03039923 0.03973128 0.05069824 0.03401505
  0.03417793 0.02975823 0.03427727 0.04057578 0.03364097 0.03147947
  0.03049675 0.0324432  0.03785808 0.02252766 0.03896451 0.038934
  0.03418152 0.03055214 0.03507272 0.03919367 0.04096692 0.02392078
  0.02234461 0.03254457 0.02803291 0.05581611 0.03854342 0.01071304
  0.00844589 0.07916561]]

-* TASK 10/20 | SAMPLE 72/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 358/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 explicitly states that Fred went to the office, which implies that Fred is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' went', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03143061 0.04128136 0.04302783 ... 0.01612665 0.0325923  0.0294973 ]
 [0.03166912 0.09692841 0.07393314 ... 0.04290155 0.04729541 0.04664963]
 [0.03273749 0.04229144 0.04828354 ... 0.0145773  0.02337085 0.02475077]
 ...
 [0.0328722  0.04410245 0.04377189 ... 0.01414211 0.02530997 0.02926249]
 [0.03321345 0.03139441 0.03031732 ... 0.02424019 0.02850805 0.04073287]
 [0.03299379 0.03522712 0.03327306 ... 0.02187868 0.03254217 0.03057817]]

-* TASK 10/20 | SAMPLE 72/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 359/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that Julie is either in the office or the cinema, but it does not provide a definitive location for Julie. Therefore, we can only conclude that Julie might be in the office, but it's not certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Julie', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' office', ',', ' but', ' it', "'s", ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 44), x_tokens=44, y_tokens=55, max_supp_attn=0.0364, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 44)
DEBUG result.interpretability.attn_scores 2420 
 [[0.01652094 0.02513082 0.0267201  ... 0.00763634 0.03103142 0.03274747]
 [0.01684389 0.02282453 0.02586545 ... 0.01370246 0.01745988 0.02015096]
 [0.01732436 0.02523316 0.02985052 ... 0.0147123  0.03087812 0.02827816]
 ...
 [0.0174523  0.02661842 0.02278734 ... 0.00628517 0.05078584 0.0315477 ]
 [0.01777306 0.02253861 0.01785683 ... 0.0078521  0.02829705 0.02177054]
 [0.01789676 0.02232339 0.01790716 ... 0.00725205 0.02794863 0.04573451]]

-* TASK 10/20 | SAMPLE 72/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 360/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 previously stated that Mary is in the bedroom, and there is no information that suggests Mary has moved or changed locations.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' previously', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', ' or', ' changed', ' locations', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.1429, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02629585 0.04109471 0.03681356 ... 0.02881264 0.03681415 0.04266305]
 [0.02679947 0.03756298 0.03583363 ... 0.02813778 0.02992183 0.02384943]
 [0.02753209 0.04106769 0.04106094 ... 0.02294952 0.03221448 0.02849977]
 ...
 [0.02775177 0.03517129 0.0293699  ... 0.02641839 0.0406592  0.03311755]
 [0.0283101  0.0270831  0.02138068 ... 0.02863855 0.04729997 0.02872896]
 [0.02813854 0.03159635 0.02388167 ... 0.02677086 0.03487846 0.03987102]]
Model's predictions for the sample 72:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 1 explicitly states  |
|          |                 |         that Julie is in the park.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 5 explicitly states  |
|          |                 |  that Bill travelled to the office, which  |
|          |                 |    implies that Bill is in the office.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 8 explicitly states  |
|          |                 |    that Fred went to the office, which     |
|          |                 |    implies that Fred is in the office.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentence 11 states that     |
|          |                 |    Julie is either in the office or the    |
|          |                 |     cinema, but it does not provide a      |
|          |                 |       definitive location for Julie.       |
|          |                 |    Therefore, we can only conclude that    |
|          |                 |   Julie might be in the office, but it's   |
|          |                 |                not certain.                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentence 10 previously     |
|          |                 |  stated that Mary is in the bedroom, and   |
|          |                 |   there is no information that suggests    |
|          |                 |    Mary has moved or changed locations.    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 72:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 73/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 361/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Bill moved to the school, which means Bill is not in the cinema. Mary is in the cinema (sentence 1), but there is no information about Bill being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' moved', ' to', ' the', ' school', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' cinema', '.', ' Mary', ' is', ' in', ' the', ' cinema', ' (', 'sentence', ' ', '1', '),', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 26), x_tokens=26, y_tokens=54, max_supp_attn=0.1667, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 26)
DEBUG result.interpretability.attn_scores 1404 
 [[0.01694379 0.03068316 0.03564719 ... 0.01256972 0.01048542 0.01794685]
 [0.01671196 0.05455605 0.04562657 ... 0.018659   0.01656724 0.02184164]
 [0.01839622 0.04152149 0.0258384  ... 0.00547414 0.00413184 0.00916922]
 ...
 [0.01816563 0.0198689  0.02043438 ... 0.00590567 0.00426055 0.01194846]
 [0.01815397 0.0157637  0.01658147 ... 0.009302   0.00808603 0.01391967]
 [0.01820739 0.02042425 0.02020109 ... 0.00751292 0.00659604 0.01261813]]

-* TASK 10/20 | SAMPLE 73/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 362/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no new information about Mary's location in sentences 4 and 5. Sentence 1 (from the previous part) stated that Mary is in the cinema, and there is no update to change this information.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Mary', "'s", ' location', ' in', ' sentences', ' ', '4', ' and', ' ', '5', '.', ' Sentence', ' ', '1', ' (', 'from', ' the', ' previous', ' part', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 32), x_tokens=32, y_tokens=51, max_supp_attn=0.0588, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 32)
DEBUG result.interpretability.attn_scores 1632 
 [[0.01805513 0.02131196 0.02305513 ... 0.0084403  0.00701936 0.01009212]
 [0.01862917 0.0199043  0.02033098 ... 0.01102002 0.01062957 0.01401267]
 [0.01898569 0.01900819 0.02168845 ... 0.01849035 0.01209003 0.01662431]
 ...
 [0.01901    0.02293959 0.01984401 ... 0.00570031 0.00714463 0.00703477]
 [0.01936767 0.01804268 0.01568463 ... 0.00821329 0.01179732 0.01155224]
 [0.01931944 0.0196275  0.01643058 ... 0.00562258 0.01099438 0.01199045]]

-* TASK 10/20 | SAMPLE 73/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 363/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Julie went back to the office, which means Julie is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' means', ' Julie', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.0357, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.03343168 0.04983919 0.04738591 ... 0.06728149 0.03938658 0.01443219]
 [0.03397952 0.04776715 0.04027603 ... 0.03505563 0.04733757 0.03369785]
 [0.03474845 0.0525603  0.05392898 ... 0.05265173 0.0326506  0.01350644]
 ...
 [0.03514453 0.04999522 0.04689708 ... 0.06390306 0.03352665 0.01640979]
 [0.03532087 0.03892146 0.034606   ... 0.04435974 0.03784807 0.03067878]
 [0.03543905 0.04175075 0.0367344  ... 0.07449014 0.02960146 0.01856987]]

-* TASK 10/20 | SAMPLE 73/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 364/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 1 (from the previous part) stated that Mary is in the cinema, and sentence 10 updated Mary's location to the office. There is no information about Mary being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '1', ' (', 'from', ' the', ' previous', ' part', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' and', ' sentence', ' ', '10', ' updated', ' Mary', "'s", ' location', ' to', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 44), x_tokens=44, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 44)
DEBUG result.interpretability.attn_scores 2068 
 [[0.01978102 0.02698007 0.02371255 ... 0.01622916 0.088353   0.03397977]
 [0.02009953 0.02146211 0.01942057 ... 0.03013812 0.03744029 0.03157885]
 [0.02052333 0.02771328 0.02712353 ... 0.01168816 0.04617461 0.05124405]
 ...
 [0.02078657 0.02987133 0.02776214 ... 0.01882185 0.0357112  0.01227682]
 [0.02135352 0.02247247 0.02011861 ... 0.02309564 0.02067559 0.00926322]
 [0.02121694 0.02441006 0.02125366 ... 0.02185718 0.03162609 0.00972598]]

-* TASK 10/20 | SAMPLE 73/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 365/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Fred's location in sentences 13 and 14. Sentence 11 (from the previous part) stated that Fred went to the kitchen, but there is no update to change this information. Sentence 14 is about Mary's location, not Fred's.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' sentences', ' ', '13', ' and', ' ', '14', '.', ' Sentence', ' ', '11', ' (', 'from', ' the', ' previous', ' part', ')', ' stated', ' that', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.', ' Sentence', ' ', '14', ' is', ' about', ' Mary', "'s", ' location', ',', ' not', ' Fred', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(64, 50), x_tokens=50, y_tokens=64, max_supp_attn=0.0, attn_on_target=0.0156)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (64, 50)
DEBUG result.interpretability.attn_scores 3200 
 [[0.01432828 0.02209474 0.021301   ... 0.00695797 0.00442439 0.02432786]
 [0.01467437 0.01453034 0.01559706 ... 0.00893248 0.00600422 0.01089418]
 [0.01492188 0.02290739 0.02511297 ... 0.01010406 0.00759431 0.02828849]
 ...
 [0.01569725 0.01840796 0.0133886  ... 0.00480857 0.00471598 0.02571102]
 [0.01567431 0.02419777 0.01983063 ... 0.00658632 0.00725227 0.02715631]
 [0.01566913 0.02280743 0.0192245  ... 0.00662408 0.0059512  0.04064472]]
Model's predictions for the sample 73:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to sentence 2, Bill moved to   |
|          |                 |   the school, which means Bill is not in   |
|          |                 |     the cinema. Mary is in the cinema      |
|          |                 |       (sentence 1), but there is no        |
|          |                 |    information about Bill being in the     |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  There is no new information about Mary's  |
|          |                 |  location in sentences 4 and 5. Sentence   |
|          |                 |   1 (from the previous part) stated that   |
|          |                 |   Mary is in the cinema, and there is no   |
|          |                 |     update to change this information.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 8 explicitly states that Julie   |
|          |                 |    went back to the office, which means    |
|          |                 |          Julie is in the office.           |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    Sentence 1 (from the previous part)     |
|          |                 |   stated that Mary is in the cinema, and   |
|          |                 |   sentence 10 updated Mary's location to   |
|          |                 |    the office. There is no information     |
|          |                 |      about Mary being in the school.       |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |    There is no information about Fred's    |
|          |                 |      location in sentences 13 and 14.      |
|          |                 |    Sentence 11 (from the previous part)    |
|          |                 |   stated that Fred went to the kitchen,    |
|          |                 |   but there is no update to change this    |
|          |                 |  information. Sentence 14 is about Mary's  |
|          |                 |           location, not Fred's.            |
+----------+-----------------+--------------------------------------------+

Metrics for sample 73:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.09 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 74/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 366/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the school. The context sentences only mention Mary moving to the bedroom and Julie going back to the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' moving', ' to', ' the', ' bedroom', ' and', ' Julie', ' going', ' back', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0541, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.02531972 0.04330695 0.045964   0.07556095 0.07505837 0.04478702
  0.03324471 0.02901022 0.03009203 0.04710978 0.03641079 0.022468
  0.0240411  0.1228385  0.12745528 0.03870977 0.02663157 0.01975222
  0.01857522 0.01879475 0.01827973 0.03866183 0.0588509  0.01225698
  0.00705252 0.02616227]
 [0.02613401 0.02732228 0.02736519 0.0564885  0.05353837 0.03859175
  0.0234318  0.02111836 0.0240818  0.04057805 0.03128817 0.02401057
  0.02378698 0.12513909 0.15261182 0.03713239 0.02881654 0.0234056
  0.02053353 0.01945459 0.01712598 0.03269379 0.03541536 0.00866412
  0.00612428 0.01696345]
 [0.02656446 0.03057789 0.03493283 0.05926022 0.05999593 0.04953877
  0.03136135 0.02975732 0.03206363 0.04827645 0.03588407 0.03878687
  0.03766727 0.09968464 0.09449186 0.03087803 0.02664164 0.02402651
  0.0200239  0.01971136 0.01640303 0.02957456 0.03272689 0.01161568
  0.00816364 0.01594995]
 [0.02568942 0.03562506 0.04187669 0.04511994 0.04833322 0.0466093
  0.03557058 0.03795172 0.03643388 0.04371502 0.03577424 0.04532828
  0.03968795 0.05764574 0.05384202 0.03856888 0.03315775 0.03024942
  0.02578892 0.02610146 0.0227281  0.03289621 0.04671825 0.02913225
  0.02163712 0.02579865]
 [0.02663137 0.03146922 0.03746833 0.03442654 0.0304681  0.04167606
  0.03602202 0.03906825 0.03491997 0.03487758 0.03081973 0.04222053
  0.03622258 0.02234891 0.01728255 0.02804998 0.02664342 0.02640132
  0.02447945 0.02494947 0.02109992 0.02693679 0.03427205 0.02447193
  0.02022499 0.02645148]
 [0.02695586 0.03012444 0.03365401 0.02906313 0.02397946 0.04117658
  0.03702303 0.03790541 0.03692565 0.03324793 0.03015853 0.0463016
  0.03825926 0.02004897 0.01485297 0.02634064 0.02668873 0.02491954
  0.02508269 0.02433767 0.02036336 0.02696872 0.03130624 0.02239343
  0.01874566 0.02468241]
 [0.02642774 0.04482213 0.03991234 0.03052522 0.02512695 0.04465798
  0.04326282 0.04882373 0.0424373  0.03817501 0.0365901  0.06086161
  0.05339977 0.02099413 0.01564756 0.03373105 0.03085491 0.02976244
  0.02839932 0.02688926 0.02243697 0.02873011 0.0353248  0.02372526
  0.02069317 0.02179118]
 [0.02705521 0.03662753 0.04023414 0.03168966 0.02306898 0.05391091
  0.04343323 0.04370313 0.04188647 0.03594428 0.03192696 0.06699894
  0.05195979 0.02057219 0.01459829 0.03117505 0.02869601 0.02807181
  0.02589313 0.02640322 0.02175971 0.02715197 0.0293796  0.01842336
  0.01641614 0.01759006]
 [0.02719651 0.04382781 0.05224368 0.03705016 0.0250881  0.07550941
  0.06605852 0.04699098 0.05709149 0.03839993 0.03098671 0.05631157
  0.04297731 0.02081497 0.01535406 0.02837565 0.02334849 0.02205493
  0.02153324 0.02321144 0.01910101 0.02765961 0.03511764 0.01717117
  0.01359188 0.01841456]
 [0.02670624 0.02184686 0.02210048 0.01840893 0.01468426 0.02129132
  0.02800771 0.02935084 0.02275414 0.02100783 0.0272627  0.02578024
  0.03448896 0.01037535 0.01020966 0.03241205 0.03211294 0.02938255
  0.03232814 0.02881506 0.02984853 0.0269676  0.01859346 0.03700048
  0.02601656 0.01989273]
 [0.02668426 0.01936106 0.01646746 0.01531343 0.01215616 0.01439844
  0.02314988 0.02356649 0.01721637 0.01512585 0.02092304 0.01751242
  0.02172677 0.00808256 0.00834278 0.03268252 0.03319181 0.03369465
  0.03675276 0.03505713 0.03828264 0.02463233 0.01601989 0.04658826
  0.03466057 0.0245581 ]
 [0.02724369 0.01967299 0.01689602 0.01663177 0.0141144  0.0168892
  0.02252715 0.02440724 0.01845204 0.0185364  0.02586074 0.02400959
  0.02447685 0.00914132 0.00892926 0.03249721 0.03296496 0.03010276
  0.0344623  0.02980548 0.029714   0.02302578 0.01329972 0.02687289
  0.02332885 0.01573643]
 [0.02720908 0.01691675 0.01467545 0.01245314 0.01206161 0.01277179
  0.01969452 0.0196715  0.01662921 0.0141065  0.02451704 0.01758517
  0.01968162 0.00710299 0.00756872 0.02959293 0.03563561 0.02840188
  0.03973112 0.03299027 0.03323429 0.02357891 0.01320237 0.02938888
  0.02239466 0.01709664]
 [0.02658549 0.02066064 0.0176845  0.01380343 0.0134487  0.01479969
  0.02311151 0.0220548  0.02099718 0.01511533 0.02581143 0.01716192
  0.02124207 0.00764698 0.00854336 0.03064435 0.03355251 0.02959494
  0.04474351 0.03574753 0.03471614 0.0257132  0.02161134 0.04060551
  0.03023236 0.033006  ]
 [0.02736782 0.02403554 0.02120676 0.01666081 0.01454698 0.01832355
  0.02382881 0.02554538 0.02262921 0.01871791 0.02533738 0.0225324
  0.02359216 0.00954379 0.00933244 0.02392711 0.02602654 0.02343705
  0.03686713 0.03295795 0.02689253 0.02529145 0.019906   0.02129002
  0.01730969 0.01803064]
 [0.02693942 0.02933388 0.02964067 0.02935497 0.02543649 0.03317153
  0.02792028 0.03095103 0.03028737 0.03527216 0.02803933 0.04153429
  0.03650023 0.02158031 0.0156736  0.02621315 0.02726621 0.02758978
  0.02406345 0.02360315 0.02016593 0.0295171  0.03381699 0.02949397
  0.01989174 0.01810252]
 [0.02674886 0.04682337 0.04572685 0.02444602 0.02035438 0.02877274
  0.03777066 0.03777266 0.03486545 0.02327145 0.02466161 0.02724908
  0.03093136 0.01547247 0.0139492  0.03225223 0.02695259 0.02493544
  0.02421772 0.02614644 0.02410803 0.02886436 0.05429238 0.03638434
  0.02795106 0.02757786]
 [0.02712416 0.06702241 0.0698992  0.02843155 0.02228283 0.03118774
  0.04502217 0.03981432 0.04169226 0.02461436 0.02417524 0.0259754
  0.02779163 0.01563476 0.01425797 0.04003245 0.02823698 0.02358583
  0.02144735 0.02465034 0.02009636 0.02896509 0.06304491 0.022962
  0.0176359  0.02203895]
 [0.02721849 0.03695501 0.04005798 0.02407288 0.01933121 0.02656503
  0.03629413 0.03500861 0.03197732 0.02194432 0.02190699 0.02427258
  0.02442038 0.01396904 0.01259217 0.03118452 0.02535133 0.02303736
  0.02157883 0.02428046 0.02187884 0.02952125 0.04446107 0.03039661
  0.02718159 0.03092151]
 [0.0278652  0.02896861 0.02914043 0.02151459 0.01690542 0.02550029
  0.0305593  0.03494583 0.02633847 0.02086052 0.02369671 0.02540812
  0.02667447 0.01211442 0.01025073 0.02315563 0.02100182 0.02199592
  0.01947724 0.02112624 0.02036669 0.02728926 0.02257975 0.02344817
  0.0208113  0.02124744]
 [0.02738454 0.02047392 0.01892138 0.01469055 0.01284128 0.01564216
  0.02235853 0.02250142 0.01882909 0.01488515 0.02323275 0.01527968
  0.0206849  0.00875183 0.00829169 0.02585304 0.02492962 0.02340242
  0.02278735 0.02428221 0.02826167 0.02485438 0.01995354 0.05537849
  0.03359632 0.02497669]
 [0.02726019 0.01674708 0.0144871  0.01232973 0.01046989 0.01145066
  0.01728925 0.01645775 0.01483477 0.01209542 0.01736713 0.01114896
  0.0158652  0.00714778 0.00711321 0.02420994 0.02529358 0.02550087
  0.02482218 0.02529271 0.03288744 0.02276781 0.01600177 0.06660839
  0.03872681 0.02668276]
 [0.02741518 0.0167945  0.01514061 0.01314861 0.011133   0.01268272
  0.01730352 0.01716368 0.0161488  0.01310425 0.01925659 0.01288177
  0.01687601 0.00759959 0.00720536 0.02852811 0.02145967 0.02761134
  0.02117992 0.02518179 0.0292524  0.02089005 0.0153039  0.06541704
  0.04066022 0.02147787]
 [0.02745193 0.01559421 0.01393653 0.0112161  0.00985211 0.01114098
  0.01650593 0.01570036 0.01504488 0.01163112 0.02458541 0.012197
  0.01609391 0.0067557  0.00689935 0.02770459 0.02830717 0.02599668
  0.0237834  0.02569927 0.03059176 0.02190468 0.01438699 0.0625266
  0.03038625 0.02019843]
 [0.02681055 0.02922941 0.0252224  0.03022467 0.03300786 0.03035028
  0.03326969 0.02946918 0.02841911 0.0357654  0.04547594 0.0348985
  0.03124571 0.02699097 0.02249106 0.02916238 0.03095916 0.0294716
  0.0263885  0.028274   0.02734361 0.0317949  0.02459356 0.03957566
  0.01825364 0.02158823]
 [0.02782485 0.01652629 0.01504605 0.01295696 0.01103198 0.01255202
  0.01581718 0.01605024 0.01670984 0.01328576 0.02008253 0.01314869
  0.01558191 0.00792222 0.00705737 0.01836222 0.02260664 0.01843265
  0.02152835 0.02352892 0.02501532 0.02244041 0.01516241 0.03489101
  0.02658228 0.0293389 ]
 [0.02759624 0.01959148 0.01820228 0.01403283 0.01180647 0.01392893
  0.0193448  0.02045565 0.0211346  0.0142959  0.01727075 0.014765
  0.01814376 0.00865121 0.00682698 0.01709184 0.02102581 0.02017594
  0.01972961 0.02372499 0.03046802 0.0266461  0.01750053 0.02305271
  0.0674961  0.05022314]
 [0.02724403 0.01693972 0.01525575 0.01318055 0.01088692 0.01223651
  0.01696093 0.01663681 0.01700854 0.01330943 0.0172192  0.01297271
  0.01601579 0.00791313 0.00643231 0.01756314 0.02137497 0.02714274
  0.02264366 0.03276275 0.04960189 0.0232946  0.01569218 0.02186357
  0.0969254  0.05679795]
 [0.02774861 0.01469547 0.01409056 0.01171847 0.01043881 0.01142319
  0.01498747 0.01526198 0.01609542 0.0124637  0.01731109 0.01303317
  0.01473486 0.00742627 0.0056793  0.01572579 0.01566112 0.01956633
  0.01888376 0.03461912 0.04917623 0.01902091 0.01300484 0.01721929
  0.08851006 0.05207423]
 [0.02807723 0.0140768  0.01345154 0.01103316 0.00978088 0.01085877
  0.01418363 0.01408371 0.01606816 0.01191785 0.01887444 0.01324209
  0.01396499 0.00747041 0.00565601 0.01625465 0.01728578 0.0195522
  0.02124749 0.0285941  0.04036832 0.02053024 0.01219943 0.01423317
  0.05168524 0.05288266]
 [0.02766374 0.01420053 0.01346527 0.01036237 0.00929649 0.01040507
  0.01459491 0.01386658 0.01591825 0.01131413 0.02248974 0.0121852
  0.01405817 0.00721075 0.00567354 0.01865399 0.02222609 0.02217297
  0.02612107 0.0320457  0.0382277  0.02181209 0.01460603 0.02084036
  0.04277896 0.073865  ]
 [0.02705135 0.02299751 0.02625567 0.0299793  0.02716032 0.02903747
  0.02896232 0.03046737 0.05550943 0.04268382 0.02767175 0.03314898
  0.03557977 0.02694034 0.02222311 0.01811408 0.02386171 0.0285291
  0.02766093 0.02693205 0.0231743  0.02768898 0.02510295 0.01508548
  0.0169488  0.03120057]
 [0.0283054  0.01839193 0.01848062 0.01605972 0.01248253 0.01599346
  0.0197427  0.02178725 0.0221931  0.01759596 0.02153156 0.01700118
  0.02141148 0.01083495 0.00793835 0.01688103 0.01906799 0.01897794
  0.024488   0.02457785 0.0214234  0.02476115 0.01500449 0.01203796
  0.01515519 0.03022301]
 [0.02676708 0.02914494 0.02814453 0.05002309 0.05465737 0.03747208
  0.02523129 0.02578    0.02991826 0.04796472 0.03269238 0.02710898
  0.03084477 0.0833884  0.09740026 0.02579416 0.02526722 0.02498598
  0.02083881 0.01977861 0.01742071 0.03166416 0.03285254 0.00912733
  0.00666535 0.01849236]
 [0.02658866 0.02943242 0.02707923 0.05365144 0.10804293 0.03404063
  0.02018789 0.0222565  0.02506079 0.05112405 0.03642087 0.02628657
  0.02364204 0.07944093 0.10114679 0.03057285 0.0365966  0.03808733
  0.02876525 0.02373678 0.02151274 0.0282726  0.03240597 0.00812777
  0.00604842 0.01619308]
 [0.02646963 0.02338205 0.02206922 0.03783855 0.05766598 0.024334
  0.01646846 0.02150323 0.02363205 0.04545909 0.0337447  0.02968385
  0.0273907  0.02756287 0.0295647  0.02252662 0.03894712 0.0620513
  0.0581077  0.0406983  0.03064773 0.0248191  0.02537237 0.01158305
  0.01083319 0.01659475]
 [0.02667377 0.02648133 0.02360425 0.03727811 0.04946517 0.02632194
  0.01949736 0.02314046 0.02770361 0.04220769 0.03274169 0.02870857
  0.02833751 0.02724154 0.02661424 0.01944597 0.03135748 0.04394059
  0.04504513 0.03523748 0.02602504 0.04219802 0.03091684 0.01014695
  0.00868411 0.01517747]]

-* TASK 10/20 | SAMPLE 74/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 367/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences do not mention Julie being in the school. Sentence 4 states Julie is in the kitchen, and sentence 5 provides alternative locations (office or cinema), but school is not mentioned.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' school', '.', ' Sentence', ' ', '4', ' states', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' and', ' sentence', ' ', '5', ' provides', ' alternative', ' locations', ' (', 'office', ' or', ' cinema', '),', ' but', ' school', ' is', ' not', ' mentioned', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0851, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01956859 0.03241419 0.0340619  ... 0.0101704  0.00827954 0.00918659]
 [0.02022182 0.0308653  0.03210736 ... 0.0121649  0.01005603 0.01022149]
 [0.02052476 0.03014072 0.03344562 ... 0.01892825 0.01420315 0.01205949]
 ...
 [0.02060212 0.03044307 0.02571122 ... 0.00649595 0.00475036 0.00742227]
 [0.02087483 0.02125689 0.01757493 ... 0.01177029 0.00606252 0.00939969]
 [0.02079784 0.0248257  0.02029733 ... 0.0087231  0.00531966 0.00883576]]

-* TASK 10/20 | SAMPLE 74/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 368/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 states that Fred travelled to the school, which implies that Fred is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 38), x_tokens=38, y_tokens=27, max_supp_attn=0.0, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 38)
DEBUG result.interpretability.attn_scores 1026 
 [[0.03445416 0.04890321 0.05226714 ... 0.04054032 0.02641051 0.02405005]
 [0.03521785 0.04676944 0.04936231 ... 0.03788318 0.03555934 0.04122522]
 [0.03618577 0.04954334 0.0595317  ... 0.03168241 0.02249514 0.0168792 ]
 ...
 [0.0364221  0.05073215 0.04239171 ... 0.02890169 0.01899319 0.01648859]
 [0.03645699 0.04263718 0.03362272 ... 0.03963599 0.03297017 0.03088286]
 [0.0366971  0.0446814  0.03457063 ... 0.03105853 0.02357166 0.02431447]]

-* TASK 10/20 | SAMPLE 74/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 369/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 provides alternative locations for Fred (bedroom or office), but kitchen is not mentioned. There is no information that suggests Fred is in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' provides', ' alternative', ' locations', ' for', ' Fred', ' (', 'bed', 'room', ' or', ' office', '),', ' but', ' kitchen', ' is', ' not', ' mentioned', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0256, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02378519 0.03242102 0.03607602 ... 0.08579454 0.01775667 0.00920829]
 [0.02408115 0.02556538 0.02753601 ... 0.03348082 0.02905051 0.01372566]
 [0.02470645 0.0342616  0.03936452 ... 0.07186081 0.02790731 0.01486411]
 ...
 [0.02489625 0.03825504 0.03893256 ... 0.02338411 0.00961529 0.00745115]
 [0.02541428 0.02896911 0.02724165 ... 0.0133305  0.01010117 0.01002308]
 [0.0253332  0.03368517 0.03129828 ... 0.01312636 0.00970542 0.00817483]]

-* TASK 10/20 | SAMPLE 74/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 370/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Bill's location. The context sentences only mention Julie moving to the office and Mary being in either the park or the cinema, but do not mention Bill or the school.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' moving', ' to', ' the', ' office', ' and', ' Mary', ' being', ' in', ' either', ' the', ' park', ' or', ' the', ' cinema', ',', ' but', ' do', ' not', ' mention', ' Bill', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01925127 0.02276358 0.02782613 ... 0.02991846 0.03011437 0.01752313]
 [0.0195419  0.02403378 0.03088327 ... 0.01441736 0.03072725 0.02305856]
 [0.02007673 0.02413093 0.03158866 ... 0.03320755 0.01966904 0.01209933]
 ...
 [0.02044602 0.02763291 0.02386817 ... 0.04585713 0.02416859 0.01924278]
 [0.02081669 0.03041049 0.02778342 ... 0.0407781  0.02296224 0.01476076]
 [0.02088272 0.02642987 0.02530225 ... 0.04821664 0.02032768 0.01333088]]
Model's predictions for the sample 74:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the school. The context    |
|          |                 |   sentences only mention Mary moving to    |
|          |                 |  the bedroom and Julie going back to the   |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    The context sentences do not mention    |
|          |                 |   Julie being in the school. Sentence 4    |
|          |                 |    states Julie is in the kitchen, and     |
|          |                 |      sentence 5 provides alternative       |
|          |                 |  locations (office or cinema), but school  |
|          |                 |             is not mentioned.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 7 states that Fred travelled to  |
|          |                 |   the school, which implies that Fred is   |
|          |                 |               in the school.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |      Sentence 11 provides alternative      |
|          |                 |  locations for Fred (bedroom or office),   |
|          |                 |   but kitchen is not mentioned. There is   |
|          |                 |  no information that suggests Fred is in   |
|          |                 |                the kitchen.                |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |   There is no information provided about   |
|          |                 |   Bill's location. The context sentences   |
|          |                 |  only mention Julie moving to the office   |
|          |                 |  and Mary being in either the park or the  |
|          |                 |   cinema, but do not mention Bill or the   |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 74:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 75/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 371/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Julie moved to the park, which implies that she is now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' moved', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1818, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02813218 0.04606107 0.054979   0.07260676 0.07624871 0.07690781
  0.06249946 0.07037577 0.0535602  0.06271394 0.04665685 0.0583561
  0.06400379 0.09530302 0.06865717 0.03011345 0.03162343 0.03141846
  0.0286864  0.03216024 0.02630725 0.03859824 0.04786287 0.01940682
  0.01546792 0.02228947]
 [0.02841534 0.06270506 0.05709504 0.06933767 0.05881852 0.05979894
  0.05561702 0.0527077  0.04670816 0.04973839 0.03932802 0.0364697
  0.03843501 0.10442232 0.10163395 0.0344688  0.03125523 0.02563435
  0.02486003 0.02680417 0.02331858 0.03933827 0.0522616  0.01239904
  0.01101419 0.02035331]
 [0.03062869 0.06230093 0.0380239  0.05574061 0.03674574 0.03806917
  0.03508973 0.02509885 0.0232563  0.03454728 0.02687235 0.01779375
  0.01895811 0.02742578 0.03541876 0.02220344 0.01518876 0.01357709
  0.01706959 0.01823446 0.01647639 0.04553638 0.05655427 0.0056502
  0.00529299 0.01101368]
 [0.02865245 0.03370332 0.03290704 0.02509306 0.01840224 0.02846979
  0.03317164 0.03406782 0.03224142 0.02764344 0.03098921 0.03137501
  0.02960474 0.01302733 0.01157134 0.02898278 0.03437634 0.03272335
  0.04135605 0.03959916 0.03711551 0.03352869 0.03731243 0.08414362
  0.06639583 0.05423519]
 [0.02909064 0.04603386 0.04956664 0.06744489 0.06103789 0.04984203
  0.03834219 0.0328697  0.03570429 0.0473573  0.03528294 0.02759149
  0.02751995 0.09352012 0.09772685 0.03700985 0.02915795 0.0207484
  0.02224009 0.02433266 0.0232674  0.03989814 0.06781072 0.00859393
  0.00833799 0.02476631]
 [0.02966101 0.03001728 0.0298924  0.05080672 0.04701681 0.04319568
  0.02783633 0.0257802  0.03038663 0.04364894 0.03172876 0.0314333
  0.02979613 0.10663561 0.12564138 0.03690104 0.03315198 0.02520764
  0.02517991 0.02548444 0.02265635 0.0338192  0.03918904 0.00779088
  0.00677016 0.01593017]
 [0.03007894 0.03406424 0.03845247 0.05395619 0.0505526  0.0545284
  0.03711148 0.03497065 0.03898364 0.051311   0.03683894 0.04943794
  0.04448355 0.08418071 0.07928356 0.03128781 0.03036691 0.02514052
  0.02386014 0.02473664 0.02147736 0.03082838 0.03633637 0.01116464
  0.00999801 0.01558817]
 [0.0290144  0.04283599 0.04776511 0.04126683 0.04492413 0.048154
  0.04044358 0.04272698 0.0418463  0.04359869 0.03608529 0.0523825
  0.04450883 0.05033845 0.04581772 0.04071647 0.03820818 0.03212604
  0.03006866 0.0316269  0.02944315 0.03563174 0.05178919 0.02797993
  0.034211   0.03284194]
 [0.0302008  0.04340578 0.05047216 0.04686777 0.0441018  0.05616909
  0.04736093 0.04957564 0.05157153 0.04971622 0.0370799  0.05390259
  0.04980025 0.03784173 0.02533751 0.0288094  0.02960143 0.0267139
  0.02642976 0.0278107  0.02406216 0.03676594 0.0398046  0.0184743
  0.01680316 0.02221676]
 [0.02946599 0.05486803 0.05673041 0.0282172  0.02373126 0.03636906
  0.04588036 0.04362497 0.04468339 0.02978953 0.02940117 0.03874361
  0.03957009 0.01633139 0.01417649 0.04490118 0.03597471 0.03001008
  0.03157431 0.03342606 0.03208124 0.03459802 0.06884404 0.03845451
  0.04296356 0.03780154]
 [0.03015549 0.04095216 0.0486378  0.02414596 0.02151765 0.02824721
  0.04976346 0.03670611 0.04248261 0.02480712 0.02500234 0.02826999
  0.02914975 0.01301911 0.01270151 0.04435851 0.03395819 0.02796086
  0.03063639 0.03387997 0.03081776 0.02942023 0.0549568  0.02847872
  0.04234039 0.0344399 ]
 [0.03064061 0.01455609 0.0173154  0.01133698 0.01033211 0.01548329
  0.01717772 0.01720939 0.02157451 0.01386976 0.01382325 0.01491272
  0.01566963 0.00619306 0.00622581 0.01847621 0.01866403 0.01707665
  0.02091767 0.02255506 0.02265109 0.01769512 0.03157065 0.04383362
  0.07523464 0.05937911]
 [0.0301741  0.02508283 0.02704538 0.01686333 0.0151371  0.02140849
  0.02609608 0.02386684 0.024729   0.01856543 0.02275165 0.02197744
  0.02276779 0.00882853 0.00918605 0.0377421  0.02695938 0.03026499
  0.02888023 0.03174661 0.02839493 0.02877909 0.02964588 0.03718888
  0.06635181 0.04926206]
 [0.03033534 0.02472911 0.0249449  0.01844229 0.01572448 0.02488123
  0.02775669 0.02797918 0.02614303 0.02173431 0.02630968 0.02881817
  0.02992854 0.0098295  0.00882529 0.03897087 0.0304634  0.03381888
  0.02848674 0.03070037 0.02919845 0.02939855 0.0213     0.03668229
  0.0566513  0.03099794]
 [0.02988576 0.02170649 0.01893462 0.01505218 0.01174988 0.0168893
  0.02426746 0.02225966 0.02105252 0.01641491 0.02411796 0.02015281
  0.0240762  0.00720388 0.00696729 0.03920716 0.02921441 0.04440703
  0.03222255 0.03988171 0.04186092 0.02705117 0.01709974 0.04970373
  0.09663544 0.04711876]
 [0.03063273 0.01950095 0.01781136 0.01401502 0.01169575 0.01715922
  0.02292218 0.02184092 0.02079378 0.01646221 0.02661729 0.02265005
  0.02399194 0.00712174 0.00661115 0.03879254 0.02641531 0.05095186
  0.03399883 0.04434075 0.03792044 0.02277736 0.01350853 0.03380405
  0.06081545 0.04131283]
 [0.03061162 0.01779558 0.01590788 0.01143127 0.00977698 0.01375598
  0.02123539 0.01933092 0.01965504 0.01366579 0.03037655 0.01887701
  0.02080938 0.00587985 0.00618444 0.034607   0.02861969 0.04194548
  0.03723311 0.04081562 0.03842562 0.02450687 0.01468109 0.04138478
  0.04350487 0.0580255 ]
 [0.03017867 0.0199427  0.01828486 0.0124051  0.01100587 0.01619939
  0.0216249  0.02132779 0.02344735 0.01512903 0.02472933 0.01915208
  0.02155808 0.00645261 0.00643307 0.0256743  0.0300124  0.02734757
  0.03712136 0.03304365 0.03373526 0.02501686 0.01932058 0.07741561
  0.04813728 0.05924129]
 [0.03098741 0.02214264 0.02140924 0.0160823  0.01249735 0.0181241
  0.02350699 0.02371556 0.02349248 0.01763132 0.0255727  0.02149017
  0.02324204 0.0079787  0.00749605 0.02450434 0.0231255  0.02695642
  0.03282735 0.03186747 0.03233611 0.02710898 0.01684597 0.03025527
  0.02496379 0.04282456]
 [0.03120658 0.0232078  0.02717153 0.02363512 0.01766859 0.02655817
  0.02700603 0.03238682 0.02793013 0.02826569 0.02783107 0.0368155
  0.0332435  0.01283568 0.00924401 0.02073617 0.02336982 0.02623525
  0.0264859  0.02455451 0.02497085 0.02980506 0.01659154 0.02464324
  0.01947584 0.02268431]
 [0.03141462 0.02837993 0.03023629 0.02759518 0.01915316 0.03038946
  0.03427798 0.04178179 0.0304122  0.0326835  0.03608786 0.04403871
  0.04168136 0.01403979 0.00978831 0.02359294 0.02342081 0.02765801
  0.02579053 0.02440358 0.02401483 0.02992951 0.01661106 0.02250191
  0.01624688 0.01604642]
 [0.03130941 0.02660734 0.0269175  0.0250818  0.01903338 0.02804174
  0.03155359 0.03570767 0.03066492 0.03108428 0.03496508 0.04033574
  0.04075452 0.0134057  0.00984018 0.02785871 0.02573674 0.03080397
  0.02841895 0.0275202  0.02702488 0.03023924 0.01443968 0.02203739
  0.01857805 0.01468858]
 [0.03111915 0.0202428  0.01948847 0.01434573 0.0108953  0.01675736
  0.02179183 0.02396245 0.02370608 0.01824618 0.02384752 0.02390948
  0.02615377 0.00767479 0.00647255 0.03128973 0.02801915 0.03013993
  0.02977949 0.02882915 0.03261797 0.02793222 0.01282269 0.03357851
  0.03115764 0.02169467]
 [0.03128416 0.02000752 0.01816562 0.01424722 0.0101916  0.01526171
  0.0221497  0.02275464 0.02257787 0.0168258  0.02319641 0.02143385
  0.02504156 0.00708341 0.00595492 0.02865636 0.02731971 0.03142205
  0.03095892 0.03116846 0.03743489 0.02365525 0.01248302 0.03960476
  0.03289249 0.02465597]
 [0.03144476 0.02034443 0.01869787 0.01526467 0.01199866 0.01602213
  0.02120157 0.02359575 0.02257787 0.01899701 0.02575598 0.0238525
  0.02464434 0.00790587 0.00663256 0.02719706 0.02889755 0.029913
  0.03238884 0.02879283 0.03339345 0.02450317 0.01266977 0.03209602
  0.02011397 0.02019013]
 [0.0314615  0.0217273  0.02027043 0.01537866 0.01164162 0.01709678
  0.02424237 0.02608155 0.02568874 0.01899258 0.02896923 0.02458012
  0.02620673 0.00808383 0.00683983 0.02856596 0.02691558 0.03076202
  0.03040548 0.02980448 0.03311018 0.02450793 0.01393343 0.03442602
  0.02172515 0.02277646]
 [0.03157247 0.01738104 0.01722036 0.01140171 0.00984839 0.0134075
  0.02201005 0.02168965 0.02149027 0.01428656 0.03498687 0.02005588
  0.02196372 0.0066125  0.00553095 0.02619416 0.03050139 0.0288726
  0.03612306 0.03288875 0.03448128 0.02361294 0.01243097 0.03362969
  0.01846451 0.02914084]
 [0.03064477 0.01869748 0.01847668 0.01169583 0.00943262 0.01487294
  0.02009959 0.02159646 0.02483881 0.01517042 0.02496901 0.01867594
  0.02162789 0.00696678 0.00570923 0.02169951 0.02825218 0.02303375
  0.03688674 0.03127966 0.0350422  0.0250641  0.01708738 0.07465709
  0.03752226 0.04952035]
 [0.03149263 0.01997391 0.02060913 0.017225   0.01301908 0.01976478
  0.02109246 0.02322663 0.02605277 0.02095096 0.02373857 0.02370252
  0.02399916 0.01063936 0.00799541 0.01785056 0.02379653 0.02252914
  0.03091867 0.02802063 0.02921703 0.02517163 0.01435704 0.0228541
  0.01522543 0.0244928 ]
 [0.03024942 0.02932425 0.029628   0.04362964 0.04505542 0.03965244
  0.02628048 0.02665762 0.03206391 0.04494369 0.03335269 0.03248708
  0.03329767 0.07099129 0.08477146 0.02618015 0.02947311 0.02580655
  0.0259097  0.02554004 0.02386093 0.03245547 0.03369714 0.00888886
  0.0082108  0.01801175]
 [0.03006838 0.03062709 0.03000386 0.04828489 0.09120729 0.03853146
  0.02407434 0.02529369 0.03086048 0.0520914  0.03937929 0.03272482
  0.02785819 0.06847848 0.0889211  0.03199204 0.0412499  0.03519089
  0.03121736 0.02785552 0.029074   0.02941424 0.03299373 0.00769177
  0.00594697 0.0154643 ]
 [0.02974127 0.02754765 0.02637661 0.04018182 0.09249031 0.02747269
  0.02002867 0.02367562 0.02658228 0.0465976  0.03823985 0.0348815
  0.0268507  0.03198871 0.0418302  0.02721602 0.06438669 0.05651463
  0.04488638 0.03389699 0.04813308 0.02705627 0.03038117 0.01805271
  0.01290878 0.02174075]
 [0.0300487  0.03352726 0.03056203 0.04092064 0.05734777 0.03251863
  0.02648778 0.0255551  0.03224142 0.04251973 0.03511632 0.02871993
  0.02880309 0.03176037 0.03457396 0.02324343 0.04232369 0.0370887
  0.03618079 0.03239854 0.03607851 0.04635575 0.04280693 0.01253306
  0.00964154 0.01925418]]

-* TASK 10/20 | SAMPLE 75/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 372/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 4, Julie travelled to the school, which implies that she is now in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Julie', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03251587 0.05354788 0.052809   0.07657359 0.06460226 0.05666837
  0.04161983 0.04378026 0.05784203 0.05952851 0.03957113 0.03902334
  0.03774381 0.10588488 0.10624424 0.03516099 0.03210045 0.02486614
  0.02647407 0.02752827 0.02476603 0.03914696 0.06218942 0.01231086
  0.01561795 0.03319453 0.04493326 0.04450783 0.11131479 0.05786687
  0.00743702 0.03560374]
 [0.0334783  0.05318398 0.05091159 0.09125019 0.09209806 0.08596432
  0.04721204 0.04645236 0.05885968 0.08042293 0.05525796 0.06194763
  0.05434257 0.17475775 0.1505764  0.04109809 0.03421504 0.02993494
  0.02785857 0.02872623 0.02571238 0.04134151 0.04878314 0.01143842
  0.01335263 0.0276938  0.04352279 0.03484362 0.08258048 0.0642199
  0.010123   0.04225835]
 [0.03398032 0.04777767 0.05400646 0.07530478 0.06704152 0.06703756
  0.04540414 0.04745841 0.05555044 0.06458385 0.04156885 0.058619
  0.05146197 0.10609935 0.07714851 0.03263603 0.03189074 0.02617983
  0.02574376 0.02617552 0.02306591 0.0373224  0.04765739 0.0152437
  0.01738526 0.02708635 0.04076904 0.03068863 0.05801964 0.06954417
  0.01785056 0.0363224 ]
 [0.03276416 0.04252809 0.04482228 0.03631062 0.03298466 0.03768566
  0.03594718 0.03875461 0.03676242 0.03466827 0.03084052 0.03816078
  0.03721179 0.02718157 0.02757608 0.03652782 0.03409562 0.02731668
  0.02912619 0.02993897 0.02779562 0.03754871 0.05627512 0.03066952
  0.04326961 0.04055455 0.0482915  0.03346265 0.04367442 0.09775026
  0.03119747 0.0270879 ]
 [0.03398615 0.03241625 0.034392   0.02598951 0.02231831 0.0305783
  0.02975745 0.02851309 0.03188067 0.02751139 0.02495269 0.02684445
  0.02771103 0.01679221 0.01872511 0.02519315 0.02340906 0.0204633
  0.02569664 0.02656498 0.02568121 0.03098935 0.04098507 0.02277097
  0.0343095  0.04805258 0.04500042 0.02943558 0.03340753 0.0667658
  0.02829342 0.02353155]
 [0.03377393 0.04632565 0.0482483  0.02758479 0.02347711 0.03402007
  0.03920675 0.03762481 0.04043742 0.028383   0.02542895 0.03124897
  0.03269647 0.02033808 0.02017289 0.0355947  0.03045844 0.02308928
  0.02709021 0.0269574  0.02532511 0.03681894 0.06293306 0.02761315
  0.03733056 0.03670121 0.05752666 0.02499866 0.03523111 0.09542209
  0.02752261 0.01881124]
 [0.03392443 0.04154627 0.0418357  0.02235375 0.02105228 0.02679325
  0.0364049  0.03016997 0.03617273 0.02300323 0.02342911 0.02338907
  0.0247337  0.01564578 0.01853606 0.03587493 0.03268298 0.02344928
  0.02949768 0.02969248 0.02744298 0.03128806 0.05568554 0.02448056
  0.04058313 0.03842902 0.0467467  0.02238947 0.02885724 0.07283865
  0.01683072 0.0131642 ]
 [0.03452927 0.02192249 0.02152756 0.01349931 0.01405204 0.0172225
  0.01951336 0.01675677 0.01945982 0.01585119 0.01986985 0.01745936
  0.01812128 0.0100748  0.01165835 0.02365073 0.02179691 0.02370613
  0.02567218 0.03026631 0.02536529 0.0233457  0.02714945 0.03268615
  0.04770784 0.03566236 0.02266812 0.02158062 0.02130842 0.03091854
  0.01942579 0.0161094 ]
 [0.03401013 0.03148307 0.03384585 0.02043693 0.02029143 0.02669042
  0.03165344 0.0269662  0.03024595 0.02387242 0.02684927 0.02599632
  0.02681339 0.01536762 0.01708828 0.03989055 0.0373447  0.03321707
  0.03491427 0.03738403 0.0321145  0.03497089 0.03878493 0.03054246
  0.04829046 0.03720326 0.03613466 0.02282985 0.0285391  0.04937737
  0.02913011 0.0163433 ]
 [0.03444697 0.0319929  0.03324633 0.0215425  0.02100074 0.02708208
  0.03290403 0.02922351 0.0284943  0.02544374 0.02893551 0.03112943
  0.03319559 0.01640746 0.01559097 0.04527476 0.04022678 0.03913501
  0.03287467 0.03351212 0.03077394 0.03601677 0.03009838 0.03287815
  0.04837411 0.02693531 0.03269247 0.02341533 0.02422232 0.03809476
  0.03918888 0.0239577 ]
 [0.03400828 0.03174969 0.02818185 0.01934621 0.01781918 0.02287512
  0.03052351 0.02604724 0.02522735 0.02192582 0.0274899  0.02516674
  0.02948312 0.01304096 0.01355248 0.0497677  0.03799713 0.05354072
  0.03662587 0.04282757 0.04030957 0.03379624 0.02499348 0.04397917
  0.06575159 0.03143303 0.03265889 0.02717321 0.01904192 0.0181973
  0.02913802 0.02213035]
 [0.03508978 0.03037694 0.02804845 0.01985818 0.0187553  0.02413479
  0.03174728 0.02791038 0.02642664 0.02303955 0.03409421 0.02917862
  0.03148735 0.01375326 0.01378502 0.05325194 0.03722382 0.05894988
  0.0427927  0.06762668 0.04435479 0.03041902 0.02248827 0.04585534
  0.05816973 0.03762162 0.03183612 0.02457101 0.01770451 0.01580841
  0.03043325 0.0263473 ]
 [0.03507352 0.02605874 0.02390365 0.01539386 0.01464381 0.01933052
  0.02735586 0.0228068  0.0225924  0.0179479  0.03167502 0.02245643
  0.0263162  0.01064152 0.01141977 0.04731484 0.03774446 0.04175889
  0.04228711 0.04773079 0.03906531 0.03054696 0.02100611 0.06374742
  0.04594733 0.04329079 0.02298716 0.02647763 0.0156187  0.01402281
  0.02675575 0.02595338]
 [0.03386299 0.03854316 0.03783528 0.02542312 0.02461942 0.04399458
  0.0474476  0.04144504 0.04361727 0.03114794 0.0346358  0.03646864
  0.03728724 0.01620209 0.0163961  0.03848128 0.04088285 0.0364999
  0.04958836 0.04597675 0.04533095 0.03631051 0.03735206 0.06928417
  0.05335217 0.05814014 0.027101   0.0411757  0.03039233 0.02034722
  0.02617204 0.02437717]
 [0.03502718 0.02778098 0.02771574 0.02137432 0.01807692 0.0245824
  0.02893011 0.02781871 0.02556077 0.02305649 0.03187732 0.0286448
  0.02911748 0.0148243  0.01383394 0.03259185 0.02953731 0.02912792
  0.03747941 0.03582422 0.03420813 0.03446687 0.02236604 0.04274674
  0.03342827 0.03845401 0.0234741  0.03228278 0.02395545 0.02275259
  0.0677959  0.03716024]
 [0.03497084 0.02664243 0.03091576 0.0263704  0.02272657 0.03083235
  0.03032816 0.03450812 0.03153481 0.0306056  0.03153594 0.03965815
  0.03623289 0.01959979 0.01494952 0.0234362  0.02308576 0.02507737
  0.02720165 0.02643779 0.02600266 0.03563572 0.02337778 0.02766256
  0.02731609 0.03182641 0.02827638 0.03163749 0.03174951 0.03000514
  0.10561708 0.03650686]
 [0.03523392 0.0339205  0.03756848 0.03428746 0.02519676 0.03928406
  0.03883138 0.04572361 0.03224891 0.03760995 0.03963013 0.05224616
  0.0489857  0.02437398 0.01696687 0.02707858 0.02567803 0.02904652
  0.0285481  0.02682528 0.02691022 0.03701071 0.02590044 0.03113962
  0.02489028 0.02323302 0.03596675 0.02505085 0.0306351  0.02872829
  0.11425282 0.03897147]
 [0.03543343 0.03424478 0.03706941 0.03798752 0.03072891 0.04237954
  0.0400475  0.04560444 0.03574228 0.0426314  0.03999048 0.05225544
  0.05099573 0.0296538  0.02109338 0.02715881 0.02613022 0.02874055
  0.02899933 0.02655118 0.02729403 0.03369731 0.02240918 0.02342883
  0.02069716 0.02014905 0.03333053 0.0277186  0.03038615 0.02726754
  0.0837695  0.05186565]
 [0.03523983 0.02417437 0.02513093 0.02179725 0.01473247 0.02338776
  0.02789402 0.02962914 0.0246924  0.02254806 0.02903456 0.02728656
  0.03113526 0.01417829 0.01276426 0.03269592 0.02923657 0.03264584
  0.03090755 0.02888102 0.0329701  0.03205181 0.0179103  0.0395118
  0.03944804 0.0259823  0.02619427 0.03806248 0.02159382 0.01917923
  0.07004245 0.05231679]
 [0.03504084 0.02550568 0.02417516 0.02095386 0.01370976 0.02152624
  0.02859879 0.02813725 0.02470236 0.02065715 0.02788397 0.02343338
  0.03027823 0.01261203 0.0123922  0.03656736 0.03476408 0.03917782
  0.03782735 0.0365775  0.04386776 0.02998271 0.01892922 0.05698107
  0.0511919  0.03732062 0.02416254 0.04105606 0.02031509 0.0118781
  0.04158038 0.04900935]
 [0.03577732 0.02370238 0.02364156 0.02219546 0.01522321 0.02266341
  0.02726202 0.0285383  0.02414003 0.02326471 0.03030527 0.02649407
  0.02993388 0.01435507 0.01247133 0.02905354 0.02914191 0.02943108
  0.03174387 0.02768701 0.03390884 0.02961906 0.01724163 0.0416576
  0.02864182 0.02413713 0.02323902 0.03468643 0.019323   0.01331109
  0.03534668 0.07727622]
 [0.03558735 0.02798635 0.02779735 0.02447832 0.01683976 0.02546553
  0.03486321 0.03556688 0.02876302 0.02522826 0.03778201 0.0308316
  0.03521917 0.01577186 0.01463001 0.03593307 0.03647672 0.03812167
  0.03754918 0.03393116 0.03823742 0.03187745 0.01964514 0.05058247
  0.03319483 0.0307104  0.02478381 0.03428296 0.02053007 0.01312112
  0.02925529 0.05832719]
 [0.03573458 0.02261247 0.02249589 0.01838656 0.01288292 0.01984164
  0.03055223 0.02882017 0.0237892  0.01857739 0.04054891 0.0229717
  0.02963982 0.01223508 0.01098731 0.03296917 0.03840782 0.03147531
  0.04157946 0.03435316 0.03928839 0.03018497 0.01786407 0.06883948
  0.03386499 0.03819973 0.01919234 0.03239924 0.01806651 0.0119952
  0.02640789 0.0440118 ]
 [0.03410763 0.03916287 0.04204757 0.03401292 0.02620916 0.03243075
  0.04538882 0.04910384 0.04472201 0.0327701  0.03624578 0.03276283
  0.037738   0.02194984 0.0201741  0.03447554 0.04845286 0.03945993
  0.047913   0.04216795 0.04342506 0.03683634 0.03595617 0.04291191
  0.03742978 0.04871979 0.03851902 0.05638159 0.02864659 0.01566572
  0.02023744 0.0279674 ]
 [0.03544772 0.02537958 0.02650416 0.02630362 0.01743566 0.02811794
  0.03236395 0.03541563 0.02994489 0.02642914 0.03028841 0.03100267
  0.03102885 0.01865613 0.01569848 0.02404549 0.02631517 0.02561983
  0.03304683 0.03132327 0.03188588 0.03332235 0.02178263 0.03300591
  0.02567814 0.03044851 0.02103938 0.03852577 0.02870095 0.01902613
  0.03419112 0.0429984 ]
 [0.03442265 0.03722266 0.03671943 0.05414563 0.05211316 0.048817
  0.03636085 0.03818398 0.04412983 0.05355315 0.0392487  0.04168006
  0.03933017 0.07103055 0.0932414  0.02823844 0.03041766 0.03191882
  0.02980032 0.02958303 0.0295373  0.03754346 0.04022909 0.01362517
  0.01654392 0.03127873 0.03841827 0.04462366 0.05283925 0.02544421
  0.00958772 0.06093847]
 [0.03403519 0.04832352 0.04248857 0.08030581 0.16748214 0.06076947
  0.04048989 0.04218984 0.04686929 0.08248574 0.0648357  0.0589261
  0.04094555 0.10255348 0.13580988 0.03970451 0.05371386 0.05373511
  0.04081653 0.03617621 0.04487716 0.03692947 0.05093398 0.01307813
  0.01331762 0.03012686 0.0534296  0.04353288 0.05235556 0.02337453
  0.00585653 0.03489647]
 [0.03422472 0.03537972 0.02941541 0.04152929 0.06830548 0.02791833
  0.02751482 0.03061914 0.02969358 0.04210117 0.03934143 0.03334405
  0.02880795 0.0323158  0.04696679 0.03043142 0.05538427 0.05966076
  0.05146034 0.04211076 0.0677962  0.03403581 0.04177597 0.03156595
  0.02473758 0.03440834 0.04157501 0.05362093 0.03294237 0.01519384
  0.00973397 0.01980353]
 [0.0342726  0.03850893 0.03270018 0.04500429 0.04358091 0.03190601
  0.03387692 0.03623147 0.03989749 0.04115208 0.03685269 0.03137366
  0.03200582 0.0337027  0.03955031 0.02590244 0.04118868 0.04465434
  0.03888475 0.04066237 0.04268724 0.04694397 0.04729686 0.0197626
  0.02017776 0.03300654 0.03553018 0.05858859 0.03804802 0.01188331
  0.00682663 0.01595217]]

-* TASK 10/20 | SAMPLE 75/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 373/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no new information about Julie's location since the previous context sentences. The previous information about Julie was that she moved to the park (sentence 2). There is no information that suggests she left the park or went to the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Julie', "'s", ' location', ' since', ' the', ' previous', ' context', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Julie', ' was', ' that', ' she', ' moved', ' to', ' the', ' park', ' (', 'sentence', ' ', '2', ').', ' There', ' is', ' no', ' information', ' that', ' suggests', ' she', ' left', ' the', ' park', ' or', ' went', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 38), x_tokens=38, y_tokens=55, max_supp_attn=0.0, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 38)
DEBUG result.interpretability.attn_scores 2090 
 [[0.01663041 0.02340209 0.02211068 ... 0.00557623 0.00792308 0.0135705 ]
 [0.01687774 0.04543238 0.03779738 ... 0.01277428 0.02360886 0.02142968]
 [0.01745091 0.02261587 0.02433776 ... 0.0043717  0.00730269 0.00975095]
 ...
 [0.0175705  0.02173669 0.02064673 ... 0.00426534 0.00711394 0.00973628]
 [0.01800789 0.01472764 0.01422131 ... 0.00781322 0.01393881 0.01180011]
 [0.01803676 0.01483122 0.01386547 ... 0.00631903 0.01051944 0.01092513]]

-* TASK 10/20 | SAMPLE 75/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 374/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 11 contradicts sentence 10, as it is not possible for Bill to be in both the bedroom and the park at the same time. However, since sentence 11 is the latest information about Bill's location, it is more reliable. Therefore, it is likely that Bill is not in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' contrad', 'icts', ' sentence', ' ', '10', ',', ' as', ' it', ' is', ' not', ' possible', ' for', ' Bill', ' to', ' be', ' in', ' both', ' the', ' bedroom', ' and', ' the', ' park', ' at', ' the', ' same', ' time', '.', ' However', ',', ' since', ' sentence', ' ', '11', ' is', ' the', ' latest', ' information', ' about', ' Bill', "'s", ' location', ',', ' it', ' is', ' more', ' reliable', '.', ' Therefore', ',', ' it', ' is', ' likely', ' that', ' Bill', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(70, 44), x_tokens=44, y_tokens=70, max_supp_attn=0.0857, attn_on_target=0.0143)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (70, 44)
DEBUG result.interpretability.attn_scores 3080 
 [[0.0128352  0.01780296 0.01717731 ... 0.00962701 0.01062315 0.01976224]
 [0.01308022 0.01383794 0.01349561 ... 0.02745386 0.01469778 0.01403073]
 [0.01348676 0.01721794 0.01806789 ... 0.02075646 0.01718888 0.0213824 ]
 ...
 [0.0137077  0.01794998 0.01814987 ... 0.00641678 0.00639742 0.00877817]
 [0.01410984 0.01392723 0.01350118 ... 0.00612381 0.00609157 0.00670855]
 [0.01399272 0.01424745 0.0136906  ... 0.0057001  0.00625626 0.00850961]]

-* TASK 10/20 | SAMPLE 75/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 375/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 13, Bill travelled to the school, which implies that he is now in the school. There is no information that suggests he went to the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Bill', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' he', ' is', ' now', ' in', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' he', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02258717 0.04114611 0.04164856 ... 0.01623371 0.01817929 0.03187466]
 [0.02314877 0.02496912 0.02768623 ... 0.01980168 0.02319174 0.02733607]
 [0.02358137 0.03849908 0.04292558 ... 0.01325067 0.01627845 0.02564281]
 ...
 [0.02376411 0.03638817 0.03487148 ... 0.0143872  0.01409198 0.03681504]
 [0.02426548 0.02676731 0.02379456 ... 0.0166672  0.01875561 0.02804945]
 [0.02420279 0.02860794 0.02534032 ... 0.01437469 0.01600546 0.03551127]]
Model's predictions for the sample 75:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Julie moved to   |
|          |                 |  the park, which implies that she is now   |
|          |                 |                in the park.                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 4, Julie travelled  |
|          |                 |  to the school, which implies that she is  |
|          |                 |             now in the school.             |
+----------+-----------------+--------------------------------------------+
|   yes    |        no       |     There is no new information about      |
|          |                 |    Julie's location since the previous     |
|          |                 |      context sentences. The previous       |
|          |                 |    information about Julie was that she    |
|          |                 |  moved to the park (sentence 2). There is  |
|          |                 |   no information that suggests she left    |
|          |                 |      the park or went to the school.       |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  Sentence 11 contradicts sentence 10, as   |
|          |                 |    it is not possible for Bill to be in    |
|          |                 |    both the bedroom and the park at the    |
|          |                 |  same time. However, since sentence 11 is  |
|          |                 |    the latest information about Bill's     |
|          |                 |       location, it is more reliable.       |
|          |                 |  Therefore, it is likely that Bill is not  |
|          |                 |              in the bedroom.               |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 13, Bill travelled  |
|          |                 |  to the school, which implies that he is   |
|          |                 |       now in the school. There is no       |
|          |                 |  information that suggests he went to the  |
|          |                 |                  kitchen.                  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 75:
+----------------------------+------------+
|           Metric           |   Before   |
+----------------------------+------------+
|    Exact-match accuracy    |    0.8     |
|    Soft-match accuracy     |    0.8     |
| Max attention distribution | 0.1 ± 0.07 |
+----------------------------+------------+

-* TASK 10/20 | SAMPLE 76/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 376/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Fred being in the office, with no information about him being in the park. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' office', ',', ' with', ' no', ' information', ' about', ' him', ' being', ' in', ' the', ' park', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 26), x_tokens=26, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 26)
DEBUG result.interpretability.attn_scores 754 
 [[0.03238208 0.0576026  0.06170363 0.09268656 0.08822151 0.06085343
  0.04535969 0.0387888  0.04324901 0.06097026 0.04693186 0.02968661
  0.03198863 0.13756074 0.13836065 0.04760315 0.03436427 0.02336983
  0.02049863 0.02248386 0.0224374  0.0473994  0.0742374  0.01592239
  0.01247046 0.03987526]
 [0.03340405 0.03610919 0.03646857 0.06895443 0.06274635 0.05256082
  0.03175275 0.0281142  0.03452775 0.05251975 0.04038884 0.03208894
  0.03185524 0.1402586  0.1649345  0.04519023 0.03693424 0.02781791
  0.02272153 0.02340752 0.02120201 0.04019285 0.04450182 0.01101818
  0.01079797 0.02599824]
 [0.0339549  0.04050564 0.04650534 0.07198256 0.07014889 0.06724658
  0.04271989 0.03959484 0.0458272  0.06191453 0.04638166 0.05139866
  0.05001486 0.1120464  0.10250663 0.03777632 0.03396968 0.02842406
  0.02209376 0.02367742 0.02021306 0.03632113 0.04122391 0.01541805
  0.01481616 0.02411852]
 [0.03289617 0.04710909 0.05505    0.0546512  0.0566904  0.06103389
  0.04821858 0.04975538 0.0506738  0.05481028 0.04571128 0.05763021
  0.05142495 0.06641631 0.05899619 0.04744434 0.04169523 0.03675675
  0.02885042 0.03195725 0.0289594  0.04052274 0.05964017 0.03797082
  0.03686212 0.03956408]
 [0.03309704 0.06467438 0.07558235 0.04369234 0.03515228 0.05362108
  0.0603864  0.0597007  0.05738889 0.04331998 0.04121993 0.04954742
  0.05190895 0.02996413 0.02211129 0.04551587 0.03809971 0.03511456
  0.02949578 0.03367276 0.03151201 0.03773576 0.07572439 0.04657792
  0.0418176  0.0496017 ]
 [0.0341692  0.08306315 0.09422874 0.03913954 0.02696535 0.0485431
  0.05865436 0.05096034 0.06029489 0.03650997 0.03344622 0.03941209
  0.03825652 0.02108413 0.01731186 0.05007894 0.03735323 0.03094335
  0.02707173 0.03289298 0.02752527 0.0362593  0.08111279 0.03330029
  0.03348211 0.0405849 ]
 [0.03417667 0.05098549 0.06503095 0.03483762 0.02399858 0.04554617
  0.05461053 0.05196789 0.05431408 0.0345513  0.03232121 0.04028788
  0.03606898 0.01909444 0.01573387 0.04488834 0.03611495 0.03126756
  0.02775317 0.03232009 0.02860868 0.03694686 0.05929221 0.04126569
  0.04653686 0.0528374 ]
 [0.03485094 0.0388821  0.04187166 0.03296845 0.02290589 0.04667298
  0.04609318 0.04915085 0.04359976 0.03529029 0.03490569 0.04539746
  0.03932362 0.01742369 0.01366019 0.03252476 0.0300623  0.03071129
  0.0265752  0.02891532 0.02579698 0.03500982 0.03277348 0.03199933
  0.03351265 0.03588727]
 [0.03432946 0.02937988 0.02810459 0.02209616 0.0169648  0.02751719
  0.03642235 0.0351712  0.02969261 0.02412843 0.03552828 0.02795548
  0.03280292 0.01175037 0.01081862 0.03894733 0.03592318 0.03500551
  0.03267928 0.03555893 0.03852754 0.03384682 0.02892462 0.06915852
  0.05384659 0.0431063 ]
 [0.03443955 0.0232672  0.01967971 0.01834545 0.01375623 0.01862114
  0.02812287 0.02667758 0.02203344 0.01858599 0.02453447 0.01900613
  0.02369326 0.00912935 0.00883045 0.03090525 0.02801692 0.03304291
  0.03562016 0.03973507 0.04854149 0.0302639  0.02220191 0.07853916
  0.05992036 0.0442204 ]
 [0.03482687 0.02423899 0.02042577 0.01852035 0.01508923 0.01981788
  0.02622501 0.02540134 0.02227766 0.01960895 0.02686267 0.02222354
  0.02432716 0.00939537 0.00913755 0.03414909 0.02897613 0.02930159
  0.03074275 0.03161173 0.04075883 0.02998234 0.02084345 0.08306611
  0.05800355 0.03277683]
 [0.03463974 0.02028941 0.01729435 0.01388806 0.0131532  0.01548096
  0.0238297  0.02157949 0.01990271 0.01548291 0.02887669 0.01820558
  0.02208119 0.00745352 0.00780308 0.03491297 0.03567651 0.03108285
  0.03956988 0.03728599 0.04792443 0.02876044 0.02136965 0.08889697
  0.05172319 0.03792158]
 [0.03399793 0.02516394 0.02037502 0.01569186 0.01481265 0.01752478
  0.02587037 0.02211822 0.02323157 0.01670259 0.02736364 0.01840225
  0.02230858 0.00813052 0.0088989  0.03485234 0.03305355 0.02990563
  0.03545735 0.03739784 0.0447519  0.03326317 0.02819746 0.09370961
  0.06588635 0.07820329]
 [0.0350503  0.02180367 0.0186738  0.01573779 0.01423079 0.01713677
  0.02185317 0.02119155 0.02033213 0.01708235 0.02635591 0.01911173
  0.02067872 0.00843278 0.00837291 0.02865018 0.02795249 0.02530749
  0.03063722 0.02958641 0.03786781 0.02982718 0.02233471 0.05469715
  0.0473722  0.04604615]
 [0.03563265 0.02324086 0.0236394  0.02068633 0.0173381  0.02594598
  0.02780212 0.03172358 0.0293894  0.02569537 0.02678014 0.03226977
  0.02974265 0.01212076 0.00966977 0.02272008 0.02792276 0.02716737
  0.02684534 0.02760519 0.02546807 0.03204636 0.0205452  0.0218979
  0.03844568 0.03359909]
 [0.03548146 0.03068925 0.02513761 0.02140361 0.0186167  0.02545758
  0.03252618 0.0365338  0.02929597 0.02395223 0.02805863 0.02874416
  0.03144238 0.012186   0.01008564 0.02404091 0.02917095 0.02790964
  0.02722913 0.03183595 0.03309591 0.03319507 0.0228325  0.02510414
  0.05591249 0.04074482]
 [0.03518211 0.03725367 0.03207647 0.02631151 0.02147313 0.03279482
  0.03913236 0.04973756 0.03966282 0.03261144 0.03732077 0.05029782
  0.04929204 0.01517089 0.01143689 0.0340352  0.03027275 0.03820281
  0.03413235 0.03807259 0.03059448 0.03279671 0.02448921 0.01873709
  0.03233238 0.02453565]
 [0.03576808 0.03154786 0.03327422 0.02964175 0.022055   0.04791258
  0.04048071 0.04791711 0.04457334 0.03976871 0.03382267 0.0761242
  0.06108467 0.01826088 0.0116593  0.02474672 0.02679427 0.02909616
  0.02592127 0.02783361 0.02314325 0.03205692 0.02120561 0.01336993
  0.02160582 0.01806957]
 [0.03498222 0.02291693 0.02268323 0.01796561 0.01447714 0.01992504
  0.02813376 0.03034179 0.02610806 0.02146498 0.03145972 0.02604879
  0.03458776 0.00995929 0.00895302 0.03290526 0.03175122 0.03973341
  0.0404236  0.04365864 0.04437654 0.03150653 0.01766495 0.02842098
  0.0355031  0.02521531]
 [0.03515198 0.02438729 0.02132612 0.0175045  0.01404489 0.01757667
  0.0282318  0.02905047 0.02418876 0.0188614  0.02814116 0.02304786
  0.02990272 0.00908151 0.00836263 0.03917608 0.03027046 0.04573745
  0.03871752 0.05224933 0.04894686 0.02843545 0.01714657 0.02965894
  0.04635901 0.026474  ]
 [0.03561728 0.02337355 0.01990505 0.01760167 0.01491996 0.01854783
  0.02476531 0.02774408 0.02483618 0.02149235 0.03063442 0.02703612
  0.02927517 0.00961789 0.0085964  0.03342307 0.03028037 0.03440231
  0.03624658 0.03601157 0.03887572 0.0270946  0.01544512 0.02008712
  0.0299018  0.01901243]
 [0.03527981 0.01953813 0.01738977 0.01370785 0.01250937 0.01486059
  0.02373771 0.02343696 0.02253334 0.01651613 0.03155528 0.01992417
  0.02352303 0.00767605 0.00738883 0.03117474 0.03575581 0.03322636
  0.0479564  0.04333623 0.04572663 0.02692887 0.01589746 0.02641168
  0.03177369 0.02615417]
 [0.03408773 0.02275302 0.01957009 0.0162837  0.0149653  0.01699691
  0.02335402 0.02257471 0.02561636 0.01897088 0.02746644 0.0201479
  0.02342521 0.00916487 0.00918355 0.03160913 0.03837916 0.03989953
  0.06087713 0.06043359 0.05500946 0.03062254 0.02320673 0.0288788
  0.03236831 0.04043431]
 [0.03547889 0.0236565  0.0217301  0.02039129 0.01605951 0.02162371
  0.02660749 0.02711213 0.02917632 0.02370077 0.03027969 0.02809605
  0.02930692 0.01260351 0.01078183 0.02451957 0.02880915 0.03192529
  0.04349345 0.04129883 0.03711363 0.03160162 0.01925775 0.01675709
  0.02411186 0.02463693]
 [0.03484964 0.03196057 0.0323688  0.03971196 0.03234421 0.04182284
  0.03849692 0.04000061 0.04118875 0.04557972 0.03777685 0.05858058
  0.05397708 0.0296568  0.01811059 0.02509706 0.0334977  0.0379158
  0.02936995 0.02798694 0.02511482 0.03806153 0.0272814  0.01846386
  0.02992066 0.02789529]
 [0.0343387  0.04011049 0.03619552 0.05947784 0.06359572 0.051337
  0.03450876 0.03101349 0.03597664 0.05511135 0.0411374  0.03284264
  0.03427398 0.09735318 0.11131299 0.03342403 0.032211   0.0261884
  0.02192735 0.02305833 0.02085793 0.0403486  0.04021767 0.01118665
  0.01056533 0.02560044]
 [0.03398355 0.03869574 0.03505563 0.06486098 0.12746651 0.0467384
  0.02996988 0.02953712 0.03540954 0.06510485 0.04718379 0.03768228
  0.03088216 0.0911355  0.11225648 0.03663644 0.04988627 0.04533841
  0.03337019 0.02810562 0.02842764 0.03486621 0.03875979 0.01017834
  0.01028464 0.02385666]
 [0.03388224 0.02908718 0.02690582 0.0418744  0.06926627 0.02996256
  0.02236999 0.02556173 0.02981718 0.04986998 0.03911615 0.03689294
  0.031356   0.03135075 0.03506961 0.02802457 0.05672771 0.06998777
  0.07918306 0.04238264 0.0436887  0.02979196 0.03305468 0.01625385
  0.0194977  0.02669723]
 [0.0340688  0.0377142  0.03174759 0.04938466 0.06603201 0.03632076
  0.02976412 0.02754257 0.03488177 0.04982208 0.03843854 0.03191074
  0.03119466 0.03652176 0.03965585 0.02502808 0.04007799 0.04521795
  0.04453974 0.03562772 0.03493352 0.05431519 0.05061738 0.01305348
  0.0143693  0.02633208]]

-* TASK 10/20 | SAMPLE 76/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 377/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 5 explicitly states that Mary is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.1905, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.04504202 0.05743419 0.06189812 0.08386311 0.06975099 0.06541966
  0.05235682 0.05643199 0.06747538 0.06727321 0.04927963 0.04520042
  0.05384713 0.13256948 0.12044566 0.04137346 0.0295949  0.03295944
  0.02957922 0.03618991 0.03201482 0.04763551 0.06433699 0.0328654
  0.02123173 0.05451141 0.06208517 0.05891291 0.12431005 0.01800715
  0.02181773 0.08467193]
 [0.04613423 0.05762478 0.05316585 0.09418438 0.09199438 0.10811514
  0.06434266 0.06624763 0.07286534 0.09025812 0.07358929 0.07956509
  0.08733816 0.16743898 0.12106323 0.04591005 0.02890254 0.0398804
  0.03280342 0.03982658 0.03456336 0.05371783 0.05149001 0.02864239
  0.02483128 0.04659196 0.05350987 0.05278828 0.11405684 0.02447292
  0.03322962 0.0991736 ]
 [0.04713073 0.05353595 0.05903234 0.08428326 0.07002738 0.0792323
  0.05547528 0.05875633 0.06542219 0.07051205 0.05357591 0.06089717
  0.06454534 0.13802013 0.09239332 0.03973313 0.02785195 0.03155758
  0.02807836 0.03257762 0.02868226 0.04705213 0.04629314 0.02976117
  0.0233672  0.03992382 0.04791877 0.04325637 0.09516385 0.03023554
  0.03907069 0.08404923]
 [0.04542156 0.06650125 0.07042413 0.05319192 0.04026629 0.05385343
  0.05976971 0.06733444 0.06143152 0.04976226 0.0460222  0.05423773
  0.05724278 0.03820194 0.03355248 0.05378826 0.04124529 0.04146681
  0.03780145 0.04345106 0.03928072 0.05224016 0.0725073  0.06374434
  0.06011225 0.06022647 0.06678443 0.05485641 0.08446699 0.09683768
  0.07865749 0.05924901]
 [0.04627912 0.06951538 0.06823913 0.03505529 0.02513286 0.04043357
  0.05534197 0.05487979 0.05622993 0.03250482 0.037379   0.03891109
  0.04643011 0.0234861  0.0226147  0.04962775 0.03454363 0.033812
  0.03584109 0.04062904 0.037282   0.04887445 0.07038812 0.05746443
  0.05120808 0.05720732 0.07271854 0.04094815 0.06869186 0.12247272
  0.07484598 0.03512004]
 [0.04733792 0.08867658 0.08196945 0.03704352 0.02621298 0.04176695
  0.05755822 0.05295474 0.06382915 0.03321364 0.03602761 0.03881047
  0.04183391 0.0212243  0.02158751 0.05894799 0.03880176 0.03836763
  0.0391702  0.04774019 0.04082414 0.04570115 0.09634165 0.05924878
  0.05020433 0.0543048  0.0686024  0.03682404 0.04792643 0.12641853
  0.06032524 0.02833864]
 [0.04753586 0.0623189  0.06516865 0.0372611  0.02714607 0.03843868
  0.05839616 0.05499879 0.05631604 0.03428722 0.03711489 0.04045971
  0.04156175 0.02285141 0.02351179 0.05964237 0.04306869 0.03824807
  0.04240314 0.04615722 0.04114713 0.04913293 0.07550308 0.0763552
  0.06693245 0.0577405  0.08492977 0.04070719 0.04035361 0.09687585
  0.0684051  0.03333136]
 [0.04851593 0.03627004 0.03964488 0.02690732 0.0213201  0.02825061
  0.03652646 0.03757021 0.04664749 0.02720937 0.03006299 0.02732126
  0.03087117 0.01626346 0.01946722 0.04649982 0.03646099 0.03350529
  0.03988809 0.04398888 0.03650125 0.04107062 0.04859423 0.06389848
  0.05409304 0.04754335 0.04946233 0.03096638 0.02566527 0.0364772
  0.03184345 0.02246827]
 [0.04761901 0.04765771 0.05105839 0.03696349 0.02713039 0.04392205
  0.04860991 0.05110902 0.04413146 0.03701126 0.04108763 0.04637895
  0.04260715 0.02007544 0.02239427 0.05341283 0.04891767 0.04281756
  0.04612082 0.04822801 0.04480843 0.05378968 0.04781124 0.06758048
  0.06945182 0.04945949 0.04757576 0.03750186 0.03493827 0.06571258
  0.06478886 0.02612909]
 [0.04843342 0.05809772 0.06151353 0.05737094 0.03700633 0.06183816
  0.06134799 0.07208625 0.05624877 0.06298666 0.0608259  0.08523914
  0.07142566 0.0343579  0.02855969 0.05054482 0.0473832  0.05060406
  0.04714957 0.04910242 0.04468022 0.05214991 0.04383672 0.05198075
  0.05689159 0.04352782 0.04620371 0.04347393 0.03903634 0.06844001
  0.0854715  0.03905251]
 [0.04926323 0.04200182 0.04473133 0.03953693 0.0288084  0.0436981
  0.05064048 0.04790413 0.03981249 0.04013369 0.04912335 0.04980582
  0.04792318 0.02235135 0.0223704  0.04679824 0.04740669 0.04214608
  0.04553019 0.04590478 0.04264699 0.05110508 0.03383341 0.05171125
  0.05950734 0.03737454 0.03448986 0.03608035 0.03056758 0.04743093
  0.06656734 0.03390398]
 [0.04850709 0.03096004 0.02958518 0.02475404 0.01917946 0.02851074
  0.03638364 0.0329136  0.02972953 0.02695326 0.04021605 0.03348107
  0.03628641 0.01354903 0.01631179 0.04600053 0.05903124 0.04540296
  0.05464419 0.04986463 0.05010766 0.04835646 0.02700247 0.0521604
  0.0807158  0.03882913 0.02834994 0.03376432 0.02234171 0.03605639
  0.04822462 0.02501016]
 [0.04813445 0.03060533 0.02722029 0.02304841 0.01733875 0.02706712
  0.0363027  0.03201718 0.02828988 0.02549682 0.03634235 0.02915324
  0.03523083 0.01235658 0.01434603 0.04529332 0.06674062 0.0514003
  0.06585066 0.05829532 0.06699403 0.04445165 0.02318008 0.05694587
  0.1027718  0.04984605 0.02601746 0.03748538 0.01691831 0.03907055
  0.04701456 0.02120213]
 [0.04908926 0.03038121 0.02846709 0.02363112 0.01944802 0.0286365
  0.03537192 0.03351914 0.02892763 0.02782506 0.04567884 0.03862888
  0.03721735 0.01304    0.0147068  0.04748556 0.07393969 0.04859571
  0.07125378 0.05463182 0.05453081 0.04245872 0.02175028 0.05008003
  0.05381552 0.03775443 0.02673778 0.03659434 0.01586684 0.0337762
  0.04442356 0.02463178]
 [0.0489241  0.02837474 0.02699698 0.01953713 0.01727602 0.02498437
  0.03726918 0.03175275 0.0277786  0.02414127 0.05418998 0.03513493
  0.03769553 0.01090257 0.013266   0.06125062 0.0684683  0.05466671
  0.06806554 0.05834898 0.06034369 0.04124805 0.02241305 0.0531567
  0.05066632 0.05059917 0.02130104 0.04224137 0.01440209 0.0346139
  0.03925551 0.02642046]
 [0.04723317 0.03426357 0.03217803 0.02501663 0.0221395  0.03187346
  0.04638651 0.04166094 0.03887874 0.03023091 0.03908255 0.0345717
  0.04323541 0.01419014 0.01663619 0.05270177 0.04125997 0.04831499
  0.05869993 0.0585807  0.05764066 0.04526831 0.03263232 0.05218899
  0.04641532 0.06126285 0.02955048 0.06190328 0.0257737  0.03519911
  0.04602593 0.03732149]
 [0.04937759 0.03288534 0.03566721 0.03158903 0.02424093 0.03891931
  0.04180166 0.04655025 0.03817371 0.03814434 0.04416678 0.04566767
  0.04361439 0.01945486 0.01918827 0.03686704 0.03320706 0.040577
  0.04469184 0.04287544 0.0436258  0.04292461 0.02651523 0.03062885
  0.03177946 0.0394223  0.02991064 0.04209402 0.02714984 0.03285433
  0.0762827  0.05853374]
 [0.04778387 0.04014535 0.04221137 0.0690402  0.05874004 0.05857192
  0.04215874 0.04257322 0.05103911 0.07018869 0.05021724 0.05304185
  0.05175124 0.08653969 0.10784835 0.03483524 0.03317064 0.04230637
  0.03497069 0.03870826 0.03715462 0.04681409 0.04446226 0.02593933
  0.02074813 0.04447255 0.04785017 0.05801233 0.05667153 0.0163068
  0.02522822 0.12178047]
 [0.04739762 0.04738947 0.04220206 0.08045687 0.16842405 0.06742144
  0.04430833 0.04093904 0.04567337 0.08348811 0.0651904  0.06324612
  0.0454712  0.10850511 0.15212728 0.04773841 0.05368729 0.06971987
  0.04813849 0.04787678 0.05493598 0.04538103 0.05229428 0.02578723
  0.01869077 0.04388605 0.06688733 0.05574745 0.05062852 0.01122725
  0.01351904 0.06784388]
 [0.04724599 0.0403924  0.03795922 0.05664568 0.10777274 0.03920529
  0.03532669 0.03701755 0.03528902 0.0634549  0.05819794 0.05104217
  0.03959303 0.0373839  0.06268144 0.04716725 0.09117715 0.10595004
  0.07712319 0.06420644 0.09315735 0.04212805 0.04464631 0.03994561
  0.03274499 0.04146172 0.04946233 0.07450099 0.02962702 0.01479091
  0.01806723 0.03433497]
 [0.04759378 0.04496829 0.04066682 0.06061963 0.08064431 0.04984125
  0.044325   0.04078303 0.04581061 0.06492428 0.0526295  0.04920557
  0.04427826 0.04723762 0.05492751 0.03438152 0.05514073 0.06770111
  0.05219617 0.05281592 0.05907806 0.05849956 0.0541677  0.02991429
  0.02382088 0.04405433 0.03965219 0.08134069 0.03544325 0.01272357
  0.01693563 0.03743329]]

-* TASK 10/20 | SAMPLE 76/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 378/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 states that Julie went back to the park, implying that she is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03108088 0.04151713 0.04219762 ... 0.02145892 0.02573328 0.04229637]
 [0.03167826 0.0468533  0.0490161  ... 0.0273158  0.0294084  0.04553761]
 [0.03239778 0.04435334 0.04900349 ... 0.0177282  0.01968351 0.04182189]
 ...
 [0.0325804  0.04708271 0.04394324 ... 0.01680443 0.01765697 0.05173956]
 [0.03289298 0.03529632 0.03160722 ... 0.02696836 0.02616097 0.05057739]
 [0.03279987 0.04220536 0.03565194 ... 0.02135029 0.02418665 0.03985503]]

-* TASK 10/20 | SAMPLE 76/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 379/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that Mary went to the kitchen, implying that she is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Mary', ' went', ' to', ' the', ' kitchen', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03231339 0.04726502 0.04610258 ... 0.01512517 0.06384047 0.06862215]
 [0.03305551 0.04254421 0.04257971 ... 0.03249582 0.02731373 0.03069132]
 [0.03370772 0.05024458 0.0543254  ... 0.02840806 0.0643221  0.05268666]
 ...
 [0.03391874 0.04846538 0.04580779 ... 0.01148    0.11192925 0.05997369]
 [0.03443068 0.03527084 0.03116853 ... 0.0133154  0.08883334 0.03597661]
 [0.0340855  0.04018144 0.03544406 ... 0.01005531 0.08329877 0.06494893]]

-* TASK 10/20 | SAMPLE 76/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 380/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences 13 and 14 do not provide any information about Mary's location. However, we can refer to a previous context sentence (10) which states that Mary is in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' to', ' a', ' previous', ' context', ' sentence', ' (', '10', ')', ' which', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 50), x_tokens=50, y_tokens=47, max_supp_attn=0.0851, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 50)
DEBUG result.interpretability.attn_scores 2350 
 [[0.01975948 0.0239177  0.02273756 ... 0.02479843 0.02544222 0.06714801]
 [0.02023258 0.01988371 0.01910995 ... 0.01721911 0.0185485  0.04223939]
 [0.02064696 0.02479272 0.02477123 ... 0.01982725 0.01564846 0.0519674 ]
 ...
 [0.02093343 0.02018012 0.02109697 ... 0.02762562 0.02076378 0.02472072]
 [0.02161398 0.01334141 0.01426681 ... 0.02840318 0.02906762 0.01445518]
 [0.02138091 0.01639685 0.01713848 ... 0.02187037 0.03002123 0.01854725]]
Model's predictions for the sample 76:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentences only mention Fred   |
|          |                 |  being in the office, with no information  |
|          |                 |        about him being in the park.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 5 explicitly states  |
|          |                 |        that Mary is in the cinema.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 8 states that Julie  |
|          |                 |  went back to the park, implying that she  |
|          |                 |         is currently in the park.          |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 11 states that Mary  |
|          |                 |   went to the kitchen, implying that she   |
|          |                 |        is currently in the kitchen.        |
+----------+-----------------+--------------------------------------------+
|    no    |       yes       |   The context sentences 13 and 14 do not   |
|          |                 |    provide any information about Mary's    |
|          |                 |    location. However, we can refer to a    |
|          |                 |    previous context sentence (10) which    |
|          |                 |     states that Mary is in the school.     |
+----------+-----------------+--------------------------------------------+

Metrics for sample 76:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 77/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 381/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 2 explicitly states that "Bill is in the office". This contradicts the information in sentence 1, which implies that Bill was in the park at some point. However, sentence 2 provides the most up-to-date information about Bill's location, which is the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' "', 'Bill', ' is', ' in', ' the', ' office', '".', ' This', ' contrad', 'icts', ' the', ' information', ' in', ' sentence', ' ', '1', ',', ' which', ' implies', ' that', ' Bill', ' was', ' in', ' the', ' park', ' at', ' some', ' point', '.', ' However', ',', ' sentence', ' ', '2', ' provides', ' the', ' most', ' up', '-to', '-date', ' information', ' about', ' Bill', "'s", ' location', ',', ' which', ' is', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(70, 26), x_tokens=26, y_tokens=70, max_supp_attn=0.1571, attn_on_target=0.0143)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (70, 26)
DEBUG result.interpretability.attn_scores 1820 
 [[0.01289887 0.02349116 0.02680139 ... 0.00993304 0.00670908 0.01417257]
 [0.01276498 0.04234466 0.03342036 ... 0.02036672 0.0146738  0.01961824]
 [0.01403861 0.03129816 0.01851144 ... 0.00497913 0.00289565 0.00666961]
 ...
 [0.01384882 0.0142893  0.01423018 ... 0.00522755 0.00288663 0.00898956]
 [0.01387777 0.01157056 0.01116535 ... 0.00799349 0.00623398 0.01361516]
 [0.01395409 0.01509282 0.01323174 ... 0.00686835 0.00483744 0.01006349]]

-* TASK 10/20 | SAMPLE 77/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 382/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that "Fred is in the school", but sentence 5 updates the information by saying "Fred went to the cinema". This implies that Fred's location has changed from the school to the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' "', 'Fred', ' is', ' in', ' the', ' school', '",', ' but', ' sentence', ' ', '5', ' updates', ' the', ' information', ' by', ' saying', ' "', 'Fred', ' went', ' to', ' the', ' cinema', '".', ' This', ' implies', ' that', ' Fred', "'s", ' location', ' has', ' changed', ' from', ' the', ' school', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0962, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01769499 0.02914623 0.03122722 ... 0.04696664 0.00635709 0.01404922]
 [0.01815826 0.02880324 0.03158275 ... 0.05178679 0.00967966 0.01968541]
 [0.01851718 0.02645093 0.03202543 ... 0.05034127 0.01428351 0.02420716]
 ...
 [0.0185428  0.02824875 0.02836318 ... 0.01873075 0.00572619 0.00953403]
 [0.01898411 0.01959501 0.01849449 ... 0.00967278 0.00763411 0.00872384]
 [0.01893607 0.02311729 0.02145361 ... 0.00926729 0.00516137 0.00901132]]

-* TASK 10/20 | SAMPLE 77/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 383/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the cinema. The context sentences only mention Fred being in the bedroom (sentence 8) and Julie travelling to the park (sentence 7).

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' bedroom', ' (', 'sentence', ' ', '8', ')', ' and', ' Julie', ' travelling', ' to', ' the', ' park', ' (', 'sentence', ' ', '7', ').\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02048126 0.03061547 0.02953148 ... 0.01783662 0.01985519 0.00978971]
 [0.02082041 0.03087204 0.02926851 ... 0.02440401 0.02397164 0.01689754]
 [0.02142225 0.0310852  0.03309451 ... 0.0268113  0.02521184 0.01267088]
 ...
 [0.02147382 0.03154441 0.02720582 ... 0.01252259 0.01384482 0.0091291 ]
 [0.02189714 0.02460895 0.0200011  ... 0.01418303 0.0142036  0.01291671]
 [0.02187348 0.02672866 0.02266369 ... 0.0137415  0.01582844 0.01332036]]

-* TASK 10/20 | SAMPLE 77/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 384/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary being in the cinema. The context sentences only mention Mary travelling to the office (sentence 10) and then moving to the bedroom (sentence 11), but do not mention the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' travelling', ' to', ' the', ' office', ' (', 'sentence', ' ', '10', ')', ' and', ' then', ' moving', ' to', ' the', ' bedroom', ' (', 'sentence', ' ', '11', '),', ' but', ' do', ' not', ' mention', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 44), x_tokens=44, y_tokens=52, max_supp_attn=0.0192, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 44)
DEBUG result.interpretability.attn_scores 2288 
 [[0.01777838 0.02755596 0.02690227 ... 0.01741849 0.01463596 0.01891837]
 [0.01821627 0.02344861 0.02005344 ... 0.01707524 0.01928031 0.02377381]
 [0.01862544 0.02785167 0.0290407  ... 0.01556816 0.01254263 0.01788762]
 ...
 [0.01874526 0.02579548 0.02469195 ... 0.015384   0.01193433 0.02054863]
 [0.01902473 0.01962943 0.01743318 ... 0.01619704 0.0149237  0.01903573]
 [0.01895661 0.02180894 0.0187551  ... 0.01620206 0.0145201  0.01789186]]

-* TASK 10/20 | SAMPLE 77/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 385/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the park. The context sentences only mention Fred being either in the school or the bedroom (sentence 14), but do not mention the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' either', ' in', ' the', ' school', ' or', ' the', ' bedroom', ' (', 'sentence', ' ', '14', '),', ' but', ' do', ' not', ' mention', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 50), x_tokens=50, y_tokens=45, max_supp_attn=0.0, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 50)
DEBUG result.interpretability.attn_scores 2250 
 [[0.02064277 0.03613074 0.03890732 ... 0.01260299 0.00884505 0.01601165]
 [0.02096113 0.03477969 0.03611901 ... 0.02144352 0.01908321 0.0180929 ]
 [0.02160168 0.03388816 0.03909218 ... 0.01918661 0.01533946 0.02517446]
 ...
 [0.02162825 0.039149   0.03391994 ... 0.00933387 0.0082558  0.01077362]
 [0.02212926 0.0276101  0.02273204 ... 0.01236624 0.01033595 0.01290141]
 [0.02196264 0.03282381 0.02626364 ... 0.00897237 0.00800944 0.01084676]]
Model's predictions for the sample 77:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 2 explicitly states  |
|          |                 |     that "Bill is in the office". This     |
|          |                 |  contradicts the information in sentence   |
|          |                 |   1, which implies that Bill was in the    |
|          |                 |  park at some point. However, sentence 2   |
|          |                 |  provides the most up-to-date information  |
|          |                 |    about Bill's location, which is the     |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 4 states that "Fred  |
|          |                 |     is in the school", but sentence 5      |
|          |                 |  updates the information by saying "Fred   |
|          |                 |   went to the cinema". This implies that   |
|          |                 |    Fred's location has changed from the    |
|          |                 |           school to the cinema.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Fred being in the cinema. The context    |
|          |                 |  sentences only mention Fred being in the  |
|          |                 |       bedroom (sentence 8) and Julie       |
|          |                 |    travelling to the park (sentence 7).    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Mary being in the cinema. The context    |
|          |                 |   sentences only mention Mary travelling   |
|          |                 |    to the office (sentence 10) and then    |
|          |                 |  moving to the bedroom (sentence 11), but  |
|          |                 |         do not mention the cinema.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |    Fred being in the park. The context     |
|          |                 |  sentences only mention Fred being either  |
|          |                 |   in the school or the bedroom (sentence   |
|          |                 |     14), but do not mention the park.      |
+----------+-----------------+--------------------------------------------+

Metrics for sample 77:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.08 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 78/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 386/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, "Julie went back to the school", which implies that Julie was in the school previously and now she has returned to the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' "', 'Jul', 'ie', ' went', ' back', ' to', ' the', ' school', '",', ' which', ' implies', ' that', ' Julie', ' was', ' in', ' the', ' school', ' previously', ' and', ' now', ' she', ' has', ' returned', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 26), x_tokens=26, y_tokens=44, max_supp_attn=0.1364, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 26)
DEBUG result.interpretability.attn_scores 1144 
 [[0.0206504  0.04360321 0.0538764  ... 0.02275236 0.01302854 0.01998185]
 [0.02066742 0.07032692 0.05060589 ... 0.03536644 0.01930664 0.02600641]
 [0.0226057  0.05335534 0.03272482 ... 0.00499049 0.00372987 0.0097051 ]
 ...
 [0.02232558 0.02637294 0.02626641 ... 0.00621393 0.00430466 0.01329781]
 [0.02226575 0.02109225 0.02128389 ... 0.01585864 0.00967909 0.01639463]
 [0.02241504 0.02703251 0.02540821 ... 0.01114295 0.00702794 0.0154153 ]]

-* TASK 10/20 | SAMPLE 78/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 387/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 5 explicitly states "Julie is in the bedroom", which directly answers the question.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' "', 'Jul', 'ie', ' is', ' in', ' the', ' bedroom', '",', ' which', ' directly', ' answers', ' the', ' question', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 32), x_tokens=32, y_tokens=26, max_supp_attn=0.1154, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 32)
DEBUG result.interpretability.attn_scores 832 
 [[0.03592081 0.05098401 0.04795558 0.05726894 0.06582718 0.05999107
  0.04360957 0.0388088  0.05285358 0.05196397 0.0367104  0.03722427
  0.04227782 0.09967097 0.09983452 0.04047997 0.03102792 0.03143941
  0.03164978 0.03358356 0.030528   0.04001108 0.07244578 0.01432048
  0.02697249 0.0484225  0.0419112  0.04480668 0.12250687 0.04610556
  0.0147278  0.01395786]
 [0.03697946 0.04843464 0.04634361 0.07052027 0.0915198  0.08560937
  0.04793429 0.04252452 0.05562906 0.07319405 0.05375264 0.05774055
  0.0599626  0.14713745 0.13097274 0.04435839 0.03288974 0.03765571
  0.03404596 0.03451758 0.03160798 0.04145123 0.05106083 0.0136844
  0.02137706 0.04176624 0.04802749 0.03756313 0.09128742 0.06202512
  0.01716283 0.02265815]
 [0.03764084 0.0439258  0.04708738 0.05668269 0.06751972 0.0652612
  0.04605906 0.04085285 0.05113507 0.05565606 0.04091568 0.05207646
  0.05278525 0.10180924 0.07961098 0.03783348 0.02958369 0.03114302
  0.03049445 0.03070817 0.02755272 0.03911519 0.0475636  0.01618016
  0.02467974 0.03701383 0.0429597  0.03145137 0.06221467 0.08037002
  0.02412475 0.03232366]
 [0.03641554 0.04664273 0.04559127 0.03337348 0.03682506 0.04146422
  0.04320813 0.04314514 0.04186853 0.03360627 0.03434348 0.03992998
  0.04241141 0.028702   0.02771222 0.0408293  0.03259557 0.03254262
  0.03389297 0.03528307 0.03220987 0.0420781  0.05267992 0.03307557
  0.04594341 0.04385072 0.04127044 0.03503405 0.04528289 0.10405343
  0.04043445 0.05078295]
 [0.03750815 0.04606822 0.04690001 0.02554761 0.02448283 0.03300418
  0.045574   0.03522922 0.03969241 0.02478814 0.03004134 0.02845729
  0.03155474 0.01879095 0.01980696 0.04439345 0.03237827 0.02939677
  0.03475581 0.03581827 0.03218426 0.03469    0.05071582 0.03089201
  0.04472439 0.03917983 0.04051319 0.02650391 0.0311727  0.09403376
  0.04711681 0.04700291]
 [0.03848996 0.0201744  0.0204349  0.0133899  0.01318366 0.01843512
  0.02166633 0.01830831 0.0222188  0.01492024 0.02069158 0.01627635
  0.01946719 0.01012626 0.01097288 0.02578139 0.02098191 0.02178088
  0.02645919 0.02704671 0.02524933 0.0238611  0.02323013 0.02596256
  0.03427595 0.02982047 0.01855277 0.01852417 0.0176695  0.03714909
  0.02666678 0.02370991]
 [0.03758027 0.03824741 0.03895461 0.02450515 0.02205742 0.03414343
  0.0379932  0.03391792 0.03278354 0.02583792 0.03131113 0.03200428
  0.03158718 0.01718552 0.01936214 0.04158553 0.03935327 0.03386162
  0.04034127 0.04013843 0.03954007 0.04542096 0.04614232 0.04826696
  0.05585146 0.04384752 0.03535802 0.03202423 0.03484232 0.06687639
  0.06366173 0.05541956]
 [0.03851741 0.05441737 0.05531598 0.04090517 0.03185017 0.0513816
  0.05364544 0.05235836 0.04604917 0.04594674 0.04896615 0.06356256
  0.05501613 0.02829    0.02646996 0.0485663  0.04368447 0.04451504
  0.04378254 0.04274623 0.04070286 0.04515133 0.04736931 0.05477267
  0.04577509 0.03936526 0.03963943 0.03661173 0.03868723 0.05104857
  0.04683243 0.06321717]
 [0.03909046 0.03703001 0.03820655 0.02741507 0.02284263 0.03521906
  0.04235137 0.03525125 0.03251246 0.0284914  0.03820762 0.03365622
  0.03687334 0.01882778 0.0205197  0.0443392  0.03926606 0.03599958
  0.03997678 0.03825109 0.03840204 0.04280378 0.03621112 0.04733308
  0.05029324 0.03218789 0.03104749 0.03179044 0.03009096 0.05829418
  0.08464773 0.06662577]
 [0.03899643 0.02774899 0.0255497  0.0199239  0.0168208  0.02395973
  0.03203301 0.02424825 0.02464113 0.01905234 0.04073669 0.02443175
  0.02584874 0.01270069 0.0173841  0.04108998 0.04323657 0.03606025
  0.04239096 0.0408859  0.04247608 0.03629122 0.02534731 0.04414275
  0.06099151 0.02841377 0.0223973  0.02615013 0.02098997 0.034324
  0.09217262 0.04648997]
 [0.03801271 0.02558092 0.02430962 0.02072332 0.01526784 0.025025
  0.0290557  0.02687687 0.02821991 0.01993237 0.02957595 0.02171551
  0.02842121 0.01345334 0.01441501 0.03097975 0.02620447 0.03269775
  0.03431933 0.03747017 0.03786077 0.03588442 0.02395548 0.03367027
  0.05420366 0.03297596 0.02038766 0.02867147 0.02508469 0.02470652
  0.10802443 0.0289858 ]
 [0.03876405 0.02588869 0.02311245 0.01821418 0.01335621 0.02143267
  0.0367127  0.0312072  0.02448693 0.01760052 0.03552484 0.02167627
  0.03168833 0.0112092  0.01301891 0.04741045 0.05685841 0.04823286
  0.04788979 0.04319265 0.05336125 0.03222297 0.0187532  0.05297508
  0.06298127 0.02736034 0.01357235 0.03032579 0.01820197 0.01329314
  0.06703375 0.02955811]
 [0.03941026 0.02331709 0.02236296 0.01880683 0.014376   0.02231448
  0.02898694 0.0267988  0.02477045 0.01994577 0.03535848 0.02554294
  0.02952806 0.01228524 0.01325803 0.04192759 0.05865888 0.04378795
  0.0540231  0.0422329  0.04781195 0.03107073 0.01794895 0.07005313
  0.04403693 0.02528226 0.0149558  0.03537389 0.01911499 0.01517289
  0.05385605 0.03385867]
 [0.03908037 0.02090109 0.01939792 0.01621028 0.01212121 0.01884939
  0.02764324 0.02400801 0.0226391  0.01675623 0.03603654 0.0203172
  0.02660445 0.01057394 0.01167122 0.04061758 0.05631368 0.04016372
  0.05036809 0.04516233 0.04976616 0.03144448 0.01651591 0.08749197
  0.04355853 0.03264666 0.01268404 0.03475072 0.01743321 0.01104582
  0.04219759 0.02596505]
 [0.03817438 0.0273677  0.0237518  0.01988126 0.01517478 0.02442283
  0.0350828  0.02982382 0.02800852 0.01975591 0.03240825 0.02234337
  0.02925135 0.01311154 0.01399497 0.03359117 0.03467322 0.03391362
  0.04073951 0.04346926 0.04219007 0.0389845  0.03442011 0.17227763
  0.09556513 0.0525355  0.01692175 0.03282623 0.03108798 0.02082551
  0.04224193 0.02851077]
 [0.0395424  0.02360434 0.02289075 0.02079154 0.01499447 0.02340638
  0.02965785 0.02855055 0.02550411 0.02121443 0.03288627 0.02419248
  0.02717505 0.01462145 0.01430438 0.02991123 0.03208411 0.03020533
  0.03556692 0.03911564 0.03824751 0.03349262 0.01902638 0.04915946
  0.0303797  0.02730279 0.01580043 0.02944483 0.0225611  0.02004299
  0.02964647 0.06642869]
 [0.03909573 0.03285287 0.03648732 0.03584212 0.02477752 0.03881731
  0.03990187 0.04416416 0.03938402 0.03979996 0.04134316 0.04604007
  0.04345337 0.02676628 0.02145254 0.03107965 0.03047728 0.03522049
  0.0351113  0.03573593 0.03388917 0.04182971 0.03016337 0.03080294
  0.03371959 0.03443701 0.02828059 0.03449061 0.03402206 0.03725481
  0.03037042 0.0795704 ]
 [0.03949687 0.04036248 0.04561129 0.0494452  0.03082456 0.04857491
  0.04752542 0.05541341 0.04467386 0.05716596 0.04804171 0.05797312
  0.05714776 0.03462883 0.02292297 0.0300548  0.02775513 0.03296813
  0.03027283 0.03114559 0.02853623 0.04017333 0.03297529 0.02649069
  0.02718333 0.03140941 0.03157174 0.02880617 0.03438507 0.03357915
  0.02721433 0.09149294]
 [0.03987631 0.04724972 0.0557937  0.05569566 0.0323019  0.05388055
  0.05026112 0.06582582 0.0537862  0.06812161 0.04858711 0.08639117
  0.06643385 0.0378673  0.02631958 0.03627073 0.03325856 0.03752658
  0.03420233 0.03519301 0.0315542  0.04119135 0.03624056 0.02460582
  0.02677936 0.03495333 0.03812492 0.03612402 0.0326759  0.02879289
  0.02250428 0.04974445]
 [0.03985224 0.04975464 0.05932086 0.06784271 0.03598363 0.03916501
  0.04017321 0.05684684 0.0495036  0.05588165 0.03679463 0.04873525
  0.04039999 0.03433537 0.02868425 0.04150349 0.03599919 0.03536089
  0.03296262 0.03472343 0.03265467 0.04074119 0.03662796 0.01559805
  0.02228601 0.05150126 0.08242439 0.06088382 0.02939341 0.02765313
  0.01899344 0.0297691 ]
 [0.03893505 0.07676669 0.07897481 0.06905145 0.04056883 0.03524125
  0.04771684 0.06788187 0.05435821 0.04612989 0.03712524 0.04668036
  0.03879888 0.03292559 0.02876088 0.04700553 0.03860381 0.03619458
  0.0337456  0.03670211 0.03477279 0.04564368 0.04973612 0.0202252
  0.02447953 0.07107678 0.16251875 0.08465582 0.03017715 0.02465063
  0.01992658 0.02392722]
 [0.03989351 0.04045653 0.04725329 0.04559515 0.03151864 0.03246711
  0.038114   0.04607607 0.0436144  0.04030698 0.03470568 0.03991179
  0.03634473 0.02923369 0.02484743 0.03759662 0.03496221 0.0342932
  0.03306724 0.03532681 0.0322167  0.03937802 0.03384783 0.01588865
  0.02105105 0.03974571 0.06186198 0.05728721 0.02878935 0.02900188
  0.02149596 0.03698807]
 [0.03830544 0.03644353 0.03569921 0.04956032 0.04947362 0.0532399
  0.03752857 0.03726927 0.0474394  0.05238388 0.04092411 0.04265004
  0.04653537 0.07467698 0.08341784 0.03320743 0.031158   0.03938289
  0.03406846 0.03728491 0.03349219 0.03935413 0.04390622 0.01432498
  0.02531406 0.040513   0.0350959  0.04214212 0.053549   0.02969267
  0.01472973 0.01687754]
 [0.03790367 0.04406942 0.03600959 0.06262404 0.14796913 0.05200005
  0.03680376 0.03372772 0.04227639 0.0670227  0.05427488 0.04633007
  0.03698212 0.09825543 0.13922314 0.0467819  0.05441859 0.06199053
  0.04560611 0.04524853 0.04983873 0.03785114 0.05692017 0.01318057
  0.02087209 0.04096538 0.04520235 0.04230236 0.05602512 0.02196588
  0.01282007 0.01089921]
 [0.03820099 0.03409421 0.02691995 0.03882665 0.07729114 0.02882595
  0.0270541  0.02751751 0.03138585 0.04296046 0.04148635 0.03164345
  0.0295147  0.03448613 0.05136522 0.03320676 0.05987471 0.07409988
  0.05810898 0.05261134 0.06995282 0.03372094 0.04398981 0.02702871
  0.03061358 0.03597799 0.03154262 0.04554055 0.03275186 0.01533632
  0.01817309 0.01325668]
 [0.03831664 0.03761648 0.02976484 0.04135711 0.05107117 0.03386824
  0.03370751 0.03336736 0.04056535 0.04156448 0.03924999 0.03249718
  0.03393637 0.03832879 0.03969746 0.02959828 0.04370221 0.04956659
  0.04215809 0.0464064  0.04340154 0.04614281 0.05220656 0.01759628
  0.02609189 0.03744863 0.02737771 0.05591467 0.0400027  0.01270564
  0.01322398 0.0119794 ]]

-* TASK 10/20 | SAMPLE 78/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 388/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 states that "Fred is either in the school or the bedroom", but it does not provide a definitive answer. It only gives two possible locations for Fred.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' "', 'Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' bedroom', '",', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' answer', '.', ' It', ' only', ' gives', ' two', ' possible', ' locations', ' for', ' Fred', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 38), x_tokens=38, y_tokens=41, max_supp_attn=0.0244, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 38)
DEBUG result.interpretability.attn_scores 1558 
 [[0.02238842 0.03605062 0.03384877 ... 0.04105933 0.025172   0.01603785]
 [0.02272329 0.03436006 0.02935476 ... 0.029842   0.02553242 0.02421422]
 [0.02339026 0.03592712 0.03687152 ... 0.03044796 0.02090252 0.01460944]
 ...
 [0.02352527 0.03211925 0.03024422 ... 0.0391716  0.02018991 0.01292975]
 [0.02400971 0.02728085 0.02333919 ... 0.03146914 0.02238747 0.01979865]
 [0.02420993 0.02483009 0.02186673 ... 0.03775716 0.02126192 0.01697727]]

-* TASK 10/20 | SAMPLE 78/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 389/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill being in the cinema in the context sentences. Sentence 11 only mentions two possible locations for Bill: the school or the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '11', ' only', ' mentions', ' two', ' possible', ' locations', ' for', ' Bill', ':', ' the', ' school', ' or', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0256, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02371843 0.0283273  0.03024214 ... 0.09561545 0.01547134 0.01972971]
 [0.02422547 0.02012002 0.02211923 ... 0.06305684 0.02537639 0.02524109]
 [0.02475564 0.02800264 0.03050034 ... 0.07718469 0.02884283 0.03591316]
 ...
 [0.02484329 0.03225646 0.02954708 ... 0.03482083 0.01359147 0.01876123]
 [0.02532863 0.02595881 0.02371669 ... 0.0172375  0.01524505 0.01713657]
 [0.02525545 0.03063315 0.02812697 ... 0.02273029 0.01373053 0.01727992]]

-* TASK 10/20 | SAMPLE 78/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 390/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill in the context sentences. The sentences only talk about Fred's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Fred', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03352072 0.03542244 0.03857857 ... 0.02694734 0.02762135 0.03849322]
 [0.03408842 0.0313272  0.03931801 ... 0.03654735 0.04183882 0.04342825]
 [0.03492894 0.033565   0.04252935 ... 0.02319697 0.02154977 0.02696848]
 ...
 [0.03541255 0.03938879 0.03236109 ... 0.03913337 0.03896776 0.03605836]
 [0.03597568 0.04312693 0.03913993 ... 0.03132813 0.02969901 0.02643143]
 [0.03622454 0.03598665 0.03450392 ... 0.02652277 0.02686829 0.02621371]]
Model's predictions for the sample 78:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    According to sentence 2, "Julie went    |
|          |                 |  back to the school", which implies that   |
|          |                 |   Julie was in the school previously and   |
|          |                 |    now she has returned to the school.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   Sentence 5 explicitly states "Julie is   |
|          |                 |  in the bedroom", which directly answers   |
|          |                 |               the question.                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   Sentence 7 states that "Fred is either   |
|          |                 |   in the school or the bedroom", but it    |
|          |                 |  does not provide a definitive answer. It  |
|          |                 |   only gives two possible locations for    |
|          |                 |                   Fred.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Bill being in the  |
|          |                 |      cinema in the context sentences.      |
|          |                 |   Sentence 11 only mentions two possible   |
|          |                 |   locations for Bill: the school or the    |
|          |                 |                  kitchen.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |     There is no mention of Bill in the     |
|          |                 |   context sentences. The sentences only    |
|          |                 |        talk about Fred's locations.        |
+----------+-----------------+--------------------------------------------+

Metrics for sample 78:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.07 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 79/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 391/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Julie moved to the office, which implies that she is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02797943 0.04925377 0.06110156 0.07568224 0.08307073 0.07565297
  0.06200685 0.07194113 0.05907858 0.06709173 0.04906283 0.06273616
  0.06986237 0.10337643 0.0678051  0.03231088 0.03377811 0.03406838
  0.03112751 0.03411905 0.02665282 0.04016868 0.04539385 0.02200485
  0.01482066 0.02495103]
 [0.02775758 0.08705536 0.06395542 0.05073116 0.03976797 0.05160699
  0.14470664 0.09162353 0.063082   0.04635473 0.06387088 0.04882972
  0.0817721  0.02355478 0.0225492  0.04206701 0.04367077 0.05824209
  0.04572972 0.05575632 0.04567861 0.04629054 0.04798039 0.04324249
  0.02943924 0.03403136]
 [0.03049144 0.06173727 0.03994266 0.05595856 0.04157446 0.03791699
  0.03159033 0.02348564 0.02388396 0.03591743 0.02927865 0.0175376
  0.01914821 0.03202233 0.0419422  0.02375174 0.01497126 0.01368591
  0.0173082  0.01763829 0.01557216 0.04465312 0.05534703 0.00969938
  0.00536847 0.01223089]
 [0.02872141 0.02991577 0.0294557  0.02341404 0.01674548 0.02445452
  0.02401823 0.02325003 0.0267158  0.02313049 0.0260121  0.02402326
  0.02224349 0.01336525 0.0131537  0.03114115 0.03034098 0.03300128
  0.03760598 0.04373208 0.04009872 0.03030219 0.04291152 0.06335052
  0.06943906 0.06279561]
 [0.02899421 0.0440947  0.04992372 0.06929222 0.06275437 0.05026307
  0.03433809 0.03094024 0.03624935 0.04745849 0.03575346 0.02714559
  0.02633942 0.10685202 0.11176258 0.03714671 0.02896269 0.02140998
  0.02243395 0.02404337 0.02185689 0.04000276 0.06531025 0.01692218
  0.00811364 0.02666481]
 [0.02958513 0.02852206 0.03054552 0.05351823 0.04718996 0.04591378
  0.02569172 0.02421041 0.03081938 0.04469154 0.03192986 0.03102232
  0.02868214 0.11646189 0.14053686 0.0367527  0.03247134 0.02574277
  0.02522043 0.02552641 0.02083364 0.03400254 0.03883269 0.01189574
  0.00653254 0.01714932]
 [0.0300199  0.03238287 0.03951918 0.05616252 0.05186734 0.05754391
  0.03390937 0.03334657 0.04028312 0.05231804 0.03711814 0.04871118
  0.04339654 0.09256526 0.08690398 0.03111949 0.02964323 0.02559518
  0.02434123 0.02538186 0.01980721 0.03086622 0.03685198 0.01647798
  0.00908662 0.01685845]
 [0.0290592  0.04093844 0.04923546 0.04254913 0.04474964 0.0505179
  0.03721101 0.0413884  0.04285545 0.04515119 0.03695561 0.05066919
  0.04263453 0.05479307 0.049399   0.04021137 0.03679584 0.03237734
  0.0296001  0.03219213 0.02771484 0.03445215 0.05300156 0.04269416
  0.02827634 0.03426073]
 [0.03022824 0.04325347 0.0535237  0.04961953 0.0447352  0.06027018
  0.04326238 0.04855596 0.0510262  0.05195063 0.03808954 0.05405216
  0.04857581 0.04340284 0.02815235 0.02881398 0.02854262 0.02675427
  0.02594704 0.02816982 0.02196652 0.03509333 0.0405196  0.02142887
  0.01442024 0.0239272 ]
 [0.02960931 0.05108265 0.05589535 0.0298026  0.02355168 0.03815969
  0.04179783 0.04208925 0.04508177 0.03161278 0.02948832 0.038652
  0.03767972 0.01842352 0.01522514 0.04257195 0.03426329 0.02995397
  0.03066712 0.03394662 0.03118849 0.03378354 0.06927921 0.04499048
  0.03629782 0.03838008]
 [0.03012183 0.03863716 0.04651136 0.0250385  0.0207301  0.02859145
  0.04334123 0.03427585 0.04137731 0.02518529 0.0241338  0.027585
  0.02653789 0.01424357 0.0134414  0.04206033 0.03208772 0.02739341
  0.03028935 0.03408605 0.03013727 0.02960704 0.05507833 0.05230208
  0.04123009 0.03839118]
 [0.03065534 0.01341858 0.01615522 0.01138286 0.00974926 0.01427752
  0.01511562 0.01548447 0.02119326 0.01355806 0.01279825 0.01431311
  0.01334278 0.00645361 0.00633076 0.01765289 0.01801362 0.0169792
  0.02091548 0.02334282 0.0230492  0.01652759 0.03182894 0.06401549
  0.06573892 0.06176531]
 [0.03023707 0.02403195 0.02579961 0.01666999 0.01447354 0.02109522
  0.02280401 0.02174906 0.02374737 0.01807438 0.02116623 0.02163894
  0.01998228 0.00940975 0.00976687 0.03558163 0.02589502 0.02533601
  0.02755811 0.0287133  0.02736878 0.02922054 0.03025378 0.05288829
  0.06431407 0.04815869]
 [0.03044136 0.02311225 0.02405485 0.01810942 0.01568709 0.02262521
  0.02435825 0.02639428 0.02500243 0.02113466 0.0243323  0.02800017
  0.02727745 0.01054962 0.00934507 0.03503285 0.03023571 0.03032674
  0.02878825 0.02906841 0.02964757 0.02938101 0.02173388 0.05116755
  0.05051083 0.02834251]
 [0.03001267 0.02026821 0.0177106  0.01487071 0.01217755 0.01617661
  0.02028688 0.02096808 0.01958157 0.01614357 0.02146026 0.01941637
  0.02171422 0.00744264 0.00731879 0.03463858 0.02873899 0.03684332
  0.03212614 0.03438311 0.04373348 0.02738398 0.01714653 0.05117512
  0.09303948 0.04351771]
 [0.03067126 0.01817077 0.01674441 0.014269   0.01232308 0.01659323
  0.01892581 0.02064875 0.01927198 0.01661833 0.02435835 0.02169133
  0.02226357 0.00729423 0.00716795 0.0357225  0.02607688 0.04291994
  0.03358147 0.0385346  0.03572829 0.02321399 0.01388573 0.0340905
  0.06844644 0.0352619 ]
 [0.03064532 0.01646079 0.01473224 0.01166696 0.01000904 0.01372742
  0.01738833 0.01799485 0.01736284 0.01364424 0.02813108 0.0176463
  0.01943647 0.0059372  0.00647725 0.03426943 0.0301021  0.03566423
  0.03709246 0.03451969 0.03846215 0.02456421 0.01431514 0.03536438
  0.04783513 0.05405609]
 [0.03039119 0.01740233 0.01646559 0.01318943 0.01170849 0.01656492
  0.01809991 0.02077792 0.02065603 0.01530441 0.01966136 0.0193594
  0.0199362  0.00707708 0.00704577 0.02219067 0.02328217 0.02590595
  0.03254864 0.03244708 0.03808336 0.02406522 0.01892949 0.05188705
  0.04840395 0.05560941]
 [0.0310597  0.01960573 0.01842428 0.01470608 0.01183237 0.01678941
  0.01852666 0.02000172 0.01939187 0.01596969 0.02111413 0.01974969
  0.0196503  0.00772183 0.00744006 0.0227734  0.02232091 0.02383695
  0.02980371 0.02702026 0.03059519 0.02584148 0.0159198  0.02560271
  0.02973581 0.03786401]
 [0.03132734 0.02340506 0.02644841 0.0229726  0.01768361 0.02721214
  0.02504322 0.03203337 0.02730311 0.02765438 0.02799089 0.03651522
  0.03133912 0.01351001 0.00983358 0.02162906 0.02283747 0.02522242
  0.0254593  0.02385272 0.02318584 0.02836949 0.01577227 0.01667262
  0.01865317 0.01972646]
 [0.03140433 0.02916027 0.03061391 0.02766531 0.02042581 0.03178895
  0.03215998 0.04180819 0.02981625 0.0329131  0.03750025 0.0446845
  0.04085179 0.0153141  0.01073542 0.02514039 0.02418337 0.02921684
  0.02605017 0.02517016 0.02334219 0.02899345 0.0174642  0.01519804
  0.01639567 0.01467577]
 [0.03130351 0.02700702 0.02706477 0.02498022 0.01954662 0.02849437
  0.0287657  0.03575768 0.02943533 0.0308583  0.03494209 0.03977507
  0.0388375  0.01429892 0.01070218 0.02889845 0.02568347 0.03086388
  0.02775805 0.0272331  0.0252047  0.02931598 0.01552178 0.01845243
  0.0173041  0.01362882]
 [0.03121706 0.01997944 0.0189784  0.01480806 0.01150282 0.01688042
  0.0206407  0.02448549 0.02260462 0.01794284 0.02368593 0.02295846
  0.02586213 0.00797304 0.00728349 0.03038173 0.02799131 0.03033634
  0.02951539 0.02783633 0.03148053 0.02736641 0.01368922 0.0287223
  0.02796573 0.01838726]
 [0.03132359 0.01927571 0.0175747  0.01447588 0.01058996 0.0151401
  0.02000796 0.02172993 0.02079716 0.01633559 0.02272569 0.02029911
  0.02388682 0.00726381 0.00694651 0.02954506 0.02673583 0.03145223
  0.02980214 0.02920328 0.03506127 0.02306407 0.01285236 0.03008328
  0.03263885 0.02139122]
 [0.03144799 0.01979259 0.01797099 0.01552777 0.01192017 0.01648099
  0.02011342 0.02313163 0.02161212 0.0184161  0.02456553 0.022504
  0.0240723  0.00824311 0.00763377 0.02785435 0.03080356 0.02985278
  0.03374036 0.02798088 0.03150532 0.02489359 0.01254474 0.0186039
  0.02076333 0.01808251]
 [0.03149985 0.02268597 0.02081609 0.01687542 0.01232308 0.01841344
  0.02459577 0.02673753 0.02659591 0.01958033 0.02950941 0.0241634
  0.02699746 0.00874614 0.00798337 0.03050576 0.03000055 0.03131424
  0.0330711  0.03023617 0.0328921  0.02596293 0.01315183 0.02032388
  0.02133309 0.01942496]
 [0.03150438 0.01747432 0.01631304 0.01147173 0.00951352 0.01329865
  0.01989462 0.0196202  0.02085787 0.01373496 0.0328504  0.01768101
  0.02152638 0.00653451 0.00584018 0.03145256 0.03450251 0.02981038
  0.0371819  0.03022251 0.03501138 0.02486406 0.01182842 0.02172879
  0.02202306 0.02917258]
 [0.03049923 0.02144028 0.01983061 0.01279752 0.0106537  0.01557695
  0.02200669 0.02336484 0.02727427 0.01595154 0.02598481 0.01988852
  0.02501743 0.00735444 0.00657055 0.02626442 0.0293507  0.02732542
  0.03612171 0.03585363 0.04675112 0.02832151 0.02002249 0.04712019
  0.04010928 0.05160659]
 [0.03160766 0.02000694 0.01925896 0.0162912  0.01239284 0.0185894
  0.01888048 0.02226214 0.02439843 0.01879107 0.02144165 0.02313135
  0.02253766 0.0096792  0.00778026 0.01794131 0.02250344 0.02091842
  0.02770964 0.02406442 0.02801387 0.02473786 0.01452483 0.0171384
  0.01697665 0.02261621]
 [0.03025385 0.02867252 0.02914358 0.04364327 0.04605098 0.0396654
  0.02391475 0.02588838 0.03186197 0.04526005 0.03231817 0.03401892
  0.03118081 0.07652368 0.08940548 0.02448362 0.02908517 0.02569197
  0.02601439 0.02526861 0.02232784 0.03212908 0.0339145  0.01261277
  0.00799459 0.01921455]
 [0.03002412 0.03058634 0.02990548 0.05000998 0.09668674 0.03990506
  0.02260591 0.0248084  0.03094383 0.05342633 0.03846669 0.03433652
  0.02588103 0.0762889  0.09642373 0.03063514 0.04104679 0.0348847
  0.03046403 0.0275     0.0259394  0.02940105 0.03305252 0.01056599
  0.00568726 0.01645429]
 [0.02981946 0.02720278 0.02578908 0.04036522 0.08750997 0.02730517
  0.01874546 0.02326079 0.02676588 0.04591021 0.03667771 0.03574184
  0.02469845 0.03301684 0.04306274 0.02637481 0.06296989 0.05269622
  0.0419767  0.03252732 0.04068279 0.02657776 0.02944015 0.01718157
  0.01178851 0.02197111]
 [0.03008604 0.03396666 0.0305955  0.04148267 0.05850275 0.03250793
  0.02524624 0.02598526 0.03307302 0.04191551 0.03662561 0.03152262
  0.02683561 0.03430634 0.03803476 0.02308401 0.04211264 0.03437715
  0.03245024 0.03042966 0.03042645 0.04658265 0.04170112 0.01439599
  0.00931747 0.01943143]]

-* TASK 10/20 | SAMPLE 79/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 392/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie's location in the given context sentences. Sentence 1, which mentioned Julie, is not provided in this task. 

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '1', ',', ' which', ' mentioned', ' Julie', ',', ' is', ' not', ' provided', ' in', ' this', ' task', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.1053, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02435242 0.02711202 0.02619481 ... 0.05243036 0.01301632 0.0513396 ]
 [0.02518553 0.02514628 0.02323104 ... 0.05967626 0.01974021 0.06573738]
 [0.02560796 0.02481994 0.02626003 ... 0.05715511 0.02816449 0.05262478]
 ...
 [0.02593434 0.02508904 0.01959999 ... 0.01162122 0.01418342 0.01885924]
 [0.02639318 0.02336934 0.02000711 ... 0.01055025 0.01261488 0.01863526]
 [0.02653448 0.02076629 0.01832392 ... 0.01151383 0.01247911 0.02229002]]

-* TASK 10/20 | SAMPLE 79/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 393/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 8, Mary travelled to the office, which implies that she is currently in the office. There is no information suggesting that she is in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Mary', ' travelled', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' suggesting', ' that', ' she', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 38), x_tokens=38, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 38)
DEBUG result.interpretability.attn_scores 1558 
 [[0.02256323 0.03839023 0.03684819 ... 0.01209947 0.01225014 0.04255881]
 [0.02297672 0.03865727 0.03008587 ... 0.03214012 0.04438483 0.03537261]
 [0.02353828 0.04207682 0.04237083 ... 0.0100491  0.00758255 0.03671326]
 ...
 [0.0237248  0.03429471 0.0305271  ... 0.01066114 0.00729544 0.04351211]
 [0.02426978 0.02687576 0.0229903  ... 0.01647585 0.01282948 0.02807825]
 [0.0241854  0.02622267 0.02294631 ... 0.01334402 0.0134848  0.03126765]]

-* TASK 10/20 | SAMPLE 79/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 394/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 10, Fred moved to the school, which implies that he is currently in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Fred', ' moved', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03248218 0.04182203 0.04555468 ... 0.01841689 0.01941743 0.03044791]
 [0.03271298 0.03654886 0.03714114 ... 0.03810908 0.0434414  0.04583764]
 [0.0339449  0.04248701 0.05011604 ... 0.02633656 0.02845968 0.03870016]
 ...
 [0.03405905 0.05067083 0.05076867 ... 0.01439978 0.01554516 0.02434059]
 [0.03417268 0.04038582 0.03715999 ... 0.01733112 0.01667984 0.01730134]
 [0.03424375 0.04446711 0.04213131 ... 0.01633547 0.01687417 0.02180951]]

-* TASK 10/20 | SAMPLE 79/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 395/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's current location in the given context sentences. Sentence 11, which mentioned Bill, is not provided in this task. 

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' current', ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '11', ',', ' which', ' mentioned', ' Bill', ',', ' is', ' not', ' provided', ' in', ' this', ' task', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.1795, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02395985 0.0280856  0.02773653 ... 0.01556808 0.01428175 0.01646449]
 [0.02453012 0.02181853 0.02171354 ... 0.0139717  0.0153312  0.01701024]
 [0.02496812 0.0281834  0.03083701 ... 0.01310317 0.01150808 0.01290098]
 ...
 [0.02565531 0.02684309 0.02272161 ... 0.01944373 0.01969081 0.02012811]
 [0.0259426  0.03026601 0.02514454 ... 0.01521734 0.01547362 0.01721368]
 [0.0257568  0.0247717  0.02198812 ... 0.0147269  0.01312029 0.01422014]]
Model's predictions for the sample 79:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Julie moved to   |
|          |                 |   the office, which implies that she is    |
|          |                 |          currently in the office.          |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information about Julie's    |
|          |                 |  location in the given context sentences.  |
|          |                 |   Sentence 1, which mentioned Julie, is    |
|          |                 |         not provided in this task.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 8, Mary travelled   |
|          |                 |  to the office, which implies that she is  |
|          |                 |    currently in the office. There is no    |
|          |                 |   information suggesting that she is in    |
|          |                 |                the school.                 |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 10, Fred moved to   |
|          |                 |    the school, which implies that he is    |
|          |                 |          currently in the school.          |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |    There is no information about Bill's    |
|          |                 |   current location in the given context    |
|          |                 |  sentences. Sentence 11, which mentioned   |
|          |                 |    Bill, is not provided in this task.     |
+----------+-----------------+--------------------------------------------+

Metrics for sample 79:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.09 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 80/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 396/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, Julie is in the bedroom, and there is no mention of Julie being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02582981 0.03945662 0.04804302 0.06908876 0.07829773 0.06609254
  0.04622878 0.05685226 0.04683303 0.0601503  0.04271907 0.05224353
  0.06033956 0.10073518 0.07078826 0.02839914 0.02644727 0.02780464
  0.02408331 0.02669169 0.02142292 0.03533486 0.03753449 0.02119073
  0.01565968 0.02254445]
 [0.02547642 0.07543898 0.05831646 0.05994787 0.05182743 0.05662762
  0.16233298 0.08867622 0.06468532 0.05810307 0.07531686 0.0526606
  0.07896274 0.0332854  0.02848795 0.03678448 0.03242806 0.04169049
  0.03195393 0.04014952 0.03323096 0.04352635 0.0370202  0.03277486
  0.0244499  0.02876437]
 [0.02800092 0.0540421  0.0351361  0.05390692 0.04094759 0.03460557
  0.02789956 0.02111589 0.02037835 0.03312143 0.02581275 0.01481797
  0.01700588 0.03224136 0.04192298 0.02229975 0.01200789 0.0114249
  0.01344347 0.01434782 0.01328481 0.04120664 0.04863661 0.0097733
  0.00561397 0.01196724]
 [0.02634524 0.02597167 0.02739837 0.02229664 0.01609339 0.02305795
  0.0228103  0.02002665 0.02288781 0.02247584 0.02316235 0.02124401
  0.02002064 0.01305887 0.01403714 0.02780863 0.02977825 0.03619017
  0.03809697 0.04191117 0.0369798  0.02914026 0.04327157 0.04891244
  0.05352199 0.05745121]
 [0.02664431 0.03860049 0.04367832 0.06713869 0.06202582 0.04561205
  0.02988448 0.0275302  0.03101641 0.04399494 0.03152464 0.02337378
  0.02366085 0.10590713 0.10990125 0.03426755 0.02311178 0.01805375
  0.01755299 0.01954801 0.01859203 0.03617715 0.05556532 0.01682865
  0.00860552 0.02616752]
 [0.02720342 0.02511625 0.02672376 0.05136533 0.04613663 0.04132387
  0.02236683 0.02143087 0.02610604 0.04059108 0.02784978 0.0261108
  0.02525957 0.11377797 0.13623719 0.03364995 0.02580182 0.02168868
  0.01974838 0.0207797  0.01771407 0.03095932 0.03349293 0.0119008
  0.0068226  0.01675969]
 [0.02763316 0.02793899 0.03359971 0.05317306 0.05060922 0.05102161
  0.02866385 0.02874269 0.03369317 0.04738788 0.03248852 0.0406394
  0.03762927 0.09007785 0.08490212 0.02810635 0.02354447 0.02153023
  0.01902238 0.02050807 0.01672472 0.02800542 0.03099315 0.01575256
  0.00971172 0.01611796]
 [0.02665591 0.03458839 0.04157811 0.03967317 0.04264654 0.04591308
  0.03255649 0.03658016 0.03689225 0.04155191 0.03337235 0.04521353
  0.03893591 0.05213358 0.04717078 0.03545325 0.0304933  0.02838208
  0.02426016 0.02614707 0.02371914 0.03168273 0.04378914 0.03284624
  0.03278897 0.03045214]
 [0.02777304 0.03414932 0.04136724 0.04518479 0.04151352 0.05349721
  0.03536146 0.03968355 0.04340663 0.04788876 0.03354868 0.04650257
  0.04299205 0.0414691  0.0270751  0.02569457 0.02325204 0.02354089
  0.021618   0.02338735 0.01892458 0.03222099 0.03402309 0.01990808
  0.01416465 0.02176927]
 [0.02708495 0.04670922 0.05421075 0.02901479 0.02363249 0.03703478
  0.03840404 0.03845632 0.04103126 0.02951557 0.02651159 0.03414047
  0.03383218 0.01826478 0.01576674 0.03910023 0.03077725 0.02646958
  0.02535158 0.02867548 0.02728601 0.03154856 0.06347883 0.042667
  0.0348538  0.03553484]
 [0.02760321 0.06148227 0.06157031 0.02710756 0.0222836  0.0312687
  0.03887153 0.03603449 0.04325721 0.0261704  0.02409378 0.02755166
  0.0279069  0.01553311 0.01472674 0.04470687 0.03067801 0.02597219
  0.02598692 0.03115168 0.02640724 0.02914153 0.06562573 0.03944404
  0.02586766 0.02672952]
 [0.0277532  0.03236956 0.03666562 0.02015584 0.01758347 0.02231309
  0.03013153 0.02718994 0.0313293  0.02049002 0.01946153 0.02121989
  0.02078543 0.01279607 0.01275508 0.03743483 0.02827776 0.02294073
  0.02384455 0.02733387 0.02606153 0.02749552 0.05040381 0.04864361
  0.04350693 0.03891038]
 [0.02792059 0.01358228 0.01483601 0.01098869 0.01014938 0.0126499
  0.01379238 0.01389362 0.01590602 0.0118903  0.01334829 0.01295839
  0.01279079 0.00644303 0.00701442 0.01767762 0.01845471 0.01801126
  0.02075886 0.02457918 0.0282767  0.01951724 0.03113212 0.05619523
  0.06460884 0.05529922]
 [0.02788019 0.02038231 0.0216898  0.01554117 0.01508055 0.01861425
  0.01968109 0.01951785 0.02008973 0.01679    0.0195935  0.0184456
  0.01779647 0.00949828 0.01018087 0.03004435 0.02895496 0.0233449
  0.02316104 0.02473675 0.02523135 0.0258425  0.02506348 0.04374841
  0.0584353  0.04819842]
 [0.02793298 0.02204839 0.02327127 0.01860103 0.01681568 0.02286514
  0.0242085  0.02688023 0.02281118 0.02162282 0.02545143 0.02744917
  0.0272701  0.01108401 0.00998974 0.02586374 0.03441072 0.02719558
  0.02371667 0.02436344 0.02743551 0.02700252 0.01884603 0.03193342
  0.05261071 0.02862695]
 [0.02753516 0.0181521  0.01614549 0.01351094 0.01148894 0.01426786
  0.01848019 0.01937564 0.01604394 0.01462403 0.02064501 0.01634871
  0.0196109  0.00704788 0.00740251 0.02487972 0.03441468 0.04004053
  0.02940081 0.03212411 0.05316234 0.02375193 0.01491116 0.0401989
  0.07382729 0.04204985]
 [0.02808934 0.01964127 0.01844512 0.01550524 0.01389502 0.01788303
  0.02252723 0.02482079 0.01880115 0.01810978 0.02936754 0.02429123
  0.02472082 0.00849476 0.0081049  0.02256078 0.03714309 0.02706415
  0.02680073 0.02546458 0.03322424 0.02390745 0.01471967 0.03561355
  0.05359378 0.03732039]
 [0.02806819 0.01627146 0.01493227 0.01156915 0.01102803 0.01379311
  0.0197094  0.01958211 0.01640408 0.01397302 0.03183187 0.01932853
  0.0202828  0.00639118 0.00673535 0.02414319 0.04019753 0.02866009
  0.03012073 0.02900161 0.03894937 0.02129853 0.01296889 0.03484502
  0.04085984 0.05252311]
 [0.02707536 0.01887182 0.01609965 0.01259602 0.01156129 0.01448159
  0.01893482 0.01781657 0.01919449 0.01446299 0.02229042 0.01481578
  0.01813913 0.00709615 0.00778433 0.02182843 0.03178075 0.03244358
  0.03925678 0.05876358 0.05533483 0.0244618  0.02677158 0.06847195
  0.0573964  0.07496934]
 [0.02839306 0.01816489 0.0169347  0.01404855 0.01222757 0.01671617
  0.01871608 0.01972432 0.01871176 0.01622633 0.03001878 0.02166601
  0.01920632 0.00802816 0.00767732 0.02131401 0.02956813 0.02396483
  0.02587078 0.02834615 0.030071   0.0231375  0.01273746 0.02253566
  0.02322257 0.03854525]
 [0.02872622 0.02010877 0.02228037 0.01864664 0.01584718 0.0233026
  0.02069157 0.02800529 0.02496434 0.0234121  0.02505766 0.03159527
  0.02582413 0.01137899 0.00883846 0.01817677 0.02063425 0.01957689
  0.02166858 0.01989246 0.01932934 0.02613872 0.01429346 0.01739517
  0.01729031 0.01879629]
 [0.02849855 0.0217713  0.02129482 0.01642016 0.01394986 0.02207753
  0.02206489 0.02742907 0.025267   0.01926305 0.02250895 0.02871684
  0.02591083 0.0099631  0.00842794 0.02052157 0.02159965 0.02216433
  0.02596062 0.02431443 0.02459978 0.02748485 0.01825733 0.02459595
  0.02307103 0.02027265]
 [0.02878405 0.02252654 0.02256075 0.01711671 0.01490202 0.02448492
  0.02504313 0.03154269 0.0280919  0.02138398 0.03001121 0.0408789
  0.03055836 0.01014247 0.00889657 0.02188802 0.02595504 0.02464306
  0.02739278 0.02366996 0.02341074 0.02386554 0.01697489 0.01753035
  0.01526337 0.01671652]
 [0.0288778  0.02148142 0.02189914 0.01786854 0.01485068 0.02614744
  0.02245089 0.02702877 0.02978659 0.02194492 0.02035293 0.03153772
  0.02845392 0.01101191 0.0086433  0.01781823 0.02027885 0.02088692
  0.02498129 0.02355224 0.02174286 0.02488613 0.02006282 0.01950103
  0.01862532 0.01898568]
 [0.02832681 0.0349074  0.02992184 0.02043502 0.01612256 0.0277181
  0.02864155 0.03757565 0.03504177 0.02559172 0.02624764 0.04012915
  0.03759108 0.01207442 0.00947759 0.02755204 0.0234664  0.02914036
  0.02911105 0.03038216 0.026998   0.02728726 0.02226005 0.02029462
  0.01920658 0.017667  ]
 [0.02900343 0.02300967 0.02521258 0.01935978 0.01486118 0.02768809
  0.02635211 0.03023223 0.03222581 0.02360864 0.02361238 0.03551884
  0.03149758 0.0115089  0.00860583 0.02156002 0.01895937 0.02099562
  0.02252732 0.02393792 0.02179574 0.0252566  0.01641847 0.01697977
  0.01569408 0.01253057]
 [0.02829994 0.01778976 0.01721127 0.01285308 0.01034192 0.01489995
  0.01884989 0.0215636  0.02122505 0.01599704 0.02388066 0.02106589
  0.0242636  0.00774748 0.00654489 0.02982765 0.02717449 0.03208948
  0.03035666 0.03072432 0.03327712 0.02456314 0.01154036 0.02469468
  0.03073312 0.0166095 ]
 [0.02830241 0.01968888 0.01899214 0.01413148 0.0106243  0.01468349
  0.02075247 0.02436571 0.02228119 0.01607347 0.02098469 0.01931866
  0.02372175 0.00779754 0.00668981 0.03710411 0.02756165 0.04288556
  0.03057478 0.035548   0.03934957 0.02339962 0.01262968 0.02765564
  0.03190761 0.01716666]
 [0.02870351 0.01918443 0.01785226 0.0134059  0.01086934 0.01461528
  0.01817224 0.02307316 0.02160179 0.01655525 0.0231894  0.02187702
  0.02381773 0.00779873 0.00635847 0.0332264  0.02812692 0.03213757
  0.0308706  0.02987969 0.0322298  0.02192682 0.011182   0.02384489
  0.02192047 0.01346034]
 [0.02857628 0.01611444 0.01591477 0.01058652 0.00934308 0.01221608
  0.01608868 0.01874464 0.01933114 0.01363864 0.02375518 0.01764269
  0.01854577 0.00668139 0.00555088 0.03167133 0.02887398 0.02667908
  0.03262125 0.02712866 0.03154106 0.02158901 0.01069069 0.0239907
  0.02115077 0.01827569]
 [0.0277428  0.01786649 0.01738851 0.01155395 0.00995568 0.01373764
  0.01800669 0.01996345 0.02195682 0.01409448 0.02346093 0.01774079
  0.01984106 0.00736372 0.00631091 0.03798791 0.0297719  0.03090001
  0.03629331 0.02939278 0.03300361 0.02317145 0.01554691 0.04124538
  0.03273414 0.03381887]
 [0.02875537 0.02089812 0.02073099 0.01482389 0.01194869 0.01752924
  0.01809418 0.02163734 0.02465145 0.01743283 0.0214239  0.02088009
  0.02066777 0.00960495 0.00762124 0.02633236 0.02243987 0.02586612
  0.03117694 0.02537297 0.0253728  0.02381296 0.01634187 0.01931953
  0.01668013 0.01647428]
 [0.02784026 0.02530453 0.02569466 0.04269157 0.0435917  0.03577697
  0.02140096 0.02346082 0.02911612 0.04537613 0.03010749 0.03060218
  0.03107648 0.06557503 0.08278105 0.0231146  0.02437992 0.02372799
  0.02231688 0.02119148 0.01886634 0.02963135 0.02762399 0.01187422
  0.00879645 0.01774848]
 [0.02761141 0.02708002 0.02584746 0.04730486 0.09252647 0.034983
  0.01899314 0.0215183  0.02620183 0.04801979 0.03427781 0.02784104
  0.02373    0.07298285 0.09335249 0.02885865 0.0334514  0.03230589
  0.02763235 0.02394433 0.02181453 0.02702833 0.02829586 0.00978051
  0.0062209  0.01589951]
 [0.02741859 0.02146011 0.02135976 0.03473787 0.0611005  0.02297428
  0.01431563 0.01927661 0.02239358 0.0404     0.03275573 0.02921667
  0.02342657 0.02708134 0.03265896 0.0229011  0.04420942 0.05326033
  0.06366586 0.03423112 0.02992257 0.02342687 0.02304188 0.01456255
  0.01143232 0.01786431]
 [0.02763406 0.02782958 0.02519654 0.03764985 0.05332101 0.02752621
  0.0185205  0.02065239 0.02638445 0.03806753 0.02996469 0.02441674
  0.02392507 0.02792336 0.03058097 0.01944176 0.03159445 0.03632754
  0.03880071 0.02882664 0.02471305 0.04117254 0.03385458 0.01255048
  0.00915114 0.0170125 ]]

-* TASK 10/20 | SAMPLE 80/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 397/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, Mary went to the school, and there is no mention of Mary being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Mary', ' went', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02937094 0.04774926 0.04712881 ... 0.06515889 0.01028044 0.00929259]
 [0.03006402 0.05074588 0.04650061 ... 0.07178266 0.01515145 0.0144523 ]
 [0.03074806 0.04498758 0.04659846 ... 0.06826099 0.01928552 0.01854446]
 ...
 [0.03066666 0.03918134 0.03632187 ... 0.02456478 0.00766704 0.00679037]
 [0.03115542 0.03026341 0.0268564  ... 0.01290905 0.01114626 0.00943474]
 [0.03127252 0.03147325 0.02800076 ... 0.01122338 0.01011225 0.00914767]]

-* TASK 10/20 | SAMPLE 80/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 398/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, Julie journeyed to the park, which implies that Julie is now in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.0303281  0.03797252 0.03754909 ... 0.03112771 0.02225574 0.02284997]
 [0.03104381 0.04267764 0.03818764 ... 0.03263792 0.02522843 0.02537106]
 [0.03157896 0.04063111 0.04536963 ... 0.02506512 0.01790422 0.0170656 ]
 ...
 [0.03175559 0.03621669 0.04002165 ... 0.02565341 0.0166166  0.01854178]
 [0.03195078 0.02946358 0.03060277 ... 0.0308247  0.02324119 0.02616117]
 [0.0319363  0.03343247 0.03399035 ... 0.02835308 0.0213152  0.02459966]]

-* TASK 10/20 | SAMPLE 80/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 399/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, Mary travelled to the kitchen, which implies that Mary is now in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03124552 0.04195347 0.04242207 ... 0.03781498 0.01164767 0.0183208 ]
 [0.03181568 0.0386771  0.0398289  ... 0.04467101 0.02419161 0.03504529]
 [0.03271772 0.04479356 0.05099573 ... 0.05653997 0.01549147 0.02794526]
 ...
 [0.03290983 0.04692525 0.04121042 ... 0.0143118  0.00828447 0.01197089]
 [0.03328431 0.03500334 0.0276817  ... 0.01097924 0.01205269 0.01359545]
 [0.03303439 0.04207873 0.03228269 ... 0.00884199 0.00964486 0.01158099]]

-* TASK 10/20 | SAMPLE 80/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 400/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 14, Julie is in the kitchen, and there is no mention of Julie being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02937169 0.04163153 0.04026037 ... 0.03640127 0.01920986 0.01524245]
 [0.02987704 0.0367041  0.03913869 ... 0.0384933  0.02789908 0.02049815]
 [0.03061883 0.04433477 0.04681916 ... 0.03029952 0.0188347  0.0133934 ]
 ...
 [0.03071757 0.03748911 0.03982882 ... 0.02778434 0.0171727  0.01506524]
 [0.03132311 0.02688749 0.02815828 ... 0.0261646  0.01994405 0.01951183]
 [0.0310247  0.03078636 0.03070474 ... 0.02613766 0.01895774 0.02031861]]
Model's predictions for the sample 80:

+----------+-----------------+-------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef               |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |   According to context sentence 2, Julie  |
|          |                 |     is in the bedroom, and there is no    |
|          |                 |   mention of Julie being in the cinema.   |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |   According to context sentence 5, Mary   |
|          |                 |    went to the school, and there is no    |
|          |                 |   mention of Mary being in the kitchen.   |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |   According to context sentence 8, Julie  |
|          |                 |    journeyed to the park, which implies   |
|          |                 |       that Julie is now in the park.      |
+----------+-----------------+-------------------------------------------+
|   yes    |       yes       |   According to context sentence 10, Mary  |
|          |                 |  travelled to the kitchen, which implies  |
|          |                 |      that Mary is now in the kitchen.     |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |  According to context sentence 14, Julie  |
|          |                 |     is in the kitchen, and there is no    |
|          |                 |   mention of Julie being in the cinema.   |
+----------+-----------------+-------------------------------------------+

Metrics for sample 80:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.05 ± 0.04 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 81/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 401/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 1, Fred went to the kitchen, which implies that Fred is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 26), x_tokens=26, y_tokens=30, max_supp_attn=0.1, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 26)
DEBUG result.interpretability.attn_scores 780 
 [[0.03124273 0.0524494  0.05644075 0.0850444  0.07969984 0.0591125
  0.04039973 0.03580412 0.04200871 0.05758205 0.0402438  0.02966535
  0.03136727 0.1312162  0.12825574 0.03974167 0.03076593 0.02191594
  0.02486372 0.02428864 0.02447166 0.04542248 0.0686892  0.01453026
  0.01228643 0.0436712 ]
 [0.03224839 0.03314168 0.03346276 0.06335539 0.0564491  0.05041991
  0.02849951 0.02599251 0.03384359 0.04974204 0.03489503 0.03190884
  0.03121012 0.13311352 0.15334642 0.03843589 0.03347208 0.02576119
  0.02748946 0.02523401 0.02302364 0.03903681 0.04084776 0.00990665
  0.00983635 0.02860537]
 [0.03276219 0.037373   0.04447199 0.06560269 0.06195084 0.06494575
  0.03903248 0.03791055 0.04499982 0.05841041 0.04001724 0.05196471
  0.05048057 0.10594149 0.09392789 0.0325371  0.03060703 0.02648492
  0.02652444 0.02539243 0.02190812 0.03527468 0.03828247 0.01406735
  0.01349    0.02722858]
 [0.03168669 0.04829086 0.05747851 0.05244883 0.0517579  0.06141438
  0.04673863 0.04928756 0.04944998 0.0513645  0.03969833 0.056808
  0.05193264 0.06313251 0.05521761 0.04411859 0.03956866 0.03533782
  0.03297761 0.03364496 0.03038347 0.03970493 0.05912052 0.03765922
  0.03868479 0.04470435]
 [0.03291934 0.04966087 0.0609281  0.06078146 0.051182   0.07377145
  0.05499537 0.05718249 0.06159135 0.06148576 0.0420575  0.06043748
  0.05896544 0.0475265  0.03079919 0.03270327 0.03106877 0.02990359
  0.02920215 0.0310174  0.02523005 0.04000845 0.04390745 0.02022721
  0.02224238 0.03480873]
 [0.03233309 0.06023645 0.06562412 0.03714241 0.02724205 0.04696272
  0.05360423 0.05024526 0.05437404 0.0373689  0.0324115  0.04348662
  0.04533231 0.02261393 0.01871621 0.04987041 0.03914759 0.03382907
  0.03429878 0.03684861 0.03398453 0.03825373 0.07665554 0.0441982
  0.0478992  0.0427154 ]
 [0.03291915 0.07768635 0.07695382 0.03411608 0.02516107 0.03953125
  0.05264964 0.04461316 0.05592396 0.03260749 0.02891707 0.03316985
  0.0336843  0.01889832 0.01742773 0.05326485 0.03886735 0.030789
  0.03487834 0.03964266 0.03359354 0.03490856 0.08040639 0.03675425
  0.03601746 0.03935637]
 [0.03306507 0.04230323 0.04884756 0.0264204  0.0204592  0.0295328
  0.0410687  0.03502719 0.04411531 0.02702751 0.02446592 0.02674248
  0.026478   0.01617568 0.0155291  0.04589547 0.03559409 0.02725018
  0.03286701 0.03552936 0.03221975 0.03338983 0.06644619 0.05297333
  0.05782534 0.04535444]
 [0.03324678 0.01836174 0.01983768 0.01489812 0.01243389 0.01756629
  0.01912637 0.01893348 0.02335927 0.01658013 0.01673336 0.01659656
  0.01718348 0.0088221  0.00932125 0.02481017 0.02447568 0.0237803
  0.02998965 0.03454021 0.03492936 0.02493016 0.04435139 0.0675311
  0.09032087 0.05430989]
 [0.03330093 0.02670218 0.02861582 0.02105695 0.01662119 0.02630471
  0.02824104 0.02521943 0.02811779 0.02232481 0.02378748 0.02473298
  0.02344059 0.01213984 0.01256111 0.03971398 0.02765679 0.02654338
  0.02822995 0.03033934 0.0298464  0.03127316 0.03447338 0.05851692
  0.06958125 0.04591824]
 [0.03336405 0.02940627 0.02947659 0.02515303 0.01948337 0.02950879
  0.03445613 0.03401308 0.03162176 0.02769444 0.02888136 0.03506768
  0.03536267 0.01496349 0.01268103 0.03914527 0.03103087 0.0333912
  0.03115818 0.03230381 0.03227003 0.03415583 0.02618087 0.05100405
  0.046249   0.02910818]
 [0.03284215 0.02396216 0.02002959 0.01861694 0.01326309 0.01924088
  0.02823453 0.02698482 0.0222378  0.01889235 0.02377516 0.02288301
  0.02573499 0.009455   0.00912585 0.03737497 0.02646939 0.04389196
  0.03879426 0.04825178 0.05010946 0.03106714 0.0204627  0.08028591
  0.07096013 0.03554063]
 [0.0337178  0.02161652 0.02026248 0.01755698 0.01448688 0.02028818
  0.02639487 0.0256002  0.02260297 0.01953156 0.0279899  0.0264839
  0.02589466 0.0092619  0.00883933 0.03269888 0.0258032  0.03711792
  0.03227694 0.0471307  0.0422649  0.02614936 0.01683481 0.05841194
  0.04973029 0.02763395]
 [0.03369556 0.01953321 0.01690418 0.01379571 0.01190065 0.0157226
  0.02341167 0.02174632 0.0193749  0.01566862 0.03596749 0.02173899
  0.02268501 0.00742436 0.00777982 0.03353605 0.02962964 0.03684576
  0.03607397 0.04122172 0.04042383 0.02680686 0.01658049 0.06114959
  0.04747714 0.03528104]
 [0.03282087 0.03116078 0.02926792 0.02145218 0.01952603 0.02621307
  0.04027267 0.03977466 0.03535943 0.02369126 0.03145108 0.03134647
  0.03545319 0.01090702 0.01085131 0.03255657 0.03521615 0.04450037
  0.04302984 0.04646417 0.04398556 0.03255476 0.02607151 0.0471224
  0.04390673 0.0525783 ]
 [0.03428961 0.02362977 0.02203152 0.01898767 0.01541472 0.02077802
  0.02323139 0.0257284  0.02234654 0.02023762 0.02641138 0.02531595
  0.02427915 0.01024252 0.00942071 0.02443231 0.02378028 0.02787271
  0.02881449 0.02740415 0.02907502 0.02929989 0.01772593 0.02899981
  0.03476965 0.03083977]
 [0.03441097 0.02640572 0.0287537  0.02764857 0.02150702 0.03170922
  0.02890241 0.03604259 0.02893089 0.03136822 0.02885797 0.04004792
  0.03543433 0.01604787 0.01146071 0.02183253 0.0234357  0.02613979
  0.02569602 0.02465619 0.02409263 0.03141012 0.01745801 0.01713795
  0.02408723 0.02495178]
 [0.03452509 0.0319217  0.03271005 0.0316238  0.0226535  0.03501694
  0.03607425 0.04508753 0.02994037 0.03594374 0.03810256 0.04702901
  0.04352193 0.01776446 0.01242883 0.0253361  0.02416518 0.02820776
  0.02544937 0.02510726 0.02406766 0.03206781 0.01868953 0.0155949
  0.01805919 0.01986265]
 [0.03433964 0.0304924  0.02936014 0.03006246 0.02326006 0.03251215
  0.03323983 0.03986697 0.03009455 0.03499145 0.03518562 0.04289433
  0.04213272 0.01775003 0.01305464 0.02950051 0.02619123 0.03108535
  0.02843678 0.02828614 0.02647727 0.03309617 0.01640252 0.01961188
  0.01920346 0.01775618]
 [0.0341754  0.0244356  0.02189551 0.01881455 0.01462419 0.0206591
  0.02594418 0.02881432 0.02437524 0.02165951 0.02745429 0.02738662
  0.03014401 0.01059916 0.00915842 0.03255191 0.0282903  0.03300616
  0.03057143 0.02956622 0.03257824 0.03115194 0.01522731 0.03132766
  0.02938912 0.02129374]
 [0.03409799 0.02566637 0.0219011  0.01909057 0.0143549  0.01946452
  0.02955726 0.02999254 0.02462031 0.02076593 0.02888013 0.02455416
  0.03038288 0.00992916 0.00896278 0.03487693 0.02898187 0.03681754
  0.03584723 0.03399868 0.03827147 0.02701307 0.01494321 0.03256653
  0.03179954 0.02328268]
 [0.03428768 0.02411039 0.0206025  0.01861367 0.01525075 0.01933143
  0.02500372 0.02752457 0.02360109 0.02177692 0.02869174 0.0262406
  0.02819786 0.01029062 0.0093109  0.03090227 0.0329474  0.03388552
  0.03709429 0.03120693 0.03598057 0.02786121 0.01539104 0.02447185
  0.02393387 0.02195647]
 [0.03440314 0.02695552 0.02341955 0.02025178 0.01555603 0.02103548
  0.02996559 0.03127588 0.02842453 0.02306837 0.03322908 0.02713933
  0.03112086 0.01064727 0.00970799 0.03164784 0.03110181 0.03524347
  0.03683603 0.03498034 0.03828857 0.02903299 0.01600971 0.02568162
  0.02286563 0.02289441]
 [0.03449764 0.02024831 0.01790562 0.01361115 0.01166869 0.01519677
  0.02510906 0.023463   0.02197488 0.01561318 0.03895709 0.01994086
  0.02480718 0.00773703 0.00754833 0.02998394 0.03416296 0.0327461
  0.03846577 0.03304294 0.03665036 0.02716957 0.01425724 0.03645387
  0.02596812 0.0246498 ]
 [0.03273962 0.03138717 0.02650024 0.01786076 0.01628258 0.02237297
  0.05219136 0.04314905 0.03582847 0.02216011 0.06699132 0.03333338
  0.04378092 0.01010233 0.01084147 0.03446315 0.05818037 0.05558212
  0.05910609 0.05481405 0.05507747 0.03371743 0.02575376 0.04744492
  0.03943191 0.06013092]
 [0.03459007 0.02498989 0.02347265 0.02172983 0.01705311 0.02578433
  0.02743959 0.03096306 0.02950542 0.02412175 0.02794435 0.03055942
  0.02965496 0.01343931 0.01096542 0.02008472 0.02631814 0.02666273
  0.02998523 0.0263643  0.02845346 0.02958122 0.01543181 0.01772165
  0.0223492  0.02657328]
 [0.03307328 0.03283354 0.03165459 0.05189028 0.05344962 0.0450994
  0.02884376 0.02842073 0.03484334 0.05152267 0.03411192 0.03494604
  0.03429656 0.0890147  0.10289622 0.02580362 0.03060564 0.02608858
  0.02743858 0.0257064  0.02421578 0.03759585 0.03614366 0.01100244
  0.01222482 0.03107853]
 [0.03287834 0.0348396  0.03164062 0.05758527 0.10663527 0.04440447
  0.02639487 0.02682328 0.03365533 0.05834845 0.03924029 0.03546587
  0.02872714 0.08683632 0.10755179 0.03123159 0.04269935 0.03599019
  0.03240358 0.02814903 0.02892005 0.0343812  0.03609318 0.00947077
  0.0089657  0.02681725]
 [0.03266983 0.0312623  0.02756968 0.0463782  0.10457829 0.03029536
  0.02197817 0.02610918 0.02867933 0.05156507 0.03821954 0.03892051
  0.02839901 0.0389676  0.05000009 0.02693501 0.0651608  0.05608369
  0.04557538 0.03359829 0.04509903 0.02933689 0.03221355 0.0152825
  0.01627857 0.03112241]
 [0.03285686 0.03893705 0.03198064 0.04840991 0.06609414 0.0358046
  0.02899906 0.02840406 0.03419902 0.04688519 0.03643046 0.03319312
  0.0299152  0.03903975 0.04231216 0.02401441 0.04460579 0.03724573
  0.03562547 0.03126915 0.03410802 0.05434786 0.04894871 0.0128933
  0.01416666 0.02997546]]

-* TASK 10/20 | SAMPLE 81/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 402/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, Fred is in the cinema, which explicitly states Fred's current location.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Fred', ' is', ' in', ' the', ' cinema', ',', ' which', ' explicitly', ' states', ' Fred', "'s", ' current', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.25, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03352204 0.04765064 0.05046885 0.06599698 0.05720321 0.04936256
  0.03632879 0.04011432 0.05671089 0.05131383 0.03501311 0.03320964
  0.03539848 0.10456421 0.10348192 0.03291367 0.02923861 0.02632328
  0.02357415 0.02819768 0.024898   0.03563692 0.05804388 0.02793009
  0.02255267 0.04496216 0.04829378 0.04292469 0.09834848 0.01511757
  0.0116838  0.03187893]
 [0.0343587  0.05179533 0.04854404 0.08509644 0.08525933 0.08959032
  0.05012165 0.0520819  0.06094405 0.07696969 0.0552241  0.06788217
  0.06916045 0.15072228 0.10762856 0.03497641 0.0294337  0.03352369
  0.02619537 0.031411   0.02684444 0.04113274 0.04483151 0.02383891
  0.02332984 0.03844253 0.04280316 0.03729518 0.09091023 0.02026349
  0.01988964 0.03740088]
 [0.03509158 0.04187818 0.04657231 0.06652292 0.05971466 0.05994658
  0.03768357 0.03966315 0.0505406  0.05391821 0.03723788 0.04650258
  0.04382652 0.11879946 0.08150454 0.0301408  0.02746919 0.02566278
  0.02224751 0.02517496 0.02207284 0.03566381 0.03953767 0.0235772
  0.02194966 0.03253359 0.04020546 0.0297611  0.0818716  0.03065369
  0.02277755 0.03614393]
 [0.03394241 0.04173077 0.04591    0.03835603 0.03227359 0.03797997
  0.03665785 0.03991932 0.04106464 0.03348788 0.0295273  0.03511084
  0.03545007 0.03088969 0.02914067 0.034144   0.03300896 0.02829419
  0.02789908 0.0300655  0.0272816  0.04016928 0.05080615 0.04118443
  0.04049206 0.04157459 0.05100957 0.03331474 0.07309861 0.09094382
  0.03828396 0.03256406]
 [0.03500586 0.03078646 0.03173396 0.0274751  0.02117709 0.0291339
  0.02852742 0.0276669  0.03364473 0.02472693 0.02503331 0.02509486
  0.02620021 0.01792731 0.01897527 0.02441492 0.02315986 0.02249701
  0.02429701 0.02787251 0.02587437 0.03304071 0.03507516 0.03987337
  0.04720122 0.04230742 0.04271461 0.03847538 0.05060581 0.06712231
  0.03475858 0.03218002]
 [0.03492726 0.04716137 0.0482598  0.03047576 0.02401436 0.03412803
  0.03713571 0.03817772 0.04663607 0.02758923 0.02514446 0.02992362
  0.03164873 0.02350678 0.02190013 0.03382741 0.03056166 0.02422482
  0.02569311 0.02759874 0.02375786 0.03813481 0.055904   0.03686832
  0.03642032 0.03642515 0.05590979 0.02554118 0.04701398 0.11162319
  0.0337172  0.02565704]
 [0.03517534 0.06117774 0.05301458 0.02881285 0.02315769 0.0300578
  0.03946894 0.03601744 0.04846078 0.02514422 0.02534453 0.02692981
  0.02969559 0.01820598 0.01970117 0.04283706 0.04059659 0.03415656
  0.03420786 0.04024556 0.03218107 0.0343296  0.07015032 0.04629819
  0.04772519 0.04248431 0.04734915 0.02575221 0.02419279 0.08641023
  0.02104691 0.02068928]
 [0.03536937 0.03550667 0.03401339 0.0241231  0.0196175  0.02296375
  0.02838564 0.02498088 0.03217891 0.02068196 0.02200482 0.02042945
  0.02090289 0.01543876 0.01842734 0.03194098 0.0306271  0.02485911
  0.02823647 0.03067845 0.02646586 0.03231408 0.0466703  0.04287424
  0.04553125 0.03325377 0.03760774 0.02153585 0.02195781 0.07367064
  0.02162028 0.01665971]
 [0.0354736  0.02223832 0.02345932 0.01960138 0.01603337 0.01960475
  0.02420227 0.0234381  0.02454063 0.01878005 0.02208861 0.02003741
  0.02229571 0.0120424  0.01510399 0.02264695 0.02703332 0.02638211
  0.02670373 0.03022902 0.02619059 0.0303997  0.02720872 0.03153966
  0.03827324 0.03482191 0.02215433 0.02432304 0.01892587 0.03316612
  0.02117423 0.02165713]
 [0.03565617 0.02653356 0.02848316 0.02362553 0.01925323 0.02574109
  0.02612592 0.0252447  0.02657073 0.02178494 0.0236191  0.02327897
  0.0221196  0.01487534 0.01717087 0.02896779 0.03275151 0.02691789
  0.03603676 0.03394971 0.03352594 0.03504957 0.03351286 0.04432159
  0.05059385 0.03410032 0.03061164 0.02635091 0.02812039 0.05242303
  0.03289359 0.02161478]
 [0.03578632 0.033421   0.03361877 0.03100824 0.02393016 0.03288725
  0.03514729 0.03394701 0.03070444 0.02974067 0.03204619 0.03487489
  0.03468695 0.02036597 0.02006552 0.0344917  0.03822831 0.03391347
  0.03943503 0.03501116 0.03308815 0.04127689 0.02886476 0.03807904
  0.04062378 0.02973424 0.03008029 0.02703851 0.02845706 0.04557
  0.0446911  0.03096579]
 [0.03565951 0.02730197 0.02416853 0.02222232 0.01669602 0.02364118
  0.02885824 0.02520838 0.02319588 0.02099021 0.02667495 0.02311018
  0.02540686 0.01296237 0.01488795 0.03937534 0.03666942 0.0401791
  0.05392499 0.04958093 0.0499138  0.03469317 0.02101631 0.05272803
  0.0537889  0.03192711 0.02380742 0.03078837 0.01525655 0.03163407
  0.02970978 0.03296221]
 [0.03617149 0.02917124 0.02670874 0.02321308 0.01914706 0.02609459
  0.03030228 0.02916953 0.02504438 0.02417753 0.03153659 0.03123767
  0.02955684 0.01437762 0.01550919 0.04060676 0.04642715 0.03638117
  0.05663246 0.03993814 0.04291041 0.03546922 0.02223775 0.03526295
  0.03812834 0.02910951 0.02835341 0.0335394  0.01784527 0.0288549
  0.04067665 0.04505938]
 [0.03648105 0.02368889 0.0225045  0.01757185 0.01573866 0.02040189
  0.02786753 0.02348589 0.0220176  0.01853891 0.03328939 0.02424635
  0.02609882 0.01079752 0.01253395 0.04683644 0.04560356 0.03712389
  0.05190603 0.04098652 0.04481212 0.03219784 0.01933281 0.03897704
  0.04096627 0.03506759 0.01934998 0.03691936 0.01275361 0.02133154
  0.03304813 0.04291187]
 [0.0350557  0.02860669 0.02517579 0.01958829 0.01707676 0.02330317
  0.03313787 0.02703602 0.03198217 0.02265097 0.02902112 0.02595425
  0.03157758 0.01220303 0.01465512 0.06646707 0.04785701 0.06980706
  0.06754937 0.09140372 0.06852903 0.03210618 0.03204334 0.08184544
  0.08392889 0.07003972 0.02427973 0.03746056 0.02016189 0.02247175
  0.03060275 0.02635876]
 [0.03636013 0.02727531 0.02763597 0.02464467 0.02069932 0.02984935
  0.02865519 0.02912557 0.02621401 0.02659738 0.03024893 0.03169686
  0.02887556 0.01675544 0.01673096 0.03049123 0.02830081 0.029061
  0.03576731 0.03180344 0.0351379  0.03289861 0.0246134  0.02825451
  0.03070055 0.03426738 0.02670032 0.0332365  0.02555703 0.02462067
  0.0815131  0.05090323]
 [0.0363573  0.02772224 0.03383678 0.0338976  0.02685347 0.03734057
  0.02995921 0.03580905 0.03391065 0.04020852 0.03179481 0.04450247
  0.03608333 0.02515445 0.01998492 0.02386963 0.02749204 0.02704404
  0.02626559 0.02536744 0.02537548 0.03605503 0.02592574 0.02315328
  0.02668881 0.03174179 0.03512811 0.03590988 0.03514726 0.02913341
  0.09881424 0.0449083 ]
 [0.03652406 0.03453283 0.04033424 0.04006695 0.03141142 0.04633593
  0.03770807 0.04416342 0.03580887 0.04760018 0.03571252 0.05398485
  0.04781108 0.02907286 0.02190349 0.02542801 0.02581214 0.02703766
  0.02498781 0.02530391 0.02381077 0.0363848  0.02913083 0.02167835
  0.02234923 0.02818716 0.04327548 0.02788025 0.03453571 0.03068363
  0.10842188 0.0483378 ]
 [0.03678092 0.04186093 0.04721529 0.04417185 0.0320521  0.04967522
  0.04272111 0.04997515 0.04112951 0.05311299 0.04185157 0.06439558
  0.05176717 0.03138131 0.02457483 0.03305504 0.03292747 0.03324942
  0.03107217 0.03112602 0.02937859 0.03765218 0.03540466 0.02638492
  0.02618241 0.03198045 0.04870705 0.03440188 0.03268905 0.03161055
  0.06242425 0.04004713]
 [0.03712084 0.03359663 0.03784371 0.03107153 0.02652947 0.03671102
  0.03918363 0.04018506 0.0323216  0.03809062 0.03743966 0.04240979
  0.04062999 0.02186884 0.01950752 0.03385361 0.0302042  0.03072857
  0.03019665 0.03031871 0.03155557 0.03833068 0.02776358 0.0311425
  0.02669467 0.02638458 0.03477388 0.03843151 0.02433577 0.02834547
  0.04598886 0.04733959]
 [0.03682783 0.03141687 0.03036659 0.02313888 0.02092448 0.02765368
  0.04811573 0.04596429 0.02803872 0.02811346 0.03649572 0.03145274
  0.04039696 0.01542294 0.01632184 0.04006419 0.0327441  0.03832939
  0.03965944 0.03809368 0.04400898 0.03873061 0.0253813  0.04218277
  0.032874   0.02650391 0.02231668 0.04151509 0.01814321 0.02292879
  0.02694918 0.04911717]
 [0.03639108 0.04442647 0.04220939 0.02811452 0.02378921 0.03219573
  0.06087763 0.06239581 0.03589751 0.03645712 0.07006898 0.04297788
  0.05869389 0.01844084 0.01989761 0.05664521 0.04821015 0.05149281
  0.04580869 0.04458387 0.04992514 0.03882508 0.03269099 0.05055577
  0.0429114  0.03811261 0.03436061 0.04996678 0.01997188 0.02455706
  0.03105319 0.05267799]
 [0.03657725 0.04244272 0.03912692 0.02652362 0.02254264 0.0294381
  0.05663475 0.0557257  0.03976097 0.03309785 0.0594479  0.03734418
  0.05242533 0.01719595 0.01810609 0.05200174 0.04291054 0.04707547
  0.03929763 0.0403773  0.04162475 0.03652255 0.02910432 0.04835173
  0.0374141  0.03711586 0.03140867 0.04518551 0.01850249 0.02268931
  0.03120071 0.06680828]
 [0.03743844 0.02729883 0.02985468 0.02284209 0.02154136 0.02743538
  0.03684514 0.0363692  0.02975533 0.02778634 0.05374662 0.03764365
  0.03763624 0.01713389 0.01662631 0.03264403 0.03265026 0.03066621
  0.03377736 0.0309924  0.03326327 0.03281156 0.02178705 0.02805718
  0.02634633 0.03123499 0.0248406  0.03660461 0.01980492 0.01839735
  0.03672717 0.05508104]
 [0.03563141 0.03421606 0.03469363 0.05306034 0.05002215 0.04544161
  0.03239397 0.03163378 0.04440058 0.05468987 0.03575698 0.03882429
  0.03545718 0.07135148 0.09112594 0.02801038 0.02912192 0.03223598
  0.02708463 0.02869103 0.02843119 0.03481248 0.03886825 0.02190327
  0.02202285 0.0368407  0.04144527 0.04307348 0.0451046  0.0112348
  0.01329547 0.0451575 ]
 [0.03520558 0.04101098 0.03705308 0.0674744  0.1512526  0.05214835
  0.03315188 0.03143879 0.03789734 0.06527305 0.04714586 0.04713328
  0.03367481 0.09503835 0.13118814 0.03927709 0.04908004 0.05616173
  0.03551923 0.03479813 0.04132491 0.03307451 0.04649608 0.0219133
  0.01997234 0.03550981 0.05127524 0.04104384 0.04176089 0.007885
  0.00794506 0.01509109]
 [0.03550252 0.03118164 0.02718891 0.03962831 0.07379671 0.02775508
  0.02403949 0.02379177 0.02584215 0.03884342 0.03511743 0.03074944
  0.02486076 0.02983342 0.0514835  0.03311618 0.0610659  0.06277745
  0.04943595 0.04133037 0.06696685 0.03040994 0.03534123 0.02806387
  0.02909937 0.03158737 0.0337407  0.04740128 0.0275402  0.00960761
  0.01043214 0.01517369]
 [0.03560619 0.03436974 0.03000508 0.0416753  0.04829232 0.03318301
  0.02976317 0.02727116 0.03478626 0.03963396 0.03236768 0.02906241
  0.0276624  0.03367151 0.04186267 0.02695636 0.04081453 0.04389411
  0.03658864 0.03487007 0.04085059 0.04187755 0.04225703 0.02315997
  0.02523838 0.03374935 0.02749734 0.05432896 0.02738708 0.00705002
  0.00866067 0.0146534 ]]

-* TASK 10/20 | SAMPLE 81/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 403/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Fred is either in the school or the school, which means Fred is in the school. There is no mention of the bedroom in relation to Fred.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' school', ',', ' which', ' means', ' Fred', ' is', ' in', ' the', ' school', '.', ' There', ' is', ' no', ' mention', ' of', ' the', ' bedroom', ' in', ' relation', ' to', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02100218 0.03378181 0.0326502  ... 0.01533906 0.02290076 0.03094293]
 [0.02144346 0.02646031 0.02591485 ... 0.01764921 0.01877783 0.02268299]
 [0.02194557 0.03454855 0.03555049 ... 0.0136374  0.01705575 0.0253205 ]
 ...
 [0.02198377 0.02979594 0.02747419 ... 0.01085457 0.01843359 0.03376811]
 [0.02243039 0.02505284 0.02164406 ... 0.01353856 0.01650584 0.03331233]
 [0.02245415 0.02471642 0.02125686 ... 0.01234826 0.01693041 0.02872434]]

-* TASK 10/20 | SAMPLE 81/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 404/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 11, Fred is in the bedroom, which explicitly states Fred's current location. There is no indication that Fred is in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' is', ' in', ' the', ' bedroom', ',', ' which', ' explicitly', ' states', ' Fred', "'s", ' current', ' location', '.', ' There', ' is', ' no', ' indication', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0769, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02396949 0.03029894 0.03498124 ... 0.00759395 0.02304827 0.0357782 ]
 [0.02444077 0.02250788 0.02645295 ... 0.01183095 0.01516287 0.0220816 ]
 [0.02494787 0.0330896  0.04176277 ... 0.0134631  0.02270464 0.03653382]
 ...
 [0.02506681 0.04009085 0.03663942 ... 0.00593674 0.04636476 0.04454816]
 [0.02567949 0.03158896 0.02609863 ... 0.00638319 0.03043491 0.02880104]
 [0.02547737 0.03325283 0.02748577 ... 0.00522387 0.03970072 0.03794961]]

-* TASK 10/20 | SAMPLE 81/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 405/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 14, Mary journeyed to the kitchen, which implies that Mary is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03031434 0.04253906 0.04585728 ... 0.03219511 0.03577323 0.08900156]
 [0.03086129 0.04068118 0.04574126 ... 0.03668359 0.0380302  0.03851261]
 [0.03165223 0.04303496 0.05356529 ... 0.02618949 0.03360082 0.04635858]
 ...
 [0.03181065 0.04730121 0.03750812 ... 0.02598175 0.03448437 0.05041676]
 [0.03214133 0.0350933  0.0259634  ... 0.03329864 0.04373968 0.0363953 ]
 [0.03200198 0.04239432 0.02931772 ... 0.02971167 0.03446104 0.05589794]]
Model's predictions for the sample 81:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Fred    |
|          |                 |  went to the kitchen, which implies that   |
|          |                 |     Fred is currently in the kitchen.      |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 5, Fred is  |
|          |                 |   in the cinema, which explicitly states   |
|          |                 |          Fred's current location.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to context sentence 7, Fred is  |
|          |                 |    either in the school or the school,     |
|          |                 |  which means Fred is in the school. There  |
|          |                 |  is no mention of the bedroom in relation  |
|          |                 |                  to Fred.                  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentence 11, Fred   |
|          |                 |    is in the bedroom, which explicitly     |
|          |                 |  states Fred's current location. There is  |
|          |                 |     no indication that Fred is in the      |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 14, Mary   |
|          |                 |  journeyed to the kitchen, which implies   |
|          |                 |   that Mary is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 81:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.14 ± 0.09 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 82/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 406/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only mention Fred being in the bedroom and Bill being in the office. There is no mention of Fred being in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' bedroom', ' and', ' Bill', ' being', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02672249 0.05036331 0.05394999 0.0836266  0.08246958 0.05332526
  0.03884995 0.03327392 0.03622866 0.05302071 0.039565   0.02512566
  0.02717934 0.13054141 0.13227774 0.0419815  0.02875793 0.01989557
  0.01754095 0.01916596 0.01907001 0.0401881  0.06436792 0.01399576
  0.01096207 0.02891876]
 [0.02758164 0.03162435 0.03191703 0.06182335 0.05831708 0.04551744
  0.02727482 0.02421227 0.02907417 0.0455707  0.03423316 0.0269598
  0.02692244 0.13256374 0.15712619 0.04002406 0.03122846 0.02355947
  0.01949478 0.02002299 0.01802618 0.03428417 0.03805591 0.00959525
  0.00884541 0.01904248]
 [0.02805201 0.03528283 0.04059367 0.06398448 0.0647283  0.05796395
  0.03623195 0.03371893 0.03826434 0.05352314 0.03919433 0.04327569
  0.04268659 0.10561106 0.09760719 0.03324321 0.02821081 0.02387519
  0.01877023 0.02000492 0.01700879 0.03089914 0.03495546 0.01305564
  0.01156774 0.0180076 ]
 [0.02713008 0.0414301  0.04800783 0.04969639 0.05266313 0.0538286
  0.0407048  0.04206857 0.04207933 0.04759385 0.03891663 0.04959308
  0.04404416 0.06220568 0.05634324 0.04082464 0.03467432 0.03112885
  0.02427906 0.02672383 0.02382009 0.03469412 0.05234051 0.03149539
  0.02892442 0.03041452]
 [0.02734228 0.0558828  0.06488612 0.03912428 0.03173909 0.04747063
  0.05066214 0.04963023 0.0471637  0.03720827 0.03492862 0.04203787
  0.04338096 0.02689311 0.02044315 0.0383742  0.03119128 0.02944355
  0.02415702 0.02799289 0.02546779 0.03194314 0.06624224 0.04009593
  0.03712156 0.03814154]
 [0.02822776 0.07203677 0.08138443 0.03571223 0.02418295 0.04345668
  0.04980022 0.04240203 0.04969141 0.03167258 0.02791851 0.03353602
  0.03220224 0.01942284 0.01637165 0.04348924 0.03036275 0.02559304
  0.02196988 0.02724293 0.02256937 0.03086123 0.07079781 0.02825678
  0.02667967 0.03139381]
 [0.02823314 0.04346116 0.05456791 0.03117402 0.02153042 0.03987797
  0.04574845 0.04258834 0.04442511 0.02992674 0.02726651 0.03494454
  0.03048889 0.01773196 0.01501465 0.03911269 0.0299932  0.02616011
  0.02301629 0.02694611 0.02358437 0.031477   0.05096657 0.03601959
  0.03683524 0.03933346]
 [0.02878858 0.03348279 0.03646887 0.02908487 0.02036751 0.04061819
  0.03934694 0.04074777 0.03557537 0.03020703 0.02996986 0.03841813
  0.0327945  0.01615682 0.01300642 0.02798093 0.0255563  0.02595505
  0.02182744 0.02417397 0.021159   0.02937303 0.02827962 0.02798905
  0.02776583 0.02762589]
 [0.02839236 0.02529158 0.02456413 0.01957334 0.01509427 0.02382809
  0.03124756 0.02973755 0.0244846  0.02092173 0.0309889  0.02318107
  0.02747063 0.01114445 0.01034123 0.0323589  0.03019704 0.02893
  0.02604039 0.02943543 0.03146593 0.02807534 0.02514404 0.05856406
  0.04593712 0.03187077]
 [0.02850109 0.01951187 0.01675311 0.01637883 0.0123116  0.01621866
  0.02333638 0.02166086 0.01802475 0.01624629 0.02103638 0.01567272
  0.01890816 0.00867902 0.00837712 0.02590672 0.02384347 0.0278559
  0.02736052 0.03179373 0.03821317 0.02474351 0.01918183 0.06268112
  0.05259777 0.0324365 ]
 [0.02883565 0.02119769 0.01818694 0.01696271 0.01366002 0.0177741
  0.02295792 0.02224472 0.01864634 0.01746435 0.02387012 0.01908551
  0.02063119 0.00899884 0.00884407 0.02819424 0.02695247 0.02591057
  0.02435067 0.02638725 0.03171127 0.02474667 0.01822468 0.0654398
  0.04495529 0.02299963]
 [0.02869442 0.01782262 0.01553769 0.01274283 0.01182429 0.0138618
  0.02167388 0.01949394 0.01656518 0.01375351 0.02812617 0.01605929
  0.01916398 0.00716689 0.00771394 0.0279721  0.03403041 0.02742409
  0.02946758 0.03040857 0.0372804  0.02337866 0.0191376  0.07142106
  0.04027685 0.02484555]
 [0.02811129 0.02001599 0.01705053 0.01365623 0.01270893 0.01464643
  0.0207267  0.01770915 0.01854159 0.01412623 0.02265669 0.01535141
  0.01764196 0.00763189 0.00837608 0.02744379 0.03178488 0.02723386
  0.02929202 0.03266115 0.03745446 0.02512537 0.02351931 0.08627305
  0.0571545  0.04564226]
 [0.02901652 0.01931006 0.01675844 0.01486556 0.0133416  0.01568965
  0.01960901 0.01850305 0.01772429 0.01552618 0.02294164 0.01689492
  0.01762046 0.00839138 0.00841943 0.02200351 0.02583547 0.02183873
  0.02382015 0.02725738 0.02979608 0.02479887 0.01903704 0.04480518
  0.04228455 0.03399419]
 [0.02930756 0.02036896 0.01887766 0.01571338 0.01344128 0.01770106
  0.02280405 0.0239417  0.02109824 0.01683519 0.01951385 0.01880324
  0.01961436 0.00846124 0.00796078 0.02164494 0.0221723  0.01997694
  0.02024359 0.02215857 0.02743318 0.02682487 0.01766977 0.02379057
  0.0593465  0.04493706]
 [0.02895854 0.01861185 0.01568684 0.01434088 0.01226868 0.01494351
  0.02210952 0.0223895  0.01758646 0.0151311  0.01972153 0.01587577
  0.01951547 0.00725865 0.00736535 0.02623367 0.02264827 0.02340974
  0.02412699 0.02478614 0.04002105 0.02407273 0.01499883 0.02521494
  0.07766966 0.05831352]
 [0.02936983 0.02090055 0.01967314 0.01651321 0.01438961 0.01863966
  0.02505295 0.02671858 0.02319594 0.01819488 0.021727   0.01963497
  0.02226823 0.0082414  0.00799842 0.02328512 0.02231108 0.020446
  0.01988246 0.02078018 0.02755385 0.02411977 0.01718877 0.0248294
  0.05393894 0.05381211]
 [0.02877973 0.01763197 0.01519499 0.01235731 0.0112899  0.01410163
  0.0215855  0.02030327 0.01750652 0.01371325 0.0263658  0.01606376
  0.02059894 0.00649231 0.00662456 0.02996714 0.03351213 0.03074586
  0.03494292 0.03119151 0.04118688 0.02348755 0.01605896 0.03120546
  0.04653757 0.07054096]
 [0.02807392 0.02698685 0.02507018 0.03024782 0.02931913 0.03581566
  0.03211261 0.02978858 0.03316895 0.04184496 0.0347294  0.05120744
  0.04990546 0.02405101 0.01711581 0.02571932 0.03004416 0.03852717
  0.04322908 0.02739924 0.02864066 0.0320753  0.02387672 0.01954397
  0.02539298 0.03773968]
 [0.02949863 0.02093318 0.01835651 0.01580136 0.0132793  0.01800307
  0.02308165 0.02269448 0.02119059 0.01680686 0.02410677 0.01987874
  0.02038612 0.0087023  0.00829899 0.02178592 0.02491078 0.02167237
  0.02630796 0.02341272 0.02506788 0.02735718 0.01698098 0.01789382
  0.02163376 0.0356699 ]
 [0.02879607 0.02820634 0.02972501 0.02880013 0.02302143 0.03653812
  0.03454242 0.03958717 0.0384063  0.03468866 0.03124487 0.04769926
  0.04041645 0.01921602 0.01383105 0.02533455 0.02548098 0.0275456
  0.02586753 0.02579994 0.0223873  0.03324049 0.02428624 0.01692717
  0.01704979 0.01909515]
 [0.02918207 0.02685373 0.02568544 0.02496417 0.02472011 0.02893855
  0.02998951 0.03354805 0.03039316 0.02817941 0.03091163 0.03704029
  0.03605567 0.0159096  0.01271181 0.02358815 0.02534604 0.02679445
  0.02570507 0.0272244  0.02187954 0.02645215 0.02293653 0.01615977
  0.01533247 0.01854308]
 [0.02939088 0.02694047 0.02714235 0.02321735 0.0197196  0.03303639
  0.03151581 0.03475374 0.03797215 0.02923497 0.02749471 0.04582385
  0.03834624 0.01558087 0.01122608 0.02125305 0.02381366 0.02369545
  0.02352178 0.02363996 0.0207388  0.02708204 0.02532578 0.01479832
  0.01479287 0.01875864]
 [0.02897342 0.03823623 0.03329226 0.02643265 0.02204542 0.03600023
  0.03683083 0.04476712 0.04050538 0.03427419 0.03344473 0.05508768
  0.0478632  0.01728476 0.01253246 0.0271288  0.0252438  0.02776151
  0.02497666 0.02564046 0.02277066 0.02891453 0.02692871 0.01560643
  0.01538231 0.0178408 ]
 [0.02966456 0.02718781 0.02926334 0.02416434 0.01883219 0.03253403
  0.0351205  0.03644835 0.03522668 0.02903071 0.02911382 0.04010165
  0.03641468 0.01448512 0.01097716 0.02160365 0.02064248 0.02110891
  0.02049537 0.0218753  0.02004042 0.02811341 0.01989485 0.01294706
  0.01263969 0.01306726]
 [0.0287     0.01951445 0.01778742 0.01448645 0.01198765 0.01573899
  0.02402987 0.0234599  0.02201753 0.01711697 0.02506302 0.01943024
  0.02520157 0.0089961  0.00806123 0.0273743  0.02801978 0.03183371
  0.03416755 0.03681123 0.0408489  0.02634293 0.01657631 0.03028631
  0.02528286 0.01832069]
 [0.02921354 0.01909364 0.01686409 0.01503193 0.01161524 0.01463656
  0.0212372  0.02125026 0.02003837 0.01618814 0.0207297  0.01729599
  0.02162438 0.00872901 0.0075377  0.02730481 0.02286397 0.03312951
  0.02992918 0.03685686 0.03794461 0.0244767  0.01324142 0.02491329
  0.02167144 0.01550817]
 [0.02935043 0.01983392 0.01774924 0.01536146 0.01272692 0.01543995
  0.01977432 0.02301845 0.02117818 0.01859892 0.02345478 0.02217977
  0.024246   0.00915635 0.00755353 0.02819197 0.02613996 0.03081421
  0.03005238 0.03112961 0.0328424  0.02270754 0.01319538 0.01983144
  0.01793019 0.0129429 ]
 [0.02921935 0.01724808 0.01605973 0.01217175 0.01108639 0.01278405
  0.0189883  0.01987725 0.01945261 0.01478968 0.02564619 0.01727703
  0.01957243 0.00771476 0.00659393 0.02542854 0.02896883 0.02659337
  0.03502685 0.03330449 0.03481179 0.02245419 0.01389144 0.02395651
  0.01915138 0.01625727]
 [0.02790875 0.02186584 0.01994215 0.01524788 0.01376247 0.015663
  0.02073813 0.02116363 0.02550589 0.01806816 0.02356707 0.01775788
  0.0203614  0.00931935 0.00871481 0.02799802 0.03345444 0.04436025
  0.05873881 0.07305998 0.04929083 0.02670833 0.0293646  0.0349894
  0.02556686 0.03077736]
 [0.02960776 0.01995158 0.01930558 0.01682034 0.01359495 0.01750269
  0.01967659 0.02160509 0.02359563 0.01922807 0.02313965 0.02115449
  0.02208012 0.01142661 0.00864862 0.01934659 0.02227807 0.02348786
  0.03113189 0.03080297 0.02619928 0.02497642 0.01654905 0.01403462
  0.01360587 0.01476834]
 [0.02821556 0.03147664 0.03038466 0.05336918 0.05573792 0.04101989
  0.02670193 0.02633172 0.03125732 0.05214555 0.03452776 0.03204551
  0.03322445 0.08435695 0.10060747 0.02731905 0.03004256 0.02624691
  0.02164264 0.02078289 0.01915971 0.03303269 0.03400921 0.01028492
  0.0110664  0.02107714]
 [0.02809254 0.03329128 0.03062526 0.05601181 0.11013988 0.03978718
  0.02396749 0.02458608 0.02914033 0.05402855 0.03886592 0.02914815
  0.02489415 0.0871196  0.10720712 0.03354881 0.04025033 0.03608963
  0.02831838 0.02418255 0.02273756 0.02988739 0.03447689 0.00867302
  0.00830291 0.01863428]
 [0.02794331 0.02540322 0.02433773 0.03803492 0.06316807 0.02609316
  0.01832392 0.02190413 0.02531844 0.04340741 0.03266476 0.02980416
  0.02757597 0.03101655 0.03389134 0.02512892 0.04564685 0.06022702
  0.06998401 0.03741255 0.03415906 0.0258477  0.02925374 0.01334742
  0.01385973 0.02003543]
 [0.02812421 0.03274938 0.02834978 0.04250595 0.05891515 0.03100524
  0.02364621 0.02387169 0.02975641 0.04173314 0.03235446 0.02655426
  0.02869922 0.03334228 0.03427964 0.02190497 0.03359066 0.04072963
  0.04032201 0.03153125 0.02765877 0.04723777 0.04304522 0.01107854
  0.01193781 0.01869329]]

-* TASK 10/20 | SAMPLE 82/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 407/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred in the context sentences. The sentences only talk about Julie being in the park and Bill being in the cinema.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', ' being', ' in', ' the', ' park', ' and', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 32), x_tokens=32, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 32)
DEBUG result.interpretability.attn_scores 1152 
 [[0.02576713 0.03662029 0.03679708 ... 0.01066882 0.01028583 0.01790844]
 [0.02657794 0.03702501 0.03469052 ... 0.01341038 0.01126235 0.02216134]
 [0.02716837 0.0333072  0.03519661 ... 0.01614704 0.01177321 0.02731721]
 ...
 [0.02747368 0.02640386 0.02203191 ... 0.00936722 0.01040832 0.01232675]
 [0.02770794 0.03008108 0.02738641 ... 0.00989396 0.01047783 0.01389756]
 [0.02794233 0.02707761 0.02544961 ... 0.01043568 0.01014875 0.01584211]]

-* TASK 10/20 | SAMPLE 82/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 408/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences mention Julie moving to the school, but there is no mention of Julie being in the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' mention', ' Julie', ' moving', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 38), x_tokens=38, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 38)
DEBUG result.interpretability.attn_scores 1102 
 [[0.0322471  0.04841818 0.04797461 ... 0.03392546 0.03140647 0.03556835]
 [0.03284186 0.04197919 0.03865207 ... 0.03086132 0.02812306 0.03315603]
 [0.03374052 0.05628677 0.05651386 ... 0.02867585 0.0200312  0.02672439]
 ...
 [0.03390289 0.03991483 0.04117932 ... 0.02461366 0.0183895  0.02975075]
 [0.03442634 0.03170694 0.03084013 ... 0.02763652 0.02665197 0.03148446]
 [0.03435936 0.03429359 0.03219248 ... 0.02508935 0.02566486 0.02917204]]

-* TASK 10/20 | SAMPLE 82/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 409/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 explicitly states that Mary moved to the cinema, but sentence 11 creates a contradiction by saying Mary is either in the park or the school. However, since sentence 10 is a more specific and direct statement, it takes precedence.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' explicitly', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' cinema', ',', ' but', ' sentence', ' ', '11', ' creates', ' a', ' contradiction', ' by', ' saying', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' school', '.', ' However', ',', ' since', ' sentence', ' ', '10', ' is', ' a', ' more', ' specific', ' and', ' direct', ' statement', ',', ' it', ' takes', ' precedence', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 44), x_tokens=44, y_tokens=56, max_supp_attn=0.0179, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 44)
DEBUG result.interpretability.attn_scores 2464 
 [[0.01599182 0.01764396 0.02178093 ... 0.0148476  0.0084024  0.01171215]
 [0.01647769 0.01962529 0.02154283 ... 0.02698276 0.01563607 0.0151261 ]
 [0.01689237 0.01933852 0.02503338 ... 0.02066883 0.01302854 0.01193083]
 ...
 [0.017206   0.02227142 0.02169152 ... 0.00800227 0.00790282 0.0105382 ]
 [0.01767469 0.01659277 0.01578703 ... 0.00787891 0.00704075 0.0107166 ]
 [0.01738221 0.02080777 0.01932747 ... 0.00797015 0.00765202 0.01157116]]

-* TASK 10/20 | SAMPLE 82/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 410/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 13 states that Mary is either in the office or the park, and sentence 14 mentions Bill going to the office, but it doesn't provide any information about Mary's location. Therefore, we can't conclude Mary's exact location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' park', ',', ' and', ' sentence', ' ', '14', ' mentions', ' Bill', ' going', ' to', ' the', ' office', ',', ' but', ' it', ' doesn', "'t", ' provide', ' any', ' information', ' about', ' Mary', "'s", ' location', '.', ' Therefore', ',', ' we', ' can', "'t", ' conclude', ' Mary', "'s", ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 50), x_tokens=50, y_tokens=56, max_supp_attn=0.0, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 50)
DEBUG result.interpretability.attn_scores 2800 
 [[0.01621413 0.02420308 0.02775234 ... 0.01262119 0.0086702  0.02383947]
 [0.0167196  0.01899624 0.0202435  ... 0.01200415 0.01829406 0.02236895]
 [0.01703136 0.02593275 0.03052205 ... 0.01197034 0.0075442  0.01602504]
 ...
 [0.01717783 0.0253804  0.02432657 ... 0.01095602 0.00835079 0.01927235]
 [0.0175819  0.01981311 0.01766947 ... 0.01543028 0.01705776 0.02195332]
 [0.01765422 0.02030789 0.01864038 ... 0.0135552  0.01266981 0.02005987]]
Model's predictions for the sample 82:

+----------+-----------------+-------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef               |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |  The context sentences only mention Fred  |
|          |                 |   being in the bedroom and Bill being in  |
|          |                 |  the office. There is no mention of Fred  |
|          |                 |             being in the park.            |
+----------+-----------------+-------------------------------------------+
|    no    |  not mentioned  |     There is no mention of Fred in the    |
|          |                 |   context sentences. The sentences only   |
|          |                 |   talk about Julie being in the park and  |
|          |                 |         Bill being in the cinema.         |
+----------+-----------------+-------------------------------------------+
|    no    |        no       |    The context sentences mention Julie    |
|          |                 |   moving to the school, but there is no   |
|          |                 |   mention of Julie being in the cinema.   |
+----------+-----------------+-------------------------------------------+
|    no    |       yes       |  Sentence 10 explicitly states that Mary  |
|          |                 |    moved to the cinema, but sentence 11   |
|          |                 |   creates a contradiction by saying Mary  |
|          |                 |    is either in the park or the school.   |
|          |                 |    However, since sentence 10 is a more   |
|          |                 |  specific and direct statement, it takes  |
|          |                 |                precedence.                |
+----------+-----------------+-------------------------------------------+
|  maybe   |      maybe      |   Sentence 13 states that Mary is either  |
|          |                 |  in the office or the park, and sentence  |
|          |                 |   14 mentions Bill going to the office,   |
|          |                 |   but it doesn't provide any information  |
|          |                 |    about Mary's location. Therefore, we   |
|          |                 |   can't conclude Mary's exact location.   |
+----------+-----------------+-------------------------------------------+

Metrics for sample 82:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.03 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 83/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 411/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 1, Fred journeyed to the school, which implies that Fred has arrived at the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Fred', ' has', ' arrived', ' at', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 26), x_tokens=26, y_tokens=31, max_supp_attn=0.0968, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 26)
DEBUG result.interpretability.attn_scores 806 
 [[0.03021297 0.05130695 0.05503179 0.08653729 0.08194191 0.05917018
  0.04148961 0.03599074 0.04098488 0.05824798 0.04348907 0.03013609
  0.03125492 0.13383204 0.13267416 0.03599148 0.03150111 0.02176139
  0.02269018 0.02164812 0.02368174 0.0451602  0.06832522 0.00957164
  0.01051151 0.04319124]
 [0.03120289 0.03217675 0.03275609 0.06458406 0.05839365 0.05090788
  0.02908648 0.02618989 0.03308006 0.05047357 0.03735748 0.03258528
  0.03115629 0.13592432 0.15758824 0.03458066 0.03393782 0.02560164
  0.02489001 0.02233999 0.02218706 0.03828672 0.04105146 0.00730995
  0.0086465  0.0286938 ]
 [0.031682   0.03636576 0.04350872 0.06737363 0.06437106 0.06582332
  0.03995542 0.03809578 0.04380057 0.0590167  0.04296251 0.05311693
  0.04957517 0.10846499 0.0965752  0.02930587 0.03114791 0.02608632
  0.0239144  0.02245718 0.02104371 0.03455115 0.03861305 0.01090655
  0.0118549  0.02823968]
 [0.0305709  0.04777    0.05577591 0.05262198 0.05367625 0.0610273
  0.04666488 0.04933247 0.0473198  0.05168344 0.04267651 0.05790503
  0.05062383 0.06471217 0.05667114 0.04057536 0.03996219 0.0338044
  0.02984381 0.02985489 0.02885074 0.03880527 0.05596362 0.03235646
  0.03443309 0.04597244]
 [0.03179996 0.04830154 0.05914808 0.06199997 0.05432286 0.07424697
  0.0565125  0.05803081 0.05873119 0.06249814 0.04566345 0.06183773
  0.05900683 0.05015527 0.03207509 0.02845437 0.03089139 0.02850212
  0.02647264 0.02749372 0.02424522 0.03954278 0.04289006 0.01669416
  0.01994906 0.03671559]
 [0.03117844 0.06156401 0.06595593 0.03722267 0.02882644 0.04664137
  0.05443774 0.05045678 0.05174966 0.03711898 0.034853   0.04372366
  0.04452789 0.02316532 0.01926061 0.04581223 0.03958938 0.0326067
  0.03254796 0.03369498 0.03251133 0.03749484 0.07337157 0.03928373
  0.04572282 0.04461081]
 [0.03180085 0.07694916 0.07716593 0.03443146 0.02700428 0.0399135
  0.0539149  0.04602236 0.05426022 0.03321119 0.03164287 0.03417974
  0.03413372 0.019735   0.01811545 0.04904005 0.04063078 0.03072077
  0.03252203 0.03538884 0.03223795 0.0341627  0.07809714 0.02984164
  0.03331903 0.04022267]
 [0.03197511 0.04238871 0.04870671 0.02662989 0.02125256 0.0294075
  0.04103212 0.03533692 0.0422702  0.02707463 0.02588549 0.0269902
  0.02589679 0.0163538  0.01568672 0.04106157 0.03527249 0.02633506
  0.03070401 0.03201494 0.03083863 0.03250207 0.06330755 0.04326785
  0.05619172 0.04923065]
 [0.03218262 0.01873133 0.01993624 0.01515767 0.01284237 0.01758906
  0.01910815 0.01889533 0.02310893 0.01659572 0.01677899 0.01674892
  0.01651881 0.00863998 0.00924863 0.02162527 0.02332686 0.02104957
  0.02863688 0.03125654 0.03355028 0.02454837 0.04153263 0.0580166
  0.09085289 0.05677258]
 [0.03211317 0.02717005 0.02841838 0.02091761 0.01732023 0.02555031
  0.02916402 0.02567581 0.02658863 0.02197838 0.0251999  0.02497073
  0.0233101  0.0122436  0.01287747 0.04092652 0.02933731 0.02765673
  0.02682191 0.02829101 0.02849405 0.03107485 0.03272825 0.05471053
  0.06797644 0.04551475]
 [0.03220718 0.02830944 0.02839024 0.02366773 0.01920886 0.02803333
  0.03339662 0.03239859 0.0297221  0.02613966 0.02945111 0.03403987
  0.03354573 0.01419977 0.0122515  0.03922252 0.03088497 0.03295221
  0.02912544 0.0305877  0.03018147 0.03369571 0.02488098 0.04923265
  0.04536316 0.02882467]
 [0.03163427 0.02415944 0.01949793 0.01787819 0.01376729 0.01831241
  0.02670267 0.02532582 0.02208605 0.01833233 0.02385678 0.02258072
  0.02505537 0.00921112 0.00889144 0.04379302 0.02712322 0.04340322
  0.03794    0.04707288 0.04614485 0.03092075 0.0192811  0.08468357
  0.05585086 0.03109025]
 [0.03268291 0.02531357 0.02454801 0.0213335  0.01972255 0.02571924
  0.03269875 0.03076148 0.02682103 0.02306315 0.02638131 0.0295591
  0.02801782 0.01181981 0.0102927  0.03628812 0.02301861 0.0338228
  0.02584172 0.03494976 0.0292449  0.02713043 0.02054073 0.05816791
  0.03947707 0.02861156]
 [0.03267871 0.02018027 0.01753961 0.0149226  0.01307637 0.01643255
  0.02216324 0.02246569 0.02004028 0.01680806 0.02541506 0.0226446
  0.02375079 0.00800289 0.00777169 0.04253981 0.02633655 0.04042196
  0.03315499 0.04411144 0.03640112 0.02514529 0.01549959 0.06039148
  0.03654968 0.02201005]
 [0.03268803 0.01822754 0.01567203 0.01286289 0.01125559 0.01465989
  0.02029452 0.02034527 0.01868224 0.01505993 0.02673012 0.01935346
  0.02178206 0.00687185 0.00718589 0.03445452 0.02927238 0.03731913
  0.03826436 0.0416121  0.03553215 0.02542293 0.01628458 0.05619178
  0.03948459 0.02613358]
 [0.03165381 0.02872652 0.02817971 0.02091761 0.01920609 0.02925156
  0.0335384  0.03742017 0.03612342 0.0259125  0.02686109 0.03036944
  0.03273302 0.01092803 0.0108702  0.02780112 0.03654151 0.03648534
  0.05185325 0.04421072 0.04687028 0.03027603 0.02755672 0.04218706
  0.04686319 0.05476445]
 [0.03310244 0.02316227 0.02091177 0.01834504 0.01494422 0.01990964
  0.02347367 0.02463354 0.02202914 0.01956853 0.02619554 0.02380262
  0.02387688 0.00991556 0.0093422  0.02431929 0.02382526 0.02491461
  0.03054234 0.02809553 0.02925093 0.02973911 0.01748032 0.02966246
  0.03526645 0.02963708]
 [0.03318635 0.02689171 0.02859352 0.02710331 0.02147964 0.03135017
  0.0307968  0.03702147 0.02831346 0.03004579 0.0312553  0.04207271
  0.03702377 0.01656219 0.01127352 0.02188796 0.02400293 0.02650901
  0.02468817 0.023757   0.023573   0.03186579 0.01762832 0.01818963
  0.02550934 0.02446228]
 [0.03335416 0.03186372 0.03199744 0.03148574 0.02375042 0.03421869
  0.03671202 0.044125   0.02973    0.03466468 0.03916167 0.04743174
  0.04406599 0.01876955 0.01220588 0.02364597 0.02390304 0.02815221
  0.02465869 0.02442891 0.02348265 0.0320349  0.01892251 0.01597857
  0.01862573 0.01930465]
 [0.03315533 0.0298607  0.02881948 0.02913014 0.02352611 0.03191109
  0.03345754 0.03885216 0.03013631 0.03390748 0.03640059 0.04254883
  0.04263282 0.01769744 0.01238265 0.02725593 0.02610822 0.03132582
  0.02746655 0.02680901 0.02589048 0.03206695 0.01664643 0.02012537
  0.02056562 0.01769557]
 [0.03303085 0.02291514 0.02070578 0.017436   0.01380329 0.01909857
  0.02424686 0.02740137 0.02391522 0.0202105  0.02612738 0.02532042
  0.02945223 0.0097591  0.00843577 0.03207349 0.02891169 0.03280225
  0.03072587 0.02892198 0.0326696  0.02986265 0.01537702 0.03177739
  0.03291176 0.02025222]
 [0.03295541 0.02394874 0.02079925 0.01838284 0.01379637 0.01827018
  0.02734626 0.02819365 0.02408439 0.02013643 0.0272099  0.02294655
  0.02959205 0.00942231 0.00867242 0.03507159 0.02950036 0.03805894
  0.03587439 0.03330555 0.03771144 0.02649134 0.01458617 0.03246852
  0.03378271 0.02209229]
 [0.03344608 0.02281716 0.01987635 0.01743272 0.01315806 0.0185344
  0.02453154 0.02708857 0.02432785 0.01990268 0.02619153 0.02405884
  0.0297893  0.00915008 0.00774473 0.03334033 0.02691915 0.03602705
  0.03142746 0.0328414  0.03256152 0.02477784 0.01312833 0.0286579
  0.02463839 0.017461  ]
 [0.0336572  0.02213214 0.0196395  0.01732751 0.01286867 0.01838497
  0.02457696 0.0242092  0.02459662 0.01937265 0.02787144 0.02246236
  0.02651724 0.00935566 0.00807858 0.03058089 0.02697445 0.03213402
  0.03208379 0.03207481 0.03229919 0.02571689 0.01258914 0.02723467
  0.02083818 0.01648554]
 [0.0333552  0.02155464 0.01905145 0.01367659 0.01085128 0.01540274
  0.02687991 0.02523865 0.02394526 0.01603605 0.04334206 0.02072802
  0.02777188 0.00799939 0.00719133 0.03338048 0.0327976  0.03365764
  0.0403015  0.03611704 0.03629304 0.02746844 0.01377249 0.03506696
  0.02316718 0.01981598]
 [0.0316755  0.03419365 0.02932675 0.01983434 0.017251   0.02368994
  0.04101108 0.03624201 0.04120147 0.02425161 0.03368896 0.02544281
  0.03410251 0.01109291 0.01060452 0.03020099 0.04050912 0.0458814
  0.06365513 0.07131501 0.06100906 0.03338863 0.03461834 0.0433236
  0.04114126 0.05323976]
 [0.03350023 0.02218243 0.01986636 0.01708258 0.01301406 0.01800488
  0.02172901 0.02321566 0.02495866 0.0187422  0.02427508 0.02173876
  0.02398799 0.01002853 0.00796635 0.0202764  0.0243333  0.02308666
  0.03162777 0.02744203 0.03081153 0.02692215 0.01464093 0.02318912
  0.02863597 0.02539126]
 [0.03211374 0.03098881 0.03061264 0.04872941 0.05049023 0.04186266
  0.02849053 0.02909617 0.0331022  0.04950239 0.03546776 0.03608153
  0.03362812 0.07764198 0.09788832 0.02205325 0.03046791 0.02527652
  0.02563125 0.02310862 0.02429608 0.03555937 0.03563414 0.00846398
  0.0119445  0.03117607]
 [0.03174528 0.03436014 0.03187856 0.05831289 0.1117902  0.04486438
  0.02660076 0.02776289 0.03357807 0.06058541 0.04266448 0.037253
  0.02934112 0.08841845 0.10761932 0.02864197 0.04526911 0.03641895
  0.03074163 0.02544574 0.02918936 0.03338657 0.03752945 0.00730043
  0.00807286 0.02790428]
 [0.03164812 0.02889994 0.02638564 0.0421229  0.08583131 0.02825857
  0.02155953 0.02573734 0.02731587 0.0468555  0.0373067  0.03582128
  0.02780309 0.03376989 0.04246836 0.02438447 0.06357946 0.05258374
  0.04188159 0.03019724 0.04509787 0.02850366 0.03011119 0.01483407
  0.01815203 0.0332786 ]
 [0.03181039 0.03658774 0.03130414 0.04453931 0.05725688 0.03355272
  0.02842739 0.02843851 0.03339626 0.04300369 0.0376368  0.03154898
  0.02952588 0.03615687 0.04008991 0.02141463 0.04412388 0.03464179
  0.03347019 0.02915534 0.03384875 0.0534956  0.04741091 0.01091366
  0.01370143 0.03120468]]

-* TASK 10/20 | SAMPLE 83/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 412/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie being in the bedroom. According to context sentence 5, Julie went to the kitchen, which implies that Julie is currently in the kitchen, not in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' bedroom', '.', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' kitchen', ',', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.1522, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02008669 0.03166018 0.03426182 ... 0.01237753 0.00919031 0.00611184]
 [0.02055543 0.03116815 0.03048533 ... 0.01999807 0.01932662 0.01057832]
 [0.02102488 0.02917167 0.03227371 ... 0.02492913 0.01675178 0.0093423 ]
 ...
 [0.0210647  0.02775227 0.0245983  ... 0.00669527 0.00651576 0.00474231]
 [0.02154189 0.02198556 0.0189423  ... 0.00690867 0.0077523  0.00662877]
 [0.02151315 0.02152593 0.01797402 ... 0.00586328 0.00696731 0.00621188]]

-* TASK 10/20 | SAMPLE 83/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 413/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie being in the kitchen. According to context sentence 7, Fred went to the kitchen, but there is no mention of Julie being in the kitchen.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' kitchen', '.', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.1364, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02110491 0.03373232 0.02951082 ... 0.01880887 0.01302107 0.02313174]
 [0.02129296 0.03225695 0.03280741 ... 0.04312246 0.04230418 0.05163943]
 [0.02201017 0.03451289 0.03524023 ... 0.01445246 0.00933831 0.01564801]
 ...
 [0.02254196 0.02705273 0.02229716 ... 0.01606035 0.01520025 0.01780086]
 [0.02273758 0.02889104 0.02584261 ... 0.014359   0.0121681  0.01491657]
 [0.02278758 0.02699555 0.0255692  ... 0.0156923  0.01268488 0.01604135]]

-* TASK 10/20 | SAMPLE 83/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 414/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 11, Julie is in the park, which implies that Julie is not in the school. There is no information about Julie being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Julie', ' is', ' in', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' not', ' in', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.122, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02267564 0.02870749 0.031787   ... 0.01308095 0.01629414 0.01064824]
 [0.02306959 0.02371733 0.02486952 ... 0.0134558  0.03969141 0.02090407]
 [0.02362847 0.03194616 0.0371261  ... 0.01861711 0.02764775 0.01345014]
 ...
 [0.02385963 0.03271481 0.03311941 ... 0.0062819  0.00779097 0.00712164]
 [0.02443508 0.0253716  0.02500039 ... 0.00710926 0.00658462 0.00813771]
 [0.02419705 0.02986959 0.02809726 ... 0.00680302 0.00715293 0.00820868]]

-* TASK 10/20 | SAMPLE 83/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 415/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, Fred journeyed to the bedroom, which implies that Fred has arrived at the bedroom and is still there, as there is no information about Fred leaving the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' has', ' arrived', ' at', ' the', ' bedroom', ' and', ' is', ' still', ' there', ',', ' as', ' there', ' is', ' no', ' information', ' about', ' Fred', ' leaving', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0217, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.02019764 0.02498296 0.03160173 ... 0.03592629 0.03039429 0.0108789 ]
 [0.02052526 0.01940085 0.02674245 ... 0.0173369  0.0240098  0.01972525]
 [0.02101794 0.0249798  0.03449792 ... 0.03286312 0.02201474 0.00891928]
 ...
 [0.02118311 0.02851971 0.02744749 ... 0.05254183 0.02375178 0.00907591]
 [0.02157225 0.02218796 0.01989027 ... 0.03868258 0.02220673 0.01526321]
 [0.02134614 0.02686102 0.02348554 ... 0.0743867  0.02647483 0.01106541]]
Model's predictions for the sample 83:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Fred    |
|          |                 |   journeyed to the school, which implies   |
|          |                 |    that Fred has arrived at the school.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    There is no information about Julie     |
|          |                 |     being in the bedroom. According to     |
|          |                 |   context sentence 5, Julie went to the    |
|          |                 |    kitchen, which implies that Julie is    |
|          |                 |    currently in the kitchen, not in the    |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |    There is no information about Julie     |
|          |                 |     being in the kitchen. According to     |
|          |                 |    context sentence 7, Fred went to the    |
|          |                 |    kitchen, but there is no mention of     |
|          |                 |        Julie being in the kitchen.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to context sentence 11, Julie   |
|          |                 |  is in the park, which implies that Julie  |
|          |                 |     is not in the school. There is no      |
|          |                 |    information about Julie being in the    |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 10, Fred   |
|          |                 |  journeyed to the bedroom, which implies   |
|          |                 |  that Fred has arrived at the bedroom and  |
|          |                 |       is still there, as there is no       |
|          |                 |     information about Fred leaving the     |
|          |                 |                  bedroom.                  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 83:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.11 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 84/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 416/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 1 explicitly states that Julie is in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03740475 0.05685274 0.06904221 0.08765187 0.08941406 0.08787724
  0.07310287 0.08567312 0.06640909 0.07619665 0.05844008 0.07096805
  0.08367997 0.10040632 0.06194951 0.03849218 0.03557609 0.04196894
  0.03887532 0.04222637 0.03574808 0.04974129 0.04467323 0.02306508
  0.02817729 0.04225475]
 [0.03785272 0.06497558 0.06016723 0.0732329  0.0624413  0.06610163
  0.07033496 0.07232721 0.05837459 0.05819147 0.04940094 0.04630297
  0.05654576 0.10460769 0.10037025 0.04130313 0.03378076 0.03649687
  0.03643252 0.03837983 0.0321229  0.0498139  0.04874057 0.01941177
  0.02112352 0.03932752]
 [0.04081928 0.06839423 0.0405894  0.06028664 0.0431861  0.04150419
  0.03851779 0.02826888 0.0278541  0.04006554 0.03460166 0.02006041
  0.02463597 0.03022222 0.03705428 0.02861602 0.01652465 0.01868312
  0.02414798 0.02478209 0.0225558  0.05644793 0.05512228 0.00967276
  0.00985683 0.02099468]
 [0.03834433 0.04044435 0.05199126 0.03099877 0.02077303 0.03766878
  0.04146102 0.03806169 0.04980505 0.03421084 0.03393653 0.03724672
  0.03557923 0.01652785 0.0151521  0.04937028 0.04252024 0.04244299
  0.04386894 0.04475419 0.04406605 0.04304172 0.0682608  0.06962518
  0.0828386  0.06391213]
 [0.03882094 0.04908839 0.05117697 0.07505278 0.0652113  0.05456336
  0.04167718 0.03681775 0.04177232 0.05289524 0.04220405 0.0308435
  0.03342296 0.10037235 0.10019563 0.04447417 0.03141019 0.02872126
  0.03060478 0.03300331 0.03106541 0.04967797 0.06539629 0.01689692
  0.01472384 0.04660397]
 [0.03956838 0.03174578 0.03127824 0.05797014 0.04944818 0.04995424
  0.03127199 0.02886654 0.035682   0.04975741 0.03746495 0.03516958
  0.03636306 0.11218052 0.12999035 0.04452453 0.03578991 0.03506105
  0.03493774 0.03573518 0.03015773 0.04291864 0.03910799 0.01200313
  0.01208813 0.02991455]
 [0.04014548 0.03546122 0.04060102 0.06032556 0.05306127 0.06249392
  0.04052078 0.0390068  0.04632108 0.05784935 0.04340013 0.05507613
  0.05453929 0.08981411 0.08221716 0.03739611 0.03249364 0.03414521
  0.03315781 0.03474053 0.02818659 0.03841832 0.03706869 0.01635028
  0.01686517 0.02830803]
 [0.03883913 0.05045978 0.05973372 0.04999159 0.04840305 0.06006889
  0.04855913 0.05310049 0.05238315 0.053608   0.04622841 0.06257432
  0.05734925 0.05582484 0.04874015 0.05161969 0.04309773 0.04296789
  0.03937504 0.04182867 0.03694345 0.04330562 0.05426705 0.04031438
  0.03908724 0.04653723]
 [0.03920948 0.05923435 0.06874098 0.03947082 0.03048731 0.0502151
  0.05839512 0.06090442 0.05935816 0.0432084  0.0417898  0.05375485
  0.05615082 0.02678165 0.01913101 0.05110557 0.03954245 0.03970367
  0.03860928 0.04025789 0.03787227 0.03895717 0.06347202 0.04804416
  0.05414128 0.05555761]
 [0.04026122 0.07777671 0.08350011 0.03411235 0.02361036 0.04389054
  0.05691089 0.05208103 0.06137649 0.03473577 0.03337203 0.04290006
  0.04272898 0.0171272  0.01409384 0.05709248 0.0386894  0.03746848
  0.03945735 0.04365072 0.03742601 0.03794101 0.07100404 0.03607829
  0.04121776 0.04550705]
 [0.04017133 0.04608993 0.05259997 0.02749289 0.02082042 0.03246943
  0.04771975 0.04466172 0.04867316 0.03021938 0.0302491  0.03630861
  0.03477271 0.01552875 0.01403242 0.05609483 0.04262    0.03772273
  0.04186194 0.04338986 0.03940773 0.03793481 0.0570728  0.05511886
  0.0641731  0.04781868]
 [0.04040137 0.0261145  0.03017971 0.0183452  0.01540267 0.02324898
  0.03044102 0.03160607 0.04323266 0.02325445 0.02192032 0.02410043
  0.02456636 0.01088055 0.01103529 0.04245779 0.04069028 0.03423652
  0.04088746 0.04417725 0.03978918 0.03321266 0.05325803 0.08051883
  0.09893451 0.05306224]
 [0.04043692 0.03478625 0.03612019 0.02337518 0.01896586 0.03185819
  0.03677059 0.03560955 0.03547716 0.02697925 0.03018201 0.03656032
  0.03291454 0.01213584 0.01200548 0.04843253 0.03540405 0.03459029
  0.03549038 0.03721234 0.03646641 0.03680198 0.03608217 0.06091506
  0.0774475  0.05188601]
 [0.04106139 0.04475162 0.04690887 0.03961404 0.02837958 0.051757
  0.05075304 0.05683517 0.04742472 0.05092131 0.05086686 0.07879712
  0.06363043 0.02118558 0.01480973 0.03586326 0.03549327 0.0401739
  0.03825433 0.03916002 0.03437669 0.04025803 0.02599947 0.02725223
  0.02859656 0.02739719]
 [0.04151652 0.03299648 0.03308202 0.02601238 0.02125693 0.03091869
  0.03839411 0.03746831 0.03182897 0.03072418 0.03808779 0.03945906
  0.03888854 0.0131826  0.01176298 0.03722298 0.03238861 0.03273728
  0.03385009 0.0354343  0.03483719 0.03749979 0.0234813  0.04406934
  0.03655724 0.02511226]
 [0.0408686  0.02586329 0.02223613 0.01712779 0.01453962 0.01951305
  0.02849207 0.0276941  0.02459086 0.02059124 0.03346101 0.02692373
  0.03028313 0.00825737 0.00900126 0.03967581 0.03831294 0.03652148
  0.03545658 0.03697068 0.04576879 0.03394523 0.02115942 0.07544547
  0.05894216 0.03111119]
 [0.04044059 0.02466891 0.02010789 0.01623263 0.01288836 0.01817231
  0.03271779 0.03355777 0.02369205 0.01923951 0.03365209 0.02444251
  0.03205052 0.00731665 0.00766808 0.036723   0.04528947 0.0501508
  0.04275116 0.0431434  0.06342821 0.03126115 0.01875003 0.08280028
  0.06558745 0.03990857]
 [0.04119312 0.02376866 0.02036621 0.01599756 0.01370775 0.01941357
  0.02859294 0.02964436 0.0238757  0.02016694 0.04072937 0.03038041
  0.03183262 0.00767948 0.00751559 0.03541298 0.04231206 0.040368
  0.04237857 0.03903358 0.05245295 0.03018832 0.01591989 0.07143602
  0.04452512 0.02640392]
 [0.04102829 0.02115193 0.0180735  0.01306146 0.01191057 0.01642483
  0.02848247 0.02766979 0.02280031 0.0173377  0.05678745 0.02961185
  0.02985036 0.00658505 0.00685469 0.0361121  0.04989431 0.04405979
  0.04893385 0.04565682 0.05855711 0.02911637 0.01497527 0.07052043
  0.04126455 0.03361755]
 [0.03946925 0.02918806 0.02568278 0.02113963 0.02414789 0.02479198
  0.03445419 0.03366357 0.03837664 0.02728616 0.03670938 0.02940197
  0.03324592 0.01556509 0.02172047 0.03515657 0.06128482 0.0564567
  0.06975935 0.06395891 0.06004247 0.03811236 0.03749881 0.05664885
  0.06667612 0.08629661]
 [0.0417774  0.0248191  0.02480146 0.02157553 0.01575812 0.02366346
  0.02625493 0.02971014 0.02891183 0.02467326 0.03007844 0.03071428
  0.02967181 0.01116235 0.00967161 0.02372748 0.02724318 0.02949111
  0.03449974 0.03679064 0.03698665 0.03179557 0.01688265 0.02675152
  0.0338257  0.0349414 ]
 [0.04050676 0.03128001 0.02916341 0.04760348 0.04538612 0.04481237
  0.03043982 0.03044506 0.03506219 0.05104038 0.0391628  0.03896536
  0.03899901 0.07368543 0.08386307 0.03037237 0.03178779 0.03449241
  0.03365901 0.03289608 0.03020047 0.03932865 0.03249997 0.01244173
  0.01552054 0.03202281]
 [0.04018004 0.03261653 0.0282061  0.05202632 0.09433793 0.04210216
  0.02855812 0.02829891 0.03323633 0.05710639 0.04449848 0.03773595
  0.03285855 0.07294072 0.0930716  0.03650247 0.04420226 0.04872866
  0.04002322 0.03685465 0.03632532 0.03644444 0.0312215  0.01059135
  0.01104401 0.02750948]
 [0.03958838 0.03112356 0.02667405 0.04635493 0.10583069 0.03093969
  0.02525344 0.02783851 0.02947159 0.05259504 0.04704962 0.04298222
  0.03228354 0.0360989  0.04880416 0.03354406 0.0750696  0.07207462
  0.05789078 0.04417405 0.05329766 0.03387349 0.0290753  0.01857148
  0.01954542 0.03275697]
 [0.04009435 0.03634806 0.0289766  0.0449476  0.07063153 0.03557644
  0.03192404 0.03018912 0.03400976 0.04714619 0.04572665 0.03871962
  0.03315664 0.03393089 0.03928934 0.02870753 0.04858235 0.05053627
  0.0448368  0.04178866 0.04191888 0.05996353 0.03901046 0.01545653
  0.01724035 0.03123761]]

-* TASK 10/20 | SAMPLE 84/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 417/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred being in the office in the context sentences. Sentence 4 states that Fred is in the park, and sentence 5 states that Fred moved to the kitchen, but there is no information about the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' office', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '4', ' states', ' that', ' Fred', ' is', ' in', ' the', ' park', ',', ' and', ' sentence', ' ', '5', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 32), x_tokens=32, y_tokens=54, max_supp_attn=0.1111, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 32)
DEBUG result.interpretability.attn_scores 1728 
 [[0.0170032  0.02634966 0.02714796 ... 0.04280951 0.00827222 0.05632092]
 [0.01741907 0.02696848 0.02587278 ... 0.04966164 0.01362569 0.06375793]
 [0.01777479 0.02548051 0.02771125 ... 0.04727888 0.01920079 0.04925099]
 ...
 [0.01783582 0.02314239 0.02054766 ... 0.01494187 0.00583002 0.06881155]
 [0.01807693 0.01909159 0.01583738 ... 0.00941503 0.00807614 0.04384983]
 [0.01818645 0.01923204 0.01593442 ... 0.00823174 0.00701969 0.05905389]]

-* TASK 10/20 | SAMPLE 84/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 418/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 states that Fred is either in the office or the office, which means Fred is definitely in the office because the two options are the same.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' office', ',', ' which', ' means', ' Fred', ' is', ' definitely', ' in', ' the', ' office', ' because', ' the', ' two', ' options', ' are', ' the', ' same', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 38), x_tokens=38, y_tokens=38, max_supp_attn=0.0526, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 38)
DEBUG result.interpretability.attn_scores 1444 
 [[0.02414413 0.04298294 0.04017115 ... 0.01939856 0.0363613  0.03940905]
 [0.02435884 0.03778123 0.03657584 ... 0.03354041 0.04374721 0.0348254 ]
 [0.02517966 0.04340984 0.04760196 ... 0.01742279 0.03738196 0.02180099]
 ...
 [0.02536528 0.03871557 0.03575151 ... 0.01491097 0.04955054 0.03163429]
 [0.02566655 0.03114741 0.02627174 ... 0.02267103 0.04685523 0.03567626]
 [0.02567181 0.0336073  0.027016   ... 0.02075247 0.03805658 0.05823931]]

-* TASK 10/20 | SAMPLE 84/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 419/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred being in the office in the context sentences. Sentence 10 states that Bill went to the office, and sentence 11 states that Julie moved to the kitchen, but there is no information about Fred's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' office', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' went', ' to', ' the', ' office', ',', ' and', ' sentence', ' ', '11', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 44), x_tokens=44, y_tokens=56, max_supp_attn=0.0714, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 44)
DEBUG result.interpretability.attn_scores 2464 
 [[0.01653117 0.02226126 0.02214119 ... 0.01008541 0.00585717 0.00543074]
 [0.0169425  0.01626623 0.01845725 ... 0.01384846 0.00940564 0.01211407]
 [0.01726218 0.02253083 0.02549554 ... 0.01354772 0.00773452 0.00882665]
 ...
 [0.0176686  0.02175698 0.01891722 ... 0.00613992 0.00680805 0.00549506]
 [0.0177907  0.02767309 0.02740948 ... 0.00699137 0.00543054 0.00475831]
 [0.01792765 0.02306074 0.02280038 ... 0.00754573 0.00627751 0.00503897]]

-* TASK 10/20 | SAMPLE 84/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 420/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill being in the cinema in the context sentences. Sentence 13 states that Julie moved to the cinema, and sentence 14 states that Mary went back to the school, but there is no information about Bill's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' cinema', ',', ' and', ' sentence', ' ', '14', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 50), x_tokens=50, y_tokens=57, max_supp_attn=0.1228, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 50)
DEBUG result.interpretability.attn_scores 2850 
 [[0.01628422 0.02507554 0.02421942 ... 0.03158989 0.02008211 0.01013609]
 [0.01653642 0.02377892 0.02170726 ... 0.01637868 0.0232613  0.01326047]
 [0.01694847 0.02760778 0.02788915 ... 0.02953487 0.01790709 0.00784972]
 ...
 [0.01747042 0.01861089 0.01874011 ... 0.02164662 0.01788209 0.0111492 ]
 [0.01763229 0.02062533 0.02106302 ... 0.02820765 0.01358484 0.00685412]
 [0.01734928 0.02095445 0.02108635 ... 0.05141362 0.01845849 0.00967332]]
Model's predictions for the sample 84:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 1 explicitly states  |
|          |                 |       that Julie is in the bedroom.        |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Fred being in the  |
|          |                 |      office in the context sentences.      |
|          |                 |   Sentence 4 states that Fred is in the    |
|          |                 |   park, and sentence 5 states that Fred    |
|          |                 |   moved to the kitchen, but there is no    |
|          |                 |       information about the office.        |
+----------+-----------------+--------------------------------------------+
|  maybe   |       yes       |  Sentence 8 states that Fred is either in  |
|          |                 |   the office or the office, which means    |
|          |                 |  Fred is definitely in the office because  |
|          |                 |       the two options are the same.        |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |  There is no mention of Fred being in the  |
|          |                 |      office in the context sentences.      |
|          |                 |  Sentence 10 states that Bill went to the  |
|          |                 |    office, and sentence 11 states that     |
|          |                 |  Julie moved to the kitchen, but there is  |
|          |                 |   no information about Fred's location.    |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |  There is no mention of Bill being in the  |
|          |                 |      cinema in the context sentences.      |
|          |                 |   Sentence 13 states that Julie moved to   |
|          |                 |  the cinema, and sentence 14 states that   |
|          |                 |  Mary went back to the school, but there   |
|          |                 |  is no information about Bill's location.  |
+----------+-----------------+--------------------------------------------+

Metrics for sample 84:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.4     |
|    Soft-match accuracy     |     0.4     |
| Max attention distribution | 0.09 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 85/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 421/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Bill travelled to the bedroom, which implies that Bill is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.0272526  0.04303122 0.05343237 0.0706101  0.08121179 0.07261948
  0.05666506 0.06399219 0.0535327  0.06371149 0.04502956 0.05849955
  0.0650221  0.09656664 0.06326441 0.02758163 0.03126007 0.03124118
  0.03010283 0.03062051 0.0245677  0.0384857  0.04037824 0.01579384
  0.0171304  0.03577093]
 [0.0276127  0.05154315 0.04976229 0.06609114 0.06025715 0.05713687
  0.04721189 0.04690261 0.04231466 0.0474708  0.03659687 0.03174834
  0.03463241 0.10447873 0.10192928 0.02833045 0.026347   0.02267775
  0.02427615 0.02343408 0.01966232 0.038971   0.04222504 0.01214892
  0.01109361 0.03152495]
 [0.02982153 0.05610797 0.03399388 0.04924804 0.03576618 0.03363748
  0.03059892 0.02131314 0.02149347 0.03224844 0.02633947 0.01580984
  0.01758257 0.02488525 0.03293482 0.01947816 0.01368471 0.01289535
  0.01745622 0.0167508  0.01507884 0.04232764 0.04857126 0.00711017
  0.00640206 0.01651416]
 [0.02815482 0.02403232 0.02509224 0.02697598 0.01929974 0.02648235
  0.02840073 0.02463406 0.02531208 0.02542267 0.0302949  0.02934249
  0.02652284 0.01342212 0.01279488 0.03330605 0.02752404 0.04067425
  0.03242202 0.03994797 0.03434779 0.02902131 0.02856321 0.06313701
  0.05595028 0.03524265]
 [0.02822064 0.04063092 0.04427307 0.06452768 0.05882208 0.04683641
  0.0342112  0.02915625 0.03360178 0.04433486 0.03304566 0.02493127
  0.02520116 0.09208786 0.09568709 0.03156964 0.02683746 0.02035573
  0.02275513 0.02302115 0.02140274 0.03857923 0.06024364 0.01269122
  0.00960381 0.03847741]
 [0.02879577 0.02570547 0.0268066  0.0493763  0.04361775 0.04206257
  0.02527912 0.022474   0.02835367 0.04150712 0.02907424 0.02830417
  0.02709847 0.10319939 0.12528655 0.03155117 0.03074335 0.02464307
  0.02561997 0.02448854 0.0204832  0.03256721 0.03539209 0.0088254
  0.00773811 0.02463096]
 [0.02920201 0.02920896 0.03510368 0.05199829 0.04775668 0.05323689
  0.03351642 0.03134325 0.03718827 0.04871353 0.03399912 0.04483824
  0.04114489 0.081323   0.07740297 0.02682697 0.0279017  0.02435112
  0.0246392  0.02422949 0.01935465 0.02944115 0.03339157 0.01184736
  0.01096026 0.0239476 ]
 [0.02815622 0.04096364 0.04816589 0.04104589 0.04230655 0.05008124
  0.03951726 0.04119934 0.04076202 0.04346708 0.03536365 0.04996584
  0.04317312 0.04975462 0.04534182 0.03932887 0.03623733 0.0317708
  0.03001993 0.03075889 0.02690956 0.0334266  0.04758032 0.03173064
  0.03214566 0.03871856]
 [0.02930798 0.04009549 0.04857566 0.0452867  0.04055568 0.05663378
  0.04397055 0.04642658 0.0486257  0.04851185 0.03520722 0.05013014
  0.04673411 0.0370817  0.02457733 0.02632838 0.02784724 0.02612375
  0.02694484 0.02785564 0.02206204 0.03424587 0.03774427 0.0174999
  0.0190007  0.0323949 ]
 [0.02866008 0.05410356 0.05666164 0.02967358 0.02354022 0.03868352
  0.04771138 0.04454383 0.04606533 0.03136646 0.02947504 0.03894051
  0.03965729 0.01732696 0.01495457 0.04405307 0.03541589 0.03062937
  0.03147863 0.03301617 0.0303142  0.03332254 0.06301268 0.03860089
  0.04239954 0.03782362]
 [0.02917386 0.06571208 0.06427576 0.02735267 0.02196008 0.03266037
  0.04702838 0.0404651  0.04793642 0.02741245 0.02567718 0.03058498
  0.03112108 0.01450321 0.0141031  0.04624807 0.03666167 0.02962209
  0.03318984 0.03614746 0.02987783 0.0305318  0.06799185 0.03152139
  0.03175252 0.03492463]
 [0.02933109 0.03652736 0.0408816  0.02117304 0.01772295 0.02435542
  0.03682547 0.03139602 0.03725479 0.02239325 0.02117252 0.02464678
  0.02362891 0.01229448 0.01245927 0.03967288 0.03196546 0.02509825
  0.0298021  0.03051534 0.02864777 0.02913201 0.05437251 0.04432518
  0.05081185 0.04097231]
 [0.02949854 0.01596474 0.01786227 0.01194612 0.01058445 0.0144886
  0.01776996 0.01774186 0.02158264 0.01443837 0.01419684 0.01555071
  0.01531844 0.00659879 0.00748154 0.02106888 0.02114736 0.01925308
  0.02498328 0.02619451 0.0287224  0.02270985 0.0369571  0.05661953
  0.07906288 0.05006617]
 [0.02943314 0.02424018 0.0255703  0.01642051 0.01505592 0.02079334
  0.02615054 0.02325876 0.02471056 0.01855571 0.02142144 0.02227294
  0.02151038 0.00916568 0.00998368 0.03881812 0.02497545 0.02383585
  0.02494535 0.02660966 0.02751447 0.02723093 0.0296933  0.05341393
  0.06308661 0.04055573]
 [0.02955367 0.02486008 0.02519856 0.01912216 0.01635596 0.02350315
  0.0283026  0.0286443  0.02536587 0.02248415 0.02626525 0.02967531
  0.03009398 0.01070626 0.00957319 0.03911793 0.02683098 0.02861132
  0.02659533 0.02787557 0.03077587 0.0283073  0.02219545 0.04559274
  0.04184661 0.02547595]
 [0.02907113 0.02117738 0.01725615 0.01434533 0.01142362 0.01494196
  0.02254512 0.02230784 0.01880573 0.01547232 0.02155618 0.01872911
  0.02244379 0.0068195  0.00690407 0.04212162 0.02413715 0.03754928
  0.03027189 0.03597642 0.04662342 0.02640147 0.01878305 0.07605035
  0.05569508 0.03042632]
 [0.02987277 0.01849578 0.01636055 0.01424272 0.01192466 0.01592376
  0.02015656 0.02038468 0.01853398 0.01621796 0.02537687 0.02076831
  0.02211196 0.00689398 0.00680119 0.03193938 0.02304989 0.04429626
  0.03162114 0.04580317 0.03850691 0.02146105 0.01489032 0.05462835
  0.0371404  0.0212661 ]
 [0.02981055 0.01669996 0.01502414 0.01124809 0.00945737 0.01321208
  0.01907808 0.01874218 0.01742576 0.01345271 0.03154753 0.01881367
  0.02000246 0.00570446 0.00621024 0.03315732 0.02701446 0.03561032
  0.03110149 0.03521533 0.03972306 0.02264421 0.0149072  0.0570605
  0.03915554 0.02586691]
 [0.0290764  0.02403305 0.02263749 0.01584265 0.01488518 0.02079147
  0.03080009 0.03140612 0.02886602 0.01995466 0.02911878 0.02591463
  0.03015493 0.00829052 0.00870761 0.02957903 0.03513289 0.03903693
  0.03641883 0.03914868 0.04314699 0.02577146 0.02123595 0.04680881
  0.04329158 0.04191849]
 [0.03030356 0.02054279 0.01945324 0.01556992 0.01273482 0.01741148
  0.02188665 0.02197216 0.02091884 0.01718516 0.02555501 0.02195039
  0.02165146 0.00813936 0.0075755  0.02189487 0.02245829 0.02311819
  0.02617214 0.02654932 0.02791511 0.02601564 0.01487576 0.02897367
  0.03424472 0.02634065]
 [0.03036257 0.02273816 0.02532817 0.02224371 0.01769282 0.02590134
  0.02653817 0.0312321  0.02601551 0.02644242 0.02808538 0.03628701
  0.03237956 0.01301356 0.00896627 0.01962363 0.02131398 0.02487725
  0.02470964 0.0239234  0.02227738 0.02840031 0.01538754 0.01714548
  0.02516452 0.02263609]
 [0.03053313 0.02649284 0.02739254 0.02589451 0.01928077 0.02863461
  0.03138693 0.03840047 0.02697512 0.03088641 0.03574275 0.04209112
  0.03987512 0.01419925 0.00968375 0.02126883 0.02196945 0.02645408
  0.02483969 0.02384867 0.02235296 0.02846816 0.01615199 0.01445589
  0.01798106 0.01720474]
 [0.03036867 0.02485053 0.02461728 0.02407451 0.01906205 0.02654336
  0.0286598  0.03336409 0.0272964  0.02920766 0.03247701 0.03688137
  0.03749587 0.01330218 0.0099648  0.02639176 0.02417281 0.02979733
  0.0275967  0.0261375  0.02488075 0.02827193 0.01414275 0.01688693
  0.01955593 0.01549833]
 [0.03023463 0.01955931 0.01832404 0.01506226 0.01148722 0.01656954
  0.02134888 0.02344288 0.0215883  0.01789813 0.02419733 0.02293617
  0.02579372 0.0076848  0.00700094 0.03101212 0.02560368 0.02960076
  0.02827512 0.02667055 0.03117904 0.0263996  0.01256143 0.02754452
  0.03084438 0.01783225]
 [0.03022952 0.02011752 0.01806793 0.0154133  0.01107434 0.01565625
  0.02396315 0.02423663 0.02127551 0.0171184  0.0245376  0.02062153
  0.02535466 0.00733101 0.00690511 0.033832   0.02613661 0.03162153
  0.02976471 0.02737961 0.03394778 0.02380305 0.01179581 0.02813941
  0.03127201 0.019561  ]
 [0.03030928 0.01933309 0.01728331 0.01518513 0.01220587 0.0158177
  0.02091022 0.02250768 0.02105613 0.01825319 0.02525926 0.0225659
  0.02403523 0.00788415 0.00721521 0.02706761 0.02883238 0.02991946
  0.03273955 0.02738182 0.03197874 0.02426114 0.01178417 0.02191938
  0.03073058 0.01967796]
 [0.03045983 0.02200294 0.01977609 0.01640836 0.01232751 0.01730823
  0.02460887 0.02528859 0.02574093 0.0194036  0.02917815 0.02363624
  0.02645625 0.00836993 0.00743943 0.02928039 0.0286421  0.03218371
  0.03347595 0.03069579 0.0340085  0.02510949 0.0125102  0.02292071
  0.02434088 0.01735915]
 [0.03051599 0.01768123 0.01642187 0.01111578 0.00955111 0.01263201
  0.02042446 0.01996142 0.02068814 0.01373108 0.0340642  0.0184724
  0.02150586 0.00626362 0.00575163 0.02774837 0.03097448 0.02816894
  0.03356211 0.02881878 0.03290397 0.02326146 0.0119076  0.03126722
  0.02547777 0.0202956 ]
 [0.02919993 0.02375615 0.02310314 0.01379717 0.01178852 0.01710455
  0.03284911 0.03317997 0.03147026 0.01875738 0.03355607 0.02495664
  0.0335421  0.00754898 0.00749377 0.02398254 0.04129952 0.03584567
  0.043132   0.04249087 0.04590309 0.02743141 0.02251043 0.04531995
  0.04126609 0.06681687]
 [0.03057177 0.02048035 0.0205576  0.01720495 0.01335638 0.02049205
  0.02163052 0.02550414 0.02514366 0.02046454 0.02339345 0.02494879
  0.023963   0.01019967 0.00826    0.01677615 0.02468823 0.0206756
  0.02649942 0.02560501 0.02721723 0.02464663 0.01366532 0.0175344
  0.02215848 0.02483794]
 [0.02946159 0.02607124 0.02618574 0.0407178  0.04250407 0.03662512
  0.0239602  0.02467111 0.02986526 0.04241609 0.02999916 0.03103257
  0.0293863  0.06659525 0.08017186 0.02143089 0.02790332 0.0244054
  0.02630652 0.02438559 0.02167405 0.03097068 0.03015792 0.00936414
  0.00967853 0.02722047]
 [0.02922215 0.02749027 0.02621523 0.04575385 0.08769526 0.03664859
  0.02227231 0.02302187 0.02889575 0.04959267 0.03542417 0.03138774
  0.02463005 0.06778313 0.08537527 0.02647945 0.03956004 0.03343215
  0.03161031 0.02685431 0.02580662 0.02831581 0.02985865 0.00799881
  0.00711449 0.02365126]
 [0.02895654 0.02481748 0.0229976  0.03701569 0.08285554 0.02501621
  0.01860017 0.0220384  0.0248988  0.04264617 0.03379701 0.03341667
  0.02420115 0.03000097 0.03807911 0.02280575 0.06004026 0.04932762
  0.04324146 0.03171428 0.04078964 0.02563015 0.02632573 0.01406477
  0.01463361 0.02791237]
 [0.02926534 0.0309328  0.0273421  0.03801615 0.0538797  0.02955822
  0.02522122 0.02484624 0.03043989 0.03886118 0.03397514 0.02934854
  0.02657476 0.03058094 0.03371971 0.02032801 0.04169079 0.03229653
  0.03343043 0.02993524 0.02944336 0.04443617 0.03823566 0.01105856
  0.01126949 0.02663699]]

-* TASK 10/20 | SAMPLE 85/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 422/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill in the context sentences. The context sentences only mention Julie's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.1071, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03340757 0.03523596 0.03608455 0.06602424 0.06114446 0.0453188
  0.03109159 0.03300684 0.0404253  0.05319256 0.04032105 0.03325459
  0.03435057 0.10364299 0.10323907 0.0321418  0.03233911 0.02832947
  0.0294729  0.03004949 0.02586447 0.03579588 0.03932763 0.02200368
  0.01733453 0.03596151 0.0368621  0.04835547 0.11568872 0.06748927
  0.01301173 0.01656225]
 [0.03442886 0.03261099 0.03063902 0.06836518 0.077557   0.06500422
  0.03229225 0.03521097 0.04128907 0.06428894 0.04922348 0.04974771
  0.0503519  0.13791643 0.10676725 0.03011947 0.0293219  0.0307614
  0.02926158 0.0307173  0.02556706 0.03827174 0.02764571 0.01834427
  0.01631706 0.02837235 0.03463804 0.0391262  0.08851518 0.07682349
  0.02066663 0.0292489 ]
 [0.03517503 0.03152824 0.03358309 0.06204518 0.06157962 0.05090832
  0.02918435 0.03264561 0.03804769 0.05029032 0.03945335 0.04070514
  0.03728759 0.11179775 0.08111553 0.02869288 0.02805633 0.02375434
  0.02523711 0.02580372 0.02162401 0.03480159 0.02669123 0.01861537
  0.01708718 0.02529037 0.03007982 0.03156162 0.05955666 0.07056568
  0.02710031 0.03296586]
 [0.03413776 0.03557672 0.03984268 0.04092357 0.03568157 0.03917145
  0.03295105 0.04068916 0.03933741 0.03780941 0.03417765 0.03959164
  0.03544626 0.03063054 0.03009136 0.03234315 0.03203479 0.02737943
  0.03057079 0.03160099 0.02950948 0.03739215 0.03861354 0.03555257
  0.03247233 0.04016059 0.04179466 0.04292259 0.03946516 0.06764191
  0.05448374 0.05719453]
 [0.03550334 0.03350466 0.03579904 0.03296727 0.02730005 0.03741955
  0.0344107  0.03907127 0.0390391  0.03278384 0.03240327 0.04318765
  0.03564832 0.021942   0.02196456 0.03121616 0.0338782  0.02883555
  0.03295011 0.03394409 0.03177144 0.03338674 0.03382103 0.03359532
  0.03599272 0.03934943 0.03540875 0.03192302 0.02838052 0.03527039
  0.0421263  0.05014941]
 [0.03610073 0.0348952  0.03663879 0.03675965 0.03014299 0.04682876
  0.03629028 0.04012282 0.04697782 0.03948216 0.03352179 0.05188853
  0.0407696  0.02820195 0.02334167 0.02976954 0.03163266 0.02675378
  0.03048997 0.03078926 0.02732805 0.03380195 0.03205462 0.02844816
  0.02932899 0.03441136 0.0358932  0.02809908 0.02989682 0.0337874
  0.03690893 0.04565484]
 [0.03522544 0.04739569 0.04565375 0.04133538 0.03293006 0.04897719
  0.04784936 0.05342719 0.04711733 0.04508051 0.03995499 0.06058638
  0.05789508 0.02974013 0.02576774 0.03821808 0.03697873 0.03413874
  0.03683145 0.03698185 0.03474744 0.03892706 0.03972678 0.03718132
  0.03873629 0.03970492 0.04249931 0.03871954 0.03221502 0.04255439
  0.04769158 0.05327539]
 [0.03627377 0.03911186 0.04164271 0.03706348 0.02744736 0.05409962
  0.04392928 0.04578927 0.04357912 0.03846975 0.03419121 0.06835972
  0.05535508 0.02626313 0.02214771 0.03567331 0.03662249 0.03184159
  0.03360514 0.03507437 0.03135418 0.03575083 0.03406856 0.03353863
  0.03693398 0.03588934 0.03712634 0.03319024 0.02804226 0.0349792
  0.04360671 0.05004988]
 [0.03549162 0.02955292 0.02842998 0.02451863 0.02090978 0.02493217
  0.03630537 0.03254765 0.02557191 0.02591769 0.03944996 0.02971225
  0.03967676 0.01512004 0.01778165 0.04888346 0.04195588 0.03838287
  0.04032381 0.04019904 0.05510444 0.0356544  0.02571082 0.05805483
  0.05639038 0.03618665 0.02820809 0.04105588 0.02368626 0.01985915
  0.05093131 0.04696434]
 [0.03573692 0.02708624 0.02513717 0.02131379 0.01691035 0.02115841
  0.03084391 0.02829399 0.02404324 0.02095415 0.02810712 0.02452045
  0.02802545 0.01291037 0.01500755 0.04460275 0.03550545 0.03535965
  0.03843281 0.03936332 0.05559083 0.03369212 0.02526112 0.06287784
  0.0685894  0.04396002 0.02635838 0.04667307 0.02141697 0.01795453
  0.0527681  0.0480281 ]
 [0.03603715 0.04075412 0.04446427 0.0237737  0.02225251 0.02906775
  0.03926994 0.0391432  0.04501874 0.02349703 0.02921717 0.02825933
  0.02795715 0.01563803 0.018069   0.04032985 0.03672272 0.02734111
  0.03528817 0.03437106 0.03636448 0.03424929 0.04743265 0.03813051
  0.04223128 0.04097822 0.04474539 0.03887695 0.02302421 0.04006414
  0.03958945 0.03689588]
 [0.03532302 0.05632148 0.05491669 0.02575225 0.02230839 0.03273286
  0.04696426 0.03645233 0.05249144 0.02436533 0.02893246 0.02736279
  0.02800838 0.01639527 0.0214237  0.0410947  0.03569022 0.02775205
  0.03787545 0.03595615 0.03737402 0.03671907 0.0688227  0.0405769
  0.03265283 0.04642259 0.05813377 0.03860278 0.0223291  0.03143625
  0.03218034 0.02904361]
 [0.03592538 0.0755284  0.07099147 0.02822498 0.02429456 0.03676426
  0.04825797 0.04106569 0.0532543  0.02682612 0.02558536 0.02884745
  0.02990805 0.0195608  0.02365212 0.04859952 0.03731445 0.02632434
  0.03137316 0.03333385 0.02781    0.03539554 0.0813742  0.03810216
  0.02952152 0.04507389 0.06588494 0.02674266 0.02547812 0.0549715
  0.03458337 0.02922713]
 [0.0358519  0.03973293 0.04556385 0.02557837 0.02232871 0.03093839
  0.0372659  0.03565792 0.04053215 0.02481955 0.02401943 0.02620847
  0.02481665 0.01866023 0.0218421  0.03827135 0.03457801 0.02599533
  0.03191284 0.03317841 0.02826974 0.03420765 0.05315048 0.04492094
  0.036458   0.04582364 0.0575172  0.02700765 0.02583843 0.05100746
  0.05255681 0.03774036]
 [0.03564166 0.02700489 0.02944658 0.0316092  0.02822794 0.03493283
  0.03174284 0.03379207 0.04102192 0.04046538 0.03340824 0.04361551
  0.03955865 0.02692784 0.02400445 0.03496906 0.03700953 0.03456222
  0.03588174 0.03440176 0.03372711 0.03671492 0.0322853  0.0430916
  0.04107877 0.03651844 0.03430773 0.04274025 0.03610877 0.05134844
  0.04529419 0.04078392]
 [0.03608841 0.04267887 0.04194897 0.02689802 0.02562205 0.03211006
  0.04172911 0.03921055 0.03527084 0.02792974 0.02953578 0.03036916
  0.03552167 0.02176594 0.02120886 0.03331522 0.02957912 0.02703456
  0.02903425 0.02956495 0.02785629 0.03722632 0.03734867 0.03273043
  0.03348714 0.03631593 0.0429177  0.0284349  0.02544506 0.03400822
  0.03609196 0.03838578]
 [0.03670652 0.05619946 0.05604887 0.02606706 0.02544595 0.03424506
  0.04426748 0.04084834 0.0419792  0.0285226  0.02685302 0.03027996
  0.03412858 0.02028983 0.0202104  0.04017737 0.03301295 0.02696784
  0.02906288 0.03035077 0.02587081 0.03480257 0.05481451 0.03280238
  0.02622976 0.03231074 0.04120011 0.02445026 0.02375515 0.04690811
  0.03142957 0.02987254]
 [0.03647344 0.03440274 0.03756449 0.02358884 0.02248957 0.02866786
  0.03692142 0.03632835 0.02986408 0.02436898 0.02549893 0.02776721
  0.02943277 0.0175475  0.01795084 0.03393199 0.03197622 0.02764502
  0.02985851 0.03089673 0.02806048 0.03698036 0.03745624 0.03804039
  0.03589645 0.03408173 0.0337352  0.02267013 0.02381784 0.03834896
  0.04107973 0.03723959]
 [0.03718683 0.02959799 0.03139479 0.0230123  0.02075569 0.02960766
  0.04056742 0.04162438 0.02631103 0.02500379 0.02683946 0.02997683
  0.03555725 0.01679816 0.0161478  0.0290086  0.02891736 0.02769589
  0.02758864 0.02848359 0.02690318 0.03576715 0.02520928 0.03201381
  0.03778968 0.03586349 0.02957335 0.02157411 0.0230683  0.02328032
  0.03353539 0.03957863]
 [0.03646231 0.0232686  0.021383   0.01680028 0.01703565 0.02034966
  0.03019895 0.02698835 0.01939933 0.01847876 0.02842065 0.02081332
  0.02900019 0.0129668  0.0139441  0.03325902 0.03544809 0.03042049
  0.03187075 0.03208266 0.03467641 0.03369309 0.02028977 0.04747708
  0.06680848 0.03956165 0.02240572 0.02352478 0.0192183  0.01853095
  0.04111072 0.03203429]
 [0.03617843 0.02026988 0.01872643 0.01596749 0.0146956  0.01740032
  0.02638447 0.02374491 0.01765694 0.01657069 0.02879179 0.01831115
  0.0238846  0.01171978 0.01256322 0.03422717 0.03961856 0.04144837
  0.03702341 0.03698856 0.04248642 0.03123428 0.01608757 0.04822277
  0.05295155 0.03442321 0.01901459 0.0258644  0.01889141 0.01472441
  0.05149192 0.03854908]
 [0.03614201 0.03514472 0.02883405 0.02083059 0.01754531 0.02167927
  0.04583778 0.04546477 0.02464284 0.02115116 0.04838797 0.02517434
  0.04063869 0.01391025 0.01545173 0.05033546 0.04886521 0.05448733
  0.04265682 0.04677062 0.04607562 0.03588355 0.02047509 0.05946191
  0.06561051 0.03382535 0.02450867 0.03048265 0.02062644 0.01570027
  0.05554299 0.0471323 ]
 [0.03698611 0.02366322 0.02343594 0.01891061 0.01674103 0.02142612
  0.03193268 0.03231346 0.02361284 0.02119129 0.05161644 0.02469507
  0.03235983 0.0140231  0.01396397 0.0376238  0.04435117 0.03915123
  0.04453266 0.04206813 0.04044767 0.03042506 0.01609988 0.04124555
  0.04412986 0.03043204 0.01786953 0.02806628 0.01929925 0.01571813
  0.04609989 0.04111362]
 [0.03546084 0.0278623  0.02886171 0.05127755 0.0495441  0.04283768
  0.03225328 0.03100782 0.03729967 0.05641403 0.04167006 0.0388735
  0.04066999 0.0748181  0.09509239 0.02906871 0.0313537  0.03938709
  0.03628924 0.03420603 0.03307395 0.03688904 0.02988775 0.01930292
  0.0162716  0.02864921 0.02869254 0.04044851 0.05650476 0.02730389
  0.01391674 0.01822632]
 [0.03489045 0.03246479 0.02869376 0.06740794 0.12242098 0.0472757
  0.02752228 0.02768326 0.03076496 0.06743927 0.05174863 0.04194413
  0.03432638 0.0832832  0.10840808 0.03677586 0.04493264 0.07321927
  0.05140204 0.04652979 0.04744726 0.03598096 0.03691063 0.02010094
  0.01645477 0.0298234  0.03820534 0.04425933 0.05695118 0.0238378
  0.01129467 0.01376442]
 [0.03525047 0.03103029 0.02726224 0.04473058 0.05540269 0.03278775
  0.02677171 0.02850981 0.03000656 0.04603637 0.04692034 0.04178462
  0.0349226  0.03197575 0.04054809 0.03822786 0.05375541 0.077912
  0.06393345 0.0567206  0.05650334 0.03358984 0.03214922 0.02984724
  0.02912843 0.03149851 0.03118084 0.04898449 0.03193601 0.01512276
  0.01650218 0.020196  ]
 [0.03580442 0.03123585 0.03003242 0.05509738 0.0637368  0.03908072
  0.02836966 0.03213591 0.03524413 0.05724037 0.04476803 0.04280514
  0.03459817 0.03547419 0.03616163 0.02590717 0.03196777 0.05127714
  0.04162797 0.04195108 0.04795203 0.03807863 0.03459602 0.025392
  0.02360385 0.03220518 0.03582714 0.05413599 0.03662821 0.01526511
  0.01452172 0.0201649 ]
 [0.03610962 0.02634096 0.02697968 0.04315653 0.03754921 0.03427754
  0.02859471 0.02722406 0.03020098 0.0414103  0.03698243 0.03135793
  0.02990378 0.03007982 0.0321334  0.02321675 0.02658124 0.03584194
  0.03561232 0.03762183 0.04063982 0.04468824 0.032689   0.02032842
  0.02051264 0.02690623 0.02541151 0.05150711 0.04421591 0.01549784
  0.01388293 0.01995805]]

-* TASK 10/20 | SAMPLE 85/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 423/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Julie is either in the school or the school, which means Julie is definitely in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' school', ',', ' which', ' means', ' Julie', ' is', ' definitely', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.0281559  0.04405121 0.0426783  ... 0.02171661 0.01670672 0.03932738]
 [0.02839498 0.03628321 0.03472501 ... 0.02639548 0.02716069 0.04225345]
 [0.02926521 0.04767953 0.05154752 ... 0.01793752 0.01615497 0.03650869]
 ...
 [0.0294734  0.03962491 0.04518611 ... 0.01722566 0.01659713 0.04362655]
 [0.02970982 0.03438437 0.03562271 ... 0.02223737 0.02365522 0.03646843]
 [0.02990933 0.03096613 0.0342678  ... 0.02140845 0.02004781 0.03542283]]

-* TASK 10/20 | SAMPLE 85/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 424/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill being in the kitchen in the context sentences. Bill went to the school according to context sentence 10.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' Bill', ' went', ' to', ' the', ' school', ' according', ' to', ' context', ' sentence', ' ', '10', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02752193 0.03191959 0.03554199 ... 0.0152867  0.01789165 0.03892418]
 [0.0278667  0.02458433 0.02682735 ... 0.01826487 0.02364001 0.01826117]
 [0.02867771 0.03456743 0.04013675 ... 0.0179321  0.02079128 0.03318998]
 ...
 [0.02886881 0.03597106 0.03200448 ... 0.00682636 0.00873668 0.07900827]
 [0.02937098 0.03187801 0.02620809 ... 0.00871114 0.00864746 0.05981567]
 [0.02939555 0.03349305 0.02634767 ... 0.00769881 0.0089188  0.04819941]]

-* TASK 10/20 | SAMPLE 85/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 425/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 14, Mary is in the cinema, which explicitly states her location.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' which', ' explicitly', ' states', ' her', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 50), x_tokens=50, y_tokens=26, max_supp_attn=0.0385, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 50)
DEBUG result.interpretability.attn_scores 1300 
 [[0.03611574 0.0467053  0.04825022 ... 0.02258132 0.02703764 0.04271671]
 [0.03672645 0.04425102 0.03891896 ... 0.02968557 0.03353689 0.03599469]
 [0.03763362 0.04711062 0.05124029 ... 0.01975637 0.02424812 0.0378407 ]
 ...
 [0.03792823 0.04293878 0.04458032 ... 0.01769134 0.02232581 0.04162762]
 [0.03819263 0.03399722 0.03423509 ... 0.03320343 0.03294189 0.03983144]
 [0.03812319 0.03950368 0.03937026 ... 0.01980206 0.02336405 0.03896301]]
Model's predictions for the sample 85:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Bill    |
|          |                 |  travelled to the bedroom, which implies   |
|          |                 |   that Bill is currently in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information about Bill in    |
|          |                 |     the context sentences. The context     |
|          |                 |       sentences only mention Julie's       |
|          |                 |                 locations.                 |
+----------+-----------------+--------------------------------------------+
|  maybe   |       yes       |   According to context sentence 7, Julie   |
|          |                 |   is either in the school or the school,   |
|          |                 |   which means Julie is definitely in the   |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no information about Bill being  |
|          |                 |  in the kitchen in the context sentences.  |
|          |                 |    Bill went to the school according to    |
|          |                 |            context sentence 10.            |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 14, Mary   |
|          |                 |     is in the cinema, which explicitly     |
|          |                 |            states her location.            |
+----------+-----------------+--------------------------------------------+

Metrics for sample 85:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.08 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 86/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 426/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Julie went to the bedroom, which implies that she is currently in the bedroom.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' went', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02798603 0.050078   0.06146727 0.0758779  0.07925372 0.0745693
  0.06287826 0.07527941 0.06029547 0.06523196 0.04776682 0.06433367
  0.07302961 0.09336565 0.05895999 0.03456229 0.03185548 0.03277721
  0.03135587 0.03188374 0.02535609 0.03972682 0.04291892 0.02637169
  0.01606921 0.02503973]
 [0.02774836 0.07490967 0.06762919 0.07308641 0.06262915 0.07268722
  0.21064416 0.1277474  0.08485718 0.08028527 0.06349781 0.05965061
  0.08134517 0.06205007 0.04832941 0.03933796 0.03323746 0.03741327
  0.0335809  0.03593928 0.02780423 0.04597189 0.04473404 0.02784016
  0.01677977 0.02521695]
 [0.03052662 0.05953599 0.03776035 0.05344555 0.03934264 0.03647756
  0.02724959 0.02157881 0.02298227 0.03398961 0.02759297 0.01658469
  0.01865699 0.03137907 0.04184023 0.0259032  0.01426561 0.01288212
  0.01739581 0.01644656 0.01465635 0.04416436 0.05428277 0.01063337
  0.00603289 0.01250774]
 [0.02903618 0.02924356 0.03033632 0.02391546 0.01685553 0.02632124
  0.02416672 0.02190736 0.02570603 0.02282071 0.02531974 0.02385074
  0.02212504 0.01215841 0.01137861 0.03007299 0.02894175 0.03605155
  0.04051683 0.04234863 0.0339801  0.03146737 0.04005061 0.04283514
  0.07262679 0.05147481]
 [0.02903206 0.04270589 0.04697293 0.06596254 0.05911767 0.04779898
  0.02923386 0.02796378 0.03435883 0.04472376 0.03366887 0.0257405
  0.0254882  0.10282335 0.10947956 0.03975169 0.02719313 0.02005185
  0.02239765 0.02224722 0.02040967 0.03918571 0.0627095  0.01851185
  0.00860112 0.02695413]
 [0.02965835 0.02776345 0.02892226 0.05061141 0.04408627 0.04349611
  0.02200853 0.02196828 0.02939573 0.04177541 0.02990926 0.02916907
  0.02756082 0.11005642 0.13519496 0.0393492  0.03056985 0.024152
  0.02534606 0.0238002  0.01959799 0.0335789  0.0380659  0.01337959
  0.0069192  0.01744182]
 [0.03009395 0.0314574  0.037581   0.05329284 0.04839265 0.054699
  0.02905232 0.03028757 0.03825593 0.04889989 0.03503187 0.04589068
  0.04178642 0.08817082 0.08335362 0.03309063 0.02781575 0.02390036
  0.02428264 0.0234228  0.01852939 0.0303841  0.03558593 0.01825179
  0.00957884 0.01675953]
 [0.02903355 0.04213091 0.04970473 0.04167148 0.04334407 0.0492503
  0.03492454 0.03977528 0.04062435 0.0429961  0.03662185 0.04932234
  0.04302224 0.05385675 0.04908189 0.04433865 0.03755988 0.03243631
  0.0300897  0.02981998 0.02626415 0.03464824 0.05040552 0.03602334
  0.0345013  0.03229628]
 [0.0302885  0.04318215 0.05285586 0.04819689 0.04255141 0.05805552
  0.03805238 0.04552056 0.04953821 0.04961644 0.0365555  0.05140822
  0.04691666 0.04116628 0.02752654 0.03110903 0.02738869 0.02549984
  0.02606573 0.02606086 0.02043563 0.03463082 0.03844932 0.02360813
  0.01485958 0.02219588]
 [0.02958537 0.0551012  0.05772246 0.0295975  0.02335041 0.03812644
  0.04068903 0.04169219 0.04524952 0.03061501 0.02955658 0.03755393
  0.0383389  0.01819058 0.01561193 0.04869484 0.03714618 0.0304048
  0.03250217 0.03258084 0.0297806  0.03438708 0.06847069 0.04751273
  0.03637355 0.03506458]
 [0.03011679 0.04220752 0.04826244 0.0248854  0.0202504  0.02837968
  0.04000526 0.03351324 0.04171066 0.0245951  0.02398235 0.02713253
  0.02693835 0.01423011 0.01389538 0.04870176 0.03482359 0.02802714
  0.03212992 0.03313449 0.02882539 0.03044295 0.05617654 0.05133386
  0.03996955 0.03746726]
 [0.03048121 0.01661921 0.01912014 0.01215653 0.01030122 0.01528797
  0.01594883 0.01711074 0.02357111 0.01421639 0.01378834 0.01513839
  0.01492217 0.00683777 0.00739509 0.02233556 0.02151003 0.01931305
  0.02483705 0.02603333 0.02657658 0.02309668 0.04256867 0.06103232
  0.06407008 0.06596924]
 [0.03021004 0.02503071 0.02640468 0.01673243 0.01463114 0.02145557
  0.02249463 0.02180183 0.02418751 0.01797901 0.02122258 0.02205597
  0.02078548 0.00976008 0.01009392 0.03704347 0.02955992 0.0286103
  0.02863767 0.02923246 0.02762877 0.0290463  0.03123677 0.0463104
  0.06724313 0.04767772]
 [0.03048003 0.02272367 0.02354251 0.01812336 0.01589133 0.02230169
  0.02216209 0.02404729 0.02435431 0.02111853 0.02495891 0.02871205
  0.0270991  0.01097136 0.00954328 0.03148097 0.03212704 0.03243294
  0.02852784 0.02851207 0.03142632 0.02892425 0.02147175 0.03456007
  0.06562089 0.02973317]
 [0.02991309 0.018961   0.01633935 0.01363964 0.01141341 0.01488707
  0.01717129 0.01800827 0.01811344 0.01498958 0.02096884 0.01860088
  0.02056658 0.00719383 0.0073418  0.02912829 0.02904033 0.0456072
  0.03294992 0.04340989 0.05675675 0.02639123 0.01677296 0.03865947
  0.09495282 0.04803308]
 [0.03076155 0.01725027 0.01606534 0.01336448 0.01209396 0.01564646
  0.01696514 0.01883291 0.01805543 0.01581801 0.02439788 0.02216329
  0.02136348 0.00708476 0.00705449 0.02810435 0.02505688 0.03871048
  0.03251168 0.04870347 0.0489274  0.02183809 0.01418915 0.02666296
  0.06523366 0.03592828]
 [0.03068216 0.01562721 0.01399033 0.01105452 0.00980679 0.01290765
  0.01500971 0.01600977 0.01614822 0.01313023 0.02751615 0.01856511
  0.01828876 0.00593522 0.00642235 0.02650621 0.03029893 0.03677272
  0.03576897 0.0441271  0.04543781 0.02239748 0.01426227 0.03359959
  0.04612486 0.05786346]
 [0.02965516 0.02343292 0.02101829 0.01568132 0.01411093 0.01917067
  0.02430839 0.02488063 0.0253681  0.01828205 0.02740091 0.02174081
  0.02480531 0.00807329 0.00927217 0.02611208 0.03705555 0.03255144
  0.03990276 0.04145887 0.04811393 0.02689926 0.02612936 0.07734147
  0.04911839 0.06779737]
 [0.03115875 0.0217988  0.02064547 0.01596886 0.01294043 0.01803544
  0.01923191 0.02145914 0.02089232 0.01725537 0.02509044 0.02260674
  0.02201787 0.00874039 0.00834073 0.02377265 0.02559523 0.02642466
  0.0287702  0.0294066  0.0311303  0.0264445  0.01663839 0.02701664
  0.02434302 0.0343809 ]
 [0.03132185 0.02418008 0.0262519  0.02258231 0.01772891 0.02658626
  0.0227152  0.0312036  0.0253478  0.02644313 0.02879418 0.03705559
  0.03281533 0.01357513 0.0095304  0.02230243 0.02253205 0.02645841
  0.02512482 0.02403521 0.02291302 0.02874754 0.01612716 0.02119912
  0.01824505 0.01837174]
 [0.03149625 0.02789772 0.02887742 0.02616489 0.0195138  0.02940216
  0.02695861 0.0382881  0.02740149 0.03069431 0.03450809 0.04309182
  0.03996119 0.01492145 0.01034016 0.023214   0.0222961  0.02655291
  0.02482227 0.0233794  0.02163195 0.02910445 0.01742367 0.01927556
  0.01392111 0.01451029]
 [0.03132943 0.02635048 0.02579687 0.02450705 0.01965058 0.02691873
  0.02421338 0.03230239 0.02730432 0.02948778 0.0327342  0.03821078
  0.03742571 0.01425377 0.0104958  0.02694011 0.02437797 0.02983738
  0.02698077 0.02558713 0.02416066 0.02913265 0.01510347 0.0213829
  0.01734464 0.01306551]
 [0.03120879 0.01927851 0.01789374 0.01450227 0.0113596  0.01591147
  0.01737744 0.0213721  0.02089087 0.01702737 0.02355168 0.02223052
  0.02452143 0.00778764 0.00699543 0.02673641 0.02717914 0.03108097
  0.02815771 0.02694586 0.03186588 0.02664698 0.01300324 0.02880671
  0.03475789 0.01870518]
 [0.03136709 0.01881884 0.01651123 0.01379511 0.01011847 0.01424429
  0.01730872 0.01932573 0.01945357 0.01531954 0.02182319 0.01918988
  0.02244197 0.00690356 0.00652871 0.02772405 0.02575423 0.03445994
  0.02920422 0.02932879 0.03637931 0.02232575 0.01191011 0.03007233
  0.0324937  0.02167915]
 [0.03159465 0.01910554 0.01694217 0.01480081 0.01166231 0.01565417
  0.01748093 0.02093694 0.02033828 0.01753151 0.02521149 0.02236189
  0.02322177 0.00794806 0.00737511 0.02477728 0.02810035 0.0290112
  0.03101107 0.02610638 0.02935238 0.02400828 0.01171594 0.02753762
  0.01948241 0.01664061]
 [0.03155977 0.02138652 0.01915335 0.01583404 0.0118787  0.01713825
  0.02082425 0.02337713 0.02433545 0.01834153 0.02905607 0.02310817
  0.02505384 0.00837625 0.0077328  0.02778397 0.02910742 0.03160788
  0.03272763 0.03027413 0.03380464 0.02518539 0.0125725  0.02742753
  0.01928691 0.01884369]
 [0.03166488 0.01645888 0.0152732  0.01073946 0.00914531 0.01236895
  0.01716111 0.01752632 0.01920411 0.01292064 0.03279356 0.01770164
  0.02014818 0.00630801 0.0057154  0.02428058 0.0325929  0.02761198
  0.03354341 0.02909748 0.03291538 0.0232027  0.01119672 0.02774393
  0.02001767 0.03096575]
 [0.03020266 0.02423616 0.02346778 0.01361488 0.0116354  0.01782825
  0.02477243 0.02713153 0.02973511 0.01767879 0.03260151 0.02249942
  0.02798036 0.00789209 0.00754629 0.02674909 0.03741106 0.03334087
  0.04200371 0.04201199 0.04677945 0.02701748 0.02387368 0.05349235
  0.03313471 0.05796186]
 [0.03147652 0.02368092 0.02325023 0.01896397 0.01458966 0.02192778
  0.02083613 0.02881236 0.02648487 0.02182518 0.02664084 0.02687225
  0.02624178 0.01153863 0.00943603 0.01942567 0.02599272 0.02323769
  0.02751618 0.02570252 0.02660225 0.02647045 0.01490622 0.02001672
  0.01400429 0.02193239]
 [0.0302969  0.02875624 0.02836344 0.04297436 0.04447532 0.03846084
  0.02087854 0.02364367 0.03035876 0.04306125 0.03081832 0.03159047
  0.03017382 0.07285639 0.08852015 0.02653935 0.02721793 0.02362659
  0.02547383 0.0233053  0.02062273 0.03224475 0.03380338 0.01418751
  0.00833913 0.01943783]
 [0.03011489 0.02971587 0.02811102 0.04696417 0.0914654  0.03766676
  0.01934814 0.02240345 0.02933481 0.04975805 0.03638207 0.03229234
  0.02483039 0.07145582 0.09165528 0.03273194 0.03878954 0.03365289
  0.03062404 0.02565171 0.02418394 0.02901183 0.03250441 0.0119575
  0.00645489 0.01656413]
 [0.02984171 0.02683147 0.0243662  0.03813294 0.08946076 0.0256457
  0.01608032 0.0206704  0.02483582 0.04254295 0.03561967 0.03347776
  0.02389554 0.031547   0.04172011 0.02712132 0.05816079 0.0512637
  0.04179303 0.0306277  0.03821542 0.02640411 0.02925083 0.01972979
  0.01309871 0.02103558]
 [0.03007691 0.03354329 0.02940053 0.03915928 0.05695271 0.03069254
  0.0218482  0.02362191 0.03131019 0.03902956 0.0346175  0.03009729
  0.02623152 0.03259208 0.03629247 0.02427799 0.03944651 0.0342383
  0.03344784 0.02937801 0.0289355  0.04687166 0.04148968 0.01568588
  0.0104003  0.02048434]]

-* TASK 10/20 | SAMPLE 86/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 427/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 4, Julie is in the school, and there is no mention of her being in the kitchen. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Julie', ' is', ' in', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' kitchen', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.0292621  0.0468259  0.04716472 ... 0.05876641 0.00940116 0.00915453]
 [0.0299405  0.04656508 0.04381508 ... 0.06734563 0.0150593  0.01700406]
 [0.03058785 0.04309509 0.04625468 ... 0.06571501 0.02013629 0.01931134]
 ...
 [0.03051446 0.03903176 0.03730718 ... 0.01980394 0.00731675 0.00813324]
 [0.03078855 0.03130319 0.02881263 ... 0.01238702 0.01114655 0.0139402 ]
 [0.03102918 0.02958268 0.02779934 ... 0.01088224 0.00969078 0.01069353]]

-* TASK 10/20 | SAMPLE 86/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 428/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 states that Fred went to the office, which contradicts sentence 8, which suggests that Fred is either in the school or the cinema. Since Fred is in the office, sentence 8 is no longer applicable.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Fred', ' went', ' to', ' the', ' office', ',', ' which', ' contrad', 'icts', ' sentence', ' ', '8', ',', ' which', ' suggests', ' that', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', '.', ' Since', ' Fred', ' is', ' in', ' the', ' office', ',', ' sentence', ' ', '8', ' is', ' no', ' longer', ' applicable', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 38), x_tokens=38, y_tokens=53, max_supp_attn=0.0, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 38)
DEBUG result.interpretability.attn_scores 2014 
 [[0.01708172 0.02979661 0.02766248 ... 0.02272808 0.01140035 0.03503599]
 [0.0175008  0.02584854 0.02388942 ... 0.02484708 0.01707876 0.02810403]
 [0.01792389 0.03112577 0.03218836 ... 0.01810748 0.01005781 0.02978255]
 ...
 [0.0180669  0.02409567 0.02312562 ... 0.01662942 0.00921718 0.03635738]
 [0.01852478 0.01825788 0.0162135  ... 0.01703437 0.01336955 0.02341724]
 [0.01850071 0.01889509 0.01715302 ... 0.01491467 0.01086145 0.02247798]]

-* TASK 10/20 | SAMPLE 86/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 429/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 10 states that Julie moved to the park, and there is no mention of her being in the school. Previously, sentence 4 mentioned Julie being in the school, but that information is now outdated.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' school', '.', ' Previously', ',', ' sentence', ' ', '4', ' mentioned', ' Julie', ' being', ' in', ' the', ' school', ',', ' but', ' that', ' information', ' is', ' now', ' outdated', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 44), x_tokens=44, y_tokens=49, max_supp_attn=0.0204, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 44)
DEBUG result.interpretability.attn_scores 2156 
 [[0.01879868 0.02319796 0.02458495 ... 0.00875614 0.01119536 0.02550241]
 [0.01926361 0.01760886 0.01900875 ... 0.01493755 0.01636926 0.01520007]
 [0.01967366 0.02599867 0.02948927 ... 0.00935362 0.01499381 0.0295328 ]
 ...
 [0.01992502 0.02723576 0.02607773 ... 0.00398693 0.00487174 0.01319459]
 [0.02040758 0.02150743 0.01935276 ... 0.00595352 0.00584679 0.00865818]
 [0.02021637 0.02414796 0.02140565 ... 0.00498866 0.00537215 0.01143923]]

-* TASK 10/20 | SAMPLE 86/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 430/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 states that Fred is either in the office or the office, which is a redundant and affirmative statement. It clearly indicates that Fred is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' office', ',', ' which', ' is', ' a', ' redundant', ' and', ' affirmative', ' statement', '.', ' It', ' clearly', ' indicates', ' that', ' Fred', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02302828 0.03428274 0.03332637 ... 0.01740947 0.01017651 0.03487032]
 [0.02327011 0.02953933 0.0276635  ... 0.03204677 0.01743016 0.03938693]
 [0.02391072 0.03773829 0.04097999 ... 0.01670716 0.00770129 0.03210136]
 ...
 [0.02417652 0.0378     0.03864171 ... 0.01229568 0.00781706 0.03553087]
 [0.02445437 0.02962293 0.02740235 ... 0.01902231 0.0171457  0.03338103]
 [0.02444794 0.03071971 0.02881455 ... 0.01649541 0.01322946 0.02907647]]
Model's predictions for the sample 86:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to sentence 2, Julie went to   |
|          |                 |   the bedroom, which implies that she is   |
|          |                 |         currently in the bedroom.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 4, Julie is in the  |
|          |                 |   school, and there is no mention of her   |
|          |                 |           being in the kitchen.            |
+----------+-----------------+--------------------------------------------+
|  maybe   |        no       |  Sentence 7 states that Fred went to the   |
|          |                 |   office, which contradicts sentence 8,    |
|          |                 |   which suggests that Fred is either in    |
|          |                 |  the school or the cinema. Since Fred is   |
|          |                 |   in the office, sentence 8 is no longer   |
|          |                 |                applicable.                 |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   Sentence 10 states that Julie moved to   |
|          |                 |  the park, and there is no mention of her  |
|          |                 |      being in the school. Previously,      |
|          |                 |  sentence 4 mentioned Julie being in the   |
|          |                 |    school, but that information is now     |
|          |                 |                 outdated.                  |
+----------+-----------------+--------------------------------------------+
|  maybe   |       yes       |   Sentence 14 states that Fred is either   |
|          |                 |  in the office or the office, which is a   |
|          |                 |  redundant and affirmative statement. It   |
|          |                 |   clearly indicates that Fred is in the    |
|          |                 |                  office.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 86:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.03 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 87/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 431/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Fred being in the bedroom. The context sentences only mention Fred journeying to the school and Bill being in the cinema, but there is no mention of Fred being in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' journey', 'ing', ' to', ' the', ' school', ' and', ' Bill', ' being', ' in', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 26), x_tokens=26, y_tokens=49, max_supp_attn=0.0612, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 26)
DEBUG result.interpretability.attn_scores 1274 
 [[0.01894062 0.03439848 0.03605894 ... 0.00785302 0.00645896 0.02259881]
 [0.01952581 0.02152043 0.02129172 ... 0.00601819 0.00532969 0.01508166]
 [0.01985893 0.02422454 0.02724052 ... 0.00848345 0.00694452 0.01433189]
 ...
 [0.01988036 0.02323297 0.02182695 ... 0.00514714 0.00490785 0.01375018]
 [0.01981514 0.01921634 0.01879242 ... 0.00840481 0.00853666 0.01431241]
 [0.0199956  0.02141325 0.02043203 ... 0.00770455 0.0074038  0.01265781]]

-* TASK 10/20 | SAMPLE 87/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 432/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences only provide information about Julie's movements, but there is no new information about Fred. The previous information about Fred journeying to the school (sentence 1) is still valid.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' provide', ' information', ' about', ' Julie', "'s", ' movements', ',', ' but', ' there', ' is', ' no', ' new', ' information', ' about', ' Fred', '.', ' The', ' previous', ' information', ' about', ' Fred', ' journey', 'ing', ' to', ' the', ' school', ' (', 'sentence', ' ', '1', ')', ' is', ' still', ' valid', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0652, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02009835 0.02616476 0.02890484 ... 0.0090891  0.01098993 0.00651059]
 [0.02080733 0.02524277 0.02728712 ... 0.0103408  0.01291116 0.00821087]
 [0.02120527 0.02432167 0.02850148 ... 0.01498791 0.01890383 0.00901109]
 ...
 [0.02117946 0.02719118 0.02335156 ... 0.00621801 0.00604537 0.00566474]
 [0.02162224 0.01988486 0.0167434  ... 0.0119506  0.00921254 0.01169449]
 [0.02160421 0.02136469 0.01787589 ... 0.00949596 0.00776902 0.0083146 ]]

-* TASK 10/20 | SAMPLE 87/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 433/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 8 explicitly states that Julie moved to the school, which means she is now in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' school', ',', ' which', ' means', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.03324608 0.04139582 0.05366145 ... 0.06986097 0.06694825 0.03532609]
 [0.03388869 0.03063099 0.03863152 ... 0.03631987 0.03955736 0.03376849]
 [0.03474523 0.04641222 0.06046182 ... 0.06596613 0.05179404 0.03029925]
 ...
 [0.03507906 0.04788024 0.04432223 ... 0.12253683 0.06802906 0.02637227]
 [0.03541335 0.03662674 0.03277931 ... 0.07668261 0.0482365  0.03386486]
 [0.03536935 0.04074558 0.03521744 ... 0.10456367 0.07599474 0.0255919 ]]

-* TASK 10/20 | SAMPLE 87/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 434/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Julie being in the bedroom. The context sentences only mention Bill's movements and Julie's previous location in the school (sentence 8), but there is no mention of Julie being in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', "'s", ' movements', ' and', ' Julie', "'s", ' previous', ' location', ' in', ' the', ' school', ' (', 'sentence', ' ', '8', '),', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 44), x_tokens=44, y_tokens=52, max_supp_attn=0.0577, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 44)
DEBUG result.interpretability.attn_scores 2288 
 [[0.01781707 0.0250826  0.02524217 ... 0.02295497 0.08741196 0.00714512]
 [0.01824229 0.01904032 0.01822885 ... 0.0137531  0.04843254 0.00824869]
 [0.01861693 0.02475562 0.02585157 ... 0.0143008  0.06332762 0.01169453]
 ...
 [0.01866738 0.02623504 0.02662055 ... 0.02287951 0.02114967 0.00417076]
 [0.01907527 0.02172705 0.02089541 ... 0.02923276 0.01228993 0.00555583]
 [0.01906591 0.02413253 0.02361517 ... 0.02483866 0.01264484 0.00529634]]

-* TASK 10/20 | SAMPLE 87/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 435/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 explicitly states that Mary travelled to the school, which means she is now in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' means', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03347716 0.05267208 0.04651232 ... 0.02422571 0.04218786 0.04944943]
 [0.03393449 0.03589672 0.02883573 ... 0.03462993 0.02805636 0.02846308]
 [0.03497714 0.05124397 0.05014402 ... 0.03789996 0.05014749 0.04409854]
 ...
 [0.03513489 0.05258087 0.0520007  ... 0.01852472 0.08936744 0.06024611]
 [0.03566794 0.03730488 0.03449562 ... 0.01807662 0.10539003 0.03943463]
 [0.03509562 0.04664322 0.0427064  ... 0.01452477 0.04932186 0.09162195]]
Model's predictions for the sample 87:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |   Fred being in the bedroom. The context   |
|          |                 |   sentences only mention Fred journeying   |
|          |                 |    to the school and Bill being in the     |
|          |                 |  cinema, but there is no mention of Fred   |
|          |                 |           being in the bedroom.            |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |     The context sentences only provide     |
|          |                 |  information about Julie's movements, but  |
|          |                 |  there is no new information about Fred.   |
|          |                 |    The previous information about Fred     |
|          |                 |  journeying to the school (sentence 1) is  |
|          |                 |                still valid.                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 8 explicitly states that Julie   |
|          |                 |  moved to the school, which means she is   |
|          |                 |             now in the school.             |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information provided about   |
|          |                 |  Julie being in the bedroom. The context   |
|          |                 |  sentences only mention Bill's movements   |
|          |                 |    and Julie's previous location in the    |
|          |                 |    school (sentence 8), but there is no    |
|          |                 |   mention of Julie being in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 14 explicitly states that Mary   |
|          |                 |  travelled to the school, which means she  |
|          |                 |           is now in the school.            |
+----------+-----------------+--------------------------------------------+

Metrics for sample 87:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.07 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 88/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 436/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Bill going to the cinema in the context sentences. In fact, the context sentences state that Bill went back to the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' going', ' to', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' In', ' fact', ',', ' the', ' context', ' sentences', ' state', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0811, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.02535548 0.03945681 0.04217905 0.07524607 0.07162596 0.04943409
  0.03451511 0.03084888 0.03099874 0.0497162  0.03669418 0.02577462
  0.02737418 0.12065609 0.12403709 0.03204423 0.02827582 0.0213826
  0.02030092 0.02090509 0.01831415 0.03823219 0.05194463 0.00824582
  0.00809402 0.02693914]
 [0.0261691  0.02459273 0.02491315 0.05639534 0.05124498 0.04268624
  0.02425228 0.02215577 0.02454662 0.04298833 0.03118571 0.02743181
  0.02703013 0.12395167 0.14905517 0.03054298 0.03018284 0.02501635
  0.02217695 0.02153828 0.01709576 0.03197993 0.03170939 0.00612481
  0.00685466 0.01761197]
 [0.02659855 0.02739309 0.03197588 0.05806733 0.05671842 0.05396467
  0.03246511 0.0312256  0.03267852 0.05011794 0.0358148  0.04377057
  0.04188409 0.09784733 0.09161162 0.02618163 0.02811184 0.02539925
  0.02155399 0.02187731 0.01632233 0.02893144 0.02942898 0.00892654
  0.00954897 0.01700417]
 [0.02572263 0.03268887 0.03826841 0.04321054 0.04552416 0.04712893
  0.03625121 0.03865129 0.03608452 0.04391458 0.03601721 0.04723269
  0.04148053 0.05592988 0.05135322 0.03541697 0.03477308 0.03222004
  0.02702153 0.027931   0.0228041  0.03188756 0.03897024 0.02337667
  0.0251771  0.03056831]
 [0.02665004 0.02936275 0.03443656 0.03280951 0.029136   0.04135969
  0.03605902 0.04037948 0.03498053 0.03537606 0.03143157 0.04474634
  0.03857443 0.02129719 0.01635762 0.02683276 0.02669273 0.02728126
  0.02448766 0.02561716 0.02140684 0.02639146 0.02885512 0.02111258
  0.0249057  0.03116886]
 [0.02697585 0.02778676 0.03138246 0.02746574 0.02274352 0.03978939
  0.03507612 0.03846506 0.03432464 0.03239365 0.03095243 0.04635691
  0.03690825 0.01799393 0.01378157 0.02388814 0.02581206 0.02507224
  0.02398858 0.02431171 0.02084256 0.02626402 0.02668488 0.02068215
  0.02439842 0.03052113]
 [0.02649803 0.04320618 0.0385103  0.03021958 0.02463604 0.0424878
  0.04288626 0.04895554 0.03807773 0.03689656 0.03769136 0.05822743
  0.05050283 0.0192369  0.01486001 0.03288125 0.02893701 0.0309524
  0.02777775 0.02724476 0.02333298 0.02836032 0.02933083 0.02133804
  0.02422404 0.0263844 ]
 [0.02727425 0.02928717 0.03338747 0.0280815  0.02103408 0.03844652
  0.03924842 0.03959733 0.03573626 0.03219835 0.03206968 0.04620916
  0.03898341 0.01670736 0.01286819 0.02755663 0.02569923 0.02684928
  0.0257461  0.02730359 0.02366478 0.02659843 0.02346306 0.01726762
  0.02046063 0.02020923]
 [0.02643866 0.02071652 0.01876589 0.01679816 0.01380914 0.01883544
  0.02707653 0.02618787 0.02111973 0.0189407  0.03046985 0.02506681
  0.02801145 0.00933094 0.00950373 0.04189379 0.03003064 0.03448117
  0.03283029 0.03238941 0.03820699 0.02570261 0.01761132 0.03497356
  0.03479962 0.02853351]
 [0.02669062 0.01727012 0.01494364 0.01521171 0.01163461 0.01475158
  0.021245   0.02122889 0.01690345 0.01543657 0.02098526 0.0185049
  0.02044652 0.00777835 0.00809394 0.03783235 0.02551541 0.03116537
  0.02835286 0.02936521 0.04210878 0.02444733 0.01447663 0.03968253
  0.04434669 0.0370247 ]
 [0.02708142 0.01705784 0.01528215 0.01514614 0.01271074 0.01571568
  0.02118917 0.02231327 0.01867726 0.01698776 0.02426381 0.02253496
  0.02258876 0.00808797 0.00798816 0.03770348 0.02514312 0.03564799
  0.03050303 0.0384484  0.03563676 0.02220184 0.01280063 0.03553905
  0.04181788 0.02358303]
 [0.02703818 0.01550223 0.01307431 0.01236806 0.01131672 0.01260408
  0.01802905 0.01716806 0.01541289 0.01375147 0.02671329 0.01831503
  0.01886797 0.00688026 0.00741082 0.04006097 0.028331   0.03780301
  0.03794096 0.04890601 0.04366564 0.02311504 0.01236598 0.03527417
  0.03621114 0.02154641]
 [0.02663723 0.01773148 0.01513345 0.0131335  0.01235574 0.0139252
  0.02008912 0.01879516 0.0184741  0.01440431 0.02564179 0.0174443
  0.01926937 0.00712706 0.00795766 0.0399511  0.02944911 0.03181637
  0.03481722 0.03134292 0.03398803 0.0248035  0.01882914 0.04014501
  0.04265744 0.04352283]
 [0.0271784  0.02598141 0.02179189 0.01625224 0.01402808 0.01767561
  0.02430353 0.0237435  0.02159801 0.01731279 0.02294759 0.02102776
  0.02217221 0.00887773 0.00914852 0.03339455 0.02491063 0.03424063
  0.03513295 0.03287745 0.03395929 0.02457086 0.02231735 0.02547048
  0.02629122 0.02375811]
 [0.02705288 0.03846179 0.04389557 0.0217813  0.01976993 0.03003595
  0.03735766 0.03548861 0.04108091 0.02305303 0.02077485 0.0278492
  0.02652919 0.01297973 0.01217548 0.02875733 0.02659601 0.02448467
  0.02523628 0.02811956 0.0234192  0.02705902 0.04995465 0.024237
  0.03075658 0.02861243]
 [0.02636237 0.06052624 0.06620756 0.02972925 0.02407323 0.03939432
  0.05327905 0.04223005 0.05623724 0.02683057 0.02286411 0.02891317
  0.02956511 0.01542593 0.01583882 0.03399086 0.03228174 0.0268825
  0.02703226 0.03178466 0.02509744 0.03164458 0.07317335 0.02429744
  0.02933175 0.04007192]
 [0.02716151 0.06737567 0.07204303 0.03089379 0.02286598 0.03517816
  0.05018849 0.03995063 0.04972476 0.02703981 0.02386586 0.02795144
  0.02946125 0.01551631 0.01495176 0.03443689 0.0297346  0.0243797
  0.02341884 0.02729732 0.01932392 0.02894773 0.06294407 0.0146409
  0.01576509 0.02024098]
 [0.02734255 0.0316564  0.03512385 0.0237013  0.0189214  0.02839225
  0.03459839 0.03187154 0.03530441 0.0237519  0.02112706 0.02600663
  0.02496795 0.01428873 0.01277152 0.02607744 0.02626898 0.02288398
  0.02352169 0.02609121 0.02138093 0.02752932 0.03925266 0.0227686
  0.02587017 0.02881745]
 [0.02720109 0.02366804 0.02336999 0.02779928 0.02481168 0.02981123
  0.02509607 0.02835875 0.02669423 0.03271728 0.02660923 0.0373418
  0.03379009 0.02002729 0.01452447 0.02133122 0.02458918 0.02614692
  0.02397605 0.02256933 0.02085924 0.02778388 0.02297033 0.02329258
  0.0220573  0.02350138]
 [0.02713877 0.02861353 0.02772536 0.02246691 0.02522358 0.02473426
  0.03022017 0.03298891 0.02997718 0.02446193 0.02739256 0.02821322
  0.03166949 0.0148913  0.01295429 0.0269778  0.0269618  0.02621035
  0.02555961 0.02588047 0.02499993 0.02775852 0.03127674 0.02866795
  0.02947379 0.02636988]
 [0.02823021 0.0203051  0.01944496 0.01951637 0.01627188 0.02244269
  0.02218855 0.02441924 0.0243098  0.02208911 0.02200759 0.02364668
  0.02425819 0.01282139 0.01008994 0.01576502 0.01719544 0.01822917
  0.01936939 0.01929051 0.01730567 0.02495067 0.01744908 0.01641097
  0.01808972 0.01871238]
 [0.02719774 0.02114502 0.01971083 0.01513188 0.01324386 0.01577911
  0.01992164 0.01936236 0.01884674 0.01530126 0.01936943 0.01688366
  0.01966968 0.00965274 0.00908284 0.02164226 0.0198272  0.02057678
  0.02214519 0.02278779 0.02967463 0.02541251 0.0258306  0.0425037
  0.040816   0.03633434]
 [0.02733288 0.03065482 0.02884572 0.01798408 0.01496568 0.01991281
  0.02855088 0.02647839 0.02675112 0.01785124 0.02102414 0.02051543
  0.02388601 0.01195215 0.01047639 0.02276738 0.02242053 0.02123646
  0.02286251 0.02456489 0.02683034 0.02718082 0.03159121 0.03309838
  0.03519404 0.03502437]
 [0.0277246  0.04398497 0.04193579 0.02230442 0.01706599 0.02423589
  0.03404379 0.03296762 0.03623776 0.02184639 0.02147012 0.02382476
  0.02744559 0.01290409 0.01130318 0.02671765 0.02503276 0.02172056
  0.02224805 0.02439996 0.02073888 0.02750865 0.03708742 0.01798343
  0.02013977 0.02162534]
 [0.02767335 0.02852481 0.02757529 0.02106719 0.01576721 0.02217448
  0.03039314 0.02990604 0.02721314 0.02014315 0.02117737 0.02388262
  0.02580753 0.01215407 0.01021072 0.0220374  0.02132876 0.02124817
  0.02136079 0.02424516 0.02330501 0.02821332 0.02595479 0.02411507
  0.03236847 0.03131855]
 [0.02809411 0.01998241 0.0191969  0.01739967 0.0142767  0.01823287
  0.02203388 0.02217919 0.02100132 0.01831297 0.01987144 0.01997952
  0.0224903  0.01049122 0.00856477 0.01989244 0.01967748 0.01883788
  0.01949639 0.02122    0.0217679  0.02616054 0.01646911 0.02718063
  0.02707751 0.0221261 ]
 [0.02735511 0.01540759 0.01380478 0.0120445  0.01005628 0.012267
  0.01528534 0.01604751 0.01631721 0.01317395 0.01692566 0.01413498
  0.01749931 0.00738155 0.00662093 0.02253388 0.02203863 0.02154195
  0.02297566 0.02600393 0.03533139 0.02401633 0.01501644 0.04950093
  0.04800674 0.03920465]
 [0.02706336 0.01536158 0.01341351 0.01231532 0.00975447 0.01215736
  0.0156203  0.0152015  0.01587375 0.01300517 0.01676785 0.01312437
  0.01651583 0.00736232 0.00632377 0.02434989 0.02064959 0.02431211
  0.02385531 0.0282353  0.04376085 0.02189655 0.01377158 0.06610741
  0.05565149 0.04131203]
 [0.0276342  0.0142371  0.01343406 0.01226401 0.01016637 0.01286504
  0.01479389 0.01553139 0.01620112 0.01347806 0.01763123 0.01409172
  0.01649635 0.00783604 0.00616117 0.01808254 0.01690901 0.02056054
  0.01955453 0.02927117 0.03461852 0.01923664 0.01159533 0.06175897
  0.05238459 0.02723805]
 [0.027928   0.0129424  0.0122397  0.01095836 0.00903581 0.01184838
  0.01419078 0.0146492  0.01525501 0.01226723 0.02145183 0.01411756
  0.01619016 0.00736552 0.00566377 0.01828    0.01895769 0.02111147
  0.02003125 0.02393652 0.03718413 0.0186865  0.01006955 0.04741133
  0.03906587 0.02524634]
 [0.02747555 0.01457885 0.0137849  0.01101395 0.00958996 0.01207128
  0.01725481 0.0165317  0.01641008 0.01267456 0.03965483 0.01552589
  0.01849794 0.00748283 0.00638404 0.02300634 0.0272228  0.02368527
  0.02343807 0.02639455 0.03787724 0.02060761 0.01206653 0.0557193
  0.03170519 0.03321319]
 [0.0270137  0.03278943 0.02669133 0.04681819 0.05566455 0.04534297
  0.02965184 0.02902385 0.02902874 0.0499645  0.04347314 0.03601268
  0.03569214 0.05310996 0.03719356 0.02015957 0.02728232 0.02436912
  0.02470724 0.02408746 0.02313102 0.03425173 0.02443552 0.01911495
  0.01369347 0.02094586]
 [0.02789663 0.01568427 0.01561449 0.01429233 0.01135259 0.01426046
  0.01613371 0.01793745 0.01836382 0.01605593 0.02198358 0.01522254
  0.01973352 0.00935658 0.00732644 0.02061543 0.02285575 0.02047973
  0.02225163 0.02352371 0.02624245 0.02169913 0.0130495  0.02982627
  0.02739075 0.02947607]
 [0.0268855  0.02454935 0.0247713  0.04456038 0.04641227 0.03463992
  0.02197714 0.02435752 0.02744996 0.04500404 0.03027202 0.02702791
  0.03022402 0.07945468 0.09501988 0.02177288 0.02879566 0.02539358
  0.02371757 0.02169646 0.01793771 0.0296253  0.02712454 0.00736013
  0.00840568 0.02014618]
 [0.02665186 0.02608788 0.02442183 0.05190681 0.104735   0.03643132
  0.02006533 0.02280385 0.02503651 0.05208344 0.03654552 0.02985748
  0.02635391 0.07847004 0.09770982 0.0250694  0.04073284 0.03724452
  0.03268629 0.02520532 0.02200142 0.02768963 0.02798983 0.00636565
  0.00671453 0.01710486]
 [0.02658261 0.02022361 0.01984445 0.03580424 0.05664544 0.02292928
  0.01507668 0.02055315 0.02187894 0.04088474 0.03389363 0.0293564
  0.024863   0.02820565 0.03274894 0.02138823 0.05116566 0.05295881
  0.07096265 0.03366351 0.03045371 0.02417336 0.02058376 0.01098751
  0.01179814 0.01805105]
 [0.02669301 0.02520525 0.02286018 0.03784112 0.05081205 0.0260581
  0.01939267 0.02144598 0.02519323 0.03757451 0.03096844 0.023877
  0.02429931 0.02916721 0.03187615 0.01816729 0.039611   0.03617778
  0.046962   0.02967289 0.02540948 0.04448101 0.03155516 0.00849178
  0.00845578 0.01693068]]

-* TASK 10/20 | SAMPLE 88/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 437/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 5 explicitly states that Bill is in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.0476, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.04491298 0.06076986 0.06197742 0.09258433 0.07262304 0.07164018
  0.05139267 0.05711532 0.0667466  0.0693785  0.05153291 0.05112287
  0.05479147 0.13094984 0.11904887 0.04494861 0.03584356 0.03370663
  0.03227697 0.03831115 0.03293552 0.05046153 0.06948894 0.02703896
  0.02510863 0.05259707 0.05325026 0.0592459  0.13684528 0.0230347
  0.02860869 0.01861345]
 [0.04623987 0.05661197 0.05630149 0.10268269 0.08894181 0.09917753
  0.0557737  0.05709926 0.0715422  0.09121089 0.06439216 0.07120693
  0.0717224  0.18287359 0.14670312 0.04774962 0.03574646 0.03890158
  0.03418424 0.04059164 0.0340997  0.05330708 0.05234373 0.02318354
  0.02363549 0.04711    0.05172211 0.04894601 0.1272227  0.02804191
  0.0332953  0.02333533]
 [0.0470749  0.054534   0.05975686 0.08724257 0.06853262 0.07744218
  0.05515807 0.05867063 0.06412198 0.07240549 0.05059969 0.0658294
  0.0631924  0.12183896 0.08552178 0.04058042 0.03282849 0.03197867
  0.03068206 0.03585451 0.0294589  0.04941402 0.05031783 0.02819482
  0.02831619 0.04416002 0.04764704 0.04178584 0.10599251 0.04283395
  0.05242803 0.03616276]
 [0.04545793 0.06499792 0.06553452 0.05387935 0.04232622 0.05437936
  0.05684378 0.06411286 0.05747354 0.05001675 0.04553364 0.05564726
  0.05564799 0.03801419 0.03496952 0.05163291 0.04184084 0.03810459
  0.03782869 0.04308861 0.03715025 0.05297831 0.06995912 0.05275748
  0.05358925 0.06055772 0.06234082 0.05040248 0.07510516 0.08020825
  0.11008654 0.08907192]
 [0.04622171 0.07065483 0.07096314 0.0387882  0.02831696 0.04689619
  0.05946524 0.06116554 0.05925274 0.03883951 0.04114119 0.04605279
  0.05066844 0.02683971 0.02589128 0.05396206 0.04257745 0.03716765
  0.04158439 0.04576577 0.04044212 0.04991219 0.07537533 0.05683106
  0.05277159 0.0601467  0.07205831 0.0419256  0.04389369 0.07660056
  0.11014407 0.11173695]
 [0.04745235 0.08643842 0.08516876 0.03994782 0.02657506 0.04487506
  0.05788699 0.0552361  0.06892642 0.03803002 0.03430226 0.04042453
  0.04314514 0.02327402 0.0236805  0.06002292 0.04341262 0.03571788
  0.03910162 0.04661557 0.03827111 0.04491457 0.0982871  0.0526299
  0.04756831 0.05707528 0.07464441 0.03697079 0.03438634 0.05497298
  0.12513408 0.11156334]
 [0.0474187  0.06355738 0.06620806 0.0357603  0.0262103  0.03923364
  0.05684602 0.05157672 0.05537326 0.03526406 0.03550913 0.03861046
  0.04047702 0.02257926 0.02520954 0.06234316 0.04862292 0.0376421
  0.04465655 0.04851553 0.04312671 0.04934107 0.07960921 0.07225146
  0.06368721 0.0617422  0.08110967 0.04073809 0.03806972 0.05783448
  0.08459175 0.09165027]
 [0.04834011 0.03268025 0.03669183 0.02261526 0.0192798  0.02784659
  0.03417074 0.03272299 0.0419173  0.02560824 0.02823048 0.02531411
  0.02763861 0.01496141 0.01906448 0.04158862 0.0368678  0.0296261
  0.03762652 0.04137018 0.03448069 0.0409617  0.04283192 0.05085273
  0.04577757 0.04407408 0.04576623 0.02790938 0.02340968 0.0300686
  0.03558996 0.03500701]
 [0.04765627 0.04040148 0.04183805 0.02784697 0.02295864 0.0370519
  0.04248284 0.04250187 0.0379082  0.03135638 0.0357898  0.03802846
  0.03801541 0.017276   0.02057644 0.04973653 0.04869228 0.03868399
  0.04734576 0.05012774 0.04632312 0.05129953 0.04660714 0.06814598
  0.07706255 0.05334998 0.05332863 0.03561803 0.03365168 0.06371619
  0.04565499 0.07455024]
 [0.04847575 0.0572299  0.0606514  0.05228488 0.03617985 0.0602873
  0.06139495 0.06816307 0.05588286 0.06055325 0.05925361 0.080722
  0.06961747 0.03395427 0.02885805 0.05151631 0.04827761 0.04909609
  0.04866577 0.05064004 0.04483011 0.05295135 0.04545015 0.05039218
  0.05822264 0.04962841 0.06202735 0.04405097 0.03919188 0.08413164
  0.05551042 0.0835648 ]
 [0.04908529 0.04041512 0.04465146 0.0340155  0.02849446 0.04125307
  0.04801678 0.04481743 0.03970214 0.03881051 0.04312458 0.04521666
  0.04644685 0.02200869 0.02187157 0.04708572 0.04218762 0.03890756
  0.04461697 0.04574157 0.04321776 0.048827   0.03656985 0.05407919
  0.05618187 0.04214043 0.05042906 0.04044012 0.03222702 0.06812578
  0.04769622 0.08398274]
 [0.04850108 0.03049896 0.03024239 0.02114158 0.0188058  0.02663869
  0.03512216 0.03206981 0.0294187  0.02513626 0.03658736 0.0306769
  0.03502815 0.01287194 0.01573534 0.04949443 0.04698252 0.04063295
  0.04890859 0.04673928 0.05022316 0.04548569 0.02773911 0.06652702
  0.0651153  0.04107552 0.03455978 0.04174804 0.02260732 0.05457456
  0.03150066 0.04579299]
 [0.0481898  0.03330987 0.03078788 0.02188782 0.0183123  0.02688301
  0.04473716 0.03987846 0.03163976 0.02542103 0.04075293 0.03095258
  0.04253502 0.0125886  0.01423045 0.05777128 0.04914125 0.0511739
  0.05789616 0.05841065 0.06707147 0.04453809 0.0257305  0.07483237
  0.07691389 0.04664667 0.02470515 0.04911478 0.01743806 0.06050016
  0.02646061 0.02958187]
 [0.04897457 0.03027479 0.02976355 0.02138854 0.02038384 0.02766037
  0.04078818 0.03728986 0.02991063 0.02611977 0.0495542  0.03776186
  0.04011564 0.01333899 0.01458399 0.04575997 0.06287844 0.0488418
  0.07146525 0.05662498 0.06048065 0.04365584 0.02108177 0.05084508
  0.06140768 0.03534371 0.02335332 0.04291621 0.01589599 0.04936308
  0.02458925 0.02680259]
 [0.04881064 0.02802333 0.02714659 0.01871765 0.01852296 0.02438178
  0.04169707 0.03528215 0.02832879 0.02233602 0.06118553 0.03515477
  0.04020951 0.01163507 0.01336547 0.05302519 0.07295155 0.05649258
  0.0721092  0.05851419 0.06387329 0.04363717 0.02043528 0.06075282
  0.0610743  0.04250848 0.01970926 0.05068815 0.01507419 0.04850378
  0.02591948 0.02115241]
 [0.04809649 0.0309551  0.02919701 0.0213268  0.01857173 0.03084498
  0.04370738 0.04200931 0.03799069 0.02575326 0.03659671 0.03432999
  0.0442504  0.0136495  0.01300132 0.03535081 0.04113927 0.04048703
  0.05192727 0.05151809 0.04406371 0.04165831 0.0232425  0.04651252
  0.05549261 0.04400869 0.02243251 0.04214798 0.02228032 0.04938333
  0.03559133 0.02767544]
 [0.04944311 0.02992002 0.03075104 0.02703631 0.02081492 0.03266793
  0.04025986 0.04343077 0.03290641 0.02991934 0.04076463 0.03816007
  0.04078678 0.01767708 0.01595395 0.03177341 0.03293215 0.03615819
  0.0393145  0.03873201 0.03984899 0.04137068 0.02287604 0.03672726
  0.03358478 0.0404291  0.02754594 0.04099124 0.02767358 0.04528438
  0.04282742 0.03136775]
 [0.04766317 0.04289075 0.04477774 0.0681169  0.05946424 0.06152253
  0.04412825 0.04518417 0.05570317 0.07257689 0.05160073 0.05919825
  0.05685415 0.08890808 0.101012   0.0383226  0.03629472 0.04573831
  0.03846409 0.04064811 0.03936988 0.04663795 0.0444879  0.02615994
  0.02371433 0.04643929 0.04878335 0.05821134 0.06088663 0.02486809
  0.03272402 0.02047085]
 [0.04717561 0.05414804 0.04811034 0.08945712 0.1907869  0.07331108
  0.0462281  0.04629243 0.05100773 0.09269539 0.07421084 0.06995898
  0.04960307 0.10815841 0.15012124 0.05338868 0.06205349 0.08147752
  0.0527873  0.05007396 0.05931294 0.045485   0.05517283 0.02736428
  0.02309489 0.04608246 0.06500529 0.05790282 0.05603356 0.01573068
  0.01556813 0.01213784]
 [0.04724291 0.04299796 0.03784069 0.05860373 0.0954861  0.04289492
  0.03690189 0.04093853 0.03835006 0.06452949 0.06355951 0.05474874
  0.0432085  0.03790551 0.05535152 0.04593486 0.08393209 0.11975276
  0.07399828 0.06034154 0.08788522 0.04298481 0.03942662 0.04086463
  0.03910341 0.04104563 0.04239646 0.0648705  0.03076491 0.02251557
  0.0179628  0.01353713]
 [0.04756674 0.04868996 0.04163985 0.06467563 0.07841244 0.05311166
  0.0469982  0.04444266 0.04589694 0.06403905 0.055778   0.05088236
  0.04604558 0.04869703 0.05524958 0.03801191 0.05479688 0.06971207
  0.05455979 0.05177491 0.06353474 0.06017811 0.05296717 0.03305683
  0.02857748 0.04383868 0.03718506 0.08337566 0.04134975 0.01970725
  0.01811623 0.01224233]]

-* TASK 10/20 | SAMPLE 88/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 438/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred going to the cinema in the context sentences. In fact, the context sentence 8 states that Fred moved to the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' going', ' to', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' In', ' fact', ',', ' the', ' context', ' sentence', ' ', '8', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 38), x_tokens=38, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 38)
DEBUG result.interpretability.attn_scores 1444 
 [[0.02457135 0.03350898 0.03444604 ... 0.03633328 0.01730302 0.01471448]
 [0.02499082 0.03732738 0.0345539  ... 0.02781204 0.02504918 0.02481864]
 [0.02564766 0.0346451  0.03685008 ... 0.02661328 0.01331496 0.01236168]
 ...
 [0.02575552 0.02832869 0.03203971 ... 0.02583575 0.01379027 0.01203144]
 [0.02637059 0.02198054 0.02467497 ... 0.01884384 0.01807709 0.01667858]
 [0.02621561 0.02399042 0.02771473 ... 0.02312375 0.01829347 0.01565214]]

-* TASK 10/20 | SAMPLE 88/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 439/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 10 states that Bill is in the bedroom, but there is no mention of Bill being in the park. 

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Bill', ' is', ' in', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' park', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 44), x_tokens=44, y_tokens=33, max_supp_attn=0.0, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 44)
DEBUG result.interpretability.attn_scores 1452 
 [[0.02832775 0.03810379 0.0408969  ... 0.07240056 0.02427273 0.05773596]
 [0.0288687  0.02967877 0.03228813 ... 0.0578131  0.02520963 0.02583041]
 [0.02944776 0.04264812 0.04853725 ... 0.06415746 0.03173508 0.04769818]
 ...
 [0.02976232 0.04492443 0.03968782 ... 0.02053321 0.01273277 0.13202438]
 [0.03026637 0.03383236 0.02783763 ... 0.014334   0.01402485 0.07924767]
 [0.03019766 0.03771923 0.03070276 ... 0.01307986 0.01249085 0.09683763]]

-* TASK 10/20 | SAMPLE 88/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 440/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 13 states that Mary is in the cinema, but there is no mention of Mary being in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02932795 0.04253238 0.0420122  ... 0.02360389 0.04297746 0.03955152]
 [0.02971028 0.03944252 0.03975548 ... 0.03657641 0.03571587 0.02743092]
 [0.0305049  0.0460101  0.04603814 ... 0.01973402 0.03868914 0.02299251]
 ...
 [0.03072025 0.03766226 0.03972627 ... 0.01494725 0.05377815 0.03409812]
 [0.03143829 0.02786101 0.02942497 ... 0.02004739 0.03879655 0.03810751]
 [0.03116189 0.03112518 0.03121976 ... 0.01860987 0.0442113  0.03931957]]
Model's predictions for the sample 88:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Bill going to the  |
|          |                 |    cinema in the context sentences. In     |
|          |                 |   fact, the context sentences state that   |
|          |                 |       Bill went back to the bedroom.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 5 explicitly states  |
|          |                 |        that Bill is in the kitchen.        |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Fred going to the  |
|          |                 |    cinema in the context sentences. In     |
|          |                 |  fact, the context sentence 8 states that  |
|          |                 |         Fred moved to the office.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 10 states that Bill  |
|          |                 |     is in the bedroom, but there is no     |
|          |                 |     mention of Bill being in the park.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 13 states that Mary  |
|          |                 |     is in the cinema, but there is no      |
|          |                 |    mention of Mary being in the office.    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 88:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.06 ± 0.02 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 89/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 441/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From sentence 1, we know Bill is either in the park or the cinema. From sentence 2, we know Julie is in the cinema. Since Julie is in the cinema, it's possible that Bill is not in the cinema, which means he could be in the park. However, we can't be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' Bill', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', '.', ' From', ' sentence', ' ', '2', ',', ' we', ' know', ' Julie', ' is', ' in', ' the', ' cinema', '.', ' Since', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' it', "'s", ' possible', ' that', ' Bill', ' is', ' not', ' in', ' the', ' cinema', ',', ' which', ' means', ' he', ' could', ' be', ' in', ' the', ' park', '.', ' However', ',', ' we', ' can', "'t", ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(72, 26), x_tokens=26, y_tokens=72, max_supp_attn=0.0417, attn_on_target=0.0139)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (72, 26)
DEBUG result.interpretability.attn_scores 1872 
 [[0.01267405 0.0318733  0.03224048 ... 0.00325438 0.00521995 0.01512158]
 [0.01307945 0.01960227 0.01897338 ... 0.00271911 0.00418852 0.01000718]
 [0.01329622 0.02214052 0.02416593 ... 0.00393837 0.00614826 0.0096798 ]
 ...
 [0.01337045 0.01962347 0.01753238 ... 0.00247639 0.0033026  0.00926559]
 [0.01348618 0.01614888 0.01436175 ... 0.00723947 0.00710665 0.01003949]
 [0.01350909 0.01815298 0.01532994 ... 0.00477855 0.00548256 0.00901191]]

-* TASK 10/20 | SAMPLE 89/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 442/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill in the given context sentences. Sentence 1 mentioned Bill, but it's not provided in this task. Sentences 4 and 5 talk about Julie and Mary, but not Bill.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '1', ' mentioned', ' Bill', ',', ' but', ' it', "'s", ' not', ' provided', ' in', ' this', ' task', '.', ' Sent', 'ences', ' ', '4', ' and', ' ', '5', ' talk', ' about', ' Julie', ' and', ' Mary', ',', ' but', ' not', ' Bill', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0577, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01752507 0.02101771 0.02221255 ... 0.01108375 0.01314232 0.0141317 ]
 [0.01805034 0.01992836 0.0196369  ... 0.01665568 0.0184209  0.02094775]
 [0.01850693 0.01841941 0.01946165 ... 0.01966036 0.01467237 0.0208537 ]
 ...
 [0.01885106 0.02096885 0.01875106 ... 0.00890786 0.01636789 0.0080153 ]
 [0.01913732 0.02132458 0.02033726 ... 0.00809631 0.01750981 0.00749939]
 [0.01917449 0.01856145 0.01773538 ... 0.00838309 0.01391654 0.00868669]]

-* TASK 10/20 | SAMPLE 89/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 443/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 explicitly states that Julie is in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.05002783 0.05893405 0.06613754 0.08016472 0.06622121 0.07046824
  0.0526244  0.05606676 0.05871834 0.06670909 0.04058269 0.05370706
  0.06116823 0.09907452 0.09616141 0.042027   0.0354237  0.03461946
  0.03782152 0.04070061 0.03422822 0.0500461  0.0811574  0.0195102
  0.02503702 0.05758483 0.06954113 0.06232376 0.13087867 0.02676904
  0.02703345 0.03916994 0.06628305 0.02595134 0.0294071  0.02623211
  0.03156475 0.05428104]
 [0.05043536 0.05189059 0.06097967 0.05000116 0.04592192 0.05253869
  0.05526147 0.06498504 0.04942773 0.04630512 0.03879254 0.04877325
  0.07315613 0.0546674  0.06696994 0.0436862  0.03931472 0.05607298
  0.05085263 0.05892054 0.05277839 0.04736135 0.05427904 0.03472086
  0.04631194 0.05886919 0.05835346 0.04166171 0.08850195 0.05082141
  0.03999333 0.05843955 0.05407186 0.04385209 0.04612933 0.05395858
  0.04638516 0.05374013]
 [0.05203475 0.06357877 0.0728246  0.1006809  0.09233523 0.10441159
  0.06177478 0.06340808 0.06837152 0.08495772 0.05186488 0.07367838
  0.07838082 0.15660764 0.10559795 0.04210461 0.03215756 0.03145111
  0.03376009 0.03654613 0.03045511 0.05343838 0.0616242  0.01638232
  0.02080437 0.04490205 0.0673036  0.04472786 0.11374426 0.04784236
  0.03035322 0.0528681  0.08284283 0.03642661 0.0388371  0.03256858
  0.03973926 0.09078594]
 [0.05063834 0.05671756 0.06748287 0.04443686 0.03931082 0.05237534
  0.05081159 0.05283285 0.05151657 0.04364891 0.03631957 0.04829725
  0.05162747 0.03652555 0.03006486 0.04713047 0.03536147 0.03268666
  0.03793816 0.04094465 0.03520102 0.05497233 0.07614844 0.03315692
  0.05032832 0.06286343 0.06499503 0.04485533 0.10169118 0.1244398
  0.03989048 0.13481851 0.09777739 0.07334048 0.06161258 0.0526486
  0.05197686 0.08236099]
 [0.05187447 0.06003292 0.06724312 0.03539051 0.03101657 0.04549212
  0.05451239 0.04971229 0.05470546 0.03673947 0.03385889 0.04073599
  0.04411739 0.02849159 0.0253512  0.05541416 0.03790766 0.03354649
  0.04258117 0.04569545 0.03698712 0.04868847 0.07662923 0.03020435
  0.04826547 0.05394343 0.06272198 0.03483867 0.06500548 0.1268416
  0.03496047 0.11675376 0.05363261 0.04966047 0.04153058 0.03911852
  0.04051673 0.04451337]
 [0.05249888 0.03353953 0.03636575 0.01991516 0.01817843 0.02622851
  0.02776579 0.02877852 0.03403538 0.02265375 0.02442528 0.0242799
  0.02707    0.01494317 0.01584162 0.0405041  0.03220077 0.02880299
  0.0375563  0.0409722  0.03447781 0.03745056 0.04628918 0.03637332
  0.05636715 0.05293852 0.03416679 0.0280363  0.02455566 0.05839921
  0.02897353 0.0612839  0.02347799 0.03054446 0.02840909 0.03021383
  0.02609605 0.02454004]
 [0.05196746 0.05737955 0.06142889 0.03513847 0.02705443 0.04849193
  0.05208696 0.05136259 0.05145889 0.03770425 0.03656564 0.04918503
  0.04823727 0.02481584 0.02239968 0.05612781 0.04262927 0.04309129
  0.04696215 0.04900763 0.0439404  0.05623575 0.06611303 0.06065866
  0.06470411 0.06022131 0.06655775 0.0371779  0.04810593 0.10206062
  0.05191047 0.09146796 0.09373628 0.07724055 0.06663094 0.05622276
  0.05570612 0.06504678]
 [0.05375704 0.06615976 0.06995706 0.05332811 0.03770958 0.0652854
  0.06130138 0.068489   0.06112855 0.06078085 0.05524216 0.08434122
  0.07088452 0.03684359 0.02851029 0.05328077 0.04660239 0.04686296
  0.04897529 0.05041476 0.04409015 0.05728111 0.05449976 0.06632426
  0.05726549 0.0543979  0.07092627 0.04657099 0.04737127 0.08533476
  0.06419292 0.071228   0.09900729 0.07767929 0.08068522 0.07167739
  0.07064953 0.08554667]
 [0.05447575 0.05078636 0.05232581 0.0368601  0.02800613 0.04612079
  0.05086171 0.04992899 0.04645308 0.03874292 0.04435059 0.04701846
  0.04812713 0.02520677 0.0229517  0.05285106 0.04378223 0.03990728
  0.044671   0.04616777 0.04332555 0.05489741 0.04413218 0.06308528
  0.0701179  0.051561   0.0549794  0.04288128 0.03930039 0.0770233
  0.0618024  0.06334792 0.07032417 0.08116975 0.07334762 0.06516626
  0.06438577 0.05736141]
 [0.0537261  0.0413388  0.03760634 0.02709253 0.01916402 0.03283452
  0.0403747  0.0397905  0.03823366 0.02789638 0.04254507 0.03531485
  0.03848312 0.01767472 0.01835259 0.057398   0.05632737 0.04600795
  0.0473488  0.04836015 0.05116395 0.05392383 0.03315267 0.07071231
  0.09361254 0.05244171 0.03494815 0.04141539 0.02689674 0.0494207
  0.0667927  0.04270567 0.04691206 0.07529149 0.06482206 0.06646008
  0.0586623  0.03723968]
 [0.05311523 0.04160949 0.03590024 0.02817049 0.01741029 0.0330449
  0.04486078 0.04525815 0.03992699 0.02847935 0.04109635 0.03353362
  0.0416496  0.01692102 0.01708557 0.0585442  0.05940423 0.05735549
  0.05148214 0.05279606 0.06164318 0.05064864 0.02774378 0.08169807
  0.1027694  0.05527014 0.02937207 0.03811842 0.01934997 0.0395743
  0.06182368 0.02897719 0.03476676 0.08248207 0.06678405 0.07320409
  0.06902868 0.03360882]
 [0.05430549 0.03593827 0.03409639 0.02657681 0.01815301 0.03212912
  0.03726425 0.0390337  0.03821307 0.02870104 0.0468205  0.03926265
  0.03895121 0.01678188 0.01642054 0.0539206  0.0586134  0.04871267
  0.05633605 0.04975744 0.05660994 0.04795761 0.02546003 0.09834944
  0.08672528 0.04748772 0.0318227  0.03943789 0.01929559 0.03967118
  0.09673449 0.03063083 0.03030835 0.06885413 0.07169752 0.07453025
  0.07249    0.03503532]
 [0.05408743 0.03579354 0.03322355 0.02494048 0.0169302  0.03078762
  0.042427   0.04067732 0.03949027 0.02722719 0.06739789 0.03918143
  0.0410163  0.01512704 0.01574397 0.06193548 0.06289422 0.04995786
  0.05945003 0.05202066 0.05776415 0.04921385 0.0254644  0.09315251
  0.06252956 0.05009598 0.03185822 0.03789965 0.01769611 0.02636335
  0.10185248 0.02450345 0.02055697 0.06016291 0.06196982 0.06883099
  0.06788222 0.02618673]
 [0.05189421 0.08126783 0.05842168 0.03761235 0.02605754 0.04880379
  0.1327222  0.0989745  0.07111132 0.04181378 0.13194449 0.05929253
  0.09057868 0.02045431 0.02240814 0.09726416 0.07714114 0.10334418
  0.08339525 0.09368167 0.07998516 0.06000131 0.05670703 0.14393109
  0.08065555 0.06647942 0.04901264 0.05444996 0.02474887 0.03271805
  0.08228497 0.03246035 0.02725556 0.05584158 0.05407651 0.06304117
  0.05593453 0.03049733]
 [0.05483702 0.03435162 0.03734798 0.03485541 0.02035012 0.03946528
  0.03954766 0.04467138 0.04638716 0.0374415  0.03710391 0.04371667
  0.04022812 0.02437853 0.0202316  0.03607358 0.03452744 0.03504336
  0.04640294 0.04272964 0.04259868 0.04931838 0.02517156 0.03483889
  0.02956198 0.03992548 0.04375622 0.04016998 0.02739308 0.03089247
  0.05924872 0.04743614 0.05415971 0.06213722 0.07377008 0.07934972
  0.08839975 0.0761117 ]
 [0.05292956 0.04880036 0.0515647  0.08370881 0.06462845 0.0743467
  0.04780416 0.05123256 0.06403315 0.08838164 0.05424866 0.06614546
  0.06317826 0.12146858 0.12471168 0.03847861 0.03864317 0.04275049
  0.04272177 0.04513653 0.03857477 0.05276002 0.04914333 0.01801742
  0.02074258 0.04539039 0.05998721 0.06484903 0.06187362 0.02398779
  0.03356305 0.04070229 0.05701485 0.03156558 0.0398748  0.03893092
  0.0418345  0.07467802]
 [0.05253849 0.06320087 0.05577991 0.11199563 0.21274437 0.08731863
  0.05102879 0.05301621 0.06744864 0.11307579 0.08043947 0.07883319
  0.04950386 0.15851758 0.18785289 0.05441561 0.06755014 0.07552505
  0.06090397 0.05730086 0.06400639 0.05277258 0.06398226 0.01780219
  0.01662401 0.04526337 0.07508169 0.07085041 0.06103368 0.01610825
  0.03308069 0.01891987 0.03028639 0.01899371 0.02726649 0.0250418
  0.03034802 0.04200265]
 [0.05216911 0.06123899 0.0518603  0.08779964 0.14158672 0.05146946
  0.04502229 0.04966561 0.05548001 0.09377618 0.07836636 0.07331193
  0.04599319 0.05925256 0.08931888 0.06368838 0.12752913 0.11812019
  0.09718528 0.07739237 0.11677625 0.0532154  0.06153897 0.05134792
  0.03954827 0.04938745 0.05252877 0.10954072 0.03839913 0.02434301
  0.05089255 0.02273862 0.03026443 0.02531459 0.03913764 0.04441023
  0.04958732 0.04580823]
 [0.05268748 0.0574412  0.0494536  0.08133186 0.0772209  0.05838733
  0.05194773 0.05211605 0.06386011 0.07496511 0.05803502 0.0613911
  0.04764871 0.0722477  0.07402544 0.04515515 0.07198999 0.07614163
  0.07365546 0.07145486 0.07539388 0.06981698 0.07076359 0.02973396
  0.0280291  0.05097669 0.04208694 0.12019472 0.04415842 0.01738887
  0.03461644 0.02154792 0.02732144 0.0234917  0.03401152 0.03839398
  0.03881244 0.04065514]]

-* TASK 10/20 | SAMPLE 89/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 444/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 7 (from a previous task) stated that Julie is in the office, and there is no new information that suggests Julie has moved or changed locations.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' (', 'from', ' a', ' previous', ' task', ')', ' stated', ' that', ' Julie', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Julie', ' has', ' moved', ' or', ' changed', ' locations', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02364    0.02746861 0.02557998 ... 0.02005706 0.01962247 0.02224134]
 [0.02412543 0.02387619 0.02142285 ... 0.02234075 0.02862491 0.02606101]
 [0.02472129 0.02629709 0.02602523 ... 0.01516631 0.01543001 0.01821959]
 ...
 [0.0249776  0.02967353 0.02646593 ... 0.01586075 0.01412655 0.02142229]
 [0.02543476 0.02504395 0.02240194 ... 0.01916754 0.02071011 0.01988524]
 [0.02533973 0.02669513 0.02218386 ... 0.01681175 0.01664159 0.01863447]]

-* TASK 10/20 | SAMPLE 89/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 445/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: Sentence 14 explicitly states that Fred moved to the cinema, which means Fred is currently in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' Fred', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03336123 0.04785372 0.04604837 ... 0.02966914 0.03005681 0.02066826]
 [0.03408797 0.03476159 0.03325427 ... 0.03515866 0.05665355 0.03112782]
 [0.03472507 0.04933831 0.05173434 ... 0.04537234 0.05137186 0.03303079]
 ...
 [0.03501085 0.05221869 0.04831912 ... 0.01803752 0.01895243 0.01750643]
 [0.03536273 0.04146305 0.03562364 ... 0.01909446 0.0167747  0.01920826]
 [0.03540076 0.04058895 0.03596361 ... 0.01567197 0.01591525 0.01671541]]
Model's predictions for the sample 89:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  From sentence 1, we know Bill is either   |
|          |                 |  in the park or the cinema. From sentence  |
|          |                 |  2, we know Julie is in the cinema. Since  |
|          |                 |   Julie is in the cinema, it's possible    |
|          |                 |   that Bill is not in the cinema, which    |
|          |                 |  means he could be in the park. However,   |
|          |                 |            we can't be certain.            |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |   There is no information about Bill in    |
|          |                 |  the given context sentences. Sentence 1   |
|          |                 |  mentioned Bill, but it's not provided in  |
|          |                 |  this task. Sentences 4 and 5 talk about   |
|          |                 |       Julie and Mary, but not Bill.        |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 7 explicitly states that Julie   |
|          |                 |             is in the office.              |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 7 (from a previous task) stated  |
|          |                 |   that Julie is in the office, and there   |
|          |                 |    is no new information that suggests     |
|          |                 |   Julie has moved or changed locations.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  Sentence 14 explicitly states that Fred   |
|          |                 |  moved to the cinema, which means Fred is  |
|          |                 |          currently in the cinema.          |
+----------+-----------------+--------------------------------------------+

Metrics for sample 89:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 90/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 446/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Bill went to the park, which implies that Bill is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02717359 0.04359012 0.05469918 0.07282609 0.07985047 0.07678962
  0.05410591 0.06600137 0.05313151 0.0622347  0.04470289 0.0603331
  0.06154576 0.09411506 0.06162515 0.02823697 0.03173297 0.03256088
  0.02872819 0.03106974 0.02419498 0.0379896  0.04070431 0.01732238
  0.02227772 0.03690039]
 [0.02707545 0.0770083  0.06108714 0.05714186 0.0423859  0.05734856
  0.1799191  0.10669594 0.06349168 0.05324995 0.06453843 0.05258017
  0.08074889 0.02718995 0.0226901  0.03872475 0.03794265 0.05110034
  0.03824977 0.04484387 0.03659787 0.04362959 0.03848532 0.02570978
  0.03435985 0.03978262]
 [0.02967669 0.05538159 0.03344605 0.0537098  0.03571157 0.03642222
  0.02828679 0.02186121 0.0209056  0.03289156 0.02459672 0.01645789
  0.01720941 0.0310981  0.04122952 0.01994251 0.01493338 0.01339625
  0.01641393 0.01700286 0.01406962 0.04316766 0.04942255 0.00757188
  0.00787208 0.01676703]
 [0.02800622 0.03285022 0.03701281 0.02474364 0.01843881 0.02703895
  0.02859177 0.02536074 0.02787278 0.02497286 0.02514384 0.02637148
  0.02385518 0.01398707 0.01338043 0.03489969 0.02861418 0.03044077
  0.02997458 0.03228302 0.03227014 0.03117151 0.05327706 0.06066995
  0.03418288 0.04235881]
 [0.02815124 0.04070183 0.04407526 0.06527368 0.06050161 0.0477957
  0.03082767 0.02905803 0.03258834 0.04546799 0.03263123 0.02597446
  0.02509406 0.10448826 0.10949012 0.0328357  0.02871202 0.02062948
  0.02162251 0.02291232 0.02013735 0.03798859 0.05794819 0.01272513
  0.01149238 0.036998  ]
 [0.02878725 0.02654996 0.02638663 0.04923589 0.04619709 0.04146016
  0.02240602 0.02272208 0.0275631  0.04176888 0.02925013 0.02927717
  0.02708779 0.11464494 0.13400525 0.03207939 0.03184986 0.02468607
  0.02419626 0.02377525 0.01944757 0.03239614 0.03398765 0.00841563
  0.01029535 0.02446329]
 [0.02922551 0.02975105 0.0338642  0.05201326 0.04891825 0.05193906
  0.02956681 0.0307766  0.0354769  0.04904571 0.03397734 0.0461908
  0.04046309 0.09059697 0.08481517 0.02727309 0.02912933 0.0244653
  0.02282767 0.02290228 0.01839286 0.02929511 0.0314713  0.01145033
  0.01202369 0.02340472]
 [0.02827629 0.03969314 0.04613426 0.04244705 0.04522333 0.04881225
  0.03466424 0.03962853 0.03953388 0.04327727 0.034856   0.05048608
  0.04124297 0.05494931 0.05018884 0.03743586 0.03682765 0.03065372
  0.0281778  0.02864423 0.02580457 0.03371047 0.04632386 0.02881747
  0.02237956 0.03899907]
 [0.02936087 0.03788733 0.04578643 0.04523518 0.04238143 0.05461332
  0.0376495  0.04347917 0.04741929 0.04740197 0.03415307 0.05105863
  0.04504444 0.04042417 0.02720648 0.02558762 0.02881118 0.02570392
  0.02523339 0.02568765 0.02074278 0.03464681 0.0339899  0.01634105
  0.01853222 0.03192476]
 [0.02870148 0.05067414 0.05425078 0.02853867 0.02430931 0.03755594
  0.04078028 0.04098117 0.04485934 0.02966129 0.02886586 0.03787985
  0.03751546 0.01777217 0.01582381 0.0423658  0.03532062 0.02978981
  0.02999138 0.03150781 0.02977903 0.03329742 0.06305073 0.03836523
  0.03306265 0.03862577]
 [0.02917412 0.0636205  0.06391892 0.02649395 0.02322152 0.03178727
  0.0401651  0.03772277 0.04489179 0.02606822 0.026101   0.02949869
  0.03026058 0.01483394 0.01502849 0.04528286 0.03667465 0.02915253
  0.03141649 0.03506469 0.02883798 0.03054031 0.06722062 0.03228081
  0.02530451 0.03555096]
 [0.02936687 0.03602671 0.04108922 0.0211274  0.01915655 0.02392072
  0.03191773 0.0302531  0.03703749 0.0221905  0.02220793 0.02420357
  0.02422064 0.01291788 0.01359634 0.03888762 0.03245464 0.02541361
  0.02853878 0.03040761 0.02809466 0.02864503 0.05591731 0.04555262
  0.02593225 0.04215039]
 [0.02950212 0.01611372 0.01746935 0.0120102  0.01110935 0.01512622
  0.01513369 0.01651832 0.01972908 0.01387412 0.01505795 0.01459985
  0.01515259 0.00690559 0.00828375 0.02166008 0.02188278 0.02027665
  0.02587899 0.028231   0.03109967 0.02229561 0.04082483 0.06181858
  0.03211104 0.05067835]
 [0.02947569 0.02326873 0.02475335 0.0165446  0.01536996 0.02112832
  0.02288091 0.02274323 0.02430264 0.01854302 0.02268827 0.02223296
  0.02201916 0.00981422 0.01085468 0.03809731 0.02614285 0.02407965
  0.02411938 0.02568131 0.02742073 0.02645657 0.029303   0.05486067
  0.03841505 0.03980372]
 [0.02964148 0.0240328  0.02469588 0.01948195 0.01640856 0.02499061
  0.02509066 0.0267303  0.0249788  0.02270958 0.02722686 0.02942061
  0.02869322 0.0116734  0.0104371  0.03744181 0.02726705 0.02795454
  0.02573745 0.02688667 0.03034677 0.02755223 0.02186883 0.0444941
  0.03148164 0.02500742]
 [0.02912144 0.01947226 0.01639032 0.0136906  0.01073818 0.01464701
  0.01948349 0.01934629 0.0185201  0.01464715 0.02138433 0.01766229
  0.02084772 0.0072527  0.00712716 0.04040357 0.02417124 0.03664208
  0.03062578 0.03704367 0.04992476 0.02583245 0.01802222 0.07821851
  0.05021003 0.02735805]
 [0.02984615 0.01777401 0.01653777 0.01351987 0.01166275 0.01609513
  0.01844746 0.01910304 0.01925306 0.01569228 0.02538869 0.02082641
  0.02158735 0.00757021 0.00709377 0.03039487 0.02319183 0.03647211
  0.0285897  0.04383826 0.04165187 0.02159698 0.01473598 0.0592792
  0.04214887 0.0190029 ]
 [0.02982202 0.0151233  0.01337857 0.01042255 0.00888457 0.01207754
  0.01499166 0.01501233 0.01681617 0.01219271 0.02775171 0.01653778
  0.01737473 0.00589619 0.0061206  0.03040676 0.02437316 0.03261597
  0.03183807 0.03995956 0.04019275 0.02179895 0.01463855 0.06235926
  0.05258905 0.02099209]
 [0.02914107 0.0219121  0.02115634 0.01675297 0.01639738 0.01925719
  0.02352919 0.02645745 0.0270979  0.0191514  0.02647472 0.02396087
  0.02558134 0.0089894  0.0091454  0.02450725 0.02846873 0.03192399
  0.03880627 0.03537066 0.03779766 0.02623521 0.02096998 0.03955832
  0.06381139 0.04500228]
 [0.03026915 0.01976397 0.01917598 0.01625961 0.01273153 0.01788147
  0.01932752 0.02142972 0.02204831 0.01752858 0.02523991 0.02209375
  0.02198436 0.00910259 0.00841396 0.02255049 0.02145661 0.02410192
  0.02883358 0.02670752 0.02794929 0.02626303 0.01457547 0.02780941
  0.03172539 0.02260271]
 [0.03043591 0.02080992 0.02364029 0.02265052 0.01725264 0.02487057
  0.02218034 0.0280491  0.02561304 0.02607799 0.02641849 0.03390049
  0.03051727 0.01374154 0.00972369 0.01871972 0.02204826 0.02411755
  0.02387906 0.02195216 0.02143795 0.02827919 0.01363831 0.01525189
  0.02437628 0.02132714]
 [0.03056982 0.02507804 0.02633597 0.02551394 0.01828229 0.02793735
  0.02760888 0.03574299 0.02732238 0.03002269 0.03507977 0.04031164
  0.03767752 0.01484323 0.01026437 0.02225543 0.02252828 0.02677649
  0.02441519 0.02342014 0.02206641 0.02860254 0.01426571 0.01413449
  0.02369763 0.01662984]
 [0.03043821 0.02382193 0.02385882 0.02424355 0.01860986 0.02595857
  0.02460445 0.03038106 0.02717363 0.02873058 0.03198218 0.03602302
  0.03532485 0.01421576 0.01049452 0.0276887  0.02454389 0.02882353
  0.02639222 0.0251867  0.02402717 0.02874045 0.01250573 0.01598181
  0.02325855 0.01492689]
 [0.030279   0.0194568  0.01855291 0.01528228 0.01173765 0.01675917
  0.01826098 0.02223453 0.0218982  0.01841325 0.02436593 0.02374783
  0.0252137  0.00875258 0.00737134 0.03145337 0.02597409 0.03030167
  0.02835243 0.0268185  0.03061598 0.02652873 0.01204222 0.02622523
  0.03276047 0.01639109]
 [0.03025942 0.01950319 0.01800697 0.01521641 0.01120773 0.01559972
  0.01965864 0.02252008 0.02125856 0.0175537  0.02455455 0.02141772
  0.02410753 0.00811351 0.00701097 0.03395983 0.02612906 0.0320541
  0.0300479  0.02765448 0.03438016 0.02322859 0.01179329 0.02677672
  0.03732654 0.01705525]
 [0.03029243 0.01863298 0.01719864 0.01500535 0.01218484 0.01558257
  0.01707507 0.02093054 0.02037549 0.01833929 0.02508409 0.02257249
  0.02265002 0.00869338 0.0072852  0.02743739 0.02881052 0.03113159
  0.03353658 0.02891056 0.03437299 0.02357268 0.01217964 0.02330317
  0.04280081 0.01686266]
 [0.03046053 0.02102501 0.01977183 0.01661316 0.01237937 0.01735653
  0.02053958 0.02383782 0.0251208  0.01931465 0.02884126 0.0238598
  0.02500813 0.00938005 0.00769432 0.02976315 0.02766038 0.03211623
  0.03263488 0.03218896 0.03437867 0.02448626 0.01263864 0.02433526
  0.03478724 0.01563063]
 [0.03059492 0.01541712 0.01542698 0.01086886 0.00930158 0.01246053
  0.01629695 0.01732208 0.01948701 0.01320435 0.03204896 0.01773734
  0.01898995 0.00698976 0.00573819 0.02681517 0.02774476 0.02821907
  0.03572541 0.03152525 0.03347561 0.02230758 0.0114137  0.03276682
  0.03742838 0.01542155]
 [0.02933154 0.01950179 0.02009697 0.0137027  0.01175777 0.01720314
  0.02124625 0.02384311 0.02842588 0.01749091 0.02364659 0.01929579
  0.02298177 0.00914264 0.00812726 0.02171239 0.03282204 0.02948738
  0.04656569 0.03762072 0.03821284 0.02688698 0.02204793 0.02998954
  0.06397834 0.08552754]
 [0.03063489 0.0196979  0.02022703 0.01784188 0.01348729 0.02104829
  0.01830368 0.02389176 0.02550891 0.0211677  0.02410116 0.02481606
  0.02488849 0.01195433 0.00887428 0.01740657 0.02244817 0.02177316
  0.02954486 0.02576427 0.02673125 0.02482378 0.01250573 0.01563757
  0.02268675 0.01995528]
 [0.02944004 0.02586321 0.02601612 0.04143477 0.04233783 0.03648128
  0.02093866 0.02371409 0.02936981 0.04346425 0.03062084 0.0297208
  0.03015725 0.07146829 0.08803119 0.02262728 0.02863519 0.02535735
  0.02497729 0.02383127 0.02068535 0.03057369 0.02897128 0.00917619
  0.01131124 0.02653098]
 [0.02923168 0.02695554 0.02630723 0.04656337 0.08832698 0.03681473
  0.01906786 0.02221127 0.0280594  0.0499206  0.0356714  0.03049852
  0.02557047 0.07203364 0.0937618  0.02748446 0.03969298 0.03401714
  0.02978467 0.02586626 0.02473938 0.02784119 0.02853762 0.00792016
  0.01020144 0.02296216]
 [0.02899473 0.02386762 0.02276996 0.03858749 0.08893739 0.02539171
  0.01555368 0.02073489 0.02379552 0.0438382  0.03369968 0.0321302
  0.02378883 0.03292129 0.04220648 0.02302577 0.0599397  0.05041929
  0.04133826 0.0306787  0.04069348 0.0253862  0.02492247 0.01348808
  0.01912071 0.02697815]
 [0.02924207 0.02917325 0.0264819  0.03900692 0.05459869 0.0298485
  0.02089945 0.02270516 0.02907364 0.03989211 0.03164829 0.02632186
  0.02559548 0.03352786 0.03686028 0.02063677 0.04106539 0.03334586
  0.03300554 0.02876207 0.02942995 0.04423281 0.03580001 0.01139266
  0.01605803 0.02542755]]

-* TASK 10/20 | SAMPLE 90/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 447/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Bill travelled to the cinema, which means Bill is currently in the cinema. Context sentence 5 is contradictory to sentence 4, so it can be ignored.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' means', ' Bill', ' is', ' currently', ' in', ' the', ' cinema', '.', ' Context', ' sentence', ' ', '5', ' is', ' contradictory', ' to', ' sentence', ' ', '4', ',', ' so', ' it', ' can', ' be', ' ignored', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.1739, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02001757 0.03293099 0.03447933 ... 0.04536654 0.00752806 0.02249672]
 [0.0206919  0.03042003 0.03104269 ... 0.05060289 0.01013466 0.02657303]
 [0.0209902  0.02957318 0.03405961 ... 0.05214481 0.01643132 0.02645688]
 ...
 [0.02107105 0.03033228 0.02511209 ... 0.01498554 0.00551217 0.01029274]
 [0.02149741 0.0234951  0.01819207 ... 0.00789875 0.00714426 0.01086978]
 [0.02151358 0.02421085 0.01856796 ... 0.00829106 0.0074053  0.01348312]]

-* TASK 10/20 | SAMPLE 90/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 448/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the context sentences that suggests Bill is in the cinema. In fact, context sentence 7 states that Bill went to the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Bill', ' is', ' in', ' the', ' cinema', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '7', ' states', ' that', ' Bill', ' went', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 38), x_tokens=38, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 38)
DEBUG result.interpretability.attn_scores 1444 
 [[0.02444246 0.02918193 0.02874288 ... 0.01655027 0.01582482 0.02369622]
 [0.0249833  0.02810064 0.03145103 ... 0.02741822 0.02613328 0.03630619]
 [0.02554973 0.03081394 0.03558795 ... 0.01327946 0.01202993 0.01489003]
 ...
 [0.02572247 0.0278164  0.02530781 ... 0.01321486 0.01350274 0.01492336]
 [0.02618066 0.02091885 0.01889989 ... 0.01760885 0.02230522 0.02103649]
 [0.02620193 0.02284813 0.01963383 ... 0.01434352 0.01545758 0.01765175]]

-* TASK 10/20 | SAMPLE 90/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 449/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 10, Mary is either in the park or the school, but it doesn't provide a definitive location. Therefore, we can only conclude that Mary might be in the park.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' school', ',', ' but', ' it', ' doesn', "'t", ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 44), x_tokens=44, y_tokens=47, max_supp_attn=0.0213, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 44)
DEBUG result.interpretability.attn_scores 2068 
 [[0.01954732 0.0259403  0.02460136 ... 0.01081571 0.00824714 0.01547509]
 [0.01987736 0.0197078  0.01942342 ... 0.0199149  0.01344679 0.02457595]
 [0.0204096  0.0280151  0.02890636 ... 0.01403854 0.01136122 0.02278759]
 ...
 [0.0206112  0.02832419 0.02879168 ... 0.00700706 0.00638144 0.00836073]
 [0.02102197 0.0228771  0.02220956 ... 0.00811493 0.00835602 0.00949325]
 [0.02111023 0.02289094 0.02281453 ... 0.00733541 0.00827991 0.00941343]]

-* TASK 10/20 | SAMPLE 90/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 450/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the context sentences that suggests Mary is in the kitchen. The possible locations for Mary are the office or the bedroom, according to context sentence 14.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' kitchen', '.', ' The', ' possible', ' locations', ' for', ' Mary', ' are', ' the', ' office', ' or', ' the', ' bedroom', ',', ' according', ' to', ' context', ' sentence', ' ', '14', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 50), x_tokens=50, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 50)
DEBUG result.interpretability.attn_scores 2100 
 [[0.02216381 0.03166458 0.03041309 ... 0.03312257 0.01478331 0.02145517]
 [0.02265878 0.02359489 0.02538572 ... 0.02472868 0.01680437 0.01660971]
 [0.02302836 0.03179203 0.03360257 ... 0.0274426  0.01291414 0.01658837]
 ...
 [0.02324751 0.03172476 0.02943233 ... 0.02510688 0.0132017  0.02005577]
 [0.02374514 0.02286031 0.02078773 ... 0.02086629 0.01601863 0.01711114]
 [0.02364078 0.02773859 0.02486688 ... 0.0238088  0.01539692 0.01859057]]
Model's predictions for the sample 90:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Bill    |
|          |                 |    went to the park, which implies that    |
|          |                 |       Bill is currently in the park.       |
+----------+-----------------+--------------------------------------------+
|  maybe   |        no       |   According to context sentence 4, Bill    |
|          |                 |    travelled to the cinema, which means    |
|          |                 |  Bill is currently in the cinema. Context  |
|          |                 |  sentence 5 is contradictory to sentence   |
|          |                 |          4, so it can be ignored.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information in the context   |
|          |                 |   sentences that suggests Bill is in the   |
|          |                 |    cinema. In fact, context sentence 7     |
|          |                 |     states that Bill went to the park.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |   According to context sentence 10, Mary   |
|          |                 |  is either in the park or the school, but  |
|          |                 |      it doesn't provide a definitive       |
|          |                 |      location. Therefore, we can only      |
|          |                 |  conclude that Mary might be in the park.  |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information in the context   |
|          |                 |   sentences that suggests Mary is in the   |
|          |                 |  kitchen. The possible locations for Mary  |
|          |                 |  are the office or the bedroom, according  |
|          |                 |          to context sentence 14.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 90:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 91/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 451/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Bill went back to the kitchen, which implies that Bill is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' went', ' back', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02636632 0.04312401 0.05523906 0.07207768 0.07533495 0.07615129
  0.0569392  0.06630836 0.05208873 0.05998972 0.04058371 0.05772398
  0.05905711 0.09580533 0.06119699 0.02707142 0.02990452 0.0309223
  0.02861471 0.03172504 0.02354478 0.03672062 0.04166291 0.01411384
  0.02503845 0.03616016]
 [0.02632336 0.06935321 0.04997063 0.04369489 0.03100872 0.04405064
  0.14002101 0.08094316 0.05111062 0.03819612 0.05051239 0.03912027
  0.06544115 0.0185322  0.01794688 0.03937665 0.03815168 0.05389932
  0.04095282 0.04886683 0.04142895 0.04035131 0.03926025 0.0321832
  0.04329108 0.04396415]
 [0.02881206 0.05484954 0.03341915 0.05331034 0.03539234 0.03631991
  0.02813371 0.02163196 0.0206614  0.03301224 0.02285792 0.01635216
  0.01673587 0.03177803 0.04083836 0.01921213 0.01455689 0.01316627
  0.01698087 0.01766705 0.01401351 0.04139065 0.05073986 0.0051302
  0.00644732 0.016406  ]
 [0.02722017 0.02694378 0.03002149 0.02525981 0.01950116 0.02524069
  0.02536712 0.02352989 0.02407019 0.02435585 0.02453365 0.02611128
  0.02274198 0.01622265 0.01624394 0.03426571 0.02841941 0.03040298
  0.03022072 0.03093688 0.03086034 0.02813461 0.04154789 0.05963283
  0.03180858 0.03818794]
 [0.02734382 0.04020143 0.04339634 0.06494347 0.05964463 0.04719826
  0.03056659 0.0282222  0.03186456 0.04482481 0.02971497 0.02565193
  0.02429035 0.10254876 0.10763751 0.03197025 0.02801863 0.02035688
  0.0221236  0.02339902 0.02008094 0.03678249 0.05823421 0.008209
  0.00918993 0.03629799]
 [0.02795947 0.02621193 0.02581844 0.04847247 0.04555789 0.04042168
  0.02227977 0.02197259 0.02696069 0.04079843 0.02685322 0.02882871
  0.02604497 0.11249752 0.13219316 0.03129779 0.03086703 0.02417307
  0.02486206 0.0243036  0.01947387 0.0316666  0.03385801 0.00591845
  0.00879409 0.02368196]
 [0.02835515 0.02951805 0.03314568 0.05134224 0.04889416 0.05093903
  0.02966399 0.03009464 0.0346195  0.04792161 0.03137103 0.04519394
  0.03870104 0.08864876 0.08361483 0.02656725 0.02823938 0.02376294
  0.02355434 0.02356135 0.01846058 0.02881142 0.03160372 0.00907374
  0.01245875 0.02239808]
 [0.02743708 0.03935003 0.04515173 0.04123644 0.04496744 0.0470315
  0.03523782 0.03906725 0.03861038 0.04187581 0.03218211 0.04870646
  0.04028082 0.05332579 0.04908109 0.03737395 0.03570502 0.03028029
  0.02900697 0.02961962 0.02573644 0.0330991  0.04682246 0.02636833
  0.02340954 0.0365705 ]
 [0.02845989 0.03889253 0.04630401 0.04526375 0.04324909 0.05434627
  0.03849376 0.04397577 0.04754368 0.04725308 0.03271336 0.05014452
  0.04469773 0.04036431 0.02722951 0.02551578 0.02787931 0.0254162
  0.02581712 0.02644728 0.02052565 0.03417413 0.03471602 0.01343462
  0.01900425 0.03037388]
 [0.02783451 0.04997812 0.05348067 0.02828365 0.02427547 0.03665438
  0.04059206 0.04041345 0.04347439 0.02912397 0.02723034 0.03673798
  0.03704483 0.01760393 0.01573834 0.0425131  0.03472597 0.02953449
  0.03050422 0.03187481 0.02935062 0.0321979  0.06279799 0.03550006
  0.03282645 0.03669133]
 [0.02833868 0.06239543 0.06354927 0.02641067 0.02281315 0.03148193
  0.04001107 0.03687764 0.04422791 0.02594568 0.02436094 0.02869204
  0.02947778 0.01456842 0.0147418  0.04482092 0.03562931 0.02849469
  0.03174913 0.03517669 0.02814309 0.02897378 0.06753889 0.02617832
  0.0255898  0.03387938]
 [0.02849209 0.03487875 0.0405471  0.02096053 0.01855866 0.02397576
  0.03173548 0.02941135 0.03614117 0.02180603 0.02065204 0.02353289
  0.02338687 0.01262699 0.01325433 0.03853917 0.03147393 0.0246623
  0.02874194 0.03033291 0.02719925 0.02752377 0.05492985 0.03777646
  0.02602334 0.03949322]
 [0.02863484 0.01612701 0.01773823 0.01195333 0.01080344 0.0156121
  0.01603676 0.01694679 0.01982149 0.01361375 0.01466073 0.01475426
  0.01496764 0.00695313 0.00828259 0.02340493 0.02278973 0.02019252
  0.02549507 0.02692827 0.02818729 0.0213209  0.03777311 0.05433086
  0.03077185 0.04752629]
 [0.02854956 0.02272129 0.02452006 0.01635042 0.01494868 0.02117872
  0.02300081 0.02212964 0.02463766 0.01820231 0.02101276 0.02141741
  0.02103447 0.00967524 0.01045522 0.03533606 0.02399016 0.02251827
  0.02369424 0.02570503 0.02676417 0.02607064 0.02954381 0.05218458
  0.03707074 0.0407985 ]
 [0.02869802 0.02382771 0.02467365 0.01917463 0.01625097 0.02445331
  0.02537663 0.02620801 0.02541643 0.02230467 0.02587271 0.02912999
  0.02839842 0.01170272 0.01009939 0.03660057 0.02574023 0.02752126
  0.02613124 0.0274355  0.0304451  0.0275971  0.02180678 0.04455121
  0.03064619 0.02457627]
 [0.02819181 0.01898946 0.01606301 0.01355032 0.01065666 0.01468828
  0.01977599 0.01903441 0.01886331 0.01447428 0.02078868 0.01749844
  0.02095072 0.00717822 0.00682511 0.04035027 0.02392814 0.03618109
  0.03003805 0.03674755 0.04869219 0.02496222 0.0172407  0.08130354
  0.04456028 0.02705593]
 [0.02889873 0.01800053 0.01718532 0.01445332 0.01251738 0.01762651
  0.01940855 0.02006854 0.02052584 0.01667601 0.0237335  0.0213366
  0.02193795 0.00802215 0.00719846 0.02501278 0.0197613  0.0297957
  0.0260246  0.03891856 0.04333346 0.02147017 0.01498353 0.06725368
  0.03544025 0.01926956]
 [0.02943961 0.01452578 0.01334863 0.01124192 0.00919987 0.01332861
  0.01551802 0.01625737 0.0172845  0.01318556 0.0227978  0.01705395
  0.01848316 0.00627959 0.00596324 0.02230918 0.01847372 0.02513339
  0.02407489 0.02690969 0.03771555 0.02030152 0.01204606 0.04976445
  0.03603087 0.02066043]
 [0.02908725 0.01618714 0.01490398 0.01138795 0.00955524 0.01336746
  0.01873074 0.01748323 0.01820946 0.0129314  0.03518378 0.01838563
  0.01903697 0.00636734 0.00687132 0.02706676 0.0227856  0.02659065
  0.02667186 0.02800449 0.03606541 0.02285521 0.01427792 0.05302741
  0.0400741  0.0228852 ]
 [0.02814309 0.02331631 0.02278939 0.01708996 0.0161991  0.02127821
  0.02795389 0.02812736 0.02826839 0.01943854 0.02925696 0.02370403
  0.02583035 0.0098781  0.01038208 0.02393777 0.03296604 0.03009857
  0.03569236 0.03232682 0.03363952 0.02792314 0.02195974 0.03682746
  0.0695736  0.06924403]
 [0.02940076 0.01969505 0.01936476 0.0162218  0.01241364 0.01767957
  0.02015381 0.02184409 0.021694   0.01715117 0.02575137 0.02182328
  0.02206253 0.00918803 0.00809252 0.02259262 0.02193092 0.0254081
  0.0264781  0.0247589  0.02584228 0.02636608 0.01426642 0.02583258
  0.02836383 0.0227952 ]
 [0.02956184 0.02098875 0.0234412  0.02309744 0.01741419 0.02535344
  0.02279504 0.02916454 0.02648625 0.02680759 0.02563004 0.03448464
  0.03028704 0.0146613  0.00953926 0.01784413 0.02080778 0.02259003
  0.02328403 0.02181121 0.02012695 0.02835083 0.01447287 0.01516438
  0.02523166 0.02195564]
 [0.02974139 0.02539023 0.02734232 0.02612664 0.01843505 0.02814007
  0.02648672 0.03593836 0.02811556 0.0311641  0.03156232 0.04078353
  0.03710765 0.01538328 0.0100418  0.0204179  0.02072413 0.02375098
  0.02350735 0.02207958 0.02008515 0.02800171 0.01502781 0.01304723
  0.02286055 0.01663886]
 [0.02968005 0.0236031  0.0235888  0.02314299 0.01732259 0.02571634
  0.02322905 0.02948783 0.02777667 0.02797752 0.02783264 0.03546453
  0.03433962 0.01384359 0.00958941 0.02444684 0.0218673  0.02554082
  0.02579969 0.02456377 0.02212797 0.02750298 0.01303978 0.0157769
  0.02155758 0.01458465]
 [0.0294545  0.01871234 0.01835933 0.01455782 0.01099327 0.0165255
  0.01822929 0.02256104 0.02258574 0.01800203 0.02265023 0.02362143
  0.0249185  0.0085954  0.00696329 0.03085585 0.02458592 0.0270764
  0.02680596 0.02554051 0.02825795 0.02527272 0.01186836 0.02645654
  0.03033988 0.01740415]
 [0.02943902 0.01947736 0.01870696 0.0154568  0.01105286 0.01631895
  0.02144719 0.0246915  0.02219502 0.01762494 0.02356516 0.02205443
  0.02490908 0.00853215 0.0069484  0.03270355 0.02602555 0.03003452
  0.02933007 0.02670418 0.03224377 0.02290758 0.01151182 0.02534202
  0.03405167 0.01769869]
 [0.02947138 0.01879942 0.01776446 0.01542732 0.01209359 0.01625451
  0.01873938 0.0220144  0.0209551  0.01836116 0.02443199 0.02246624
  0.02262158 0.00912649 0.007297   0.0260442  0.02780329 0.02875551
  0.03127556 0.0265566  0.03050523 0.023268   0.01201846 0.0220012
  0.03924629 0.01715871]
 [0.02960324 0.02097493 0.01996338 0.01649109 0.01205055 0.01764356
  0.02220628 0.02424888 0.02517855 0.01920511 0.02973574 0.02312228
  0.02493944 0.00951398 0.00759852 0.02799795 0.02679753 0.02942029
  0.03120956 0.029671   0.0315528  0.02448036 0.01271602 0.02399393
  0.03282488 0.01588678]
 [0.02958162 0.01668748 0.01652827 0.01182337 0.00982121 0.01347168
  0.0188855  0.01882024 0.01999825 0.01443422 0.03755363 0.01797323
  0.0210261  0.00740729 0.00614083 0.02791101 0.02909469 0.02859462
  0.0321076  0.02822421 0.03150018 0.02303198 0.01225711 0.02992912
  0.03558477 0.01767478]
 [0.02836232 0.02163699 0.02057998 0.01392813 0.01187286 0.01666952
  0.02739711 0.02782752 0.02673476 0.01773544 0.03983822 0.02226717
  0.0305205  0.00830592 0.00762129 0.02710755 0.03698656 0.03761829
  0.04187831 0.03924596 0.04107115 0.027867   0.02073772 0.04019986
  0.0661744  0.05100473]
 [0.02962908 0.01976554 0.02040766 0.01840159 0.01396645 0.02062916
  0.01938348 0.02614886 0.02405026 0.02230329 0.02469871 0.02429054
  0.0258     0.01275292 0.00986028 0.01719008 0.02400861 0.02400987
  0.02651717 0.02376194 0.02352403 0.02448609 0.0135585  0.01501465
  0.02426405 0.02264353]
 [0.02859164 0.02508754 0.0259945  0.04138247 0.04262002 0.03635687
  0.02032585 0.02325963 0.02864183 0.04394909 0.02852567 0.02906997
  0.02939403 0.07099868 0.08763186 0.02223389 0.02737739 0.02501571
  0.02545231 0.02412706 0.02031938 0.02986288 0.02867775 0.0068115
  0.0096109  0.02603448]
 [0.02839071 0.02632388 0.02586863 0.04619488 0.08677409 0.03643361
  0.01863304 0.02138516 0.02765308 0.04999213 0.03348837 0.02981099
  0.02462641 0.0710283  0.09351715 0.0267423  0.03771973 0.03367401
  0.03081043 0.02644564 0.02434128 0.02747581 0.02762767 0.0061493
  0.00880705 0.02249185]
 [0.0281016  0.024572   0.02381056 0.04114801 0.09721112 0.02688272
  0.01621227 0.02120566 0.02451008 0.04753485 0.03530183 0.03448226
  0.02380878 0.03580106 0.04585871 0.02315762 0.05990161 0.05131391
  0.04150663 0.03084833 0.03732707 0.02528941 0.02450387 0.0123231
  0.018921   0.02562603]
 [0.02840541 0.02889331 0.02701342 0.04014185 0.05662951 0.0305799
  0.02103307 0.02269872 0.02902457 0.04182747 0.03256142 0.02820893
  0.02509857 0.03428245 0.03750561 0.02021208 0.04036297 0.03409378
  0.03308641 0.02877407 0.02751406 0.04350929 0.03437213 0.00919543
  0.01411201 0.02428111]]

-* TASK 10/20 | SAMPLE 91/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 452/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie's current location in the given context sentences. Context sentence 2 mentioned Julie's possible locations, but it is not relevant to the current situation. Context sentences 4 and 5 only provide information about Bill's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' current', ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Context', ' sentence', ' ', '2', ' mentioned', ' Julie', "'s", ' possible', ' locations', ',', ' but', ' it', ' is', ' not', ' relevant', ' to', ' the', ' current', ' situation', '.', ' Context', ' sentences', ' ', '4', ' and', ' ', '5', ' only', ' provide', ' information', ' about', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 32), x_tokens=32, y_tokens=58, max_supp_attn=0.0345, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 32)
DEBUG result.interpretability.attn_scores 1856 
 [[0.01575359 0.02086322 0.02282093 ... 0.03886021 0.00996559 0.00740658]
 [0.0163297  0.01786434 0.01891672 ... 0.04548977 0.01447057 0.00983472]
 [0.01657459 0.01817794 0.02141073 ... 0.04350932 0.02005774 0.01224036]
 ...
 [0.01681294 0.01875205 0.01634798 ... 0.00829627 0.00864987 0.0089703 ]
 [0.01706755 0.01918769 0.01822626 ... 0.00839557 0.00855053 0.00902449]
 [0.01723304 0.01657323 0.0159355  ... 0.00875617 0.00878836 0.0091942 ]]

-* TASK 10/20 | SAMPLE 91/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 453/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, Julie journeyed to the office, which implies that Julie is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03029261 0.04168717 0.04679093 ... 0.02147446 0.01758623 0.02634018]
 [0.03045995 0.0344434  0.03995124 ... 0.02457642 0.02982355 0.03698873]
 [0.03163493 0.04525701 0.05274718 ... 0.01587519 0.01430305 0.01875659]
 ...
 [0.03182761 0.04256732 0.04222592 ... 0.01697287 0.01365244 0.01731784]
 [0.03197067 0.03381499 0.03169422 ... 0.02082242 0.02673935 0.0257732 ]
 [0.03198495 0.0398379  0.03527145 ... 0.01968728 0.0193103  0.0243195 ]]

-* TASK 10/20 | SAMPLE 91/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 454/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Mary is in the park, and there is no information that suggests Mary has moved from the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' in', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', ' from', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02739213 0.03121035 0.03139446 ... 0.02100048 0.02390694 0.01200879]
 [0.02788749 0.02799573 0.0284557  ... 0.03068037 0.0543904  0.02512634]
 [0.02852431 0.03367624 0.03489606 ... 0.0299626  0.03007405 0.01573055]
 ...
 [0.0287462  0.03748336 0.03540354 ... 0.00934497 0.0119057  0.00921545]
 [0.0291418  0.03131091 0.02825732 ... 0.01187463 0.01045161 0.01220288]
 [0.02918607 0.03262739 0.02869867 ... 0.00908541 0.01082486 0.01048191]]

-* TASK 10/20 | SAMPLE 91/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 455/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie's current location being the cinema. Context sentence 14 only mentions the bedroom as a possible location for Julie, and there is no mention of the cinema.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' current', ' location', ' being', ' the', ' cinema', '.', ' Context', ' sentence', ' ', '14', ' only', ' mentions', ' the', ' bedroom', ' as', ' a', ' possible', ' location', ' for', ' Julie', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0227, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02099122 0.02875476 0.0281968  ... 0.02604277 0.04344868 0.03063954]
 [0.02121774 0.02693862 0.02317724 ... 0.01144016 0.02092329 0.02684586]
 [0.02187789 0.03235739 0.03285513 ... 0.02542396 0.04023559 0.02363071]
 ...
 [0.02211086 0.03093728 0.02943739 ... 0.0286942  0.05918555 0.02847194]
 [0.02258269 0.02336215 0.02178138 ... 0.01123073 0.03192045 0.02509172]
 [0.02238703 0.02616401 0.02402228 ... 0.01051028 0.06440039 0.02716058]]
Model's predictions for the sample 91:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Bill    |
|          |                 |  went back to the kitchen, which implies   |
|          |                 |   that Bill is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|  maybe   |  not mentioned  |   There is no information about Julie's    |
|          |                 |   current location in the given context    |
|          |                 |  sentences. Context sentence 2 mentioned   |
|          |                 |   Julie's possible locations, but it is    |
|          |                 |   not relevant to the current situation.   |
|          |                 |   Context sentences 4 and 5 only provide   |
|          |                 |     information about Bill's location.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 8, Julie   |
|          |                 |   journeyed to the office, which implies   |
|          |                 |   that Julie is currently in the office.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 7, Mary is  |
|          |                 |  in the park, and there is no information  |
|          |                 |   that suggests Mary has moved from the    |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information about Julie's    |
|          |                 |     current location being the cinema.     |
|          |                 |   Context sentence 14 only mentions the    |
|          |                 |     bedroom as a possible location for     |
|          |                 |   Julie, and there is no mention of the    |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 91:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 92/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 456/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Mary moved to the school, which implies that she is currently in the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Mary', ' moved', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02712761 0.04540917 0.05721802 0.06884167 0.07545729 0.07200094
  0.05457683 0.06685213 0.05341074 0.0609313  0.04514362 0.05986208
  0.06512176 0.08670767 0.05345215 0.02908851 0.03016603 0.0322846
  0.02877956 0.03168515 0.02693234 0.03900975 0.04125483 0.02032009
  0.02171513 0.03680522]
 [0.026948   0.06885536 0.05999615 0.0619756  0.05332816 0.06415009
  0.18935113 0.11705205 0.07445959 0.06714926 0.06130237 0.05646416
  0.08518023 0.04056853 0.03092079 0.03532292 0.03318305 0.0425358
  0.03463339 0.04020315 0.0342654  0.04509138 0.04044564 0.02491574
  0.02535759 0.03692504]
 [0.02962515 0.05444964 0.03448067 0.0527714  0.03992613 0.03475342
  0.02651193 0.02017524 0.02118107 0.03311761 0.02656009 0.01576206
  0.01722806 0.0315868  0.04135068 0.02075997 0.01339529 0.01283991
  0.01583663 0.01611482 0.01521776 0.04259955 0.04974508 0.00735126
  0.00703505 0.0182394 ]
 [0.02807956 0.03293805 0.0373398  0.02479813 0.01713879 0.02862366
  0.02701045 0.02503685 0.02915535 0.02479001 0.02550501 0.02666575
  0.02396432 0.01323711 0.0132447  0.03488304 0.02897406 0.03213495
  0.03275496 0.03416704 0.03148451 0.031045   0.04978985 0.05513111
  0.06008629 0.04480449]
 [0.02817225 0.03895291 0.04309708 0.06515346 0.06006004 0.04575805
  0.02858719 0.02638865 0.03203603 0.04373377 0.03238492 0.02451478
  0.02359913 0.10392109 0.10909183 0.03208732 0.0258607  0.02009496
  0.02054039 0.02196493 0.02141866 0.03789366 0.05798239 0.01259828
  0.0102444  0.03903573]
 [0.02876385 0.02519824 0.02635027 0.05039515 0.04514502 0.04171608
  0.02136763 0.02066792 0.02713206 0.04090705 0.02881632 0.02778859
  0.02559757 0.11268795 0.13545923 0.03166937 0.02888939 0.02403134
  0.02307978 0.02333498 0.02042551 0.0324303  0.03484908 0.00897485
  0.00835429 0.02551491]
 [0.02920321 0.02830086 0.03401864 0.05285442 0.04923716 0.05244983
  0.02798126 0.02829624 0.03551368 0.04830951 0.03364675 0.04386945
  0.03891449 0.08971611 0.08519454 0.02674998 0.02634868 0.0238641
  0.02225321 0.02304611 0.01929088 0.02923769 0.03275003 0.01218785
  0.01108438 0.02391382]
 [0.02829161 0.03830686 0.04529244 0.04167409 0.04368574 0.04971433
  0.03276315 0.03754204 0.03879768 0.04328161 0.03516251 0.04928954
  0.04094892 0.05461809 0.05014891 0.03638822 0.03398458 0.03021745
  0.02727663 0.02884583 0.02593671 0.03306634 0.04612894 0.03072994
  0.02904683 0.03874306]
 [0.02938932 0.03739839 0.04631024 0.04657629 0.04235331 0.05589293
  0.03548371 0.04092562 0.04566349 0.04816249 0.03492543 0.04950481
  0.04328078 0.04174835 0.0273995  0.02529303 0.02587805 0.02499551
  0.0238038  0.02566567 0.02133862 0.03299824 0.03492239 0.01635755
  0.01778882 0.03150817]
 [0.0287292  0.05156879 0.05548093 0.03036992 0.02436318 0.03950944
  0.04016557 0.04105999 0.04500642 0.03124376 0.0292388  0.03860994
  0.03735851 0.01884128 0.01611541 0.04240938 0.03353041 0.02941229
  0.02897308 0.03116093 0.02926117 0.03251316 0.06130081 0.03734453
  0.03919384 0.03760267]
 [0.02919344 0.06532845 0.06450012 0.02803995 0.0228959  0.03239936
  0.03955061 0.0369262  0.04597734 0.02695374 0.02555445 0.0298184
  0.02877729 0.0157151  0.01524634 0.04600985 0.03409947 0.0284021
  0.02946363 0.03366931 0.02905081 0.03000556 0.06605741 0.03088393
  0.03033403 0.03529984]
 [0.02933627 0.03621966 0.04048546 0.02168425 0.01848608 0.02435503
  0.03136351 0.02910142 0.03629628 0.02214498 0.02111167 0.02444126
  0.02231412 0.01332071 0.01358918 0.03978629 0.03105073 0.02499963
  0.0282582  0.03019769 0.02820783 0.02903943 0.05280161 0.04396686
  0.04796139 0.04153895]
 [0.02955199 0.01604224 0.01744884 0.01211258 0.010992   0.01431966
  0.01514838 0.01637839 0.02044387 0.01390199 0.014334   0.0153968
  0.01463686 0.00703656 0.00808532 0.02187073 0.02137795 0.02051999
  0.02571063 0.02845201 0.03010136 0.0227582  0.03498955 0.05849324
  0.08109663 0.04775327]
 [0.02950047 0.02309749 0.02428617 0.0165956  0.01549096 0.02082625
  0.02168904 0.02111784 0.02361569 0.0181282  0.02105885 0.02213971
  0.02059936 0.0099873  0.01088328 0.03690448 0.02543675 0.02312778
  0.02351641 0.0248479  0.02590785 0.02680993 0.02785689 0.05187644
  0.06394852 0.04477144]
 [0.0296065  0.02372644 0.02431617 0.01895551 0.01640629 0.02385382
  0.02435713 0.02708084 0.02451181 0.02218937 0.02572861 0.02968489
  0.02939228 0.01139908 0.01023425 0.0355657  0.02805166 0.02749667
  0.02552962 0.02610313 0.0284762  0.02808117 0.02132411 0.0468604
  0.04053422 0.02603208]
 [0.02915128 0.02002624 0.01688107 0.01420847 0.01144452 0.01521706
  0.02056081 0.02299489 0.01839654 0.01554421 0.02137684 0.01920586
  0.02337262 0.00733563 0.00735245 0.03830673 0.02956107 0.03534998
  0.03271356 0.03417535 0.04297167 0.0256977  0.01664698 0.07404599
  0.05951221 0.02989537]
 [0.02984067 0.01850951 0.01636954 0.01431599 0.0121016  0.01637888
  0.01858885 0.02059259 0.01869169 0.01637502 0.02639941 0.0217268
  0.02291429 0.00744102 0.00729744 0.03736121 0.02530151 0.039824
  0.02921426 0.03507209 0.03697212 0.0221012  0.01433751 0.05135966
  0.04276134 0.02216673]
 [0.029727   0.01612282 0.01402268 0.01090677 0.0091739  0.01327208
  0.01733926 0.01784827 0.01694619 0.01305314 0.03239391 0.0175966
  0.02023312 0.00595858 0.00644812 0.03331556 0.03054331 0.03444828
  0.03455829 0.03422678 0.03678907 0.02268558 0.01514725 0.05901445
  0.04065083 0.02534   ]
 [0.02911081 0.02433969 0.02267884 0.01534896 0.01330147 0.0199998
  0.02449488 0.02735059 0.02819512 0.01788964 0.02262069 0.02305668
  0.02550548 0.00806154 0.00827519 0.03037929 0.02865183 0.03664265
  0.03993794 0.04389245 0.04202878 0.02661772 0.02310364 0.04492398
  0.04670046 0.04716103]
 [0.03027375 0.02037352 0.01921893 0.01594778 0.0128558  0.0180364
  0.01844946 0.02092138 0.02078709 0.01716007 0.02421847 0.02222617
  0.02117624 0.00883691 0.00806824 0.02347907 0.02192307 0.02352624
  0.02777728 0.02655566 0.02695623 0.02584564 0.01461563 0.02739717
  0.0321921  0.02606101]
 [0.03048117 0.02164209 0.02437693 0.02254438 0.01772958 0.02590382
  0.02177596 0.02896502 0.02509676 0.02626162 0.02699718 0.0355514
  0.03043807 0.01372871 0.00959698 0.01909532 0.02114339 0.02344767
  0.02272739 0.02188804 0.02184031 0.02715865 0.01446118 0.01547132
  0.02154341 0.0220779 ]
 [0.03056927 0.02574375 0.02676879 0.02617815 0.0190483  0.02885308
  0.02656031 0.03600294 0.02586067 0.03038797 0.03475801 0.04074974
  0.03733945 0.01486379 0.01030523 0.02157395 0.02160892 0.02584781
  0.02295365 0.02242006 0.02231098 0.0279745  0.01560221 0.01419127
  0.01652661 0.01698469]
 [0.03043635 0.02392895 0.0238324  0.02370256 0.01871919 0.02617562
  0.02423496 0.03128894 0.02593278 0.02852383 0.0321456  0.03613017
  0.03567762 0.01401424 0.01051107 0.02502486 0.02370893 0.02870553
  0.02522682 0.02451643 0.02425726 0.02816085 0.01372699 0.01722827
  0.01804383 0.01548758]
 [0.03033471 0.01863716 0.01745784 0.01452421 0.01115198 0.01626924
  0.01851096 0.02248288 0.02060279 0.01730155 0.0234398  0.02231322
  0.02497518 0.00809334 0.00736842 0.02786905 0.02694556 0.02870965
  0.02716639 0.02567295 0.03002876 0.02666686 0.01215227 0.02770403
  0.02771863 0.01738961]
 [0.03042235 0.01818934 0.01616853 0.01400024 0.01006181 0.01433993
  0.01826416 0.02008363 0.01924592 0.01539302 0.02202067 0.01920233
  0.02275446 0.00722672 0.00671607 0.02887735 0.02749247 0.03151798
  0.02940682 0.02899078 0.03536248 0.02250895 0.01136435 0.03013783
  0.03073768 0.01861333]
 [0.03055659 0.01858439 0.01645355 0.01460859 0.0114171  0.01544279
  0.01753523 0.02069032 0.02006592 0.01747076 0.02398476 0.02178915
  0.02311223 0.00819813 0.00731496 0.02621894 0.02922328 0.02866587
  0.03042402 0.0268279  0.03006009 0.02398717 0.01139681 0.02128996
  0.02096228 0.01610185]
 [0.03057568 0.02105237 0.0185874  0.01559938 0.01167421 0.01684232
  0.02094126 0.02335626 0.02406308 0.01834735 0.02831293 0.02273671
  0.02551289 0.00857315 0.00748354 0.02784712 0.02797357 0.03036898
  0.03104936 0.02930978 0.03286332 0.02460694 0.01189542 0.0232247
  0.02180931 0.01671543]
 [0.03062774 0.01574204 0.01417419 0.01039641 0.00882422 0.01198956
  0.01671775 0.017265   0.0189254  0.01279516 0.03248156 0.0165267
  0.02020666 0.00627886 0.00540559 0.0264975  0.03326593 0.02826816
  0.03518989 0.03034628 0.0329021  0.022306   0.01091164 0.03110216
  0.02289276 0.01693304]
 [0.0289509  0.02458641 0.02178855 0.01366136 0.01270725 0.01682574
  0.02688336 0.02648739 0.03017434 0.01743193 0.03337146 0.02250496
  0.02804799 0.00790376 0.0080048  0.0291139  0.04694006 0.04701844
  0.0701694  0.06107443 0.05419883 0.02745956 0.02578077 0.045253
  0.041198   0.05148296]
 [0.03063721 0.01962264 0.01926243 0.01656702 0.01298036 0.0187228
  0.01781565 0.02249713 0.02447575 0.01930577 0.02333531 0.02379779
  0.02280526 0.01044945 0.00840495 0.01812603 0.02347078 0.02120243
  0.02856245 0.02596181 0.02711012 0.02455344 0.01300007 0.01767636
  0.01920096 0.02082388]
 [0.02943023 0.02528666 0.02545998 0.04114196 0.04325036 0.03541311
  0.01977366 0.02212457 0.02816975 0.04128293 0.02935003 0.02987016
  0.02724353 0.07284709 0.08801512 0.02138216 0.02658174 0.02401039
  0.023941   0.02334329 0.02177236 0.0307191  0.02935605 0.00941478
  0.01036133 0.02784184]
 [0.02922489 0.02683049 0.02549823 0.04616119 0.08927643 0.03598803
  0.01872824 0.02102521 0.027502   0.0485356  0.03481644 0.03051187
  0.02319797 0.07299957 0.09237375 0.02634864 0.03661235 0.03255586
  0.02831789 0.02555501 0.02532053 0.02816521 0.02915516 0.00793201
  0.00758991 0.02422577]
 [0.02894546 0.02482601 0.02314387 0.03829482 0.08676925 0.02505065
  0.01587649 0.02053355 0.02397894 0.04352433 0.03496251 0.03300105
  0.02326148 0.03320405 0.0441808  0.02397064 0.05934414 0.04995585
  0.0395379  0.03096402 0.03923797 0.02556738 0.02648139 0.01362132
  0.01423541 0.02833491]
 [0.0291856  0.03016344 0.02723532 0.03909371 0.05254653 0.02895627
  0.02104129 0.02288801 0.02968822 0.03847146 0.03254111 0.02769037
  0.02531178 0.03289378 0.03646125 0.02042395 0.03948128 0.03297715
  0.03071575 0.02974828 0.02970143 0.04463816 0.03866612 0.01101969
  0.01158157 0.02787489]]

-* TASK 10/20 | SAMPLE 92/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 457/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill's current location in the provided context sentences. However, we can look back at the previous context sentences. According to context sentence 2, Bill went to the cinema, but there is no information about him moving to the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' current', ' location', ' in', ' the', ' provided', ' context', ' sentences', '.', ' However', ',', ' we', ' can', ' look', ' back', ' at', ' the', ' previous', ' context', ' sentences', '.', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' him', ' moving', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 32), x_tokens=32, y_tokens=59, max_supp_attn=0.0508, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 32)
DEBUG result.interpretability.attn_scores 1888 
 [[0.0155653  0.02043356 0.02175257 ... 0.02321239 0.00649786 0.00703469]
 [0.01603462 0.01984272 0.01891287 ... 0.03111556 0.00996671 0.0123667 ]
 [0.0163903  0.01818665 0.01988833 ... 0.03490827 0.01256969 0.01282689]
 ...
 [0.01645243 0.0202497  0.0163553  ... 0.00990167 0.00435997 0.00537751]
 [0.01685193 0.01642327 0.01237604 ... 0.00762017 0.00738494 0.00932419]
 [0.01684463 0.01707366 0.01281982 ... 0.00661616 0.00609473 0.00802353]]

-* TASK 10/20 | SAMPLE 92/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 458/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 7, Bill is either in the school or the kitchen, but we don't have specific information about his exact location. Therefore, we can't be certain about his location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' we', ' don', "'t", ' have', ' specific', ' information', ' about', ' his', ' exact', ' location', '.', ' Therefore', ',', ' we', ' can', "'t", ' be', ' certain', ' about', ' his', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01963086 0.0262644  0.03096106 ... 0.0159839  0.01241534 0.02795416]
 [0.01980388 0.01995428 0.02582054 ... 0.01910701 0.01743316 0.0329357 ]
 [0.02049795 0.02680075 0.03434481 ... 0.01474641 0.01289511 0.02666872]
 ...
 [0.02054764 0.0284978  0.02753296 ... 0.01471656 0.01091502 0.02978579]
 [0.02097182 0.02192367 0.02002447 ... 0.02187295 0.01841543 0.02431774]
 [0.02109751 0.02171793 0.02010884 ... 0.01910887 0.01308295 0.02298853]]

-* TASK 10/20 | SAMPLE 92/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 459/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 11, Julie is either in the kitchen or the bedroom, but we don't have specific information about her exact location. Therefore, we can't be certain about her location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' we', ' don', "'t", ' have', ' specific', ' information', ' about', ' her', ' exact', ' location', '.', ' Therefore', ',', ' we', ' can', "'t", ' be', ' certain', ' about', ' her', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 44), x_tokens=44, y_tokens=47, max_supp_attn=0.0638, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 44)
DEBUG result.interpretability.attn_scores 2068 
 [[0.01976127 0.02735321 0.02643103 ... 0.01350762 0.02270064 0.0207052 ]
 [0.02002841 0.02456947 0.02519559 ... 0.01965261 0.02454829 0.03731138]
 [0.02056486 0.02788515 0.0299103  ... 0.01778993 0.03879882 0.02822848]
 ...
 [0.02080309 0.0276645  0.02760942 ... 0.00847047 0.01379123 0.01036169]
 [0.02120644 0.01981182 0.01857007 ... 0.00988785 0.0109406  0.00869299]
 [0.02109921 0.02325512 0.02136932 ... 0.00891457 0.01201144 0.00964552]]

-* TASK 10/20 | SAMPLE 92/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 460/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no new information about Julie's location in the provided context sentences. We can look back at the previous context sentences. According to context sentence 11, Julie is either in the kitchen or the bedroom, but we don't have specific information about her exact location.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' provided', ' context', ' sentences', '.', ' We', ' can', ' look', ' back', ' at', ' the', ' previous', ' context', ' sentences', '.', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' we', ' don', "'t", ' have', ' specific', ' information', ' about', ' her', ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 50), x_tokens=50, y_tokens=61, max_supp_attn=0.1148, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 50)
DEBUG result.interpretability.attn_scores 3050 
 [[0.01516487 0.02076444 0.02070758 ... 0.03145271 0.01859906 0.01207065]
 [0.01544824 0.02122108 0.02014397 ... 0.0120142  0.0187357  0.01599626]
 [0.01585043 0.02039186 0.02270226 ... 0.02701427 0.01354518 0.01034627]
 ...
 [0.01621698 0.01934683 0.01728592 ... 0.04321882 0.01328262 0.00908231]
 [0.01650229 0.0159391  0.01277503 ... 0.02511782 0.01084633 0.01154007]
 [0.01643104 0.01795307 0.01403775 ... 0.03501426 0.01303434 0.00971264]]
Model's predictions for the sample 92:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Mary    |
|          |                 |  moved to the school, which implies that   |
|          |                 |      she is currently in the school.       |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    There is no information about Bill's    |
|          |                 |  current location in the provided context  |
|          |                 |  sentences. However, we can look back at   |
|          |                 |      the previous context sentences.       |
|          |                 |   According to context sentence 2, Bill    |
|          |                 |    went to the cinema, but there is no     |
|          |                 |    information about him moving to the     |
|          |                 |                  school.                   |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to context sentence 7, Bill is  |
|          |                 |  either in the school or the kitchen, but  |
|          |                 |  we don't have specific information about  |
|          |                 |  his exact location. Therefore, we can't   |
|          |                 |       be certain about his location.       |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to context sentence 11, Julie   |
|          |                 |  is either in the kitchen or the bedroom,  |
|          |                 |   but we don't have specific information   |
|          |                 |  about her exact location. Therefore, we   |
|          |                 |    can't be certain about her location.    |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |     There is no new information about      |
|          |                 |  Julie's location in the provided context  |
|          |                 |     sentences. We can look back at the     |
|          |                 |  previous context sentences. According to  |
|          |                 |  context sentence 11, Julie is either in   |
|          |                 |  the kitchen or the bedroom, but we don't  |
|          |                 |    have specific information about her     |
|          |                 |              exact location.               |
+----------+-----------------+--------------------------------------------+

Metrics for sample 92:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.08 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 93/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 461/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, "Bill is in the kitchen", which explicitly states Bill's location as the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' "', 'Bill', ' is', ' in', ' the', ' kitchen', '",', ' which', ' explicitly', ' states', ' Bill', "'s", ' location', ' as', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02643112 0.04101218 0.04988743 0.06933069 0.07839306 0.06914974
  0.050605   0.05579665 0.05032188 0.06015819 0.03828484 0.05155108
  0.05856621 0.09553508 0.06367071 0.02834718 0.02859607 0.03124296
  0.02847771 0.03122973 0.0247623  0.03650071 0.03906379 0.01901734
  0.01377961 0.02424109]
 [0.0267883  0.05066644 0.04656195 0.06493015 0.05735528 0.05328496
  0.04075094 0.03823913 0.03929569 0.04422697 0.03076592 0.02756945
  0.03049236 0.0980725  0.10027781 0.02987003 0.02446701 0.02290386
  0.0236201  0.02450173 0.02078113 0.03817113 0.04124947 0.01488386
  0.00902851 0.02055645]
 [0.02892194 0.05303709 0.03184721 0.04549465 0.03337123 0.03111279
  0.02775517 0.01915477 0.02025301 0.02931706 0.02218741 0.01428703
  0.01630587 0.02328258 0.03118051 0.02078781 0.01300865 0.01349319
  0.01731724 0.01801858 0.01609766 0.04061829 0.04742461 0.00880782
  0.00534718 0.01086129]
 [0.0270143  0.03536437 0.03467207 0.02227439 0.01596784 0.02571378
  0.02908356 0.0242374  0.03106135 0.02327197 0.02232797 0.02382508
  0.02354974 0.01147013 0.01130707 0.03623601 0.03045493 0.0309038
  0.03253102 0.03318316 0.0303237  0.03302488 0.05216083 0.05350098
  0.06675632 0.05921802]
 [0.02736981 0.03854695 0.04160648 0.06025284 0.05526759 0.04347131
  0.03112174 0.02632455 0.03164366 0.04059598 0.02794875 0.02253156
  0.02341397 0.08686401 0.09027015 0.03376346 0.02552922 0.02128614
  0.02245139 0.02465581 0.02281453 0.03741897 0.05924866 0.01650904
  0.00855948 0.02561178]
 [0.02789514 0.02460605 0.02547306 0.04667033 0.04136733 0.03932706
  0.02321736 0.02041727 0.02679692 0.03817269 0.02459645 0.02556132
  0.02524694 0.09929423 0.12157784 0.03400259 0.02928285 0.02580746
  0.02534622 0.02631362 0.02190207 0.03156674 0.03511069 0.01150952
  0.00681013 0.01642355]
 [0.02830171 0.02764993 0.03280282 0.04854684 0.04505254 0.04983171
  0.03062416 0.02819736 0.03501243 0.04488333 0.02867388 0.04042399
  0.03818705 0.07877357 0.07480465 0.02850078 0.02640758 0.0253467
  0.02421686 0.02586095 0.02052864 0.02842049 0.03275566 0.01548523
  0.00960049 0.01663194]
 [0.02733898 0.03952352 0.04676883 0.04044534 0.04179503 0.04768536
  0.03705115 0.03864737 0.0401631  0.04195859 0.03045376 0.04572443
  0.04079438 0.04960466 0.04490823 0.03732286 0.03329058 0.03162523
  0.02861517 0.03116762 0.02680112 0.03309237 0.04906927 0.03204773
  0.02442468 0.03338977]
 [0.02843733 0.03756759 0.04581837 0.04446372 0.04007469 0.05372148
  0.04092252 0.0430319  0.04691007 0.04644022 0.03045861 0.04682022
  0.04440517 0.03733259 0.02453191 0.0267436  0.02591517 0.02681274
  0.02587128 0.02873346 0.02252685 0.03232907 0.03442419 0.01971671
  0.01497888 0.02368142]
 [0.02776113 0.05098728 0.05289856 0.02831148 0.02296879 0.03660193
  0.04241616 0.04015379 0.04421774 0.02971219 0.02523337 0.03553934
  0.03655773 0.01699662 0.01441057 0.04256834 0.03310457 0.02992252
  0.02975801 0.03249519 0.03027768 0.03198443 0.06173099 0.04205865
  0.03609323 0.03730407]
 [0.02824476 0.06367421 0.06163007 0.02631308 0.02139561 0.03079821
  0.0431115  0.0366878  0.04570108 0.02559811 0.02227175 0.02788528
  0.0288832  0.01423099 0.01367289 0.04814455 0.03384707 0.02944102
  0.03093805 0.03626289 0.03070074 0.02929256 0.06640469 0.03970961
  0.02814735 0.0286164 ]
 [0.02842925 0.03312751 0.03658623 0.02012618 0.01755266 0.02294005
  0.03288268 0.02782382 0.03440592 0.02105346 0.01838529 0.0226914
  0.02209227 0.0122726  0.01222857 0.03918455 0.02953974 0.02515557
  0.02770791 0.02984961 0.02776469 0.02795858 0.04870897 0.04681466
  0.04542129 0.04085432]
 [0.02864312 0.01324456 0.01450713 0.01077408 0.00984346 0.01302831
  0.01459054 0.01420176 0.01788344 0.01254439 0.01168554 0.01357463
  0.01315013 0.00624669 0.00668024 0.0182482  0.01765643 0.01750048
  0.02165841 0.02305234 0.02468581 0.01951636 0.02661461 0.05194188
  0.0680005  0.06147797]
 [0.02852326 0.01976036 0.02047783 0.01462741 0.01380287 0.01840965
  0.02185556 0.02020702 0.02066857 0.01644055 0.01813324 0.01974457
  0.01944569 0.00840411 0.00910048 0.03189443 0.02538375 0.02506407
  0.02747072 0.02837096 0.02884773 0.02625998 0.02489494 0.04787485
  0.06688885 0.04665688]
 [0.02875366 0.02192435 0.02314735 0.01901017 0.0170805  0.02409496
  0.02695508 0.0284321  0.02440044 0.02307112 0.02314909 0.02984727
  0.02971589 0.01134382 0.00995909 0.03116261 0.02882014 0.02927388
  0.02830844 0.02799891 0.0291811  0.02783605 0.02045709 0.04174461
  0.04096261 0.02568961]
 [0.02912451 0.02065146 0.01972248 0.01511368 0.01565024 0.01764266
  0.02719709 0.02300961 0.02059595 0.01712973 0.02827932 0.02335436
  0.02328455 0.00840941 0.0095449  0.03123245 0.02714296 0.02594166
  0.02599419 0.02895681 0.02985563 0.02528553 0.0209839  0.04620587
  0.05798684 0.02467743]
 [0.02846094 0.01597039 0.01366784 0.01168568 0.01028281 0.01350106
  0.02349911 0.02319842 0.01707789 0.01338716 0.02028053 0.0164171
  0.02160644 0.00577009 0.00615621 0.03787376 0.0298251  0.03524375
  0.03306362 0.03711748 0.04880033 0.02009391 0.01479966 0.05913083
  0.0942575  0.03924463]
 [0.02907328 0.01595568 0.01509095 0.0116971  0.01210266 0.01479735
  0.02089562 0.0190272  0.01690306 0.01410128 0.02089321 0.019532
  0.01997607 0.00618353 0.00645652 0.02375128 0.03029647 0.02713522
  0.03405498 0.03075556 0.04028021 0.01952438 0.01379889 0.04815549
  0.07011648 0.03436494]
 [0.02899363 0.01411604 0.01221234 0.0094689  0.00907911 0.01170463
  0.01832103 0.01715846 0.0154399  0.01159791 0.025467   0.01660769
  0.01859709 0.00510562 0.00538205 0.02707105 0.03466384 0.03297414
  0.03644308 0.0324707  0.03865497 0.02086738 0.01215138 0.04355391
  0.04266898 0.05270695]
 [0.02847119 0.01805733 0.01629024 0.01158157 0.01040667 0.01457821
  0.01897755 0.01851995 0.02107067 0.0131338  0.01865189 0.01587881
  0.01785987 0.00613789 0.00609494 0.02513319 0.02212192 0.02526618
  0.02987284 0.03043905 0.03951159 0.02351961 0.01877208 0.06090598
  0.06195046 0.06095572]
 [0.02957667 0.01675571 0.01536408 0.01287786 0.01133406 0.0154212
  0.01801219 0.01820459 0.01722986 0.01408815 0.01924712 0.01752003
  0.01835206 0.00700616 0.00681266 0.01895522 0.02176321 0.02630603
  0.02646534 0.025296   0.02586091 0.02170848 0.0127123  0.02384091
  0.02546076 0.03398431]
 [0.02921116 0.02477768 0.02776048 0.02953159 0.02217691 0.02917674
  0.02702371 0.03303709 0.02907773 0.03407831 0.02732055 0.03875806
  0.03178541 0.01692391 0.0127387  0.02012381 0.02290248 0.02530929
  0.02628314 0.0252536  0.02380551 0.03016692 0.01784063 0.01717018
  0.01798693 0.01915897]
 [0.02949289 0.027989   0.03153285 0.03137129 0.02233465 0.03382996
  0.03039388 0.04000274 0.03267648 0.03826458 0.02781981 0.04704927
  0.03872697 0.01727897 0.01167732 0.01992618 0.02226583 0.02518404
  0.02366108 0.02248381 0.02028394 0.0279802  0.01769913 0.01388158
  0.01256007 0.01512389]
 [0.02938795 0.03164025 0.03589492 0.03293674 0.02264907 0.03811913
  0.03482062 0.04387696 0.03558398 0.04090578 0.03133013 0.05737717
  0.04557943 0.01733629 0.01208406 0.02315636 0.02435683 0.02858702
  0.0260012  0.02578033 0.02179106 0.02864456 0.01819582 0.0144269
  0.0116368  0.01344913]
 [0.02968949 0.02422285 0.02512556 0.02093493 0.01576987 0.02269351
  0.02934815 0.03173479 0.02603978 0.02438253 0.02628229 0.02924252
  0.03050084 0.01089376 0.00924016 0.0257605  0.0224961  0.02464683
  0.02498828 0.02509475 0.02432029 0.02761083 0.01400802 0.01852214
  0.01430367 0.01158809]
 [0.02936094 0.02167075 0.01935511 0.01550091 0.01162837 0.01624916
  0.03071988 0.03085502 0.02329366 0.01783073 0.02703166 0.02156374
  0.02896488 0.00766798 0.00736572 0.03027238 0.02519217 0.02794693
  0.02791276 0.0276179  0.03337347 0.02722819 0.0128629  0.02961924
  0.02533043 0.01726604]
 [0.0290379  0.02971655 0.02697052 0.01933647 0.01454817 0.02006382
  0.0389313  0.04358303 0.02900646 0.02447967 0.05075174 0.02991043
  0.04090257 0.00991722 0.00916195 0.03415366 0.03234258 0.03729253
  0.03463448 0.03435366 0.03609562 0.02828781 0.01547537 0.02805346
  0.02128794 0.01945752]
 [0.02959889 0.02219616 0.02265777 0.01729109 0.01330212 0.0187578
  0.02943213 0.0322951  0.02819419 0.02109153 0.04346937 0.02816651
  0.0325046  0.0093297  0.00777165 0.02676207 0.03044657 0.02956465
  0.03212132 0.02973495 0.03067231 0.02453468 0.01329139 0.01992311
  0.01633423 0.01807407]
 [0.02992127 0.01808115 0.0165862  0.01252617 0.01135947 0.0151782
  0.02114667 0.0220135  0.02156959 0.01607824 0.03830907 0.02217453
  0.02256536 0.00775025 0.00648574 0.02201688 0.02651467 0.02402748
  0.02826963 0.02656803 0.0279857  0.02550519 0.01121369 0.01964915
  0.01375223 0.02476334]
 [0.0288388  0.02387818 0.02087539 0.01409924 0.01394791 0.01742793
  0.03539677 0.03102445 0.0259564  0.01790424 0.08004703 0.03041521
  0.03169419 0.00842746 0.00826001 0.03170541 0.04184272 0.04154789
  0.03989477 0.03551282 0.03971635 0.02702263 0.01601753 0.0292896
  0.01698479 0.04523941]
 [0.02958933 0.01988856 0.01986088 0.01849343 0.01414376 0.01900699
  0.02181222 0.02580506 0.02450803 0.02086574 0.02536618 0.02687572
  0.02615176 0.0131016  0.01040372 0.01840484 0.02288762 0.0243764
  0.02669445 0.02449934 0.02456871 0.02461347 0.01233154 0.01524209
  0.01540219 0.02327996]
 [0.02854164 0.02546212 0.02482003 0.0396607  0.03987885 0.03663551
  0.02240281 0.02313004 0.02881818 0.04123003 0.02669042 0.02830987
  0.0286562  0.06778374 0.0782524  0.02302478 0.02509344 0.02449352
  0.0249651  0.02515865 0.02212071 0.03020787 0.02886451 0.01140372
  0.00839684 0.01804813]
 [0.02835586 0.02602606 0.02451892 0.04218727 0.08119217 0.03350832
  0.02007837 0.02053872 0.0268803  0.04458009 0.02951438 0.02702512
  0.02302573 0.06440458 0.08335409 0.02824343 0.03651064 0.03626285
  0.03065449 0.02865522 0.02598275 0.02726243 0.02841953 0.00964231
  0.00631673 0.01624749]
 [0.02805246 0.02357274 0.02171541 0.03564106 0.08335821 0.02403752
  0.01674251 0.01961507 0.0232829  0.04044633 0.029907   0.03016859
  0.02294193 0.03052121 0.04133128 0.02419159 0.05696434 0.05476577
  0.04049477 0.03205386 0.03905028 0.02426981 0.02556439 0.01654431
  0.01255569 0.02223121]
 [0.02836739 0.02867904 0.02529268 0.03649298 0.05356632 0.028499
  0.02190523 0.02181754 0.02805971 0.03697943 0.02878537 0.02607654
  0.02551743 0.03032643 0.03284513 0.02146422 0.03906681 0.03734824
  0.03324205 0.03050295 0.02927384 0.04167546 0.03567899 0.01321674
  0.00991126 0.01892421]]

-* TASK 10/20 | SAMPLE 93/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 462/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 5, "Julie is either in the cinema or the school", which provides two possible locations for Julie, but it does not specify her exact location. Therefore, we can only conclude that Julie might be in the school, but we are not certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' "', 'Jul', 'ie', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' school', '",', ' which', ' provides', ' two', ' possible', ' locations', ' for', ' Julie', ',', ' but', ' it', ' does', ' not', ' specify', ' her', ' exact', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' are', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(63, 32), x_tokens=32, y_tokens=63, max_supp_attn=0.1429, attn_on_target=0.0159)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (63, 32)
DEBUG result.interpretability.attn_scores 2016 
 [[0.01447603 0.02382492 0.02620371 ... 0.00842877 0.00599915 0.03486306]
 [0.01495357 0.02201398 0.02329884 ... 0.01173549 0.0098705  0.04340602]
 [0.01518676 0.02162587 0.02508041 ... 0.0203614  0.01408425 0.03410017]
 ...
 [0.0152472  0.02205113 0.02093759 ... 0.00576582 0.0042546  0.05138073]
 [0.01551196 0.01775612 0.01596275 ... 0.00614449 0.00503787 0.02733483]
 [0.01556481 0.01844745 0.0167234  ... 0.00520956 0.00475566 0.02526676]]

-* TASK 10/20 | SAMPLE 93/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 463/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, "Julie went back to the park", which explicitly states that Julie returned to the park, implying that she is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' "', 'Jul', 'ie', ' went', ' back', ' to', ' the', ' park', '",', ' which', ' explicitly', ' states', ' that', ' Julie', ' returned', ' to', ' the', ' park', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 38), x_tokens=38, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 38)
DEBUG result.interpretability.attn_scores 1596 
 [[0.02208138 0.03136937 0.03197925 ... 0.01444089 0.01658554 0.02056647]
 [0.02253005 0.02729088 0.02840555 ... 0.01963181 0.01833219 0.0320967 ]
 [0.02312242 0.03419373 0.0378933  ... 0.01056286 0.01266584 0.01372271]
 ...
 [0.02323605 0.03164284 0.03041765 ... 0.01124919 0.01331482 0.01277914]
 [0.02336916 0.02534573 0.02284998 ... 0.01818974 0.01651994 0.01611018]
 [0.0234372  0.02891404 0.0252535  ... 0.01517291 0.01463038 0.01802586]]

-* TASK 10/20 | SAMPLE 93/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 464/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the context sentences that suggests Julie is in the school. In fact, context sentence 10 states that Julie went to the kitchen, which implies that she is currently in the kitchen, not in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Julie', ' is', ' in', ' the', ' school', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '10', ' states', ' that', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 44), x_tokens=44, y_tokens=53, max_supp_attn=0.0189, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 44)
DEBUG result.interpretability.attn_scores 2332 
 [[0.01734969 0.02296608 0.02041424 ... 0.02485137 0.01045733 0.01166506]
 [0.01780593 0.01676287 0.01682513 ... 0.03978122 0.01810748 0.014689  ]
 [0.01814265 0.02352149 0.02325364 ... 0.04426692 0.01673128 0.01664502]
 ...
 [0.01828416 0.02219363 0.0215689  ... 0.0098521  0.00857903 0.00913289]
 [0.01857937 0.01716043 0.01694839 ... 0.0076014  0.01095715 0.01195147]
 [0.01860842 0.01675991 0.01685571 ... 0.00645822 0.00841471 0.00987778]]

-* TASK 10/20 | SAMPLE 93/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 465/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information in the context sentences that suggests Bill is in the bedroom. In fact, context sentence 13 states that Bill is either in the kitchen or the office, which implies that he is not in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Bill', ' is', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '13', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' which', ' implies', ' that', ' he', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01776486 0.02871072 0.02958533 ... 0.01180797 0.02975238 0.04913451]
 [0.01821605 0.02118295 0.02318116 ... 0.01138559 0.0175497  0.02473471]
 [0.0185676  0.02922465 0.03147623 ... 0.01495577 0.03325272 0.04361521]
 ...
 [0.01870305 0.03111651 0.02598239 ... 0.01329236 0.02820618 0.11542641]
 [0.01904851 0.02324727 0.01936422 ... 0.01689796 0.02734752 0.08275938]
 [0.01899868 0.02491149 0.01934186 ... 0.01175109 0.02123679 0.08738112]]
Model's predictions for the sample 93:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 2, "Bill   |
|          |                 |    is in the kitchen", which explicitly    |
|          |                 |   states Bill's location as the kitchen.   |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  According to context sentence 5, "Julie   |
|          |                 |  is either in the cinema or the school",   |
|          |                 |   which provides two possible locations    |
|          |                 |   for Julie, but it does not specify her   |
|          |                 |   exact location. Therefore, we can only   |
|          |                 |    conclude that Julie might be in the     |
|          |                 |      school, but we are not certain.       |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to context sentence 8, "Julie   |
|          |                 |  went back to the park", which explicitly  |
|          |                 |  states that Julie returned to the park,   |
|          |                 |   implying that she is currently in the    |
|          |                 |                   park.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information in the context   |
|          |                 |  sentences that suggests Julie is in the   |
|          |                 |    school. In fact, context sentence 10    |
|          |                 |   states that Julie went to the kitchen,   |
|          |                 |   which implies that she is currently in   |
|          |                 |      the kitchen, not in the school.       |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   There is no information in the context   |
|          |                 |   sentences that suggests Bill is in the   |
|          |                 |   bedroom. In fact, context sentence 13    |
|          |                 |     states that Bill is either in the      |
|          |                 |    kitchen or the office, which implies    |
|          |                 |       that he is not in the bedroom.       |
+----------+-----------------+--------------------------------------------+

Metrics for sample 93:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.06 ± 0.07 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 94/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 466/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to sentence 2, Bill journeyed to the cinema, which implies that Bill is now in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.1471, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02733391 0.042613   0.05125423 0.07074751 0.0776657  0.07527932
  0.05685757 0.06407051 0.04998604 0.06305529 0.04549075 0.05839575
  0.06241973 0.09450973 0.06839205 0.02345532 0.03189027 0.0330795
  0.02956862 0.03366635 0.02661439 0.037566   0.04636593 0.01926312
  0.01190338 0.02257991]
 [0.02766697 0.05522288 0.05153666 0.07117403 0.06311072 0.06160549
  0.04636567 0.04387249 0.04104838 0.0501491  0.0373788  0.03341247
  0.03416849 0.10838738 0.10344425 0.02467065 0.02737968 0.02378765
  0.02348536 0.02578754 0.02176271 0.03840285 0.0488501  0.01045312
  0.00831628 0.02076913]
 [0.02985194 0.06011273 0.03545904 0.05131465 0.03327983 0.03574041
  0.03302464 0.02376026 0.02181772 0.03299674 0.02534549 0.01737841
  0.01796146 0.02600217 0.03345629 0.01646787 0.01475545 0.01385273
  0.01743241 0.01883827 0.01632669 0.04319267 0.05671266 0.00587838
  0.00491717 0.01119355]
 [0.02852502 0.02387502 0.02243346 0.02395537 0.01898432 0.02425482
  0.02676496 0.02283869 0.02335629 0.02566802 0.02533302 0.02492967
  0.02257083 0.01370987 0.01728529 0.01749816 0.02657273 0.0259956
  0.02984806 0.02961276 0.03168282 0.02748032 0.03472527 0.06828436
  0.02882347 0.04722453]
 [0.02826237 0.04468942 0.04779885 0.06562513 0.05988179 0.04775845
  0.03672482 0.03168344 0.03401866 0.04563317 0.03324429 0.02707572
  0.02665823 0.09129281 0.09557924 0.02863019 0.02896875 0.02144223
  0.02270159 0.02497694 0.02352217 0.03881009 0.06844305 0.00915996
  0.00743008 0.02673078]
 [0.02884595 0.02860287 0.02825675 0.04886009 0.04594619 0.04091956
  0.02656348 0.02459373 0.0288518  0.04165677 0.02993121 0.03053254
  0.02859058 0.10577281 0.12486021 0.02860247 0.03279069 0.02586105
  0.02561232 0.02601413 0.02277697 0.03293419 0.03887752 0.00773024
  0.00599571 0.01732988]
 [0.02925331 0.03228566 0.03637092 0.05238783 0.05014538 0.05205974
  0.03525041 0.03370857 0.037026   0.04926837 0.03510027 0.04796264
  0.0422667  0.08311079 0.07835587 0.02434398 0.02989841 0.02520585
  0.02417652 0.02512145 0.02156315 0.02981155 0.03568624 0.01062154
  0.00821372 0.0169347 ]
 [0.02809608 0.04265559 0.04732179 0.0411428  0.04471532 0.04673212
  0.04091193 0.04278284 0.04091313 0.04249375 0.035812   0.05069527
  0.04363466 0.04924234 0.04542692 0.03571349 0.03737742 0.03127604
  0.02905052 0.03047986 0.02912407 0.03492426 0.05078135 0.02374341
  0.02945836 0.03607632]
 [0.02929519 0.04271872 0.04994977 0.04547131 0.0432464  0.05436081
  0.04580948 0.04933236 0.04963266 0.04804643 0.03629687 0.05233744
  0.04912891 0.03735711 0.02503678 0.02373256 0.02937188 0.02680582
  0.02644238 0.02846377 0.02427597 0.03572601 0.0395195  0.01855115
  0.01406306 0.02400601]
 [0.02851478 0.05387282 0.05547158 0.02813253 0.02419889 0.03570082
  0.04690401 0.04466307 0.04468976 0.02945487 0.02999478 0.03788676
  0.03973696 0.0160494  0.01421476 0.04079961 0.03611602 0.02958999
  0.0300068  0.03171984 0.03202318 0.0335046  0.06816658 0.03681806
  0.03742229 0.03877579]
 [0.02925167 0.04229279 0.04914224 0.02439565 0.02170556 0.02807312
  0.04855891 0.03706215 0.04232373 0.02495352 0.02529937 0.02794978
  0.02927987 0.01287814 0.01292211 0.03837067 0.03374074 0.02754208
  0.02958516 0.0324222  0.03035938 0.02873079 0.05784842 0.02776658
  0.0345722  0.0362825 ]
 [0.02957933 0.01660679 0.01917437 0.01187931 0.01065929 0.01627677
  0.01817457 0.01814158 0.02210566 0.01416313 0.01481291 0.0151432
  0.01589007 0.00627982 0.00672483 0.01964922 0.01954511 0.01759044
  0.02116107 0.0223584  0.02312413 0.0196202  0.03524098 0.03209272
  0.06029233 0.06409622]
 [0.0293096  0.02598491 0.02792297 0.01713515 0.01533458 0.02200125
  0.02806517 0.02494265 0.02508973 0.01836263 0.02318413 0.02197415
  0.02249778 0.00872827 0.00918399 0.03513129 0.02528924 0.02555184
  0.02598381 0.02799453 0.02757634 0.02804058 0.02874411 0.03662915
  0.05723755 0.05013686]
 [0.02943953 0.02509273 0.02526269 0.01845324 0.01584904 0.02499315
  0.02901383 0.02774677 0.0264916  0.02138832 0.0273124  0.02815779
  0.02825949 0.00975253 0.00875436 0.03934443 0.02733005 0.02865692
  0.02604775 0.02685862 0.0274359  0.02887813 0.02123909 0.03149036
  0.05781954 0.03355439]
 [0.02875518 0.02219487 0.01854574 0.01412886 0.01121211 0.01601747
  0.02435239 0.02219301 0.02148761 0.01536611 0.02379115 0.01934294
  0.02264506 0.00676665 0.00655656 0.05416608 0.02694901 0.03935694
  0.03326752 0.03744638 0.04296938 0.02700355 0.01576965 0.04335672
  0.10909759 0.04561897]
 [0.02992841 0.02330382 0.02289975 0.01779557 0.01607694 0.02403115
  0.02979353 0.02745813 0.02566996 0.02054258 0.02620056 0.02593551
  0.02648738 0.00913808 0.00781362 0.03661096 0.02173413 0.03385378
  0.02671962 0.0384229  0.0290997  0.02354355 0.01782584 0.0282139
  0.06984349 0.02621962]
 [0.02981268 0.01918749 0.01711373 0.01264842 0.01049457 0.01529795
  0.0214508  0.020227   0.0209321  0.01464432 0.0253567  0.02048768
  0.02173426 0.00634803 0.00598563 0.04575591 0.02408392 0.03942672
  0.03246998 0.04304564 0.03285974 0.0225449  0.01313595 0.03214886
  0.06961017 0.03574986]
 [0.0296079  0.01800781 0.01602626 0.01101113 0.00906514 0.01339375
  0.02020621 0.01882552 0.01998249 0.01314679 0.0255175  0.01811551
  0.0201495  0.00551299 0.00556885 0.04369727 0.02623486 0.0371306
  0.03577425 0.03873335 0.03371099 0.02326471 0.01295851 0.04502925
  0.05287137 0.04801537]
 [0.02906754 0.02507828 0.02350684 0.01544695 0.01462381 0.01860754
  0.0275688  0.02599521 0.02619494 0.01768604 0.02830333 0.02256009
  0.02477772 0.00781787 0.00819165 0.02939313 0.02899696 0.02791857
  0.03293407 0.0293154  0.03430571 0.02649011 0.02088686 0.07738751
  0.03189386 0.0524421 ]
 [0.03016625 0.02245576 0.02153234 0.01651051 0.01284124 0.01860952
  0.02419498 0.02406397 0.02434807 0.01792081 0.02640124 0.02257494
  0.02375381 0.00818698 0.00768137 0.02597302 0.02311008 0.02783918
  0.03179314 0.02721367 0.02910114 0.02736776 0.0150672  0.03320923
  0.02323693 0.03391712]
 [0.03031447 0.02246564 0.02499186 0.02216811 0.01666022 0.02525344
  0.02633891 0.03127539 0.02726234 0.02608797 0.02763398 0.03551331
  0.03210299 0.01253653 0.00856504 0.01902275 0.02194691 0.02484441
  0.02551256 0.02450473 0.02345446 0.02945457 0.01540613 0.02658993
  0.01772671 0.02260091]
 [0.03043756 0.02839751 0.03014677 0.02728774 0.01960709 0.03064934
  0.03380329 0.04121907 0.03049653 0.03199644 0.03583817 0.04487792
  0.04218893 0.01460982 0.00944934 0.02245963 0.02331267 0.02835397
  0.02604334 0.02649942 0.02365114 0.02957161 0.0164967  0.02385747
  0.01637886 0.01517069]
 [0.03038569 0.02572707 0.02611411 0.02420853 0.0185195  0.02726948
  0.02979878 0.03455479 0.02982322 0.02961381 0.0333652  0.03902374
  0.03919732 0.01311248 0.00921747 0.02707229 0.02479909 0.0297705
  0.0278848  0.02786132 0.02608307 0.02879637 0.01440263 0.02139054
  0.0189167  0.01378993]
 [0.0301714  0.01988723 0.01935244 0.0142981  0.01087929 0.01648263
  0.02102474 0.02388545 0.02318469 0.01785665 0.02367523 0.02346451
  0.02535036 0.00755383 0.00624951 0.0322779  0.0260214  0.02919303
  0.02901359 0.02767993 0.03150512 0.02644209 0.01289704 0.03137363
  0.03347068 0.02078345]
 [0.03010527 0.02089882 0.01977484 0.01499979 0.01071457 0.01591751
  0.02340373 0.02470965 0.02299128 0.01754314 0.02526447 0.02203488
  0.02517951 0.00734479 0.00619644 0.03763115 0.02710027 0.03369709
  0.03161512 0.03025208 0.03753981 0.0240847  0.01237634 0.03679979
  0.0355111  0.02112184]
 [0.03025393 0.01991994 0.01903026 0.01488422 0.01166791 0.0161293
  0.02090301 0.02388198 0.02263209 0.01831451 0.02525076 0.02365702
  0.02400478 0.00793999 0.00645252 0.03027771 0.02961356 0.03015117
  0.03427617 0.02872009 0.03458552 0.02405079 0.01215903 0.03593234
  0.02551673 0.02015583]
 [0.03039072 0.02256148 0.02173609 0.01584596 0.01178975 0.01802559
  0.02526327 0.02685997 0.02774077 0.01895027 0.02854888 0.0252643
  0.02659107 0.00856709 0.00689604 0.0333991  0.02792319 0.0321786
  0.0322418  0.03144865 0.03321944 0.02509885 0.01352938 0.03286706
  0.0264179  0.01930867]
 [0.03046273 0.01760545 0.01746573 0.0110015  0.00908093 0.01314335
  0.02107826 0.01991285 0.02140472 0.01386712 0.030269   0.01842754
  0.02127592 0.00648885 0.00506279 0.03508122 0.02989092 0.03036929
  0.03852072 0.03244183 0.03413159 0.02353288 0.0111522  0.03700251
  0.02489095 0.0263356 ]
 [0.0295249  0.02131106 0.02014009 0.01201827 0.00923437 0.01479814
  0.02120734 0.02191016 0.02410376 0.01551047 0.02587024 0.01782029
  0.02337559 0.00686841 0.00556906 0.02594293 0.02556626 0.02371202
  0.03321737 0.0284822  0.03593047 0.0252646  0.01696921 0.07641269
  0.02976367 0.05227076]
 [0.03047901 0.02126923 0.02167149 0.016699   0.01211016 0.01900045
  0.02033423 0.02446505 0.02546346 0.02012117 0.02372758 0.0214244
  0.02422629 0.00968102 0.00743454 0.0186574  0.02292925 0.02334222
  0.03011428 0.02503463 0.02834125 0.02504291 0.01435345 0.03109472
  0.01481245 0.02402654]
 [0.02943397 0.02721631 0.02826834 0.04134643 0.04208096 0.03693993
  0.02414041 0.02561731 0.03062596 0.04393296 0.03133596 0.03099186
  0.03219961 0.06660315 0.08108249 0.02018887 0.02996401 0.02695249
  0.02681553 0.02624904 0.02453822 0.03087251 0.03331571 0.01010873
  0.00718874 0.01958358]
 [0.02924316 0.02895579 0.02887543 0.04765207 0.08929977 0.03766341
  0.02253483 0.02445926 0.02987848 0.05149061 0.03730401 0.03220895
  0.02765151 0.06785735 0.0880215  0.02498528 0.04237069 0.03639058
  0.03223132 0.02861839 0.02948879 0.02851237 0.03229692 0.00734174
  0.00577562 0.01671229]
 [0.02895849 0.02582671 0.02558488 0.03957293 0.08826971 0.02669347
  0.01898156 0.02368027 0.02646978 0.04674721 0.03781506 0.03517738
  0.02644379 0.03281997 0.04118736 0.02249638 0.07078403 0.05399983
  0.04304142 0.03250011 0.04397468 0.02635396 0.02787551 0.01802141
  0.01156339 0.02092377]
 [0.02927502 0.0311037  0.02986765 0.03980132 0.05104907 0.03032075
  0.02463153 0.02560687 0.03195657 0.04137097 0.03399466 0.02726565
  0.02760084 0.03117301 0.03318125 0.01850116 0.04564232 0.03528117
  0.03541102 0.03121552 0.03334197 0.04508498 0.03992489 0.01337984
  0.00904788 0.01956258]]

-* TASK 10/20 | SAMPLE 94/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 467/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Julie going to the park. According to sentence 5, Julie went to the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' going', ' to', ' the', ' park', '.', ' According', ' to', ' sentence', ' ', '5', ',', ' Julie', ' went', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.1667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03122673 0.04779273 0.04778862 0.07597198 0.06766778 0.0506007
  0.03753569 0.03847489 0.04838873 0.05886646 0.03872336 0.03409387
  0.0374314  0.10771129 0.10974604 0.03405724 0.0277313  0.02420734
  0.02067232 0.02087644 0.02072854 0.03589572 0.05273438 0.0115137
  0.01943673 0.03826739 0.04611477 0.0536837  0.11892221 0.06424114
  0.01087087 0.01441908]
 [0.03199117 0.04782771 0.04600315 0.08642866 0.09205663 0.07740565
  0.04384814 0.04480593 0.05021593 0.07602537 0.05115202 0.0551431
  0.05638961 0.14168642 0.1172578  0.03459102 0.02703692 0.02769427
  0.02055481 0.02283726 0.02184485 0.03978496 0.04000638 0.01170328
  0.02094372 0.03304132 0.04545726 0.0445794  0.08960702 0.07299706
  0.01826706 0.02663529]
 [0.03266583 0.04387042 0.04805198 0.07332738 0.06857655 0.05945748
  0.03854954 0.04004553 0.04662367 0.05779428 0.03836138 0.04539987
  0.04162134 0.11425275 0.08671085 0.03208466 0.02556013 0.02150066
  0.01789644 0.01934354 0.01822903 0.03594889 0.0377099  0.0124414
  0.02094372 0.02989838 0.03846384 0.03679328 0.06211518 0.07215496
  0.02367244 0.03210664]
 [0.03171739 0.04424882 0.04950612 0.04094152 0.03621437 0.04213537
  0.04099492 0.04665967 0.04340034 0.0379235  0.03344474 0.04174075
  0.03841958 0.03029828 0.02952363 0.03246633 0.0310066  0.02543453
  0.022889   0.02428711 0.02384088 0.03740096 0.04657137 0.0284096
  0.03443369 0.04330716 0.04662283 0.04144713 0.04152488 0.08089993
  0.04804301 0.0538626 ]
 [0.03320357 0.04239975 0.04511254 0.03306083 0.02762813 0.0449801
  0.04293583 0.04847657 0.04632075 0.03541635 0.03578357 0.05211819
  0.04254606 0.0227457  0.0220283  0.03310225 0.03299836 0.02609082
  0.0256383  0.02676171 0.02632577 0.03352206 0.0434457  0.03244661
  0.03264319 0.03770712 0.03936043 0.03141411 0.02874438 0.03293084
  0.03541742 0.04665376]
 [0.03370017 0.0447083  0.04708208 0.03581166 0.03061189 0.05189747
  0.04517811 0.04928322 0.05433829 0.04233991 0.03398596 0.05719922
  0.04799312 0.0276048  0.02281692 0.03109013 0.03000602 0.02426769
  0.0233543  0.02330177 0.02287887 0.03365789 0.04199463 0.0286431
  0.02970078 0.03647856 0.04088464 0.03021733 0.03004318 0.03253515
  0.03299282 0.04348578]
 [0.03297939 0.06656481 0.0582126  0.04076448 0.03513845 0.05610781
  0.05646977 0.06644393 0.05905289 0.04895336 0.04443952 0.07364437
  0.06502938 0.03090326 0.02647246 0.03966251 0.03570942 0.03141174
  0.02998546 0.02912651 0.02814099 0.03785735 0.05118416 0.03746778
  0.03439515 0.04005352 0.04892409 0.03718668 0.03113039 0.03500772
  0.03918757 0.04893096]
 [0.03385912 0.0509821  0.05367742 0.03682524 0.02878091 0.06128595
  0.05456654 0.05816995 0.05442955 0.04160418 0.0359505  0.07445221
  0.06241388 0.0271336  0.02306688 0.03818308 0.03406928 0.02726636
  0.02529523 0.02594388 0.02563065 0.03500387 0.04410544 0.03399116
  0.032851   0.03848475 0.04390317 0.03479156 0.02800143 0.03270218
  0.0371859  0.04663999]
 [0.0332591  0.0332832  0.03546872 0.0228343  0.02162411 0.02833251
  0.04228231 0.04182946 0.03287599 0.02809148 0.04236779 0.03426677
  0.04590042 0.01598972 0.01813454 0.04115897 0.04715832 0.03647875
  0.03648375 0.03356756 0.03822673 0.03549201 0.02688543 0.04122599
  0.0338942  0.03232038 0.03123132 0.03507223 0.01936839 0.01647288
  0.03519292 0.03511629]
 [0.03328713 0.02881873 0.02624827 0.01918497 0.01800824 0.02149675
  0.03266458 0.03173082 0.02505651 0.02115374 0.03109888 0.02457644
  0.02835346 0.01278888 0.01505285 0.04329466 0.04475624 0.04528498
  0.0365924  0.0412574  0.051977   0.03289179 0.02328028 0.05206988
  0.05360893 0.03319522 0.02728631 0.03375089 0.01726881 0.01203179
  0.03969161 0.03581295]
 [0.03416013 0.02351479 0.02315874 0.01769559 0.01849432 0.02116396
  0.02627187 0.02572749 0.02347009 0.02174556 0.03189841 0.02693661
  0.02571681 0.01266596 0.01356775 0.03553503 0.03401889 0.03506397
  0.03448142 0.04682666 0.0469298  0.02798193 0.01841783 0.03563677
  0.03908953 0.02728872 0.02441721 0.02536165 0.01573562 0.01048184
  0.03615465 0.03471152]
 [0.03392507 0.02195032 0.02124442 0.01502443 0.01712253 0.01839446
  0.02636686 0.02229535 0.021439   0.01907829 0.03783949 0.02358751
  0.02288222 0.01102818 0.01288124 0.04048406 0.04453752 0.0372155
  0.04709774 0.053187   0.04885871 0.02874324 0.01880808 0.04440569
  0.03533375 0.02698766 0.02425284 0.02443293 0.01436505 0.00929626
  0.03181672 0.02523097]
 [0.03330689 0.02557849 0.0240536  0.01674619 0.01863842 0.01935715
  0.02944939 0.02398039 0.0238565  0.02024978 0.04112896 0.02445422
  0.02360748 0.01163557 0.01505696 0.04117545 0.04477618 0.03639339
  0.0513203  0.04475886 0.04518984 0.03246539 0.0260238  0.05464737
  0.03390521 0.03469514 0.0328153  0.02990671 0.01757191 0.01175242
  0.03037124 0.02190604]
 [0.03396672 0.03021944 0.02925993 0.01979135 0.01982001 0.02490635
  0.03215683 0.02863996 0.02953227 0.02347646 0.02925558 0.02821693
  0.02820085 0.01523772 0.01547004 0.0320259  0.03412853 0.02943475
  0.03984716 0.04781833 0.03921094 0.0330251  0.02997955 0.03229188
  0.02922047 0.03254449 0.03544531 0.02654975 0.02193129 0.02343873
  0.03187032 0.0361241 ]
 [0.03321172 0.03291593 0.03469988 0.0315471  0.02927083 0.03515935
  0.03508375 0.03495161 0.03892069 0.0384606  0.03211806 0.04661312
  0.04276364 0.02588387 0.02150667 0.03256682 0.03419941 0.03439355
  0.02915464 0.02667444 0.02692074 0.03713711 0.03651479 0.02962935
  0.03387493 0.03716979 0.03696952 0.03556418 0.03426411 0.05259212
  0.03472654 0.04027649]
 [0.03399871 0.03139757 0.03540076 0.03027902 0.02781065 0.03548577
  0.03456781 0.03568263 0.03705078 0.03362263 0.02796404 0.03091022
  0.03279724 0.02439674 0.0214122  0.02629047 0.02206    0.02041538
  0.02086304 0.02120442 0.0204584  0.03271463 0.02935856 0.01878756
  0.02213968 0.03114719 0.04049611 0.02751474 0.03513224 0.06660634
  0.03873712 0.04438344]
 [0.03306875 0.04259372 0.04280884 0.02416214 0.02007747 0.02689294
  0.03567503 0.03247155 0.03260802 0.0213625  0.02362903 0.02163126
  0.02631062 0.01745396 0.01827008 0.03491887 0.02670358 0.02116355
  0.02043317 0.0220497  0.02309975 0.03603307 0.05552296 0.03222776
  0.03700865 0.0396161  0.0440526  0.02942895 0.0307766  0.08406547
  0.04867451 0.03953577]
 [0.0332315  0.0335996  0.03325706 0.02076731 0.0171744  0.02181425
  0.03061557 0.02446903 0.02807012 0.01779533 0.02036592 0.01561496
  0.01960491 0.01406512 0.01596586 0.0312417  0.02376438 0.01937631
  0.02003459 0.02271198 0.02318582 0.0290333  0.04607746 0.03076755
  0.04082773 0.04005621 0.0350269  0.02559896 0.02667746 0.06502855
  0.03630238 0.02797353]
 [0.03366475 0.01817905 0.01859524 0.01410823 0.0125537  0.01504224
  0.01862125 0.01671278 0.01848558 0.01265738 0.01819402 0.01182021
  0.01548448 0.0094121  0.01150058 0.02292138 0.02069673 0.0204045
  0.02179424 0.02551385 0.02660079 0.02159857 0.02703955 0.03238876
  0.03666734 0.03124034 0.0201584  0.02388264 0.02093014 0.02782166
  0.02494413 0.01753887]
 [0.03379033 0.02419368 0.02551766 0.019393   0.01550672 0.02096377
  0.02519577 0.02212277 0.02186425 0.01741631 0.02207743 0.01691689
  0.01992675 0.01377348 0.01487799 0.0298051  0.02853254 0.02317317
  0.02286892 0.02668077 0.0269137  0.03238223 0.0265186  0.0252076
  0.03952029 0.03074487 0.02818291 0.02269454 0.02435948 0.03700408
  0.05289511 0.03626178]
 [0.03413459 0.02483441 0.02680898 0.0212409  0.01751447 0.02302304
  0.02831596 0.0264779  0.02357494 0.02044841 0.02665141 0.02176764
  0.02637257 0.0153498  0.01456466 0.03188586 0.03001764 0.02749798
  0.02314055 0.02581367 0.02793311 0.03415536 0.01982744 0.02651935
  0.03967168 0.02572265 0.02643455 0.02319595 0.02005419 0.02557924
  0.06406652 0.05601314]
 [0.03364533 0.022157   0.0209584  0.0186295  0.01251335 0.01846331
  0.02403122 0.02140338 0.01959433 0.01648398 0.02394884 0.0156552
  0.02157522 0.01243578 0.01266531 0.03478213 0.03442588 0.03687513
  0.0293495  0.04243065 0.04652107 0.03080265 0.01680903 0.03589257
  0.05148401 0.02295638 0.02347579 0.02223175 0.01640033 0.01265665
  0.05399299 0.04451699]
 [0.03446655 0.01939533 0.0197308  0.01773321 0.01241345 0.01834983
  0.023209   0.0215682  0.01918267 0.01656911 0.02512441 0.01619774
  0.02156767 0.01215016 0.0118497  0.03139162 0.02645495 0.02955545
  0.0252663  0.04270796 0.04398962 0.02631061 0.01465044 0.03149521
  0.04003226 0.0210501  0.02141363 0.01853421 0.01536585 0.01045972
  0.04478124 0.03769914]
 [0.03400588 0.01828239 0.01764658 0.01557327 0.01080148 0.0157818
  0.02250962 0.01986764 0.01797296 0.01473688 0.02784631 0.01463497
  0.02029694 0.01081728 0.01080292 0.0369936  0.03971621 0.03314841
  0.04090708 0.04906125 0.04004573 0.02895845 0.01528405 0.04461061
  0.03988362 0.02291588 0.01785714 0.02014804 0.01584244 0.00997778
  0.04003343 0.0264866 ]
 [0.03260757 0.02255448 0.02267308 0.02040216 0.0145211  0.01978558
  0.0250156  0.02429064 0.02414194 0.01921814 0.02221273 0.01689901
  0.02321916 0.01305401 0.01334889 0.02925209 0.03421602 0.0345795
  0.03811054 0.04381153 0.04486014 0.03148861 0.0391132  0.14609618
  0.0661892  0.06697502 0.0262104  0.05253029 0.03078681 0.01647835
  0.03694257 0.02040809]
 [0.03468903 0.02063864 0.02026885 0.01969398 0.01304747 0.01918374
  0.02525473 0.02461058 0.02143318 0.01884318 0.02900606 0.01929047
  0.02300461 0.01383133 0.01263186 0.02769138 0.03106031 0.02536711
  0.0343332  0.03383853 0.02994646 0.03093319 0.01594739 0.02794889
  0.02369484 0.02207615 0.01725941 0.02058244 0.0186632  0.01182649
  0.02867807 0.04353121]
 [0.03336444 0.03256138 0.03473103 0.05458944 0.0524435  0.0422106
  0.0337243  0.03484302 0.0371401  0.05726122 0.03993934 0.03927551
  0.03762934 0.07430135 0.09526881 0.02836026 0.02765876 0.03297007
  0.03068932 0.02400629 0.02661595 0.03559482 0.03253921 0.01204132
  0.0174398  0.02942451 0.03245667 0.04120982 0.05115328 0.0250558
  0.01263428 0.01946018]
 [0.0326084  0.04094657 0.03710128 0.0737545  0.13556229 0.0513428
  0.03483316 0.03507571 0.03806826 0.07453161 0.05364021 0.0443081
  0.03648402 0.0902043  0.11677313 0.0371847  0.04303083 0.06603149
  0.05455675 0.03591407 0.03987141 0.03577703 0.04606124 0.01168446
  0.01888898 0.03448318 0.04569636 0.04751693 0.05512384 0.02310418
  0.00950866 0.01259415]
 [0.03303824 0.03227679 0.02776755 0.04249287 0.06418641 0.0292085
  0.02608515 0.02965603 0.03061577 0.04516121 0.04376828 0.03844159
  0.03431879 0.0368988  0.04400615 0.03073922 0.04856147 0.08704823
  0.08641405 0.05350934 0.05021484 0.03234871 0.03735569 0.02047081
  0.02244658 0.03154815 0.03278542 0.04797814 0.03034526 0.01315673
  0.01191733 0.01693859]
 [0.03322588 0.03171396 0.02716579 0.04122479 0.04422038 0.02977082
  0.02799166 0.02923331 0.03227598 0.04271284 0.03808374 0.03419299
  0.03213845 0.03428968 0.036769   0.02506365 0.03540764 0.06025546
  0.06997552 0.04417751 0.04480979 0.04506049 0.04023351 0.0173378
  0.01983033 0.02860368 0.02634489 0.05620102 0.03779516 0.01164406
  0.01043056 0.01474606]]

-* TASK 10/20 | SAMPLE 94/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 468/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information about Bill going to the park. According to sentence 4, Bill is in the office.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' going', ' to', ' the', ' park', '.', ' According', ' to', ' sentence', ' ', '4', ',', ' Bill', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.0312871  0.04596297 0.04050868 ... 0.01822485 0.00855003 0.02285452]
 [0.03186264 0.03994921 0.03901597 ... 0.02469575 0.01746994 0.03141029]
 [0.03261959 0.04766231 0.04925455 ... 0.0141422  0.00595507 0.01352864]
 ...
 [0.03295565 0.03854349 0.0427784  ... 0.01243093 0.00564247 0.01357012]
 [0.03356463 0.02703898 0.02986751 ... 0.01365771 0.0114572  0.01899456]
 [0.03344927 0.03019359 0.03278501 ... 0.01163802 0.00706511 0.01650109]]

-* TASK 10/20 | SAMPLE 94/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 469/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 10, Mary is in the park, and there is no information about Mary being in the kitchen.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Mary', ' is', ' in', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03015727 0.04207775 0.04494254 ... 0.03574228 0.01855239 0.04344227]
 [0.0307757  0.03064617 0.03326879 ... 0.03376327 0.03400704 0.0256523 ]
 [0.03131271 0.04534616 0.05199239 ... 0.05287169 0.03744243 0.04994181]
 ...
 [0.03146064 0.04840088 0.0420563  ... 0.01253464 0.01066241 0.05731642]
 [0.0321895  0.03756765 0.02980827 ... 0.01026739 0.0087966  0.02162036]
 [0.03202047 0.04116448 0.03164093 ... 0.00896963 0.00905819 0.02425136]]

-* TASK 10/20 | SAMPLE 94/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 470/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to sentence 14, Mary went back to the kitchen, which implies that Mary is now in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '14', ',', ' Mary', ' went', ' back', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 50), x_tokens=50, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 50)
DEBUG result.interpretability.attn_scores 1500 
 [[0.03135446 0.0433181  0.04211432 ... 0.02301302 0.01845187 0.03376396]
 [0.03157079 0.04181418 0.04100493 ... 0.03313385 0.02817812 0.03083231]
 [0.03273365 0.04774115 0.04918162 ... 0.02100797 0.01428466 0.03538208]
 ...
 [0.03282324 0.04544772 0.04647495 ... 0.01792827 0.01546441 0.06279254]
 [0.03306581 0.03327524 0.03282014 ... 0.02441944 0.02264791 0.05639145]
 [0.03292961 0.04088588 0.03918496 ... 0.02219802 0.02148052 0.05108735]]
Model's predictions for the sample 94:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 2, Bill journeyed   |
|          |                 |   to the cinema, which implies that Bill   |
|          |                 |           is now in the cinema.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |    There is no information about Julie     |
|          |                 |  going to the park. According to sentence  |
|          |                 |        5, Julie went to the school.        |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no information about Bill going  |
|          |                 |   to the park. According to sentence 4,    |
|          |                 |           Bill is in the office.           |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to sentence 10, Mary is in the  |
|          |                 |  park, and there is no information about   |
|          |                 |         Mary being in the kitchen.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  According to sentence 14, Mary went back  |
|          |                 |  to the kitchen, which implies that Mary   |
|          |                 |           is now in the kitchen.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 94:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.09 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 95/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 471/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 2, Julie journeyed to the park, which implies that she is currently in the park.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02722978 0.04466347 0.05474291 0.07514081 0.08037978 0.07474874
  0.05967277 0.0678541  0.0543048  0.06516173 0.04688411 0.06013684
  0.06799041 0.10175262 0.06577506 0.02834484 0.02969989 0.03004535
  0.02788577 0.02894635 0.02421922 0.03911382 0.04006612 0.02347629
  0.01328945 0.02541034]
 [0.02954187 0.05816853 0.03682949 0.05729316 0.04238659 0.03805439
  0.0328839  0.02372512 0.02311851 0.03571554 0.02812761 0.01640372
  0.01923357 0.03417572 0.04347552 0.02182072 0.01351161 0.01195677
  0.01515737 0.01508435 0.0142624  0.04273975 0.05032723 0.01058745
  0.0049247  0.01336811]
 [0.02789062 0.03413754 0.03473848 0.02500751 0.01839157 0.02739335
  0.0305118  0.02513776 0.02908565 0.02505106 0.02521409 0.02423508
  0.02373091 0.0128568  0.01222088 0.02954687 0.02836496 0.0305096
  0.03601988 0.04404245 0.0365794  0.03332751 0.04995487 0.05330148
  0.06175114 0.05198784]
 [0.02816495 0.04139738 0.04555716 0.06827304 0.06121331 0.04898012
  0.03546962 0.03030043 0.03439472 0.04632588 0.03413907 0.02541143
  0.02592587 0.10551249 0.11120108 0.03354581 0.02568621 0.01872418
  0.01987789 0.02067919 0.02008694 0.0383889  0.05965508 0.01818729
  0.00662949 0.02812812]
 [0.02874012 0.02681909 0.0278888  0.05234608 0.04563278 0.04448222
  0.0264593  0.02352001 0.02901237 0.04302807 0.03043678 0.02872493
  0.027951   0.11381337 0.13768041 0.03315198 0.02872416 0.02248072
  0.02242794 0.02204252 0.01927263 0.03304562 0.03632241 0.01296015
  0.00578343 0.01827776]
 [0.029163   0.03052589 0.03658284 0.05546508 0.05051485 0.05642428
  0.03522142 0.03281282 0.03834742 0.05072979 0.03577012 0.04579294
  0.04255553 0.0910833  0.08486926 0.02803466 0.02623463 0.02246679
  0.02164313 0.02183251 0.01822666 0.02992976 0.03405389 0.01780881
  0.00843953 0.01747041]
 [0.02815293 0.04185711 0.04956381 0.04365024 0.04496027 0.05183255
  0.04149039 0.04388331 0.04201132 0.04520954 0.03710256 0.05115775
  0.04478052 0.05537281 0.04968589 0.0373847  0.03514712 0.03035845
  0.02746845 0.0280466  0.02556664 0.0342245  0.04756184 0.03670724
  0.03032231 0.03029683]
 [0.02933392 0.04043833 0.04952858 0.04923564 0.04380258 0.0595256
  0.04574939 0.04832981 0.04967391 0.05119067 0.03744281 0.05166616
  0.04879266 0.04261515 0.0280114  0.02689162 0.02652691 0.02437536
  0.02388625 0.02481619 0.02049308 0.03417524 0.03650622 0.02281858
  0.0128295  0.02300604]
 [0.02863772 0.05529672 0.05842042 0.0312227  0.02488743 0.04029741
  0.04914276 0.04574789 0.04688216 0.03236359 0.03058668 0.03891691
  0.04000938 0.01914158 0.01610879 0.0438815  0.03544502 0.02949507
  0.02952247 0.03095195 0.02891158 0.03368364 0.06517162 0.04593126
  0.03417824 0.03198251]
 [0.02911907 0.07061408 0.06780478 0.02898569 0.0231573  0.03409576
  0.04891694 0.04188197 0.04887648 0.0282962  0.02679517 0.03055765
  0.03157036 0.01594903 0.01523449 0.04811205 0.03538194 0.02775855
  0.02954575 0.03283224 0.02769319 0.03101867 0.06959245 0.04202437
  0.0240433  0.02617235]
 [0.02934286 0.03803462 0.04205504 0.02203671 0.01841019 0.02541009
  0.03847034 0.03220558 0.0375428  0.02269987 0.02214471 0.02471001
  0.02403936 0.01329215 0.01319828 0.04067287 0.03232415 0.02470483
  0.0273725  0.02856109 0.02656482 0.02940498 0.052055   0.04850425
  0.04068606 0.03743779]
 [0.02947674 0.01622846 0.0172367  0.01215396 0.01092999 0.01448731
  0.01764428 0.016801   0.01971899 0.01373112 0.01504351 0.01524442
  0.01506431 0.00693213 0.00767995 0.02040062 0.02176936 0.0211792
  0.0267507  0.02938399 0.03045459 0.02337219 0.03383332 0.05528626
  0.05988131 0.0563775 ]
 [0.02924575 0.02345938 0.02442913 0.01672772 0.0154828  0.02093885
  0.02623246 0.02376568 0.02434269 0.01860468 0.02236361 0.02233113
  0.02190217 0.0097395  0.01031663 0.03753145 0.03168008 0.0291043
  0.02903108 0.02984611 0.02766034 0.02831898 0.02773215 0.04758177
  0.06311834 0.04645764]
 [0.0294117  0.02299432 0.0241144  0.0190089  0.01677429 0.02362535
  0.02715506 0.02771504 0.02565595 0.02279351 0.02617297 0.02970462
  0.02923563 0.01127486 0.00998076 0.03353033 0.03399253 0.03185013
  0.02829983 0.02804856 0.02932563 0.0284146  0.02101672 0.0376
  0.06022639 0.02796744]
 [0.02881105 0.02019938 0.01702207 0.01463747 0.01198413 0.01569624
  0.02212706 0.02161717 0.01958105 0.01608231 0.0221578  0.01910104
  0.02228109 0.00733941 0.00740386 0.03557755 0.03086811 0.04384521
  0.03345584 0.04107738 0.04911348 0.02703285 0.01663799 0.04265517
  0.10792477 0.04220106]
 [0.03001028 0.0207984  0.02028553 0.01722072 0.01598311 0.02121046
  0.02670749 0.02585393 0.02218314 0.01981904 0.02463947 0.02517762
  0.02479951 0.00910708 0.00823846 0.03421548 0.02103526 0.03127756
  0.02477959 0.03280678 0.02627891 0.02247452 0.01636702 0.03194698
  0.07216177 0.02540147]
 [0.02982497 0.0174364  0.01568785 0.01302027 0.01106496 0.01533178
  0.02049853 0.02038532 0.01861407 0.01522786 0.02529855 0.02146348
  0.02181437 0.00676372 0.00675331 0.03920709 0.02625714 0.04111784
  0.03206414 0.04062505 0.03353738 0.02206177 0.01288064 0.02930006
  0.06223781 0.034374  ]
 [0.02963804 0.01672168 0.01497269 0.01157547 0.009884   0.01383742
  0.01951592 0.01930063 0.01834538 0.01408372 0.02717706 0.01996017
  0.02031141 0.0061528  0.00648173 0.03212885 0.03059004 0.03989921
  0.03756481 0.03959214 0.03490943 0.02315359 0.01385066 0.0301888
  0.04428036 0.05201248]
 [0.02874437 0.02485608 0.02046813 0.016239   0.01556308 0.01853582
  0.03178126 0.026905   0.02657264 0.01854908 0.02972297 0.0219171
  0.0241572  0.00876071 0.00988624 0.02468871 0.02945559 0.0328772
  0.04406362 0.04104164 0.05305984 0.02759321 0.0251814  0.06138204
  0.03314487 0.06347016]
 [0.03017042 0.02193251 0.02068115 0.01632164 0.01338267 0.01874324
  0.02292251 0.02295565 0.02290012 0.01792434 0.02607779 0.02235122
  0.0228021  0.00879057 0.00832869 0.02452576 0.02383365 0.02541602
  0.03167849 0.03005367 0.02870309 0.02626278 0.01635101 0.02483229
  0.0206431  0.03621937]
 [0.03029257 0.02335358 0.02623345 0.02348008 0.01856377 0.02649555
  0.02712454 0.03376887 0.02743905 0.02755149 0.02950645 0.03794514
  0.03423781 0.0136415  0.0096424  0.02262215 0.02376702 0.02703343
  0.0252719  0.02316599 0.02285245 0.02822541 0.01531221 0.01916079
  0.01805029 0.01864299]
 [0.03044758 0.0278474  0.0294865  0.02834878 0.02092801 0.03082851
  0.03326332 0.04144625 0.02871495 0.0327162  0.03671116 0.04442114
  0.0420426  0.0159341  0.01076438 0.0230271  0.02304951 0.0271595
  0.02419319 0.02368587 0.02193756 0.02902029 0.01669135 0.01788555
  0.01578755 0.01432825]
 [0.03027911 0.02554721 0.02592672 0.02551191 0.02010774 0.02803732
  0.03037041 0.03552684 0.02864598 0.03072201 0.03436392 0.03908252
  0.04015725 0.01474331 0.01085484 0.02633872 0.02507767 0.03030482
  0.02594493 0.02511872 0.02414767 0.02913797 0.01450406 0.02102183
  0.0186645  0.01302505]
 [0.03017626 0.01977161 0.01882719 0.01555792 0.01185382 0.01712443
  0.02224404 0.02442507 0.02250068 0.01851543 0.0241981  0.02384114
  0.02659822 0.00842629 0.00744581 0.02805182 0.02890154 0.03064265
  0.02846332 0.02722174 0.031334   0.02724376 0.01205944 0.02566558
  0.02940803 0.01741028]
 [0.0302662  0.02007987 0.01774684 0.01505922 0.01086484 0.01524882
  0.02235796 0.02221978 0.02114863 0.01674948 0.02317854 0.02059218
  0.02466319 0.00760814 0.0068282  0.02967983 0.02788168 0.03523331
  0.03088529 0.03206759 0.03865375 0.02339152 0.01175172 0.02987059
  0.02868035 0.0203819 ]
 [0.03048581 0.01989872 0.01779489 0.01563201 0.01249258 0.01613773
  0.02080267 0.02311209 0.02190871 0.01903336 0.02526762 0.02378086
  0.02465279 0.00856065 0.00739325 0.02643059 0.03013224 0.03028357
  0.03205157 0.02766575 0.03003585 0.02408958 0.01157977 0.02022149
  0.01814594 0.01689225]
 [0.03047286 0.02256426 0.02032478 0.01698989 0.01274855 0.01786914
  0.02500267 0.02653417 0.02661287 0.02012337 0.02995615 0.02474715
  0.02704183 0.00890403 0.0076892  0.02852857 0.02928561 0.03171465
  0.03237341 0.03064404 0.0325782  0.02493354 0.01275613 0.02200056
  0.01874045 0.0188224 ]
 [0.03060826 0.01655119 0.01562379 0.01116654 0.0096001  0.01266208
  0.01935927 0.01959846 0.02041297 0.01399447 0.03026309 0.01864561
  0.02069495 0.00658934 0.0056063  0.02494957 0.03178491 0.02817683
  0.03726067 0.03221788 0.03196974 0.02264181 0.01175942 0.02092621
  0.01811452 0.03016277]
 [0.0292599  0.02266169 0.02132424 0.01365432 0.01225523 0.01609921
  0.026087   0.02806385 0.02813303 0.01683434 0.02962185 0.02183733
  0.02519922 0.00798974 0.0078189  0.02340763 0.0279566  0.02828863
  0.04097095 0.03692323 0.05011575 0.02637807 0.0235402  0.05612678
  0.02563368 0.0573475 ]
 [0.03052237 0.0216859  0.02173027 0.0188365  0.01466951 0.02212901
  0.02319206 0.02886346 0.02771492 0.02241457 0.02628242 0.02775439
  0.02640529 0.01185413 0.00919533 0.01825598 0.02363672 0.02356492
  0.03107812 0.02714635 0.02893533 0.02579478 0.014191   0.01606389
  0.01220169 0.02237958]
 [0.02937673 0.02725903 0.02689495 0.04319856 0.04489511 0.03864107
  0.0246965  0.02515166 0.03026959 0.04398493 0.03164074 0.03121158
  0.0308957  0.07363833 0.09014081 0.02268573 0.02677625 0.02305504
  0.02359422 0.02221484 0.02079218 0.03169107 0.03126953 0.01336012
  0.00617375 0.02069193]
 [0.02918574 0.02850047 0.02714081 0.04762841 0.09107357 0.03802377
  0.02290725 0.02361735 0.02913594 0.05049862 0.03694076 0.03078842
  0.0253598  0.07437824 0.09446791 0.02794859 0.03670503 0.03093625
  0.02749686 0.02406428 0.02358319 0.02863936 0.03033982 0.01108285
  0.00527143 0.01776466]
 [0.0288703  0.02537443 0.02374601 0.03870031 0.08835213 0.0257775
  0.01860349 0.02207492 0.02510133 0.04367183 0.035299   0.0325298
  0.02517727 0.03302494 0.04226534 0.02387495 0.0595822  0.05059661
  0.04026811 0.02950148 0.03867633 0.02613723 0.0280132  0.01874696
  0.01108392 0.02211292]
 [0.02910612 0.03232524 0.02858955 0.04067373 0.05680943 0.03127494
  0.02541565 0.02489904 0.0310972  0.04060227 0.03347285 0.0278585
  0.02792674 0.03428142 0.03735651 0.02100526 0.03893456 0.0335675
  0.03165194 0.0280515  0.02946873 0.04493878 0.0411144  0.01478624
  0.00754799 0.02201829]]

-* TASK 10/20 | SAMPLE 95/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 472/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Mary being in the school in the context sentences. The options provided are office, bedroom, and cinema, but school is not one of them.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' options', ' provided', ' are', ' office', ',', ' bedroom', ',', ' and', ' cinema', ',', ' but', ' school', ' is', ' not', ' one', ' of', ' them', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 32), x_tokens=32, y_tokens=41, max_supp_attn=0.0732, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 32)
DEBUG result.interpretability.attn_scores 1312 
 [[0.02250089 0.03313118 0.03495413 ... 0.0117023  0.00981834 0.06756047]
 [0.02317342 0.03124091 0.03114015 ... 0.01554309 0.0172766  0.07789139]
 [0.02354699 0.0301413  0.03345961 ... 0.0247933  0.02301578 0.05605097]
 ...
 [0.02353518 0.0319275  0.02573332 ... 0.00817765 0.00940676 0.09042727]
 [0.02368484 0.02479663 0.01969427 ... 0.00963246 0.0149588  0.05026061]
 [0.02388813 0.02572567 0.01997548 ... 0.00852208 0.01276658 0.06971783]]

-* TASK 10/20 | SAMPLE 95/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 473/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, Bill is in the cinema, but there is no mention of him being in the bedroom.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Bill', ' is', ' in', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' him', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02913312 0.04528885 0.04217271 ... 0.01880902 0.02554175 0.02752041]
 [0.02963684 0.03611461 0.03588866 ... 0.02643791 0.02402094 0.03379621]
 [0.03034807 0.04524447 0.04632495 ... 0.01417301 0.02057475 0.02104607]
 ...
 [0.0305054  0.04175019 0.03401815 ... 0.013379   0.02117268 0.01768482]
 [0.03107061 0.03404965 0.02632231 ... 0.02175921 0.02553362 0.02148326]
 [0.03110226 0.0341473  0.0262184  ... 0.01654614 0.02008569 0.01925721]]

-* TASK 10/20 | SAMPLE 95/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 474/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no mention of Fred being in the cinema in the context sentences. The information provided is about Julie traveling to the cinema and Bill's possible locations, but it does not mention Fred's location.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' The', ' information', ' provided', ' is', ' about', ' Julie', ' traveling', ' to', ' the', ' cinema', ' and', ' Bill', "'s", ' possible', ' locations', ',', ' but', ' it', ' does', ' not', ' mention', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 44), x_tokens=44, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 44)
DEBUG result.interpretability.attn_scores 2112 
 [[0.01915356 0.02191821 0.02344275 ... 0.02386225 0.01028053 0.00641128]
 [0.01953945 0.02168519 0.02516777 ... 0.02345407 0.02550266 0.01396751]
 [0.02007434 0.02221812 0.02542679 ... 0.0369902  0.01590522 0.01040051]
 ...
 [0.02054148 0.02362705 0.02142389 ... 0.01052439 0.00758228 0.00910531]
 [0.02073554 0.02743741 0.02738035 ... 0.01172723 0.01060822 0.0110655 ]
 [0.02085593 0.02304341 0.02361036 ... 0.01244468 0.01109797 0.01038938]]

-* TASK 10/20 | SAMPLE 95/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 475/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentences 13 and 14, Bill went to the kitchen and then travelled to the bedroom, but there is no mention of him being in the school.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ',', ' Bill', ' went', ' to', ' the', ' kitchen', ' and', ' then', ' travelled', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' him', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02262643 0.02841362 0.03395353 ... 0.03477511 0.02413763 0.01841019]
 [0.02292809 0.03276287 0.03639011 ... 0.02410012 0.03089004 0.02586406]
 [0.02360692 0.03341315 0.04111205 ... 0.03277625 0.02140146 0.01459231]
 ...
 [0.02383578 0.03053305 0.03100908 ... 0.03378373 0.019666   0.01394019]
 [0.0243576  0.02326356 0.02264066 ... 0.02030043 0.01957989 0.01983827]
 [0.02408068 0.02710303 0.02494655 ... 0.02926991 0.0178961  0.0174562 ]]
Model's predictions for the sample 95:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 2, Julie   |
|          |                 |    journeyed to the park, which implies    |
|          |                 |     that she is currently in the park.     |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  There is no mention of Mary being in the  |
|          |                 |    school in the context sentences. The    |
|          |                 |   options provided are office, bedroom,    |
|          |                 |    and cinema, but school is not one of    |
|          |                 |                   them.                    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  According to context sentence 8, Bill is  |
|          |                 |   in the cinema, but there is no mention   |
|          |                 |        of him being in the bedroom.        |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |  There is no mention of Fred being in the  |
|          |                 |    cinema in the context sentences. The    |
|          |                 |    information provided is about Julie     |
|          |                 |     traveling to the cinema and Bill's     |
|          |                 |    possible locations, but it does not     |
|          |                 |          mention Fred's location.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |   According to context sentences 13 and    |
|          |                 |   14, Bill went to the kitchen and then    |
|          |                 |   travelled to the bedroom, but there is   |
|          |                 |   no mention of him being in the school.   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 95:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.08 ± 0.01 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 96/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 476/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: From context sentence 2, "Fred travelled to the school", we can infer that Fred has moved to the school.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '2', ',', ' "', 'Fred', ' travelled', ' to', ' the', ' school', '",', ' we', ' can', ' infer', ' that', ' Fred', ' has', ' moved', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02650266 0.04233338 0.05161104 0.0668107  0.0793134  0.06757753
  0.05205586 0.06221564 0.05216551 0.05876753 0.04587658 0.0526339
  0.0598962  0.093867   0.06454754 0.02875103 0.0304656  0.02872202
  0.02478858 0.02541667 0.02487548 0.0368103  0.03987642 0.02070812
  0.01450927 0.02385328]
 [0.02629442 0.08096466 0.06204924 0.05429426 0.04474816 0.05424954
  0.15939513 0.09569222 0.06299678 0.04868374 0.06640684 0.0446426
  0.07014341 0.02642618 0.02413972 0.03883728 0.03840264 0.04886653
  0.03502432 0.0391489  0.03892044 0.04271888 0.04036886 0.03362267
  0.02464603 0.02810387]
 [0.02882457 0.05554896 0.03632154 0.05078502 0.04031027 0.03410308
  0.0279238  0.02080007 0.02161247 0.03181227 0.02777707 0.01401257
  0.01585783 0.03085779 0.04169177 0.02257492 0.01407789 0.01164136
  0.01351178 0.01309653 0.01484692 0.04109234 0.05112074 0.00964961
  0.00646577 0.01142918]
 [0.02707806 0.02239571 0.02234205 0.01849696 0.01359231 0.02087688
  0.01880278 0.01766953 0.0229361  0.0198282  0.02036588 0.0169858
  0.01691489 0.00974311 0.01007454 0.02278285 0.02522236 0.02468814
  0.05094879 0.04487471 0.03611102 0.03012822 0.04655035 0.05291193
  0.05789344 0.07356373]
 [0.02741411 0.03963868 0.04502149 0.06217377 0.06000553 0.04502371
  0.03008238 0.02723948 0.03268465 0.04200567 0.03378692 0.02187347
  0.02185266 0.10057528 0.10938991 0.03462238 0.026882   0.01821118
  0.01756189 0.01787551 0.02082241 0.0366761  0.05954995 0.0166755
  0.00898797 0.02490801]
 [0.02798868 0.02572122 0.0276532  0.04821879 0.04499735 0.04070992
  0.02246273 0.02128603 0.02766759 0.03928532 0.03009007 0.02488982
  0.02355941 0.10841543 0.134923   0.03407483 0.03007693 0.02184568
  0.01971004 0.01895886 0.01988343 0.03124739 0.03563413 0.01177177
  0.00712894 0.01609366]
 [0.02840247 0.02938814 0.03566101 0.05116352 0.04975013 0.05175824
  0.02988685 0.0294805  0.03615477 0.04650746 0.03531999 0.03938243
  0.03600375 0.08581772 0.08377119 0.02869409 0.02719412 0.02156406
  0.01900364 0.01874738 0.01869236 0.02854112 0.03327167 0.01542965
  0.00927906 0.0159296 ]
 [0.02737115 0.03690882 0.04355504 0.03932864 0.04325527 0.04780163
  0.03394907 0.03863228 0.03903075 0.04087791 0.03548787 0.04410957
  0.0389278  0.05273117 0.0491308  0.03659664 0.03458065 0.02841954
  0.0248648  0.025232   0.02643072 0.03335414 0.04620207 0.03436984
  0.0281767  0.03465217]
 [0.02768535 0.04454013 0.0513266  0.03033444 0.0271733  0.03931962
  0.03959791 0.04131545 0.04401803 0.03089316 0.02962607 0.03515871
  0.03492352 0.0212353  0.01780248 0.03951426 0.03327905 0.02784553
  0.02755958 0.02892972 0.02928881 0.03377387 0.06670479 0.04197029
  0.03347227 0.04036655]
 [0.02853436 0.06095666 0.06247511 0.02609683 0.02207505 0.03270206
  0.0395023  0.03692936 0.04503309 0.02601898 0.02549437 0.02681517
  0.02696613 0.01556136 0.01473906 0.04424686 0.03451316 0.02590884
  0.02619772 0.02840039 0.02778164 0.02863199 0.06565533 0.03662362
  0.0232309  0.02509362]
 [0.02849584 0.03123809 0.03670949 0.019332   0.01659508 0.02270919
  0.02975593 0.0273959  0.03387294 0.02036831 0.02006393 0.01998864
  0.01979646 0.01229036 0.01218562 0.03601522 0.03115264 0.02438128
  0.0287804  0.02908633 0.02887025 0.02782292 0.05266727 0.04810245
  0.04088427 0.04209423]
 [0.02870402 0.01277526 0.01400635 0.01015831 0.00913064 0.0125047
  0.01306005 0.01345967 0.01731407 0.01144529 0.01256415 0.01176096
  0.01159677 0.00593775 0.00647935 0.01684528 0.01878219 0.01799383
  0.02634405 0.02824587 0.02802682 0.01780643 0.02823306 0.05565232
  0.0617944  0.0646799 ]
 [0.02857713 0.02187993 0.02270235 0.01591381 0.01468763 0.0198259
  0.02109144 0.02004403 0.02150149 0.01679487 0.02030293 0.01870854
  0.01783294 0.00939871 0.01016484 0.03017422 0.02518893 0.02487656
  0.02598046 0.027642   0.02587605 0.0278399  0.02620101 0.04184078
  0.05848947 0.05199762]
 [0.0287657  0.02564796 0.02928558 0.02262012 0.01989914 0.02938747
  0.02895486 0.031587   0.02988175 0.02593314 0.02589542 0.03469166
  0.03203326 0.01538042 0.01189494 0.03014613 0.02980418 0.03051033
  0.02835729 0.02751554 0.02638565 0.03053647 0.02214382 0.02812733
  0.03777386 0.0279728 ]
 [0.02901544 0.02122713 0.0202127  0.01488367 0.01588828 0.01753194
  0.02402181 0.02162599 0.02037275 0.01629438 0.02987556 0.02062194
  0.02008414 0.00889647 0.01024446 0.0305033  0.02938052 0.02852216
  0.02792929 0.03095027 0.02812027 0.02651555 0.02231797 0.03714855
  0.06645201 0.03051066]
 [0.02859036 0.01632276 0.01357574 0.01192983 0.01072886 0.01296367
  0.01551839 0.01558285 0.01563044 0.01290714 0.01791414 0.01296106
  0.01567538 0.00620775 0.0068719  0.02470519 0.02215458 0.03426966
  0.03871694 0.04846689 0.03687783 0.02216171 0.01552178 0.03731791
  0.09020399 0.04200098]
 [0.02900341 0.01656014 0.01446541 0.01232654 0.01103243 0.01414056
  0.01611962 0.01667989 0.01654669 0.01393586 0.02215777 0.0158948
  0.01756168 0.00647775 0.00681563 0.03289619 0.02369831 0.04222774
  0.03367143 0.05362359 0.0337382  0.01975036 0.01252272 0.03304716
  0.05665855 0.03004619]
 [0.02900427 0.01395776 0.01245852 0.00953268 0.00857109 0.01163587
  0.0141738  0.01476215 0.01498757 0.01144132 0.02060022 0.01336109
  0.01559912 0.00525401 0.0057254  0.02988151 0.02610561 0.03553915
  0.0395065  0.0457738  0.03376644 0.02023331 0.01235838 0.04135953
  0.04422758 0.03847788]
 [0.02868337 0.02881668 0.02630843 0.03560089 0.04815983 0.03806147
  0.02698318 0.02732082 0.02831857 0.04182079 0.03754555 0.03460126
  0.02961119 0.03056862 0.02862898 0.02164134 0.03079741 0.02631428
  0.0242387  0.02299704 0.02641029 0.03280991 0.02481825 0.02203731
  0.01670134 0.02216342]
 [0.02967237 0.01682902 0.01524999 0.0118674  0.01084667 0.01401734
  0.01605158 0.0164244  0.01703391 0.0132188  0.02041252 0.0151576
  0.01620246 0.00683681 0.00703448 0.02228847 0.02329684 0.02256605
  0.03111891 0.02776512 0.02649682 0.02204142 0.01288888 0.02832121
  0.02400538 0.03005895]
 [0.02917738 0.02831261 0.02852312 0.0275679  0.02144414 0.03027148
  0.02903841 0.03430875 0.02833346 0.03005329 0.03234712 0.04147143
  0.03414255 0.01837522 0.01253013 0.02364921 0.02246046 0.02419152
  0.02278105 0.02245348 0.02384365 0.03055344 0.01829884 0.02037285
  0.01859382 0.02159251]
 [0.02935842 0.03277007 0.03799105 0.04500871 0.03180941 0.04455848
  0.03274659 0.04141035 0.03919451 0.04630409 0.03039669 0.05950875
  0.04921459 0.03061428 0.01711458 0.01843728 0.0205993  0.02052169
  0.01819288 0.0171791  0.01831196 0.03048748 0.02075991 0.01247506
  0.00901518 0.01541719]
 [0.02916529 0.03493726 0.04107487 0.04976009 0.03230666 0.04406915
  0.03575277 0.04704366 0.03742155 0.04981809 0.03579798 0.07749619
  0.05874357 0.03071912 0.01664597 0.0220093  0.02280976 0.02426117
  0.02014742 0.01908114 0.01944024 0.03019515 0.01974965 0.01405064
  0.01023958 0.01446186]
 [0.02925274 0.02561132 0.02738693 0.0319785  0.02593753 0.03519782
  0.03118838 0.03976791 0.03506663 0.04204529 0.03549369 0.07593866
  0.06544601 0.02996436 0.01587311 0.02307381 0.02441191 0.02477327
  0.0223718  0.01988057 0.02131548 0.02819932 0.01576685 0.0136736
  0.01195763 0.01320657]
 [0.02905077 0.01863501 0.01795218 0.01451038 0.01176868 0.01706315
  0.02000698 0.0238962  0.02166796 0.01804544 0.02254132 0.02186412
  0.02529607 0.00915294 0.00790319 0.02939189 0.02725817 0.03002347
  0.03006073 0.02693764 0.03057333 0.02762389 0.01285486 0.02682074
  0.03243903 0.0230343 ]
 [0.02902281 0.01876835 0.01722844 0.01401222 0.01044796 0.01489509
  0.02036014 0.02215365 0.02041742 0.01585727 0.02155153 0.01770482
  0.02243477 0.00780125 0.00709052 0.03381673 0.02600969 0.03387062
  0.03421519 0.03235481 0.03713623 0.02379763 0.01186075 0.03490167
  0.03418965 0.02533421]
 [0.02953169 0.01876542 0.01712493 0.0135921  0.01057482 0.01534156
  0.01855729 0.02202539 0.02157864 0.0165334  0.02147342 0.01955588
  0.02364146 0.00787735 0.00628097 0.03167818 0.02409791 0.03111362
  0.02826354 0.0307434  0.03110847 0.02219518 0.01101886 0.02805721
  0.0250645  0.01868387]
 [0.02931819 0.02077069 0.01866407 0.01448827 0.01130994 0.01618807
  0.02193816 0.02426328 0.02348016 0.01715274 0.02598635 0.02000994
  0.02549204 0.00854474 0.00683253 0.03565002 0.03053777 0.05035876
  0.03920242 0.04176996 0.03753767 0.02331113 0.01263401 0.02713953
  0.02553472 0.01803774]
 [0.02940364 0.01680338 0.01575329 0.01083986 0.00887805 0.0129217
  0.0181068  0.01965193 0.02060013 0.01385135 0.02685023 0.01606417
  0.02129662 0.00688415 0.0057741  0.03099994 0.03123637 0.03559601
  0.04227546 0.03679166 0.03600316 0.02329868 0.01163182 0.03235976
  0.02381622 0.02402745]
 [0.0285779  0.01862988 0.01768038 0.01099204 0.00939682 0.01376374
  0.01834626 0.0205352  0.02338137 0.0141762  0.02119712 0.01526514
  0.02047511 0.00701944 0.00622247 0.02425446 0.02990166 0.02416897
  0.03295809 0.02937696 0.03974794 0.02430904 0.0177101  0.06323438
  0.03852603 0.05225448]
 [0.0295647  0.01892514 0.01792927 0.01317978 0.01048194 0.01499332
  0.01773986 0.02062384 0.02217819 0.01547695 0.02488581 0.01785081
  0.020283   0.00866762 0.00679806 0.0262109  0.02796239 0.02607101
  0.03610695 0.02852016 0.03029599 0.02360895 0.01191322 0.02611801
  0.01951017 0.02572083]
 [0.02868624 0.02483032 0.02600818 0.03512615 0.03733921 0.03146176
  0.02146527 0.02440301 0.02847557 0.03684228 0.02942322 0.02657152
  0.02614558 0.05901952 0.07947409 0.02312423 0.02790741 0.02239109
  0.02185046 0.02017999 0.02276165 0.02922036 0.02894751 0.01316993
  0.00960943 0.01873445]
 [0.02843939 0.02759315 0.02692314 0.04398767 0.08659662 0.03529336
  0.01974684 0.02206397 0.02848234 0.04673591 0.03570238 0.02704013
  0.02218668 0.07004217 0.09013467 0.02829603 0.03914278 0.03046626
  0.02455664 0.0212135  0.02529193 0.02730101 0.02999179 0.01014179
  0.00676044 0.01590937]
 [0.02831689 0.02171435 0.02090326 0.02962427 0.05764726 0.02094742
  0.01486289 0.01932761 0.02223503 0.03462638 0.02848589 0.02383363
  0.020673   0.02483775 0.03350345 0.02306855 0.05317319 0.0471647
  0.03559335 0.02615161 0.04352457 0.02343805 0.02490359 0.01690138
  0.01307519 0.02133125]
 [0.0285262  0.02928191 0.02586596 0.03346388 0.04330058 0.02613361
  0.02075378 0.02238203 0.02772714 0.03364125 0.03030342 0.02157319
  0.0234899  0.02800109 0.03156652 0.02054749 0.03743565 0.03011398
  0.0276089  0.02461892 0.03088582 0.04196834 0.03735077 0.01389584
  0.01068728 0.01825766]]

-* TASK 10/20 | SAMPLE 96/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 477/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From context sentence 4, "Julie travelled to the office", we can infer that Julie has moved to the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '4', ',', ' "', 'Jul', 'ie', ' travelled', ' to', ' the', ' office', '",', ' we', ' can', ' infer', ' that', ' Julie', ' has', ' moved', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02957226 0.04317524 0.04183932 ... 0.05647513 0.01129724 0.01118519]
 [0.03019355 0.0448143  0.04231576 ... 0.06169872 0.01507746 0.01730609]
 [0.03084453 0.03859679 0.04340884 ... 0.06207407 0.02211984 0.02579073]
 ...
 [0.03087419 0.0362114  0.03398399 ... 0.02221027 0.00919505 0.00671799]
 [0.03100982 0.02714348 0.02359328 ... 0.01336309 0.01211773 0.00889474]
 [0.03117295 0.03125404 0.02717499 ... 0.01123438 0.00738504 0.00602503]]

-* TASK 10/20 | SAMPLE 96/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 478/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From context sentence 7, "Mary is either in the park or the bedroom", we can infer that Mary is in one of these two locations, but we don't have enough information to determine which one.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '7', ',', ' "', 'Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' bedroom', '",', ' we', ' can', ' infer', ' that', ' Mary', ' is', ' in', ' one', ' of', ' these', ' two', ' locations', ',', ' but', ' we', ' don', "'t", ' have', ' enough', ' information', ' to', ' determine', ' which', ' one', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 38), x_tokens=38, y_tokens=49, max_supp_attn=0.0, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 38)
DEBUG result.interpretability.attn_scores 1862 
 [[0.01865622 0.02746288 0.02629944 ... 0.02061598 0.01559484 0.02387793]
 [0.0189542  0.02188209 0.02340422 ... 0.02113749 0.02295183 0.02574077]
 [0.01952923 0.0278942  0.02964042 ... 0.01612492 0.01376874 0.01911905]
 ...
 [0.01965808 0.02466517 0.02266651 ... 0.0189299  0.01236322 0.02231084]
 [0.02008531 0.01967768 0.01701074 ... 0.01979025 0.01683835 0.01748187]
 [0.02023748 0.01872429 0.01645551 ... 0.0199523  0.01427194 0.01913249]]

-* TASK 10/20 | SAMPLE 96/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 479/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From context sentence 11, "Bill is in the kitchen", we can infer that Bill's location is explicitly stated as the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '11', ',', ' "', 'Bill', ' is', ' in', ' the', ' kitchen', '",', ' we', ' can', ' infer', ' that', ' Bill', "'s", ' location', ' is', ' explicitly', ' stated', ' as', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.1176, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02761154 0.03468739 0.03769867 ... 0.01222908 0.01512892 0.04023388]
 [0.02797312 0.03451504 0.03673184 ... 0.01560691 0.01342143 0.02071507]
 [0.02876971 0.03372917 0.03800021 ... 0.0173843  0.02525276 0.03939674]
 ...
 [0.02889539 0.0374245  0.03582403 ... 0.0097201  0.00798524 0.06531867]
 [0.02912734 0.03167515 0.02893811 ... 0.01175616 0.00758956 0.04222493]
 [0.02931122 0.03397584 0.03181947 ... 0.00992799 0.00756446 0.02646917]]

-* TASK 10/20 | SAMPLE 96/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 480/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: From context sentence 13, "Julie is in the cinema", we can infer that Julie's location is explicitly stated as the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '13', ',', ' "', 'Jul', 'ie', ' is', ' in', ' the', ' cinema', '",', ' we', ' can', ' infer', ' that', ' Julie', "'s", ' location', ' is', ' explicitly', ' stated', ' as', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02701035 0.03391501 0.03978356 ... 0.01069382 0.0176963  0.02441843]
 [0.02720937 0.05417163 0.05680203 ... 0.02496625 0.03008682 0.03429619]
 [0.02811449 0.03395812 0.04362224 ... 0.00956095 0.01426803 0.0202489 ]
 ...
 [0.02826712 0.03870663 0.03386302 ... 0.01146427 0.01399488 0.0189962 ]
 [0.02852809 0.02938616 0.02481356 ... 0.01991276 0.01942686 0.02044626]
 [0.02833435 0.03437692 0.02870319 ... 0.01300035 0.01658121 0.02299012]]
Model's predictions for the sample 96:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  From context sentence 2, "Fred travelled  |
|          |                 |   to the school", we can infer that Fred   |
|          |                 |          has moved to the school.          |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |      From context sentence 4, "Julie       |
|          |                 |   travelled to the office", we can infer   |
|          |                 |    that Julie has moved to the office.     |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  From context sentence 7, "Mary is either  |
|          |                 |    in the park or the bedroom", we can     |
|          |                 |   infer that Mary is in one of these two   |
|          |                 |    locations, but we don't have enough     |
|          |                 |    information to determine which one.     |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   From context sentence 11, "Bill is in    |
|          |                 |   the kitchen", we can infer that Bill's   |
|          |                 |    location is explicitly stated as the    |
|          |                 |                  kitchen.                  |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   From context sentence 13, "Julie is in   |
|          |                 |   the cinema", we can infer that Julie's   |
|          |                 |    location is explicitly stated as the    |
|          |                 |                  cinema.                   |
+----------+-----------------+--------------------------------------------+

Metrics for sample 96:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.07 ± 0.06 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 97/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 481/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: The context sentence 2 explicitly states that "Bill is in the office". This contradicts the information in sentence 1, which implies that Bill was in the kitchen previously, but sentence 2 provides the current location of Bill, which is the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' "', 'Bill', ' is', ' in', ' the', ' office', '".', ' This', ' contrad', 'icts', ' the', ' information', ' in', ' sentence', ' ', '1', ',', ' which', ' implies', ' that', ' Bill', ' was', ' in', ' the', ' kitchen', ' previously', ',', ' but', ' sentence', ' ', '2', ' provides', ' the', ' current', ' location', ' of', ' Bill', ',', ' which', ' is', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(62, 26), x_tokens=26, y_tokens=62, max_supp_attn=0.1935, attn_on_target=0.0161)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (62, 26)
DEBUG result.interpretability.attn_scores 1612 
 [[0.01458433 0.02808784 0.03227931 ... 0.00911153 0.00799906 0.01574291]
 [0.01452332 0.04313799 0.03221498 ... 0.02463088 0.01936806 0.02409197]
 [0.01588405 0.03618834 0.02144155 ... 0.00369144 0.00311998 0.00711179]
 ...
 [0.0156833  0.01592864 0.01680177 ... 0.00425306 0.00317998 0.00964594]
 [0.01575491 0.01218685 0.01300969 ... 0.00759423 0.00657343 0.01411183]
 [0.01578975 0.01615554 0.01626045 ... 0.00622901 0.00531266 0.01035638]]

-* TASK 10/20 | SAMPLE 97/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 482/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that "Julie moved to the kitchen", which implies that Julie is currently in the kitchen. There is no information provided about Julie being in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' "', 'Jul', 'ie', ' moved', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' kitchen', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 32), x_tokens=32, y_tokens=44, max_supp_attn=0.0227, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 32)
DEBUG result.interpretability.attn_scores 1408 
 [[0.0210782  0.03228746 0.03608332 ... 0.05829304 0.01517482 0.01244932]
 [0.02166    0.03179717 0.03394945 ... 0.06295609 0.02309039 0.01875674]
 [0.02212875 0.03053465 0.03529131 ... 0.05521387 0.02494328 0.02015451]
 ...
 [0.02209232 0.03085184 0.03002749 ... 0.02034571 0.01150576 0.00935055]
 [0.02244766 0.02441383 0.02241725 ... 0.0096657  0.00971044 0.0092883 ]
 [0.02251388 0.02391214 0.02216559 ... 0.00974721 0.00979293 0.00925576]]

-* TASK 10/20 | SAMPLE 97/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 483/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Julie's location in the given context sentences. The context sentences only mention Fred and Mary, but not Julie.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' and', ' Mary', ',', ' but', ' not', ' Julie', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 38), x_tokens=38, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 38)
DEBUG result.interpretability.attn_scores 1368 
 [[0.02577706 0.03203349 0.02672956 ... 0.00985612 0.05485127 0.03208831]
 [0.0261683  0.02488916 0.02398046 ... 0.01629714 0.02654522 0.02220063]
 [0.02699027 0.0290593  0.0290913  ... 0.01340417 0.03938803 0.02171641]
 ...
 [0.02742755 0.02874038 0.02472528 ... 0.01638643 0.04804008 0.02997674]
 [0.02790011 0.02891071 0.02665762 ... 0.01561005 0.05870588 0.02825745]
 [0.02799622 0.02536392 0.02489129 ... 0.01590701 0.11364038 0.02908341]]

-* TASK 10/20 | SAMPLE 97/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 484/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that "Julie went to the cinema", but it does not provide direct information about Bill's location. However, sentence 10 mentions that Bill is either in the cinema or the bedroom, and since Julie is in the cinema, it is possible that Bill is also in the cinema.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' "', 'Jul', 'ie', ' went', ' to', ' the', ' cinema', '",', ' but', ' it', ' does', ' not', ' provide', ' direct', ' information', ' about', ' Bill', "'s", ' location', '.', ' However', ',', ' sentence', ' ', '10', ' mentions', ' that', ' Bill', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' bedroom', ',', ' and', ' since', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' it', ' is', ' possible', ' that', ' Bill', ' is', ' also', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(70, 44), x_tokens=44, y_tokens=70, max_supp_attn=0.1286, attn_on_target=0.0143)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (70, 44)
DEBUG result.interpretability.attn_scores 3080 
 [[0.01297586 0.02093056 0.02016752 ... 0.02213601 0.02310748 0.07622774]
 [0.01340381 0.01591189 0.01457552 ... 0.01537815 0.01474299 0.03802159]
 [0.01361199 0.02191945 0.02292645 ... 0.01930995 0.01501546 0.05971067]
 ...
 [0.01375029 0.02027515 0.01777506 ... 0.02309609 0.01867707 0.02520248]
 [0.01416267 0.01767281 0.01406945 ... 0.02050983 0.0155504  0.00940171]
 [0.01412369 0.01785401 0.01442282 ... 0.01665885 0.02219279 0.01579658]]

-* TASK 10/20 | SAMPLE 97/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 485/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 14 states that "Mary journeyed to the school", which implies that Mary has moved to the school and is currently there.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' "', 'Mary', ' journey', 'ed', ' to', ' the', ' school', '",', ' which', ' implies', ' that', ' Mary', ' has', ' moved', ' to', ' the', ' school', ' and', ' is', ' currently', ' there', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 50), x_tokens=50, y_tokens=36, max_supp_attn=0.1389, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 50)
DEBUG result.interpretability.attn_scores 1800 
 [[0.02585715 0.03485815 0.03828478 ... 0.00918517 0.01272677 0.0544646 ]
 [0.02629586 0.02988067 0.03241818 ... 0.01649473 0.02913641 0.01960753]
 [0.02695176 0.03981308 0.04768374 ... 0.01364296 0.02322888 0.04733423]
 ...
 [0.027131   0.04280362 0.03856506 ... 0.00591706 0.01087427 0.09767739]
 [0.02738486 0.03444543 0.02925596 ... 0.0091489  0.01231311 0.06468704]
 [0.02737768 0.03966423 0.03285679 ... 0.0075437  0.01236568 0.0855605 ]]
Model's predictions for the sample 97:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 2 explicitly states  |
|          |                 |     that "Bill is in the office". This     |
|          |                 |  contradicts the information in sentence   |
|          |                 |   1, which implies that Bill was in the    |
|          |                 |     kitchen previously, but sentence 2     |
|          |                 |   provides the current location of Bill,   |
|          |                 |            which is the office.            |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |     The context sentence 4 states that     |
|          |                 |    "Julie moved to the kitchen", which     |
|          |                 |   implies that Julie is currently in the   |
|          |                 |      kitchen. There is no information      |
|          |                 |  provided about Julie being in the park.   |
+----------+-----------------+--------------------------------------------+
|   yes    |  not mentioned  |   There is no information provided about   |
|          |                 |   Julie's location in the given context    |
|          |                 |   sentences. The context sentences only    |
|          |                 |   mention Fred and Mary, but not Julie.    |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |    The context sentence 11 states that     |
|          |                 |  "Julie went to the cinema", but it does   |
|          |                 |    not provide direct information about    |
|          |                 |   Bill's location. However, sentence 10    |
|          |                 |    mentions that Bill is either in the     |
|          |                 |   cinema or the bedroom, and since Julie   |
|          |                 |   is in the cinema, it is possible that    |
|          |                 |        Bill is also in the cinema.         |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |    The context sentence 14 states that     |
|          |                 |   "Mary journeyed to the school", which    |
|          |                 |     implies that Mary has moved to the     |
|          |                 |       school and is currently there.       |
+----------+-----------------+--------------------------------------------+

Metrics for sample 97:
+----------------------------+------------+
|           Metric           |   Before   |
+----------------------------+------------+
|    Exact-match accuracy    |    0.8     |
|    Soft-match accuracy     |    0.8     |
| Max attention distribution | 0.1 ± 0.07 |
+----------------------------+------------+

-* TASK 10/20 | SAMPLE 98/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 486/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 2 states that Bill is either in the park or the cinema, but it does not provide a definitive location. Therefore, we can only conclude that Bill might be in the park, but we cannot be certain.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' park', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 26), x_tokens=26, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 26)
DEBUG result.interpretability.attn_scores 1378 
 [[0.01737377 0.0349368  0.03583432 ... 0.0179815  0.00315437 0.02142977]
 [0.01792905 0.02151035 0.02107712 ... 0.0128979  0.00289098 0.01436332]
 [0.01822675 0.02451477 0.02764727 ... 0.01708293 0.00389411 0.01417375]
 ...
 [0.01833096 0.02049363 0.02071318 ... 0.01106559 0.00278189 0.01261131]
 [0.01835048 0.01699286 0.01699883 ... 0.0153501  0.00742302 0.01530329]
 [0.01846365 0.01842505 0.01810352 ... 0.01410193 0.00531921 0.01473136]]

-* TASK 10/20 | SAMPLE 98/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 487/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Bill moved to the bedroom, which means Bill is not in the park. The previous information about Bill being either in the park or the cinema (sentence 2) is no longer relevant.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' park', '.', ' The', ' previous', ' information', ' about', ' Bill', ' being', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', ' (', 'sentence', ' ', '2', ')', ' is', ' no', ' longer', ' relevant', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0192, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01781251 0.0261207  0.0302043  ... 0.00687915 0.00673381 0.0116252 ]
 [0.01829989 0.02645704 0.02819068 ... 0.0086032  0.00812657 0.01967949]
 [0.01870542 0.0236016  0.02899526 ... 0.01292758 0.00823064 0.01895796]
 ...
 [0.01878063 0.02588456 0.02472119 ... 0.00402283 0.00678723 0.00898752]
 [0.01899427 0.02010484 0.01840059 ... 0.00465891 0.01017079 0.00939642]
 [0.01899662 0.02161403 0.01939571 ... 0.0035931  0.00804054 0.00807738]]

-* TASK 10/20 | SAMPLE 98/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 488/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 7 explicitly states that Bill is in the cinema.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 38), x_tokens=38, y_tokens=21, max_supp_attn=0.0, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 38)
DEBUG result.interpretability.attn_scores 798 
 [[0.04541782 0.05979652 0.06661058 0.08395412 0.06509475 0.06942598
  0.05437404 0.05912124 0.06776087 0.06773786 0.04591263 0.0576793
  0.05505968 0.10129529 0.1075694  0.04090907 0.03612579 0.04006962
  0.03549111 0.04273516 0.03244642 0.04900948 0.07489408 0.03168311
  0.01339172 0.04672109 0.05658655 0.05524381 0.12254184 0.01732994
  0.02154173 0.02800184 0.01946067 0.0348899  0.02662614 0.06562895
  0.06612718 0.06300062]
 [0.04552479 0.05005757 0.05104218 0.04827131 0.03591353 0.04654218
  0.04286755 0.04996328 0.04993267 0.04365811 0.03719054 0.04397225
  0.05322816 0.0420822  0.06049346 0.03960095 0.03415156 0.04040855
  0.04012538 0.0473369  0.0369237  0.04373438 0.05954529 0.04304503
  0.02573171 0.05082002 0.04800054 0.0387041  0.08224925 0.03700397
  0.02893411 0.02737837 0.02676528 0.03886642 0.03759941 0.03566568
  0.04168304 0.05474954]
 [0.04721377 0.063821   0.06979888 0.09722254 0.08285311 0.10028411
  0.06544098 0.06609108 0.07309078 0.0827854  0.05633283 0.08111673
  0.07631412 0.15578473 0.10695735 0.04258309 0.03429588 0.03602483
  0.03410026 0.03792425 0.02947706 0.05203959 0.06146389 0.03062974
  0.01394805 0.03607868 0.05624852 0.03947318 0.10946069 0.02993209
  0.02538996 0.05238083 0.0283214  0.05972438 0.03523821 0.06550686
  0.05842249 0.04577851]
 [0.04591656 0.05333176 0.05849737 0.04776631 0.03797106 0.05003741
  0.04736654 0.05279406 0.05071885 0.04448324 0.04030821 0.05095626
  0.04922867 0.03547988 0.03202436 0.04266469 0.03434013 0.03645046
  0.03688197 0.04064933 0.03291467 0.05301521 0.06817899 0.05132724
  0.02524426 0.04640359 0.0613528  0.04313372 0.08665518 0.07800492
  0.0380042  0.05951206 0.05166322 0.06957836 0.0446402  0.04077564
  0.04220754 0.06983375]
 [0.0464887  0.05775722 0.05511687 0.03185412 0.02481914 0.03808915
  0.04384709 0.04457332 0.04513897 0.03101597 0.03511322 0.03659058
  0.03983304 0.02389878 0.02117365 0.04085496 0.03004052 0.03105258
  0.03473834 0.03742967 0.031536   0.04898588 0.07183156 0.0472971
  0.03136656 0.04060254 0.06243451 0.0302146  0.06528453 0.09117378
  0.03729747 0.047939   0.05697234 0.04496189 0.03344001 0.02112108
  0.03381724 0.07583113]
 [0.04746159 0.07979347 0.07324043 0.04049179 0.02893421 0.04593118
  0.05812895 0.05287057 0.06324939 0.03666662 0.03799932 0.0438178
  0.04769553 0.02570817 0.02218255 0.05198387 0.03798744 0.03808992
  0.03995474 0.04491483 0.03404845 0.04520603 0.08880028 0.04734213
  0.02812394 0.03779035 0.06277253 0.02872968 0.05107379 0.10828885
  0.03450619 0.04415235 0.03610201 0.04106059 0.03098676 0.0215949
  0.03707526 0.09228322]
 [0.04747572 0.05042902 0.04894152 0.03425035 0.02512659 0.03620802
  0.04701491 0.04071734 0.04672343 0.03005455 0.0343984  0.03322285
  0.03654457 0.02247628 0.02085536 0.04515553 0.03446809 0.03275116
  0.0376964  0.03971099 0.03239767 0.04221468 0.05458228 0.05376367
  0.0257582  0.0356442  0.05655275 0.02741633 0.03165925 0.09224186
  0.03321855 0.03738922 0.02121817 0.03026188 0.02834084 0.02098512
  0.03652121 0.05836174]
 [0.04776608 0.02749489 0.02656011 0.02253321 0.01624215 0.02385323
  0.02780394 0.02524368 0.03049179 0.02103708 0.02748851 0.02302379
  0.0267966  0.01389224 0.01407949 0.02904493 0.02650289 0.02796019
  0.03323277 0.03740817 0.03151672 0.03284788 0.03067946 0.05175181
  0.0270828  0.03512616 0.03025386 0.02556905 0.01918642 0.04514742
  0.03042098 0.01915517 0.01224759 0.01938158 0.02521755 0.01586822
  0.02979393 0.03716276]
 [0.0472249  0.04382159 0.04628235 0.03543197 0.02497418 0.03833692
  0.04361791 0.04189938 0.04281671 0.03342506 0.0382678  0.03967072
  0.0392712  0.02235802 0.01998311 0.04728219 0.03800476 0.04497356
  0.04304473 0.04691856 0.04028649 0.05025734 0.04511419 0.06179983
  0.05597501 0.0419227  0.05036676 0.03296407 0.03802901 0.09369379
  0.05060376 0.0994674  0.15319555 0.05856546 0.04582616 0.02624215
  0.03463084 0.04966304]
 [0.04846094 0.05912495 0.06043071 0.05366449 0.03512257 0.05685949
  0.06428249 0.06352808 0.05343622 0.05524674 0.05980623 0.0730853
  0.06409027 0.03455407 0.02623366 0.05373691 0.04695227 0.05200959
  0.05015099 0.05203833 0.04483633 0.05267511 0.04722464 0.06209735
  0.06859581 0.04153596 0.05161748 0.04384807 0.04223437 0.07649875
  0.06111038 0.12444167 0.16447285 0.10781369 0.07341561 0.03938126
  0.04030554 0.05102621]
 [0.04928306 0.04351163 0.04631852 0.04021454 0.02901567 0.04304454
  0.05085145 0.04609582 0.04135723 0.03948827 0.04612406 0.04689261
  0.04753047 0.02578589 0.02105664 0.04605738 0.03817505 0.03801898
  0.04131979 0.04254163 0.03880804 0.04714463 0.03547052 0.05684015
  0.05180251 0.03478956 0.03985397 0.04219159 0.03391181 0.07460178
  0.0578074  0.07497217 0.05814401 0.07093234 0.06003404 0.03046831
  0.0366152  0.03638492]
 [0.0484889  0.03420318 0.03181516 0.02588002 0.01987371 0.02794744
  0.03755228 0.03520114 0.03092721 0.0262678  0.04096933 0.03245237
  0.03757935 0.01638417 0.01531259 0.05820239 0.04259493 0.04349568
  0.04515682 0.04525302 0.04877054 0.04638605 0.02696353 0.06823745
  0.07369023 0.04048795 0.02910455 0.04867259 0.02497265 0.05574481
  0.06049383 0.04155101 0.0343262  0.04624575 0.06380811 0.02007634
  0.03259547 0.02965665]
 [0.04814168 0.03570867 0.03161617 0.02668537 0.01913794 0.02835638
  0.04371209 0.04103867 0.03233428 0.02628622 0.04070086 0.03042321
  0.04021712 0.01583679 0.01454098 0.06707751 0.04076213 0.04877927
  0.04725314 0.04921161 0.05743826 0.04451235 0.02355893 0.06824227
  0.09079878 0.03909857 0.02616367 0.04351974 0.01754329 0.04082223
  0.05191237 0.03390374 0.0283214  0.03616101 0.06714334 0.01573571
  0.03091186 0.02744833]
 [0.04890949 0.03154643 0.02987278 0.02483703 0.01942174 0.02811583
  0.03556807 0.03540006 0.0303668  0.02659196 0.04252984 0.03572069
  0.03633507 0.0163622  0.01440352 0.05409336 0.0470504  0.04806069
  0.05551079 0.04837102 0.05488839 0.04288519 0.02129824 0.05378779
  0.10879216 0.04414524 0.02910455 0.0453537  0.01808384 0.03883209
  0.07847882 0.0446226  0.04693994 0.04729248 0.07512818 0.0198259
  0.02970711 0.02592238]
 [0.04876737 0.03009997 0.02902031 0.02103804 0.01751136 0.02639828
  0.03896508 0.03520879 0.02991122 0.02365981 0.05315476 0.03447621
  0.03710322 0.01459843 0.01343963 0.07187625 0.05524651 0.05919012
  0.0679711  0.05735555 0.06486563 0.04384521 0.02030636 0.06516579
  0.11861011 0.07341545 0.02626508 0.05207726 0.01569297 0.02458262
  0.10176116 0.03211961 0.03352068 0.04357477 0.07194922 0.01525288
  0.03107655 0.02477674]
 [0.04725837 0.03129305 0.02937079 0.02127898 0.01728012 0.0281471
  0.0395145  0.03574435 0.03738197 0.0268756  0.03834834 0.03128245
  0.03629698 0.0153874  0.0137882  0.04748232 0.04206289 0.0476009
  0.05868394 0.05414567 0.05409248 0.04527304 0.02505942 0.05933286
  0.09807349 0.12371982 0.0296116  0.06284295 0.02204455 0.02131996
  0.08574328 0.0317427  0.03430789 0.03277095 0.05224186 0.01917033
  0.03668054 0.03323129]
 [0.04944722 0.03413922 0.0367898  0.03151745 0.02451958 0.04105276
  0.04531327 0.04533074 0.03961553 0.03676977 0.04527165 0.04431489
  0.0455339  0.0261677  0.01919187 0.03684728 0.03491739 0.04001182
  0.04715133 0.04318478 0.04217536 0.046912   0.02271547 0.02894756
  0.03791804 0.0446967  0.03076091 0.03690119 0.02506908 0.02255493
  0.07717441 0.07987543 0.07967339 0.07749571 0.07516029 0.03645791
  0.03443751 0.02679569]
 [0.04802897 0.04661117 0.05066909 0.07533955 0.05956069 0.0721779
  0.05460637 0.05638991 0.06588613 0.08428831 0.05866186 0.06702977
  0.06673438 0.11451346 0.11080963 0.03588187 0.04178773 0.04329469
  0.03992463 0.04336267 0.03691803 0.05104458 0.04458205 0.02402648
  0.01683304 0.04048318 0.05026536 0.05356367 0.0581753  0.01513884
  0.03155762 0.04000993 0.03291654 0.05164383 0.04126216 0.12857251
  0.06525897 0.04155593]
 [0.0476472  0.05966368 0.05741878 0.10014027 0.19712628 0.08872313
  0.05716511 0.05897205 0.06063281 0.1074103  0.08362334 0.07477182
  0.05851003 0.15274711 0.19082063 0.05198044 0.08222756 0.07133239
  0.05655464 0.05423755 0.06429534 0.04960201 0.06080686 0.02496566
  0.01804902 0.04382057 0.07727411 0.05890584 0.0602339  0.01122949
  0.02498102 0.02677603 0.02123648 0.02777831 0.0265769  0.13816738
  0.08178718 0.04859565]
 [0.04736076 0.05360728 0.04990027 0.07071871 0.13921319 0.05042951
  0.04557071 0.05237709 0.04580823 0.08271172 0.075804   0.06296257
  0.05046343 0.05706413 0.08620673 0.05455459 0.1380465  0.10900193
  0.08824313 0.06934079 0.11953407 0.0483925  0.05499677 0.03875114
  0.04269191 0.0492874  0.06706554 0.09194386 0.03728734 0.0151903
  0.03918488 0.03097128 0.03829889 0.03471778 0.0486155  0.10700259
  0.05696712 0.04899788]
 [0.04771613 0.05418782 0.05068718 0.06690981 0.08028843 0.0600396
  0.05643673 0.06143942 0.06241886 0.07353954 0.06199431 0.05653778
  0.0556342  0.06762312 0.06887718 0.04213044 0.08425951 0.07142303
  0.06681398 0.06592955 0.07183041 0.06401677 0.06192726 0.03096585
  0.02752257 0.0534102  0.05834432 0.09873101 0.03861088 0.01066763
  0.02987782 0.02363751 0.02189554 0.02628281 0.03674955 0.11650035
  0.1433782  0.05894394]]

-* TASK 10/20 | SAMPLE 98/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 489/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 states that Bill moved to the kitchen, which means Bill is not in the bedroom. The previous information about Bill being either in the bedroom or the park (sentence 10) is no longer relevant.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' bedroom', '.', ' The', ' previous', ' information', ' about', ' Bill', ' being', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' park', ' (', 'sentence', ' ', '10', ')', ' is', ' no', ' longer', ' relevant', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 44), x_tokens=44, y_tokens=52, max_supp_attn=0.0, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 44)
DEBUG result.interpretability.attn_scores 2288 
 [[0.01790938 0.02706126 0.02555837 ... 0.01822321 0.07872756 0.03522183]
 [0.01828219 0.01760641 0.01634287 ... 0.01271924 0.03403391 0.04317534]
 [0.01867235 0.02720525 0.02727331 ... 0.01470882 0.04578539 0.04479852]
 ...
 [0.01882904 0.02795452 0.02785764 ... 0.02747251 0.03129158 0.00943899]
 [0.01926461 0.02138811 0.0203399  ... 0.02968917 0.01830605 0.00639741]
 [0.01917918 0.02254129 0.02064065 ... 0.02830448 0.02536234 0.00539313]]

-* TASK 10/20 | SAMPLE 98/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 490/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 11 (from previous questions) states that Bill moved to the kitchen, and there is no new information that contradicts this.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' (', 'from', ' previous', ' questions', ')', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' contrad', 'icts', ' this', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 50), x_tokens=50, y_tokens=36, max_supp_attn=0.0, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 50)
DEBUG result.interpretability.attn_scores 1800 
 [[0.02576392 0.03135304 0.02852269 ... 0.01669127 0.01590662 0.03412112]
 [0.02613848 0.0283939  0.02943773 ... 0.0222983  0.02763055 0.01992661]
 [0.02700918 0.03147727 0.03182327 ... 0.0232954  0.02076459 0.03530025]
 ...
 [0.02724552 0.03312162 0.02768366 ... 0.00902914 0.00997131 0.07312569]
 [0.02750998 0.02430805 0.01925387 ... 0.01086024 0.00986052 0.05786913]
 [0.02743749 0.02689449 0.02104303 ... 0.00978731 0.00991328 0.03952605]]
Model's predictions for the sample 98:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 2 states that Bill   |
|          |                 |  is either in the park or the cinema, but  |
|          |                 |      it does not provide a definitive      |
|          |                 |      location. Therefore, we can only      |
|          |                 |  conclude that Bill might be in the park,  |
|          |                 |         but we cannot be certain.          |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 4 states that Bill   |
|          |                 |   moved to the bedroom, which means Bill   |
|          |                 |      is not in the park. The previous      |
|          |                 |   information about Bill being either in   |
|          |                 |   the park or the cinema (sentence 2) is   |
|          |                 |            no longer relevant.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 7 explicitly states  |
|          |                 |        that Bill is in the cinema.         |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 11 states that Bill  |
|          |                 |   moved to the kitchen, which means Bill   |
|          |                 |    is not in the bedroom. The previous     |
|          |                 |   information about Bill being either in   |
|          |                 |  the bedroom or the park (sentence 10) is  |
|          |                 |            no longer relevant.             |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   The context sentence 11 (from previous   |
|          |                 |  questions) states that Bill moved to the  |
|          |                 |  kitchen, and there is no new information  |
|          |                 |           that contradicts this.           |
+----------+-----------------+--------------------------------------------+

Metrics for sample 98:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     1.0     |
|    Soft-match accuracy     |     1.0     |
| Max attention distribution | 0.06 ± 0.05 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 99/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 491/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 1 states that Fred is either in the school or the park, but it does not provide a definitive location. Therefore, we cannot conclude that Fred is definitely in the park.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' park', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 26), x_tokens=26, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 26)
DEBUG result.interpretability.attn_scores 1222 
 [[0.01955726 0.03397959 0.03735208 ... 0.01022553 0.01446411 0.0235419 ]
 [0.01997173 0.03855622 0.03935595 ... 0.00419634 0.00816511 0.02811388]
 [0.02039798 0.02396058 0.02378581 ... 0.0039801  0.00713936 0.02022575]
 ...
 [0.02078691 0.02390782 0.02338218 ... 0.00367264 0.00623188 0.01919226]
 [0.02081458 0.01948056 0.01933479 ... 0.010931   0.0135952  0.01998745]
 [0.0210798  0.01959434 0.01925484 ... 0.00831579 0.01102962 0.01802442]]

-* TASK 10/20 | SAMPLE 99/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 492/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 4 states that Fred is either in the bedroom or the office, but it does not provide a definitive location. Therefore, we cannot conclude that Fred is definitely in the bedroom.

Answer: maybe


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0435, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02023363 0.03129756 0.03577613 ... 0.00578709 0.0083157  0.00853143]
 [0.02086924 0.0295296  0.03297801 ... 0.00735015 0.01041039 0.01030089]
 [0.02121929 0.02695537 0.03391907 ... 0.01358154 0.01492239 0.01485763]
 ...
 [0.02127715 0.02866596 0.02883043 ... 0.00409251 0.00499048 0.00488374]
 [0.02157944 0.02183507 0.02037233 ... 0.00707187 0.00634353 0.00719321]
 [0.0216107  0.02407761 0.02261794 ... 0.00501746 0.00525026 0.0062567 ]]

-* TASK 10/20 | SAMPLE 99/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 493/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentences 7 and 8 provide information about Mary's location, but they do not mention Bill's location. However, we can refer back to context sentence 2, which states that Bill went to the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' provide', ' information', ' about', ' Mary', "'s", ' location', ',', ' but', ' they', ' do', ' not', ' mention', ' Bill', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' back', ' to', ' context', ' sentence', ' ', '2', ',', ' which', ' states', ' that', ' Bill', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 38), x_tokens=38, y_tokens=52, max_supp_attn=0.0962, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 38)
DEBUG result.interpretability.attn_scores 1976 
 [[0.01774033 0.02494713 0.02615519 ... 0.02383834 0.01308332 0.00980474]
 [0.01796294 0.02477986 0.02898738 ... 0.01807683 0.01287558 0.01372433]
 [0.018627   0.02474733 0.0257444  ... 0.01641865 0.01018584 0.0087985 ]
 ...
 [0.01884748 0.02117709 0.01915356 ... 0.0181416  0.00874691 0.00779994]
 [0.01913208 0.01633281 0.01413257 ... 0.0149081  0.01106329 0.01128257]
 [0.0191088  0.01871917 0.01586879 ... 0.02111864 0.00990183 0.00944394]]

-* TASK 10/20 | SAMPLE 99/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 494/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 8 states that Mary journeyed to the school, but it does not provide a current location. However, we can infer that Mary is likely to be in the school since she journeyed there.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' school', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' current', ' location', '.', ' However', ',', ' we', ' can', ' infer', ' that', ' Mary', ' is', ' likely', ' to', ' be', ' in', ' the', ' school', ' since', ' she', ' journey', 'ed', ' there', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 44), x_tokens=44, y_tokens=50, max_supp_attn=0.0, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 44)
DEBUG result.interpretability.attn_scores 2200 
 [[0.01838667 0.02616056 0.02726941 ... 0.03809896 0.09524295 0.010216  ]
 [0.01863781 0.02345285 0.02451152 ... 0.02277704 0.05660861 0.02688626]
 [0.01917077 0.02924443 0.03138511 ... 0.02767642 0.07856265 0.01932124]
 ...
 [0.01944005 0.02630446 0.02861809 ... 0.03446859 0.03401368 0.00716978]
 [0.02004241 0.02172346 0.0215298  ... 0.02669935 0.01486438 0.00762451]
 [0.01982963 0.02183076 0.02246737 ... 0.03689869 0.02212803 0.00673705]]

-* TASK 10/20 | SAMPLE 99/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 495/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: The context sentence 1 stated that Fred is either in the school or the park, but later context sentences updated Fred's location. The latest information is that Fred moved to the school (sentence 10) and then went to the bedroom (sentence 13). There is no current information suggesting that Fred is in the park.

Answer: no


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' stated', ' that', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' park', ',', ' but', ' later', ' context', ' sentences', ' updated', ' Fred', "'s", ' location', '.', ' The', ' latest', ' information', ' is', ' that', ' Fred', ' moved', ' to', ' the', ' school', ' (', 'sentence', ' ', '10', ')', ' and', ' then', ' went', ' to', ' the', ' bedroom', ' (', 'sentence', ' ', '13', ').', ' There', ' is', ' no', ' current', ' information', ' suggesting', ' that', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(72, 50), x_tokens=50, y_tokens=72, max_supp_attn=0.0278, attn_on_target=0.0139)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (72, 50)
DEBUG result.interpretability.attn_scores 3600 
 [[0.0126801  0.01760138 0.01985835 ... 0.01578585 0.03334974 0.02521436]
 [0.01288221 0.01342452 0.01473789 ... 0.01174021 0.0128238  0.01589334]
 [0.01322814 0.01973879 0.02322857 ... 0.02264321 0.02936404 0.02446845]
 ...
 [0.01347101 0.02362621 0.02251712 ... 0.01284699 0.06653698 0.02598494]
 [0.01386933 0.01846191 0.01585573 ... 0.01215016 0.04076847 0.01603411]
 [0.01366593 0.01889385 0.01683996 ... 0.00960396 0.06054154 0.02734602]]
Model's predictions for the sample 99:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 1 states that Fred   |
|          |                 |  is either in the school or the park, but  |
|          |                 |      it does not provide a definitive      |
|          |                 |  location. Therefore, we cannot conclude   |
|          |                 |    that Fred is definitely in the park.    |
+----------+-----------------+--------------------------------------------+
|  maybe   |      maybe      |  The context sentence 4 states that Fred   |
|          |                 |  is either in the bedroom or the office,   |
|          |                 |    but it does not provide a definitive    |
|          |                 |  location. Therefore, we cannot conclude   |
|          |                 |  that Fred is definitely in the bedroom.   |
+----------+-----------------+--------------------------------------------+
|    no    |       yes       |   The context sentences 7 and 8 provide    |
|          |                 |   information about Mary's location, but   |
|          |                 |    they do not mention Bill's location.    |
|          |                 |   However, we can refer back to context    |
|          |                 |  sentence 2, which states that Bill went   |
|          |                 |              to the kitchen.               |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |  The context sentence 8 states that Mary   |
|          |                 |  journeyed to the school, but it does not  |
|          |                 |  provide a current location. However, we   |
|          |                 |   can infer that Mary is likely to be in   |
|          |                 |   the school since she journeyed there.    |
+----------+-----------------+--------------------------------------------+
|    no    |        no       |  The context sentence 1 stated that Fred   |
|          |                 |  is either in the school or the park, but  |
|          |                 |   later context sentences updated Fred's   |
|          |                 |  location. The latest information is that  |
|          |                 |   Fred moved to the school (sentence 10)   |
|          |                 |   and then went to the bedroom (sentence   |
|          |                 |    13). There is no current information    |
|          |                 |    suggesting that Fred is in the park.    |
+----------+-----------------+--------------------------------------------+

Metrics for sample 99:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.8     |
|    Soft-match accuracy     |     0.8     |
| Max attention distribution | 0.05 ± 0.03 |
+----------------------------+-------------+

-* TASK 10/20 | SAMPLE 100/100 | PART 1/5 | 'init_prompt_reasoning' 1/1 | RUN ID 496/1000 *-


DEBUG starting interpretability
The output of the model:
assistant

Reasoning: According to context sentence 1, Fred travelled to the kitchen, which implies that Fred is currently in the kitchen.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02721596 0.04354205 0.05347333 0.07223881 0.07658678 0.07594351
  0.0614208  0.06967303 0.0547934  0.06245355 0.0438819  0.05958793
  0.06270823 0.09159196 0.06215812 0.02809783 0.03037587 0.02963529
  0.02798143 0.02977842 0.02533028 0.03761024 0.04168621 0.0162996
  0.01671637 0.03716901]
 [0.02764801 0.05358171 0.04957688 0.07094254 0.06123628 0.05979188
  0.04349332 0.04156737 0.04114949 0.04872832 0.03523324 0.03134208
  0.03152495 0.10484115 0.1025464  0.02859954 0.02599128 0.02075651
  0.02149532 0.02188109 0.02001091 0.0381685  0.04361056 0.01258092
  0.00877152 0.03076848]
 [0.02983025 0.05726979 0.03380807 0.05196817 0.0337235  0.03500151
  0.03112514 0.02228346 0.0214677  0.03232102 0.0241574  0.01644906
  0.01677277 0.02537449 0.03334122 0.01931701 0.01394276 0.01206938
  0.01599568 0.01611293 0.01533627 0.04248523 0.04888046 0.00752099
  0.00600278 0.0160911 ]
 [0.02809654 0.02693129 0.02803613 0.02435331 0.01857435 0.02619058
  0.03127878 0.02657622 0.02495185 0.02496695 0.02733294 0.02909106
  0.0269969  0.01340606 0.01225162 0.03555615 0.02956803 0.04352967
  0.03486963 0.04257876 0.03374907 0.0301139  0.03373895 0.06540514
  0.03926558 0.03633124]
 [0.02824124 0.04200487 0.04539965 0.06538592 0.05940298 0.04719755
  0.03438954 0.03013173 0.03370748 0.04555408 0.0322305  0.02577437
  0.02501015 0.09167039 0.09584962 0.03296647 0.02700347 0.01853206
  0.02098006 0.02163833 0.02184834 0.03773627 0.05970611 0.01288305
  0.0075307  0.03789011]
 [0.02882773 0.02699483 0.02698576 0.0488345  0.04551644 0.04049924
  0.02468093 0.02332286 0.02838369 0.04176713 0.02876893 0.02919304
  0.02681351 0.10480086 0.12384873 0.03273516 0.0306055  0.02236007
  0.02351181 0.02248827 0.02113432 0.03178786 0.03446639 0.00837411
  0.00710871 0.02483258]
 [0.0292509  0.03055366 0.03481151 0.05160877 0.04834314 0.05126289
  0.03307581 0.03194684 0.03656805 0.04902191 0.03342482 0.04615509
  0.04027867 0.08224468 0.07755866 0.02757743 0.02784554 0.02227501
  0.02223742 0.02176503 0.01991809 0.02895474 0.03192383 0.01178021
  0.0093614  0.02389408]
 [0.0282044  0.04084314 0.04631159 0.0404861  0.04407138 0.04750124
  0.0392633  0.0412828  0.03973829 0.0421827  0.03363614 0.05045622
  0.04217045 0.05038044 0.0460386  0.03772474 0.03628916 0.0297731
  0.0285723  0.02905062 0.02774053 0.03399587 0.04768587 0.03166825
  0.02133808 0.04036363]
 [0.02932035 0.03956806 0.04700688 0.04445704 0.04168076 0.05348431
  0.04279901 0.04563709 0.04843878 0.04724332 0.03351472 0.05000553
  0.04491806 0.03640921 0.02486801 0.02607328 0.02741219 0.02370199
  0.02482025 0.02487845 0.02268004 0.03468752 0.03636867 0.01723838
  0.01593261 0.03463186]
 [0.02865977 0.05059906 0.05414281 0.02781677 0.02373271 0.03626454
  0.04530493 0.04238702 0.04358019 0.02930989 0.02764348 0.03746063
  0.03855609 0.01657411 0.01479238 0.04288271 0.03536619 0.02914826
  0.03068893 0.03190556 0.03097585 0.03322198 0.06515148 0.03975112
  0.03506957 0.04113246]
 [0.02916515 0.06318384 0.06395824 0.02588246 0.02253573 0.03125689
  0.04453672 0.03882273 0.04565739 0.02617963 0.02515093 0.02939885
  0.03060144 0.01370691 0.01383519 0.0460889  0.03635152 0.02770801
  0.03173699 0.03466572 0.0310206  0.03021168 0.06912684 0.03242671
  0.02511499 0.03661491]
 [0.02934316 0.03513775 0.04044267 0.02021949 0.0180515  0.0231754
  0.03464431 0.03020974 0.03659774 0.0217374  0.02083477 0.02356916
  0.02395128 0.01159774 0.01212899 0.03819573 0.03184988 0.02454468
  0.02936998 0.03186197 0.0300215  0.0283495  0.05740409 0.04564224
  0.02699519 0.04299621]
 [0.02951945 0.01557755 0.01684577 0.01139323 0.01041796 0.01474385
  0.01648928 0.01661178 0.0193608  0.01351106 0.01406341 0.0143269
  0.01516809 0.00621093 0.00723431 0.02062721 0.02173972 0.01998273
  0.02685576 0.02993199 0.03041331 0.02115085 0.03942951 0.0591435
  0.03476597 0.05362066]
 [0.02946802 0.0233869  0.02477397 0.01618125 0.01497339 0.02062852
  0.02495418 0.02314707 0.02441028 0.01829227 0.02143018 0.02171631
  0.02207369 0.00921942 0.01014378 0.03592242 0.02603445 0.02448761
  0.0253295  0.02691132 0.02710739 0.02713953 0.03023072 0.05297246
  0.03910222 0.04228571]
 [0.02952301 0.02470603 0.0245323  0.0187213  0.01582997 0.02477429
  0.02864936 0.02818147 0.02557685 0.02227495 0.02615612 0.03007367
  0.03044643 0.01102076 0.00970527 0.03510581 0.02757082 0.0302185
  0.02788028 0.03027359 0.02993862 0.0291737  0.02198249 0.04761912
  0.03573783 0.02638814]
 [0.0290361  0.02129593 0.01757313 0.01417962 0.01109989 0.0156275
  0.02471593 0.02256364 0.02030537 0.0155407  0.02211666 0.01914711
  0.02324718 0.00720803 0.00690268 0.03780734 0.02474338 0.04672243
  0.0365401  0.04905089 0.0464825  0.02635428 0.01725063 0.0771113
  0.04920861 0.02738762]
 [0.02985957 0.0194389  0.01714453 0.01377041 0.01149035 0.01637302
  0.02188717 0.02036067 0.02039304 0.01586975 0.02638378 0.02090592
  0.02262496 0.00720964 0.00664894 0.03375014 0.02385814 0.04696289
  0.0319473  0.0526093  0.0373845  0.02209924 0.01381909 0.05330929
  0.04115815 0.01917902]
 [0.02978805 0.0169992  0.01494916 0.01082653 0.00930664 0.01308914
  0.02003763 0.01797971 0.01847846 0.01303166 0.03007767 0.01761183
  0.01993738 0.00582573 0.00601841 0.03191856 0.02712724 0.03722168
  0.03251063 0.03797477 0.03627103 0.02328046 0.01477779 0.0570075
  0.05314721 0.02225699]
 [0.02910027 0.02316452 0.02175895 0.01534668 0.01466858 0.02136647
  0.03328682 0.032672   0.02834692 0.0187901  0.02998661 0.02392458
  0.02881991 0.00834105 0.00848046 0.02448383 0.0331643  0.02951039
  0.03746497 0.03159944 0.03497624 0.02782349 0.02203014 0.0389555
  0.07536641 0.06152637]
 [0.0302956  0.02014215 0.0192875  0.01558359 0.01227017 0.01752819
  0.02165865 0.02205822 0.02158223 0.01712781 0.02548249 0.02191723
  0.02235424 0.00841357 0.00766682 0.02241405 0.02196423 0.02529585
  0.02655431 0.02375432 0.02684353 0.0264656  0.01458024 0.02639447
  0.03253184 0.02334198]
 [0.03041448 0.02231254 0.02523463 0.02269897 0.01743299 0.02614328
  0.02694082 0.03151943 0.02661192 0.02668881 0.0276645  0.03682856
  0.03332831 0.01337383 0.00909359 0.01964911 0.02082731 0.02376156
  0.02311672 0.02179088 0.02191066 0.02857348 0.01430599 0.01610418
  0.02648863 0.02248831]
 [0.03053063 0.02665476 0.02819803 0.02622571 0.01884689 0.02920955
  0.03234747 0.03842498 0.02832571 0.03105444 0.03494488 0.04245123
  0.04015423 0.01450147 0.0096454  0.02266282 0.02169079 0.02533784
  0.02352984 0.02256987 0.02250734 0.02870285 0.01486901 0.01399141
  0.02483283 0.01734112]
 [0.03039655 0.02493202 0.02502346 0.02393737 0.01854542 0.0266816
  0.02918905 0.03344661 0.02858023 0.02909856 0.03212659 0.03823255
  0.03849387 0.0137832  0.00972495 0.02641497 0.02373086 0.0282704
  0.02662191 0.02554239 0.02502001 0.02897112 0.01300101 0.01803459
  0.02517109 0.01584123]
 [0.03020289 0.02022879 0.01918114 0.01494554 0.01146922 0.01699365
  0.02175881 0.02432271 0.02296656 0.01858444 0.02396594 0.02474719
  0.02721523 0.00834105 0.00675582 0.03098814 0.02620331 0.03035273
  0.02903198 0.0277491  0.031368   0.02701451 0.01251353 0.02969719
  0.03604473 0.01744716]
 [0.03018393 0.02092265 0.01943454 0.01558762 0.01138133 0.016426
  0.02426279 0.02526433 0.02290435 0.01855608 0.02493845 0.02256151
  0.02673273 0.00803805 0.00677488 0.03274671 0.02664305 0.03360219
  0.03354967 0.03147476 0.03593855 0.02345028 0.01232354 0.02862397
  0.04044864 0.01786472]
 [0.03028191 0.01966995 0.01821054 0.01484055 0.01217673 0.01604945
  0.02113841 0.02382828 0.02184807 0.01866529 0.02576268 0.02386595
  0.02472196 0.00830398 0.00686561 0.02791347 0.02962176 0.02969379
  0.03327076 0.02718652 0.0323681  0.0237     0.01214691 0.02260915
  0.04938681 0.01820605]
 [0.03043351 0.02192842 0.02045127 0.01607491 0.01217784 0.01746953
  0.02483165 0.02621254 0.02624003 0.01943261 0.03000996 0.02455543
  0.02657991 0.00880575 0.00724177 0.03054542 0.02911166 0.03148541
  0.0340449  0.03185893 0.03425028 0.02498736 0.01267157 0.02355809
  0.0376007  0.01655969]
 [0.0305067  0.01712339 0.01655404 0.01105806 0.00950799 0.01310901
  0.02128622 0.02010796 0.02079038 0.01382735 0.0349227  0.01839352
  0.02157918 0.00681854 0.00559605 0.02859929 0.03065603 0.02933094
  0.03473993 0.02979058 0.03213638 0.02360004 0.01161062 0.03267121
  0.04055094 0.01690169]
 [0.02914738 0.0223342  0.02109026 0.01298565 0.0109219  0.01710245
  0.03297662 0.03052178 0.02876547 0.01771926 0.04649822 0.0241481
  0.03357611 0.00803966 0.00703215 0.0293537  0.04609357 0.04478079
  0.0516745  0.04357061 0.04466562 0.02810914 0.01957531 0.0435951
  0.06345985 0.04779346]
 [0.03054606 0.02040713 0.02073518 0.01718408 0.01317236 0.02045066
  0.02148848 0.02506985 0.02511305 0.02089349 0.0250692  0.02522536
  0.02551666 0.01115936 0.00844504 0.01782244 0.02397232 0.0227003
  0.02650073 0.02285268 0.02592332 0.02506809 0.01337693 0.01622149
  0.02721794 0.02369259]
 [0.02949585 0.02611974 0.02678476 0.04111741 0.04169744 0.0361406
  0.0232398  0.02470837 0.0304623  0.04341665 0.03013138 0.02984588
  0.03001306 0.06398259 0.07966381 0.02269084 0.02708471 0.0230147
  0.02423989 0.02264893 0.02254579 0.03008431 0.02923891 0.0089566
  0.00826249 0.02769913]
 [0.02923953 0.02754067 0.02701627 0.04638194 0.08699028 0.03651715
  0.02116758 0.02296797 0.02915999 0.05071682 0.03540603 0.03069596
  0.02570879 0.06649898 0.08613979 0.02796705 0.0379285  0.0317937
  0.02911611 0.02475833 0.02693866 0.02772755 0.02909714 0.00769957
  0.00770478 0.02378339]
 [0.02892338 0.02509087 0.02395511 0.03858273 0.0895233  0.02604867
  0.01804223 0.02214831 0.02482883 0.0453229  0.03483981 0.03329325
  0.02509857 0.03193193 0.04169781 0.02410355 0.05858759 0.04963489
  0.04088453 0.02964208 0.04328928 0.02557972 0.02579227 0.01332006
  0.02009562 0.028802  ]
 [0.02930373 0.02981359 0.0273119  0.03818295 0.05264382 0.02995791
  0.02363849 0.02404143 0.02991507 0.04011902 0.03221299 0.0270489
  0.026307   0.0303745  0.03330518 0.02069825 0.03904496 0.03180447
  0.03233587 0.0278535  0.03195506 0.04362115 0.03562728 0.01083359
  0.01250923 0.02687727]]

-* TASK 10/20 | SAMPLE 100/100 | PART 2/5 | 'init_prompt_reasoning' 1/1 | RUN ID 497/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 4, Mary journeyed to the office, which implies that Mary is currently in the office.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.0304934  0.04957623 0.04834603 0.07081147 0.06284453 0.05445803
  0.0366278  0.03726534 0.04943254 0.0558139  0.03561977 0.03495456
  0.03365651 0.10196885 0.10343459 0.03054934 0.02841346 0.02384306
  0.02492894 0.02694511 0.02415941 0.03533581 0.06333146 0.0192241
  0.0090896  0.03523336 0.0414721  0.0409895  0.10692283 0.03383495
  0.00653637 0.0320043 ]
 [0.03131534 0.04738299 0.04645492 0.08373463 0.08562547 0.07944407
  0.0412486  0.03932012 0.05186417 0.07543263 0.04937133 0.05496027
  0.04955717 0.16672747 0.14679806 0.03525336 0.03124011 0.02959374
  0.02702514 0.02826133 0.02543531 0.03664388 0.04924156 0.01598476
  0.00961118 0.03156637 0.04777206 0.03304776 0.0791466  0.0425524
  0.00964392 0.03884916]
 [0.03181965 0.04387772 0.04969293 0.07034668 0.06411259 0.0641426
  0.04075713 0.04047927 0.04895835 0.06187303 0.03864534 0.05305543
  0.04714044 0.10265792 0.0770345  0.02830812 0.02852611 0.02535506
  0.02478307 0.02531705 0.02258793 0.03435199 0.04554617 0.01873515
  0.01171205 0.03050352 0.04362485 0.0287138  0.05484724 0.06205449
  0.01650587 0.03331063]
 [0.03060835 0.04131217 0.04403683 0.03487865 0.03285712 0.03750676
  0.03520324 0.0374516  0.0345012  0.03407598 0.02995343 0.03806281
  0.03633802 0.02658786 0.02702345 0.03249383 0.03161432 0.0256671
  0.02781818 0.0281905  0.02640597 0.03657354 0.04910323 0.03714154
  0.02729565 0.04085059 0.04837357 0.03330779 0.03971797 0.09765026
  0.03104171 0.02495405]
 [0.0318876  0.03058824 0.03357471 0.02462205 0.0225217  0.02997626
  0.02857879 0.02733029 0.02986044 0.02615445 0.02402793 0.02641097
  0.02596918 0.01691006 0.01814108 0.02142379 0.02065021 0.01879549
  0.02442147 0.025018   0.02398549 0.03008861 0.03449359 0.02664849
  0.0198178  0.03821684 0.03925604 0.02867804 0.03080325 0.06961092
  0.02659719 0.02059979]
 [0.03168597 0.04896979 0.05213112 0.0278205  0.02496538 0.036249
  0.04056123 0.03945089 0.04298941 0.02953451 0.02548869 0.03285611
  0.03372582 0.02145109 0.02008943 0.03066135 0.02629509 0.02071662
  0.02450457 0.02475043 0.02312413 0.03531142 0.0583417  0.03194013
  0.02331329 0.03728272 0.05375544 0.02300935 0.03072359 0.09736709
  0.0247499  0.01699648]
 [0.03187566 0.06633522 0.05862866 0.02623685 0.02498146 0.0348455
  0.04590204 0.03891193 0.05043711 0.02912502 0.02641933 0.03094738
  0.03252456 0.01750701 0.01869891 0.04106374 0.03927916 0.0314151
  0.03508193 0.03864156 0.0322994  0.03208115 0.077783   0.04315716
  0.03089634 0.05181851 0.05641472 0.02490962 0.02589605 0.07271725
  0.01467884 0.01279907]
 [0.03214462 0.03780852 0.03695487 0.02021131 0.02036941 0.02471642
  0.03095535 0.02599083 0.03239095 0.02174024 0.02151676 0.02208276
  0.02239029 0.01438344 0.01601471 0.02958594 0.02724292 0.02069653
  0.02609065 0.02571251 0.02427559 0.02755949 0.04275091 0.03246894
  0.0190623  0.03370573 0.04530273 0.01906818 0.02200274 0.06344461
  0.0156614  0.01135647]
 [0.03193874 0.02209169 0.02238745 0.01542442 0.01562874 0.0186346
  0.023061   0.02133637 0.02064409 0.01789978 0.02362936 0.02271025
  0.02175057 0.01078205 0.01198465 0.03865008 0.02390286 0.02992788
  0.02605263 0.03016385 0.02691537 0.02676899 0.02237588 0.0439182
  0.03137203 0.02463339 0.02652948 0.02840346 0.02779907 0.02968603
  0.03161124 0.0239031 ]
 [0.03204005 0.02646515 0.02939187 0.01863245 0.01869942 0.02374286
  0.02831073 0.02415599 0.02659955 0.0214603  0.02482506 0.02397009
  0.02392384 0.01371646 0.01490195 0.03358399 0.03482489 0.02839311
  0.03274526 0.03263791 0.02974006 0.0305361  0.03229118 0.04285498
  0.02527425 0.03002621 0.03501385 0.02212195 0.02472109 0.04688496
  0.02679726 0.01461911]
 [0.0321185  0.02960949 0.03108769 0.02150986 0.02102856 0.02706433
  0.03418423 0.02992007 0.02689395 0.02450259 0.02973549 0.03173539
  0.03242327 0.01624554 0.01516231 0.04109617 0.03429465 0.03111846
  0.0300187  0.02925391 0.02804552 0.03404878 0.02629457 0.04624611
  0.0284776  0.02506399 0.02759003 0.0266232  0.02450788 0.03934053
  0.03900283 0.02265119]
 [0.03170349 0.02748292 0.02405743 0.0183186  0.01575132 0.02069685
  0.02890701 0.02537261 0.02245545 0.01914677 0.02726163 0.02248357
  0.02737835 0.01189735 0.0123749  0.05006549 0.04285099 0.04507931
  0.04105756 0.04122481 0.04249277 0.03183211 0.02090563 0.06106691
  0.0424405  0.02847808 0.02100514 0.02981275 0.01864947 0.01724913
  0.02546672 0.02126006]
 [0.03251731 0.02909248 0.03096133 0.02553727 0.02336775 0.03394336
  0.03604526 0.0396748  0.03615075 0.02953683 0.03122178 0.03516469
  0.03476359 0.0190817  0.01618114 0.03603253 0.02514656 0.03237265
  0.03111145 0.03660821 0.03225815 0.02851994 0.0257541  0.04202678
  0.02907081 0.03719728 0.02595964 0.0262486  0.02930321 0.0257113
  0.0370954  0.02330215]
 [0.03281439 0.02455156 0.02315423 0.01805026 0.01453752 0.02096793
  0.02654936 0.02346248 0.02212509 0.01893392 0.0299122  0.02400608
  0.02596029 0.01151289 0.01166051 0.0520596  0.0307772  0.04299144
  0.03410854 0.04734848 0.03828014 0.02731712 0.01832182 0.06565137
  0.04227709 0.02266718 0.01992877 0.02515511 0.01824297 0.01535316
  0.02883479 0.03026514]
 [0.03278656 0.02118935 0.02081368 0.01591078 0.01239327 0.0186448
  0.02358167 0.02092225 0.0203834  0.01680548 0.02966874 0.0201137
  0.02340851 0.01001927 0.0107507  0.04318902 0.0335035  0.0350096
  0.03491749 0.0372978  0.03368597 0.02738978 0.01628145 0.05198543
  0.04977172 0.02344979 0.01913732 0.02542182 0.01430515 0.01219792
  0.02442464 0.02438054]
 [0.03165083 0.03820034 0.03422662 0.02907832 0.02478653 0.03448115
  0.04320242 0.04159286 0.03933973 0.03298399 0.03808578 0.03881094
  0.04547361 0.01744437 0.0164154  0.04398638 0.05555926 0.05354059
  0.0560174  0.04981467 0.04790568 0.0337389  0.03266368 0.04909303
  0.09730938 0.06722236 0.02971112 0.04273339 0.0264355  0.01760739
  0.02230977 0.02237277]
 [0.03282136 0.02401178 0.02525355 0.02102111 0.01503188 0.02393233
  0.0279447  0.02793662 0.02356339 0.02155747 0.03232913 0.02797434
  0.02849608 0.01461558 0.0135068  0.03168862 0.02804054 0.02776702
  0.0340272  0.02937589 0.0318285  0.03364545 0.01901248 0.02856019
  0.03467948 0.02348852 0.02328453 0.02642984 0.02312499 0.02098745
  0.07247484 0.03237634]
 [0.03271041 0.02264934 0.02738733 0.02419799 0.01863511 0.02719404
  0.02716627 0.03106337 0.02577477 0.02607116 0.0291936  0.03219068
  0.03132153 0.01744928 0.01394692 0.02129262 0.02164659 0.02506511
  0.02577502 0.02498652 0.02460281 0.0341525  0.01962904 0.02434227
  0.02647075 0.02439758 0.02496241 0.03109657 0.03092449 0.02710658
  0.10336681 0.03479489]
 [0.03292363 0.0298241  0.03397821 0.03359687 0.02245136 0.03696751
  0.03682027 0.04309282 0.02970537 0.03399269 0.03666232 0.04526483
  0.04457444 0.02457836 0.01678593 0.02291188 0.02158962 0.02594767
  0.02536657 0.02501899 0.02436702 0.03532194 0.02293809 0.02130018
  0.02711657 0.02024531 0.02975861 0.02432833 0.03102992 0.02777761
  0.11540914 0.03890553]
 [0.03309203 0.02884373 0.03339091 0.03675459 0.02705739 0.03949031
  0.03648174 0.04268464 0.0324314  0.03949888 0.03756941 0.04567051
  0.0461311  0.02859491 0.02008131 0.02271439 0.02320882 0.02693067
  0.02670421 0.02582662 0.02513214 0.03320643 0.01983061 0.0178496
  0.0230413  0.0184158  0.02581717 0.02687051 0.02981748 0.02521618
  0.07831742 0.04944145]
 [0.03283912 0.02334845 0.0241206  0.02331393 0.01480279 0.02369185
  0.02970779 0.03306068 0.0249455  0.02367666 0.03062883 0.0289472
  0.03239839 0.0148723  0.01272398 0.0305744  0.02969859 0.03078833
  0.03039179 0.0286499  0.03113006 0.03436893 0.01736339 0.02706328
  0.03968933 0.02078186 0.01996043 0.03301018 0.02259373 0.01803215
  0.05591068 0.04684546]
 [0.03268479 0.0222185  0.02126312 0.02124632 0.01303232 0.01992296
  0.02626582 0.02735209 0.02265546 0.02060429 0.02517062 0.02210027
  0.02738723 0.0131146  0.01198755 0.03376772 0.03368931 0.0387762
  0.03896313 0.03858254 0.0421683  0.02882263 0.01712329 0.03923302
  0.04723546 0.02767041 0.01891571 0.03951777 0.01881903 0.01116734
  0.03555006 0.05521625]
 [0.03333293 0.02141697 0.02083953 0.02067131 0.01423407 0.0200381
  0.02522275 0.02686267 0.02180372 0.02091431 0.02722628 0.02471529
  0.02670131 0.01381719 0.01178402 0.02715164 0.02778093 0.02807906
  0.03027244 0.02807836 0.03298546 0.02758105 0.01606111 0.02722906
  0.04721978 0.02005279 0.01908983 0.03671071 0.01887966 0.01259693
  0.03235752 0.0829854 ]
 [0.03308183 0.02669114 0.026319   0.02448549 0.01721633 0.02366125
  0.03300025 0.03573763 0.02888734 0.02511567 0.03640316 0.03102715
  0.0331323  0.01610429 0.0144224  0.03573039 0.03615081 0.03676869
  0.03641162 0.03422465 0.03639311 0.03055613 0.01808666 0.02924639
  0.05177074 0.02338942 0.02138504 0.03830245 0.01946597 0.01240171
  0.02749198 0.06418703]
 [0.03337251 0.02067884 0.01986023 0.01650015 0.01303835 0.01696439
  0.02702192 0.02658923 0.02204193 0.01676615 0.04079721 0.02204482
  0.02565998 0.01184576 0.01072634 0.03234497 0.03667587 0.0295482
  0.03720377 0.03258184 0.03618688 0.02895023 0.01613719 0.0376053
  0.06610636 0.02739359 0.01815592 0.03236403 0.01571909 0.01091634
  0.02392139 0.04181622]
 [0.03226128 0.02820478 0.02792436 0.02376674 0.01931637 0.02441765
  0.03312054 0.03460622 0.03833741 0.02468305 0.02609145 0.02443803
  0.02834681 0.01551347 0.01429715 0.02359575 0.0274598  0.02501958
  0.03445069 0.03216474 0.03527877 0.03307857 0.02950482 0.02988153
  0.05021271 0.07626279 0.03431737 0.04246668 0.02358185 0.01621726
  0.01803893 0.02450603]
 [0.03324121 0.02275502 0.02344572 0.02343372 0.01709173 0.02274599
  0.02567985 0.0287193  0.02582646 0.0240422  0.0264586  0.02561421
  0.02637967 0.01705622 0.01448677 0.02005508 0.02458201 0.02387721
  0.02915582 0.02741041 0.02846348 0.03104316 0.01963793 0.0163289
  0.0257824  0.02655972 0.02320538 0.02635892 0.02371013 0.01666262
  0.02789949 0.03587329]
 [0.03222086 0.03356349 0.03335932 0.04971849 0.04647022 0.04511013
  0.03282326 0.03416039 0.04008135 0.04860263 0.0360576  0.03877591
  0.03713056 0.06463088 0.08436399 0.02399565 0.02798616 0.03137894
  0.02816297 0.02960706 0.02849579 0.03494197 0.03788861 0.01658422
  0.01103825 0.03426962 0.04128215 0.0420448  0.04838494 0.01913738
  0.00889642 0.05533193]
 [0.03189361 0.04286483 0.03863346 0.07500419 0.15844972 0.05657421
  0.0367017  0.03523831 0.04169045 0.07443318 0.05545979 0.05360315
  0.03720875 0.10018535 0.1362538  0.03521455 0.04893612 0.05102618
  0.03688904 0.03529396 0.04088072 0.03397484 0.04886016 0.0163401
  0.01046742 0.03258137 0.05429363 0.04154473 0.05030026 0.01631509
  0.00525371 0.03184621]
 [0.03195717 0.03260426 0.02764579 0.04054482 0.0718516  0.02730772
  0.02636721 0.02745711 0.02866036 0.0419119  0.0383901  0.03288238
  0.02757559 0.03252179 0.04835379 0.02797945 0.05727946 0.05974393
  0.04828242 0.04117858 0.06042879 0.0306963  0.03863263 0.02348539
  0.02732028 0.03177598 0.03552038 0.04876334 0.03330781 0.01266215
  0.00800162 0.01737392]
 [0.0321668  0.03579087 0.03067846 0.04462014 0.04685004 0.03246699
  0.03200014 0.03280111 0.03856889 0.04311031 0.03617933 0.03242611
  0.03117226 0.0362067  0.0396129  0.02298017 0.0411541  0.04476727
  0.03726035 0.03983383 0.0400613  0.0415622  0.04381408 0.01680735
  0.01505755 0.03479933 0.02920459 0.05194683 0.03631609 0.0095408
  0.00615219 0.01487596]]

-* TASK 10/20 | SAMPLE 100/100 | PART 3/5 | 'init_prompt_reasoning' 1/1 | RUN ID 498/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: According to context sentence 8, Julie is in the park, which directly states her current location.

Answer: yes


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Julie', ' is', ' in', ' the', ' park', ',', ' which', ' directly', ' states', ' her', ' current', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 38), x_tokens=38, y_tokens=27, max_supp_attn=0.0, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 38)
DEBUG result.interpretability.attn_scores 1026 
 [[0.0346556  0.04657249 0.04124673 ... 0.02605158 0.02795389 0.0315651 ]
 [0.03578133 0.05442559 0.04834675 ... 0.03110988 0.03666326 0.04208215]
 [0.0362941  0.04760114 0.04622682 ... 0.02235181 0.0257728  0.02341887]
 ...
 [0.03654315 0.03844463 0.04096057 ... 0.021022   0.02263708 0.02226483]
 [0.03697732 0.03002483 0.02961483 ... 0.02674222 0.03006006 0.02784499]
 [0.03690553 0.03258014 0.03354518 ... 0.02174616 0.02552451 0.02605467]]

-* TASK 10/20 | SAMPLE 100/100 | PART 4/5 | 'init_prompt_reasoning' 1/1 | RUN ID 499/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Julie's location in the context sentences 10 and 11, which only mention Fred and Mary's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ',', ' which', ' only', ' mention', ' Fred', ' and', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02566913 0.03043354 0.03026339 ... 0.03556456 0.01604909 0.01607494]
 [0.02614768 0.02969521 0.03300767 ... 0.04360704 0.02420897 0.02325081]
 [0.02690287 0.02882087 0.03145293 ... 0.05591273 0.02115742 0.02530334]
 ...
 [0.02733995 0.03061748 0.02379431 ... 0.01392774 0.01793519 0.01660543]
 [0.02770626 0.03452157 0.02821663 ... 0.01193525 0.01690421 0.01769489]
 [0.0279428  0.03001127 0.02510128 ... 0.01254608 0.01678525 0.01803313]]

-* TASK 10/20 | SAMPLE 100/100 | PART 5/5 | 'init_prompt_reasoning' 1/1 | RUN ID 500/1000 *-


DEBUG starting interpretability
The output of the model:
Reasoning: There is no information provided about Mary's location in the context sentences 13 and 14, which only mention Bill and Julie's locations.

Answer: not mentioned


Saving part result...
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ',', ' which', ' only', ' mention', ' Bill', ' and', ' Julie', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 50), x_tokens=50, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 50)
DEBUG result.interpretability.attn_scores 1800 
 [[0.02597485 0.03766    0.03365241 ... 0.02184438 0.01876563 0.04396057]
 [0.02643029 0.03656017 0.03361164 ... 0.03086615 0.02556519 0.03283449]
 [0.02713338 0.04054067 0.03861821 ... 0.01996111 0.01629416 0.03325872]
 ...
 [0.02759873 0.02826528 0.02316519 ... 0.02854828 0.04563824 0.04494967]
 [0.02729674 0.03418131 0.02607763 ... 0.02141931 0.03031371 0.0423035 ]
 [0.02773857 0.03058566 0.02478825 ... 0.01673021 0.01847644 0.03163914]]
Model's predictions for the sample 100:

+----------+-----------------+--------------------------------------------+
|  GOLDEN  |  PREDICTED-Bef  |               REASONING-Bef                |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 1, Fred    |
|          |                 |  travelled to the kitchen, which implies   |
|          |                 |   that Fred is currently in the kitchen.   |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 4, Mary    |
|          |                 |   journeyed to the office, which implies   |
|          |                 |   that Mary is currently in the office.    |
+----------+-----------------+--------------------------------------------+
|   yes    |       yes       |   According to context sentence 8, Julie   |
|          |                 |   is in the park, which directly states    |
|          |                 |           her current location.            |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |      Julie's location in the context       |
|          |                 |  sentences 10 and 11, which only mention   |
|          |                 |         Fred and Mary's locations.         |
+----------+-----------------+--------------------------------------------+
|    no    |  not mentioned  |   There is no information provided about   |
|          |                 |  Mary's location in the context sentences  |
|          |                 |   13 and 14, which only mention Bill and   |
|          |                 |             Julie's locations.             |
+----------+-----------------+--------------------------------------------+

Metrics for sample 100:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    |     0.6     |
|    Soft-match accuracy     |     0.6     |
| Max attention distribution | 0.06 ± 0.03 |
+----------------------------+-------------+

- TASK RESULTS -


Metrics for task 10:
+----------------------------+-------------+
|           Metric           |    Before   |
+----------------------------+-------------+
|    Exact-match accuracy    | 0.81 ± 0.17 |
|    Soft-match accuracy     | 0.81 ± 0.16 |
| Max attention distribution | 0.07 ± 0.03 |
+----------------------------+-------------+
The work on task 10 is finished successfully
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' being', ' in', ' the', ' kitchen', ',', ' with', ' no', ' information', ' about', ' him', ' being', ' in', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02813006 0.04298579 0.05189936 0.07291258 0.08273926 0.0700423
  0.05150617 0.06052095 0.05188767 0.06495348 0.04395387 0.05597342
  0.06477298 0.10507298 0.07436867 0.03247471 0.0318436  0.03335727
  0.0289178  0.03237732 0.02576762 0.03798472 0.04200315 0.02213615
  0.01860136 0.02333465]
 [0.02798236 0.06264175 0.04943635 0.04365812 0.0341766  0.0413911
  0.10285293 0.06347379 0.05097058 0.03799732 0.06285024 0.0380284
  0.06554407 0.01968818 0.02095225 0.04392769 0.04132107 0.05392405
  0.04150452 0.0489832  0.04219754 0.0414388  0.0410061  0.04966858
  0.04693985 0.04366403]
 [0.03054524 0.05953544 0.03833761 0.05535875 0.0415693  0.03553768
  0.03054466 0.02187007 0.02232572 0.03474616 0.02643298 0.01544267
  0.01755075 0.03232522 0.04257973 0.02539045 0.01469095 0.0138645
  0.01676312 0.01775978 0.01622165 0.04403048 0.05360876 0.0102339
  0.00762972 0.01230991]
 [0.02871547 0.0287841  0.03083823 0.02360464 0.01731338 0.02532106
  0.02716399 0.02390999 0.02621769 0.02402836 0.027513   0.02349079
  0.02269497 0.0127355  0.01427467 0.0346244  0.03610497 0.03475365
  0.03661771 0.03865836 0.03605799 0.03316167 0.05592253 0.05864217
  0.06203281 0.06093869]
 [0.0290003  0.04312865 0.04863191 0.07029321 0.06430287 0.04828423
  0.03340823 0.02931317 0.03468377 0.04695989 0.03262209 0.0246116
  0.0248357  0.10881947 0.11334331 0.03943846 0.02824952 0.02196356
  0.02185654 0.0243098  0.02281627 0.03947601 0.06331461 0.01810157
  0.01133964 0.02711315]
 [0.02962507 0.02767173 0.02945931 0.05343461 0.04765144 0.04313315
  0.02475587 0.02261771 0.02904396 0.04333728 0.02876761 0.02755696
  0.0264674  0.11792663 0.14186305 0.03897522 0.03182951 0.0263992
  0.02461112 0.02586859 0.02181776 0.03371134 0.03770876 0.012797
  0.00905577 0.01729379]
 [0.03009351 0.03089422 0.03697555 0.05614052 0.05299176 0.05375843
  0.03201155 0.030611   0.03739541 0.05088111 0.03349841 0.04282254
  0.0395609  0.09324333 0.08831703 0.03246931 0.02876573 0.02601753
  0.02359234 0.02543387 0.02061496 0.03036846 0.03476663 0.01688291
  0.01194195 0.01628535]
 [0.02910008 0.03739884 0.0446392  0.04303501 0.0454865  0.04934865
  0.03685058 0.03963701 0.04076939 0.04515805 0.03462879 0.04870635
  0.04207046 0.05572852 0.05018264 0.04119539 0.03534755 0.03293122
  0.02890203 0.03168853 0.02910695 0.03427805 0.04899224 0.03769229
  0.03488992 0.03045581]
 [0.02926117 0.05197733 0.06124096 0.03473408 0.02898633 0.04304666
  0.04687779 0.04805625 0.0452968  0.03442279 0.03296008 0.04137755
  0.04129397 0.0241073  0.0178047  0.0392867  0.03191702 0.03020706
  0.02808883 0.0306849  0.02991812 0.03240734 0.06221958 0.04248196
  0.04084096 0.04393656]
 [0.03016604 0.06657545 0.07506131 0.03121611 0.02252543 0.03927364
  0.04507596 0.04090489 0.04839339 0.02998156 0.02584093 0.03432103
  0.03197721 0.01708016 0.01432501 0.04350111 0.03155715 0.02804855
  0.02763796 0.03214619 0.02789718 0.03128158 0.06867096 0.03610471
  0.02874218 0.02906517]
 [0.03018514 0.04162379 0.05068217 0.02799237 0.02017535 0.03642059
  0.04155676 0.04130977 0.04274651 0.02818264 0.0243871  0.03540953
  0.02968334 0.01542845 0.01325237 0.03841989 0.03097769 0.02867472
  0.0285509  0.03162144 0.02893688 0.03228017 0.04927518 0.04521123
  0.04005675 0.03636367]
 [0.03077455 0.03150104 0.03298031 0.0255908  0.01925202 0.03588552
  0.03558484 0.03938188 0.03527818 0.0279758  0.02677098 0.03856255
  0.03184133 0.01362597 0.01137978 0.02717721 0.02619521 0.02670825
  0.02513018 0.02650977 0.02554174 0.03075865 0.02664821 0.03112069
  0.03049702 0.03013755]
 [0.03036732 0.02195841 0.02112852 0.01609414 0.0135898  0.02073546
  0.02693532 0.02656    0.02419387 0.01840873 0.02594166 0.02320872
  0.02502551 0.00890162 0.00858652 0.03007549 0.02979289 0.02850486
  0.03017322 0.03085982 0.03677084 0.02806777 0.02189695 0.05842175
  0.06353439 0.04311804]
 [0.0303567  0.01857107 0.01610984 0.01355698 0.01163665 0.01431372
  0.02163043 0.02149403 0.01837715 0.01460405 0.02008495 0.0164435
  0.01992982 0.00710283 0.00732228 0.0313578  0.02479277 0.02798278
  0.02874376 0.03015268 0.04395971 0.02619411 0.01764727 0.04744075
  0.07991552 0.050634  ]
 [0.03082056 0.01994327 0.01741463 0.01486667 0.01343732 0.01627531
  0.0209283  0.02181239 0.01941312 0.01651076 0.0232724  0.01962998
  0.02153132 0.00770407 0.00772855 0.03142345 0.02583141 0.02805177
  0.02876463 0.02867877 0.03485387 0.02588001 0.01617499 0.04248785
  0.06736034 0.04562118]
 [0.03062294 0.01754035 0.01542164 0.011754   0.01177097 0.01348689
  0.02078976 0.02047574 0.01792285 0.013867   0.03015316 0.01725396
  0.02092523 0.00636006 0.00678899 0.03319032 0.03296843 0.0302236
  0.0344     0.03106169 0.03838586 0.02471776 0.0177961  0.04664485
  0.05520884 0.06139321]
 [0.03016779 0.01972426 0.01619997 0.01252279 0.01196822 0.0145057
  0.0195117  0.01760609 0.01898996 0.01399809 0.02786554 0.01593472
  0.01836174 0.00668991 0.00736074 0.03314172 0.02951496 0.02761402
  0.03271153 0.03063213 0.03690636 0.02627559 0.01997452 0.04895682
  0.05911707 0.09080651]
 [0.03097354 0.0194024  0.0171476  0.01391758 0.01216426 0.01606148
  0.01974321 0.02016071 0.01927442 0.01589461 0.02773012 0.01865338
  0.01947794 0.00765546 0.00774976 0.02399872 0.02622142 0.02660698
  0.02743034 0.02698922 0.02952649 0.02541528 0.01835035 0.03573116
  0.03817463 0.05171291]
 [0.03146411 0.02039466 0.02167184 0.01834714 0.01480841 0.02453415
  0.02408884 0.02881068 0.02708383 0.02392931 0.02495565 0.03062231
  0.02591739 0.01126718 0.00879933 0.01956832 0.02304588 0.02206725
  0.02386561 0.02418305 0.02295412 0.02768731 0.01629135 0.02272676
  0.02208791 0.02057764]
 [0.03131207 0.02468947 0.02154717 0.01629751 0.01451555 0.02127053
  0.02636508 0.02841578 0.02622901 0.01961335 0.02537423 0.02410686
  0.02569199 0.01025671 0.00851194 0.0222327  0.02919409 0.0251751
  0.02851222 0.02872981 0.02991845 0.0277125  0.01940435 0.03318026
  0.03109354 0.02339811]
 [0.03118917 0.02892305 0.02692132 0.02072708 0.01733275 0.02780536
  0.03101813 0.04165696 0.03487908 0.02811854 0.03323428 0.04139832
  0.03980894 0.0127232  0.00963073 0.02555301 0.02627845 0.0290459
  0.02873969 0.02933085 0.02750322 0.0283162  0.01868657 0.02056876
  0.01718077 0.0166092 ]
 [0.03159007 0.02555063 0.0281343  0.02343011 0.01743319 0.03971272
  0.03164341 0.03902137 0.03815965 0.03271563 0.02862323 0.05981462
  0.048745   0.01459644 0.00958412 0.02106435 0.02315961 0.02540669
  0.02574237 0.02618402 0.02310327 0.02717446 0.01731595 0.01599362
  0.01253332 0.01196412]
 [0.03099724 0.01775623 0.01866972 0.01408057 0.0112615  0.01595123
  0.02157065 0.02497599 0.02217995 0.01729151 0.02655945 0.02142166
  0.02753075 0.00779392 0.00739547 0.02580225 0.02643381 0.02758457
  0.02859975 0.02929816 0.03572316 0.02540295 0.01326409 0.02860344
  0.02747715 0.01921688]
 [0.03121826 0.01948012 0.01842881 0.01473829 0.011368   0.01504457
  0.02439721 0.02690609 0.02210636 0.01647726 0.02680231 0.02085
  0.02597347 0.00762099 0.00734116 0.03240962 0.02659866 0.03206136
  0.02869644 0.03009476 0.0403201  0.02434407 0.01303626 0.02994367
  0.02798624 0.0198366 ]
 [0.03149992 0.0181974  0.01692354 0.0152013  0.01238935 0.01641217
  0.0202774  0.02374693 0.0226852  0.01947643 0.02738989 0.02527901
  0.02407215 0.00849485 0.00778262 0.02542057 0.02551579 0.02588519
  0.02748937 0.02661186 0.03120396 0.02347803 0.01135207 0.02144963
  0.01811283 0.01389934]
 [0.03115272 0.01633692 0.01562043 0.01183333 0.0106286  0.01319132
  0.01967015 0.02042693 0.02091188 0.01473369 0.02972339 0.01968363
  0.01971951 0.00686837 0.00645149 0.02599949 0.0306896  0.02435567
  0.03138538 0.02988199 0.03531592 0.0232131  0.01137718 0.02761235
  0.02340436 0.02112456]
 [0.03013724 0.01936629 0.01786275 0.01312859 0.0118339  0.01510159
  0.02103741 0.02167373 0.02452787 0.01657194 0.02781742 0.02112227
  0.02245124 0.00779884 0.00739874 0.02891652 0.03848442 0.02937512
  0.03757594 0.03886826 0.03933587 0.02496446 0.01662328 0.04164569
  0.03129538 0.03331548]
 [0.03129726 0.02028476 0.01966116 0.01718891 0.01372655 0.01834525
  0.02139227 0.02425941 0.02549874 0.02120835 0.02772564 0.02517748
  0.0239794  0.01083949 0.00951    0.02140482 0.02950807 0.02656341
  0.02996763 0.03296917 0.02985766 0.02663295 0.01464451 0.02118125
  0.01796884 0.0167884 ]
 [0.03081996 0.02737186 0.02848893 0.03433887 0.02806058 0.03681405
  0.03094697 0.03463538 0.03467811 0.04075324 0.03232662 0.04832217
  0.04541906 0.02480823 0.01527972 0.02111551 0.02794439 0.03059559
  0.02579326 0.02524805 0.02308965 0.03215752 0.02257369 0.0225055
  0.01954242 0.01865036]
 [0.03036675 0.03233393 0.03044654 0.04811653 0.0503936  0.04266461
  0.02595329 0.02555723 0.03136782 0.04635102 0.03108433 0.02835416
  0.02865558 0.07999951 0.0924878  0.02930729 0.02699786 0.02420357
  0.02371142 0.02452486 0.02116836 0.03311441 0.03400109 0.01186439
  0.00923319 0.01660547]
 [0.03001949 0.03069718 0.02926725 0.05210329 0.10685965 0.03833751
  0.02218929 0.02374693 0.03005446 0.05451973 0.03575022 0.03263837
  0.02514845 0.07642778 0.09432962 0.0322067  0.0420136  0.0431783
  0.03454758 0.02982693 0.02711292 0.02817357 0.0316322  0.01080474
  0.00822238 0.01579723]
 [0.029867   0.02569428 0.02448274 0.038454   0.06900787 0.02709543
  0.01838069 0.02271089 0.02597143 0.0450459  0.03548497 0.03518226
  0.02740349 0.02843411 0.03252385 0.02647865 0.0515812  0.0696715
  0.06968953 0.04324527 0.03613472 0.02529176 0.0253866  0.01749287
  0.01507688 0.01970967]
 [0.03018094 0.03106535 0.02826908 0.04133155 0.05864308 0.03089791
  0.02334116 0.02374027 0.03048611 0.04128636 0.03187447 0.02859932
  0.02593896 0.03187476 0.03479338 0.0224521  0.03463273 0.03899724
  0.04128723 0.03658685 0.02996097 0.044609   0.03843388 0.01367072
  0.01290615 0.01832277]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' explicitly', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02917604 0.03930278 0.03966948 ... 0.03705021 0.0097202  0.00938441]
 [0.02993434 0.04042608 0.03730627 ... 0.04658488 0.01225569 0.01305433]
 [0.03054938 0.03926533 0.0424062  ... 0.05605194 0.01703978 0.01593744]
 ...
 [0.03073201 0.0338257  0.03221339 ... 0.01563874 0.00677256 0.00772029]
 [0.03070704 0.02895288 0.025778   ... 0.01419524 0.01126226 0.01360939]
 [0.03084339 0.03206198 0.02774655 ... 0.01070676 0.00960083 0.0114872 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' mentions', ' that', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' him', ' being', ' in', ' the', ' park', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 38), x_tokens=38, y_tokens=37, max_supp_attn=0.027, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 38)
DEBUG result.interpretability.attn_scores 1406 
 [[0.02517265 0.03971587 0.03876834 ... 0.02053462 0.02224848 0.03685235]
 [0.02527696 0.04681161 0.04179187 ... 0.02607974 0.03571852 0.03554656]
 [0.02624091 0.04241014 0.0435758  ... 0.01789408 0.01805392 0.03331412]
 ...
 [0.02635981 0.03388294 0.03297818 ... 0.01744616 0.01542849 0.04520176]
 [0.02690005 0.02497587 0.02218455 ... 0.01864413 0.01709841 0.03514415]
 [0.02681327 0.02792974 0.02486773 ... 0.01887821 0.01980585 0.03418876]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' previously', ' mentioned', ' that', ' Fred', ' went', ' back', ' to', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' left', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02724596 0.03141021 0.03785156 ... 0.01117412 0.00857261 0.04495324]
 [0.02765532 0.03673219 0.04156514 ... 0.01948334 0.01374938 0.02056351]
 [0.02848279 0.03674964 0.0438313  ... 0.02051098 0.01270738 0.04432622]
 ...
 [0.02871374 0.04239793 0.03778762 ... 0.0082418  0.00787517 0.10070593]
 [0.02928682 0.03120256 0.02572158 ... 0.01198916 0.01789661 0.08307458]
 [0.02897255 0.03797458 0.0319766  ... 0.00761325 0.01109416 0.09108261]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' explicitly', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02943647 0.04513121 0.04255885 ... 0.01463553 0.0282428  0.02205762]
 [0.02954888 0.0395533  0.03984436 ... 0.04087496 0.07244962 0.04015   ]
 [0.03063998 0.0469346  0.05002517 ... 0.01285098 0.02307335 0.02279419]
 ...
 [0.03086976 0.05121939 0.04061337 ... 0.01206211 0.02344773 0.0253238 ]
 [0.0313531  0.03587664 0.02519335 ... 0.02610197 0.02492796 0.03234394]
 [0.0310169  0.04350257 0.02945982 ... 0.01668881 0.02739677 0.02988343]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '1', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' office', ',', ' but', ' then', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' went', ' back', ' to', ' the', ' cinema', ',', ' implying', ' that', ' Fred', ' left', ' the', ' office', ' and', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 26), x_tokens=26, y_tokens=51, max_supp_attn=0.1765, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 26)
DEBUG result.interpretability.attn_scores 1326 
 [[0.01786196 0.03744632 0.04463782 ... 0.01296127 0.0076567  0.01739541]
 [0.01777175 0.06162743 0.04465519 ... 0.02693424 0.01644939 0.02547079]
 [0.01946535 0.04704935 0.02955855 ... 0.00445165 0.00273748 0.00862518]
 ...
 [0.01920781 0.02226099 0.02307258 ... 0.00468154 0.00293307 0.01082091]
 [0.0192688  0.0171133  0.01843672 ... 0.00862483 0.00635349 0.01386287]
 [0.01941075 0.02058051 0.02085272 ... 0.00719507 0.00454091 0.01180935]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' indicates', ' that', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' office', ',', ' but', ' sentence', ' ', '5', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' Julie', ' left', ' her', ' previous', ' location', ' (', 'school', ' or', ' office', ')', ' and', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 32), x_tokens=32, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 32)
DEBUG result.interpretability.attn_scores 1696 
 [[0.01733492 0.02952139 0.03334729 ... 0.00999679 0.00711364 0.00588913]
 [0.01779928 0.02840501 0.03275482 ... 0.01384339 0.00946139 0.00836589]
 [0.01809748 0.02704381 0.03552734 ... 0.02499647 0.01595786 0.01158532]
 ...
 [0.01812989 0.02965849 0.02944876 ... 0.00725324 0.00625827 0.00596344]
 [0.01837809 0.02422838 0.02258388 ... 0.00859884 0.00756839 0.00881961]
 [0.01827653 0.02717013 0.02506567 ... 0.00668826 0.00690385 0.00647716]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' indicates', ' that', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' sentence', ' ', '8', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' school', ',', ' which', ' means', ' Julie', ' left', ' her', ' previous', ' location', ' (', 'k', 'itchen', ' or', ' bedroom', ')', ' and', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 38), x_tokens=38, y_tokens=55, max_supp_attn=0.0182, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 38)
DEBUG result.interpretability.attn_scores 2090 
 [[0.0168156  0.03105258 0.02769487 ... 0.05049053 0.02505869 0.00790519]
 [0.01711794 0.02460161 0.02318769 ... 0.02818532 0.0201341  0.014533  ]
 [0.01754956 0.03157525 0.03271073 ... 0.03773488 0.0212738  0.00681021]
 ...
 [0.0176733  0.02885946 0.0271477  ... 0.04529132 0.02123803 0.0078082 ]
 [0.01804705 0.01993264 0.0175946  ... 0.02192811 0.02201354 0.01484289]
 [0.01785745 0.02406468 0.02037972 ... 0.04931878 0.02128518 0.00966691]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' indicates', ' that', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' and', ' sentence', ' ', '11', ' states', ' that', ' Bill', ' went', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Bill', ' is', ' now', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 44), x_tokens=44, y_tokens=54, max_supp_attn=0.0185, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 44)
DEBUG result.interpretability.attn_scores 2376 
 [[0.01704015 0.03307087 0.03027778 ... 0.10039978 0.02475832 0.00498017]
 [0.01750118 0.02194926 0.02182342 ... 0.04425809 0.05040872 0.00889268]
 [0.01786163 0.03069739 0.0313941  ... 0.06056915 0.04252972 0.00587901]
 ...
 [0.01795574 0.02926226 0.0235531  ... 0.03848332 0.01025144 0.00387542]
 [0.01833509 0.02446009 0.01829603 ... 0.02020647 0.00755466 0.00540861]
 [0.01825081 0.02703383 0.01952945 ... 0.02882295 0.00635294 0.00484354]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' means', ' Julie', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.1071, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03345963 0.04702476 0.05185059 ... 0.0082137  0.01495694 0.06684126]
 [0.03414974 0.05088642 0.05246755 ... 0.02186147 0.01452519 0.02502529]
 [0.03505531 0.04817843 0.05822932 ... 0.01106147 0.01260344 0.05812545]
 ...
 [0.03534547 0.05123594 0.04334299 ... 0.00896592 0.01004417 0.1295195 ]
 [0.03534409 0.04126494 0.03236227 ... 0.01173562 0.01668577 0.12921412]
 [0.03534243 0.04556989 0.03615138 ... 0.01050877 0.01217352 0.10510803]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 26), x_tokens=26, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 26)
DEBUG result.interpretability.attn_scores 1040 
 [[0.02328781 0.04101321 0.04377789 ... 0.0106338  0.00758044 0.03221114]
 [0.02401908 0.0251241  0.02567212 ... 0.00768255 0.00662179 0.02136848]
 [0.02441618 0.02813352 0.03249107 ... 0.01019986 0.01006307 0.02003761]
 ...
 [0.02448611 0.02641591 0.0255546  ... 0.006754   0.00682801 0.01951428]
 [0.02444428 0.0227726  0.0220276  ... 0.01068272 0.01390323 0.0215538 ]
 [0.02452544 0.02716037 0.024608   ... 0.00870919 0.01126956 0.02053431]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', ' in', ' relation', ' to', ' the', ' bedroom', '.', ' Sentence', ' ', '2', ' mentioned', ' that', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' mention', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 32), x_tokens=32, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 32)
DEBUG result.interpretability.attn_scores 1536 
 [[0.01918969 0.03039032 0.03376421 ... 0.00980454 0.01492763 0.00804958]
 [0.01978221 0.03109428 0.03162191 ... 0.01184911 0.01903265 0.01164911]
 [0.02014826 0.02794035 0.03206291 ... 0.01567679 0.02521903 0.01449118]
 ...
 [0.02013773 0.03075309 0.02660819 ... 0.00600363 0.00733587 0.00591202]
 [0.02066171 0.02409686 0.01965406 ... 0.00829563 0.00855905 0.00747588]
 [0.02067515 0.03319073 0.02889455 ... 0.0080017  0.00879463 0.00649014]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' which', ' means', ' it', ' is', ' possible', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' but', ' it', ' is', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 38), x_tokens=38, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 38)
DEBUG result.interpretability.attn_scores 1520 
 [[0.02300451 0.03514301 0.04114106 ... 0.03595562 0.01738092 0.01570299]
 [0.02301429 0.03096868 0.03570428 ... 0.04088295 0.03267886 0.02867001]
 [0.02401602 0.03737306 0.04704846 ... 0.02976546 0.01646272 0.01355829]
 ...
 [0.02404005 0.03722696 0.03619801 ... 0.02630065 0.01331399 0.0144642 ]
 [0.02458259 0.03171846 0.02898844 ... 0.02928768 0.0193205  0.02331661]
 [0.02469109 0.03046295 0.02745384 ... 0.02745862 0.01847452 0.01940264]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' mentioned', ' that', ' Bill', ' is', ' in', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' has', ' moved', ' or', ' changed', ' locations', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 44), x_tokens=44, y_tokens=32, max_supp_attn=0.0312, attn_on_target=0.0313)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 44)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02887376 0.03864352 0.03902883 ... 0.01967161 0.008572   0.01922798]
 [0.0294739  0.0284954  0.02624444 ... 0.02209046 0.01356201 0.02526615]
 [0.03012889 0.04023813 0.0406391  ... 0.02897201 0.01194572 0.02983439]
 ...
 [0.03039846 0.04567161 0.04385278 ... 0.01012451 0.00761067 0.01129591]
 [0.03093639 0.0345296  0.03022467 ... 0.01255253 0.01118922 0.01266928]
 [0.03081305 0.04038493 0.03624045 ... 0.00961813 0.00930785 0.01178105]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' school', ',', ' which', ' contrad', 'icts', ' the', ' uncertainty', ' in', ' sentence', ' ', '13', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03217511 0.04352169 0.04647733 ... 0.03842098 0.04058497 0.01932503]
 [0.0328606  0.03841342 0.03518924 ... 0.02775261 0.03722871 0.03057886]
 [0.03364407 0.04682254 0.04820963 ... 0.03868543 0.03372581 0.01769253]
 ...
 [0.03399174 0.04540577 0.04630878 ... 0.05483295 0.0377325  0.01921145]
 [0.03450345 0.03617824 0.03337266 ... 0.04662272 0.03681953 0.02682164]
 [0.03468384 0.03832441 0.03664298 ... 0.06027068 0.03591837 0.01880388]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' journey', 'ing', ' to', ' the', ' bedroom', ' and', ' travelling', ' to', ' the', ' park', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' or', ' going', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 26), x_tokens=26, y_tokens=39, max_supp_attn=0.1538, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 26)
DEBUG result.interpretability.attn_scores 1014 
 [[0.0239123  0.04486864 0.04810484 ... 0.00969373 0.00929465 0.02442493]
 [0.02466505 0.02809963 0.02851108 ... 0.0075409  0.00767155 0.01615146]
 [0.02505766 0.03181544 0.03644226 ... 0.01081866 0.01025108 0.01537185]
 ...
 [0.02507617 0.03055428 0.02818661 ... 0.00719668 0.00692617 0.01503893]
 [0.02486877 0.02518431 0.0241403  ... 0.01190195 0.01122439 0.01733956]
 [0.02515395 0.02936307 0.02647599 ... 0.00928153 0.00941979 0.0152396 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03220669 0.04539812 0.04975011 0.07035767 0.06129682 0.05571562
  0.03906463 0.04085444 0.05129736 0.05623198 0.03325864 0.03883229
  0.03963513 0.10799545 0.10368071 0.03034438 0.02567744 0.02226551
  0.02443085 0.02539437 0.02102035 0.03560874 0.05599569 0.01193792
  0.0142051  0.03770857 0.04541076 0.03501804 0.10910879 0.00873828
  0.02297625 0.01091449]
 [0.03315693 0.04379606 0.04311211 0.07819617 0.0804243  0.08370585
  0.04338507 0.04193457 0.05299138 0.07548223 0.04569514 0.05917137
  0.05738353 0.14820006 0.12005424 0.03283442 0.02525847 0.02647831
  0.02615382 0.02635228 0.0218321  0.03791052 0.04286916 0.01075293
  0.01275951 0.03248203 0.04632964 0.02852369 0.09823485 0.01126501
  0.03037197 0.01474454]
 [0.03379336 0.04292127 0.04915909 0.06929342 0.06157616 0.06478781
  0.0419288  0.04129064 0.0486479  0.05871797 0.03558369 0.0498313
  0.04691477 0.1084104  0.07956742 0.02939072 0.02421129 0.02193636
  0.02355256 0.02311643 0.01922164 0.03577229 0.04097933 0.01322624
  0.014452   0.03016264 0.04523291 0.02519123 0.08212987 0.01423816
  0.03751453 0.0187999 ]
 [0.03233324 0.04731125 0.05141477 0.0372751  0.03397418 0.04095444
  0.04049671 0.04144549 0.04047836 0.03613729 0.02931988 0.03913903
  0.03880371 0.02896903 0.02828582 0.03787694 0.03257955 0.02691479
  0.02927366 0.02971303 0.02664282 0.03839937 0.06162494 0.04384226
  0.04356322 0.04328284 0.05720807 0.03268537 0.07107336 0.03923257
  0.05958738 0.03913694]
 [0.03409143 0.05324779 0.06109302 0.05291211 0.04631589 0.06744304
  0.06215861 0.0654313  0.09107578 0.06449563 0.03825566 0.05613848
  0.060658   0.05076368 0.03774732 0.0363725  0.02868418 0.02574487
  0.03061421 0.0314015  0.02428859 0.04150576 0.04913227 0.02039651
  0.02047254 0.0342207  0.06049827 0.02498406 0.05277109 0.02543083
  0.05251594 0.03276984]
 [0.03338505 0.05945305 0.05801147 0.03048306 0.026559   0.03707766
  0.04646696 0.04117734 0.04275209 0.0310059  0.02771144 0.03403157
  0.03709989 0.02210255 0.02278949 0.0482057  0.03621771 0.02853313
  0.03313226 0.03224169 0.02862249 0.03987594 0.08110009 0.04623597
  0.04642535 0.04177482 0.06052791 0.0283967  0.05065659 0.0384115
  0.0425404  0.03825082]
 [0.03430232 0.0796446  0.06869239 0.02999649 0.02756026 0.03657295
  0.05007781 0.04113769 0.05014439 0.03051042 0.02671449 0.03032894
  0.03337641 0.02047918 0.02314327 0.05675579 0.039885   0.02872275
  0.03443332 0.03482875 0.02812327 0.03597885 0.09626067 0.03909537
  0.03532056 0.0374264  0.06408489 0.02457833 0.03716926 0.02887862
  0.03003838 0.02595667]
 [0.03442368 0.05056357 0.04940943 0.02497301 0.02414652 0.02904262
  0.04220296 0.03347854 0.04008116 0.024778   0.02403375 0.02530043
  0.02697599 0.01789127 0.02065468 0.0468069  0.03587153 0.02581821
  0.03199847 0.03105374 0.02664454 0.03469596 0.06472547 0.04079994
  0.04474641 0.03704237 0.05673381 0.02294681 0.02839071 0.0305084
  0.03044225 0.0240488 ]
 [0.03466044 0.01940585 0.02074244 0.01346409 0.01377832 0.01692974
  0.01976696 0.01697815 0.01986667 0.01512273 0.01705683 0.01567267
  0.0168521  0.00922043 0.01160103 0.02371758 0.02096406 0.01819344
  0.02499397 0.02454789 0.02311205 0.02383532 0.03396163 0.04480034
  0.05360003 0.03301358 0.02534347 0.01788542 0.01720681 0.02327228
  0.02093068 0.01561559]
 [0.03440082 0.02703938 0.02880249 0.01836094 0.0187901  0.0234063
  0.02751602 0.02206725 0.02455368 0.01936657 0.02334517 0.02204701
  0.02242622 0.0127541  0.01539876 0.0346591  0.03203709 0.02712648
  0.03121683 0.03318701 0.03202229 0.03356684 0.03651718 0.05719011
  0.06181073 0.04062508 0.03325775 0.02489796 0.0251627  0.03956429
  0.03331671 0.02651727]
 [0.0344253  0.02752716 0.02846311 0.0218736  0.02023033 0.02667301
  0.02916744 0.02553426 0.02582474 0.02349193 0.02741533 0.02954485
  0.02956245 0.01515991 0.01512738 0.03503333 0.03553883 0.03529269
  0.03400467 0.03459152 0.03680658 0.03405903 0.02618263 0.06084446
  0.05695209 0.03148567 0.0283669  0.03052758 0.02504063 0.04770795
  0.03757888 0.04089411]
 [0.03392342 0.02584477 0.02276068 0.01888084 0.01495735 0.02149425
  0.02630811 0.02161216 0.02161222 0.01832823 0.02528301 0.02143535
  0.02502292 0.01100382 0.01190653 0.03553623 0.03131291 0.04915347
  0.03542423 0.04721412 0.05262212 0.03138533 0.01972836 0.07659789
  0.10201608 0.04205113 0.02535829 0.03211875 0.01595    0.09024244
  0.03262752 0.04647606]
 [0.03499077 0.02378998 0.02224321 0.01914523 0.01531105 0.02247593
  0.02585977 0.02256389 0.02221984 0.01969832 0.02989282 0.02444283
  0.02646553 0.01153243 0.01197739 0.03417359 0.02922071 0.04827872
  0.03631514 0.0551802  0.04862716 0.02655589 0.01732625 0.05881163
  0.07597517 0.04633165 0.02433566 0.03255676 0.01457431 0.08289751
  0.03933319 0.04953678]
 [0.03493881 0.02041207 0.01968557 0.01543483 0.01213493 0.01875444
  0.02321009 0.01924417 0.01957467 0.01605335 0.03376149 0.02062858
  0.02274889 0.00941908 0.0107995  0.03392566 0.03721582 0.04077797
  0.0403805  0.04677831 0.05560254 0.02784084 0.0170546  0.06966789
  0.05084731 0.05499688 0.01941517 0.03212467 0.01311263 0.06883345
  0.04085128 0.03695178]
 [0.03412731 0.02400466 0.02468472 0.01988731 0.01468345 0.02384306
  0.02910454 0.02716013 0.02599865 0.01977587 0.02807938 0.02153336
  0.02622823 0.01169576 0.01298784 0.02647949 0.03025279 0.02741449
  0.0352242  0.03473889 0.03783491 0.03033862 0.02007799 0.03814916
  0.02907151 0.03518897 0.02223112 0.02962465 0.01880542 0.03902083
  0.041394   0.02492135]
 [0.03530996 0.025449   0.0271288  0.02232684 0.01604205 0.02587158
  0.02912873 0.0282025  0.02472115 0.02185902 0.02944778 0.02633862
  0.02746426 0.01414351 0.01410905 0.02917567 0.02891011 0.02776272
  0.03173792 0.03169893 0.03416109 0.03384525 0.0187214  0.03430596
  0.03315266 0.03115549 0.02086761 0.03109151 0.02122987 0.04276388
  0.05116634 0.03913543]
 [0.03541244 0.02571918 0.03189953 0.02974321 0.02184288 0.03408687
  0.03267024 0.04145304 0.02986549 0.03446344 0.03596039 0.04454324
  0.03994755 0.02091509 0.01649109 0.02639873 0.02704708 0.02994634
  0.02948377 0.02639901 0.02539562 0.03652101 0.01809174 0.02005639
  0.02374327 0.02485649 0.02187542 0.0321957  0.02717848 0.03090424
  0.05852395 0.05384833]
 [0.03569709 0.03287662 0.03768068 0.03937914 0.02559945 0.04169209
  0.04049026 0.05304184 0.0336078  0.04476068 0.04431798 0.05800704
  0.05131602 0.02630168 0.01882222 0.03079468 0.02844853 0.03319314
  0.0311     0.02734703 0.02506644 0.03772225 0.02072275 0.01852682
  0.02014334 0.02207111 0.02572881 0.02873194 0.02617006 0.02664714
  0.04433535 0.05383024]
 [0.03550309 0.03054873 0.03302608 0.035471   0.0247052  0.03697367
  0.03727775 0.04388335 0.03190733 0.03859957 0.04186502 0.0460615
  0.04740134 0.02365529 0.01932666 0.03688384 0.03225709 0.03922284
  0.03537801 0.03275389 0.03120767 0.03809107 0.01898048 0.02533522
  0.02563522 0.02317285 0.02286841 0.04031673 0.02402691 0.03213702
  0.03780748 0.05886063]
 [0.03549027 0.02452018 0.02401885 0.02374435 0.01475963 0.02365172
  0.0287562  0.03104257 0.0251205  0.02350701 0.03141366 0.02911287
  0.03243743 0.01446686 0.013402   0.03841364 0.0354752  0.03900937
  0.03455519 0.03231987 0.03543874 0.03545447 0.01592774 0.03652862
  0.03106029 0.02568894 0.01860003 0.04647692 0.01796896 0.0386997
  0.03197727 0.05641024]
 [0.03535452 0.02781339 0.02615323 0.02667046 0.01598038 0.02400668
  0.03415232 0.03536312 0.02688753 0.02463152 0.03241412 0.02838778
  0.03408492 0.01484208 0.01456467 0.04322468 0.03772108 0.04484586
  0.03823813 0.0364633  0.04159031 0.03324592 0.01707136 0.03745457
  0.0370876  0.02797321 0.02083796 0.05008435 0.01593036 0.04441778
  0.02808086 0.06161242]
 [0.03556605 0.0245085  0.02310651 0.02342441 0.01665333 0.02263538
  0.0288449  0.03120497 0.02468036 0.02437947 0.03330069 0.03023092
  0.03049631 0.01493368 0.01442977 0.03764734 0.0424927  0.04140586
  0.04383736 0.03600052 0.04017363 0.03211782 0.01625892 0.02903998
  0.02730641 0.03028675 0.02309072 0.05080594 0.01598238 0.03583772
  0.02927129 0.06096441]
 [0.03573865 0.02224633 0.02122764 0.01833427 0.01429165 0.0187475
  0.02872878 0.02763033 0.02366051 0.01825067 0.03785969 0.02505268
  0.02672674 0.01244951 0.01204458 0.0366547  0.04326487 0.03754249
  0.04564186 0.03829195 0.04288692 0.0307283  0.01551272 0.04023537
  0.02853511 0.0361104  0.02169757 0.04227541 0.01346345 0.0435379
  0.02978946 0.05177318]
 [0.03488334 0.02613101 0.02365753 0.01832761 0.01516957 0.01986229
  0.03584889 0.03502322 0.0275617  0.01908006 0.06921027 0.03023909
  0.03414638 0.0129086  0.01342089 0.03521693 0.04654337 0.03895809
  0.04320112 0.03876191 0.04233656 0.03169491 0.01870547 0.04781794
  0.02593634 0.04487515 0.0259363  0.03924268 0.01524039 0.04372375
  0.03257502 0.03199072]
 [0.03557829 0.02871154 0.02836632 0.02655937 0.01896605 0.02635133
  0.03281861 0.03939097 0.03134695 0.02621488 0.03464981 0.03116566
  0.03112799 0.01825766 0.01645173 0.0285042  0.03095702 0.02868339
  0.03229516 0.03575341 0.03173562 0.0356005  0.01878512 0.02309376
  0.02137011 0.02873658 0.02406889 0.03257775 0.01887442 0.02901507
  0.03593124 0.03238254]
 [0.03426071 0.03174188 0.03177694 0.05094137 0.04680927 0.0424117
  0.03114139 0.03344644 0.03668237 0.04999332 0.03508258 0.03863354
  0.03793814 0.06882711 0.0904341  0.02445525 0.02655477 0.02835484
  0.02775072 0.02800839 0.02473209 0.03577796 0.03415782 0.01060215
  0.01422931 0.02964162 0.03435448 0.03826064 0.04739144 0.01047982
  0.02373233 0.01472721]
 [0.0339103  0.04061676 0.03541338 0.07295717 0.15974213 0.05317963
  0.03402975 0.03526304 0.03993516 0.07329998 0.05233566 0.05362377
  0.03635554 0.09726091 0.13163008 0.03398717 0.04618748 0.04836398
  0.03854239 0.03501207 0.03787225 0.03466866 0.04414861 0.01107427
  0.01241288 0.03283796 0.05074622 0.03914582 0.04385136 0.00857301
  0.01342998 0.00999371]
 [0.03397524 0.03350605 0.02889153 0.04585568 0.08503158 0.02893724
  0.027437   0.0302608  0.03048384 0.04816222 0.04179494 0.03747194
  0.02937637 0.03632882 0.05485938 0.03266162 0.06629741 0.06725151
  0.05775306 0.04732914 0.06367    0.03327863 0.03640902 0.01934401
  0.01994679 0.03194697 0.04007529 0.05021134 0.0250263  0.01370705
  0.01622824 0.01566231]
 [0.03416047 0.03525123 0.02962837 0.04573126 0.05266814 0.03271558
  0.03196065 0.03288371 0.03642043 0.04360171 0.03494066 0.03305328
  0.03102726 0.03911206 0.04429242 0.02386925 0.04291599 0.04280834
  0.03933663 0.04352089 0.04070962 0.04392396 0.04297061 0.01423623
  0.01722312 0.03285318 0.03491767 0.05652327 0.02827872 0.01131383
  0.0151318  0.01327371]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Julie', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Julie', ' is', ' in', ' the', ' office', ',', ' not', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 38), x_tokens=38, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 38)
DEBUG result.interpretability.attn_scores 1292 
 [[0.02748465 0.0446277  0.04100626 ... 0.03020342 0.01853195 0.02535773]
 [0.02812995 0.03519451 0.0324765  ... 0.03098481 0.02627842 0.02897426]
 [0.02866894 0.04824416 0.04713007 ... 0.02626718 0.01247278 0.01857912]
 ...
 [0.02886312 0.04113461 0.03794064 ... 0.02447546 0.00955872 0.01929859]
 [0.02932883 0.03247034 0.02645794 ... 0.02631688 0.01696097 0.02137666]
 [0.02932577 0.0339541  0.02815826 ... 0.02399147 0.01467719 0.02541169]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Bill', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 44), x_tokens=44, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 44)
DEBUG result.interpretability.attn_scores 1232 
 [[0.03342709 0.0332488  0.03615828 ... 0.05288735 0.01804999 0.04718997]
 [0.03437067 0.0251165  0.02732025 ... 0.0491385  0.0257806  0.02677158]
 [0.03486563 0.03473763 0.04076097 ... 0.07234809 0.03207029 0.05702242]
 ...
 [0.03547283 0.03844977 0.03153731 ... 0.01366436 0.01749393 0.02587456]
 [0.03602785 0.04235049 0.03711572 ... 0.01361368 0.01728094 0.02859107]
 [0.03606017 0.03728683 0.03296848 ... 0.01429251 0.01805142 0.03064205]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Fred', ' and', ' Julie', "'s", ' locations', ',', ' but', ' not', ' Mary', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02670879 0.04008549 0.03663057 ... 0.02128159 0.01714764 0.04205875]
 [0.02729265 0.03051377 0.02963811 ... 0.02684332 0.02315407 0.02963351]
 [0.02786099 0.03936918 0.03896912 ... 0.01803166 0.01378405 0.03606969]
 ...
 [0.02834762 0.03282011 0.02432218 ... 0.02562879 0.02623271 0.03428121]
 [0.02804419 0.04171881 0.02829093 ... 0.024186   0.02655119 0.04262648]
 [0.02838653 0.03422124 0.0254476  ... 0.01620986 0.01662523 0.03628737]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' park', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Fred', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 26), x_tokens=26, y_tokens=48, max_supp_attn=0.1042, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 26)
DEBUG result.interpretability.attn_scores 1248 
 [[0.01927557 0.03848303 0.03981974 ... 0.01901279 0.00324447 0.02232714]
 [0.01988041 0.02366769 0.02342238 ... 0.01375155 0.00301811 0.01485183]
 [0.02022291 0.02697015 0.0304461  ... 0.01739628 0.00408222 0.01474601]
 ...
 [0.02029658 0.02373858 0.02340676 ... 0.01111994 0.00290795 0.01397306]
 [0.02031245 0.0189937  0.01905787 ... 0.01539584 0.00917036 0.01677773]
 [0.02059755 0.01905171 0.0189016  ... 0.0137218  0.00670804 0.01514525]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Fred', ' went', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Fred', ' is', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.025, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02325175 0.03846295 0.04378364 ... 0.01103407 0.01876383 0.00728962]
 [0.02390967 0.03757727 0.04039098 ... 0.01308348 0.02486665 0.01088092]
 [0.02429642 0.03583387 0.04256993 ... 0.02130472 0.02712798 0.01301125]
 ...
 [0.02430986 0.03888483 0.03293013 ... 0.00724977 0.01469599 0.00659229]
 [0.02463641 0.02855146 0.02355631 ... 0.00768169 0.0135776  0.00832164]
 [0.02476874 0.02955786 0.02404205 ... 0.0066567  0.01272934 0.00759555]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' back', ' to', ' the', ' previous', ' context', ' sentence', ' ', '4', ',', ' which', ' states', ' that', ' Fred', ' went', ' to', ' the', ' bedroom', '.', ' Therefore', ',', ' we', ' can', ' conclude', ' that', ' Fred', ' is', ' still', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 38), x_tokens=38, y_tokens=61, max_supp_attn=0.0492, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 38)
DEBUG result.interpretability.attn_scores 2318 
 [[0.01516876 0.02051899 0.0208745  ... 0.02218505 0.0053183  0.0073541 ]
 [0.01538968 0.01466083 0.01444275 ... 0.02114303 0.02996999 0.01561491]
 [0.01584952 0.02134914 0.0221589  ... 0.01521806 0.00415732 0.00614294]
 ...
 [0.01608026 0.02014889 0.01718785 ... 0.01735065 0.00358769 0.00589464]
 [0.01627815 0.01500094 0.01242912 ... 0.01434771 0.00785993 0.01202107]
 [0.01628967 0.01758648 0.01377429 ... 0.01980796 0.00555941 0.008451  ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' means', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 44), x_tokens=44, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 44)
DEBUG result.interpretability.attn_scores 1848 
 [[0.02214223 0.03627423 0.03657023 ... 0.11842432 0.01191053 0.00777618]
 [0.02267152 0.02471365 0.02491274 ... 0.04999874 0.0356558  0.01183961]
 [0.02307    0.03742489 0.0399067  ... 0.07895434 0.02160766 0.01194382]
 ...
 [0.02324351 0.0323868  0.03497103 ... 0.04261063 0.00776327 0.00552845]
 [0.02378775 0.02291774 0.0243303  ... 0.01949409 0.00746523 0.00666867]
 [0.02366172 0.02556869 0.02681251 ... 0.02980413 0.00642631 0.00596658]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', ' from', ' the', ' office', '.', ' Therefore', ',', ' we', ' can', ' conclude', ' that', ' Mary', ' is', ' still', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0625, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01933847 0.02860801 0.02976204 ... 0.02828333 0.03589754 0.02279508]
 [0.01967775 0.02341858 0.02457491 ... 0.01641513 0.02849937 0.0280365 ]
 [0.02005563 0.0308415  0.03489865 ... 0.03235341 0.03099519 0.02102633]
 ...
 [0.02035989 0.03496515 0.02789611 ... 0.08380666 0.03117595 0.02185635]
 [0.02084116 0.02331666 0.01809548 ... 0.05750173 0.02353387 0.0254482 ]
 [0.02056537 0.02929826 0.02209786 ... 0.06409159 0.03337994 0.02105142]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' journey', 'ing', ' to', ' the', ' cinema', ' and', ' Fred', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0541, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.0253573  0.04307062 0.04607582 0.07537495 0.07316425 0.04515558
  0.03345532 0.02939703 0.03086794 0.0473138  0.03577838 0.02248084
  0.02433091 0.12091399 0.12629661 0.03490787 0.02627145 0.01836183
  0.01800434 0.01917383 0.01922094 0.03844126 0.0590967  0.0091094
  0.00776671 0.02539136]
 [0.02615632 0.02695579 0.02717005 0.05593749 0.05191761 0.03893299
  0.02354683 0.02134186 0.02476325 0.04087419 0.03080649 0.02414319
  0.02416766 0.12391212 0.15177499 0.03345517 0.02835294 0.02171213
  0.01980513 0.01980926 0.01796574 0.03241095 0.03527799 0.00709314
  0.00651058 0.01662502]
 [0.02658726 0.03026942 0.03484231 0.05913851 0.05870908 0.049979
  0.03131576 0.029769   0.03262788 0.04842609 0.03534326 0.03863901
  0.03780242 0.09842744 0.09351937 0.02765602 0.02600488 0.02215473
  0.01919247 0.01995345 0.01713056 0.02921692 0.03265091 0.00980291
  0.0086597  0.01606348]
 [0.0256959  0.03580651 0.04294424 0.04601833 0.04794269 0.04698905
  0.03525597 0.03746678 0.03699607 0.04406472 0.03587998 0.04570227
  0.03920546 0.05815035 0.05394042 0.03484959 0.03250537 0.02844938
  0.02430612 0.02606276 0.02371379 0.03250768 0.04705011 0.02694429
  0.02277193 0.02747997]
 [0.02665464 0.03142173 0.03818835 0.03483342 0.03035108 0.04168947
  0.03551667 0.03902134 0.03463738 0.0348803  0.03074354 0.04270677
  0.03648773 0.02242306 0.01736633 0.02613219 0.02545973 0.02497564
  0.02288067 0.02476459 0.02199233 0.0269994  0.03416888 0.02166597
  0.02301637 0.027695  ]
 [0.02700889 0.02860529 0.03250967 0.02802478 0.02288483 0.0391422
  0.03436508 0.03567258 0.03485064 0.03192793 0.02942602 0.04506961
  0.03595474 0.01887649 0.01434003 0.02392044 0.02506883 0.02332276
  0.02357639 0.02446546 0.02138379 0.02658932 0.03148646 0.02000345
  0.0225968  0.02656861]
 [0.02645101 0.04387344 0.04049682 0.03078473 0.02543773 0.04401834
  0.04132944 0.04675246 0.0415576  0.0381347  0.03733554 0.06123124
  0.05077263 0.02086498 0.01576562 0.0318733  0.02930219 0.02900551
  0.02681963 0.02710165 0.02374327 0.0282994  0.03595565 0.0223394
  0.02110396 0.02319192]
 [0.02709368 0.03601563 0.04063879 0.03166831 0.02259743 0.05291958
  0.04315256 0.04354957 0.04211182 0.03609638 0.03161931 0.06616928
  0.05166766 0.02042174 0.01464036 0.02882922 0.02781776 0.02641563
  0.02449557 0.02657459 0.02269525 0.02692963 0.02962402 0.0173485
  0.01687268 0.01809338]
 [0.02723521 0.04299897 0.05231934 0.03696121 0.02446805 0.07459402
  0.06570692 0.04692021 0.05706656 0.03876003 0.03067617 0.05582538
  0.04287488 0.02064432 0.01537474 0.02583961 0.02285654 0.02069988
  0.02063413 0.02362763 0.02017755 0.0275024  0.0351176  0.01514325
  0.01419418 0.01831254]
 [0.0266683  0.02274429 0.02257425 0.01841308 0.01450764 0.02052716
  0.02670852 0.02753718 0.02312284 0.02057879 0.02843761 0.02516001
  0.03164094 0.01010728 0.01017574 0.03244182 0.03060833 0.03008278
  0.02861686 0.02883866 0.03310275 0.02599403 0.01969626 0.03451647
  0.02959181 0.02200846]
 [0.0265888  0.02079793 0.01802149 0.01653528 0.01260328 0.0149824
  0.02335625 0.02360702 0.01889876 0.01616687 0.02268714 0.01881852
  0.02200596 0.00849276 0.00882373 0.0352466  0.0305573  0.03961982
  0.03083254 0.03420866 0.04100555 0.02451135 0.01711042 0.04618736
  0.03775936 0.02670424]
 [0.02722182 0.02016767 0.01729052 0.01683268 0.01422524 0.0165506
  0.02159965 0.0231767  0.01883666 0.0187161  0.02691578 0.02438477
  0.02319004 0.00910277 0.00911134 0.03303651 0.03024881 0.03090691
  0.03076847 0.02951484 0.03255102 0.02256309 0.01380512 0.02567386
  0.02531745 0.01747064]
 [0.02721722 0.01743897 0.01515422 0.01262451 0.01221591 0.01266441
  0.01932525 0.01886415 0.01704509 0.01426159 0.02707702 0.018372
  0.01888008 0.0070681  0.00771967 0.02969318 0.03324289 0.02941213
  0.03644177 0.03266197 0.03724672 0.02287643 0.01369274 0.02661422
  0.02523597 0.01914741]
 [0.02658993 0.02039214 0.01729882 0.01356557 0.0131231  0.01404517
  0.02138929 0.01963622 0.01995918 0.01461684 0.02571533 0.01651311
  0.01889641 0.00750557 0.00862567 0.03015013 0.03138603 0.02930651
  0.04017111 0.03587044 0.03767269 0.02518038 0.02238433 0.04014645
  0.03576453 0.03520675]
 [0.02734654 0.02417517 0.02145362 0.01683125 0.01450139 0.01803679
  0.02335894 0.02482712 0.02273265 0.01876001 0.02578932 0.02268232
  0.02296725 0.00954729 0.009491   0.02320753 0.0252653  0.02354521
  0.03484863 0.03305737 0.02964386 0.0250226  0.02059134 0.01973541
  0.01919529 0.01995251]
 [0.02690194 0.02936643 0.02968242 0.02962673 0.02523904 0.0325012
  0.02735039 0.03058587 0.03052931 0.03529675 0.02802237 0.0421944
  0.03614681 0.02156031 0.01564115 0.02517427 0.02709636 0.02809755
  0.02350875 0.02404319 0.0214625  0.02909625 0.03299426 0.02946576
  0.02612662 0.01913376]
 [0.0267548  0.04571451 0.04446888 0.02391718 0.01971215 0.02796146
  0.03674737 0.03638421 0.03461395 0.02294974 0.02429952 0.02742631
  0.03035026 0.01532031 0.01385011 0.03129193 0.02595503 0.02370694
  0.0224812  0.02570586 0.02471909 0.02849302 0.05235734 0.034841
  0.03470999 0.02982042]
 [0.02716082 0.06504353 0.06824532 0.02775898 0.02136659 0.03053217
  0.04426009 0.03939956 0.04136778 0.02445719 0.02352536 0.02573673
  0.0278342  0.01532096 0.01406563 0.03706063 0.02779166 0.02200885
  0.02063888 0.02498088 0.02093186 0.02873009 0.06195869 0.02111659
  0.02020395 0.0217802 ]
 [0.02730077 0.03605365 0.03926216 0.02348185 0.01847256 0.0258259
  0.03472737 0.03377105 0.03144443 0.0215434  0.02104052 0.02403725
  0.02396695 0.01354479 0.01228832 0.02869601 0.02434098 0.02118505
  0.02024297 0.02393169 0.02209618 0.02942561 0.04310273 0.02684959
  0.03081774 0.03033152]
 [0.02790266 0.02814612 0.02828767 0.02062276 0.01605462 0.02422004
  0.02832847 0.03266348 0.02572758 0.02013175 0.02191629 0.02449863
  0.025394   0.01170897 0.01001036 0.02280076 0.01930674 0.02027874
  0.01819933 0.02075724 0.02011778 0.02714799 0.02247807 0.02423452
  0.02400723 0.02238641]
 [0.02737844 0.01985254 0.01821859 0.01426382 0.01217467 0.01518324
  0.02123467 0.02126372 0.01896204 0.01468868 0.02161258 0.01508244
  0.01967716 0.00845876 0.00803622 0.02676803 0.02347237 0.02323926
  0.02156676 0.02483132 0.02921005 0.02464788 0.01906434 0.05567183
  0.04326433 0.02650576]
 [0.0270896  0.01838948 0.01575304 0.01297076 0.0107439  0.01193052
  0.01827435 0.01740128 0.01646743 0.01280869 0.01845518 0.01211665
  0.01677888 0.00740935 0.00739215 0.03374894 0.02413834 0.03263339
  0.02307289 0.02817368 0.03660735 0.0238244  0.01649544 0.07270578
  0.04409598 0.02446552]
 [0.02773239 0.01737536 0.01654972 0.01386153 0.01191351 0.01324015
  0.01797768 0.01740858 0.01801528 0.01367352 0.01676659 0.01259733
  0.01567354 0.00814637 0.00767103 0.02810988 0.0169493  0.02080814
  0.01735332 0.02247097 0.02216488 0.02057487 0.01700255 0.05800667
  0.04060363 0.02449942]
 [0.02749884 0.01663542 0.01498431 0.01226246 0.01042401 0.01164433
  0.01655011 0.01622807 0.01607491 0.01239092 0.01904712 0.01297752
  0.01615371 0.00716945 0.00678449 0.03598187 0.02011318 0.03088513
  0.02281106 0.03262032 0.03147892 0.02189802 0.01425068 0.06474648
  0.03124105 0.01535928]
 [0.02739982 0.01578289 0.01374285 0.01060735 0.00919942 0.01043095
  0.01483847 0.0139056  0.01530274 0.01114424 0.01980251 0.01158844
  0.01453651 0.0063856  0.00617384 0.03395375 0.02145656 0.02934678
  0.0278804  0.0314959  0.0342971  0.02224245 0.01423882 0.06290231
  0.03207644 0.01992067]
 [0.02670489 0.03308001 0.02593993 0.0399769  0.04937846 0.03917065
  0.03177694 0.028129   0.02942906 0.04653546 0.04702421 0.03697567
  0.03243802 0.0388473  0.02862094 0.03206074 0.02791981 0.0306399
  0.03123281 0.02806621 0.02688871 0.0340216  0.02590591 0.03253828
  0.01575164 0.01817112]
 [0.02787792 0.01648407 0.01478495 0.01264032 0.01038027 0.01227446
  0.0151567  0.01557061 0.01695136 0.01313999 0.01869704 0.0128097
  0.01564377 0.00775445 0.00666451 0.02098482 0.01873549 0.02177979
  0.02443664 0.02309252 0.02738013 0.02196605 0.01455789 0.0329492
  0.03522321 0.03097865]
 [0.0276662  0.01861322 0.01738415 0.01308283 0.0107614  0.01371127
  0.02159426 0.02237337 0.01957602 0.01404206 0.01773071 0.01530125
  0.02160934 0.00884876 0.0069374  0.01693168 0.02326621 0.02188541
  0.02357955 0.02522583 0.02627747 0.02702541 0.01648245 0.02241028
  0.05799234 0.05168581]
 [0.02739182 0.01678092 0.01473209 0.01260152 0.01009162 0.01250793
  0.0191913  0.01918819 0.01675685 0.01345931 0.01778483 0.0129503
  0.01827892 0.00805208 0.00660938 0.01725067 0.02492689 0.02498785
  0.03248778 0.03181205 0.03525182 0.02391954 0.01413774 0.02139295
  0.07780387 0.05889157]
 [0.02775073 0.01701709 0.01520481 0.01231705 0.01067018 0.01274726
  0.02109892 0.02203162 0.01740364 0.01354446 0.02239779 0.01504135
  0.02051456 0.00838371 0.00672338 0.0179367  0.03048604 0.02219598
  0.03048331 0.02669684 0.03234818 0.02220978 0.01279201 0.01738173
  0.05882867 0.05343452]
 [0.02756045 0.01326549 0.01224616 0.00939906 0.00838344 0.009964
  0.01755247 0.01621452 0.01468641 0.01056681 0.0224508  0.01133299
  0.01694886 0.00668259 0.00536588 0.01792528 0.03785221 0.02448354
  0.03421778 0.03386251 0.03941607 0.02066446 0.01222503 0.02020115
  0.04117585 0.0754678 ]
 [0.02710246 0.02246937 0.02408983 0.02176209 0.02181894 0.02536147
  0.02994393 0.03190599 0.04942222 0.03114427 0.02609192 0.02747681
  0.03270595 0.01909715 0.01511831 0.01748569 0.02616294 0.02546774
  0.02647513 0.02841594 0.02815337 0.02831891 0.02480584 0.01695641
  0.02325893 0.04339666]
 [0.02834462 0.01821912 0.0186762  0.01620196 0.01243084 0.01728365
  0.02254807 0.02522097 0.02334195 0.01875335 0.02343259 0.01903832
  0.02380273 0.01118876 0.00840216 0.01490832 0.02160172 0.01727531
  0.02120052 0.02297116 0.0218479  0.02415408 0.01465897 0.01045086
  0.01452384 0.02906371]
 [0.02677423 0.02863234 0.02811247 0.05019346 0.05411312 0.03823341
  0.02553806 0.026315   0.03096988 0.0487188  0.03247741 0.027707
  0.03175234 0.08462864 0.09780265 0.02344397 0.02511838 0.02337722
  0.02038219 0.020086   0.01835709 0.03143127 0.032896   0.00688906
  0.00750401 0.01833652]
 [0.02662532 0.02890215 0.02681287 0.05305973 0.10532597 0.03421333
  0.02020175 0.02237858 0.02558932 0.05138645 0.03616712 0.02650603
  0.02393622 0.07914106 0.1010325  0.02772952 0.03645047 0.03592296
  0.02860302 0.02398363 0.02272364 0.02805646 0.03220987 0.00646097
  0.00607298 0.01561772]
 [0.02649244 0.02324441 0.02231146 0.03805887 0.060451   0.0245305
  0.01649797 0.02171696 0.02397468 0.04476456 0.0344443  0.03110299
  0.02776697 0.02808446 0.02993154 0.02082545 0.03982725 0.05954739
  0.06201275 0.03785956 0.03184188 0.02452752 0.02548576 0.01047107
  0.00999755 0.01618298]
 [0.02671595 0.0261983  0.02353177 0.03778876 0.052245   0.0263054
  0.01922816 0.02240463 0.02731879 0.04128132 0.03258232 0.02760353
  0.02724551 0.027808   0.0279125  0.01769193 0.03208368 0.04227604
  0.04573919 0.03323156 0.02718215 0.04257945 0.03219123 0.00903339
  0.00836282 0.0146588 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03115795 0.04138919 0.04288848 0.06632598 0.05769083 0.05047772
  0.03294522 0.03611535 0.04402315 0.0492604  0.03089094 0.03395955
  0.03373329 0.1013651  0.09943587 0.02589724 0.02457503 0.02027349
  0.0229993  0.02558145 0.02186404 0.03567171 0.04955602 0.01530813
  0.01611737 0.03703516 0.04062712 0.03747258 0.10835768 0.01585431
  0.01931711 0.01372696]
 [0.03190472 0.04024851 0.04006024 0.07744183 0.07561127 0.07690769
  0.03753028 0.03896745 0.05111821 0.06904589 0.04149022 0.05249096
  0.05116127 0.14282978 0.11230814 0.02728131 0.0241091  0.02443678
  0.0246378  0.02727614 0.02291744 0.03794002 0.0391431  0.01333449
  0.01406775 0.03193877 0.03962325 0.03179684 0.10161892 0.02240187
  0.02588045 0.01820387]
 [0.03253865 0.03811042 0.04351563 0.0671145  0.05739476 0.05808938
  0.03469943 0.03684143 0.04457773 0.05348612 0.03199387 0.04487567
  0.03942715 0.10506941 0.07644916 0.02480237 0.02275834 0.01980444
  0.02182622 0.02380354 0.01985892 0.03461714 0.03677279 0.01659464
  0.01697863 0.03030002 0.03726121 0.02686445 0.08520715 0.03264666
  0.03794249 0.02092755]
 [0.03142207 0.04587229 0.04995907 0.04040382 0.03322889 0.03921247
  0.03744271 0.04077507 0.03958447 0.03642651 0.02883134 0.03922208
  0.03675651 0.03182173 0.02888616 0.03622765 0.03168729 0.02666137
  0.0275044  0.03007587 0.02638153 0.03632986 0.05545712 0.04528388
  0.03926069 0.04378992 0.0492781  0.03445928 0.05928994 0.06422387
  0.09195405 0.04340888]
 [0.0328888  0.04750903 0.05617127 0.05326407 0.04285938 0.06324365
  0.05164002 0.05670505 0.07903832 0.06164394 0.03432992 0.05621036
  0.05800257 0.0536037  0.03619847 0.03111157 0.02774297 0.02453951
  0.02839319 0.03240227 0.02461172 0.03877207 0.04733221 0.02323581
  0.02310031 0.03915894 0.05497653 0.02643992 0.05381374 0.049583
  0.06613356 0.03334336]
 [0.03230809 0.060709   0.06033493 0.03349272 0.02648179 0.03797804
  0.04600703 0.04302913 0.04713164 0.03269478 0.02683465 0.03573909
  0.03772147 0.02435447 0.02386987 0.04768489 0.03838809 0.02936316
  0.03253834 0.03455688 0.02921229 0.03731477 0.07583524 0.04840661
  0.04462522 0.04494247 0.05606897 0.02853388 0.03711617 0.05299474
  0.08405796 0.04102329]
 [0.03307618 0.07664526 0.0698875  0.03187334 0.02566595 0.0352302
  0.04658842 0.03960256 0.05036671 0.03036369 0.02387107 0.02873749
  0.03126368 0.02075276 0.02374707 0.05125829 0.03943285 0.02693204
  0.03221431 0.03618804 0.02862197 0.0332936  0.09763061 0.0463342
  0.03709676 0.04234635 0.06525141 0.0243274  0.02810164 0.0341194
  0.07835257 0.03165095]
 [0.03307709 0.04796928 0.04895902 0.0256237  0.02200785 0.02780453
  0.0386184  0.03197113 0.03874053 0.02482065 0.02141214 0.02390568
  0.02534558 0.01783265 0.02161092 0.04375757 0.03752604 0.02526238
  0.03204541 0.03377305 0.02860686 0.03252831 0.06843459 0.04997227
  0.04825137 0.04453827 0.05846054 0.02419358 0.02748072 0.02918205
  0.05528728 0.03436089]
 [0.03339832 0.02175635 0.02358479 0.01461071 0.01420806 0.01802721
  0.01947429 0.0177915  0.02159061 0.01646246 0.01626316 0.0159471
  0.01691767 0.00998113 0.0138214  0.02616001 0.02622931 0.02002891
  0.0271177  0.02756246 0.02436013 0.0253185  0.03371772 0.03881143
  0.04378432 0.03432586 0.02986507 0.01873545 0.01777801 0.0183386
  0.02571324 0.02523836]
 [0.03312484 0.02754858 0.02931633 0.0189546  0.01804545 0.02486815
  0.02727778 0.02290776 0.02642514 0.02124962 0.02230736 0.02233987
  0.02294402 0.01353573 0.0167627  0.03698755 0.03341139 0.02612873
  0.03078827 0.03252933 0.0288445  0.03178793 0.03439754 0.05096614
  0.04872219 0.03587683 0.03569636 0.02167734 0.02418671 0.03253236
  0.03287813 0.04116715]
 [0.03332315 0.02993868 0.03001734 0.02256241 0.02055546 0.02702744
  0.03002681 0.02695933 0.02771315 0.0255428  0.02659915 0.02954226
  0.03053223 0.01642861 0.01620892 0.04053176 0.03233742 0.03075781
  0.02938897 0.03007945 0.03019074 0.03311728 0.02649155 0.05879199
  0.04593353 0.03098485 0.03144468 0.03000708 0.02429206 0.04526596
  0.03455308 0.04801789]
 [0.03291865 0.02750083 0.02542145 0.01840607 0.01646806 0.0221547
  0.02711126 0.02274435 0.0225953  0.02007912 0.02407878 0.02238764
  0.02534249 0.01163331 0.01258912 0.03935916 0.02856243 0.03633369
  0.03053454 0.03373458 0.03600333 0.03117284 0.02032709 0.05839812
  0.04394051 0.02903083 0.02734064 0.02866883 0.01597634 0.04206569
  0.02490989 0.06918478]
 [0.03383349 0.02449264 0.02377608 0.01763571 0.01773458 0.02255471
  0.02708399 0.02373324 0.02370447 0.02110678 0.03175397 0.0268867
  0.02753529 0.01193799 0.01236135 0.04374928 0.02971315 0.04532227
  0.03451997 0.04527441 0.03913042 0.02712652 0.0184687  0.04687653
  0.04041395 0.02683429 0.02215891 0.02467715 0.01385804 0.03283144
  0.02030424 0.05680691]
 [0.03378799 0.02098971 0.02013424 0.01394118 0.01441695 0.01829856
  0.02542165 0.02024771 0.02019009 0.01693066 0.04335819 0.02309363
  0.02389196 0.00961573 0.01115844 0.03864307 0.03492851 0.03955942
  0.03756234 0.03784694 0.03933029 0.02822632 0.01813949 0.04545075
  0.0403517  0.03344354 0.01829106 0.02796934 0.0126955  0.03119203
  0.02168769 0.05037209]
 [0.03274137 0.02779396 0.02636702 0.0183012  0.01893695 0.02492548
  0.03536838 0.0332801  0.03434806 0.02343192 0.0341266  0.02899414
  0.03221781 0.01244893 0.01342268 0.03040217 0.0375815  0.03669784
  0.04374873 0.04510978 0.03784344 0.03292861 0.02213939 0.03748503
  0.03855447 0.03941647 0.02214414 0.03519812 0.01935105 0.0328687
  0.03388135 0.04071463]
 [0.03421817 0.02435071 0.0253137  0.01989638 0.0182675  0.0247535
  0.0281233  0.02820764 0.02438162 0.02226935 0.03036287 0.02837478
  0.02727704 0.01413357 0.01339475 0.0275208  0.02689429 0.02823484
  0.03123992 0.02958733 0.0314353  0.03176858 0.01867939 0.02588124
  0.02865498 0.02960942 0.02167173 0.02732215 0.02003753 0.03286467
  0.03155708 0.03477419]
 [0.03435986 0.02659094 0.0301481  0.02854988 0.02385006 0.03336645
  0.03404196 0.04275284 0.03147266 0.03499413 0.03166182 0.04366771
  0.03927406 0.02188667 0.0167627  0.02447451 0.02510088 0.02835767
  0.02800267 0.02642521 0.02620547 0.03369487 0.01896827 0.02137935
  0.02448106 0.02636773 0.02669107 0.03161522 0.02595924 0.04023697
  0.03315111 0.02915811]
 [0.03453305 0.03319093 0.03632276 0.0352089  0.02641929 0.03970802
  0.03981419 0.04859012 0.03232263 0.0417652  0.04018689 0.05253954
  0.04766794 0.02406759 0.01791649 0.03002183 0.0263016  0.03086271
  0.02899693 0.02720008 0.02647856 0.03457626 0.02158796 0.02236525
  0.02325763 0.02209244 0.0310018  0.02755887 0.02456778 0.04436167
  0.03065915 0.03081651]
 [0.03432685 0.03194017 0.0323625  0.03187132 0.02545213 0.03487732
  0.03619955 0.0406841  0.03038761 0.0367598  0.03768261 0.04335682
  0.0443942  0.02182385 0.01821168 0.03494419 0.02819107 0.03583203
  0.03259107 0.03193252 0.03172465 0.03576242 0.02008594 0.0311181
  0.03094453 0.02223911 0.02800496 0.03725047 0.02307376 0.04420558
  0.02684028 0.03443675]
 [0.03435252 0.0246266  0.02389837 0.0210479  0.01475085 0.02328976
  0.02802856 0.02932793 0.02426909 0.02205707 0.02773134 0.0270041
  0.03119718 0.01309284 0.01292957 0.03883402 0.03006965 0.03541353
  0.03189944 0.03055457 0.03462223 0.03333351 0.01684898 0.04285686
  0.0420301  0.02307407 0.02062358 0.04285143 0.01829694 0.04134669
  0.02323103 0.03843367]
 [0.03422218 0.02821707 0.02633796 0.02467184 0.01606507 0.02465413
  0.03434629 0.03471373 0.02560331 0.02421159 0.03130198 0.02795135
  0.03432401 0.01400583 0.01464437 0.03788948 0.03285732 0.03972465
  0.03516803 0.03291139 0.03853951 0.03177511 0.01741769 0.03637337
  0.04102736 0.0247671  0.02007736 0.04166275 0.01680405 0.04006074
  0.01993864 0.03929426]
 [0.03436837 0.02440907 0.02293221 0.02193321 0.01586605 0.02280822
  0.02822523 0.02933973 0.02310969 0.02271176 0.03122591 0.02742105
  0.02977603 0.01382784 0.01410985 0.0349797  0.03627481 0.03670219
  0.03773659 0.03261881 0.03908335 0.03157242 0.01694939 0.03180154
  0.04893382 0.02682505 0.02139124 0.04259109 0.01764296 0.03871639
  0.02212739 0.03419349]
 [0.0346378  0.02708568 0.02546625 0.02296776 0.01528871 0.0242452
  0.03309451 0.03253381 0.02797838 0.02333471 0.03638659 0.02803636
  0.03272348 0.01404143 0.01420808 0.03834242 0.03437692 0.03754246
  0.03764488 0.03596166 0.04074683 0.03219791 0.01717737 0.03540035
  0.04356137 0.02605707 0.02273465 0.0335703  0.01573929 0.03721998
  0.02042903 0.03588851]
 [0.0346691  0.02054936 0.01990179 0.01685727 0.01255994 0.01882723
  0.02959471 0.02607489 0.0213937  0.01665688 0.05063405 0.02172294
  0.02645745 0.01104175 0.01118589 0.0332508  0.03597574 0.03269325
  0.03611796 0.03212847 0.03732226 0.02992718 0.01477496 0.0341758
  0.04060295 0.0321501  0.01668192 0.03117551 0.01379696 0.03214567
  0.02201917 0.03788435]
 [0.0328332  0.02719709 0.02492142 0.02040055 0.01539234 0.02506943
  0.04639031 0.0416275  0.03139229 0.02284667 0.06809522 0.03462587
  0.04169882 0.01351793 0.01447534 0.03348318 0.05577559 0.05340699
  0.06131364 0.05794166 0.05118556 0.03519595 0.02385211 0.03950837
  0.04568681 0.06021201 0.02026927 0.0490366  0.02019612 0.03054856
  0.03215374 0.03988019]
 [0.03458164 0.02216885 0.02347825 0.02494207 0.01646147 0.02656501
  0.03055221 0.03707223 0.02672655 0.0245072  0.02955249 0.02860714
  0.03035903 0.01759393 0.01509413 0.02056692 0.02464039 0.02664561
  0.02884026 0.02738262 0.02841396 0.03155984 0.01647121 0.01666888
  0.02243258 0.02794873 0.01837964 0.02920975 0.0221732  0.02770477
  0.03078394 0.02683006]
 [0.03302626 0.02973973 0.03083457 0.05195929 0.04777249 0.04330046
  0.02929469 0.02999336 0.03520004 0.04972463 0.03134147 0.03651957
  0.03493794 0.07157979 0.09350946 0.02173556 0.02541579 0.02816201
  0.02685557 0.02787921 0.02673479 0.03422579 0.03428807 0.01320565
  0.01522554 0.03269289 0.03634592 0.03863595 0.04972173 0.01542281
  0.02062792 0.01367399]
 [0.03272383 0.03577071 0.03287826 0.06879438 0.1523295  0.0512357
  0.03019907 0.03033366 0.03533466 0.06736553 0.04482828 0.04743083
  0.03179873 0.09159545 0.12600964 0.02899482 0.04340143 0.04585165
  0.03649625 0.03377574 0.04050687 0.03329626 0.04188954 0.01363694
  0.01280924 0.03219514 0.05081343 0.03789598 0.04608475 0.01086913
  0.01005463 0.0109477 ]
 [0.03268473 0.03203832 0.02706803 0.04565319 0.08638985 0.02777396
  0.02478141 0.02727772 0.02725903 0.04640358 0.03809072 0.03641108
  0.02669869 0.03594695 0.05570551 0.03016229 0.06854092 0.06612296
  0.05463891 0.0419244  0.06558689 0.03182324 0.03535636 0.02331986
  0.02200138 0.03257625 0.04154241 0.0509332  0.02635824 0.01544195
  0.01194358 0.01377209]
 [0.03296114 0.03365118 0.0277424  0.04529422 0.05182865 0.03272567
  0.03007849 0.02979963 0.03202122 0.04184654 0.03277646 0.03199865
  0.02862241 0.03863357 0.04301238 0.02094568 0.03720023 0.04234546
  0.03663839 0.03598224 0.04363628 0.04314517 0.04180971 0.01705845
  0.01715179 0.03723033 0.035283   0.05766941 0.03042392 0.01275374
  0.01163014 0.01186845]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.02834944 0.0405099  0.03941036 ... 0.04244306 0.02238703 0.0341207 ]
 [0.02879674 0.03378262 0.03159329 ... 0.0275021  0.02809692 0.02768078]
 [0.02948263 0.04313588 0.0428054  ... 0.03171465 0.01890442 0.02616879]
 ...
 [0.02959408 0.03734232 0.03656568 ... 0.03415747 0.01590837 0.03092649]
 [0.03019296 0.03001239 0.0280453  ... 0.02880125 0.01838866 0.02536201]
 [0.03024004 0.03071309 0.02798521 ... 0.03077601 0.01850908 0.02953609]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', "'s", ' possible', ' locations', ' and', ' Bill', "'s", ' possible', ' locations', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 44), x_tokens=44, y_tokens=46, max_supp_attn=0.0435, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 44)
DEBUG result.interpretability.attn_scores 2024 
 [[0.01999621 0.02082614 0.02253337 ... 0.0103457  0.00696212 0.03516847]
 [0.02038848 0.02283474 0.02437132 ... 0.02082388 0.01112238 0.02090882]
 [0.02089802 0.02255347 0.0257302  ... 0.01628553 0.00971002 0.0368064 ]
 ...
 [0.02135891 0.02406461 0.02244494 ... 0.00949553 0.01315129 0.03557248]
 [0.02167607 0.02770899 0.0282017  ... 0.0082598  0.012017   0.03734837]
 [0.0217337  0.02423999 0.02514031 ... 0.00908382 0.01253383 0.05205473]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', "'s", ' possible', ' locations', ' and', ' Julie', "'s", ' possible', ' locations', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.02028561 0.02350857 0.02841805 ... 0.01349037 0.03224659 0.04683847]
 [0.02058884 0.02866898 0.03094855 ... 0.01931225 0.02974196 0.0262882 ]
 [0.0211275  0.02741401 0.03293754 ... 0.01074955 0.02974196 0.03393914]
 ...
 [0.02155195 0.02385098 0.02170175 ... 0.02494947 0.0361362  0.02850153]
 [0.02172515 0.03025345 0.02869466 ... 0.01696478 0.02588853 0.02578107]
 [0.02160007 0.02586831 0.02440056 ... 0.01288074 0.02487542 0.0349787 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', ' or', ' left', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 26), x_tokens=26, y_tokens=38, max_supp_attn=0.1053, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 26)
DEBUG result.interpretability.attn_scores 988 
 [[0.02407048 0.04394586 0.05503007 0.07259744 0.08569447 0.06965838
  0.05226025 0.0583395  0.04797415 0.06144589 0.0440901  0.05138619
  0.05402077 0.09172228 0.05781221 0.02845983 0.0276716  0.02766917
  0.02526003 0.02611461 0.02294156 0.03546875 0.03666633 0.01869649
  0.01962092 0.02960365]
 [0.02628063 0.05035923 0.03207099 0.05011844 0.03982083 0.03148088
  0.02696165 0.01876525 0.01855143 0.03086055 0.02552624 0.01334249
  0.01520088 0.03182163 0.04068272 0.0209356  0.01301278 0.01152434
  0.01514434 0.01479955 0.01439633 0.03791836 0.04540835 0.00733547
  0.00706775 0.0141283 ]
 [0.02456355 0.0400406  0.04490842 0.02770059 0.02118056 0.03332997
  0.03426319 0.03237363 0.03666522 0.02877792 0.02672237 0.02866119
  0.02802542 0.01648556 0.01555345 0.03405334 0.03107824 0.03033537
  0.03002957 0.03032256 0.02816001 0.03171612 0.05493209 0.04538644
  0.05244656 0.04594117]
 [0.02501242 0.03640103 0.03981668 0.06172108 0.05732431 0.04153618
  0.02932177 0.02443188 0.02799953 0.04069255 0.03124473 0.02081864
  0.02085548 0.09918267 0.10510604 0.03234689 0.02451908 0.01811982
  0.01951804 0.01982254 0.02000814 0.03468081 0.05224311 0.0124415
  0.01054087 0.03028576]
 [0.02552348 0.02337866 0.02432253 0.04807976 0.04277087 0.03781647
  0.02168678 0.01878876 0.0235535  0.03797247 0.02774337 0.02359299
  0.02233638 0.10695862 0.13192138 0.03206573 0.02755092 0.02195874
  0.02185785 0.02122826 0.01929921 0.02989928 0.03230838 0.00888039
  0.00841997 0.01994486]
 [0.02591169 0.02599517 0.03113353 0.04992731 0.04675769 0.04774259
  0.02852836 0.02572322 0.03068108 0.04405139 0.03173613 0.03682289
  0.03354041 0.0852829  0.08250922 0.02655708 0.02468365 0.02134893
  0.02073708 0.02078586 0.0179799  0.02697207 0.03032379 0.0124843
  0.0110634  0.01918587]
 [0.025057   0.03582605 0.04326561 0.04019643 0.04132435 0.04562106
  0.03399426 0.03554036 0.03492048 0.04066823 0.03271044 0.04197001
  0.03642961 0.05223009 0.04817371 0.03468806 0.03159494 0.0271818
  0.02556827 0.02620328 0.0241056  0.03107685 0.04555257 0.02956612
  0.02853369 0.03355875]
 [0.02604946 0.03534624 0.04453664 0.04479238 0.03988536 0.0520701
  0.03839026 0.03952628 0.04196331 0.04550168 0.03353085 0.04222583
  0.0385844  0.03983141 0.02644834 0.0254837  0.02408264 0.02249336
  0.02249564 0.02373491 0.01991047 0.03106291 0.03271178 0.01671381
  0.0180965  0.02584419]
 [0.02547534 0.04477265 0.04882505 0.02793758 0.02223991 0.03481222
  0.03885022 0.03623164 0.03912737 0.02907617 0.02700256 0.03209897
  0.03199528 0.01825994 0.01566022 0.03900931 0.03147514 0.02588698
  0.02691199 0.02827479 0.02737864 0.03000675 0.06083778 0.03881023
  0.04011471 0.03537128]
 [0.0258907  0.05920471 0.05824134 0.02630791 0.02107946 0.02945127
  0.03962603 0.03359725 0.0404101  0.02530132 0.02428766 0.02534354
  0.0253289  0.01524084 0.01476607 0.04484825 0.03227534 0.0253741
  0.02780981 0.03092439 0.02743148 0.02765377 0.06273563 0.0317947
  0.03010982 0.03121299]
 [0.02597436 0.03217325 0.03583473 0.02036006 0.01695069 0.02204498
  0.0306983  0.02582761 0.03066831 0.02074693 0.01988947 0.02037987
  0.01937644 0.01290919 0.01325183 0.03696646 0.02918505 0.02240092
  0.02656435 0.02828497 0.02680538 0.02692468 0.05257545 0.04707985
  0.04781539 0.03641839]
 [0.02618943 0.01421199 0.01534752 0.01139878 0.01008588 0.01309433
  0.01503958 0.01437208 0.01741496 0.01275691 0.01312769 0.01287708
  0.01227165 0.00690256 0.00786188 0.01884455 0.01916196 0.01710266
  0.02208775 0.02441282 0.02591832 0.0210046  0.03744595 0.05975984
  0.06967434 0.0432213 ]
 [0.02617317 0.0202427  0.02140383 0.01561375 0.01404903 0.01928998
  0.0217337  0.01929006 0.02045173 0.01728314 0.01967402 0.01922892
  0.01801189 0.00984671 0.01079958 0.02979602 0.02361537 0.02087605
  0.02247988 0.022916   0.02396132 0.02511295 0.02778531 0.05152561
  0.05316223 0.03929092]
 [0.02634759 0.02324582 0.02373045 0.01989753 0.01699263 0.02344194
  0.02831891 0.02741803 0.02249714 0.0232763  0.0256069  0.02814251
  0.02824323 0.01297737 0.01133451 0.02808393 0.02569524 0.0242169
  0.02404841 0.02367144 0.02528419 0.02766539 0.02032455 0.0422541
  0.03290114 0.02394566]
 [0.02595852 0.01882705 0.01561645 0.01375346 0.01147863 0.01462047
  0.0255868  0.02508836 0.01621233 0.01512626 0.0222934  0.01767539
  0.02212788 0.00751054 0.00782384 0.02873276 0.0262195  0.0323683
  0.03371125 0.03189255 0.04028377 0.02443403 0.01542473 0.06304738
  0.04930258 0.03341577]
 [0.02643443 0.01924672 0.01703759 0.01499578 0.01345537 0.01695812
  0.02285889 0.02337568 0.01713636 0.01757627 0.02626918 0.02317131
  0.02388057 0.00869947 0.00841302 0.02477282 0.02713047 0.02596908
  0.02877994 0.02440022 0.03182522 0.02426786 0.01556216 0.05221712
  0.03479787 0.02248682]
 [0.02641727 0.01567918 0.01339129 0.01099232 0.01068062 0.01283928
  0.02168008 0.01980358 0.01448848 0.01325868 0.03390869 0.01851172
  0.02020764 0.00628668 0.00686593 0.02558925 0.0310922  0.02903814
  0.03253856 0.02616403 0.03339331 0.02153377 0.01352688 0.05530952
  0.03437901 0.02967728]
 [0.02522417 0.0287954  0.02089236 0.01772889 0.02142792 0.01918812
  0.03784065 0.03206796 0.02553854 0.02054212 0.03365397 0.02306275
  0.02695128 0.0110948  0.01332489 0.02722777 0.04726302 0.04236363
  0.04843936 0.04490503 0.04516972 0.02839835 0.02855448 0.05602386
  0.04862001 0.05436956]
 [0.02690383 0.01749203 0.01713488 0.01554749 0.01225298 0.01669893
  0.01844864 0.01942267 0.01749855 0.01665719 0.02177441 0.0198235
  0.01850986 0.00924266 0.00856561 0.01813907 0.01937276 0.02087191
  0.02241175 0.02098889 0.02330849 0.02223173 0.01428142 0.02465479
  0.02843958 0.02845656]
 [0.02700958 0.02021163 0.02359216 0.0241673  0.01818319 0.02526204
  0.02124023 0.02575049 0.02413508 0.02720603 0.02213314 0.02952968
  0.02387592 0.01554681 0.01084432 0.01616745 0.01998978 0.01872584
  0.02015213 0.01862809 0.01889872 0.02444921 0.0149696  0.01426785
  0.0193996  0.02197187]
 [0.02681598 0.02437596 0.02500356 0.01904893 0.01462441 0.02273145
  0.0263023  0.03034775 0.02869023 0.02023619 0.01945539 0.02756453
  0.02663667 0.01143852 0.00908455 0.0194607  0.02129533 0.02275756
  0.02485353 0.02537322 0.025796   0.02637353 0.01897118 0.01652496
  0.02633704 0.03060989]
 [0.02701771 0.02351084 0.02370682 0.01843095 0.01513419 0.0243669
  0.02787152 0.03268776 0.03041176 0.02168008 0.02568332 0.03859405
  0.03072753 0.01070713 0.00888138 0.02333036 0.0254853  0.02670547
  0.02724294 0.02521429 0.0254163  0.02200672 0.01678175 0.01445727
  0.01886595 0.02252122]
 [0.02723418 0.02212295 0.02251571 0.01925662 0.01494276 0.02697036
  0.02543432 0.02815446 0.03166431 0.02249675 0.02000516 0.03111639
  0.02852154 0.01170504 0.00865725 0.01705864 0.02064837 0.02003962
  0.02456708 0.02288644 0.02199661 0.02289361 0.01826367 0.01299038
  0.02024662 0.02401124]
 [0.02666337 0.03335627 0.0296311  0.02186613 0.01611933 0.02784812
  0.03449443 0.03745714 0.03761131 0.02581206 0.0251155  0.03723402
  0.03832285 0.01301681 0.00963245 0.0268058  0.02394161 0.03095001
  0.02849349 0.03115746 0.02659252 0.02535825 0.02168732 0.01602173
  0.02331924 0.02403489]
 [0.02723449 0.02642872 0.02800774 0.02267014 0.01561601 0.04036528
  0.03340025 0.0348566  0.04017561 0.02760156 0.02372621 0.05396503
  0.04253192 0.01402092 0.00945198 0.02144031 0.0212837  0.02228848
  0.02346207 0.02351104 0.02008088 0.02407692 0.01717418 0.01103623
  0.01425133 0.01636226]
 [0.02735688 0.01926588 0.01865886 0.01706631 0.01179912 0.01896206
  0.02314458 0.02594706 0.02408981 0.02063429 0.02179351 0.02855012
  0.03085784 0.01044061 0.00741102 0.02267543 0.01975745 0.02433969
  0.02322428 0.0241967  0.02328326 0.02364346 0.01116659 0.01602401
  0.01770661 0.01497168]
 [0.02734309 0.01961352 0.01823981 0.01792256 0.01283266 0.01947795
  0.02252879 0.02486264 0.02372415 0.02184009 0.02333139 0.0257999
  0.02978929 0.01105536 0.00803479 0.02110932 0.02009387 0.02460493
  0.02454251 0.02549533 0.02383366 0.02529987 0.01070832 0.01691522
  0.01644488 0.01364937]
 [0.02687176 0.01896385 0.01637254 0.0139586  0.01032033 0.01346034
  0.02097213 0.02168933 0.01927347 0.01517107 0.02185401 0.01888766
  0.02442789 0.00785483 0.00676392 0.02996881 0.02198503 0.03528975
  0.02754886 0.0340193  0.03479961 0.02265621 0.01182812 0.0245287
  0.03071276 0.02235888]
 [0.02691301 0.02017991 0.01768387 0.01462754 0.01105596 0.01514464
  0.02376372 0.02578717 0.02182152 0.01695544 0.0251813  0.0221832
  0.0284992  0.00843464 0.00660052 0.03373763 0.02504624 0.04115642
  0.03027385 0.03872635 0.03444247 0.02171449 0.0113432  0.02143344
  0.02815414 0.0206474 ]
 [0.02720408 0.01712061 0.01588887 0.01322722 0.01018805 0.01436708
  0.02025413 0.02170814 0.02065836 0.0155666  0.02391407 0.01910428
  0.02239502 0.00802781 0.00638828 0.02803363 0.02337723 0.03256456
  0.0274784  0.03023098 0.02846817 0.01946047 0.01031956 0.01839296
  0.03293423 0.02661662]
 [0.02733534 0.01793682 0.01686733 0.0143485  0.01062577 0.01562658
  0.02247517 0.02489462 0.02151506 0.01748922 0.02565148 0.02304516
  0.02768847 0.00886908 0.00631717 0.02579048 0.0254507  0.03675701
  0.03101222 0.03731094 0.03112193 0.02018647 0.00954359 0.01678998
  0.0183442  0.01578926]
 [0.027512   0.01484381 0.01407649 0.01103946 0.00853396 0.01224887
  0.01684423 0.01690302 0.01813353 0.01307692 0.0243853  0.01525186
  0.0180938  0.00736968 0.00561495 0.02170807 0.02145351 0.02299555
  0.02602714 0.02618051 0.0278477  0.02068419 0.00973275 0.02423486
  0.0169232  0.01836024]
 [0.02691061 0.01806437 0.01598616 0.01067505 0.00846728 0.01237473
  0.02187613 0.01913581 0.01944992 0.01271082 0.03421435 0.0146593
  0.02139627 0.00705807 0.00578872 0.02539813 0.02645211 0.02707074
  0.0295795  0.02771997 0.03019093 0.02220634 0.0120643  0.04219191
  0.02332337 0.02628873]
 [0.02743594 0.0182025  0.01847609 0.01432301 0.01037948 0.01511069
  0.01864888 0.02043561 0.02291968 0.01572532 0.0189884  0.01654404
  0.01980833 0.00956272 0.00699259 0.01844538 0.01831582 0.02030797
  0.02297306 0.02402032 0.02344773 0.02254177 0.01403217 0.01690324
  0.02159522 0.02546793]
 [0.02614926 0.02432177 0.02351085 0.0393937  0.03966381 0.03262279
  0.0205926  0.02100087 0.02515431 0.03996549 0.02741118 0.02397697
  0.02583897 0.06790987 0.08583293 0.02207197 0.0236427  0.02105195
  0.02190976 0.02108047 0.01968574 0.0284541  0.0275972  0.00917708
  0.01037565 0.02051464]
 [0.02591867 0.02536929 0.02385762 0.04436298 0.08478891 0.03243813
  0.01825175 0.01927407 0.02342813 0.04566424 0.03267223 0.02511787
  0.02151914 0.0697406  0.09080748 0.02668285 0.03422785 0.02971176
  0.02593722 0.02299402 0.02332007 0.02586759 0.02791438 0.00815864
  0.00827803 0.01856235]
 [0.02563903 0.02350423 0.02156158 0.03804562 0.08865635 0.02346512
  0.01574334 0.01877278 0.02026135 0.04258446 0.03253001 0.0268247
  0.02131622 0.03402932 0.04496909 0.02315852 0.05410451 0.04558514
  0.03556298 0.02643781 0.03593099 0.02347342 0.02419967 0.01408869
  0.01476999 0.02126018]
 [0.02597757 0.02742271 0.02382288 0.03590246 0.05261692 0.02546161
  0.02007316 0.02035096 0.02312979 0.03601144 0.03116195 0.02291549
  0.02185516 0.03072623 0.03505221 0.02035612 0.03676917 0.02999735
  0.02876511 0.02497007 0.02728572 0.04062443 0.03250172 0.01188122
  0.01291152 0.01964223]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' is', ' in', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.1471, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02746751 0.04706796 0.0467159  ... 0.03611412 0.01358336 0.00849566]
 [0.02825453 0.04628997 0.04449687 ... 0.04487119 0.01528638 0.01071511]
 [0.02874436 0.04300892 0.04690211 ... 0.06174678 0.02601065 0.01830236]
 ...
 [0.02881877 0.04248616 0.03819677 ... 0.01491519 0.00843659 0.00502731]
 [0.02920325 0.02989084 0.02558959 ... 0.01159441 0.01276473 0.00700785]
 [0.02921067 0.03124231 0.02753141 ... 0.00984623 0.01121106 0.00684226]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Bill', ' was', ' in', ' context', ' sentence', ' ', '5', ',', ' where', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' update', ' about', ' his', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0638, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01960845 0.02593393 0.02503433 ... 0.02084785 0.01228993 0.00726052]
 [0.01999803 0.02035922 0.02042134 ... 0.01437488 0.01233121 0.00889917]
 [0.02054685 0.02559299 0.02656022 ... 0.01432985 0.00924341 0.00540638]
 ...
 [0.02069454 0.02310418 0.01960665 ... 0.01705338 0.01002435 0.00449935]
 [0.02123912 0.01694804 0.0144812  ... 0.01269824 0.01223201 0.0071804 ]
 [0.02112039 0.01883423 0.0161738  ... 0.01697056 0.01209952 0.00675197]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' has', ' left', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02751448 0.03616585 0.04045787 ... 0.08074544 0.01039641 0.01165734]
 [0.02773779 0.03249635 0.03782983 ... 0.05739862 0.02298822 0.01656679]
 [0.0287692  0.03930616 0.04916397 ... 0.06696612 0.01473959 0.01796043]
 ...
 [0.02881873 0.04563454 0.04348505 ... 0.02439452 0.00832047 0.00721521]
 [0.02928135 0.03298512 0.02933517 ... 0.01275052 0.01016083 0.00819494]
 [0.02915965 0.03788209 0.03465051 ... 0.01278886 0.00781088 0.00720186]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '14', ',', ' Fred', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' he', ' is', ' no', ' longer', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 50), x_tokens=50, y_tokens=45, max_supp_attn=0.0, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 50)
DEBUG result.interpretability.attn_scores 2250 
 [[0.02059584 0.02980495 0.03152261 ... 0.03243875 0.02089941 0.01746756]
 [0.02089598 0.02291635 0.02564652 ... 0.02051645 0.02591823 0.02640015]
 [0.02146551 0.03101761 0.03845    ... 0.03077829 0.01922483 0.01397334]
 ...
 [0.0216849  0.03408442 0.03274858 ... 0.03025253 0.01801487 0.01446598]
 [0.02224008 0.02557773 0.02346811 ... 0.02205994 0.01761428 0.01865869]
 [0.02191325 0.02798685 0.02557896 ... 0.02902015 0.01731384 0.01784055]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' going', ' to', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' In', ' fact', ',', ' sentence', ' ', '1', ' states', ' that', ' Mary', ' went', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' she', ' is', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 26), x_tokens=26, y_tokens=46, max_supp_attn=0.1087, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 26)
DEBUG result.interpretability.attn_scores 1196 
 [[0.02016181 0.03646023 0.03874355 ... 0.0092292  0.00885297 0.02779652]
 [0.02081037 0.02287365 0.02285282 ... 0.00634305 0.00709021 0.01815523]
 [0.02116581 0.02580069 0.02933067 ... 0.00845238 0.00862231 0.01708017]
 ...
 [0.02122429 0.02379235 0.02280805 ... 0.00602086 0.00634698 0.01760081]
 [0.02123144 0.01881347 0.01825073 ... 0.00816763 0.00915859 0.01779148]
 [0.02128124 0.02472038 0.02202559 ... 0.00692049 0.00877265 0.01702417]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 32), x_tokens=32, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 32)
DEBUG result.interpretability.attn_scores 608 
 [[0.04963483 0.07677312 0.0767559  0.09576838 0.08084435 0.08079841
  0.06558693 0.06637745 0.08032308 0.0804002  0.05657119 0.0605229
  0.06418431 0.13222569 0.1253006  0.0571492  0.04268651 0.0421971
  0.03883888 0.04660799 0.0387887  0.05611531 0.09802746 0.03607552
  0.03336628 0.07209169 0.08045719 0.06185223 0.15435344 0.02709672
  0.03736909 0.02156211]
 [0.05121981 0.07117868 0.07039605 0.10939647 0.10400743 0.114306
  0.07093188 0.06914814 0.08454106 0.10431904 0.07284572 0.08516845
  0.08729254 0.20048267 0.16064708 0.06133316 0.04202465 0.04707511
  0.0411064  0.0476584  0.03939466 0.05842764 0.06854028 0.02997487
  0.02883879 0.06076195 0.09093858 0.0498173  0.13932723 0.0336117
  0.04164734 0.02659898]
 [0.05210969 0.06773997 0.07411152 0.09061582 0.07864523 0.0884899
  0.06882613 0.06964859 0.07489373 0.08184291 0.05775775 0.07764477
  0.0766903  0.12717535 0.09313859 0.05118757 0.03847495 0.0392652
  0.0368796  0.04194005 0.0346334  0.05514007 0.06596565 0.03615936
  0.03238058 0.0540424  0.07611489 0.04399957 0.1136757  0.04873481
  0.0651119  0.0437769 ]
 [0.05031291 0.07350598 0.07458484 0.05163223 0.04647091 0.05862191
  0.06263451 0.06960551 0.06441586 0.05230974 0.04888178 0.06201944
  0.06170417 0.03735009 0.03539708 0.05896824 0.04698002 0.04350159
  0.04404597 0.04870217 0.04205797 0.06036495 0.08079147 0.05969422
  0.054899   0.06510025 0.07252128 0.0534215  0.07473668 0.08680537
  0.13093059 0.11602074]
 [0.05189777 0.06532069 0.06976274 0.03827244 0.03195954 0.04490607
  0.06042497 0.05621932 0.06115898 0.03890292 0.04092192 0.04443688
  0.04559297 0.02514784 0.0260008  0.05997725 0.04622347 0.03994931
  0.04701994 0.0515713  0.04381233 0.0506015  0.0754598  0.06499769
  0.06194118 0.05428615 0.0638866  0.03879648 0.03708382 0.05934453
  0.0847851  0.15319699]
 [0.05295038 0.02802442 0.02960594 0.01855114 0.0164887  0.02292582
  0.02804665 0.02615923 0.02999013 0.02131821 0.02651156 0.02366481
  0.02556898 0.0114185  0.01317556 0.03229896 0.02807348 0.02658365
  0.0353516  0.03873572 0.0349572  0.0342968  0.03530029 0.05171973
  0.05958947 0.04157594 0.0317187  0.02916536 0.01985302 0.03418359
  0.0375794  0.07351672]
 [0.05213735 0.05575544 0.05589863 0.03155213 0.02578241 0.04291182
  0.04964767 0.04891475 0.04697451 0.03390197 0.03967428 0.04534554
  0.04220114 0.01911455 0.02039629 0.05392846 0.04853501 0.03894333
  0.04838521 0.051105   0.04715136 0.05677967 0.06412065 0.07368419
  0.06951114 0.0544924  0.06044272 0.04087154 0.03688666 0.08053313
  0.07744054 0.1101407 ]
 [0.05344342 0.06993797 0.07353598 0.05419235 0.0387063  0.06203154
  0.06938329 0.07552473 0.06292524 0.06065613 0.06312346 0.08443642
  0.07293269 0.03294925 0.02826771 0.0608991  0.05423055 0.05164612
  0.05517719 0.05599364 0.05010619 0.05927813 0.05567908 0.06261678
  0.05664273 0.05241114 0.06832872 0.04927537 0.04120018 0.09787486
  0.07783619 0.08757889]
 [0.05420797 0.05025797 0.05578752 0.03779403 0.0302857  0.04439264
  0.05674605 0.0529548  0.04654292 0.04027364 0.04948961 0.05132039
  0.05200254 0.0224776  0.02185674 0.0545844  0.04812805 0.04141101
  0.04893688 0.04925807 0.04517835 0.05400424 0.04301074 0.06261412
  0.05705408 0.0418947  0.05415388 0.0426348  0.03394414 0.07588809
  0.06564391 0.09086741]
 [0.05352955 0.03882542 0.03726353 0.02562379 0.01923409 0.03042107
  0.04109084 0.03854121 0.03482468 0.02722985 0.0422219  0.03429179
  0.03992052 0.01408585 0.01585327 0.05251091 0.05490153 0.04124211
  0.05316632 0.0495103  0.05044457 0.05036078 0.03055771 0.07133655
  0.06592019 0.0376853  0.03661002 0.04526971 0.02440198 0.06363985
  0.04535803 0.04921985]
 [0.05323542 0.03954648 0.03542358 0.02606017 0.01703731 0.02959047
  0.04435188 0.0407982  0.03575315 0.02622841 0.04237022 0.03148808
  0.04291055 0.01337138 0.01406221 0.0581406  0.06325183 0.0506582
  0.06447349 0.05963439 0.06691585 0.04683489 0.0276048  0.09300688
  0.08648015 0.04730878 0.02879888 0.05943448 0.01940129 0.07628924
  0.03948085 0.03234316]
 [0.05413409 0.03645586 0.03506359 0.02592764 0.01882555 0.0311367
  0.04180914 0.04143122 0.03524539 0.02799032 0.04704959 0.03742618
  0.04150837 0.01412915 0.01454991 0.05148781 0.06994063 0.04699969
  0.06955358 0.05483537 0.05844907 0.04662207 0.02448145 0.05370937
  0.05566221 0.03525248 0.02894862 0.05001853 0.01873409 0.05844762
  0.03761206 0.0298993 ]
 [0.05389057 0.032311   0.03210366 0.02247536 0.01555956 0.0273187
  0.04238269 0.03878977 0.03399414 0.0238406  0.05149048 0.03229499
  0.04066872 0.01234948 0.0131473  0.06011108 0.07500161 0.05191169
  0.07361501 0.06095197 0.06765196 0.04668743 0.02405384 0.07461179
  0.06842195 0.050358   0.02475606 0.06282052 0.01755483 0.05926019
  0.04020685 0.02604523]
 [0.05318492 0.03485212 0.03509914 0.02573692 0.01752055 0.03324591
  0.04499645 0.04322753 0.03955404 0.02538657 0.03744366 0.03218194
  0.0401727  0.01474547 0.01396362 0.0394862  0.03785405 0.03926945
  0.04930466 0.05248398 0.04822585 0.04564525 0.03443162 0.05587333
  0.06841678 0.06288072 0.03012154 0.04536833 0.0273603  0.05349813
  0.05242217 0.0350794 ]
 [0.05453281 0.03300968 0.0344236  0.02972256 0.01798979 0.03335494
  0.04047905 0.04230617 0.03623551 0.02976475 0.04020649 0.03532057
  0.04051354 0.01778376 0.0159834  0.03758351 0.03282857 0.03537299
  0.0439957  0.04183385 0.04468275 0.04783642 0.02553552 0.03938403
  0.04463066 0.04078141 0.02854932 0.04075997 0.02951914 0.04732874
  0.05547984 0.03231658]
 [0.05272834 0.05031018 0.05294537 0.07199679 0.05878782 0.06759004
  0.05298247 0.05519191 0.06332056 0.07837854 0.06033736 0.06595227
  0.0661518  0.0918171  0.10124466 0.04540908 0.04059803 0.05394065
  0.04463997 0.04859597 0.04497532 0.055105   0.05351561 0.02963683
  0.03554982 0.05418302 0.04986149 0.06111206 0.06731676 0.02814998
  0.04498542 0.02302326]
 [0.05211354 0.06679264 0.06168738 0.10710142 0.21312279 0.08548071
  0.05821544 0.06057753 0.0638537  0.10757686 0.08979788 0.0827053
  0.05983922 0.12116515 0.167459   0.06578127 0.07584193 0.09962204
  0.06197578 0.06169871 0.06960935 0.05514247 0.06980068 0.03001347
  0.03358877 0.05907914 0.07197225 0.06129536 0.06554393 0.01820677
  0.0191527  0.01591612]
 [0.05223773 0.0521551  0.0457411  0.06452656 0.09532303 0.04555231
  0.04448025 0.04899098 0.04620925 0.06865828 0.06858224 0.05704369
  0.0468178  0.04100037 0.06366939 0.05365023 0.09059881 0.12863302
  0.08068744 0.07188088 0.09810611 0.05017347 0.05310743 0.04082401
  0.04441334 0.05495177 0.05395423 0.07340501 0.03426526 0.02726746
  0.02295559 0.01781584]
 [0.05249894 0.05724728 0.04980989 0.07305381 0.07340891 0.05692503
  0.05698367 0.05559293 0.05924403 0.07102107 0.064723   0.05673563
  0.05332712 0.05121077 0.0558867  0.04551297 0.0638263  0.0817778
  0.06284627 0.06700219 0.07485891 0.07058392 0.07001599 0.03406725
  0.0426929  0.06086274 0.04786504 0.09068187 0.04484151 0.02383923
  0.02400234 0.01508181]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Mary', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Mary', "'s", ' location', ' is', ' not', ' provided', ' in', ' this', ' task', ',', ' so', ' we', ' cannot', ' determine', ' Mary', "'s", ' current', ' location', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.1333, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02040026 0.02394142 0.02098856 ... 0.04017443 0.02505071 0.0154048 ]
 [0.020867   0.01834089 0.01679495 ... 0.02784622 0.02792828 0.04779586]
 [0.02131601 0.02386343 0.02260448 ... 0.03001042 0.01746346 0.01086682]
 ...
 [0.02146494 0.02589529 0.02194326 ... 0.06103708 0.01785862 0.0103427 ]
 [0.02204451 0.02418278 0.01917605 ... 0.04303301 0.01807094 0.01429966]
 [0.02220088 0.02479439 0.02126931 ... 0.06267367 0.0185992  0.01111133]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '11', ' only', ' provides', ' information', ' about', ' Mary', "'s", ' possible', ' locations', ',', ' which', ' does', ' not', ' imply', ' anything', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 44), x_tokens=44, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 44)
DEBUG result.interpretability.attn_scores 1848 
 [[0.02195089 0.02558047 0.0300696  ... 0.0493775  0.03654079 0.02836886]
 [0.02234517 0.02208443 0.02319293 ... 0.02171054 0.05586008 0.02526764]
 [0.02291635 0.02789895 0.03247142 ... 0.03235625 0.05794552 0.03964578]
 ...
 [0.02303874 0.0325961  0.02997717 ... 0.03845998 0.01293895 0.0149387 ]
 [0.02352656 0.02669392 0.02404327 ... 0.02901629 0.01044115 0.01408465]
 [0.02362975 0.02936043 0.02818538 ... 0.03067651 0.00865908 0.01314352]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Mary', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '14', ' only', ' provides', ' information', ' about', ' Bill', "'s", ' location', ',', ' which', ' does', ' not', ' imply', ' anything', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02261987 0.02690669 0.03301097 ... 0.02094042 0.0341834  0.03257465]
 [0.02327996 0.02211531 0.0262448  ... 0.02431297 0.02424034 0.01996866]
 [0.02364058 0.03173772 0.03981822 ... 0.01974411 0.02773638 0.02628999]
 ...
 [0.0239511  0.03547052 0.03240333 ... 0.01589741 0.03259348 0.03189605]
 [0.02411857 0.02801483 0.02560806 ... 0.0239069  0.03290664 0.04929909]
 [0.0241776  0.03274279 0.03388049 ... 0.01779401 0.03208157 0.02954848]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' being', ' in', ' the', ' school', ' or', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' cinema', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0714, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02219089 0.04275034 0.04352462 ... 0.00472668 0.00637587 0.03375433]
 [0.02292521 0.02687658 0.02508168 ... 0.00407821 0.00584859 0.02196139]
 [0.02330208 0.03002599 0.03155075 ... 0.00583284 0.00723565 0.02065852]
 ...
 [0.02338127 0.02682345 0.0253631  ... 0.0040646  0.00525345 0.02071363]
 [0.02318836 0.02241509 0.02213098 ... 0.00939104 0.00962263 0.02216083]
 [0.02337914 0.02595213 0.02403052 ... 0.00737569 0.00824642 0.02103125]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', "'s", ' movements', ',', ' but', ' there', ' is', ' no', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' From', ' the', ' previous', ' context', ' (', 'sentence', ' ', '1', '),', ' we', ' know', ' that', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 32), x_tokens=32, y_tokens=49, max_supp_attn=0.102, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 32)
DEBUG result.interpretability.attn_scores 1568 
 [[0.01891534 0.02561055 0.0281285  ... 0.00570643 0.00649096 0.01349833]
 [0.01955811 0.0251076  0.02622401 ... 0.00645737 0.00724878 0.01791641]
 [0.01995573 0.0237236  0.02799104 ... 0.00899853 0.00889603 0.02170175]
 ...
 [0.02003573 0.02517658 0.02257815 ... 0.0036872  0.00388414 0.00730757]
 [0.02044732 0.02098791 0.01740953 ... 0.00721834 0.0078774  0.00880456]
 [0.0205712  0.02004836 0.01759087 ... 0.0052168  0.00652543 0.00980489]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' journey', 'ing', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' park', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Julie', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 38), x_tokens=38, y_tokens=40, max_supp_attn=0.075, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 38)
DEBUG result.interpretability.attn_scores 1520 
 [[0.02336485 0.02983771 0.03609838 ... 0.04495813 0.02848381 0.01971195]
 [0.02350582 0.03197874 0.0342425  ... 0.0371284  0.0375051  0.03275478]
 [0.02435539 0.03293126 0.03966581 ... 0.03336463 0.02339778 0.01512868]
 ...
 [0.0244912  0.03217155 0.03023952 ... 0.03847721 0.01900577 0.01457292]
 [0.02482788 0.02385492 0.02235106 ... 0.02555018 0.01712724 0.0177723 ]
 [0.02480971 0.0255758  0.0231634  ... 0.03816823 0.01800132 0.01851431]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' mentions', ' Julie', ' going', ' back', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' office', ' (', 'sentence', ' ', '7', ').', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02583883 0.03632206 0.03361178 ... 0.09869548 0.0116286  0.01537498]
 [0.02613902 0.02849485 0.02721    ... 0.06745684 0.02640119 0.03066314]
 [0.02700703 0.03897574 0.03950233 ... 0.07881459 0.0176999  0.02252379]
 ...
 [0.02737087 0.03720606 0.0368175  ... 0.02481754 0.00824826 0.01056043]
 [0.02784002 0.02894595 0.02579524 ... 0.01196773 0.00888794 0.01210937]
 [0.0276898  0.02994066 0.0272309  ... 0.01238315 0.00788997 0.01112673]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' moving', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' park', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Mary', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02390118 0.03460986 0.03110823 ... 0.02470794 0.03243056 0.03911088]
 [0.02436498 0.02914045 0.02402402 ... 0.01905028 0.01756479 0.03231109]
 [0.02504623 0.03602125 0.03577598 ... 0.02926183 0.02974778 0.0300043 ]
 ...
 [0.02524712 0.03319648 0.03240662 ... 0.05027437 0.06417452 0.03039011]
 [0.02568338 0.02405112 0.02213149 ... 0.03343163 0.05918097 0.02339942]
 [0.02555688 0.02523685 0.02281105 ... 0.02009891 0.064574   0.02973303]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' the', ' bedroom', ' and', ' the', ' office', ' as', ' possible', ' locations', ' for', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02683533 0.04616231 0.04998027 0.08285873 0.07808547 0.04915122
  0.03438164 0.02981797 0.03280873 0.05084255 0.03540346 0.02386264
  0.02377084 0.12638985 0.13379015 0.04225614 0.02753909 0.0206562
  0.01671877 0.01963329 0.02048654 0.04015179 0.06549647 0.01942581
  0.00440804 0.02483806]
 [0.0276932  0.02827091 0.02946858 0.06002355 0.0555901  0.0417776
  0.02428311 0.02160216 0.02618859 0.04409618 0.03004126 0.02570609
  0.0238021  0.13222593 0.15906657 0.03977982 0.02967769 0.02422611
  0.01856823 0.02059884 0.01946408 0.03324955 0.03888266 0.01413358
  0.00389307 0.01654279]
 [0.02815191 0.0318622  0.03704412 0.06365313 0.0619219  0.05292498
  0.0321113  0.02984772 0.03462284 0.05234824 0.03525233 0.04116388
  0.03683864 0.10410447 0.09758639 0.03308031 0.02703594 0.02437546
  0.01821793 0.02065208 0.01830886 0.03026126 0.03497464 0.01728842
  0.00520004 0.01653947]
 [0.02716429 0.03752692 0.043123   0.04723435 0.05212833 0.04817864
  0.03642238 0.03915384 0.03958607 0.04672508 0.03593068 0.04865674
  0.04029579 0.06224503 0.05581023 0.03942398 0.03307248 0.03129642
  0.0242226  0.0275531  0.02573813 0.03450294 0.04848891 0.03307042
  0.01391648 0.03227179]
 [0.02815763 0.03187228 0.03702682 0.03495766 0.03295021 0.04258882
  0.0348765  0.03816097 0.03675137 0.03659767 0.03004587 0.0449867
  0.03564584 0.02266147 0.01732718 0.02733533 0.02504813 0.02666638
  0.02314997 0.02610206 0.02348197 0.02748594 0.03589735 0.02858242
  0.01999201 0.03180428]
 [0.02854794 0.03090298 0.03259615 0.02948214 0.02584261 0.0410094
  0.03388677 0.03592085 0.03527537 0.03339646 0.02912756 0.04882902
  0.03596606 0.01924998 0.01446789 0.02523668 0.02426696 0.02442144
  0.02174458 0.02354334 0.02239903 0.02761062 0.03207767 0.02857323
  0.02152757 0.03037599]
 [0.02794388 0.04638701 0.04015027 0.0323562  0.02822453 0.04672292
  0.04327181 0.0476148  0.0451931  0.0404611  0.0366944  0.0625793
  0.04967527 0.02164723 0.01618425 0.03296761 0.02941557 0.03211303
  0.02866483 0.02996113 0.02641987 0.02979793 0.03740903 0.02723317
  0.02399449 0.02691323]
 [0.02866711 0.03707598 0.03984716 0.03226429 0.02458143 0.05487371
  0.04315016 0.04396332 0.0437483  0.03735409 0.03102417 0.06865441
  0.05043795 0.02062698 0.01493326 0.03142836 0.0281392  0.0286748
  0.02434725 0.02695843 0.02498588 0.02840697 0.03092674 0.02418081
  0.01621982 0.02080316]
 [0.0288189  0.04528211 0.05363337 0.03740646 0.02753327 0.07712097
  0.06615815 0.04736042 0.0607765  0.03964902 0.0305131  0.05813426
  0.04301489 0.02094772 0.0157662  0.02953617 0.02352156 0.02274481
  0.02032164 0.02403559 0.02207777 0.0291924  0.03733663 0.02353468
  0.01151754 0.01968959]
 [0.02818178 0.0227782  0.02311046 0.0187928  0.01672529 0.02158215
  0.03150027 0.03036569 0.02567206 0.02225146 0.02889567 0.02788988
  0.03718919 0.0109093  0.01045804 0.03103379 0.03322052 0.03614164
  0.03900156 0.03864347 0.04005918 0.02917603 0.01980637 0.03061273
  0.03126014 0.02457151]
 [0.02828871 0.02006555 0.01783221 0.01641878 0.01425066 0.01530211
  0.02484109 0.0248095  0.01939503 0.01690089 0.02231521 0.01885176
  0.02297121 0.00862408 0.0090422  0.03096449 0.0276908  0.03844838
  0.04044775 0.04468    0.04335374 0.02630382 0.01704192 0.03475699
  0.04291407 0.03103367]
 [0.02870295 0.02063427 0.0181238  0.01809337 0.01632581 0.01791057
  0.02457125 0.02654498 0.02047551 0.02077146 0.02707982 0.02574876
  0.02638572 0.00975969 0.00946288 0.03120996 0.03122995 0.03530553
  0.03780505 0.03790306 0.03699414 0.0241843  0.01489404 0.02632325
  0.03837708 0.01969706]
 [0.02866019 0.01692132 0.01513296 0.01348552 0.0132458  0.01360526
  0.02125538 0.02043594 0.01768572 0.01558359 0.02706943 0.01838866
  0.01985798 0.00747047 0.00804993 0.02842265 0.034529   0.03258754
  0.0453348  0.04300698 0.04116808 0.02378795 0.01492594 0.02826257
  0.04031543 0.02246727]
 [0.02800579 0.0195193  0.01708265 0.01402917 0.01304674 0.01501168
  0.02144839 0.0194964  0.02011119 0.01513687 0.02520858 0.01639664
  0.01912373 0.00772853 0.00855632 0.03108242 0.03479113 0.0309672
  0.04144071 0.03784666 0.03675931 0.02582512 0.0222567  0.05109873
  0.0526135  0.04328372]
 [0.02885578 0.02445104 0.02188645 0.01835351 0.01575044 0.01959487
  0.02457491 0.02438179 0.02474878 0.02097983 0.02566428 0.02411869
  0.02341082 0.0107766  0.01017619 0.02367792 0.02497534 0.02784238
  0.04043669 0.04599794 0.03756997 0.02582793 0.02185424 0.02149885
  0.02195756 0.02140602]
 [0.02836798 0.02843052 0.02808394 0.03070965 0.02665658 0.03368597
  0.02833075 0.03102316 0.03281746 0.03791212 0.02752397 0.04411371
  0.03782964 0.02282818 0.01565131 0.02404919 0.02640587 0.02920045
  0.02539929 0.02516177 0.0237752  0.0317177  0.03508016 0.02433522
  0.02051717 0.03291287]
 [0.02831235 0.04495668 0.04183638 0.0244942  0.0207229  0.02870568
  0.03454629 0.0361065  0.03595909 0.02409826 0.02430065 0.02870545
  0.03141464 0.01552108 0.01347509 0.03068173 0.02670439 0.02443873
  0.02462398 0.02664214 0.02500505 0.02993319 0.0522227  0.03295002
  0.03607501 0.04035241]
 [0.02874867 0.06917373 0.07042114 0.02934505 0.02299166 0.03296797
  0.0446942  0.04012107 0.04519435 0.02606209 0.02428912 0.02784562
  0.02919578 0.01571846 0.01416237 0.04079202 0.02804927 0.02283641
  0.01974378 0.02425623 0.02204621 0.03028209 0.06817503 0.03024141
  0.0136471  0.02557629]
 [0.02879932 0.03755249 0.0400539  0.0246157  0.01953262 0.02712716
  0.03533386 0.03471259 0.03436832 0.02276097 0.02203487 0.02517028
  0.02451835 0.0136713  0.01250569 0.03142224 0.02531821 0.02237881
  0.020359   0.02385241 0.02406931 0.03110391 0.04740668 0.04014388
  0.02099985 0.03594797]
 [0.02946172 0.02807952 0.02837224 0.02171048 0.01679347 0.02535949
  0.02890977 0.03509106 0.02778935 0.02157783 0.02249287 0.02573612
  0.0265951  0.01207558 0.01032605 0.02213546 0.02075044 0.02007244
  0.01885221 0.02047476 0.02062402 0.02893147 0.02269106 0.02352181
  0.02771824 0.02772453]
 [0.02893184 0.01962777 0.01872345 0.01526136 0.01263225 0.01633294
  0.02160847 0.02197653 0.02023222 0.01561213 0.02244326 0.01611846
  0.02070403 0.00894283 0.00827289 0.02501363 0.02421771 0.0219591
  0.02260794 0.02488835 0.0295153  0.02536312 0.01828242 0.05019616
  0.05708336 0.03298096]
 [0.0287189  0.02051882 0.01904058 0.01325808 0.01123746 0.01412695
  0.02322844 0.0226576  0.02008125 0.0145032  0.0277997  0.01478658
  0.02449467 0.00833268 0.00730664 0.02741453 0.03015025 0.0245969
  0.02686987 0.02780307 0.03582977 0.02426963 0.0167094  0.06122913
  0.06394961 0.03605302]
 [0.02911968 0.01457671 0.0134971  0.01159751 0.00970359 0.01164846
  0.01424862 0.0129135  0.01538876 0.01208552 0.01849314 0.01146269
  0.01351972 0.00697835 0.00602226 0.01759544 0.02483403 0.01711608
  0.02314692 0.02526871 0.03200097 0.02029119 0.01224984 0.0474949
  0.07053203 0.0514374 ]
 [0.02926327 0.01549023 0.0145819  0.01146199 0.00994628 0.01202853
  0.01552191 0.0147618  0.01676245 0.01244232 0.01858659 0.01309487
  0.01537099 0.00735911 0.00623497 0.02204723 0.02688546 0.01805151
  0.02860117 0.02472276 0.02664584 0.02432882 0.01325721 0.02952542
  0.05667207 0.05478433]
 [0.02848709 0.01796346 0.01694839 0.01287799 0.01120201 0.01313376
  0.0181124  0.01735065 0.02016484 0.01449178 0.02075431 0.01451157
  0.01851075 0.00822065 0.00702058 0.02561203 0.03484068 0.02847764
  0.04284192 0.03859609 0.04106513 0.02538891 0.01811125 0.03996465
  0.05291943 0.05775591]
 [0.02953625 0.01863213 0.01750603 0.01418183 0.01136426 0.01422824
  0.02038    0.02220937 0.01948361 0.01500985 0.02101734 0.01576547
  0.01996599 0.00871144 0.00693645 0.01995121 0.02695489 0.01932057
  0.02894042 0.02293964 0.02467259 0.02556187 0.01397256 0.01877646
  0.04138531 0.03620124]
 [0.02943865 0.02346314 0.02250916 0.01624275 0.0130372  0.01778149
  0.03031844 0.03332892 0.02342376 0.0185436  0.04069875 0.02107718
  0.03162118 0.01120204 0.00809778 0.02641864 0.0295841  0.02583211
  0.02669339 0.0252854  0.02614906 0.02832578 0.01633884 0.02365049
  0.03698428 0.02102155]
 [0.02931598 0.02784321 0.02436248 0.01853577 0.01408704 0.0181777
  0.03281197 0.03509209 0.02486482 0.02088135 0.04055454 0.02117675
  0.032075   0.01262905 0.00908506 0.02830675 0.03260481 0.02689518
  0.02834578 0.0254379  0.02591041 0.02768172 0.01717075 0.0263591
  0.04147284 0.02141599]
 [0.02961264 0.02396522 0.02456346 0.01861366 0.01448926 0.01853266
  0.03487376 0.03376177 0.02627593 0.02046461 0.04475501 0.02236744
  0.03197931 0.01109335 0.0084898  0.02871442 0.03072436 0.0274944
  0.02596915 0.02606732 0.02783558 0.02589143 0.01587871 0.02347494
  0.02150887 0.01566382]
 [0.02923123 0.01907533 0.01760405 0.0139653  0.01050665 0.01351741
  0.01969121 0.01923793 0.01950233 0.01456029 0.01774903 0.01228246
  0.02026821 0.00844204 0.00667826 0.02439746 0.02581279 0.02297435
  0.02561008 0.02623832 0.03170715 0.02726999 0.01668731 0.03702351
  0.03527452 0.02980883]
 [0.0295472  0.01970913 0.01904222 0.01763538 0.01284222 0.0153783
  0.01943692 0.0188615  0.02054663 0.01778718 0.01868349 0.01489617
  0.02018769 0.01065191 0.00872327 0.02126741 0.02076359 0.02142647
  0.02389365 0.02367283 0.02654348 0.02532757 0.01638363 0.02427272
  0.02721517 0.02857943]
 [0.02822384 0.03032263 0.02985818 0.0534171  0.05936273 0.04047336
  0.02485298 0.02571724 0.03154484 0.05297621 0.03389448 0.02936401
  0.03291063 0.08997172 0.10466219 0.02905861 0.02643186 0.02735314
  0.02001137 0.02054876 0.0204122  0.03298134 0.03448936 0.01419516
  0.00415714 0.01905309]
 [0.02812582 0.03020409 0.02892658 0.05619147 0.11286677 0.03657052
  0.02037451 0.02216219 0.02731898 0.05483871 0.03683861 0.02788514
  0.02396411 0.08459842 0.10778151 0.03385168 0.03711478 0.04170269
  0.02747518 0.0244173  0.02536053 0.02927012 0.03354824 0.01279444
  0.00428079 0.01626876]
 [0.02792149 0.02392416 0.02314176 0.03844237 0.06168057 0.02531826
  0.01652627 0.02075801 0.02532271 0.04665942 0.03436978 0.03074647
  0.02760316 0.02900767 0.03033216 0.02338119 0.03715332 0.0697746
  0.05341497 0.04071175 0.03809212 0.0265507  0.02666534 0.01664688
  0.01066139 0.01828123]
 [0.02816065 0.0267786  0.02488882 0.03803267 0.05214196 0.02755025
  0.01946619 0.02268016 0.02991913 0.04363804 0.03245471 0.0289262
  0.02888503 0.02867692 0.02755805 0.02045352 0.03054574 0.05163113
  0.04617758 0.0358984  0.03347361 0.0437648  0.03241019 0.01462806
  0.00883902 0.01594283]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' the', ' kitchen', ' and', ' the', ' cinema', ' as', ' possible', ' locations', ' for', ' Bill', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 32), x_tokens=32, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 32)
DEBUG result.interpretability.attn_scores 1120 
 [[0.02683649 0.04591701 0.04719443 ... 0.01153875 0.00638906 0.00399518]
 [0.02776318 0.04399743 0.0440296  ... 0.01163536 0.00778646 0.00508075]
 [0.02812605 0.04185349 0.04602027 ... 0.01931838 0.01227818 0.00688225]
 ...
 [0.02815904 0.03756414 0.03398582 ... 0.00646642 0.00397141 0.0032006 ]
 [0.02851276 0.02628287 0.02277058 ... 0.00950538 0.00535532 0.00542808]
 [0.02837577 0.03129429 0.02663991 ... 0.00836597 0.00452696 0.00446291]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Fred', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03083207 0.04717249 0.04583554 ... 0.02945617 0.02195834 0.02149416]
 [0.03135547 0.03777835 0.0354948  ... 0.03013457 0.0313428  0.04754145]
 [0.032251   0.05132159 0.05215488 ... 0.02216855 0.01557299 0.01409611]
 ...
 [0.03265644 0.04406681 0.03881001 ... 0.02137603 0.01263912 0.01262438]
 [0.03276181 0.03487939 0.0287551  ... 0.02920386 0.02141136 0.02055531]
 [0.0328116  0.04191105 0.03308617 ... 0.0239724  0.01771413 0.01755904]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' provided', ' about', ' Fred', "'s", ' location', '.', ' The', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ' only', ' mention', ' Mary', "'s", ' movements', ' and', ' do', ' not', ' update', ' our', ' knowledge', ' about', ' Fred', "'s", ' location', '.', ' Previously', ',', ' we', ' knew', ' that', ' Fred', ' went', ' back', ' to', ' the', ' cinema', ' (', 'sentence', ' ', '8', ').\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 44), x_tokens=44, y_tokens=58, max_supp_attn=0.0345, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 44)
DEBUG result.interpretability.attn_scores 2552 
 [[0.01584502 0.01785267 0.01886461 ... 0.02750304 0.01192634 0.00618288]
 [0.01607805 0.01642284 0.01747165 ... 0.01579511 0.00920023 0.01061363]
 [0.01657773 0.01800664 0.0210737  ... 0.03575864 0.01289423 0.00803788]
 ...
 [0.01687934 0.02152253 0.02121382 ... 0.00959091 0.00671547 0.00475297]
 [0.01738091 0.01609519 0.01484585 ... 0.00804062 0.00751973 0.00551459]
 [0.01721275 0.01795218 0.01664096 ... 0.00701668 0.00696747 0.00488241]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Mary', ' was', ' initially', ' in', ' the', ' bedroom', '.', ' However', ',', ' sentence', ' ', '14', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0682, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02092514 0.02944859 0.03501685 ... 0.0343147  0.01115606 0.01238718]
 [0.02143349 0.02351139 0.02553439 ... 0.02411135 0.01465337 0.01749526]
 [0.02180615 0.03308399 0.04023464 ... 0.02616625 0.0094197  0.01065532]
 ...
 [0.02212511 0.0352745  0.03321636 ... 0.02866844 0.00841903 0.01170038]
 [0.02266595 0.02610625 0.02405795 ... 0.02292197 0.01222046 0.01511292]
 [0.0224237  0.02836168 0.02528311 ... 0.02832135 0.01088213 0.0125143 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '2', ' only', ' mentions', ' the', ' bedroom', ' as', ' a', ' possible', ' location', ' for', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0909, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02848971 0.05244214 0.05604672 0.08877775 0.08220951 0.05809884
  0.04040949 0.03436876 0.03884894 0.05593527 0.03887439 0.02934921
  0.0285261  0.13078418 0.13459538 0.04325718 0.02764216 0.02291776
  0.01843093 0.02334912 0.02367362 0.04280499 0.07191485 0.02245075
  0.00357521 0.02313007]
 [0.02940047 0.03202426 0.0327506  0.06411412 0.0586241  0.04883715
  0.02829575 0.02455062 0.03071433 0.04829396 0.03281865 0.031336
  0.0282275  0.13758056 0.16195795 0.04086675 0.02969949 0.0265228
  0.02026002 0.02424143 0.02231345 0.03546735 0.04270128 0.0160695
  0.00330749 0.01529659]
 [0.02988765 0.03591881 0.04140892 0.06737644 0.06480882 0.06177905
  0.03740865 0.03415865 0.04043247 0.05693005 0.03823435 0.04973792
  0.04376721 0.10801875 0.09931332 0.0341961  0.02712538 0.02665894
  0.01982061 0.02430185 0.02094238 0.03230815 0.03877819 0.02007614
  0.00454321 0.0159737 ]
 [0.02876818 0.04173255 0.04736557 0.04911941 0.05353853 0.05465272
  0.0403484  0.04245814 0.0426742  0.04891531 0.03810937 0.0537824
  0.0451036  0.06288    0.05575054 0.04181135 0.03357424 0.03378946
  0.02589895 0.03138683 0.02865323 0.03663179 0.05267041 0.04228636
  0.01345432 0.03558225]
 [0.02893806 0.05624974 0.06036264 0.03762645 0.03241012 0.04717525
  0.04767258 0.04975026 0.0450532  0.03681946 0.03358493 0.04539691
  0.04443879 0.02560454 0.01925444 0.03934931 0.0301775  0.03100609
  0.02596661 0.03037744 0.02827481 0.03307857 0.06215735 0.04456486
  0.02820159 0.049136  ]
 [0.0299524  0.07405368 0.08064664 0.03527532 0.0260353  0.0435425
  0.05043336 0.04469585 0.05173561 0.03241983 0.02778167 0.03831166
  0.03471562 0.0194206  0.0162928  0.04626729 0.03073121 0.02955825
  0.02462079 0.0316889  0.02783991 0.03219996 0.07546292 0.04111638
  0.01389164 0.0296375 ]
 [0.02999108 0.04642991 0.05627224 0.03133792 0.0229022  0.04091678
  0.0458185  0.0428702  0.04472262 0.02953904 0.02576056 0.03822721
  0.0304642  0.01710456 0.01481866 0.0395325  0.02898339 0.0289628
  0.02410327 0.03000052 0.02833641 0.03297883 0.05506659 0.05144426
  0.01802224 0.03688966]
 [0.03016663 0.03518891 0.0360001  0.04571908 0.03883927 0.05315639
  0.03846538 0.03804809 0.04428873 0.0510963  0.03551893 0.05383912
  0.04167587 0.02939554 0.02042941 0.02329953 0.02234253 0.02854913
  0.02374029 0.02678416 0.02425452 0.03738846 0.03803349 0.02663109
  0.00937733 0.02802736]
 [0.03029937 0.03679276 0.03918111 0.03342301 0.02569226 0.04368486
  0.04053595 0.05036892 0.0423451  0.0377907  0.03204354 0.05776628
  0.04240829 0.01788674 0.0138789  0.03052184 0.02534765 0.02949604
  0.02496915 0.02751661 0.02769392 0.031678   0.02871933 0.02736636
  0.0194521  0.02702707]
 [0.02983564 0.02857238 0.02802199 0.0221113  0.01907731 0.0275921
  0.03691887 0.03468977 0.03090323 0.02538732 0.0327732  0.03500336
  0.03500183 0.0120104  0.01152976 0.04135456 0.03301412 0.03787201
  0.0354375  0.03826919 0.04779848 0.03150531 0.02460604 0.04160623
  0.02970141 0.02495116]
 [0.03008058 0.02086671 0.01825159 0.01638145 0.01417898 0.01665691
  0.02538601 0.02455996 0.02023911 0.01713095 0.02206678 0.01992843
  0.02299238 0.00840021 0.00871662 0.03263003 0.02717605 0.03920107
  0.04150498 0.04539909 0.05085574 0.02713251 0.01742152 0.04131739
  0.04371399 0.0280961 ]
 [0.03050595 0.02249515 0.01956362 0.01749716 0.0153153  0.01841371
  0.02463151 0.02645682 0.0209711  0.0195928  0.02544244 0.02498693
  0.02623869 0.00884014 0.00887156 0.03800462 0.03057889 0.03792614
  0.03907983 0.03982124 0.04082711 0.0256174  0.0152872  0.03208143
  0.04158441 0.02136017]
 [0.03045939 0.01802704 0.01587404 0.01314241 0.01234944 0.01442137
  0.02112697 0.02023979 0.01794867 0.01512256 0.02533766 0.01870748
  0.02077371 0.00697443 0.00743141 0.03466751 0.03225528 0.03351718
  0.04320251 0.03991801 0.04541673 0.02474055 0.01467844 0.03312359
  0.04489133 0.02398449]
 [0.02992036 0.0198127  0.01724634 0.01401036 0.01260386 0.01590084
  0.02265954 0.01964447 0.02040883 0.01513511 0.02581106 0.01795196
  0.02002213 0.00736447 0.00801903 0.03674197 0.03061308 0.03259693
  0.0393814  0.0365327  0.04130353 0.02581759 0.020251   0.05757034
  0.04873977 0.03627178]
 [0.03083559 0.02312404 0.02020914 0.01754704 0.01496798 0.01899685
  0.02345047 0.02378954 0.02228162 0.0196838  0.02574163 0.02346106
  0.02298562 0.00973524 0.0093203  0.02798343 0.02376924 0.03106669
  0.03902511 0.03621726 0.03928487 0.02715524 0.01726749 0.02371588
  0.02291873 0.02267124]
 [0.03021596 0.02778715 0.02740569 0.02919962 0.02438156 0.03522458
  0.02849724 0.03101745 0.03314645 0.03646956 0.02754308 0.04382592
  0.0367833  0.02028244 0.01454599 0.02409286 0.0278311  0.02897532
  0.02731578 0.02731291 0.02550478 0.03301971 0.02825858 0.02840558
  0.02256431 0.03785852]
 [0.03055537 0.0355587  0.03621832 0.02430613 0.02195599 0.02609154
  0.0404395  0.03075131 0.03345489 0.02369274 0.02339356 0.02509265
  0.0255874  0.01444906 0.01416147 0.03692367 0.02938936 0.02621902
  0.02564708 0.03003848 0.02754385 0.02946156 0.04454831 0.04895987
  0.01735904 0.03504554]
 [0.03079866 0.01625192 0.01678799 0.01199012 0.01192778 0.01360202
  0.01610271 0.01456205 0.01839436 0.01250067 0.01422348 0.01265495
  0.01347316 0.00721829 0.00779854 0.02088822 0.02109104 0.01950379
  0.02371898 0.02668739 0.02736247 0.01969126 0.03293039 0.06485567
  0.02782435 0.04487742]
 [0.03044549 0.02532692 0.02453419 0.01890883 0.01621721 0.02237864
  0.02706327 0.027714   0.02558593 0.0194657  0.02168048 0.02414825
  0.0265418  0.01154206 0.01065368 0.02882867 0.02991896 0.02498529
  0.02725605 0.02507279 0.02398772 0.03029717 0.02543781 0.03561286
  0.04508452 0.04706667]
 [0.03127333 0.02583811 0.02412241 0.02031386 0.01639874 0.02632775
  0.02836434 0.03412713 0.02801214 0.02290194 0.02409293 0.02904817
  0.03188847 0.01189123 0.00952152 0.02010981 0.0274993  0.02178663
  0.02440317 0.02195961 0.02043601 0.02887917 0.01746371 0.01866025
  0.04123532 0.03173095]
 [0.03083164 0.02046794 0.01908976 0.01634819 0.01345574 0.01928157
  0.02456721 0.02585566 0.02334124 0.01828107 0.02486679 0.02142013
  0.0263694  0.00975602 0.00843619 0.02271863 0.03062712 0.02256024
  0.02751837 0.02480013 0.02465199 0.02693585 0.01397995 0.02559137
  0.06870601 0.03711597]
 [0.03056868 0.01796029 0.01645565 0.01299608 0.01095584 0.01534933
  0.02152565 0.02121798 0.02022583 0.01510216 0.02639681 0.01715325
  0.0237541  0.00831985 0.0067999  0.02102636 0.03192074 0.02057835
  0.02762321 0.02531819 0.02565587 0.02449086 0.01178869 0.02570066
  0.08839693 0.06439275]
 [0.03098368 0.01667703 0.01518288 0.01329372 0.01094869 0.01471874
  0.01805647 0.01731921 0.0192459  0.01462987 0.02226371 0.01604963
  0.01877026 0.00802818 0.00650154 0.01583645 0.02565747 0.01845144
  0.02658606 0.02762941 0.02658489 0.022559   0.01111129 0.02054258
  0.06986054 0.06169092]
 [0.03144619 0.0196792  0.01800142 0.01466549 0.01226796 0.01765764
  0.02223192 0.02569341 0.02222406 0.01832029 0.02862874 0.02182625
  0.02661617 0.01034352 0.00704689 0.01770714 0.03001877 0.01979182
  0.02928523 0.02307593 0.02235462 0.02620544 0.01252804 0.01756638
  0.0512983  0.03438599]
 [0.0310363  0.02660051 0.02396263 0.01747055 0.01489222 0.02096772
  0.03178101 0.03682943 0.02698794 0.02333813 0.04673662 0.02746557
  0.03670667 0.01150881 0.00826119 0.025738   0.0419214  0.02686254
  0.03342462 0.0268681  0.02645183 0.02715859 0.01562941 0.02293231
  0.05717591 0.03017749]
 [0.03104651 0.02952538 0.02555405 0.01889387 0.01460493 0.02069249
  0.03638086 0.03850801 0.02824827 0.02352799 0.04123382 0.02642125
  0.03746163 0.01205612 0.00900374 0.0274073  0.03792394 0.02968187
  0.03463385 0.0298952  0.0293049  0.02831404 0.01775905 0.02690773
  0.04667105 0.02169214]
 [0.03150165 0.02471033 0.02493775 0.01909673 0.01488222 0.02147704
  0.03556313 0.03778311 0.03058446 0.0229851  0.0487388  0.02913842
  0.03769713 0.01149911 0.00841131 0.02656027 0.03204497 0.0275089
  0.02849578 0.02845222 0.02978983 0.02774134 0.01563276 0.02229609
  0.02508937 0.01458842]
 [0.03091612 0.02167654 0.02001649 0.01518759 0.01179057 0.01661895
  0.0278124  0.0246405  0.02417064 0.01673241 0.02216398 0.01767735
  0.02580825 0.00957659 0.00762353 0.02612676 0.03523171 0.03025793
  0.0333582  0.03078323 0.03285661 0.031026   0.01689045 0.02963119
  0.04177303 0.02333737]
 [0.03132794 0.02051274 0.01956545 0.0173791  0.01340857 0.0176376
  0.02316968 0.0219347  0.0236851  0.01853682 0.0216161  0.01886219
  0.02303407 0.0107592  0.00828875 0.0211102  0.02339959 0.02459869
  0.02832327 0.0288024  0.0315046  0.02598323 0.01528586 0.0251347
  0.02860012 0.02558585]
 [0.03014894 0.0332188  0.03241643 0.05187127 0.05481206 0.04372914
  0.02833755 0.0287097  0.03628547 0.05100843 0.03431586 0.0336206
  0.03470773 0.08911706 0.10402579 0.02924786 0.02594562 0.02734368
  0.02155322 0.02402277 0.02286984 0.03408829 0.03591456 0.01575334
  0.00361856 0.01830188]
 [0.02988251 0.03452401 0.03197726 0.05969286 0.11560874 0.04261875
  0.02427356 0.02524049 0.03201008 0.05863561 0.04006989 0.03350973
  0.028072   0.08885796 0.11116258 0.03563686 0.03847002 0.04205877
  0.02969708 0.02844153 0.02850043 0.03112116 0.03684946 0.01367732
  0.0033054  0.01525821]
 [0.02963071 0.02708975 0.02550475 0.04101681 0.06488028 0.02852955
  0.0187263  0.02301212 0.02812725 0.04831279 0.0371752  0.03444768
  0.02996164 0.03030866 0.03321442 0.02632994 0.04380017 0.07182548
  0.06170068 0.04760713 0.0423901  0.02785517 0.02965691 0.01889737
  0.00969297 0.02022606]
 [0.02985929 0.03286395 0.02906559 0.04391    0.06305788 0.03327164
  0.02354585 0.02443389 0.03270223 0.04576622 0.03496095 0.02985203
  0.02942529 0.03248544 0.0343629  0.02322703 0.03427843 0.04736899
  0.04401744 0.03742821 0.03478101 0.04866734 0.04331874 0.01745416
  0.00636951 0.01863275]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Bill', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 32), x_tokens=32, y_tokens=26, max_supp_attn=0.0769, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 32)
DEBUG result.interpretability.attn_scores 832 
 [[0.03605101 0.04834184 0.04738972 0.07554376 0.07281931 0.05588663
  0.0374417  0.04173051 0.05243121 0.05918464 0.04472585 0.04303068
  0.04247519 0.11664463 0.11890278 0.03894162 0.03850577 0.03115013
  0.03237524 0.03300987 0.02851941 0.04093958 0.0545603  0.02711321
  0.01453552 0.04249703 0.04341546 0.04997268 0.10805076 0.01456259
  0.02119279 0.00911446]
 [0.03711873 0.04881138 0.04630167 0.08755966 0.09892853 0.08955625
  0.04515446 0.04787683 0.056903   0.08313812 0.06314369 0.07126404
  0.06405132 0.16708434 0.13288005 0.04160793 0.03734009 0.03437033
  0.03326533 0.03393779 0.02950568 0.04406669 0.0418066  0.02292496
  0.01684818 0.03460627 0.04688759 0.03968789 0.09557033 0.0193994
  0.02779393 0.01464348]
 [0.03785215 0.04428735 0.04658314 0.07447927 0.07244729 0.06433852
  0.03858935 0.04167326 0.0513086  0.06114058 0.04579352 0.05565382
  0.0473861  0.1270102  0.09453847 0.03675822 0.03569416 0.02814683
  0.02983708 0.02968808 0.02558559 0.04017358 0.03975849 0.0243829
  0.01699938 0.03258063 0.0419155  0.03427585 0.08134722 0.02369693
  0.03710384 0.01486474]
 [0.03665571 0.04009076 0.0429633  0.04181743 0.03660389 0.04205537
  0.03606259 0.04213505 0.0418907  0.03845179 0.03515355 0.0436209
  0.03952796 0.03167016 0.03100523 0.03473683 0.03829983 0.03012021
  0.03385364 0.03542552 0.0313328  0.04075934 0.04965812 0.04220331
  0.03326004 0.0484622  0.04563762 0.04631462 0.06551271 0.05422293
  0.06909674 0.03063463]
 [0.036978   0.0522882  0.05234966 0.03143184 0.02448755 0.03658592
  0.03974659 0.03970591 0.04756173 0.02910778 0.02969066 0.0341657
  0.03323174 0.02254772 0.02326913 0.03689842 0.03478944 0.02571006
  0.03138863 0.03188373 0.02942857 0.04071428 0.06209538 0.03941909
  0.03704872 0.0484111  0.05983167 0.03427458 0.05863196 0.07688772
  0.05262681 0.04071963]
 [0.03792265 0.07149179 0.06749136 0.0314475  0.02472597 0.03859579
  0.04369874 0.03871173 0.0524747  0.02832986 0.02769209 0.03276162
  0.0299832  0.01934695 0.02176124 0.04388106 0.03994419 0.02827121
  0.03375711 0.03673354 0.03097883 0.03677305 0.0857024  0.04222186
  0.03209074 0.04321234 0.04802644 0.02831815 0.04168259 0.07584695
  0.04956724 0.03049132]
 [0.03795889 0.04215121 0.04624706 0.03005649 0.02310429 0.03658029
  0.03842176 0.03874226 0.0436119  0.02986126 0.02762064 0.03610653
  0.03059966 0.01926127 0.01978112 0.03454741 0.03465031 0.02642069
  0.03275322 0.03355225 0.03104713 0.03552087 0.05323685 0.0434536
  0.03524294 0.04281636 0.04472098 0.02931661 0.03388815 0.0762406
  0.06683176 0.04398197]
 [0.0382049  0.02628697 0.02655292 0.02537582 0.02269733 0.029108
  0.02479194 0.0261901  0.02774417 0.02827207 0.02592421 0.02996026
  0.02647838 0.01630834 0.01753449 0.02193368 0.02674684 0.02360472
  0.0304132  0.02962382 0.03028925 0.03341897 0.03240785 0.02834849
  0.03636039 0.05190888 0.0349157  0.04170644 0.03331325 0.06891674
  0.0559672  0.03731019]
 [0.03855825 0.03369008 0.03608492 0.03243596 0.02530558 0.03870417
  0.03481119 0.03935289 0.03804235 0.03761608 0.02920276 0.04799262
  0.0400994  0.02139027 0.01980376 0.02655096 0.03141504 0.02708202
  0.03054021 0.02934065 0.0274296  0.03599287 0.03299003 0.02758241
  0.04049899 0.04189029 0.04424877 0.03623461 0.0328167  0.0741488
  0.06234967 0.05541213]
 [0.03815337 0.03088206 0.02953841 0.02370079 0.02118459 0.02816781
  0.0344744  0.03238222 0.02738999 0.02723409 0.03252009 0.0332196
  0.03696341 0.01688311 0.0177499  0.03405577 0.04259388 0.0357385
  0.04186438 0.0393681  0.04295427 0.03761693 0.02601527 0.04354196
  0.05928256 0.03922917 0.03355462 0.04330906 0.02239605 0.05712508
  0.04301628 0.06482203]
 [0.03844009 0.02804933 0.0268862  0.01992137 0.01820843 0.02410442
  0.03692134 0.03314168 0.02478645 0.0226021  0.03099106 0.02710153
  0.03183778 0.01376407 0.01585452 0.03534687 0.03870384 0.03572637
  0.04235718 0.04146464 0.04715635 0.03513314 0.02437276 0.05014244
  0.08137239 0.04034578 0.02684648 0.0483497  0.02037492 0.05718781
  0.03723413 0.07345121]
 [0.0397952  0.02870577 0.0312244  0.02038206 0.02116198 0.02750629
  0.04345293 0.04134505 0.0329699  0.02498922 0.03114825 0.0309122
  0.03688029 0.01577576 0.01632869 0.03572136 0.03897895 0.03021956
  0.03933841 0.03619552 0.04145174 0.03306657 0.03013159 0.04182248
  0.05869791 0.04496442 0.03019361 0.03709316 0.02288731 0.03641319
  0.03401895 0.0493639 ]
 [0.03998253 0.02732338 0.03047802 0.02330272 0.02249796 0.03055629
  0.033381   0.03155024 0.03707301 0.02824762 0.02912927 0.03353951
  0.03168366 0.0183978  0.01743098 0.02721895 0.02887618 0.02403625
  0.03193935 0.03005184 0.03012035 0.03674134 0.02901095 0.03062552
  0.03295907 0.04322511 0.0339435  0.03293015 0.02872891 0.03580383
  0.0533192  0.04338231]
 [0.0385432  0.03023489 0.03200017 0.02812876 0.0262716  0.0322157
  0.03261644 0.03342219 0.03630872 0.03362865 0.02996421 0.03602388
  0.03521793 0.02214433 0.0205425  0.02925778 0.03218691 0.02754238
  0.03122504 0.03115947 0.03091714 0.03923542 0.03219981 0.03737444
  0.02786718 0.03994235 0.0370823  0.03766172 0.03710883 0.03653289
  0.08693948 0.0394436 ]
 [0.03956579 0.03721478 0.04213151 0.02626365 0.02355236 0.03249438
  0.04352156 0.04151297 0.03488786 0.02776975 0.03095023 0.03295803
  0.03535299 0.01786126 0.0179472  0.03780319 0.03329914 0.02875583
  0.03251038 0.03186304 0.0335932  0.03848388 0.03361766 0.04041579
  0.03507301 0.0342582  0.04519319 0.02238843 0.02456224 0.03988757
  0.03995211 0.04790056]
 [0.03987219 0.03751443 0.04049313 0.02690548 0.02325844 0.03408765
  0.04862457 0.04913816 0.03405729 0.02917224 0.03230166 0.03482983
  0.04066737 0.01854676 0.01746333 0.03741997 0.03207451 0.02876873
  0.03051989 0.03008234 0.03214502 0.03763139 0.03027845 0.0384489
  0.03719416 0.03213356 0.04355435 0.02272422 0.02488621 0.04102501
  0.04016479 0.06798757]
 [0.04032792 0.04125845 0.04745134 0.0312999  0.02840301 0.03747404
  0.05414258 0.05051206 0.04080745 0.03263957 0.03705413 0.03750089
  0.04212021 0.02213246 0.01989109 0.03905752 0.03266168 0.02823936
  0.03133376 0.03175848 0.0310978  0.03813399 0.03367011 0.03745397
  0.03001424 0.03122665 0.04185995 0.02393382 0.02516519 0.03144101
  0.02986648 0.0405411 ]
 [0.03904631 0.03275407 0.03003552 0.01931979 0.01803989 0.02287851
  0.04169074 0.03673865 0.02653872 0.02019053 0.03601912 0.02353979
  0.03458242 0.01327104 0.0147794  0.05117837 0.04292165 0.03463274
  0.03736519 0.03546255 0.04388766 0.03576647 0.02467609 0.06485965
  0.05311353 0.03066888 0.02372156 0.02751048 0.01699807 0.02902276
  0.02461375 0.04702055]
 [0.03874112 0.02854668 0.02641149 0.02016513 0.01669363 0.02170046
  0.03353424 0.03160176 0.02515306 0.02018164 0.03612323 0.02371384
  0.02988623 0.01347801 0.01442102 0.05761204 0.04208689 0.04325509
  0.04362931 0.04265722 0.05291899 0.03597757 0.02086396 0.0609188
  0.05774749 0.03160985 0.02015222 0.03048233 0.01708118 0.03038999
  0.02737408 0.05786486]
 [0.03881639 0.04747997 0.03961513 0.02620327 0.02024117 0.02728814
  0.05376429 0.05471393 0.03445704 0.0250559  0.05988147 0.03175329
  0.04688912 0.01596031 0.01802935 0.07608929 0.05228635 0.05898298
  0.04770072 0.05037793 0.05162649 0.03935279 0.02661056 0.07140182
  0.07427599 0.02943412 0.02908253 0.02793848 0.01712777 0.02730221
  0.02264063 0.0737806 ]
 [0.0397619  0.03103034 0.03066427 0.02308804 0.01818171 0.0256625
  0.03557257 0.03459955 0.02942188 0.02304218 0.0429845  0.02792512
  0.03386552 0.01556483 0.01552914 0.05179152 0.04417064 0.04454515
  0.04446452 0.04701911 0.04627584 0.03306184 0.02062445 0.05671994
  0.05948704 0.02976729 0.02255493 0.02698962 0.0164957  0.02520017
  0.02839793 0.05308511]
 [0.03835366 0.0341411  0.03621935 0.05176917 0.04787342 0.046693
  0.03630043 0.03557846 0.04635628 0.0570109  0.04215568 0.04461368
  0.0459298  0.06775784 0.0890393  0.03228051 0.03515887 0.0440044
  0.04070707 0.04029711 0.03878302 0.04023616 0.03778993 0.0233482
  0.01504672 0.03728442 0.03630455 0.05006553 0.04582861 0.01342356
  0.02125816 0.0106834 ]
 [0.0377221  0.04472138 0.03973416 0.08131578 0.14136553 0.05955873
  0.03514    0.03538573 0.04236915 0.08111329 0.06103081 0.05505971
  0.04293061 0.08535149 0.11217775 0.04268593 0.05427892 0.0868947
  0.05903811 0.05592259 0.05553997 0.04084696 0.04836789 0.02370606
  0.01585169 0.03563772 0.05185967 0.05138198 0.0429012  0.00913082
  0.01321839 0.00778689]
 [0.03800974 0.03853693 0.03246648 0.04447421 0.05283095 0.03633679
  0.03112081 0.03326953 0.03580956 0.04746685 0.04925171 0.04477801
  0.04287867 0.03338655 0.04154947 0.03775334 0.05647429 0.08246256
  0.06370596 0.06646518 0.05711887 0.03762193 0.04090449 0.02993543
  0.04314574 0.04440452 0.03849893 0.05657525 0.02743513 0.01449538
  0.01725991 0.01644248]
 [0.03868277 0.03989615 0.03771349 0.057161   0.05929299 0.04242272
  0.03330439 0.03645242 0.04116577 0.0587379  0.04825549 0.04913222
  0.04211328 0.03665981 0.03799289 0.03152717 0.04240209 0.06903948
  0.05161668 0.05165545 0.05365042 0.0418427  0.0437839  0.02722543
  0.03231971 0.03662766 0.04199883 0.05811555 0.02707939 0.01567506
  0.01757388 0.01439959]
 [0.03888549 0.03427084 0.03497306 0.04645114 0.03982258 0.03944169
  0.0337194  0.03253678 0.03847938 0.04581542 0.04129215 0.03884274
  0.03636773 0.03180066 0.03379719 0.02734419 0.03345949 0.04227978
  0.04250044 0.04500425 0.04664596 0.05089167 0.04486609 0.0244094
  0.02366665 0.03285526 0.03399906 0.062449   0.03212958 0.01602102
  0.02062194 0.01487165]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.04969424 0.05969629 0.06609438 0.07991881 0.06816296 0.07870872
  0.06094789 0.05935759 0.07622592 0.07031134 0.05110253 0.05731215
  0.06523902 0.12847452 0.1127525  0.04575891 0.03933403 0.03891068
  0.03148478 0.03758078 0.03493502 0.05105617 0.07810082 0.03689397
  0.01519858 0.05183427 0.0596473  0.06097935 0.12604854 0.02499773
  0.0265112  0.01428195 0.01099922 0.06226415 0.07804399 0.05373868
  0.03340378 0.05748741]
 [0.05075483 0.06697578 0.06386019 0.05567608 0.04675529 0.07327884
  0.08523016 0.08926328 0.06773103 0.05572651 0.05404243 0.0710435
  0.09382518 0.0513184  0.06117516 0.04381606 0.03886416 0.04719709
  0.04193078 0.04990137 0.0398059  0.05434288 0.05826255 0.04904779
  0.0502508  0.07305198 0.04187414 0.05681746 0.09006878 0.05298048
  0.05537633 0.05271692 0.06827342 0.04319628 0.05760106 0.05630671
  0.04094372 0.05727685]
 [0.05192295 0.06604222 0.07569027 0.09706986 0.0894238  0.10888925
  0.06970073 0.06411894 0.08155739 0.08406888 0.05979601 0.07481557
  0.07817154 0.17187642 0.11418308 0.04796687 0.03455674 0.0340566
  0.02772881 0.03277884 0.02981378 0.05297296 0.06774241 0.03743322
  0.01382289 0.04252116 0.05899032 0.04344016 0.11502928 0.03912337
  0.04835691 0.02151293 0.01682302 0.06710703 0.06180548 0.04404336
  0.02907348 0.04239415]
 [0.05028936 0.06723584 0.07087819 0.05239459 0.04217414 0.06118155
  0.06046658 0.06522291 0.06701076 0.05416119 0.04658227 0.05581834
  0.05795804 0.04490224 0.03875521 0.05506495 0.04284305 0.03979452
  0.03568237 0.04046319 0.03693908 0.05781943 0.08148579 0.06939901
  0.03370541 0.0604506  0.07503458 0.0520945  0.09186191 0.09675351
  0.1343504  0.04576839 0.04002477 0.04609874 0.05926387 0.07578187
  0.05659622 0.05558281]
 [0.05213681 0.06565992 0.06850259 0.03936076 0.02872432 0.04814929
  0.06464538 0.05372932 0.06356865 0.03859729 0.04094053 0.04029275
  0.04186001 0.02988073 0.0304772  0.05836339 0.04062944 0.0359978
  0.03768695 0.04355506 0.03875238 0.05062411 0.0828789  0.07393961
  0.03091484 0.06084625 0.09080222 0.03820424 0.05157952 0.08217663
  0.17509541 0.05719805 0.03392642 0.03548032 0.05714964 0.09728238
  0.08203736 0.06161245]
 [0.05335181 0.03439922 0.0332234  0.02182767 0.01773735 0.02624442
  0.03202784 0.03088099 0.03796818 0.02297684 0.02985212 0.02468705
  0.02614198 0.0162135  0.01801983 0.03773241 0.03120028 0.02897154
  0.03425582 0.03751512 0.03169428 0.03949546 0.03762598 0.05265405
  0.02705178 0.04699198 0.04560858 0.02699273 0.02394562 0.03311798
  0.07662109 0.03386164 0.02211526 0.02070085 0.02747472 0.05280903
  0.06621037 0.04827784]
 [0.05208852 0.05576203 0.05488214 0.03645791 0.02562927 0.04870809
  0.05235763 0.05615402 0.0531844  0.04084706 0.04291098 0.05181093
  0.04940184 0.02613888 0.02548444 0.052869   0.04569033 0.04427879
  0.0489306  0.04895724 0.04281795 0.05783326 0.05754251 0.0672551
  0.06630325 0.06682273 0.07081605 0.04423555 0.05009248 0.09432168
  0.08429703 0.10257716 0.08645163 0.03193687 0.05055662 0.07570625
  0.07158516 0.05547992]
 [0.05346299 0.06687132 0.06969909 0.05717697 0.03658927 0.06811064
  0.06738343 0.07186712 0.0647486  0.06219907 0.06119282 0.08360483
  0.07179545 0.03991611 0.03306141 0.06055534 0.05103577 0.05182125
  0.0482601  0.04994044 0.04497592 0.05839438 0.0566855  0.06136262
  0.06472956 0.05694692 0.07060858 0.05408678 0.04971476 0.10001514
  0.06508878 0.10340548 0.10383541 0.04002066 0.05588516 0.06508869
  0.05536741 0.04526302]
 [0.05433333 0.05038298 0.05305258 0.041155   0.02842171 0.0478549
  0.05558017 0.05237475 0.04725572 0.04440027 0.051484   0.05064426
  0.05194905 0.0275707  0.02580094 0.05580628 0.04854229 0.04398707
  0.04792716 0.0487259  0.04422697 0.05675333 0.04507291 0.05795297
  0.06101913 0.04800967 0.0514177  0.04821252 0.04096838 0.07399885
  0.05164715 0.07959491 0.07561012 0.0400163  0.04294443 0.05102091
  0.05593266 0.03842703]
 [0.05364581 0.03905142 0.03739808 0.02884773 0.01971782 0.03062212
  0.04103568 0.04108096 0.03522101 0.0320176  0.04264998 0.03568782
  0.04098089 0.01832336 0.0197305  0.05806626 0.05906375 0.04876197
  0.05881938 0.05536138 0.0501481  0.05528577 0.03496496 0.06444087
  0.07801414 0.04603363 0.03762102 0.046547   0.03040391 0.05745551
  0.03377269 0.06444219 0.06149748 0.03450794 0.03648923 0.04637415
  0.06284345 0.03990094]
 [0.0532237  0.04162314 0.03743071 0.03136512 0.01983467 0.03130086
  0.04801627 0.04570345 0.03460208 0.03217532 0.04487856 0.03666756
  0.04470672 0.01781844 0.01855155 0.06309144 0.0551925  0.0618157
  0.07789522 0.07723426 0.06455696 0.05199906 0.03177957 0.06903202
  0.10936624 0.04260468 0.03571923 0.04640515 0.02254542 0.06309445
  0.0267156  0.06813891 0.08799374 0.03084422 0.03605172 0.0536601
  0.07919391 0.05208226]
 [0.05428407 0.03912033 0.03678243 0.03046118 0.02149155 0.03082928
  0.04030893 0.04297059 0.03480839 0.0346334  0.04880224 0.0419518
  0.04197916 0.01832156 0.01862355 0.05557518 0.0653564  0.04876089
  0.08308238 0.05996324 0.05648653 0.05053317 0.02682734 0.04785319
  0.11530624 0.0437103  0.03720609 0.04352375 0.02095743 0.05327222
  0.02799948 0.08003102 0.08308703 0.02648455 0.03172845 0.03778344
  0.05059966 0.04524866]
 [0.05427727 0.03575731 0.03340831 0.02610861 0.01929836 0.0258628
  0.04027068 0.03869351 0.03246659 0.02814596 0.05197159 0.03562273
  0.03951246 0.01491692 0.01606783 0.05924377 0.06571021 0.05062292
  0.08149051 0.06474954 0.05999932 0.04905639 0.02534031 0.05655428
  0.10296835 0.04557424 0.02845781 0.04598719 0.01842622 0.04691654
  0.02765096 0.08245745 0.11430307 0.0241333  0.03299293 0.04045821
  0.06172279 0.06227763]
 [0.05257379 0.04280786 0.03683681 0.02902851 0.02038297 0.03189509
  0.05043557 0.04467397 0.04147906 0.03065464 0.05668403 0.04138432
  0.0478851  0.01663186 0.01833712 0.05896965 0.06699345 0.06236553
  0.08929148 0.08615036 0.06305906 0.05292938 0.03687659 0.06569351
  0.09788635 0.07190021 0.03250346 0.06214964 0.02530892 0.04453821
  0.03419469 0.06561296 0.06803977 0.02857623 0.043693   0.0507051
  0.07231507 0.08503954]
 [0.05453321 0.03977382 0.03984763 0.03670009 0.02409822 0.03445465
  0.04024837 0.04343453 0.03723705 0.03596362 0.04659947 0.04317855
  0.04082954 0.02324277 0.02069899 0.03855778 0.03592141 0.03634917
  0.04244406 0.04409278 0.0420419  0.04831633 0.02827134 0.03934683
  0.03761179 0.04376745 0.03143154 0.04130729 0.03264098 0.04249604
  0.0441935  0.0647788  0.07196514 0.04447175 0.03606563 0.03273635
  0.04579995 0.0501968 ]
 [0.05250993 0.0502874  0.05487996 0.07929117 0.0677345  0.07165151
  0.04939326 0.05066798 0.06174444 0.08038175 0.05903881 0.06198385
  0.06158404 0.1148163  0.1212845  0.04333485 0.04065471 0.04668847
  0.0340038  0.04086804 0.04085507 0.05057173 0.0537486  0.03292259
  0.01614733 0.04694582 0.05245505 0.05992938 0.06742242 0.02857532
  0.03317832 0.01679911 0.01406591 0.11780922 0.06065353 0.03826531
  0.03332268 0.05051982]
 [0.0521543  0.06599999 0.0642409  0.11715786 0.24475144 0.08169897
  0.05135675 0.05275064 0.06042695 0.10917646 0.08472345 0.0785092
  0.05125026 0.13361032 0.17660761 0.06027922 0.07325336 0.08538333
  0.04887049 0.05216947 0.07394212 0.04954209 0.07227006 0.03443175
  0.01589983 0.04632377 0.07710927 0.06360237 0.06376345 0.01960408
  0.01655761 0.01149551 0.00922345 0.12028344 0.0802012  0.03827866
  0.02836815 0.05168507]
 [0.05222891 0.0535704  0.04881699 0.06447332 0.1010939  0.04401419
  0.03900844 0.0448907  0.04485602 0.07093628 0.06643301 0.05987749
  0.04484519 0.04490945 0.06612518 0.05849245 0.09949476 0.12004941
  0.07750332 0.06849167 0.12917027 0.04843367 0.05522782 0.04577107
  0.04180073 0.05410045 0.05518672 0.07632995 0.03539797 0.02484833
  0.02051568 0.02053973 0.01691648 0.08059362 0.05712562 0.04847513
  0.04046695 0.05171857]
 [0.05253423 0.05898279 0.05447533 0.07552872 0.07797842 0.05654489
  0.05158626 0.05216479 0.05790781 0.07262658 0.06031515 0.05510733
  0.05008453 0.06111754 0.06426339 0.04645621 0.06566341 0.0741873
  0.05271202 0.06150135 0.07577926 0.06404042 0.06929598 0.03801554
  0.02200277 0.05156391 0.04751037 0.08915504 0.04382414 0.02171389
  0.01787728 0.01478685 0.01484865 0.10547458 0.09427365 0.04148572
  0.03421725 0.04952923]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' kitchen', ',', ' implying', ' that', ' she', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03217521 0.04490597 0.0478925  ... 0.03014905 0.03188963 0.0507666 ]
 [0.03263774 0.04736073 0.04571675 ... 0.06209192 0.0392676  0.02889667]
 [0.03339042 0.04981094 0.0548573  ... 0.0421632  0.04196458 0.0451889 ]
 ...
 [0.0337242  0.04999784 0.04550801 ... 0.01818813 0.03973176 0.10384285]
 [0.03392995 0.03962037 0.03324435 ... 0.01757688 0.01990275 0.08130399]
 [0.03398501 0.04259253 0.03510698 ... 0.01642297 0.01827148 0.11137754]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Julie', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 50), x_tokens=50, y_tokens=26, max_supp_attn=0.0, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 50)
DEBUG result.interpretability.attn_scores 1300 
 [[0.03630873 0.04279985 0.04303475 ... 0.02862244 0.04277567 0.03993919]
 [0.03698473 0.0411575  0.04339072 ... 0.03040132 0.03679528 0.02629951]
 [0.03778632 0.04475053 0.04849673 ... 0.0192693  0.03844339 0.02575923]
 ...
 [0.03840481 0.03528285 0.03276812 ... 0.06381661 0.06486446 0.0619788 ]
 [0.03880079 0.04570018 0.04174083 ... 0.02572715 0.03317422 0.04543151]
 [0.03857972 0.04068473 0.03750309 ... 0.02628215 0.03657815 0.05347817]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' went', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02717428 0.04625931 0.05901215 0.0685867  0.07165725 0.07150596
  0.0730227  0.08307313 0.06007914 0.06195492 0.0479273  0.06561495
  0.07480256 0.08244583 0.05150864 0.03267757 0.03128394 0.0337946
  0.03111114 0.0330807  0.02707383 0.03890384 0.04140188 0.02191537
  0.01649691 0.0278576 ]
 [0.0270147  0.07911958 0.05462068 0.05022593 0.04096195 0.05005972
  0.12234334 0.0743064  0.05852535 0.04444524 0.0507721  0.04192682
  0.05793995 0.02166976 0.021463   0.03802444 0.03641757 0.04888403
  0.04393091 0.05019513 0.0463738  0.04459608 0.04812444 0.04289368
  0.03322942 0.03770768]
 [0.02776081 0.05730704 0.04809859 0.07188781 0.05915159 0.05692072
  0.03799551 0.03364886 0.0386429  0.04772107 0.03756592 0.030805
  0.02980966 0.10753355 0.10437563 0.03173889 0.02512261 0.02252948
  0.0225727  0.02238635 0.01999036 0.04135224 0.04422693 0.01270811
  0.00915865 0.02200869]
 [0.02978559 0.05732714 0.03669755 0.05324327 0.0367001  0.03672437
  0.03059509 0.02249445 0.02230687 0.03363014 0.02718149 0.01717953
  0.0180844  0.02722299 0.03640851 0.02318244 0.01380642 0.01308177
  0.01603682 0.01620018 0.01450471 0.04373093 0.05135708 0.00737437
  0.00539961 0.01165337]
 [0.02817098 0.02497988 0.02825806 0.02138622 0.01541477 0.02294878
  0.02382149 0.02057761 0.02367886 0.02194177 0.02367432 0.02273638
  0.02076014 0.01105581 0.01068526 0.02805929 0.02820665 0.03013438
  0.03592856 0.03780398 0.03368813 0.02937035 0.03906314 0.04704902
  0.06619368 0.05890453]
 [0.02829893 0.04143086 0.04701619 0.06471538 0.06011295 0.04783652
  0.03269865 0.03002429 0.03430111 0.04577729 0.03438266 0.02685063
  0.02571039 0.09495852 0.09862579 0.03655002 0.02647905 0.02000262
  0.02146988 0.02213414 0.02045508 0.03791253 0.06076724 0.01248148
  0.008201   0.02651829]
 [0.02890834 0.02703188 0.02859987 0.04895711 0.04560379 0.04255847
  0.02392241 0.02361839 0.02898644 0.04252862 0.03125883 0.03015801
  0.02771325 0.10727924 0.12631536 0.03625374 0.02985677 0.02399626
  0.02392207 0.02326754 0.01947361 0.03188996 0.03551451 0.00905701
  0.00628667 0.01673261]
 [0.02929964 0.03062436 0.03709958 0.05180284 0.04906355 0.05317583
  0.0316478  0.03230348 0.03766007 0.0505767  0.03661725 0.04762107
  0.04247494 0.08513813 0.07907897 0.03127372 0.02767066 0.02435623
  0.0228405  0.02275754 0.01850195 0.02893163 0.03347884 0.0129966
  0.00880621 0.0163861 ]
 [0.02828349 0.03879364 0.04650917 0.04046991 0.04417597 0.04840979
  0.0362984  0.04088681 0.03969106 0.04354624 0.03664515 0.05078232
  0.04293142 0.0514821  0.04670256 0.04031365 0.036464   0.03192972
  0.02862486 0.02916185 0.02637601 0.03311101 0.04709661 0.02977775
  0.03094405 0.03294728]
 [0.02948147 0.03933866 0.04869432 0.04609381 0.04317592 0.05577897
  0.04016295 0.04594398 0.04763325 0.04931324 0.0362897  0.05333779
  0.04707691 0.03853367 0.025675   0.02818993 0.02693909 0.02578712
  0.02469977 0.02482095 0.02071375 0.03348317 0.03545578 0.01815755
  0.0135162  0.02244682]
 [0.028701   0.05031491 0.05433828 0.02822084 0.02386679 0.03699904
  0.04281276 0.0420566  0.04416351 0.03010991 0.02937241 0.03811609
  0.03803189 0.01677654 0.01475422 0.04579412 0.03616387 0.03066816
  0.03138833 0.03240951 0.03068722 0.03378793 0.06641968 0.03972811
  0.03506268 0.03622731]
 [0.0292716  0.03955383 0.04608679 0.02354281 0.02122959 0.02706691
  0.04440802 0.03442164 0.04085853 0.02416711 0.02432456 0.02733837
  0.02681608 0.01317048 0.01309377 0.04533084 0.03409338 0.02841566
  0.03092536 0.03347478 0.0296234  0.0296537  0.05449224 0.04226438
  0.04150482 0.03362941]
 [0.02961568 0.0143759  0.0166389  0.0108154  0.01020636 0.01393828
  0.01559243 0.01605389 0.02157543 0.01333486 0.01363927 0.01433865
  0.01427027 0.00608189 0.00640901 0.01987374 0.0194293  0.01852313
  0.02390675 0.02643792 0.02706373 0.01963617 0.03623458 0.0527142
  0.07193571 0.06227618]
 [0.02937813 0.02395164 0.02570342 0.01542991 0.01477538 0.01988531
  0.02263639 0.02137051 0.02315762 0.01720382 0.02110369 0.02058871
  0.02040623 0.00850151 0.00917586 0.03437582 0.0280323  0.02501336
  0.02560199 0.02643487 0.02667988 0.02741263 0.03053633 0.04494423
  0.06975909 0.05093757]
 [0.02956264 0.02283481 0.02383892 0.01745273 0.01590512 0.02276216
  0.02469365 0.02643999 0.02501676 0.02105564 0.02535208 0.02801533
  0.02806153 0.0097436  0.00896372 0.03259381 0.03606547 0.03220746
  0.02905867 0.02894676 0.03184947 0.02792339 0.02157782 0.03380249
  0.05979732 0.03133266]
 [0.02908603 0.01859009 0.01643626 0.01335845 0.01101299 0.01478239
  0.01868574 0.01928815 0.01817102 0.0152186  0.0205141  0.01775283
  0.02071957 0.00655101 0.00677388 0.03058041 0.02923344 0.03989272
  0.03080332 0.03977688 0.04654952 0.02531049 0.01683926 0.04778141
  0.0917448  0.0463223 ]
 [0.02976167 0.01695058 0.01649974 0.01292199 0.01125873 0.01588298
  0.01922922 0.02033492 0.01871499 0.01596038 0.02397275 0.02098277
  0.02166521 0.00652597 0.00646736 0.02911542 0.02632867 0.03591066
  0.02995496 0.04160436 0.04081412 0.02093623 0.01463561 0.04107299
  0.07086838 0.03317314]
 [0.02973414 0.01550316 0.01415344 0.0102195  0.00880925 0.01288076
  0.0168155  0.01661753 0.01700498 0.01266168 0.02466666 0.01681857
  0.01854087 0.00539574 0.00561333 0.03109729 0.02825801 0.03486739
  0.03423579 0.04061791 0.03734107 0.02159008 0.0149005  0.04757215
  0.04817494 0.04404279]
 [0.02907562 0.01971512 0.0173738  0.01223556 0.01088557 0.01525038
  0.02038377 0.01913605 0.0219589  0.01449683 0.02120195 0.01690912
  0.0196691  0.00642191 0.00673912 0.02796017 0.02458599 0.02681544
  0.03274956 0.0322951  0.04005475 0.02482778 0.02261798 0.0790041
  0.04957611 0.06223354]
 [0.03028571 0.02061454 0.01996261 0.01498671 0.01253183 0.01760278
  0.02000324 0.02174963 0.02209525 0.01730101 0.02393029 0.02219743
  0.02235161 0.00813979 0.00747349 0.02377609 0.02366499 0.0251812
  0.03014766 0.02847032 0.02751447 0.02587868 0.01642637 0.02785932
  0.02352519 0.03093989]
 [0.03047406 0.0217001  0.0248139  0.02037819 0.01684601 0.02459967
  0.02366595 0.03147926 0.02550533 0.02504895 0.02768858 0.0351066
  0.03102694 0.011762   0.00850153 0.01986189 0.02109941 0.02384076
  0.02348479 0.02189058 0.02183229 0.0272312  0.01506553 0.01957461
  0.01672631 0.02071881]
 [0.03058203 0.02644963 0.02882286 0.02489541 0.01861855 0.02965857
  0.03004143 0.04044059 0.02824505 0.03088742 0.03574501 0.04427496
  0.04050927 0.01394455 0.00965533 0.02274205 0.022998   0.02684646
  0.02413354 0.02273974 0.02186083 0.02848328 0.01662371 0.01788758
  0.01280417 0.01502048]
 [0.03044689 0.02410875 0.02537626 0.0231496  0.01858328 0.02658744
  0.02716755 0.03438138 0.02788714 0.02927094 0.03363051 0.0389854
  0.03799019 0.01318216 0.01001767 0.02616172 0.0263585  0.03008167
  0.0267972  0.02472282 0.02409672 0.02849225 0.01419101 0.01801664
  0.01541384 0.0139025 ]
 [0.03029407 0.01825653 0.0180151  0.01408542 0.01098796 0.01635863
  0.01965974 0.02300554 0.02126155 0.01752112 0.02384537 0.02302803
  0.02524038 0.00770796 0.00686509 0.02622825 0.02965566 0.03050481
  0.02894256 0.02722861 0.03134967 0.02701424 0.01199029 0.02427981
  0.02777353 0.01916724]
 [0.03043043 0.01803912 0.01671215 0.01321657 0.00972738 0.01418137
  0.01899035 0.02048367 0.01983559 0.01540726 0.02135844 0.01923915
  0.02258492 0.00667233 0.00603466 0.02623741 0.02650242 0.03146622
  0.02930325 0.02928693 0.03505493 0.02216757 0.01152101 0.0321147
  0.02709155 0.02192071]
 [0.03062066 0.01877474 0.01740391 0.01395976 0.01117341 0.01545614
  0.01903664 0.02207843 0.02107123 0.01784556 0.02483893 0.02268705
  0.02409299 0.00766288 0.00659565 0.02618542 0.03076978 0.02966489
  0.03301884 0.02828167 0.03027543 0.02363545 0.01184287 0.02253398
  0.01623843 0.01647545]
 [0.0305414  0.02111637 0.0196558  0.01518939 0.0114931  0.0170544
  0.02228086 0.02468642 0.02548403 0.01885746 0.02825754 0.02363817
  0.02623111 0.00804463 0.00680337 0.02889239 0.02992965 0.03198094
  0.03404853 0.0319173  0.03447128 0.02410571 0.01289536 0.0272873
  0.01813845 0.0171018 ]
 [0.03065839 0.01552029 0.01490055 0.00983574 0.00840082 0.01188735
  0.01687383 0.01728295 0.01924333 0.01265025 0.02819931 0.01616845
  0.0199768  0.00577916 0.00481576 0.02765688 0.03371299 0.02906046
  0.03890894 0.03390139 0.03388853 0.02161946 0.01210776 0.03110966
  0.01807788 0.02340561]
 [0.02948601 0.01992285 0.01937991 0.01180857 0.01008576 0.01450772
  0.02039765 0.02178654 0.02545136 0.01499564 0.02217731 0.017686
  0.02267509 0.00681924 0.00606752 0.02566154 0.02473391 0.02342809
  0.03348032 0.03085966 0.04118816 0.02442724 0.02121603 0.06727354
  0.03948081 0.05189092]
 [0.03060539 0.02005315 0.02027594 0.01568125 0.01235776 0.01882396
  0.02025415 0.02488436 0.02549823 0.01924764 0.0247807  0.02403598
  0.02414033 0.0099278  0.00805197 0.02005851 0.02497346 0.02315185
  0.03088534 0.02743759 0.02782398 0.02503361 0.01412111 0.01999847
  0.01390203 0.0209796 ]
 [0.02951189 0.02677501 0.02765826 0.04091312 0.04307467 0.0364765
  0.02246696 0.02474569 0.03031297 0.04249432 0.03157667 0.03193848
  0.03012751 0.06651182 0.08176725 0.02472447 0.02752244 0.02487693
  0.02497597 0.02329805 0.02097629 0.03070576 0.03017688 0.01033393
  0.00776916 0.01856675]
 [0.02930357 0.02831326 0.02792438 0.04577357 0.09047717 0.03717992
  0.02119112 0.02342939 0.02953182 0.05035231 0.03812517 0.03243871
  0.02522348 0.06853633 0.08658049 0.03083845 0.0377983  0.0340798
  0.02921333 0.02548401 0.02397571 0.02795625 0.02977985 0.00874083
  0.00577542 0.01591124]
 [0.02909974 0.02462398 0.02406517 0.03614186 0.08025489 0.02455565
  0.01699141 0.02183015 0.02496705 0.04310032 0.03568799 0.03274784
  0.02478503 0.02906386 0.03913891 0.02551151 0.05713627 0.05394374
  0.04114125 0.03114035 0.03913631 0.02486646 0.02724964 0.0168306
  0.0112337  0.02085397]
 [0.029295   0.03172928 0.02935755 0.03841871 0.05141974 0.02970259
  0.0232132  0.02513935 0.03148328 0.0393757  0.03369602 0.02795475
  0.02755996 0.02975725 0.03280237 0.02247809 0.038707   0.03508195
  0.03175643 0.02953456 0.02874094 0.04402274 0.04005221 0.0128639
  0.00939329 0.01980719]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Fred', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' cinema', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02748362 0.0473115  0.04819432 ... 0.07795168 0.00800485 0.02298608]
 [0.02834141 0.04612102 0.04401563 ... 0.07285296 0.0115651  0.02677857]
 [0.02876863 0.0443409  0.0477346  ... 0.06936524 0.01810654 0.0267658 ]
 ...
 [0.02872416 0.04179171 0.03718542 ... 0.02983947 0.00617903 0.01184212]
 [0.02913275 0.03024744 0.02590185 ... 0.01575227 0.00873912 0.01227692]
 [0.02915207 0.03127449 0.02729806 ... 0.01634472 0.00756917 0.01345861]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' kitchen', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 38), x_tokens=38, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 38)
DEBUG result.interpretability.attn_scores 1292 
 [[0.02754779 0.04097058 0.03749741 ... 0.02095402 0.01853263 0.02095971]
 [0.02788395 0.06754628 0.06124021 ... 0.03030837 0.03431289 0.03360363]
 [0.0287516  0.04496318 0.0454586  ... 0.01645636 0.0158461  0.01404682]
 ...
 [0.0289141  0.03956857 0.0372113  ... 0.01499711 0.01344128 0.01607784]
 [0.02941352 0.02734611 0.02335073 ... 0.01838894 0.02226074 0.02222024]
 [0.02909199 0.0313873  0.02721855 ... 0.01784198 0.01575543 0.02234042]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', ' from', ' the', ' office', '.', ' Sentence', ' ', '10', ' mentions', ' Fred', ' moving', ' to', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' imply', ' that', ' Bill', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 44), x_tokens=44, y_tokens=57, max_supp_attn=0.0175, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 44)
DEBUG result.interpretability.attn_scores 2508 
 [[0.01583182 0.02039    0.02444718 ... 0.02772654 0.00790484 0.00717887]
 [0.01635158 0.01562096 0.01841218 ... 0.02616195 0.01482884 0.01191495]
 [0.01666983 0.02029234 0.02715491 ... 0.04368598 0.01153078 0.01143976]
 ...
 [0.01687646 0.02553054 0.02425377 ... 0.01002018 0.0060837  0.00652829]
 [0.01741244 0.02046047 0.01837702 ... 0.00720042 0.00710356 0.00871386]
 [0.01716541 0.02277804 0.0208086  ... 0.00647522 0.00682677 0.00762901]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '14', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.0324366  0.04470733 0.05431864 ... 0.04988166 0.02401186 0.01543517]
 [0.03290184 0.04021701 0.04970871 ... 0.03555882 0.03210961 0.03196351]
 [0.0339086  0.04681182 0.06298632 ... 0.03674516 0.01933665 0.01394509]
 ...
 [0.03406828 0.05055191 0.04804458 ... 0.04482886 0.02222889 0.01459478]
 [0.03448154 0.03612939 0.03208967 ... 0.0428976  0.0365332  0.02277026]
 [0.0341506  0.04498315 0.03893617 ... 0.04452143 0.02584082 0.01896746]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 26), x_tokens=26, y_tokens=53, max_supp_attn=0.0377, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 26)
DEBUG result.interpretability.attn_scores 1378 
 [[0.01735408 0.03565094 0.03664929 ... 0.01675507 0.00735536 0.02292335]
 [0.01789994 0.02216081 0.0216354  ... 0.01198982 0.00638255 0.01476939]
 [0.01819765 0.02512126 0.0281425  ... 0.01585669 0.0071989  0.01446311]
 ...
 [0.01831202 0.02100952 0.02117232 ... 0.01032103 0.00558682 0.01318544]
 [0.01837265 0.01721411 0.01729514 ... 0.0142927  0.00910525 0.01469244]
 [0.01846318 0.01874176 0.01862807 ... 0.01339281 0.00875992 0.01473073]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' in', ' the', ' provided', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' talk', ' about', ' Mary', ' and', ' Fred', ',', ' but', ' not', ' Julie', '.', ' Therefore', ',', ' we', ' cannot', ' determine', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 32), x_tokens=32, y_tokens=43, max_supp_attn=0.0465, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 32)
DEBUG result.interpretability.attn_scores 1376 
 [[0.02142012 0.02559611 0.02940515 ... 0.01002645 0.01855841 0.01205562]
 [0.02213655 0.02321234 0.02517387 ... 0.01231098 0.02850747 0.01788001]
 [0.02262619 0.02215114 0.02656595 ... 0.01836589 0.02731604 0.01969986]
 ...
 [0.02288149 0.02484425 0.02175391 ... 0.00816231 0.01866093 0.010978  ]
 [0.02326409 0.02552746 0.02368766 ... 0.0076673  0.01698412 0.01257522]
 [0.02330651 0.02288067 0.02179938 ... 0.00770448 0.01475591 0.01053417]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' mention', ' Mary', ' being', ' in', ' the', ' bedroom', '.', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Mary', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.0682, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02110858 0.02897946 0.03380408 ... 0.0394344  0.04005201 0.01385341]
 [0.02114726 0.02760505 0.02823226 ... 0.02418025 0.03045705 0.03784805]
 [0.0219983  0.03367165 0.03851366 ... 0.04227536 0.03098848 0.01169077]
 ...
 [0.02225288 0.02974178 0.02860413 ... 0.07461074 0.0369374  0.00886054]
 [0.02260121 0.02523043 0.02259236 ... 0.04764154 0.02409545 0.00996731]
 [0.0225872  0.024016   0.0216507  ... 0.0649253  0.03403204 0.00887978]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 44), x_tokens=44, y_tokens=53, max_supp_attn=0.0189, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 44)
DEBUG result.interpretability.attn_scores 2332 
 [[0.01751344 0.02808531 0.02739665 ... 0.02924811 0.08209317 0.01284179]
 [0.01763846 0.0234738  0.02548075 ... 0.02151462 0.03951183 0.02025358]
 [0.01829535 0.02780697 0.02978161 ... 0.01756069 0.06492487 0.01890295]
 ...
 [0.01850844 0.02429756 0.02756117 ... 0.02578656 0.0320122  0.00863936]
 [0.01876887 0.01769124 0.01922316 ... 0.02490732 0.01465193 0.01038808]
 [0.01870351 0.02075555 0.02223236 ... 0.03575742 0.02166174 0.0101029 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' Bill', ' is', ' in', ' the', ' office', ',', ' which', ' contrad', 'icts', ' the', ' idea', ' that', ' Bill', ' is', ' in', ' the', ' park', '.', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' park', ' in', ' the', ' provided', ' context', ' sentences', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01926128 0.02688111 0.0276279  ... 0.02478239 0.04062954 0.03231055]
 [0.01968107 0.01955259 0.02066511 ... 0.01239538 0.01560492 0.0207481 ]
 [0.02011214 0.02894937 0.03152268 ... 0.0266355  0.03133224 0.03336909]
 ...
 [0.02029366 0.03067318 0.02571652 ... 0.05165057 0.09211984 0.03020612]
 [0.02072756 0.02146655 0.01788086 ... 0.02908781 0.07259607 0.01889637]
 [0.02065603 0.02422059 0.01919448 ... 0.02096363 0.08358108 0.02694067]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Mary', ' went', ' back', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02631555 0.04472904 0.05445293 0.07018399 0.07529898 0.07184158
  0.0662924  0.07200292 0.05565022 0.06214496 0.04650137 0.0606174
  0.07012349 0.08969208 0.05878869 0.03066467 0.03129578 0.03345201
  0.0295283  0.03096632 0.02358006 0.03865751 0.03907604 0.01437592
  0.01858643 0.03366369]
 [0.02668429 0.05516149 0.05126385 0.06279193 0.0560604  0.05680297
  0.0547586  0.05252101 0.0465492  0.04821207 0.03962526 0.03727916
  0.04009174 0.09419119 0.09304468 0.0329931  0.02994677 0.02785646
  0.0255418  0.02590386 0.02021576 0.03788151 0.04392258 0.0106721
  0.0138376  0.03191856]
 [0.02877576 0.05633655 0.0357358  0.05371025 0.03848724 0.03623865
  0.03194515 0.02261325 0.02175455 0.03337791 0.02703631 0.01616496
  0.01820204 0.028456   0.03639681 0.02274625 0.0140464  0.01328109
  0.0157325  0.01554853 0.013352   0.0422981  0.04776779 0.00499806
  0.00656686 0.01707249]
 [0.02715136 0.02882625 0.02849777 0.02350703 0.01691505 0.02438051
  0.02758499 0.0224174  0.0245591  0.02297213 0.02596126 0.02465908
  0.02291164 0.01228519 0.0115659  0.02913366 0.0273566  0.03406257
  0.03336905 0.03830682 0.03751582 0.02984897 0.03993718 0.06490913
  0.06637469 0.04036918]
 [0.0273833  0.04032975 0.04445891 0.06528573 0.05909689 0.04744967
  0.03458359 0.02909192 0.03286531 0.0446181  0.03345134 0.02520292
  0.02503909 0.09527935 0.0984394  0.0352333  0.02663468 0.02024444
  0.02065299 0.02118751 0.01869527 0.03741499 0.05685853 0.00827897
  0.00975765 0.03669766]
 [0.02790905 0.02638688 0.02745285 0.04966763 0.04456022 0.04259391
  0.02571791 0.02309559 0.02795321 0.04144065 0.03017678 0.02854167
  0.02713088 0.10449873 0.12462043 0.03536879 0.03055197 0.02475976
  0.02353002 0.02278534 0.01811208 0.0319103  0.03387152 0.00652773
  0.0078624  0.02409425]
 [0.02831892 0.02970183 0.03531531 0.05205584 0.04815074 0.05306469
  0.03378554 0.0315238  0.03648395 0.04889325 0.03528741 0.04511767
  0.04133433 0.08335852 0.0782158  0.02999303 0.0279396  0.02479094
  0.02263601 0.02246978 0.01715391 0.02879409 0.03203065 0.00984532
  0.01100208 0.02303167]
 [0.02739887 0.04088815 0.04714089 0.04096909 0.04326415 0.04878477
  0.03921967 0.04066601 0.03958879 0.04284202 0.03593197 0.04919557
  0.04269506 0.05098946 0.04585698 0.04064004 0.03649165 0.03218006
  0.0285441  0.02904192 0.02455499 0.03305528 0.04744805 0.02818127
  0.02948628 0.03791025]
 [0.02846649 0.03961129 0.04724719 0.04660926 0.04253329 0.05605512
  0.04356796 0.04585544 0.04730682 0.04853525 0.03596843 0.05094006
  0.04640389 0.03855282 0.02538951 0.02816243 0.02773787 0.02653332
  0.02472919 0.02516055 0.01945566 0.03364281 0.03454979 0.0135399
  0.01735755 0.03003093]
 [0.02782104 0.05233116 0.05462696 0.02888862 0.02342118 0.03732194
  0.04519177 0.04232234 0.04457252 0.03024503 0.02891471 0.03764273
  0.03791302 0.01711026 0.01489785 0.0454195  0.03589787 0.03159375
  0.03132705 0.03295034 0.02948731 0.03277159 0.06264934 0.0353623
  0.03928616 0.03696268]
 [0.02829085 0.0666045  0.06590763 0.0272843  0.02252467 0.03211077
  0.04651297 0.03990277 0.04694179 0.02665246 0.02592009 0.03006322
  0.03025464 0.01448673 0.0142201  0.04958903 0.03639522 0.03014203
  0.03179989 0.03503753 0.02782754 0.03033748 0.06683645 0.02631252
  0.0288674  0.03345742]
 [0.02847642 0.03622036 0.04046429 0.02070861 0.01793691 0.02373624
  0.03600567 0.03073257 0.03667129 0.02162091 0.02129171 0.02442051
  0.02332063 0.01219135 0.01229568 0.04085692 0.03140203 0.02552855
  0.02868888 0.03011582 0.02678504 0.02868134 0.05291856 0.03792823
  0.04658717 0.03977289]
 [0.0286484  0.01541521 0.01655408 0.01124379 0.01038429 0.01363226
  0.01599681 0.01572497 0.01873925 0.013072   0.01420624 0.01439883
  0.01438622 0.00621942 0.00704552 0.02128928 0.02088214 0.02037764
  0.02595517 0.02929487 0.03007627 0.02106606 0.03393358 0.05700483
  0.08045895 0.04495201]
 [0.0285262  0.02271711 0.02402676 0.01614069 0.01523619 0.02011104
  0.02417025 0.02270949 0.02423953 0.01841141 0.02133405 0.02191103
  0.02149073 0.00930334 0.0099056  0.03546751 0.02587502 0.02419077
  0.02444841 0.02588884 0.02612355 0.02651091 0.03009225 0.0532858
  0.05980477 0.04229307]
 [0.02866985 0.02291038 0.02321886 0.01822699 0.01598272 0.0230112
  0.02581186 0.02629744 0.024015   0.02160837 0.02539903 0.02822378
  0.02861865 0.01021644 0.00923921 0.03433139 0.02857366 0.02915882
  0.02620085 0.02755579 0.03021445 0.02717796 0.0220361  0.04914944
  0.042505   0.02521808]
 [0.02811137 0.01749609 0.01509183 0.01301599 0.010466   0.01375674
  0.01881227 0.0183997  0.01705459 0.01433825 0.01940272 0.01682178
  0.02036515 0.00636374 0.00644418 0.03026663 0.02831642 0.03966004
  0.03236194 0.04223528 0.05342064 0.02387445 0.01726492 0.08420961
  0.05398374 0.02726073]
 [0.02883016 0.0170572  0.01610603 0.0139488  0.01198592 0.01657137
  0.01948078 0.01992285 0.01863869 0.01661582 0.0227655  0.02119773
  0.02144393 0.00703869 0.00671779 0.02401627 0.02129607 0.0314132
  0.02635782 0.03931461 0.0505629  0.02065029 0.01454795 0.06503248
  0.03716729 0.01986144]
 [0.02944917 0.01413245 0.01264293 0.01082274 0.00896286 0.01291957
  0.01559135 0.01540937 0.01558068 0.01294663 0.02067656 0.01670219
  0.01709652 0.00575409 0.00559296 0.02037686 0.01912428 0.02530873
  0.02498755 0.02983232 0.04164544 0.01977081 0.01169688 0.04799417
  0.03076738 0.0196508 ]
 [0.02911341 0.01552512 0.01406187 0.01060206 0.00917439 0.01268866
  0.01822979 0.0168497  0.01733697 0.01274604 0.0292217  0.01885772
  0.01820427 0.00576726 0.00624139 0.02564313 0.02503954 0.02846587
  0.03010302 0.03251306 0.0381372  0.02189396 0.01434569 0.05197947
  0.03223402 0.02247725]
 [0.02822911 0.02441295 0.0247441  0.0175663  0.01638229 0.02528324
  0.03958557 0.04182544 0.03290526 0.02344157 0.03479575 0.03168212
  0.03518712 0.00949539 0.00935713 0.02806607 0.02982846 0.03639818
  0.04079463 0.03737317 0.03887752 0.02668962 0.02191419 0.03642519
  0.0367773  0.04203805]
 [0.02934418 0.02038764 0.01919826 0.01580765 0.01294623 0.01727265
  0.02124402 0.02200332 0.0215438  0.01742795 0.0257613  0.02184673
  0.02239454 0.00849504 0.00776023 0.02309204 0.02253628 0.02476553
  0.02834278 0.02696825 0.02661143 0.02629633 0.01548501 0.02824593
  0.03085404 0.024143  ]
 [0.02958512 0.02094751 0.02291334 0.02139501 0.01768508 0.02386072
  0.0243443  0.02954629 0.02486904 0.02546561 0.02721274 0.03372348
  0.0313401  0.0125612  0.00884499 0.01839896 0.02063695 0.02339504
  0.02270376 0.02098666 0.02023499 0.02822391 0.01470089 0.01636069
  0.02260193 0.02179158]
 [0.02974859 0.02485774 0.0256024  0.024758   0.01812494 0.02667916
  0.02864215 0.03541503 0.02621759 0.02948584 0.03271151 0.0396961
  0.03764221 0.01388092 0.00956962 0.02033354 0.0211692  0.02448874
  0.02297821 0.02127817 0.02011715 0.02845734 0.01510209 0.01404037
  0.01639534 0.01646244]
 [0.02966627 0.02297455 0.02252356 0.02204351 0.01667553 0.02516827
  0.02663959 0.03027484 0.02698622 0.02692549 0.02970042 0.03493134
  0.03553148 0.01240646 0.00925387 0.02398792 0.02315607 0.02659453
  0.02528929 0.02338841 0.02157775 0.0275028  0.01259515 0.01689268
  0.01866642 0.01490046]
 [0.02948546 0.01824554 0.01700685 0.01379581 0.0105477  0.01587199
  0.01996337 0.02184216 0.02179863 0.01734854 0.02325245 0.02268503
  0.02513604 0.00759566 0.00660731 0.02720696 0.02627087 0.0276174
  0.02734055 0.02589334 0.02834371 0.02515664 0.01093659 0.0280139
  0.02852074 0.01643119]
 [0.02949985 0.01898244 0.0172478  0.01440099 0.010635   0.01520682
  0.02196099 0.02314819 0.02111678 0.01690557 0.02244793 0.0207891
  0.02499228 0.00747164 0.00638284 0.02728967 0.02865645 0.03086501
  0.02976326 0.02725776 0.03066909 0.02292322 0.0108568  0.02655107
  0.02804185 0.01730438]
 [0.02951811 0.01892122 0.01692889 0.01456751 0.01158971 0.01521727
  0.01933244 0.02146501 0.02057405 0.01778734 0.02368765 0.02177102
  0.02288377 0.00793258 0.00670334 0.02460363 0.02857842 0.02824143
  0.03051542 0.02683501 0.02990541 0.02312805 0.01197617 0.0235265
  0.02858851 0.01760378]
 [0.02961836 0.02120495 0.01924786 0.01583201 0.01184825 0.0166778
  0.02265027 0.02447213 0.02478088 0.01891986 0.02773968 0.0229272
  0.02503909 0.00825524 0.00697902 0.0267564  0.02736802 0.02964696
  0.03092879 0.02955383 0.03175059 0.02432923 0.01306617 0.02454864
  0.02357803 0.01615555]
 [0.02970249 0.01561954 0.01521624 0.01053572 0.00908597 0.01224774
  0.01794004 0.01836948 0.01961257 0.01326981 0.02895588 0.01785417
  0.01945912 0.0062496  0.00542219 0.0242363  0.03004668 0.02671503
  0.03331348 0.03000913 0.03114817 0.02180701 0.01215959 0.03086892
  0.02382969 0.01680747]
 [0.02827645 0.02097333 0.02055263 0.01355889 0.01311971 0.01640603
  0.02498017 0.02527679 0.02665425 0.01666318 0.02397699 0.0192297
  0.02290495 0.00825854 0.00799255 0.02358724 0.02901709 0.03044346
  0.04688163 0.04079973 0.04373128 0.02737221 0.02392684 0.03308436
  0.0466905  0.0876051 ]
 [0.02963211 0.01941175 0.01962111 0.01716421 0.01364463 0.01963972
  0.02100273 0.02494552 0.02473542 0.02060819 0.02440513 0.02419817
  0.02373074 0.01124642 0.00896621 0.01831232 0.02344154 0.02208036
  0.02926702 0.02649942 0.02504973 0.0246764  0.01341085 0.01756269
  0.01979641 0.02091589]
 [0.02857216 0.0263618  0.02658432 0.0404966  0.04175877 0.03602865
  0.02392598 0.02446765 0.02930315 0.04194353 0.03095308 0.03002597
  0.02971302 0.06522212 0.08088487 0.02429328 0.02787584 0.02500884
  0.02428365 0.02276681 0.01901503 0.03039302 0.02869692 0.00700891
  0.01000515 0.02629878]
 [0.02834041 0.02800894 0.02688197 0.04563719 0.08494794 0.03648477
  0.0221657  0.0229322  0.02821907 0.04882918 0.03655301 0.03020684
  0.02524414 0.06787363 0.08698687 0.03021963 0.03834974 0.0335086
  0.02868401 0.02483096 0.02214996 0.02772053 0.02836776 0.00587239
  0.00726602 0.02284478]
 [0.02809758 0.02529959 0.02384329 0.03831553 0.08772253 0.02540583
  0.0182021  0.02197422 0.02448059 0.04395225 0.03548266 0.03297051
  0.02486635 0.03104221 0.04056737 0.02526818 0.05835897 0.0521635
  0.04031448 0.03040633 0.03674252 0.02514986 0.0267153  0.0121814
  0.0142887  0.02688695]
 [0.0283433  0.03100967 0.02762057 0.03846174 0.0528437  0.02947764
  0.02416135 0.02398307 0.02970124 0.03973282 0.03329138 0.02750447
  0.02690911 0.03025861 0.03280322 0.022156   0.03990587 0.03506734
  0.03210456 0.02904392 0.02715974 0.04393538 0.03830578 0.0092291
  0.01160596 0.02511557]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Mary', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0213, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01960969 0.03192358 0.03284422 ... 0.01018542 0.0081411  0.00652648]
 [0.02020879 0.03029923 0.03058549 ... 0.01407166 0.01223686 0.0085854 ]
 [0.02053866 0.02921947 0.03315644 ... 0.02495913 0.01768988 0.01115906]
 ...
 [0.02058628 0.03034836 0.02463702 ... 0.00610532 0.00594394 0.00550086]
 [0.02095564 0.02429938 0.01927445 ... 0.00752825 0.00820048 0.00905866]
 [0.0210596  0.02367431 0.01873963 ... 0.00629778 0.00776528 0.00871237]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' in', ' the', ' office', ',', ' which', ' provides', ' a', ' definitive', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 38), x_tokens=38, y_tokens=26, max_supp_attn=0.0, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 38)
DEBUG result.interpretability.attn_scores 988 
 [[0.03643793 0.04612224 0.04802957 0.06024196 0.05369433 0.04726366
  0.03768484 0.04215728 0.04967199 0.04633978 0.03516056 0.03771655
  0.03645987 0.08202812 0.08508144 0.03559523 0.03114091 0.0323339
  0.02910232 0.03569233 0.02941721 0.03956531 0.05515162 0.02000336
  0.01985228 0.0517101  0.04981594 0.05451007 0.11472731 0.01461488
  0.01390649 0.01083471 0.01571041 0.05932644 0.05479541 0.02738674
  0.02516555 0.04020125]
 [0.03674906 0.03977467 0.04539765 0.04775327 0.0416168  0.04631692
  0.04646215 0.05798751 0.04329692 0.04235182 0.03699679 0.05085154
  0.05686492 0.04845971 0.0606044  0.03375527 0.03172123 0.03819065
  0.03638765 0.04069847 0.03449814 0.04029658 0.03890231 0.02685066
  0.03153918 0.04714151 0.04332742 0.04425285 0.07837037 0.04649158
  0.03958746 0.02836485 0.03923982 0.04263052 0.04096309 0.03181606
  0.03444795 0.04013195]
 [0.03800611 0.04450726 0.05207353 0.07110012 0.07120626 0.06552594
  0.03988094 0.04406305 0.05018634 0.05443999 0.03907281 0.04823571
  0.04476174 0.13760047 0.09892949 0.03887335 0.0292131  0.02946641
  0.02660313 0.03142379 0.02500637 0.04100068 0.04239223 0.01918783
  0.01846412 0.04140555 0.05153738 0.03879819 0.06770487 0.02819414
  0.02102612 0.01439938 0.01966335 0.05442429 0.03831613 0.02132335
  0.01992083 0.03072845]
 [0.03705395 0.03629393 0.04615799 0.03620072 0.03199014 0.03692468
  0.03318353 0.03685677 0.03803287 0.03169834 0.02884609 0.03513563
  0.03141043 0.03107958 0.02957976 0.03626737 0.02845227 0.02896921
  0.02785333 0.0330172  0.02787193 0.04081924 0.04692493 0.03395395
  0.03494482 0.04635606 0.0567282  0.03629179 0.04465541 0.08260261
  0.03325041 0.02379275 0.02535385 0.03229959 0.04845834 0.03601974
  0.04030532 0.04106522]
 [0.03822705 0.02978385 0.03876689 0.02674677 0.02340258 0.0340638
  0.03057713 0.03241454 0.03592549 0.02651075 0.02641363 0.03035314
  0.02808057 0.02025289 0.01975761 0.03059355 0.02454973 0.02604591
  0.02868883 0.03285262 0.02688023 0.03360328 0.0320995  0.02581972
  0.03016238 0.03462232 0.04804153 0.02253996 0.03175814 0.06293332
  0.0275254  0.02112274 0.02199457 0.02316413 0.03404191 0.03695732
  0.0455622  0.03713657]
 [0.03803072 0.04348009 0.05508478 0.03243303 0.02704065 0.04037727
  0.04098611 0.04265086 0.04909003 0.03025014 0.02553656 0.03404299
  0.03416633 0.02817343 0.02346867 0.0374134  0.02679973 0.02600634
  0.02658361 0.03146419 0.02487594 0.04206992 0.05904664 0.03189906
  0.02954213 0.03916689 0.06101856 0.02560907 0.03597001 0.09982875
  0.02495094 0.02002616 0.01875113 0.02513816 0.05796953 0.03627937
  0.04336094 0.03897384]
 [0.03814996 0.06055877 0.05988741 0.02932372 0.0243772  0.03596666
  0.04473799 0.04394239 0.0543776  0.02949092 0.02654541 0.03293871
  0.03586997 0.01994241 0.02078728 0.04907045 0.03906873 0.03849506
  0.03702556 0.04281104 0.03214636 0.0372525  0.07448274 0.03704678
  0.03776659 0.04430716 0.04737943 0.02708572 0.03056298 0.08738627
  0.0193688  0.01928402 0.01869321 0.02254039 0.06962396 0.04146597
  0.05373941 0.0403953 ]
 [0.03834157 0.04349414 0.04407251 0.02538886 0.02151069 0.02792127
  0.0337622  0.03146851 0.04044593 0.02364136 0.02282542 0.02327714
  0.02517663 0.01823311 0.02035761 0.04177447 0.03230968 0.02878758
  0.0313783  0.03515072 0.02769569 0.0347867  0.05145614 0.03812248
  0.03652383 0.03631813 0.03893112 0.02452015 0.02732342 0.06656065
  0.01808572 0.01489557 0.0174914  0.02198167 0.05061053 0.05146
  0.06197895 0.03747692]
 [0.03815832 0.03724085 0.03646083 0.02396408 0.01763853 0.02549995
  0.03141668 0.03830461 0.03485269 0.02388724 0.02471565 0.02917438
  0.03229414 0.01747861 0.01734162 0.02966982 0.03281961 0.03114875
  0.0367865  0.03679051 0.02956855 0.03892719 0.03662771 0.03102478
  0.03126427 0.03460311 0.0251066  0.03096805 0.0300419  0.043005
  0.02084361 0.02069957 0.02642534 0.02263222 0.03396931 0.03952898
  0.04778171 0.04312579]
 [0.03846966 0.02675451 0.03295495 0.02373004 0.01914822 0.02749862
  0.02710272 0.02782424 0.03344776 0.02341711 0.02379754 0.02488177
  0.02527457 0.01721487 0.01793174 0.03776487 0.03125914 0.03360733
  0.0339092  0.03770915 0.03408992 0.0356855  0.03667122 0.05018464
  0.05167545 0.04357695 0.03440239 0.03029205 0.03116278 0.06411505
  0.04015249 0.03092531 0.03735746 0.0227456  0.03651352 0.04461873
  0.05188172 0.03638965]
 [0.03858461 0.03229359 0.03618845 0.02866534 0.0225713  0.033288
  0.03365785 0.03382948 0.0311846  0.02845069 0.03009257 0.03439091
  0.03465829 0.0214681  0.01904581 0.04451713 0.03576276 0.03411772
  0.03449466 0.03598109 0.03513836 0.04206216 0.03240259 0.0699418
  0.05808234 0.03446379 0.03352843 0.03308672 0.03006851 0.06196466
  0.05381011 0.05433356 0.04488688 0.02482161 0.03116934 0.04740572
  0.04825145 0.03146306]
 [0.03838314 0.03032954 0.02840132 0.02370947 0.01737577 0.02474857
  0.03018581 0.02986712 0.02668767 0.02220127 0.02571802 0.02421386
  0.03130338 0.01408171 0.01451573 0.05190923 0.04056964 0.04345382
  0.04147751 0.04278411 0.04573433 0.03779682 0.0252922  0.10169818
  0.07858893 0.034471   0.02899971 0.03845452 0.02075227 0.03719893
  0.03779004 0.06179262 0.04187511 0.01769716 0.0258475  0.0629655
  0.05935811 0.03543636]
 [0.03907327 0.02952305 0.02837458 0.02460703 0.01952564 0.02706658
  0.02745135 0.02918707 0.02648193 0.02483019 0.02925654 0.03065917
  0.03101868 0.01568752 0.01523437 0.03975653 0.03754887 0.03370575
  0.04027365 0.03530632 0.03936201 0.03753291 0.02607541 0.05405802
  0.08062914 0.0305005  0.03233666 0.03365951 0.02200619 0.03105662
  0.05055817 0.08024535 0.04952036 0.01988289 0.02537954 0.06125209
  0.05153055 0.03370382]
 [0.03938795 0.02627303 0.02511602 0.02030954 0.01668303 0.02264846
  0.02877708 0.02861946 0.02587352 0.02077468 0.0365345  0.02703681
  0.03164047 0.01240746 0.01318036 0.04883989 0.04474023 0.04068779
  0.04696255 0.04094234 0.04786308 0.03514473 0.0237783  0.05700537
  0.08083589 0.03994994 0.02219339 0.04036169 0.01841462 0.02191645
  0.04133511 0.06571279 0.06817014 0.01686903 0.02236848 0.0585671
  0.04790485 0.03879673]
 [0.0379135  0.05363742 0.03395424 0.02611668 0.02438197 0.02932823
  0.13105501 0.0566521  0.04503398 0.02917209 0.11886672 0.04640301
  0.07117511 0.01574427 0.02074773 0.08181787 0.08510952 0.08867318
  0.08943047 0.08485156 0.08134364 0.04099518 0.03767648 0.10276409
  0.10730181 0.08449969 0.02595408 0.04656916 0.02224178 0.01580297
  0.02550676 0.03529764 0.0368362  0.02348108 0.04456384 0.08581682
  0.0859405  0.08880805]
 [0.03927891 0.02751686 0.02874054 0.02749259 0.02131482 0.03126303
  0.02676121 0.02997132 0.02947107 0.02817781 0.03152915 0.03598391
  0.0321461  0.01976714 0.01708914 0.03372373 0.0311725  0.03040093
  0.03663891 0.03430838 0.03789837 0.03646172 0.02411439 0.03125279
  0.03008513 0.03240528 0.02534495 0.03526833 0.02759061 0.02766486
  0.08818413 0.07491928 0.11265159 0.02480374 0.02405382 0.02632243
  0.02711294 0.03340813]
 [0.03901242 0.0292482  0.03545319 0.03704942 0.02831624 0.04025892
  0.02961426 0.03597381 0.03762432 0.04149262 0.0325704  0.04442484
  0.03799498 0.02899637 0.02120097 0.02681451 0.02833765 0.02995041
  0.03036959 0.03042286 0.02848228 0.03861897 0.0260289  0.02562248
  0.02378956 0.03279921 0.03265447 0.0359242  0.03261515 0.03182978
  0.10704783 0.06386333 0.06602715 0.03325938 0.02858939 0.02486454
  0.02713118 0.03411501]
 [0.03923682 0.03352539 0.03707578 0.0394772  0.02860289 0.04338654
  0.03276138 0.03893529 0.03406793 0.04215458 0.0342943  0.0465182
  0.04084882 0.02788799 0.01952339 0.02557161 0.0237185  0.02535998
  0.02733983 0.02807389 0.02587261 0.03814159 0.02914072 0.02538887
  0.02167892 0.0282018  0.03922244 0.02960722 0.02907181 0.03211227
  0.12156083 0.07061784 0.05374842 0.02830765 0.03198018 0.03005319
  0.02733641 0.03602158]
 [0.03933313 0.04046279 0.04098105 0.0418304  0.03111586 0.05323901
  0.03841529 0.04383271 0.03921735 0.05392393 0.04147719 0.05556538
  0.04930556 0.03378208 0.02088918 0.02784714 0.02673114 0.02883324
  0.03019884 0.03057098 0.02780721 0.03917914 0.03410254 0.02743817
  0.02268767 0.02867499 0.04147356 0.02955057 0.02884231 0.02975856
  0.04619735 0.05503597 0.03897918 0.02467736 0.03440042 0.03054568
  0.02680738 0.03694098]
 [0.03927792 0.04074566 0.03609988 0.03495854 0.02861245 0.04315737
  0.0381473  0.04305943 0.03461168 0.05122746 0.05395492 0.04885127
  0.04887281 0.02846221 0.01816672 0.02991089 0.03196402 0.03307462
  0.03446295 0.03225116 0.03162462 0.03817588 0.0343381  0.03372734
  0.03048045 0.02870622 0.03726264 0.03234021 0.02638436 0.02665808
  0.04009995 0.0571056  0.04659548 0.02221369 0.03606566 0.04432612
  0.03210379 0.0420955 ]
 [0.03953671 0.04448519 0.04081394 0.03785439 0.02929085 0.04324754
  0.04312531 0.04970083 0.03792118 0.04865528 0.0480617  0.04626104
  0.05077006 0.02868422 0.02108766 0.03349693 0.0324568  0.03507456
  0.03506549 0.03380717 0.03169133 0.03764578 0.03252862 0.03331748
  0.02813126 0.0277262  0.03522339 0.03319499 0.02417588 0.02299459
  0.03481462 0.05028665 0.04419186 0.02120798 0.03316517 0.0327114
  0.02547871 0.03406418]
 [0.04011303 0.03119019 0.03028794 0.02995895 0.02337631 0.03280899
  0.03510927 0.03838138 0.03214865 0.0327845  0.04161545 0.03765022
  0.04107885 0.02292367 0.01755379 0.03039379 0.02957682 0.02849434
  0.03374819 0.03138339 0.03164354 0.03414858 0.0241609  0.02733465
  0.0247665  0.02497352 0.02568924 0.03572782 0.02291919 0.02215104
  0.04533275 0.07177456 0.08189683 0.027139   0.02433862 0.02545285
  0.02491168 0.03051747]
 [0.03847607 0.03827404 0.0354699  0.05943184 0.05326196 0.04882841
  0.03351081 0.03596833 0.04654471 0.05745527 0.03766216 0.04064656
  0.03918161 0.08790552 0.10295843 0.03093301 0.03526276 0.03585282
  0.03474836 0.03548436 0.03400628 0.03838351 0.03875077 0.01749384
  0.01717138 0.03672887 0.04049366 0.04790355 0.05804993 0.01134383
  0.01343732 0.01167566 0.01836018 0.09594142 0.03780014 0.02095038
  0.02198375 0.03508985]
 [0.03816505 0.04823475 0.03920972 0.08024288 0.15720843 0.06076408
  0.03710142 0.03642351 0.04475475 0.07542001 0.05486655 0.04991482
  0.03869193 0.12416308 0.16081451 0.04531319 0.06348488 0.05957105
  0.05072658 0.04387481 0.05774316 0.03718781 0.05112305 0.01976136
  0.01740766 0.04034387 0.05598665 0.05087195 0.06084879 0.00962009
  0.00953462 0.00915387 0.01287964 0.10513295 0.04607049 0.02197863
  0.017414   0.03510217]
 [0.0380917  0.04268163 0.03152118 0.05566671 0.10344482 0.03638744
  0.03104434 0.03254891 0.03304216 0.05960326 0.05131723 0.04420026
  0.03433487 0.04828778 0.0721125  0.0443504  0.08975665 0.08744136
  0.07156292 0.0560251  0.09840653 0.03640512 0.04186109 0.03470232
  0.03219122 0.03766805 0.03705077 0.06765261 0.04134268 0.01287697
  0.01460057 0.01984895 0.02234208 0.0945314  0.03911804 0.03213752
  0.02656719 0.03276285]
 [0.03851144 0.04356837 0.03342619 0.05574644 0.06329232 0.04222003
  0.03748799 0.03937951 0.04600684 0.05164896 0.04227217 0.04067215
  0.03661931 0.04928765 0.05204006 0.03402638 0.05647313 0.05225721
  0.04818104 0.04632252 0.05333233 0.04811313 0.04487089 0.0243999
  0.02443707 0.03867929 0.03029741 0.07495905 0.04239869 0.00931806
  0.01149242 0.01399125 0.02035837 0.09315064 0.04982761 0.02779372
  0.02602295 0.0360493 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '10', ' and', ' ', '11', '.', ' The', ' previous', ' information', ' about', ' Julie', ' was', ' in', ' sentence', ' ', '5', ',', ' but', ' it', "'s", ' not', ' relevant', ' to', ' the', ' current', ' question', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 44), x_tokens=44, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 44)
DEBUG result.interpretability.attn_scores 2112 
 [[0.01914256 0.01911358 0.01976302 ... 0.00946711 0.01265054 0.01142219]
 [0.01951737 0.01273317 0.01366784 ... 0.01552613 0.01848592 0.01329521]
 [0.02005272 0.01785007 0.01994578 ... 0.01349606 0.01695709 0.02311063]
 ...
 [0.02054006 0.02149901 0.01791918 ... 0.00872279 0.01497214 0.01364667]
 [0.02083647 0.02255557 0.02073508 ... 0.00750365 0.01429642 0.01651435]
 [0.02090418 0.01917307 0.01792565 ... 0.00713699 0.01258539 0.01204425]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' but', ' context', ' sentence', ' ', '14', ' provides', ' alternative', ' locations', ' for', ' Fred', ' (', 'school', ' or', ' cinema', ').', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0208, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01925443 0.02490392 0.02810359 ... 0.03471918 0.02455533 0.01394568]
 [0.01965351 0.02304656 0.02425339 ... 0.01321982 0.02306094 0.01568147]
 [0.02008021 0.02858722 0.03245281 ... 0.03070049 0.0208278  0.01035986]
 ...
 [0.02027881 0.02648494 0.02657602 ... 0.0719552  0.01927658 0.01029161]
 [0.02070152 0.02112484 0.02018496 ... 0.06169208 0.02063428 0.013284  ]
 [0.02057636 0.02330719 0.02224664 ... 0.07678021 0.01834431 0.01166541]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 26), x_tokens=26, y_tokens=30, max_supp_attn=0.1, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 26)
DEBUG result.interpretability.attn_scores 780 
 [[0.03126648 0.05164257 0.05574529 0.0840124  0.07846308 0.05877497
  0.04076888 0.03600784 0.041744   0.05714355 0.03947858 0.02943236
  0.03151704 0.13076714 0.1275009  0.03631242 0.03043622 0.02190664
  0.02530927 0.02496348 0.0247523  0.0455674  0.06931181 0.01431578
  0.0112471  0.0443809 ]
 [0.03229167 0.03244291 0.03284603 0.06254282 0.05556952 0.05004454
  0.02864899 0.02599157 0.03354514 0.0494183  0.03417671 0.03158399
  0.03130549 0.13345663 0.15335856 0.03507248 0.03310441 0.02569259
  0.02792937 0.02584983 0.02321353 0.0390717  0.04112368 0.00988902
  0.0090772  0.02900953]
 [0.03278819 0.03679158 0.0438066  0.06488171 0.06113371 0.06454571
  0.03926782 0.03814915 0.04467067 0.05796773 0.03937861 0.05159319
  0.05081538 0.10582948 0.09364144 0.03008305 0.03048552 0.02662153
  0.02713751 0.02619423 0.02226138 0.03540708 0.03872151 0.01362525
  0.01258052 0.02798287]
 [0.03165649 0.04913321 0.05830032 0.05294103 0.05176313 0.06196249
  0.04669664 0.04958826 0.0496924  0.05163014 0.03967731 0.05706589
  0.05138457 0.06366897 0.0558617  0.04280554 0.03918686 0.03502408
  0.03298786 0.03381991 0.0306256  0.03957851 0.05684647 0.03568479
  0.0377079  0.04437187]
 [0.03290953 0.04905485 0.06014597 0.06025738 0.05096975 0.07336727
  0.05516767 0.05753621 0.06080348 0.06083212 0.04140566 0.05984232
  0.05921598 0.04769816 0.03099881 0.03054868 0.03125862 0.03016601
  0.0299623  0.03215984 0.02574549 0.04037244 0.04445318 0.02066766
  0.02186198 0.0358256 ]
 [0.03232375 0.06106015 0.06609429 0.0373851  0.02751832 0.04764034
  0.05463126 0.0514491  0.05468845 0.03755111 0.03292532 0.04417187
  0.04615607 0.02291023 0.01904368 0.04779497 0.03894754 0.03387614
  0.03436296 0.03708225 0.03387866 0.0384773  0.07354506 0.04299065
  0.04711342 0.04357946]
 [0.03294653 0.07695626 0.07688665 0.03404035 0.02500266 0.0400339
  0.05374745 0.04543114 0.05539002 0.03267081 0.02881101 0.03350174
  0.03448011 0.01905316 0.01758584 0.04997165 0.03881846 0.03087515
  0.0350707  0.03995596 0.03294202 0.03485686 0.07823675 0.03572689
  0.03566207 0.04071112]
 [0.03309306 0.04204891 0.04871279 0.02627858 0.02023975 0.02967716
  0.04165815 0.03562875 0.04398676 0.02703757 0.0245618  0.02697589
  0.02687033 0.0161274  0.01559378 0.04383087 0.03540831 0.02693799
  0.03279718 0.03490441 0.0321047  0.03336763 0.06483754 0.05071756
  0.05590388 0.04826461]
 [0.03329688 0.01848296 0.02033783 0.01512994 0.0125283  0.01798162
  0.01968854 0.01992879 0.02420965 0.01686893 0.01705222 0.01701662
  0.01760587 0.00893731 0.00946418 0.02464771 0.02398399 0.02273772
  0.02852326 0.03206844 0.03386487 0.02490483 0.04267317 0.06536898
  0.08733439 0.05508745]
 [0.03325347 0.02675503 0.0285066  0.02067591 0.01626364 0.02572151
  0.02828738 0.0250746  0.02776886 0.02204393 0.02383192 0.02410814
  0.02304844 0.0117106  0.01222767 0.04085418 0.02683605 0.02557667
  0.02727995 0.02990829 0.03061319 0.03074445 0.03429833 0.06019365
  0.07585664 0.04838061]
 [0.03333498 0.02935244 0.0297087  0.02484187 0.01932927 0.02946126
  0.03386774 0.03367827 0.03155443 0.02741485 0.02919401 0.03506209
  0.03461611 0.01451892 0.01251737 0.04375825 0.03033316 0.03237444
  0.030204   0.0314168  0.03382486 0.03294402 0.02634262 0.04937741
  0.04548864 0.02862463]
 [0.03278569 0.02510678 0.01998497 0.0182042  0.01302302 0.01872805
  0.0269207  0.02520267 0.02177424 0.01799752 0.02335738 0.02198213
  0.02445631 0.00903346 0.00884364 0.04499145 0.02710653 0.04077058
  0.03426987 0.04039412 0.05059952 0.03135369 0.02180418 0.08468325
  0.06573837 0.03675661]
 [0.03373337 0.02191329 0.01901141 0.01751905 0.0139506  0.01931934
  0.02423322 0.0228129  0.02164581 0.01853024 0.02797875 0.02450562
  0.02424853 0.00917494 0.00877223 0.03453149 0.02542474 0.04703048
  0.0356674  0.05515189 0.03997061 0.02620157 0.01689441 0.05834823
  0.0454794  0.02632875]
 [0.03369417 0.02032051 0.01771424 0.01416296 0.012227   0.01608299
  0.02359412 0.021951   0.02030368 0.01593627 0.03825007 0.02293607
  0.02310259 0.00758157 0.00814943 0.03655646 0.02842231 0.03738694
  0.03502864 0.03875352 0.03862427 0.02763787 0.01771958 0.05943034
  0.04565891 0.03198257]
 [0.0327548  0.03026549 0.02808244 0.02100634 0.02010686 0.02489913
  0.03592595 0.03616024 0.03397058 0.0232891  0.03395028 0.02978713
  0.03321202 0.01098466 0.01141334 0.0326001  0.03667685 0.04272191
  0.0434374  0.04657675 0.0453987  0.03192962 0.02748346 0.05206132
  0.0493348  0.05339719]
 [0.03424923 0.02430026 0.02299798 0.01958583 0.01592024 0.02133622
  0.02441676 0.02677023 0.02325925 0.02087972 0.0283196  0.02589711
  0.02515646 0.01043384 0.0097024  0.02548764 0.02433699 0.02820946
  0.02920408 0.02759658 0.02904683 0.03000098 0.01818718 0.0305281
  0.03585346 0.02875569]
 [0.03434914 0.02693553 0.02927539 0.02825789 0.02224754 0.03262058
  0.030622   0.03807743 0.02940317 0.03239878 0.03102835 0.04256882
  0.03774162 0.01668989 0.01165231 0.02225118 0.02414423 0.02787575
  0.02674718 0.02632632 0.02477782 0.03230012 0.01780865 0.0188842
  0.02579722 0.02422269]
 [0.0344811  0.03199299 0.03267509 0.03225864 0.02340275 0.03555097
  0.0371091  0.04609326 0.03001965 0.03670912 0.03938223 0.04819394
  0.04528592 0.0181672  0.01245706 0.02478545 0.02424592 0.02962132
  0.02626937 0.02667839 0.02449675 0.03240655 0.01869669 0.0166424
  0.01934297 0.01944715]
 [0.03433032 0.03041517 0.0293019  0.03013193 0.02341722 0.0326911
  0.03395076 0.03996645 0.03028615 0.0348535  0.03614233 0.042896
  0.04286686 0.01747353 0.01285073 0.029977   0.02577671 0.03204273
  0.02865505 0.02929852 0.02714355 0.03245662 0.01649885 0.01950495
  0.02069849 0.01761979]
 [0.034203   0.02459874 0.02221913 0.01883752 0.01466372 0.02074494
  0.02601395 0.02847739 0.0247266  0.02144158 0.02752468 0.02736351
  0.02999333 0.01026283 0.00903064 0.03571054 0.02773823 0.03306793
  0.03042272 0.0298216  0.03325653 0.03036443 0.01528336 0.03001803
  0.03144635 0.01990136]
 [0.03418374 0.0261343  0.02240653 0.01941414 0.01445057 0.01947014
  0.03013366 0.030579   0.02472981 0.02074208 0.0299251  0.02514421
  0.03081311 0.00965089 0.00886181 0.03938268 0.02920398 0.03545245
  0.03259249 0.03061478 0.03746899 0.02741892 0.01496115 0.03099848
  0.0319347  0.0223185 ]
 [0.03428004 0.02458642 0.02117244 0.01922139 0.01579393 0.01980213
  0.02553217 0.0282443  0.02430438 0.02236939 0.02961195 0.02708429
  0.02885998 0.01036654 0.0094561  0.03258962 0.03282811 0.03423272
  0.03660114 0.03092497 0.03603162 0.02779094 0.0154353  0.02398916
  0.02515444 0.02078867]
 [0.03439562 0.02736696 0.023775   0.0205188  0.01580445 0.02125377
  0.03002988 0.03134741 0.02900984 0.02327291 0.03419477 0.02760331
  0.03125637 0.01062271 0.00990276 0.03338613 0.03118432 0.03536381
  0.03687482 0.03458183 0.03803491 0.02912842 0.01612425 0.02511758
  0.0244483  0.02121877]
 [0.03449323 0.02131721 0.01869877 0.01405768 0.01218622 0.01560454
  0.02565125 0.02393094 0.02283381 0.01602533 0.04164052 0.02095066
  0.02508217 0.00785079 0.00785064 0.03189142 0.03324822 0.03207001
  0.03785175 0.03226305 0.03634268 0.02739264 0.01469984 0.03412569
  0.02647432 0.02271922]
 [0.0327825  0.03053492 0.02594792 0.01738299 0.01576761 0.02177779
  0.04894713 0.04056581 0.03475884 0.02118575 0.05186607 0.02905525
  0.03987105 0.00995652 0.01078902 0.03075704 0.05818849 0.05181515
  0.06156944 0.05514304 0.05245762 0.0331405  0.02738326 0.04764869
  0.04288846 0.06296183]
 [0.03458385 0.02491748 0.02378415 0.02186156 0.01680572 0.02507923
  0.02708457 0.03054058 0.02938872 0.02428816 0.02845209 0.02945798
  0.02897458 0.01320645 0.01100604 0.01966227 0.02668883 0.02589033
  0.02988042 0.02632632 0.02903718 0.02948864 0.01592712 0.01899488
  0.02301358 0.02535105]
 [0.03311685 0.03185211 0.03104061 0.05103946 0.05244994 0.04460688
  0.0288653  0.02838134 0.03445541 0.05095331 0.03355161 0.03491623
  0.03434789 0.08833397 0.10216006 0.02362212 0.03086454 0.02640574
  0.02800003 0.02643071 0.02437916 0.03736733 0.03620736 0.01104661
  0.01122532 0.03127001]
 [0.03290392 0.03413958 0.03115579 0.0573791  0.10646954 0.04420437
  0.02651321 0.02686116 0.03336534 0.05807298 0.03864271 0.03521516
  0.02875168 0.08692534 0.10723585 0.02856788 0.04267541 0.03586438
  0.03298954 0.02879077 0.02938204 0.03436147 0.03640383 0.00961894
  0.00803944 0.02732228]
 [0.03265765 0.03072422 0.02745442 0.04676336 0.10443938 0.03066336
  0.02230391 0.0264603  0.02907567 0.0525709  0.03858731 0.03999802
  0.02868872 0.03905343 0.04905074 0.02509412 0.06686039 0.05565565
  0.04647417 0.0342392  0.04557285 0.02962839 0.03245413 0.01633623
  0.015184   0.03137546]
 [0.0328607  0.03885718 0.03221071 0.04941001 0.06809256 0.03635382
  0.0297218  0.02911389 0.03463522 0.04790434 0.03710105 0.0340904
  0.0302754  0.03955342 0.04302107 0.02247551 0.04558602 0.03673355
  0.03590013 0.03176414 0.03415179 0.05433902 0.04963735 0.01346525
  0.01245381 0.03004373]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' was', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 32), x_tokens=32, y_tokens=58, max_supp_attn=0.1034, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 32)
DEBUG result.interpretability.attn_scores 1856 
 [[0.01586014 0.02734702 0.02922921 ... 0.00659358 0.00464407 0.03900794]
 [0.0162967  0.02686794 0.02663263 ... 0.00833321 0.00686031 0.04570384]
 [0.01657954 0.02514002 0.02822213 ... 0.01364308 0.009061   0.03454534]
 ...
 [0.01662914 0.02729588 0.02330184 ... 0.00451472 0.00374315 0.0673007 ]
 [0.01684217 0.02119614 0.01666074 ... 0.00671129 0.00655079 0.05242144]
 [0.01690781 0.02481974 0.01850862 ... 0.00480765 0.00452087 0.05763288]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' previous', ' context', ' sentences', ',', ' Julie', ' was', ' in', ' the', ' kitchen', ' (', 'sentence', ' ', '5', '),', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '7', ',', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' which', ' means', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 38), x_tokens=38, y_tokens=49, max_supp_attn=0.0612, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 38)
DEBUG result.interpretability.attn_scores 1862 
 [[0.01901716 0.02718843 0.03095684 ... 0.00874883 0.00792999 0.02064087]
 [0.01922614 0.02037944 0.02594374 ... 0.02504512 0.03141151 0.0330715 ]
 [0.01982697 0.02833524 0.03700533 ... 0.00650107 0.00576929 0.01952224]
 ...
 [0.01994774 0.02848514 0.02658452 ... 0.00556944 0.00510221 0.02509548]
 [0.02035229 0.02086449 0.018961   ... 0.00879838 0.00750781 0.02304292]
 [0.02020712 0.02251951 0.02037667 ... 0.00760208 0.00672775 0.0196774 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Fred', ' was', ' in', ' the', ' school', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Fred', ' is', ' no', ' longer', ' in', ' the', ' school', ',', ' but', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 44), x_tokens=44, y_tokens=51, max_supp_attn=0.1176, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 44)
DEBUG result.interpretability.attn_scores 2244 
 [[0.01823744 0.02764054 0.0252899  ... 0.00791604 0.00704783 0.01044539]
 [0.0186235  0.01912097 0.01857808 ... 0.02448868 0.01696382 0.01516112]
 [0.01909743 0.02832252 0.02944438 ... 0.0106872  0.00973365 0.01436654]
 ...
 [0.01926658 0.02855641 0.02750413 ... 0.00527797 0.00466051 0.00511333]
 [0.01963384 0.02097818 0.01923147 ... 0.00648803 0.00557222 0.00506472]
 [0.01936181 0.02542786 0.02209206 ... 0.00543915 0.00530748 0.00457052]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Mary', ' went', ' to', ' the', ' school', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '14', ',', ' Mary', ' went', ' to', ' the', ' park', ',', ' which', ' means', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', ',', ' but', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 50), x_tokens=50, y_tokens=51, max_supp_attn=0.0784, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 50)
DEBUG result.interpretability.attn_scores 2550 
 [[0.01820169 0.0220534  0.02504674 ... 0.02433261 0.02857417 0.02937539]
 [0.01874817 0.01558395 0.01947477 ... 0.01139111 0.01671745 0.01811164]
 [0.01900697 0.02406603 0.03101435 ... 0.02417929 0.02721124 0.02973556]
 ...
 [0.01917459 0.02324439 0.02385057 ... 0.02688488 0.05625964 0.02926305]
 [0.01959718 0.01572651 0.01531068 ... 0.01390037 0.05118288 0.01895705]
 [0.01933091 0.01973752 0.01786444 ... 0.01292581 0.05383938 0.03007952]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' went', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02809828 0.0470335  0.05761209 0.07443722 0.08318438 0.07518259
  0.06303025 0.07045761 0.05765634 0.06743141 0.05146471 0.06274078
  0.07071131 0.09979263 0.0681676  0.03314873 0.03374092 0.03355019
  0.02984563 0.03046824 0.02588325 0.03991845 0.04473327 0.02094712
  0.01282073 0.02338435]
 [0.02847595 0.06086999 0.05539505 0.07539083 0.06849    0.06295179
  0.05007498 0.04762933 0.04536132 0.05230458 0.04274603 0.03433147
  0.03607923 0.10744492 0.10698121 0.03388179 0.02717232 0.02307092
  0.02290579 0.02212078 0.02052524 0.04167994 0.04609566 0.01580331
  0.00804674 0.02042794]
 [0.03065374 0.06314731 0.03931296 0.0533328  0.03918702 0.03659431
  0.03500731 0.02455447 0.02404539 0.03491259 0.03064435 0.0175762
  0.01931369 0.0265258  0.03502274 0.02438349 0.01476127 0.01366987
  0.0167985  0.01618084 0.01565296 0.04505722 0.05430886 0.00956042
  0.00479267 0.01147492]
 [0.02870754 0.04226996 0.03889368 0.02425003 0.0168535  0.02676295
  0.03143187 0.02623363 0.02989646 0.02437663 0.02780479 0.02532649
  0.02420379 0.01205023 0.01185737 0.03447638 0.02880942 0.02984658
  0.03440234 0.03589515 0.03466701 0.03488022 0.04981184 0.05782076
  0.06910899 0.05967104]
 [0.02907644 0.04536308 0.0502387  0.06862211 0.06200789 0.04962997
  0.03849949 0.03276725 0.03689128 0.04717808 0.03780377 0.02725375
  0.02716314 0.09442639 0.09883653 0.03886301 0.02865548 0.02139066
  0.02176507 0.02210554 0.02212071 0.04066178 0.06683357 0.01732685
  0.00752581 0.02658898]
 [0.02963434 0.02885953 0.03044834 0.05266542 0.04667243 0.04506769
  0.0285602  0.02550019 0.03125029 0.04427285 0.03345759 0.03116283
  0.02944985 0.1078166  0.13041987 0.03879048 0.03264827 0.02589455
  0.02446663 0.0234691  0.02107047 0.03407162 0.03893653 0.01203917
  0.00592306 0.01692544]
 [0.03005287 0.03300462 0.03990575 0.05567726 0.05131358 0.05756644
  0.03812763 0.03548494 0.04114264 0.0525482  0.03948014 0.04991721
  0.04515243 0.08483861 0.0799666  0.03290791 0.02997098 0.02596131
  0.02382001 0.02352955 0.02013989 0.03095082 0.03672563 0.01700719
  0.00867905 0.0167387 ]
 [0.02902732 0.04279593 0.04998943 0.04277268 0.0446706  0.05092221
  0.04230027 0.04507944 0.04371804 0.04626263 0.03973541 0.05336259
  0.0464891  0.05169449 0.04643476 0.04235919 0.03783417 0.03361372
  0.02954825 0.03018754 0.02808731 0.03534379 0.05115668 0.04229091
  0.02842997 0.03299187]
 [0.03022892 0.04441764 0.05411785 0.04923216 0.0444025  0.06093052
  0.04971977 0.0526198  0.05289145 0.05275852 0.04092755 0.05647935
  0.05178181 0.039783   0.02601041 0.03066428 0.02923078 0.02767434
  0.02585029 0.02654262 0.02232979 0.03543904 0.03946545 0.0219861
  0.01383841 0.02297899]
 [0.0295599  0.05843331 0.06129393 0.03104176 0.02446403 0.03977941
  0.05000061 0.04770561 0.04819193 0.03267921 0.03219045 0.04101934
  0.04136948 0.0177796  0.01467032 0.04632066 0.03564475 0.03103486
  0.030426   0.031846   0.03075618 0.03442653 0.06700653 0.0439061
  0.03504927 0.03767767]
 [0.03012203 0.04292475 0.04923632 0.02566533 0.02124681 0.02949102
  0.04991958 0.03775899 0.04364802 0.02602595 0.02614684 0.02910118
  0.02860538 0.01368026 0.01290593 0.0457966  0.03335591 0.02823672
  0.02960783 0.03144387 0.02916103 0.02983017 0.05376741 0.04951494
  0.04073263 0.03832261]
 [0.03063925 0.01489588 0.01734255 0.01184598 0.01010805 0.01494369
  0.01770402 0.01729884 0.02229785 0.01428098 0.01410306 0.01544271
  0.01463348 0.00640308 0.00630728 0.01945244 0.01851373 0.0176308
  0.02085804 0.021736   0.0227901  0.01826952 0.03004402 0.05634381
  0.06868364 0.06363174]
 [0.03021494 0.02429003 0.02558266 0.01662695 0.01444058 0.02110358
  0.02606705 0.0234918  0.0245418  0.01845875 0.02209935 0.02295816
  0.02204842 0.00908135 0.0091984  0.03486972 0.02866988 0.02904509
  0.0291502  0.03111743 0.0283633  0.02934085 0.02834699 0.04464007
  0.06678362 0.04742639]
 [0.03040051 0.02360964 0.02437593 0.01789986 0.01558329 0.02255457
  0.02740354 0.02788356 0.02600768 0.02131101 0.02556261 0.02910451
  0.02960942 0.00992177 0.00868607 0.03475791 0.03329419 0.03465918
  0.02943269 0.03083253 0.03154813 0.02966048 0.02097103 0.04673906
  0.05631682 0.02849555]
 [0.02996854 0.01929611 0.01699639 0.01420194 0.01172262 0.01561813
  0.02140156 0.02109317 0.01969133 0.01615273 0.02193224 0.02017072
  0.02318134 0.00700542 0.00688033 0.03246698 0.03097243 0.04306574
  0.03376495 0.0451909  0.04932923 0.02684661 0.0166288  0.04425092
  0.09508    0.0414152 ]
 [0.03073011 0.01713357 0.01610411 0.01321382 0.01167377 0.01572935
  0.02038143 0.02100674 0.01888525 0.01615273 0.02365335 0.02146465
  0.02237491 0.0065361  0.00641603 0.02854937 0.02550986 0.03859745
  0.03345936 0.05250807 0.04534153 0.02182497 0.0139435  0.02767983
  0.07051862 0.03450401]
 [0.03065089 0.01536076 0.01358319 0.01070396 0.00924536 0.01271513
  0.01733881 0.0168603  0.01689651 0.01310073 0.02343097 0.01655436
  0.01886813 0.00529488 0.00553696 0.02907172 0.02895067 0.03569776
  0.04035708 0.05024301 0.0410151  0.02281825 0.01477761 0.03452824
  0.05210901 0.05657162]
 [0.02989338 0.01972466 0.01742799 0.01306711 0.01158083 0.0164321
  0.02145595 0.0206915  0.0213984  0.01554294 0.02300727 0.01873642
  0.02080625 0.00648129 0.00671473 0.02744992 0.02948379 0.03142691
  0.04035913 0.0374101  0.0400144  0.02579159 0.02201758 0.06513795
  0.05151317 0.06545359]
 [0.03103973 0.02002769 0.01849731 0.01437598 0.01156414 0.01650996
  0.02116956 0.02147324 0.02064368 0.01633733 0.02308228 0.02074484
  0.02157586 0.00726177 0.00692556 0.02384251 0.02385665 0.0267098
  0.03340235 0.03323689 0.03118496 0.02596128 0.01581099 0.02767382
  0.03050927 0.03778061]
 [0.03120481 0.02417856 0.02666872 0.02174735 0.01667596 0.02615829
  0.02855243 0.03520656 0.02721523 0.02627107 0.02861534 0.03902023
  0.03547165 0.01225063 0.00876015 0.02231933 0.02387448 0.02752181
  0.02651849 0.02547659 0.02465384 0.02936555 0.01623275 0.02055422
  0.02041158 0.02008407]
 [0.03140045 0.02861925 0.02944596 0.02533883 0.01894947 0.02951327
  0.03496846 0.04396466 0.0293378  0.03000247 0.03666427 0.04507544
  0.04320449 0.01376361 0.00946996 0.0245836  0.02380865 0.02898157
  0.02552364 0.02535201 0.02386093 0.02969735 0.01776684 0.01805481
  0.01632065 0.01555404]
 [0.03128261 0.02666561 0.0263252  0.02369052 0.01863489 0.02728369
  0.03098786 0.0367764  0.02933469 0.02959695 0.03409577 0.03967418
  0.04013836 0.01277304 0.00953715 0.02839857 0.02607521 0.03153696
  0.02796583 0.0271403  0.02632361 0.02913218 0.01558101 0.02201089
  0.01744642 0.01479888]
 [0.03110901 0.01922097 0.01808156 0.01358059 0.01064426 0.01576171
  0.02077994 0.02356553 0.02183101 0.01677009 0.0234836  0.02170348
  0.02528271 0.00696488 0.006295   0.02975834 0.02789024 0.03049635
  0.02865201 0.02794666 0.03239025 0.02627773 0.01359445 0.03575052
  0.03193384 0.01983448]
 [0.03130531 0.01887582 0.01675064 0.01339217 0.009946   0.01438959
  0.02152477 0.02159019 0.02060478 0.01552629 0.02255331 0.01923736
  0.023703   0.00649443 0.00606177 0.0290161  0.02597407 0.03251849
  0.02858781 0.02884606 0.03531742 0.02262069 0.01252847 0.03397832
  0.03383913 0.02239417]
 [0.03141083 0.01908308 0.01698229 0.01430263 0.01121978 0.01584361
  0.02178452 0.02354264 0.02156335 0.01797455 0.02432574 0.02248849
  0.02521643 0.00745988 0.00663698 0.0252513  0.03040434 0.02981057
  0.03457028 0.02881978 0.03221558 0.02392179 0.01205283 0.02621715
  0.02097798 0.01896545]
 [0.03142604 0.02065358 0.01854752 0.01446228 0.01111373 0.01674252
  0.0245907  0.02487098 0.02431927 0.01765679 0.02605473 0.02228359
  0.02558834 0.00761061 0.00685083 0.02708095 0.02870519 0.03065131
  0.03271976 0.02977227 0.03318734 0.02464166 0.01330304 0.028833
  0.0234901  0.02263284]
 [0.03151456 0.01646474 0.01522417 0.01065793 0.00900228 0.01280715
  0.02070334 0.01960849 0.02095491 0.0135456  0.02777189 0.01760148
  0.02194286 0.00600684 0.00515233 0.02582296 0.03456616 0.02926073
  0.04297287 0.03630569 0.03487577 0.02353036 0.01168748 0.02687975
  0.02089405 0.03056972]
 [0.03058045 0.02095002 0.01977099 0.01226597 0.01038211 0.01530063
  0.02377815 0.02447439 0.02780034 0.01606951 0.02512707 0.01975426
  0.02554293 0.00687239 0.00595668 0.0258436  0.02887113 0.02736442
  0.03932473 0.03571327 0.0422651  0.02616078 0.02102493 0.05114214
  0.03570839 0.05096214]
 [0.03142662 0.02149664 0.02052585 0.0160847  0.01232794 0.01876986
  0.02229736 0.02478327 0.02589097 0.01949222 0.02441784 0.0239321
  0.02470459 0.00906251 0.00725354 0.0198925  0.02487079 0.023448
  0.03088208 0.02678338 0.02850291 0.02584715 0.01482336 0.02203944
  0.01753606 0.0236804 ]
 [0.03023926 0.02917165 0.02935524 0.04332499 0.0459003  0.03959235
  0.02678414 0.02749968 0.03240805 0.04577086 0.0345142  0.03534599
  0.03338132 0.06690315 0.08164938 0.02610477 0.03050376 0.02730697
  0.02614715 0.02404206 0.02323722 0.03274142 0.03423146 0.01339781
  0.00805443 0.01935943]
 [0.03002258 0.03108401 0.03002466 0.04890566 0.0953741  0.03965807
  0.02540325 0.0265654  0.03188831 0.05346819 0.04062886 0.03523755
  0.02724292 0.0705189  0.08800575 0.03273532 0.04235324 0.03731693
  0.0307619  0.02620936 0.0272394  0.02973545 0.03352332 0.01123233
  0.00550188 0.01643991]
 [0.02986177 0.02595797 0.02483837 0.03643545 0.07761501 0.02548285
  0.02024379 0.02423414 0.02701761 0.04335136 0.0360024  0.03416515
  0.02575282 0.02732455 0.03539013 0.02673348 0.058886   0.05530417
  0.04197494 0.03142967 0.04424464 0.0264005  0.0296417  0.01949796
  0.01226487 0.02270389]
 [0.03004101 0.03412016 0.03110455 0.04078779 0.05380276 0.032211
  0.0280074  0.02772721 0.03477805 0.04241624 0.03647215 0.0310331
  0.02941057 0.03217638 0.03504169 0.02440614 0.04214136 0.03770533
  0.03317842 0.03009871 0.03170542 0.04715422 0.04262639 0.01521508
  0.00915911 0.01955938]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' The', ' last', ' known', ' location', ' of', ' Julie', ' is', ' the', ' park', ',', ' according', ' to', ' sentence', ' ', '5', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.0789, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02456123 0.03127002 0.03173167 ... 0.03244608 0.01005633 0.0081974 ]
 [0.02516298 0.03154598 0.02937323 ... 0.04427192 0.01924492 0.0122833 ]
 [0.02570696 0.02896173 0.03116648 ... 0.05071764 0.02157205 0.01385101]
 ...
 [0.02567917 0.02715754 0.02428473 ... 0.01331108 0.00763086 0.00709526]
 [0.02601528 0.02234569 0.01933045 ... 0.00993944 0.01066419 0.01253169]
 [0.02616356 0.02203686 0.01900357 ... 0.0082012  0.0096538  0.01142456]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Julie', ' and', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03015692 0.03893512 0.03728876 ... 0.02246427 0.02148101 0.04956833]
 [0.03076181 0.03148309 0.02711802 ... 0.02337991 0.02809939 0.03247646]
 [0.03149109 0.03838918 0.0373952  ... 0.01885303 0.01624579 0.03828911]
 ...
 [0.03192369 0.03202491 0.0267585  ... 0.02804095 0.0249152  0.03791565]
 [0.03239553 0.03753108 0.03257592 ... 0.02274518 0.02087884 0.039876  ]
 [0.03262663 0.03150922 0.0283669  ... 0.02102283 0.0206106  0.03563929]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Mary', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' her', ' moving', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0645, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03003008 0.03827082 0.04551922 ... 0.01518512 0.02076341 0.01256667]
 [0.03057719 0.03421121 0.03824984 ... 0.02493361 0.03685021 0.02602834]
 [0.03129653 0.04111415 0.05251294 ... 0.0225454  0.03002471 0.01571436]
 ...
 [0.03153642 0.04684873 0.04271372 ... 0.00968936 0.01254035 0.00931714]
 [0.03213768 0.03584053 0.02980891 ... 0.01192976 0.00990611 0.01209058]
 [0.03193839 0.03898964 0.03200751 ... 0.01202478 0.0126838  0.01399671]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Mary', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03225663 0.05152523 0.0453885  ... 0.04788571 0.02538541 0.01972665]
 [0.03293304 0.05459982 0.04867075 ... 0.0384089  0.03091119 0.02812056]
 [0.03375001 0.05398702 0.05347062 ... 0.04091259 0.02267708 0.01585915]
 ...
 [0.03394797 0.04833391 0.04691057 ... 0.03519473 0.01996439 0.0173584 ]
 [0.03417641 0.03658734 0.03233293 ... 0.03867902 0.03028266 0.0274521 ]
 [0.03409177 0.0445245  0.03744211 ... 0.03926692 0.02435969 0.02543957]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '1', ')', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Julie', ' is', ' definitely', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 26), x_tokens=26, y_tokens=51, max_supp_attn=0.0392, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 26)
DEBUG result.interpretability.attn_scores 1326 
 [[0.01799032 0.02998351 0.03389082 ... 0.01041004 0.01375321 0.02277045]
 [0.01812174 0.04064819 0.03792371 ... 0.00778588 0.0119743  0.02333879]
 [0.01955799 0.04253055 0.02498159 ... 0.00296185 0.00548007 0.01295873]
 ...
 [0.01924139 0.01875265 0.01982786 ... 0.00346649 0.00578659 0.01611399]
 [0.01918156 0.0160903  0.01672694 ... 0.01005821 0.01189033 0.01706484]
 [0.01952819 0.01590539 0.01657077 ... 0.00815326 0.01055631 0.01572531]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '4', ')', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' bedroom', ',', ' which', ' means', ' Julie', ' is', ' definitely', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' mention', ' of', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0217, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02018948 0.02861249 0.03149459 ... 0.00764774 0.00567294 0.01097546]
 [0.0208129  0.02682198 0.0284991  ... 0.00954924 0.00652122 0.0158282 ]
 [0.02119857 0.02576501 0.03066057 ... 0.01733899 0.00700418 0.01887989]
 ...
 [0.02116973 0.02840745 0.02648764 ... 0.00529077 0.00646414 0.00775707]
 [0.02137471 0.0231861  0.02076273 ... 0.00608729 0.01085795 0.00795578]
 [0.02143916 0.0239976  0.02081934 ... 0.00472753 0.00783808 0.00710361]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '7', ')', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' bedroom', ',', ' but', ' the', ' context', ' sentence', ' (', '8', ')', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' cinema', '.', ' These', ' two', ' sentences', ' contradict', ' each', ' other', ',', ' and', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' in', ' the', ' cinema', ' based', ' on', ' the', ' provided', ' information', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(63, 38), x_tokens=38, y_tokens=63, max_supp_attn=0.0317, attn_on_target=0.0159)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (63, 38)
DEBUG result.interpretability.attn_scores 2394 
 [[0.01440483 0.02225007 0.02300012 ... 0.02754582 0.02168594 0.01138842]
 [0.01477102 0.02184287 0.02073923 ... 0.01561868 0.02315038 0.01748197]
 [0.01519666 0.02279623 0.02347696 ... 0.02646027 0.01729399 0.01019039]
 ...
 [0.01533605 0.01957644 0.01807691 ... 0.06758749 0.01571477 0.00887564]
 [0.0158825  0.01562931 0.01318512 ... 0.03940201 0.01299953 0.01142119]
 [0.01576511 0.01665215 0.01439884 ... 0.04597122 0.0135589  0.01086723]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', ' and', ' Julie', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03109915 0.03913783 0.03894786 ... 0.04952229 0.09264644 0.01884938]
 [0.03187448 0.02654122 0.0287703  ... 0.03145875 0.078393   0.03234262]
 [0.03266454 0.03503729 0.03770843 ... 0.02443649 0.08383115 0.0293894 ]
 ...
 [0.03297428 0.03097953 0.02931743 ... 0.04598075 0.01571706 0.01625533]
 [0.03347887 0.0326439  0.033931   ... 0.04823584 0.01575066 0.01555168]
 [0.03371971 0.02765997 0.02988068 ... 0.05138354 0.01694638 0.01424731]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '13', ')', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' the', ' context', ' sentence', ' (', '14', ')', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', '.', ' This', ' means', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' is', ' now', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(60, 50), x_tokens=50, y_tokens=60, max_supp_attn=0.0167, attn_on_target=0.0167)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (60, 50)
DEBUG result.interpretability.attn_scores 3000 
 [[0.01526195 0.02442796 0.02569916 ... 0.01904076 0.02902955 0.03143007]
 [0.01565522 0.01702577 0.01833624 ... 0.01530058 0.01231379 0.01804819]
 [0.01595567 0.02602343 0.03000178 ... 0.02254967 0.02488924 0.02494259]
 ...
 [0.01615311 0.02611455 0.02414982 ... 0.04226734 0.0847669  0.02724906]
 [0.01658614 0.02133263 0.01867596 ... 0.02228014 0.06119241 0.02018289]
 [0.01656723 0.02132965 0.01776767 ... 0.01555885 0.08201146 0.0244773 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' moved', ' to', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '1', ' only', ' provides', ' information', ' about', ' Fred', "'s", ' possible', ' locations', ',', ' which', ' does', ' not', ' affect', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 26), x_tokens=26, y_tokens=51, max_supp_attn=0.2157, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 26)
DEBUG result.interpretability.attn_scores 1326 
 [[0.0181558  0.03701766 0.03872333 ... 0.00463814 0.00600328 0.0202978 ]
 [0.01872598 0.02300555 0.02306606 ... 0.00395806 0.00488483 0.01327241]
 [0.0190255  0.02589652 0.02916699 ... 0.0062066  0.00709135 0.01290446]
 ...
 [0.0191486  0.02315709 0.02331251 ... 0.00348709 0.00422966 0.0118087 ]
 [0.01915115 0.0165283  0.01712201 ... 0.00845052 0.00873923 0.01402832]
 [0.01920908 0.02192424 0.02143681 ... 0.0062484  0.00646551 0.01210853]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '2', ' from', ' the', ' previous', ' part', ' mentioned', ' that', ' Mary', ' moved', ' to', ' the', ' school', ',', ' but', ' it', ' is', ' not', ' mentioned', ' in', ' the', ' current', ' context', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 32), x_tokens=32, y_tokens=48, max_supp_attn=0.0417, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 32)
DEBUG result.interpretability.attn_scores 1536 
 [[0.01919073 0.02227684 0.02267262 ... 0.00880201 0.01078793 0.01257165]
 [0.01986123 0.02008456 0.01996093 ... 0.01096155 0.01465081 0.0179387 ]
 [0.02024044 0.01852797 0.0208113  ... 0.01660832 0.02011323 0.02032663]
 ...
 [0.02072126 0.02147938 0.01921588 ... 0.00720784 0.00963438 0.01051572]
 [0.02090712 0.02230592 0.02013126 ... 0.00618618 0.01113411 0.01338344]
 [0.02100031 0.01865354 0.01671678 ... 0.00646314 0.01074304 0.01306192]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '5', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' left', ' the', ' office', ' or', ' moved', ' to', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 38), x_tokens=38, y_tokens=37, max_supp_attn=0.1081, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 38)
DEBUG result.interpretability.attn_scores 1406 
 [[0.02514887 0.03613841 0.03803387 ... 0.0408974  0.05856487 0.02750531]
 [0.02551346 0.02779269 0.02719917 ... 0.02356086 0.03475671 0.03877972]
 [0.0261168  0.04224594 0.04867202 ... 0.04558326 0.04242118 0.02061531]
 ...
 [0.02629869 0.04192394 0.03961785 ... 0.09491529 0.05865195 0.01940186]
 [0.02688965 0.02852292 0.02574344 ... 0.05772567 0.02982282 0.02196211]
 [0.0266631  0.03659238 0.03256738 ... 0.08004022 0.0682382  0.01910183]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' park', ',', ' but', ' we', ' are', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 44), x_tokens=44, y_tokens=51, max_supp_attn=0.0, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 44)
DEBUG result.interpretability.attn_scores 2244 
 [[0.01788595 0.0253927  0.02356701 ... 0.03929164 0.03658831 0.00910825]
 [0.01812719 0.01968849 0.01875439 ... 0.04624263 0.05193376 0.0296713 ]
 [0.01861552 0.0262437  0.02701348 ... 0.02737447 0.05470692 0.01349318]
 ...
 [0.01887227 0.02591428 0.02554047 ... 0.02965741 0.0150392  0.00716957]
 [0.0192727  0.02048002 0.0193715  ... 0.02278217 0.0107128  0.00850499]
 [0.01930675 0.01987608 0.01970514 ... 0.0320036  0.01067473 0.00815351]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' kitchen', ',', ' but', ' sentence', ' ', '14', ' provides', ' alternative', ' locations', ' for', ' Fred', ' (', 'cin', 'ema', ' or', ' bedroom', ').', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' left', ' the', ' kitchen', ' or', ' moved', ' to', ' one', ' of', ' the', ' alternative', ' locations', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0577, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01740541 0.02888675 0.02966071 ... 0.01275502 0.03591622 0.02799367]
 [0.01801722 0.02372104 0.02509035 ... 0.0158436  0.01922095 0.01948836]
 [0.01827184 0.02995134 0.03277601 ... 0.01583061 0.04090246 0.02951677]
 ...
 [0.01861973 0.02895724 0.02530572 ... 0.01068766 0.10061615 0.02495692]
 [0.01929692 0.02271971 0.01819665 ... 0.00960038 0.07265861 0.01512566]
 [0.01899618 0.02705399 0.02141201 ... 0.01049057 0.07756628 0.02308006]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '2', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' kitchen', ',', ' which', ' contrad', 'icts', ' the', ' ambiguity', ' in', ' sentence', ' ', '1', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1818, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02793854 0.04886739 0.0613154  0.07677941 0.08163331 0.0766843
  0.05898672 0.07016668 0.05607535 0.06136442 0.04711509 0.05765901
  0.0610343  0.09557702 0.06558871 0.03446832 0.03213416 0.03391932
  0.02915411 0.03497082 0.02935644 0.0389875  0.04985328 0.01734647
  0.02064453 0.02620566]
 [0.027739   0.08270896 0.06177294 0.04871058 0.03727528 0.0489964
  0.15506724 0.09800993 0.0548399  0.04392497 0.07795624 0.0486601
  0.07762598 0.02141024 0.0198978  0.04736678 0.04505126 0.06175381
  0.04689509 0.0555874  0.04854548 0.04064954 0.04292254 0.0411318
  0.03057219 0.03521502]
 [0.0304716  0.06165454 0.03826213 0.05689967 0.03922158 0.03733096
  0.03138913 0.02355673 0.02286085 0.03409484 0.02668506 0.01704079
  0.01805788 0.03202471 0.0427498  0.02577477 0.01637641 0.01534003
  0.01830217 0.0207596  0.01937175 0.04452157 0.05767741 0.00483713
  0.0051129  0.01156084]
 [0.02861641 0.03593677 0.03630965 0.02312777 0.01829657 0.02521012
  0.02619843 0.02632599 0.02805089 0.02380483 0.02478603 0.02501078
  0.0227779  0.01332063 0.01317459 0.03646983 0.03381339 0.03046989
  0.03653801 0.03637455 0.03315004 0.03200408 0.05710261 0.06496467
  0.06812642 0.05234595]
 [0.02895777 0.04450358 0.04872938 0.06769873 0.06412265 0.04829505
  0.03354622 0.03038773 0.0345557  0.04611722 0.03508455 0.02681169
  0.02613097 0.10370415 0.10983491 0.04159764 0.03082912 0.02331864
  0.02370433 0.02732472 0.02703978 0.03890368 0.06692459 0.00725751
  0.00890129 0.02570801]
 [0.02959426 0.02949984 0.02983871 0.05155014 0.04922732 0.04155634
  0.02462569 0.02401415 0.02963156 0.04263819 0.03151929 0.0302591
  0.02807424 0.1136812  0.13520493 0.04099571 0.03422892 0.02779317
  0.02665143 0.02858994 0.02637163 0.03337904 0.03963704 0.00625858
  0.0066537  0.0166664 ]
 [0.03004387 0.03283339 0.03710322 0.05356149 0.05216823 0.051601
  0.03195805 0.03172179 0.03699721 0.04922636 0.03604481 0.04649226
  0.04098127 0.0892894  0.08547454 0.03413504 0.03074074 0.02716309
  0.02481537 0.02717011 0.02446576 0.0303417  0.03621083 0.00911744
  0.01111754 0.0168178 ]
 [0.02897846 0.0409099  0.04617719 0.04142575 0.0463544  0.04622271
  0.03466767 0.03897537 0.03904062 0.04188268 0.03528191 0.04865135
  0.04101172 0.05278886 0.04879457 0.04256701 0.0376861  0.03305551
  0.03061321 0.03326496 0.03197294 0.03498904 0.05211795 0.02517624
  0.03388699 0.03844438]
 [0.02976366 0.03874534 0.04620735 0.02717443 0.02451229 0.03175284
  0.04236742 0.03625668 0.03998079 0.0276252  0.02707599 0.03286076
  0.03051602 0.0174864  0.01672573 0.04757388 0.03730015 0.0313288
  0.03377061 0.0359906  0.03340863 0.02928594 0.05232636 0.02679376
  0.04374705 0.0454399 ]
 [0.03030495 0.01664332 0.02038648 0.01378933 0.01304921 0.01787382
  0.01872914 0.01955793 0.02481612 0.01651542 0.015487   0.01884544
  0.01773757 0.0085007  0.00850882 0.02432656 0.02264252 0.02070369
  0.02460564 0.02522653 0.02427027 0.0199537  0.03004737 0.03013431
  0.06469313 0.07117243]
 [0.02991928 0.02830799 0.03215222 0.02110515 0.0187414  0.02756972
  0.02814337 0.0289986  0.02724881 0.02280511 0.02489357 0.02998781
  0.02594713 0.01157927 0.01146348 0.03966567 0.03027425 0.03158208
  0.03244529 0.03282561 0.03116786 0.03091497 0.03147706 0.03593185
  0.05174235 0.05276919]
 [0.03056197 0.03585558 0.0396804  0.03282115 0.02561543 0.04051777
  0.03633972 0.04113999 0.03525936 0.03762957 0.03668752 0.05509611
  0.04327417 0.01807474 0.0140946  0.0332226  0.03058144 0.03403573
  0.03071071 0.03248933 0.02977424 0.03186735 0.025903   0.02665356
  0.02433379 0.02550285]
 [0.03094979 0.02619467 0.02842561 0.02190236 0.01907174 0.02599409
  0.0289013  0.02890307 0.02551831 0.02415616 0.02928119 0.03009095
  0.02875884 0.01154636 0.01105777 0.03368205 0.02895496 0.02852011
  0.02886048 0.02973019 0.02893369 0.03004344 0.02196239 0.02799589
  0.03227745 0.02371869]
 [0.03034759 0.02019759 0.01898631 0.01443021 0.01258053 0.01674782
  0.02123626 0.02166185 0.01998599 0.01629263 0.02455577 0.02016753
  0.02219931 0.00746316 0.00842732 0.03771339 0.03269545 0.03291821
  0.03319015 0.03139611 0.0324691  0.02835661 0.01756248 0.04017052
  0.05359268 0.04086941]
 [0.0301118  0.02068394 0.01867009 0.01465979 0.01196635 0.01636832
  0.02706338 0.02662045 0.02064264 0.01611268 0.02765924 0.01989311
  0.02601029 0.00716003 0.0075335  0.03957674 0.03590708 0.04878479
  0.04757192 0.04897268 0.05059653 0.02610348 0.01616863 0.05222855
  0.05514982 0.03861385]
 [0.03069386 0.01897893 0.01686925 0.01344847 0.01220129 0.01599459
  0.02121698 0.02147753 0.01900909 0.01558997 0.02870554 0.02116768
  0.02212826 0.00702204 0.0071025  0.0312894  0.0342863  0.03342121
  0.03893866 0.03080988 0.03376044 0.02501734 0.01238666 0.04576262
  0.04877545 0.04200063]
 [0.03043807 0.01672372 0.0148823  0.01092724 0.01067478 0.0130643
  0.01974935 0.01848799 0.0178515  0.01306352 0.03106762 0.01812033
  0.01994701 0.00595794 0.00642361 0.03303765 0.03906633 0.03774022
  0.04233188 0.03531676 0.04133237 0.024461   0.01336501 0.05326132
  0.03429716 0.05888984]
 [0.0304845  0.01964659 0.01983331 0.01354425 0.01262704 0.01845315
  0.0217994  0.02402539 0.02508642 0.01582276 0.02167749 0.02023254
  0.02186322 0.00779341 0.007233   0.02012719 0.02434385 0.02242107
  0.02859462 0.02692853 0.02870561 0.02570046 0.02101988 0.06806993
  0.05223456 0.04254431]
 [0.03103445 0.01903569 0.01848053 0.01716554 0.01346184 0.01816589
  0.01956999 0.02175963 0.02173118 0.01902473 0.02415597 0.02215971
  0.02223202 0.00962196 0.00871744 0.01865651 0.02229114 0.02550836
  0.02718484 0.02598541 0.02822017 0.02580122 0.01569339 0.02656125
  0.02344965 0.03716519]
 [0.03108079 0.02234559 0.02725809 0.02735894 0.02007947 0.03000523
  0.02411656 0.03026972 0.03044393 0.03090429 0.02629158 0.03668448
  0.03167093 0.0162537  0.01073243 0.01803335 0.02189841 0.02367723
  0.02389253 0.02309549 0.02373946 0.02907884 0.01815121 0.02336577
  0.02247283 0.02843284]
 [0.03138249 0.02476161 0.0264266  0.02679976 0.01906578 0.02820382
  0.02622639 0.03480574 0.02999587 0.03172264 0.02773262 0.03858665
  0.0355789  0.0151538  0.01029896 0.01837063 0.02135994 0.02305781
  0.02362611 0.02225931 0.02193092 0.02738834 0.01642151 0.0241813
  0.01903879 0.02232854]
 [0.03175186 0.02294231 0.0229223  0.02422078 0.01791256 0.02932405
  0.02404038 0.02762521 0.03208188 0.02806222 0.02394342 0.03112549
  0.03150288 0.01313703 0.00898791 0.01678086 0.02003138 0.02385052
  0.02589694 0.02675395 0.02305646 0.02419977 0.01488695 0.02113851
  0.02174364 0.01998609]
 [0.03120498 0.02174336 0.02125674 0.01584999 0.01230027 0.01891912
  0.01940607 0.0240917  0.02620434 0.01861913 0.02108413 0.02376559
  0.02467944 0.00954575 0.00748721 0.01998316 0.02176834 0.02098584
  0.026669   0.02681386 0.027823   0.02732041 0.01792422 0.04497207
  0.03746687 0.02455313]
 [0.03071121 0.02745194 0.02574676 0.01606408 0.01327461 0.02111636
  0.02272221 0.0292054  0.02959924 0.01996732 0.02429261 0.02691421
  0.03044722 0.01043664 0.00736869 0.02302452 0.02619663 0.02285031
  0.02944207 0.02657937 0.02843176 0.02753485 0.02068801 0.07516399
  0.04933298 0.026419  ]
 [0.03144517 0.027005   0.02650673 0.02040089 0.01598057 0.02549258
  0.02537397 0.03116209 0.03252112 0.02750524 0.03160152 0.03525614
  0.03597816 0.01228424 0.00825867 0.0220133  0.02814599 0.031415
  0.0312906  0.02830649 0.02700431 0.02930689 0.01730959 0.03774892
  0.02459205 0.01375791]
 [0.03154997 0.0233656  0.02438881 0.01437387 0.01246008 0.01836861
  0.02110512 0.0255359  0.02846809 0.01756799 0.02022002 0.02276293
  0.0240095  0.00943201 0.0073215  0.02319532 0.02248999 0.01902274
  0.02462094 0.02427118 0.02410983 0.02930707 0.02208452 0.03736857
  0.03294739 0.01753525]
 [0.03115789 0.03179683 0.03659227 0.01819375 0.01493945 0.02202907
  0.03239487 0.02950323 0.04087248 0.01957458 0.01965828 0.0220497
  0.02347829 0.01081944 0.00920668 0.03442031 0.02838939 0.02334353
  0.02723076 0.03018565 0.02781764 0.02700278 0.03985873 0.02206925
  0.03023115 0.02323007]
 [0.03097465 0.02957867 0.02634388 0.03640159 0.04060258 0.04300036
  0.02519462 0.02518187 0.03182186 0.04678132 0.04211386 0.03838037
  0.03596124 0.0540002  0.03886497 0.02469338 0.02305449 0.02304271
  0.02118691 0.02267611 0.02059917 0.03702844 0.02736189 0.00885178
  0.00994627 0.01399276]
 [0.03121228 0.01835385 0.01978075 0.01334143 0.01103137 0.01657392
  0.01756333 0.0203188  0.02437982 0.01615552 0.02066789 0.0193674
  0.02091132 0.0087022  0.00679433 0.02203454 0.02145437 0.01931867
  0.02436415 0.02452048 0.0251038  0.02364116 0.01771647 0.0565158
  0.04198179 0.03013527]
 [0.03030012 0.02814719 0.02820331 0.04278638 0.04399786 0.03753464
  0.02225068 0.02471995 0.03110351 0.04348367 0.03180395 0.03046164
  0.03253599 0.07452244 0.08946074 0.02919556 0.02859787 0.02764343
  0.02661118 0.02721392 0.02567791 0.03081265 0.03216071 0.00689972
  0.0084708  0.01820624]
 [0.03005075 0.02978913 0.02923211 0.04809928 0.09501167 0.03658734
  0.02070205 0.02317348 0.02990773 0.05017467 0.03771738 0.03089795
  0.02612533 0.07177413 0.09240659 0.03478713 0.04214825 0.04070798
  0.03240221 0.03075899 0.03202615 0.02828362 0.03252975 0.00624955
  0.00652799 0.01645134]
 [0.02996092 0.02442896 0.02330573 0.03607481 0.06977071 0.02423688
  0.01607835 0.02017944 0.02438129 0.04214832 0.03369665 0.02851133
  0.02447304 0.02728388 0.03985859 0.02704141 0.05567189 0.06292954
  0.04302854 0.03441229 0.05206811 0.024728   0.02548816 0.01519382
  0.01490213 0.02443786]
 [0.03026708 0.0303622  0.02795343 0.03931298 0.05077171 0.03020891
  0.02127001 0.02217996 0.02903661 0.03964187 0.03345627 0.02602907
  0.02633962 0.03265232 0.03494515 0.02417977 0.03958949 0.03837696
  0.03485955 0.03243908 0.0376988  0.04308549 0.03705975 0.01062755
  0.01103665 0.01888325]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', ',', ' implying', ' that', ' she', ' has', ' arrived', ' at', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 32), x_tokens=32, y_tokens=27, max_supp_attn=0.037, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 32)
DEBUG result.interpretability.attn_scores 864 
 [[0.03459199 0.05234468 0.0507935  0.0801513  0.07110042 0.05850502
  0.03947601 0.04397176 0.05623903 0.05979932 0.03708557 0.0387249
  0.03953058 0.1188506  0.11860902 0.03249392 0.03021611 0.02402746
  0.02750513 0.02764735 0.02457418 0.04131368 0.0680554  0.01238269
  0.02451379 0.04283479 0.05464334 0.05317835 0.1202025  0.07033692
  0.01306794 0.0200562 ]
 [0.03540127 0.05445592 0.05361387 0.10016231 0.098963   0.09561118
  0.0497996  0.05371343 0.06891157 0.09021448 0.05335279 0.06874341
  0.06472879 0.17644311 0.13917077 0.03465383 0.03166916 0.02921514
  0.02923636 0.02924565 0.02605428 0.04460486 0.05452235 0.01257822
  0.02181395 0.0352989  0.05981645 0.04499275 0.09159511 0.08208463
  0.01742894 0.02861512]
 [0.03606084 0.05105014 0.05959911 0.08359949 0.07284968 0.07297549
  0.04514999 0.05041831 0.06248811 0.06816506 0.04008829 0.05755092
  0.04998315 0.1259179  0.09042273 0.03170744 0.0295495  0.02387688
  0.02606213 0.02576706 0.02276116 0.04109862 0.05139623 0.01335538
  0.02472296 0.03331809 0.0539536  0.03800478 0.06351434 0.08185896
  0.02513366 0.0376216 ]
 [0.03481369 0.05175389 0.0538042  0.04395892 0.03722135 0.04286382
  0.04093258 0.04598557 0.0446287  0.03913458 0.03185612 0.04267287
  0.0397186  0.03301458 0.03209754 0.03944005 0.03522956 0.02895737
  0.03043204 0.0319108  0.02827307 0.04077054 0.05882137 0.02807809
  0.05012939 0.04676208 0.05176939 0.04255545 0.04601764 0.09674782
  0.0424836  0.07180969]
 [0.03601341 0.04368428 0.04658889 0.0312133  0.02421608 0.03274896
  0.03720833 0.03615205 0.04270774 0.02892261 0.02457041 0.02983717
  0.02766788 0.02053348 0.02150767 0.03370311 0.03034632 0.02281948
  0.02954005 0.02985796 0.02608015 0.03422794 0.05114795 0.02255405
  0.042852   0.04040204 0.04617478 0.02875549 0.03377866 0.08716867
  0.03587215 0.07152861]
 [0.03686266 0.02158323 0.0236405  0.01679719 0.01378637 0.01838549
  0.01906113 0.01784638 0.02181759 0.01754672 0.01882601 0.01748572
  0.01763443 0.010741   0.01257197 0.02133009 0.02062648 0.01861358
  0.02297428 0.0256586  0.02205379 0.02387415 0.02805555 0.02456629
  0.03638942 0.03001993 0.02094151 0.02072719 0.02283875 0.03679531
  0.02721527 0.03033079]
 [0.03580764 0.0430344  0.04488849 0.03157483 0.02374536 0.0337529
  0.03684085 0.0359118  0.03519564 0.03095698 0.02886406 0.03608381
  0.03210391 0.01977303 0.01954242 0.04018547 0.03713284 0.03479935
  0.03359808 0.03799046 0.03193588 0.04165422 0.04649792 0.03447741
  0.04770684 0.04159438 0.04552335 0.02755475 0.03147206 0.0765411
  0.04559516 0.05526051]
 [0.03702078 0.04264691 0.04664551 0.03535962 0.02777007 0.04104321
  0.04320979 0.04372209 0.03961094 0.03670638 0.03140154 0.0431561
  0.04131479 0.02339531 0.02033971 0.0387157  0.03401037 0.02995098
  0.03148496 0.03214646 0.02890283 0.03963057 0.04321892 0.03402022
  0.04873813 0.03689647 0.04406721 0.02939402 0.03188079 0.07051069
  0.07077947 0.06554374]
 [0.0367882  0.02995519 0.02719704 0.01965698 0.01693748 0.02326039
  0.02782723 0.02511023 0.02570708 0.02260128 0.02530733 0.02490854
  0.02769334 0.01235797 0.01415693 0.04123621 0.03629327 0.03291077
  0.03324438 0.03465582 0.03169419 0.03728418 0.02976904 0.03767281
  0.04330684 0.02908996 0.03113444 0.02508085 0.02359404 0.03007684
  0.06968681 0.03460755]
 [0.03643845 0.03210291 0.02720333 0.01936277 0.01643799 0.02303537
  0.02968936 0.02806853 0.02624347 0.02215226 0.02530733 0.02388939
  0.0283514  0.01230385 0.01406065 0.04627407 0.04127498 0.04493009
  0.04025023 0.04111212 0.04271189 0.03521633 0.02775223 0.04443689
  0.04603586 0.03713274 0.03027226 0.03127222 0.02235428 0.02005045
  0.05852139 0.02935134]
 [0.03762136 0.03022973 0.02790016 0.02023791 0.01846473 0.02546809
  0.02949705 0.02688144 0.02814858 0.02433964 0.03354659 0.02826791
  0.02953826 0.01358389 0.01472977 0.04717793 0.03768478 0.05598868
  0.04294891 0.06390936 0.04760563 0.03061906 0.02589442 0.04815703
  0.03903574 0.03775088 0.02860537 0.02658216 0.02090373 0.01695594
  0.04107496 0.02934701]
 [0.03767295 0.02573272 0.02493665 0.01556551 0.01540612 0.02095827
  0.02652678 0.02321419 0.02525789 0.02000502 0.03474875 0.02413759
  0.02606974 0.01112799 0.01266463 0.04134728 0.04153087 0.04026716
  0.04156684 0.04665244 0.04360309 0.03266555 0.02485605 0.06250858
  0.04085266 0.03978664 0.02507999 0.02834356 0.02052429 0.0156772
  0.04472682 0.02746809]
 [0.03662036 0.04110041 0.04095128 0.0259874  0.02779063 0.03901017
  0.04807837 0.04380453 0.04146321 0.03396212 0.04900232 0.04558039
  0.04345544 0.0180424  0.01799838 0.03861304 0.04673737 0.04194334
  0.04779891 0.04503935 0.04326064 0.03805276 0.03965128 0.06035556
  0.0490227  0.04717418 0.03441074 0.03610944 0.03069176 0.02227439
  0.03743757 0.052227  ]
 [0.03781769 0.03082053 0.03227308 0.02322984 0.02223867 0.02872065
  0.03220076 0.03168397 0.03087017 0.02793929 0.03266585 0.03346297
  0.03162603 0.01654856 0.01575693 0.03131315 0.03384193 0.0300391
  0.0359758  0.03439552 0.03549589 0.03838915 0.02741956 0.04190632
  0.03623861 0.03846931 0.03408503 0.03071312 0.02542617 0.0242062
  0.04870913 0.04087782]
 [0.03767642 0.03293872 0.03794372 0.03143271 0.02790162 0.03732488
  0.03772051 0.04399531 0.03714302 0.03820645 0.03505594 0.05148259
  0.04446211 0.02394467 0.01751759 0.02728129 0.02808479 0.03214468
  0.03117127 0.03246592 0.02938213 0.04053709 0.02911593 0.02894698
  0.03801418 0.03644728 0.03711225 0.03398674 0.03040594 0.03428157
  0.04477988 0.06851455]
 [0.03804126 0.03637576 0.03879471 0.0326968  0.02856967 0.0386388
  0.04199884 0.04722919 0.03684708 0.04018061 0.03869614 0.04969552
  0.04957187 0.02393249 0.01904178 0.03679531 0.03205396 0.0384542
  0.03614765 0.03512713 0.03429697 0.03902217 0.02878326 0.03493318
  0.03931303 0.03057764 0.03958385 0.0349819  0.02939412 0.03065819
  0.04339054 0.05724104]
 [0.03802531 0.02817236 0.02818016 0.02087619 0.01787685 0.02496141
  0.0317933  0.03270619 0.0276439  0.02410887 0.02929023 0.0305757
  0.03412313 0.01408049 0.01350285 0.04230116 0.03650964 0.03696937
  0.03639315 0.0336294  0.03773646 0.03667518 0.0223329  0.04564779
  0.04265863 0.03078781 0.02758991 0.04087503 0.02315745 0.02256594
  0.05253224 0.03663133]
 [0.03844406 0.02928098 0.02760444 0.02153441 0.01736092 0.02361444
  0.03194372 0.03050159 0.02674815 0.02332121 0.02898304 0.02795183
  0.03276393 0.01341475 0.01319717 0.04480061 0.03937364 0.04471177
  0.04023932 0.0400857  0.04448611 0.03226302 0.0217336  0.04610071
  0.03442048 0.02978916 0.02488839 0.03396026 0.02057967 0.0147976
  0.0389427  0.02628647]
 [0.03880106 0.03004381 0.0278687  0.02177875 0.01700326 0.02512348
  0.03228454 0.03256016 0.02873518 0.02460554 0.03047995 0.02888791
  0.03512981 0.01367455 0.01272661 0.04489589 0.03445024 0.0433578
  0.03787979 0.04009162 0.04135843 0.03125535 0.02159417 0.04722486
  0.03294287 0.02981526 0.02410285 0.03189984 0.02019131 0.01443754
  0.03403898 0.0280562 ]
 [0.03906883 0.02958333 0.02799927 0.02237215 0.01727664 0.02572616
  0.03227692 0.02981855 0.02934819 0.02500188 0.03254865 0.02884435
  0.03235852 0.01456084 0.01368637 0.0400665  0.03288187 0.03596525
  0.0387445  0.03909379 0.04021193 0.03247274 0.02155993 0.04286763
  0.02906824 0.03202685 0.02538655 0.02930057 0.01939029 0.01480897
  0.03302471 0.02604971]
 [0.03884673 0.0296094  0.02845229 0.01932537 0.01419131 0.02352789
  0.03767291 0.03387915 0.02907868 0.02144488 0.05537887 0.02773503
  0.03416231 0.01272873 0.01271398 0.04294498 0.0393717  0.03617304
  0.04121768 0.03725984 0.04140949 0.03283108 0.0233945  0.06145056
  0.03136189 0.0370874  0.02814554 0.03025758 0.02068078 0.01471509
  0.03578411 0.02520863]
 [0.03679165 0.05305712 0.04913871 0.02646112 0.01948427 0.03434141
  0.07629021 0.06203012 0.04757488 0.02963753 0.08390023 0.0401503
  0.05974438 0.01622787 0.01698566 0.05585389 0.0642038  0.06018472
  0.05490296 0.0531896  0.05778933 0.03746038 0.044815   0.09294944
  0.05374864 0.0592088  0.03762957 0.04457926 0.02891537 0.01635185
  0.03695758 0.0337816 ]
 [0.03885967 0.02858071 0.02854667 0.02323732 0.01567745 0.02669233
  0.03413143 0.03325734 0.02947502 0.02367239 0.03215977 0.02688709
  0.0315379  0.0154999  0.01430977 0.02971915 0.03118524 0.02747386
  0.03386631 0.03160416 0.03470478 0.03479748 0.02107682 0.04326155
  0.03067112 0.03279884 0.0266894  0.03009173 0.02133746 0.0154498
  0.03730009 0.02634377]
 [0.03676965 0.03542354 0.03739632 0.05392454 0.0472009  0.0457812
  0.03522434 0.03712244 0.04005221 0.04992098 0.03429594 0.03855876
  0.03848278 0.06775573 0.09567343 0.02621212 0.02801223 0.02835174
  0.03036202 0.02917565 0.02991658 0.0390014  0.0423102  0.01629552
  0.0271066  0.03719455 0.04153814 0.05107744 0.05761065 0.03255851
  0.02009487 0.02743458]
 [0.03614162 0.04608222 0.0437229  0.08464417 0.17726184 0.06856952
  0.04007197 0.04325338 0.04890661 0.08783644 0.0597471  0.06654604
  0.04440532 0.10210042 0.13672714 0.03577932 0.05083935 0.05442758
  0.04425552 0.03631722 0.04422876 0.03876469 0.05460674 0.01376921
  0.02158288 0.03547198 0.05690418 0.05385892 0.05900761 0.02737855
  0.01114492 0.01418432]
 [0.03642657 0.03387878 0.03060886 0.04590368 0.06739432 0.03099602
  0.02800049 0.03125766 0.03006954 0.04532045 0.0372809  0.03465638
  0.03047247 0.03277238 0.04763905 0.030782   0.05697417 0.06144992
  0.06149146 0.04676287 0.06901059 0.03624833 0.04287525 0.03154012
  0.04039539 0.03906547 0.03856839 0.05910886 0.04013681 0.01661075
  0.02015155 0.01959675]
 [0.0365759  0.03647828 0.03370765 0.04895544 0.04587303 0.03836343
  0.03509296 0.03590474 0.03908776 0.044297   0.03556024 0.0335268
  0.03336911 0.0366734  0.0426495  0.02437649 0.03991586 0.04199661
  0.04071032 0.03920817 0.04046179 0.04926946 0.04874344 0.0179629
  0.02735713 0.03319858 0.03138352 0.0627578  0.04439845 0.01410051
  0.01412502 0.01602594]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' or', ' the', ' cinema', ' in', ' the', ' context', ' sentences', ',', ' so', ' we', ' cannot', ' determine', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03095961 0.03486089 0.03225274 ... 0.02534616 0.01768382 0.05017918]
 [0.03172532 0.02419201 0.02301024 ... 0.02361782 0.01983693 0.02970507]
 [0.03232449 0.03247675 0.03329116 ... 0.02200069 0.01698181 0.03538832]
 ...
 [0.03293918 0.02770848 0.02589677 ... 0.02776146 0.02694966 0.03102084]
 [0.03341953 0.02945387 0.02998868 ... 0.02684585 0.02374202 0.03455954]
 [0.03354977 0.0258235  0.02798326 ... 0.02376021 0.0225401  0.03285572]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' or', ' the', ' office', ' in', ' the', ' context', ' sentences', ',', ' so', ' we', ' cannot', ' determine', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03139977 0.03757937 0.0373529  ... 0.01546696 0.01172481 0.05071742]
 [0.03200233 0.04149916 0.03981457 ... 0.03475371 0.0308612  0.02992638]
 [0.03273616 0.0383786  0.04244193 ... 0.02725391 0.01608801 0.05453302]
 ...
 [0.03311971 0.03566366 0.02777388 ... 0.01858091 0.01805937 0.05960505]
 [0.03257104 0.05038897 0.03892786 ... 0.02339985 0.02326868 0.06274915]
 [0.03332053 0.03504316 0.02825456 ... 0.01421288 0.01345837 0.06443983]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' previously', ' stated', ' that', ' Bill', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 50), x_tokens=50, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 50)
DEBUG result.interpretability.attn_scores 1500 
 [[0.03061863 0.03951775 0.03896736 ... 0.02065308 0.02195172 0.04066793]
 [0.03140353 0.02973012 0.02974874 ... 0.0325973  0.02657114 0.03086241]
 [0.0320692  0.04315551 0.04804607 ... 0.01713462 0.01506143 0.03613422]
 ...
 [0.03240269 0.04088028 0.04277555 ... 0.01624438 0.01610021 0.04204604]
 [0.03298926 0.03041899 0.03183203 ... 0.02747767 0.02447009 0.04996193]
 [0.03282738 0.03404589 0.03562297 ... 0.02077419 0.02055704 0.03870123]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' going', ' to', ' the', ' office', ' in', ' the', ' context', ' sentences', '.', ' She', ' travelled', ' to', ' the', ' park', ' and', ' then', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' her', ' going', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 26), x_tokens=26, y_tokens=45, max_supp_attn=0.0667, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 26)
DEBUG result.interpretability.attn_scores 1170 
 [[0.02064713 0.03674553 0.03984556 ... 0.01218672 0.00761599 0.02041909]
 [0.02131012 0.02306518 0.02362742 ... 0.0084872  0.00620665 0.01356854]
 [0.02166261 0.02613233 0.03016475 ... 0.01111531 0.00852623 0.01297976]
 ...
 [0.02167506 0.02444929 0.02405452 ... 0.00804532 0.00529555 0.01322907]
 [0.02163238 0.01975185 0.01938791 ... 0.01150352 0.01037867 0.01532554]
 [0.02174753 0.02481102 0.02239144 ... 0.00963022 0.00821337 0.01295533]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', ' being', ' in', ' the', ' bedroom', ' and', ' Bill', ' going', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02003451 0.03044408 0.03213972 ... 0.00828734 0.01284312 0.00669557]
 [0.02073463 0.02843458 0.0295037  ... 0.0094437  0.01263895 0.00770008]
 [0.02109316 0.02755943 0.03112094 ... 0.01438482 0.01972773 0.00883493]
 ...
 [0.02143687 0.02510841 0.0197446  ... 0.00971615 0.00750422 0.007842  ]
 [0.02158156 0.02909193 0.02423817 ... 0.0108361  0.0089372  0.00736582]
 [0.02173131 0.0258988  0.02213938 ... 0.01078082 0.01040027 0.00776496]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' going', ' to', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' previous', ' sentence', ' (', '4', ')', ' mentioned', ' Julie', ' being', ' in', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' update', ' about', ' her', ' going', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01975354 0.02817806 0.0304623  ... 0.04751228 0.02951101 0.00730362]
 [0.01985297 0.03247973 0.03394704 ... 0.02267322 0.02892461 0.02057743]
 [0.02059018 0.03017389 0.0358223  ... 0.03800729 0.02195649 0.00562961]
 ...
 [0.02078344 0.02612871 0.02534148 ... 0.07521797 0.0190329  0.00524751]
 [0.02122192 0.02112857 0.01958283 ... 0.04634855 0.01669311 0.01021135]
 [0.02121848 0.02164776 0.01947546 ... 0.09884712 0.01646478 0.0074901 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' (', '10', ')', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(22, 44), x_tokens=44, y_tokens=22, max_supp_attn=0.0, attn_on_target=0.0455)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (22, 44)
DEBUG result.interpretability.attn_scores 968 
 [[0.04309426 0.0471101  0.05015538 0.07482232 0.06009788 0.06484006
  0.04678256 0.0532218  0.0588893  0.06143667 0.04003539 0.04519647
  0.05491129 0.10228933 0.09593072 0.03706479 0.03046937 0.0364589
  0.03315475 0.03893401 0.03407767 0.04371101 0.05885708 0.02700286
  0.03695479 0.05654229 0.051294   0.05711492 0.13730328 0.01991264
  0.02505873 0.01798499 0.0166408  0.02677849 0.07152345 0.07213169
  0.04665098 0.01715384 0.01112886 0.02912165 0.0565375  0.0729894
  0.16137907 0.02117905]
 [0.04361696 0.04020001 0.04016634 0.0446755  0.03347998 0.04524687
  0.04730697 0.05140337 0.05110766 0.04007671 0.03431063 0.0409448
  0.05670644 0.04819674 0.0547912  0.03278655 0.02770213 0.03817613
  0.03768467 0.04575955 0.03914994 0.04726134 0.03423267 0.02853493
  0.04016118 0.04603229 0.04393078 0.03204479 0.07345264 0.040009
  0.04151865 0.0459624  0.04761217 0.04562851 0.02759163 0.02974587
  0.0324959  0.02290584 0.02549764 0.04244008 0.04373944 0.04598943
  0.07085337 0.03863515]
 [0.04493412 0.05196    0.05487523 0.09317876 0.08131059 0.09611987
  0.05448706 0.05651834 0.0641657  0.07410051 0.04740806 0.0594799
  0.0676943  0.15365285 0.09868788 0.03786401 0.02568705 0.03044192
  0.02981155 0.03324441 0.02891033 0.04657941 0.04662754 0.02632421
  0.02910308 0.04643048 0.05499114 0.04108172 0.11927503 0.03478416
  0.04086025 0.02054733 0.01902321 0.04114008 0.07658216 0.0597539
  0.03677185 0.01466567 0.01036327 0.02398623 0.04607874 0.05167335
  0.1251225  0.03050087]
 [0.04333307 0.05568961 0.05917466 0.05004241 0.03982196 0.05430141
  0.05198692 0.05690205 0.05691586 0.0478154  0.03862252 0.04816023
  0.05220632 0.04046947 0.0340919  0.04739342 0.03447067 0.03593172
  0.03542187 0.04043997 0.03550476 0.04999413 0.06700515 0.05287339
  0.05083408 0.05764254 0.06191941 0.04559245 0.06815284 0.06966969
  0.09333895 0.04336534 0.03342598 0.06070898 0.03819448 0.03353644
  0.06042592 0.03773111 0.02429931 0.0491508  0.06010977 0.04738888
  0.08559273 0.08575057]
 [0.04420107 0.05846527 0.05927977 0.0343877  0.02694548 0.04462893
  0.05316329 0.05322514 0.05784812 0.03591809 0.03453558 0.04013326
  0.04533716 0.02891461 0.02545233 0.04848215 0.032913   0.03286873
  0.03676087 0.04164155 0.03525596 0.04783923 0.07203035 0.05246248
  0.04859829 0.0582468  0.06816416 0.03709002 0.04141524 0.06778818
  0.10006835 0.05698602 0.04732339 0.06009378 0.02436964 0.02457961
  0.06885325 0.0373784  0.03652664 0.05389176 0.0501982  0.04029609
  0.0466237  0.11179687]
 [0.04569156 0.08357048 0.08730537 0.0394987  0.02762365 0.05224333
  0.06481075 0.05741922 0.07794775 0.03915747 0.03340832 0.04143514
  0.04436435 0.02827439 0.02543175 0.0609662  0.03546771 0.03230596
  0.03746342 0.0434857  0.03382652 0.0441568  0.10974443 0.05421953
  0.04039912 0.06016089 0.08065368 0.03267042 0.03533384 0.04844728
  0.13455881 0.04049052 0.03555572 0.04729208 0.02079232 0.02837254
  0.09229257 0.02693415 0.02323414 0.04316115 0.04531172 0.03802468
  0.03581617 0.1196987 ]
 [0.04519916 0.05607439 0.06175868 0.033832   0.02572134 0.03978363
  0.05866529 0.05069935 0.06026046 0.03338649 0.03286238 0.03647279
  0.03662386 0.02511963 0.02552473 0.06346823 0.04254586 0.03522548
  0.04066008 0.04595849 0.03724637 0.04401028 0.08263807 0.07871603
  0.05878399 0.06162089 0.08257993 0.03588818 0.03489505 0.04575805
  0.07616512 0.05034407 0.04360539 0.04522759 0.02280619 0.02897714
  0.07533053 0.0534326  0.02394425 0.07479524 0.0521528  0.04166055
  0.03618383 0.06857739]
 [0.04542526 0.03644435 0.03879203 0.02280205 0.0192558  0.02746097
  0.03957129 0.0320245  0.04172741 0.02398259 0.02984961 0.0263712
  0.02659131 0.01741811 0.02377654 0.05298873 0.04327178 0.03528998
  0.04171893 0.04838552 0.03677224 0.04093185 0.05372227 0.0648697
  0.05745837 0.05013989 0.0443036  0.0257313  0.0229962  0.02343809
  0.03160436 0.03443535 0.0344367  0.02670937 0.01531122 0.02676893
  0.04437019 0.04509987 0.02002752 0.06358223 0.03530218 0.03318715
  0.01920414 0.02900159]
 [0.04598825 0.03397731 0.03432801 0.02397195 0.01963224 0.03005943
  0.03961948 0.03146395 0.04153839 0.02590038 0.03084292 0.02940634
  0.02899185 0.01756915 0.02049355 0.04551771 0.0344112  0.03364282
  0.04377485 0.0440288  0.0361162  0.03819321 0.0422767  0.06883004
  0.05845919 0.04694044 0.04585702 0.02751397 0.02886164 0.03630141
  0.03817113 0.0485421  0.04670974 0.0381885  0.01986646 0.02787893
  0.04709769 0.0589851  0.02667377 0.07142355 0.04011938 0.04014942
  0.02957657 0.03986953]
 [0.04567432 0.04647681 0.04904085 0.03803632 0.02553456 0.04600702
  0.04946128 0.04851055 0.04916305 0.04158334 0.03973209 0.05301395
  0.0471568  0.02649276 0.02238195 0.04354903 0.03535314 0.03784915
  0.03834412 0.04028878 0.03671473 0.04728667 0.04069762 0.05289756
  0.05343999 0.04710111 0.05943393 0.03971614 0.03902931 0.0871465
  0.05996168 0.06262109 0.04735949 0.08109354 0.02771875 0.02465873
  0.05012156 0.05379649 0.02949204 0.04745742 0.046246   0.04157713
  0.04218272 0.06637894]
 [0.04646829 0.05504229 0.05667393 0.04982306 0.03375585 0.05872268
  0.05649397 0.05747594 0.05010172 0.05358931 0.05243523 0.07150095
  0.06484935 0.0332863  0.02565809 0.04717404 0.04176135 0.04404964
  0.04445728 0.04645782 0.04077068 0.04742929 0.04084438 0.05070357
  0.05231831 0.04429984 0.06024171 0.04686535 0.03875369 0.09114709
  0.05899921 0.0594685  0.04786485 0.08270872 0.03352615 0.02948608
  0.05002921 0.04831741 0.03401904 0.0435958  0.04619582 0.04234952
  0.03978369 0.0631209 ]
 [0.04717105 0.04287947 0.04284754 0.03365652 0.02611789 0.03979139
  0.04731264 0.04230784 0.03719105 0.0377507  0.0441375  0.04382476
  0.04401092 0.0226995  0.02096908 0.04680705 0.03827868 0.03597065
  0.0402851  0.04095124 0.03942222 0.04587527 0.0332332  0.05306862
  0.05356462 0.03484469 0.04101035 0.04223566 0.03236376 0.06679358
  0.04601372 0.05793388 0.04837021 0.05984724 0.02911905 0.02649142
  0.03789936 0.0575471  0.03539489 0.04497512 0.04781589 0.03878899
  0.03420403 0.04926342]
 [0.04626144 0.03677502 0.03270779 0.02496271 0.01953741 0.02824698
  0.03871807 0.03517757 0.02932932 0.02907808 0.04327815 0.03444937
  0.03755468 0.01509066 0.01702842 0.05082515 0.05044526 0.04310761
  0.04334814 0.04343199 0.04845068 0.04569407 0.02584866 0.06190595
  0.0597206  0.03061135 0.02650138 0.04295707 0.0238066  0.05439747
  0.03224028 0.05811095 0.05988521 0.04549717 0.02244085 0.0219522
  0.03512891 0.0860581  0.06635156 0.05506758 0.05448733 0.04033377
  0.02357768 0.03971996]
 [0.04589085 0.03713375 0.03170432 0.02494809 0.01785925 0.02731877
  0.04327897 0.03968195 0.02775954 0.02776236 0.04223177 0.03285577
  0.0389474  0.01394582 0.01568794 0.05034562 0.05127788 0.05228434
  0.04480352 0.04532985 0.05279885 0.04290321 0.02154427 0.06291928
  0.06086116 0.02832005 0.02000808 0.03885569 0.01806184 0.05224039
  0.0254937  0.06516606 0.06786269 0.03840278 0.01948811 0.01848873
  0.02910049 0.09397109 0.07416284 0.05270841 0.0398876  0.0401252
  0.0173037  0.0364403 ]
 [0.04681351 0.03314161 0.03025862 0.02393174 0.01937649 0.02778934
  0.0362803  0.03560799 0.02739112 0.02843197 0.05017566 0.03940551
  0.0374217  0.0145929  0.01566966 0.0458847  0.05501506 0.04600377
  0.05128448 0.0442715  0.05060188 0.04221505 0.01940786 0.04483556
  0.04938383 0.03027255 0.02159257 0.04966293 0.01815508 0.05330785
  0.02682768 0.07707157 0.09464679 0.04554325 0.02187532 0.01935548
  0.02795365 0.08983903 0.0908062  0.04419124 0.03077412 0.03647183
  0.01764755 0.03310658]
 [0.04678552 0.03094913 0.02825962 0.02068892 0.0175604  0.02447468
  0.03807178 0.03370948 0.0256131  0.02493708 0.06697334 0.03715554
  0.03567204 0.01236157 0.01412646 0.04598093 0.05418506 0.0450673
  0.05079313 0.04390546 0.04843308 0.0422735  0.01758727 0.04331464
  0.04292949 0.03222505 0.01783329 0.04908055 0.0147462  0.04582774
  0.02408832 0.06949566 0.10331011 0.03801569 0.01856425 0.01843914
  0.02620547 0.07565057 0.16598983 0.04572132 0.02592586 0.04122861
  0.01318937 0.02880157]
 [0.04468336 0.03091908 0.02821005 0.02158463 0.01677017 0.02683269
  0.039662   0.03747981 0.0323055  0.02873153 0.05034753 0.0380245
  0.04387445 0.01401619 0.0148893  0.03913296 0.07715472 0.0664337
  0.06900044 0.06311285 0.05288687 0.0468023  0.02510371 0.04741072
  0.04909303 0.04775078 0.0203809  0.04981895 0.02131439 0.04288828
  0.03143645 0.05954836 0.06941486 0.04869529 0.02057211 0.02625171
  0.03963679 0.07396199 0.18800347 0.06380584 0.04025558 0.0521349
  0.01563337 0.03110995]
 [0.04722088 0.02975269 0.03117879 0.02699175 0.01833051 0.02971556
  0.03353639 0.03648885 0.03145013 0.03076679 0.03940099 0.03736192
  0.03656437 0.01792273 0.01554849 0.03013854 0.02802486 0.0323827
  0.03784845 0.0361847  0.03467738 0.04173147 0.01791981 0.02375649
  0.03347269 0.03374794 0.0209712  0.03352468 0.02440789 0.04042236
  0.03887713 0.05268073 0.05649208 0.07079181 0.03278546 0.02002385
  0.02514883 0.02157637 0.0401438  0.03158384 0.02807878 0.03437131
  0.02451798 0.03333724]
 [0.04568877 0.04082528 0.04498337 0.07419716 0.06080478 0.06489694
  0.04134009 0.04800005 0.05289209 0.07647938 0.05040061 0.05673494
  0.05703888 0.10842893 0.10942008 0.03547942 0.03453364 0.03964868
  0.0396472  0.04049368 0.03727102 0.04542558 0.03926344 0.02198828
  0.02769815 0.04635364 0.04073073 0.05605675 0.06397883 0.02158509
  0.02806911 0.02022096 0.01927589 0.03061946 0.13759182 0.06619667
  0.03821291 0.01558976 0.0130484  0.02647606 0.04698674 0.05573849
  0.06518246 0.02214674]
 [0.04529815 0.05311836 0.05030609 0.10079407 0.21020465 0.07665079
  0.04121537 0.04862399 0.04672188 0.09793332 0.07527613 0.07059165
  0.04948385 0.14292529 0.17764962 0.049336   0.06337712 0.06920418
  0.05682584 0.05031721 0.06131915 0.04414083 0.05215991 0.02238617
  0.02225218 0.04779619 0.0524746  0.05514997 0.06371075 0.01551136
  0.01322346 0.01492615 0.01559398 0.01950899 0.13638571 0.11389872
  0.04400294 0.01777309 0.0145463  0.02385056 0.0517442  0.05173795
  0.04654303 0.01567571]
 [0.0450804  0.04889975 0.04328383 0.07197801 0.12611245 0.04333616
  0.03497354 0.04482029 0.03558603 0.07514016 0.06867181 0.06240176
  0.04503972 0.05222    0.07986783 0.04906769 0.10146514 0.10917206
  0.0849665  0.06660818 0.11449002 0.04567069 0.04692292 0.03537722
  0.04134329 0.04806164 0.0472551  0.07930868 0.03686619 0.02420305
  0.01782959 0.02387351 0.02400462 0.02572781 0.12031177 0.109846
  0.04452911 0.03122581 0.0278499  0.03889503 0.06235349 0.04842367
  0.02437383 0.01869768]
 [0.04547971 0.05059521 0.0447097  0.07119564 0.07414677 0.05153231
  0.04326196 0.04923792 0.04409489 0.0660417  0.05506382 0.05507927
  0.04895895 0.06411299 0.06692258 0.03974706 0.06218942 0.06848459
  0.0619448  0.05676875 0.0653035  0.05987473 0.05233268 0.02560279
  0.03317055 0.0448587  0.03787243 0.08203984 0.04311968 0.01842074
  0.01559527 0.02022443 0.02158611 0.02178086 0.06258314 0.1731661
  0.04774198 0.0204065  0.01849633 0.03011909 0.0496988  0.0653597
  0.02550854 0.0171912 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' (', '13', ')', ' and', ' (', '14', ')', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' cinema', '.', ' They', ' only', ' provide', ' possibilities', ' for', ' her', ' location', ' as', ' either', ' in', ' the', ' school', ' or', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 50), x_tokens=50, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 50)
DEBUG result.interpretability.attn_scores 2100 
 [[0.02212058 0.02944346 0.03532063 ... 0.02541793 0.03777573 0.03096954]
 [0.02260754 0.0249482  0.02678598 ... 0.01251074 0.02271566 0.02687323]
 [0.02302089 0.03218475 0.03681093 ... 0.02390761 0.03524704 0.02749736]
 ...
 [0.02324424 0.02997328 0.02984737 ... 0.04143343 0.03546001 0.02344429]
 [0.02373872 0.02280001 0.02135064 ... 0.02556897 0.02015558 0.02043832]
 [0.02362749 0.02640925 0.02470054 ... 0.01852708 0.03251098 0.02083122]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 26), x_tokens=26, y_tokens=24, max_supp_attn=0.0833, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 26)
DEBUG result.interpretability.attn_scores 624 
 [[0.03912661 0.05674287 0.06942914 0.09058746 0.09859896 0.09192581
  0.076186   0.08844639 0.07275158 0.08325449 0.06815338 0.08241138
  0.09111985 0.1088044  0.07083107 0.04259037 0.03993209 0.04425814
  0.03584442 0.03998666 0.03422707 0.05031374 0.04461268 0.02641802
  0.01659794 0.03126601]
 [0.03967369 0.07238971 0.06602948 0.08421042 0.06889109 0.07154796
  0.0613728  0.06131904 0.05668209 0.06034911 0.05373963 0.04300315
  0.04679731 0.11501895 0.11185361 0.04619407 0.03496116 0.03278557
  0.0292471  0.03139034 0.02804117 0.05248177 0.04932952 0.01993999
  0.01172695 0.02664112]
 [0.0428155  0.07512134 0.04585245 0.06215321 0.0415159  0.0427751
  0.0421115  0.03077786 0.02943097 0.04104082 0.03837985 0.02227216
  0.02511663 0.02813623 0.03645544 0.03182288 0.01855681 0.01919617
  0.02105344 0.02272629 0.021587   0.05703593 0.05593068 0.0115016
  0.00712071 0.01392102]
 [0.04011594 0.03066838 0.02993304 0.02389751 0.01670447 0.02817197
  0.03152892 0.02780133 0.03331823 0.02790205 0.03146957 0.02908622
  0.03021309 0.01121487 0.01047568 0.03299441 0.03285202 0.03975756
  0.04723601 0.06744577 0.05641087 0.04165176 0.05500256 0.08215243
  0.08242761 0.09279798]
 [0.04058732 0.05355224 0.05863259 0.07828115 0.06780026 0.05769566
  0.04644619 0.04088616 0.04543325 0.0563807  0.04829356 0.03504314
  0.03552987 0.10258196 0.10401868 0.05131659 0.0360629  0.02941155
  0.02772474 0.03107849 0.03030192 0.0509874  0.06878262 0.01897708
  0.01055189 0.03230081]
 [0.04136682 0.03451834 0.03590866 0.05980774 0.05117841 0.05211773
  0.03444941 0.03213212 0.03866704 0.05260687 0.0434833  0.03990731
  0.03849801 0.11571662 0.13466585 0.05080134 0.04097422 0.03589265
  0.03148935 0.03336861 0.02938248 0.04325358 0.04041875 0.01498698
  0.00858163 0.02095383]
 [0.0419513  0.03888175 0.04639607 0.06355228 0.05579473 0.06622538
  0.04544023 0.04428903 0.05083776 0.06258413 0.05115381 0.06356187
  0.05886467 0.09257828 0.08391421 0.04253691 0.0368816  0.03529318
  0.02979594 0.03242785 0.02740993 0.03909711 0.03778952 0.02013351
  0.01180497 0.02128331]
 [0.04042624 0.05281026 0.06257068 0.05072111 0.05075628 0.06340127
  0.05390149 0.06103378 0.05764237 0.05650031 0.05167371 0.07156327
  0.06395633 0.05709836 0.04944141 0.0545074  0.04833604 0.04558377
  0.0383753  0.04238173 0.0386081  0.04582881 0.05640945 0.04291947
  0.03404385 0.04416491]
 [0.04212383 0.05247768 0.06468289 0.05667826 0.04868436 0.07033446
  0.05975846 0.06532067 0.06652314 0.0620111  0.05101915 0.07025602
  0.06529271 0.0416258  0.02683112 0.03992883 0.03654023 0.03745298
  0.03232285 0.03640598 0.03107272 0.04485699 0.04208108 0.02850485
  0.01849275 0.03022071]
 [0.04106975 0.06303856 0.06647039 0.03375502 0.02625467 0.04537079
  0.05864844 0.05756821 0.05944388 0.03784003 0.04020543 0.05062031
  0.05370754 0.01843823 0.0154154  0.05893876 0.04727247 0.04427737
  0.04348461 0.04769135 0.04575422 0.04499996 0.07919256 0.0602231
  0.04755242 0.04971919]
 [0.04188922 0.08512403 0.08293133 0.03243796 0.02559631 0.04014309
  0.06275366 0.05597101 0.06386122 0.03393946 0.03737586 0.04238246
  0.0444822  0.01587244 0.01504031 0.06976274 0.04913201 0.04387075
  0.04262865 0.0508999  0.04429735 0.04141581 0.07926746 0.05448958
  0.03527806 0.03321972]
 [0.04214064 0.04435571 0.04959239 0.02431412 0.02021964 0.02908562
  0.04796047 0.04232191 0.04938196 0.02727546 0.03031388 0.03345468
  0.03374484 0.01317173 0.01280726 0.05447556 0.04199619 0.03723242
  0.03983954 0.04390897 0.04087791 0.03901568 0.0613737  0.0623802
  0.0570757  0.05272813]
 [0.04244027 0.01852725 0.02002349 0.0130854  0.01157694 0.01661081
  0.020921   0.02121503 0.02442978 0.01603074 0.01975754 0.01929539
  0.02002337 0.00669404 0.00704142 0.02526304 0.02486449 0.02649166
  0.03365896 0.03864698 0.04059016 0.02798478 0.03804763 0.07660628
  0.08931619 0.07801711]
 [0.04230556 0.02784631 0.02893088 0.01918197 0.01778368 0.02550131
  0.03210261 0.03166189 0.03031444 0.02319637 0.02978717 0.02975082
  0.0309635  0.01012097 0.01050986 0.04282885 0.04046602 0.03884421
  0.04377059 0.0413003  0.03970879 0.03718492 0.03099578 0.05755659
  0.08455583 0.05813892]
 [0.04255041 0.02936723 0.03049015 0.02400084 0.02031646 0.03246142
  0.0392177  0.0427843  0.03464343 0.03178477 0.03773041 0.04471743
  0.04644606 0.01329084 0.01108287 0.0385518  0.04656184 0.0454667
  0.04929532 0.04208327 0.040553   0.04066636 0.02373664 0.03862518
  0.06530976 0.03876406]
 [0.04201236 0.02311336 0.01957428 0.01622636 0.01275684 0.01922994
  0.02932355 0.03164465 0.02383824 0.01975993 0.02940023 0.0249787
  0.03206199 0.00744275 0.00749246 0.03394946 0.03995524 0.04958215
  0.07091544 0.05813867 0.05987245 0.03480582 0.0173334  0.05324591
  0.11570919 0.05677353]
 [0.04268598 0.02485892 0.02237638 0.01781242 0.01502369 0.02329098
  0.03312859 0.03750836 0.0274182  0.02379975 0.03796223 0.03633856
  0.03802381 0.00890736 0.00832684 0.03645821 0.05089119 0.04329729
  0.06357709 0.04354576 0.04828187 0.03460494 0.01697633 0.03907955
  0.08266293 0.0422399 ]
 [0.0426569  0.02005498 0.01801087 0.01279837 0.01134716 0.01695753
  0.0285991  0.02920887 0.02364426 0.01728392 0.0386969  0.02752563
  0.03085334 0.00644973 0.0065714  0.03860261 0.04944979 0.04527159
  0.0625428  0.05062378 0.05580999 0.03123548 0.01520969 0.05274586
  0.06255484 0.05878905]
 [0.04117848 0.02908911 0.02627921 0.01652651 0.01398967 0.02042353
  0.033797   0.03105843 0.03224846 0.01941897 0.03291674 0.02427103
  0.02990174 0.00765849 0.00797499 0.03957054 0.03540374 0.04298058
  0.04891424 0.05208031 0.07035464 0.03647031 0.03243209 0.1317493
  0.08412097 0.08256473]
 [0.0434182  0.02574677 0.02574804 0.02157829 0.01629008 0.02451152
  0.02955436 0.03348637 0.03168381 0.02643822 0.03420027 0.0353159
  0.03397156 0.01162508 0.00985419 0.02811491 0.03085911 0.0343623
  0.04113271 0.03915904 0.04110675 0.03405705 0.01856443 0.03339404
  0.02682146 0.03971774]
 [0.04225646 0.03407782 0.03426225 0.05120332 0.05025283 0.04718286
  0.03409318 0.03499736 0.03892632 0.05615399 0.04547763 0.04580427
  0.04250397 0.07115431 0.08517305 0.03436613 0.03886122 0.03726126
  0.03214123 0.03194185 0.03149324 0.03967351 0.03322113 0.01541676
  0.01085149 0.02351408]
 [0.04198725 0.03571446 0.03290114 0.05452962 0.09756494 0.04475467
  0.03221735 0.03174496 0.03661394 0.06029734 0.05118279 0.04327085
  0.03519458 0.07347277 0.09542868 0.04175286 0.05130548 0.05237536
  0.03691436 0.0350261  0.036989   0.03713855 0.03229903 0.01303511
  0.0076387  0.01914747]
 [0.04131962 0.03220291 0.02912592 0.04495749 0.0955666  0.03204091
  0.02822687 0.03145969 0.03282656 0.05400465 0.04944925 0.04546817
  0.03506047 0.03184454 0.04409779 0.03509786 0.078123   0.08428546
  0.05515161 0.04575476 0.06110184 0.03473774 0.02946986 0.02582136
  0.01624239 0.02753409]
 [0.0419017  0.03972001 0.03384832 0.04770317 0.06553599 0.03823966
  0.03826111 0.03536257 0.03943912 0.05014692 0.04817766 0.03970126
  0.03767256 0.03108124 0.03469642 0.02957383 0.04976115 0.0547693
  0.04294369 0.04198726 0.04616749 0.06050199 0.0415234  0.0200972
  0.01296181 0.02558258]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' not', ' the', ' park', '.', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 32), x_tokens=32, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 32)
DEBUG result.interpretability.attn_scores 1152 
 [[0.02592517 0.04088577 0.04100762 ... 0.03216533 0.05387369 0.08324865]
 [0.02671877 0.03780502 0.0364087  ... 0.04151358 0.06838457 0.06153949]
 [0.02710328 0.03761536 0.04173134 ... 0.05943539 0.05096734 0.04684437]
 ...
 [0.02716069 0.03203282 0.0307439  ... 0.0136114  0.08407713 0.05350866]
 [0.02754823 0.02594244 0.02382976 ... 0.01130407 0.05977515 0.0328379 ]
 [0.02756271 0.02451624 0.02298336 ... 0.00903373 0.06870073 0.07082676]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', ',', ' but', ' it', ' doesn', "'t", ' specify', ' which', ' one', '.', ' Therefore', ',', ' we', ' can', "'t", ' be', ' certain', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02093823 0.03068777 0.03042735 ... 0.01843121 0.0203465  0.10171203]
 [0.0210549  0.04048496 0.03966907 ... 0.02718421 0.02662932 0.05545609]
 [0.02183648 0.03185836 0.03327665 ... 0.01424413 0.01474474 0.06350255]
 ...
 [0.0220385  0.0297384  0.02498404 ... 0.01425337 0.02013357 0.03856042]
 [0.02240037 0.02409888 0.01948909 ... 0.02115194 0.02948494 0.01697586]
 [0.02259764 0.02279377 0.01865691 ... 0.0174292  0.02455292 0.02910505]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Bill', ' is', ' explicitly', ' stated', ' to', ' be', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 44), x_tokens=44, y_tokens=24, max_supp_attn=0.0417, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 44)
DEBUG result.interpretability.attn_scores 1056 
 [[0.0390125  0.05249302 0.05567281 ... 0.02768518 0.04720798 0.06595297]
 [0.0400358  0.04353074 0.05004851 ... 0.05018785 0.03160925 0.03173856]
 [0.04089628 0.04975792 0.05901888 ... 0.04456437 0.0511802  0.05049866]
 ...
 [0.0410545  0.05754427 0.0515715  ... 0.01624065 0.08831255 0.08792564]
 [0.04126655 0.04913425 0.0397052  ... 0.01930672 0.05114346 0.06971806]
 [0.04149654 0.05255491 0.04279369 ... 0.02144936 0.03941178 0.14081624]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Julie', ' travelled', ' to', ' the', ' office', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '14', ',', ' Julie', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.01995466 0.03182323 0.0299644  ... 0.01700788 0.01143721 0.03164979]
 [0.02054566 0.0306426  0.02917822 ... 0.02179505 0.01587652 0.02453851]
 [0.0209067  0.03197008 0.03328269 ... 0.01558671 0.00993982 0.02945565]
 ...
 [0.02103383 0.02987199 0.02487168 ... 0.01481438 0.01067624 0.03552294]
 [0.02165758 0.02351811 0.01876612 ... 0.01715938 0.01331792 0.02254885]
 [0.02142666 0.02346286 0.01852262 ... 0.01680038 0.01442822 0.02499267]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' going', ' back', ' to', ' the', ' office', ' and', ' Bill', "'s", ' possible', ' locations', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02602015 0.0435097  0.04628245 0.07841518 0.07392862 0.04803885
  0.03484013 0.03018917 0.03195509 0.04870722 0.0339009  0.02466796
  0.02501745 0.12198313 0.12882558 0.03963933 0.0273287  0.02127857
  0.02044992 0.02131063 0.01909709 0.03994102 0.06411059 0.0082098
  0.00538189 0.030429  ]
 [0.02687118 0.02718525 0.0272619  0.05647771 0.05327812 0.04071578
  0.02458655 0.02213975 0.02543869 0.04232043 0.0293271  0.02639967
  0.02504028 0.12776265 0.15277894 0.03736911 0.02929926 0.02466869
  0.02256828 0.02217828 0.01805877 0.03317071 0.03747008 0.00651084
  0.00497081 0.02000425]
 [0.02733141 0.03086348 0.03512866 0.06022281 0.05831599 0.05155674
  0.03277126 0.0308295  0.03396979 0.0505166  0.03441561 0.04225068
  0.03908666 0.09999374 0.09312262 0.03111553 0.02684034 0.0251155
  0.02188382 0.02205124 0.01696387 0.02981625 0.03425565 0.0093208
  0.00654377 0.01897402]
 [0.02646112 0.03684507 0.042308   0.0440551  0.04844891 0.0459601
  0.03624407 0.03824785 0.03726966 0.04353853 0.03388626 0.04572274
  0.03913828 0.05866327 0.0529118  0.03775445 0.03408178 0.03108826
  0.02693501 0.02785916 0.02329651 0.03317236 0.04736988 0.02470782
  0.01461925 0.03211245]
 [0.02741271 0.03233623 0.03783156 0.03386831 0.03092715 0.03953846
  0.03585697 0.03836315 0.03445173 0.03373372 0.02865921 0.04115617
  0.03455807 0.02112961 0.01666134 0.02680153 0.02634026 0.02566806
  0.02335952 0.02460703 0.02179425 0.02737812 0.03493724 0.02264013
  0.01994011 0.0323564 ]
 [0.02779019 0.03033969 0.03303251 0.02746503 0.02380517 0.03721282
  0.03529761 0.03635672 0.03500613 0.0303471  0.02711171 0.04067625
  0.03341053 0.01722039 0.01379956 0.02528204 0.02789043 0.02475216
  0.02365485 0.02379857 0.02135063 0.02686591 0.03199711 0.02082946
  0.02060786 0.0306165 ]
 [0.02725068 0.04780815 0.04467021 0.0323561  0.02739144 0.04626234
  0.04608554 0.04914992 0.04386215 0.0387918  0.03671434 0.05916335
  0.04974404 0.02069014 0.01595222 0.03050894 0.02946044 0.02905516
  0.02586794 0.02586447 0.02290618 0.02922218 0.03566278 0.02131182
  0.02357095 0.02667805]
 [0.02786194 0.03747186 0.04038296 0.03124704 0.02416419 0.05344835
  0.04540302 0.0441395  0.04281131 0.03563733 0.03072818 0.06623673
  0.05160332 0.01960808 0.01449882 0.02969558 0.02868731 0.02869522
  0.02706178 0.02697611 0.02310533 0.02806113 0.02991788 0.01679234
  0.01862076 0.0220259 ]
 [0.02799637 0.04444113 0.05272313 0.03592103 0.02680301 0.07372364
  0.06707519 0.04765204 0.05988076 0.0377567  0.02999498 0.05694309
  0.04399941 0.01972753 0.01514649 0.02807407 0.0239938  0.02290527
  0.02313107 0.02438422 0.02017606 0.02884462 0.03578984 0.01491728
  0.01261042 0.02154304]
 [0.02746409 0.02364291 0.02412108 0.01857781 0.01617642 0.02140605
  0.03035049 0.03145644 0.02484322 0.02171259 0.02901061 0.02709129
  0.03645904 0.01011416 0.01026331 0.02966687 0.03464532 0.03071359
  0.02890106 0.02858292 0.03029555 0.02720139 0.01998187 0.03693517
  0.02775139 0.02471033]
 [0.02750416 0.0195965  0.01747916 0.01513692 0.01280012 0.01420598
  0.02265845 0.02303333 0.01798017 0.01540638 0.02156143 0.01701716
  0.02123435 0.00760957 0.00807044 0.02822449 0.0335829  0.0336316
  0.03226898 0.03229703 0.0413182  0.02404098 0.01718185 0.04846755
  0.03142571 0.02624459]
 [0.02800069 0.02025471 0.0179216  0.01733141 0.014927   0.01712818
  0.0225927  0.02488226 0.01914334 0.01926549 0.02689209 0.02385946
  0.02408433 0.00886091 0.00894521 0.02765263 0.03269129 0.03082803
  0.02923168 0.02962863 0.03101138 0.02235352 0.01430168 0.02865167
  0.0322997  0.01853401]
 [0.02797569 0.01753713 0.01565662 0.01268548 0.01177622 0.0132571
  0.02033398 0.0203526  0.01743905 0.01420604 0.0266398  0.01799909
  0.01972251 0.00691077 0.00745868 0.0265461  0.03778294 0.02989438
  0.03362256 0.03430326 0.03607662 0.02197728 0.01407904 0.02851235
  0.03382249 0.01937976]
 [0.02738822 0.02064554 0.01829093 0.0133456  0.01210024 0.01475422
  0.02275569 0.02045142 0.02149987 0.01412547 0.02685605 0.01646236
  0.01947037 0.00751056 0.00820068 0.02975958 0.03630705 0.02776876
  0.03253459 0.03218153 0.03409749 0.02392663 0.02110579 0.04145798
  0.04242192 0.03452774]
 [0.02810262 0.02593459 0.02406154 0.01740082 0.01497884 0.01906987
  0.02491624 0.0245065  0.02383949 0.01953177 0.02640441 0.02328905
  0.02205728 0.0099928  0.00980607 0.02369827 0.03152724 0.02702509
  0.02988595 0.04170837 0.03115559 0.02500963 0.02191089 0.02167929
  0.01832256 0.0210491 ]
 [0.02769744 0.03093434 0.03100798 0.02917513 0.02488999 0.03270476
  0.02782691 0.02971458 0.03139464 0.03458037 0.02743158 0.04039723
  0.03380363 0.02087219 0.01537334 0.02635876 0.0275419  0.0277578
  0.02506368 0.02606996 0.02177474 0.0299542  0.03748314 0.02892311
  0.01353792 0.0231035 ]
 [0.02761023 0.04263014 0.04168089 0.02244843 0.01874267 0.02574454
  0.03428633 0.03359568 0.03486361 0.02154326 0.02323056 0.0260194
  0.02840049 0.01413389 0.01266532 0.03040556 0.02564772 0.02402624
  0.02455383 0.02582164 0.02524075 0.02873373 0.05352208 0.03470374
  0.02182744 0.032683  ]
 [0.02792477 0.06435759 0.06584569 0.0274414  0.02125707 0.02979749
  0.04361754 0.03796989 0.04349496 0.02410917 0.02294562 0.0258842
  0.02802526 0.01463915 0.0136764  0.04065041 0.02826902 0.02373052
  0.02382527 0.0259304  0.02167421 0.02958093 0.06585852 0.01983919
  0.01348218 0.02501678]
 [0.02806597 0.03531606 0.03817149 0.02338766 0.01786003 0.02527098
  0.0353254  0.03278652 0.03385142 0.02095197 0.02049034 0.02348349
  0.02387686 0.012758   0.01196808 0.03023162 0.02438713 0.02280367
  0.02349837 0.02503195 0.02283833 0.03040288 0.04562908 0.02504642
  0.01867595 0.0361386 ]
 [0.02872331 0.02575853 0.02658053 0.020632   0.01518103 0.02370884
  0.0274926  0.02933471 0.02651973 0.0195386  0.02047682 0.0234808
  0.02450522 0.01125116 0.00973602 0.02173435 0.01888982 0.01987432
  0.02024282 0.0213241  0.02078147 0.02802713 0.02204863 0.02450466
  0.018657   0.02597141]
 [0.02813419 0.01927068 0.01836781 0.01470423 0.01197322 0.01599479
  0.02212039 0.02089616 0.02034999 0.01491341 0.02092958 0.01620813
  0.02045212 0.0085543  0.00786458 0.025957   0.02256572 0.02218011
  0.02416517 0.02618064 0.03076856 0.02615683 0.01895413 0.05625202
  0.02906683 0.02865383]
 [0.02790919 0.01562168 0.01406322 0.01214794 0.00968175 0.01175646
  0.01586193 0.0141624  0.01606572 0.01224645 0.01539169 0.01190495
  0.0153587  0.00704044 0.00634164 0.022295   0.02339298 0.02524391
  0.02723126 0.03116711 0.04161898 0.023522   0.01608524 0.07666239
  0.03032653 0.02539581]
 [0.02817214 0.01475015 0.01406548 0.01206524 0.00992671 0.01202882
  0.01399032 0.01389062 0.01658751 0.01286915 0.01495694 0.01254593
  0.01473431 0.00704107 0.00589654 0.0201875  0.01594946 0.02019762
  0.02039559 0.03115315 0.04508884 0.02010203 0.01567616 0.07938229
  0.03002777 0.02064487]
 [0.02835074 0.01424755 0.013363   0.01121166 0.00925533 0.01126884
  0.01334669 0.01350354 0.01626381 0.01240622 0.01743362 0.01286911
  0.01495369 0.00685583 0.00569447 0.02448783 0.01889944 0.02144248
  0.02297086 0.02747418 0.04792251 0.02096226 0.01384808 0.06575558
  0.0339741  0.01964589]
 [0.02825477 0.01483051 0.01396222 0.01072137 0.00919831 0.01114759
  0.01400977 0.01365899 0.0162626  0.01185999 0.02082033 0.01248614
  0.01491497 0.00674469 0.0059499  0.02617525 0.02254768 0.02050997
  0.02493274 0.02674608 0.03965442 0.02240798 0.01501059 0.06587715
  0.03501308 0.02113831]
 [0.02754887 0.03302366 0.02784002 0.04396354 0.05508875 0.04322855
  0.03133769 0.02842981 0.0312654  0.05033088 0.04703666 0.04135439
  0.03275635 0.04487751 0.03379104 0.02854092 0.0268641  0.02996917
  0.02939652 0.02658198 0.02597114 0.03609613 0.02808564 0.02485103
  0.01718771 0.02131724]
 [0.02860701 0.01563994 0.01522171 0.01219076 0.01006668 0.01240398
  0.01480898 0.01517952 0.01749099 0.01260969 0.01829748 0.01300647
  0.0152634  0.00795323 0.00640663 0.02060102 0.02032241 0.0177502
  0.0243054  0.02288472 0.02674192 0.02285732 0.01568388 0.0372127
  0.0296755  0.02744165]
 [0.02849178 0.02240612 0.02110764 0.01593291 0.0124437  0.01590693
  0.02237321 0.0257676  0.02217144 0.01618885 0.01877614 0.01697945
  0.0230986  0.00978967 0.00687651 0.02025861 0.01983255 0.01828652
  0.02107679 0.02118984 0.02545171 0.02762927 0.01643851 0.01873458
  0.04313761 0.05604255]
 [0.02811693 0.01817269 0.01654452 0.01408842 0.01085729 0.01370781
  0.0205368  0.02220049 0.01851767 0.0148383  0.01941474 0.01469294
  0.02135447 0.00865139 0.00656899 0.02639404 0.02598151 0.02441866
  0.02905523 0.02476102 0.03282597 0.02509148 0.0139787  0.0177543
  0.09377102 0.05513732]
 [0.02814558 0.02495129 0.02255407 0.01803731 0.0137333  0.01723361
  0.02802694 0.03555373 0.02416078 0.02055595 0.03556103 0.02127293
  0.0331028  0.01100396 0.0082328  0.03217557 0.03089274 0.03000014
  0.03409434 0.02859784 0.0321332  0.02625996 0.01532171 0.01605686
  0.08913353 0.04214154]
 [0.02836199 0.02383358 0.0207971  0.01801073 0.01394716 0.01699727
  0.0272796  0.03193309 0.02346385 0.02176585 0.04302824 0.02060609
  0.03159492 0.01165038 0.00820523 0.02883656 0.03160723 0.03149691
  0.03352829 0.02790969 0.02848206 0.02572465 0.01452077 0.01391258
  0.07817967 0.03943745]
 [0.02888107 0.01838089 0.01877031 0.01548692 0.01217023 0.01571716
  0.02271216 0.02590761 0.023058   0.01832461 0.03085207 0.01738612
  0.0258503  0.0099583  0.00739419 0.02144473 0.02316173 0.02163359
  0.02667358 0.02370617 0.024295   0.02272316 0.013477   0.01169225
  0.05839229 0.03934672]
 [0.02751762 0.0281386  0.02788223 0.04902297 0.05373952 0.03892871
  0.02508756 0.02644808 0.03212902 0.04985293 0.03232299 0.02900129
  0.03328148 0.08655418 0.10197552 0.02703044 0.02581942 0.02693935
  0.02398082 0.02161861 0.0184491  0.03286146 0.03128286 0.00639371
  0.00497304 0.02236158]
 [0.02733481 0.02912774 0.02715487 0.05454462 0.10724964 0.03608998
  0.02072849 0.02271317 0.02741475 0.05422822 0.03763901 0.02919412
  0.02483678 0.08154757 0.10484995 0.03192916 0.03678759 0.04177494
  0.03255595 0.02654685 0.02255128 0.02968489 0.03062442 0.00618625
  0.00539917 0.01952896]
 [0.02729224 0.02382408 0.02336282 0.04111927 0.05961856 0.02626906
  0.01728347 0.02222314 0.02584936 0.04797254 0.03762662 0.03416898
  0.02831115 0.03031373 0.03258953 0.02270387 0.0391972  0.06948099
  0.05935351 0.04924005 0.02873587 0.02559478 0.02372353 0.01067756
  0.01282668 0.02080717]
 [0.02742814 0.02637217 0.02450398 0.03916107 0.05329756 0.02781539
  0.02017933 0.02238065 0.02943429 0.04271645 0.03323527 0.02812277
  0.02689857 0.03003204 0.03150157 0.01981337 0.03098355 0.04739456
  0.04774294 0.04233252 0.02629637 0.04464532 0.03267515 0.00863736
  0.00982541 0.01886062]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Bill', ' being', ' in', ' the', ' school', '.', ' Bill', ' is', ' mentioned', ' as', ' going', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' connection', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.025, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02321366 0.03749622 0.04009263 ... 0.00899319 0.0078491  0.00971167]
 [0.02388134 0.03506338 0.03609126 ... 0.01230465 0.01055479 0.01202371]
 [0.02431064 0.03344705 0.03734395 ... 0.01721243 0.0138958  0.01323147]
 ...
 [0.02432631 0.03376531 0.02816304 ... 0.0057513  0.00539294 0.00709537]
 [0.02462272 0.02500542 0.02043758 ... 0.0083279  0.00642699 0.00913471]
 [0.02478532 0.02742873 0.02196535 ... 0.0069743  0.00564829 0.00763348]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' The', ' previous', ' information', ' (', 'sentence', ' ', '4', ')', ' stated', ' that', ' Bill', ' went', ' to', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01956351 0.02796471 0.02784125 ... 0.00960457 0.01147457 0.02013537]
 [0.01997801 0.0220844  0.02396104 ... 0.04721127 0.05681205 0.03732482]
 [0.0205215  0.02936494 0.03145219 ... 0.00556109 0.00652956 0.01136045]
 ...
 [0.02066173 0.02733832 0.02511856 ... 0.00592461 0.00721369 0.01106371]
 [0.02110826 0.01950567 0.01759    ... 0.01187541 0.01709539 0.01803512]
 [0.02101233 0.02321856 0.0203127  ... 0.00795525 0.01120934 0.01604067]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' provide', ' information', ' about', ' Mary', "'s", ' location', ',', ' stating', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02587595 0.03770408 0.03834813 ... 0.05493681 0.00922846 0.01415764]
 [0.02624856 0.02946871 0.02898402 ... 0.04807322 0.01657491 0.02626581]
 [0.02705867 0.04083508 0.04167015 ... 0.0613926  0.01565541 0.01958893]
 ...
 [0.02717673 0.03924862 0.03901286 ... 0.01838887 0.00704536 0.00839014]
 [0.02785294 0.02863034 0.02602896 ... 0.00988543 0.00701095 0.00832934]
 [0.02762816 0.03167104 0.02892768 ... 0.0102722  0.00699757 0.00941488]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' provide', ' information', ' about', ' Mary', "'s", ' location', ',', ' stating', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', ',', ' but', ' then', ' updating', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' school', '.', ' This', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 50), x_tokens=50, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 50)
DEBUG result.interpretability.attn_scores 2350 
 [[0.01969739 0.02830266 0.031278   ... 0.03264195 0.0279458  0.01197807]
 [0.01995438 0.03160458 0.02981023 ... 0.02027665 0.04137636 0.01741178]
 [0.0205374  0.03125555 0.03492698 ... 0.03260128 0.02312357 0.0100116 ]
 ...
 [0.02072582 0.0287042  0.02822842 ... 0.04328325 0.02225919 0.00957226]
 [0.02124469 0.02234746 0.02069947 ... 0.03009427 0.02044455 0.0130149 ]
 [0.02109982 0.02210499 0.02057667 ... 0.05403093 0.01991808 0.01279172]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03739988 0.0569838  0.07012395 0.09153112 0.10131972 0.09187164
  0.06891912 0.08468901 0.07325032 0.08165932 0.06341736 0.07749253
  0.0845982  0.11149259 0.06908661 0.0400097  0.03849406 0.04264137
  0.034288   0.03944761 0.03441835 0.04952263 0.04719975 0.02739175
  0.02153519 0.03087861]
 [0.03712536 0.10328188 0.07818595 0.06972997 0.05247497 0.068846
  0.19876914 0.13354494 0.07889214 0.06394909 0.09245834 0.06804846
  0.11181814 0.03109307 0.02593289 0.05245592 0.04814234 0.07217769
  0.05048134 0.06410066 0.05453952 0.05813779 0.04643141 0.04800081
  0.03219486 0.03707562]
 [0.04079206 0.06852487 0.04379429 0.06359431 0.04696191 0.0428932
  0.03541857 0.02773111 0.0285293  0.04178739 0.03734155 0.02080869
  0.02364295 0.03602994 0.0457583  0.03154691 0.01844475 0.0184041
  0.02048183 0.0224152  0.02217015 0.05507031 0.05934337 0.01205574
  0.00734194 0.01426751]
 [0.0383895  0.04434075 0.04425687 0.02728415 0.01864774 0.03215915
  0.0313725  0.02961464 0.0389389  0.02889363 0.03118773 0.029659
  0.02857834 0.01340632 0.01286128 0.04154038 0.03740852 0.03924904
  0.04559033 0.04915983 0.04422739 0.04204195 0.06676716 0.06637736
  0.08872046 0.07496687]
 [0.03879575 0.04875499 0.05390665 0.07799046 0.0699476  0.05666987
  0.0382276  0.03595725 0.04307541 0.05524259 0.04560749 0.03259042
  0.03254055 0.11777413 0.11913428 0.04808114 0.03506962 0.0287053
  0.0263992  0.03028225 0.03079551 0.04899042 0.06857692 0.02098115
  0.01168377 0.030622  ]
 [0.03961113 0.03195249 0.03358383 0.06088716 0.05268477 0.05142226
  0.02878899 0.02833663 0.03670699 0.05178015 0.04054594 0.03700585
  0.03516755 0.12706098 0.14815502 0.04751569 0.03925787 0.03434977
  0.02968056 0.03230539 0.02965699 0.04197277 0.04161452 0.0148399
  0.0094175  0.02022921]
 [0.0402135  0.0355514  0.04258542 0.06331459 0.05684213 0.06468844
  0.03743608 0.03842676 0.0478162  0.06057008 0.04674855 0.05808379
  0.05293669 0.10056695 0.09154975 0.03922839 0.0350115  0.03341534
  0.02820184 0.03146457 0.02745583 0.03782047 0.03853377 0.01990053
  0.01320138 0.02030268]
 [0.0388412  0.04807342 0.05748132 0.05082736 0.05109007 0.06089422
  0.04198956 0.05038228 0.05295446 0.05510005 0.04751187 0.06364549
  0.05472519 0.0618927  0.0543056  0.05028537 0.04425331 0.04171867
  0.03508414 0.03946923 0.0363219  0.04426254 0.05738503 0.04022035
  0.03217683 0.04091096]
 [0.03909603 0.06009496 0.06854482 0.03942461 0.03233743 0.04993718
  0.04963618 0.05718531 0.05632121 0.04246528 0.04300275 0.05268707
  0.05220825 0.02884621 0.02036914 0.05009092 0.04038107 0.03878315
  0.03594853 0.03854268 0.03713886 0.03934207 0.06409667 0.04897823
  0.04643225 0.05481485]
 [0.04021806 0.0791387  0.08688075 0.03543995 0.02506636 0.0452793
  0.05168685 0.05121104 0.06221844 0.03581851 0.03476985 0.04416905
  0.04133099 0.01936196 0.01577196 0.05779908 0.04082314 0.03693027
  0.0347807  0.04098298 0.03650525 0.03792023 0.07587085 0.03987048
  0.03095655 0.03872177]
 [0.04017252 0.04440445 0.0514014  0.02796135 0.02175879 0.03271153
  0.0411118  0.04214638 0.04752485 0.03081953 0.03103979 0.03688134
  0.03322988 0.01662426 0.01498988 0.05462084 0.04241911 0.03664402
  0.03847719 0.04051827 0.03796396 0.03836526 0.05831132 0.0550658
  0.05313667 0.04780434]
 [0.04062121 0.0224379  0.02678166 0.01787537 0.0151556  0.02258985
  0.02472191 0.0276195  0.04018525 0.02241199 0.02138254 0.02321095
  0.0215764  0.01113826 0.01068662 0.03379326 0.03143028 0.02852193
  0.03361968 0.03640282 0.0326268  0.03059462 0.04176377 0.06317484
  0.07147428 0.07675144]
 [0.04028301 0.03002519 0.03173639 0.02241946 0.01852956 0.02949007
  0.02867402 0.03202137 0.03166585 0.02582924 0.02870259 0.03511097
  0.03014961 0.01228554 0.01201559 0.04644797 0.03643718 0.03557365
  0.03894321 0.03905711 0.03788719 0.03815771 0.03319684 0.05566835
  0.0781671  0.05214651]
 [0.04106282 0.04282202 0.04680443 0.04039297 0.02952779 0.0525508
  0.04383572 0.05435862 0.04834316 0.05180101 0.04811623 0.08021851
  0.05994297 0.02326549 0.01631739 0.03730179 0.03686125 0.04028955
  0.03691408 0.03777824 0.03413609 0.04023473 0.02736196 0.02789897
  0.02408333 0.02484024]
 [0.04165032 0.02947011 0.03134208 0.02485834 0.0209382  0.03051106
  0.03276983 0.03487038 0.03149319 0.02986006 0.03596756 0.03885715
  0.03650566 0.01342951 0.01216523 0.03834494 0.03466152 0.03366214
  0.03479994 0.03499714 0.03328661 0.03759926 0.02326925 0.04104134
  0.04008606 0.02350501]
 [0.04077435 0.02142238 0.01971984 0.01580125 0.01346796 0.01824212
  0.02091021 0.02386081 0.02311947 0.01913206 0.0267573  0.02393311
  0.02668847 0.00809652 0.00887119 0.0383811  0.03916168 0.03753581
  0.04593968 0.04067389 0.04172364 0.0348599  0.02072527 0.065474
  0.07771739 0.04159135]
 [0.04039429 0.02218493 0.01952076 0.01649644 0.01306165 0.01865074
  0.0295385  0.0334096  0.02431006 0.01983776 0.03120347 0.02452997
  0.03329071 0.00776996 0.00788586 0.03919119 0.04008471 0.04942124
  0.06164096 0.06044489 0.06522153 0.03219494 0.01826362 0.07571374
  0.0855042  0.04344939]
 [0.04112205 0.01982812 0.01781084 0.0147462  0.01268721 0.01800441
  0.02131924 0.02502023 0.02226699 0.01877052 0.02924716 0.02538209
  0.02725036 0.00752686 0.0073046  0.03234998 0.04543464 0.03665202
  0.0588101  0.04131152 0.04618919 0.03064558 0.0144085  0.05218445
  0.07437613 0.04355321]
 [0.04102539 0.01751318 0.01557679 0.01187547 0.01053748 0.01488256
  0.02095443 0.02250746 0.0208282  0.01539499 0.03382868 0.02153007
  0.02597452 0.00627956 0.00624176 0.0356974  0.04818982 0.04185246
  0.06681368 0.05086956 0.05273172 0.02999452 0.01437169 0.05244454
  0.04669254 0.06698368]
 [0.04011652 0.02196108 0.02005836 0.01472166 0.01298862 0.01914992
  0.02506904 0.02595223 0.02777393 0.01747906 0.02851059 0.02311601
  0.02671453 0.00781897 0.00751663 0.02925176 0.03480028 0.03603208
  0.04823378 0.04689173 0.05252758 0.03283841 0.02496188 0.0722974
  0.06886106 0.08501945]
 [0.04166859 0.02244791 0.02154516 0.01900076 0.01433236 0.02192201
  0.02225779 0.02595641 0.02645925 0.02160895 0.02763079 0.02790419
  0.02806279 0.01063815 0.00943905 0.02370642 0.02636607 0.02857097
  0.03983057 0.03668958 0.03744416 0.03286856 0.01737815 0.02935121
  0.03187659 0.03878353]
 [0.04051198 0.03149569 0.03114782 0.05041352 0.04880358 0.04698738
  0.02821193 0.03043084 0.03650556 0.05423271 0.04209462 0.04177146
  0.03870545 0.07938803 0.09351871 0.03187614 0.03505243 0.03479753
  0.02954839 0.0305445  0.03079731 0.03862724 0.03425633 0.0156234
  0.01256869 0.02227572]
 [0.04020496 0.03304172 0.03041211 0.05441781 0.10005963 0.04336295
  0.02639562 0.02822083 0.0344427  0.05919867 0.04710424 0.03932173
  0.03202355 0.08121757 0.10482436 0.03917574 0.04961797 0.04988073
  0.0348049  0.03391136 0.03765461 0.03600609 0.03335948 0.01269856
  0.00864049 0.01897916]
 [0.03969856 0.02854194 0.02617001 0.04303469 0.09337943 0.02979569
  0.02219036 0.02644194 0.02969651 0.04885306 0.04285952 0.03898633
  0.02975716 0.03219597 0.04482634 0.03232822 0.07334919 0.07395703
  0.05071528 0.04190521 0.06176172 0.03307979 0.03053708 0.0238699
  0.01850512 0.02861595]
 [0.04021093 0.0357061  0.03062849 0.04596103 0.06739953 0.03648764
  0.02979498 0.03010436 0.03668181 0.04750424 0.0429634  0.03505572
  0.0325811  0.03480053 0.0404719  0.02897974 0.04884762 0.05023414
  0.03997205 0.0398338  0.0448181  0.05885218 0.04201543 0.0188773
  0.01464973 0.02291086]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', "'s", ' location', '.', ' They', ' only', ' mention', ' Mary', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03340377 0.04056262 0.04114252 0.06270306 0.05871486 0.04427006
  0.03368266 0.03316754 0.04612658 0.05435071 0.03792741 0.0319122
  0.03603048 0.10067677 0.10709688 0.03413332 0.03415703 0.030404
  0.02837231 0.02939803 0.02731229 0.03438192 0.04824081 0.02142707
  0.01983324 0.03406584 0.04027436 0.03876413 0.0988943  0.06363796
  0.01293502 0.07385987]
 [0.03438653 0.04062599 0.0374426  0.07107747 0.07807869 0.07315639
  0.03632712 0.03569992 0.0443214  0.06315499 0.05018402 0.04650287
  0.04666845 0.14444292 0.11933243 0.03598191 0.03008015 0.02995665
  0.02749866 0.02929627 0.02722256 0.03746863 0.03681877 0.01825642
  0.01708888 0.02875634 0.04170084 0.03033155 0.08183263 0.07424179
  0.02118481 0.08465582]
 [0.03504783 0.03895741 0.04145459 0.06306044 0.0626668  0.05518485
  0.03450679 0.03639114 0.04415878 0.05380414 0.04012255 0.04307204
  0.04098757 0.10836374 0.082594   0.03164389 0.02976842 0.02566184
  0.02495625 0.0256995  0.02362151 0.03360809 0.03414512 0.02041459
  0.01857552 0.0262324  0.03922827 0.02721526 0.05568753 0.06892839
  0.0277555  0.06478946]
 [0.03394461 0.03751496 0.04115824 0.03810063 0.03378079 0.03775333
  0.03357277 0.03936967 0.04269525 0.03759516 0.03219369 0.03780567
  0.03684328 0.03279529 0.03015631 0.03172393 0.03118019 0.02738372
  0.02913686 0.03143417 0.02961861 0.03749617 0.04811534 0.04071599
  0.0378787  0.04584713 0.0491661  0.04495918 0.04837107 0.0739122
  0.04855956 0.04529552]
 [0.03419989 0.04952173 0.05040916 0.03148443 0.02395997 0.03181796
  0.0338576  0.03545328 0.04541206 0.02668703 0.02826981 0.02884027
  0.02924932 0.02635485 0.02335119 0.03091246 0.02772613 0.02265042
  0.02732934 0.02850978 0.0273834  0.03656472 0.05632003 0.034746
  0.03413552 0.04332027 0.05843824 0.03438184 0.03390946 0.0735127
  0.05400771 0.02559468]
 [0.03497041 0.06048736 0.06185467 0.02963282 0.02365437 0.03282708
  0.03894557 0.03753165 0.05176387 0.02633758 0.02848611 0.02970767
  0.0300198  0.02077672 0.02083609 0.03665998 0.03475163 0.02808338
  0.03125074 0.03458111 0.03075249 0.03323654 0.08151213 0.03986983
  0.03640977 0.04742471 0.04745432 0.02830354 0.03286809 0.0690852
  0.04017626 0.02150775]
 [0.03506919 0.04691389 0.05488476 0.02943168 0.02360749 0.0340229
  0.04193849 0.04211098 0.04547776 0.02469428 0.0294054  0.03025647
  0.0269685  0.0220657  0.02221727 0.03949678 0.03563872 0.02690841
  0.03117655 0.03291016 0.03101237 0.03722667 0.05866507 0.0432641
  0.04152104 0.04218037 0.05453919 0.02588932 0.03204508 0.06815535
  0.04952227 0.02269535]
 [0.03601162 0.03256639 0.03810378 0.03472967 0.0273858  0.03965104
  0.03435932 0.03941837 0.04663742 0.03580133 0.03158533 0.03896607
  0.03313677 0.02576621 0.02203142 0.02723029 0.02898011 0.02536519
  0.02828416 0.02845557 0.02497539 0.03557032 0.03190164 0.02646946
  0.02752807 0.03543528 0.03682703 0.02879869 0.03223655 0.0352632
  0.03986037 0.02929264]
 [0.03590757 0.03743917 0.03940145 0.03581979 0.02737538 0.0406058
  0.0409958  0.0466259  0.04037102 0.03571173 0.03346784 0.04889963
  0.04260442 0.0248112  0.02126758 0.03273326 0.0337818  0.03017555
  0.0324543  0.03115267 0.03007721 0.03653497 0.03005398 0.03348299
  0.03922498 0.03762853 0.03884788 0.03732457 0.03131836 0.03955287
  0.05964296 0.0246257 ]
 [0.03629822 0.04053777 0.04201923 0.04083224 0.03105124 0.0517262
  0.04021069 0.04456638 0.04101655 0.04494968 0.03826707 0.06331512
  0.05257551 0.03330686 0.02284644 0.03302617 0.03411598 0.0310532
  0.03409164 0.03305281 0.03089805 0.03660677 0.02979856 0.03128272
  0.03397882 0.03464844 0.04074986 0.03636451 0.03037105 0.03610616
  0.05296979 0.02171189]
 [0.03606411 0.04063592 0.03678816 0.03409391 0.02920723 0.03770252
  0.03828626 0.04226022 0.03372027 0.03540529 0.03489916 0.04468436
  0.04696905 0.02443925 0.02050804 0.03261821 0.03336615 0.03061335
  0.03338992 0.03225396 0.03141382 0.03616735 0.02790982 0.03763092
  0.04608452 0.03620657 0.03706478 0.03609452 0.03028482 0.03314284
  0.05175888 0.02084361]
 [0.0367071  0.03550348 0.04036123 0.03400591 0.0269274  0.04390375
  0.04125171 0.04426162 0.04030861 0.03526909 0.03409985 0.05291104
  0.04850273 0.02378695 0.02003831 0.03219913 0.03415767 0.02862415
  0.03241241 0.03154069 0.03030851 0.0360776  0.0269845  0.03166094
  0.03547908 0.03006742 0.032714   0.03286096 0.02754479 0.02828887
  0.04228408 0.02013532]
 [0.03572585 0.0313339  0.02889664 0.02498855 0.02110019 0.02349451
  0.03867375 0.0353496  0.02543351 0.0244649  0.03513068 0.02629545
  0.0384149  0.01491599 0.01732983 0.04424276 0.03827304 0.03560101
  0.03710534 0.03718501 0.04328705 0.03682463 0.02459091 0.0674836
  0.05259658 0.03079104 0.02175386 0.04619132 0.02660308 0.01855995
  0.04996132 0.01821738]
 [0.03567805 0.025866   0.0238014  0.02124224 0.01763964 0.02067512
  0.02977884 0.02858193 0.02306822 0.02017118 0.0291722  0.02217165
  0.02546401 0.01252344 0.01552472 0.03627592 0.03503    0.033352
  0.04122573 0.04032529 0.04838887 0.03444241 0.02449606 0.0685023
  0.07402411 0.04429386 0.02100496 0.053164   0.02584781 0.01886507
  0.05298859 0.01979188]
 [0.03570908 0.04048808 0.03329591 0.02720113 0.02190065 0.02658921
  0.052139   0.05231119 0.02933625 0.02690207 0.05965573 0.03319585
  0.04572431 0.01555378 0.01953088 0.06025756 0.05473001 0.05723399
  0.0556711  0.05513367 0.06520108 0.03797837 0.02743335 0.0752784
  0.06362988 0.04991655 0.02836323 0.05359139 0.02929161 0.01699389
  0.05295099 0.01648013]
 [0.03692693 0.02570697 0.02633948 0.02264486 0.01831855 0.02360912
  0.02957787 0.03299788 0.02737503 0.02261193 0.04315248 0.0277163
  0.02932228 0.01448149 0.01568309 0.03572457 0.04128772 0.03408985
  0.04133046 0.03860679 0.04359411 0.03153938 0.02116967 0.0442966
  0.04473006 0.0401904  0.02194406 0.04092297 0.02253502 0.01772798
  0.0351728  0.02034912]
 [0.03582881 0.02795203 0.02972059 0.03182565 0.02564944 0.03337182
  0.02891133 0.03148034 0.03877609 0.03642496 0.03058831 0.0382351
  0.03544969 0.02558414 0.02244243 0.02853253 0.03102625 0.02820477
  0.03055426 0.03058206 0.02891076 0.03766903 0.03433332 0.03481778
  0.03862133 0.04033434 0.03466353 0.04149838 0.04199744 0.0446865
  0.03252816 0.03677821]
 [0.03703451 0.03256514 0.03482033 0.02613615 0.02116096 0.02989662
  0.03669437 0.03516894 0.02990622 0.02429286 0.02807885 0.02919839
  0.0291603  0.0165825  0.01703248 0.02965079 0.02970043 0.02478623
  0.0280712  0.02925823 0.027186   0.03662718 0.02868877 0.02679246
  0.03108048 0.02954026 0.0365655  0.01805873 0.02294485 0.02515975
  0.03520852 0.01388907]
 [0.03731877 0.03349324 0.03412547 0.02575541 0.02073382 0.0313004
  0.04195006 0.04108672 0.02915229 0.02579101 0.02824446 0.03151687
  0.03529355 0.01680478 0.01660908 0.02998705 0.02954007 0.02592643
  0.02721937 0.02850122 0.02615979 0.03537804 0.02813462 0.02576687
  0.02988817 0.02800742 0.03259513 0.01816922 0.02366709 0.02355974
  0.03716967 0.01347665]
 [0.03673552 0.02709848 0.02504518 0.01889856 0.01725937 0.02236368
  0.03385182 0.03007748 0.02256066 0.02018193 0.02841007 0.02214374
  0.02985199 0.0130674  0.01483898 0.03415055 0.03510377 0.02816658
  0.03141482 0.03108515 0.03193689 0.03407184 0.02339747 0.03672956
  0.03839377 0.0274647  0.0247257  0.01855179 0.01955312 0.01750925
  0.03494528 0.01239251]
 [0.03625008 0.02277237 0.02083001 0.01575029 0.01481632 0.0186108
  0.02971523 0.02542431 0.01980115 0.01761215 0.02629097 0.01932607
  0.02526263 0.01104346 0.01324557 0.04273487 0.04373475 0.03995857
  0.04156262 0.04020451 0.04186603 0.03160676 0.01999715 0.03829625
  0.04314939 0.03147285 0.02063645 0.02210641 0.01850223 0.01373045
  0.03436051 0.01476149]
 [0.03661273 0.03280618 0.02668298 0.01760549 0.01682181 0.02160861
  0.03986947 0.03449971 0.0234033  0.0196031  0.03651468 0.02402581
  0.03313239 0.01215596 0.01498012 0.05576503 0.04080217 0.04385377
  0.03845553 0.04058872 0.0373943  0.0343802  0.02144301 0.03791113
  0.0369848  0.03070059 0.02819681 0.02098321 0.01918192 0.01482808
  0.03367044 0.01227113]
 [0.03700709 0.02557527 0.02483414 0.01812451 0.01754761 0.02272526
  0.0315717  0.02810279 0.02423115 0.02040235 0.0328916  0.02427773
  0.02893995 0.01341143 0.0146025  0.04440672 0.03956037 0.04128356
  0.03953778 0.04303285 0.03815465 0.03078793 0.0194781  0.03289772
  0.031864   0.0322986  0.02439285 0.02013312 0.01767921 0.01565805
  0.02984968 0.01781531]
 [0.03542409 0.031893   0.03356757 0.05074217 0.05322971 0.0453938
  0.03447209 0.03105304 0.04193639 0.05510516 0.03882304 0.03780722
  0.03838863 0.07516187 0.09814189 0.03055452 0.03308649 0.03666278
  0.03521926 0.03414269 0.03339845 0.03781116 0.03543564 0.0180473
  0.01897886 0.02772147 0.03639908 0.03593347 0.0485144  0.02875928
  0.01114075 0.0914138 ]
 [0.03477732 0.03847286 0.03442519 0.06962097 0.13199079 0.05106211
  0.03188979 0.0293784  0.03664732 0.07287859 0.05314129 0.04744622
  0.03625082 0.08056911 0.10462111 0.03883038 0.05050112 0.07929453
  0.05496677 0.0493486  0.04845401 0.03671496 0.04375833 0.01927442
  0.01684497 0.02937881 0.04391189 0.04085521 0.04474139 0.02336498
  0.00941041 0.0890393 ]
 [0.03508502 0.03313914 0.0296712  0.03453391 0.04647876 0.02988835
  0.02625096 0.02718692 0.02958592 0.03912198 0.03326506 0.03557246
  0.031123   0.02791749 0.03677021 0.03362143 0.04196122 0.05903906
  0.05037159 0.04834812 0.04937254 0.03337375 0.05041857 0.04427037
  0.0453446  0.05636304 0.04001284 0.0675378  0.03895619 0.02349382
  0.02125109 0.0511328 ]
 [0.03582352 0.03870272 0.03691725 0.05102413 0.06666736 0.04066725
  0.03337324 0.03321939 0.03932635 0.05828603 0.04175834 0.04890738
  0.03649306 0.03400608 0.03512132 0.02999428 0.03737056 0.05888904
  0.04760575 0.04500147 0.04859624 0.03574761 0.04365227 0.02618097
  0.02343879 0.03195819 0.03720742 0.05242285 0.02867462 0.01620687
  0.01482143 0.04497069]
 [0.03605177 0.030868   0.0320061  0.03893394 0.04227504 0.03612149
  0.03334577 0.02722462 0.03745054 0.04238886 0.03597392 0.0352903
  0.03117261 0.02863458 0.03124983 0.02691181 0.03058815 0.03677803
  0.03933529 0.04037094 0.04350306 0.04410703 0.04310709 0.02423331
  0.02269206 0.02775454 0.03062183 0.04859199 0.03594629 0.0170688
  0.01391324 0.07221296]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' explicitly', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 38), x_tokens=38, y_tokens=21, max_supp_attn=0.0476, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 38)
DEBUG result.interpretability.attn_scores 798 
 [[0.04504929 0.05249947 0.05743859 0.07000107 0.06335743 0.06763493
  0.05132193 0.05761338 0.05972061 0.06200617 0.04299819 0.05030646
  0.05978002 0.09769931 0.09865177 0.03823422 0.03793448 0.0327506
  0.03632636 0.03412853 0.03279335 0.04850147 0.06605279 0.03095166
  0.03210964 0.05400041 0.06488879 0.06348566 0.12591943 0.06238715
  0.01374725 0.07103202 0.12096998 0.07903792 0.03269498 0.02135549
  0.05535423 0.06602581]
 [0.04629866 0.08672971 0.06617302 0.05470561 0.04999482 0.06215839
  0.08117936 0.10817136 0.0670341  0.05409878 0.04762288 0.06462041
  0.09413928 0.05221295 0.06490798 0.04329006 0.05408285 0.04190803
  0.05203189 0.04110219 0.03774978 0.06177177 0.04595897 0.03303795
  0.03847583 0.0504648  0.05147376 0.05509564 0.07163686 0.05271009
  0.02411766 0.02835728 0.0587387  0.04015748 0.03218029 0.02816756
  0.04345671 0.05312859]
 [0.04703488 0.06103276 0.07164568 0.09638743 0.09747321 0.11158777
  0.06530185 0.0674509  0.07632585 0.08761688 0.06048156 0.07516322
  0.08154652 0.1804039  0.1204889  0.04498712 0.03883278 0.0337069
  0.03417541 0.03081765 0.02999783 0.05354962 0.05718962 0.02953866
  0.02986565 0.04434666 0.05301231 0.04931298 0.08011221 0.0755395
  0.02988201 0.06951788 0.07080396 0.06033299 0.02593775 0.01833628
  0.04723847 0.03819449]
 [0.04549198 0.05492057 0.05921667 0.0475197  0.04328113 0.05526542
  0.05206852 0.05516263 0.05428376 0.0485713  0.0433755  0.05069776
  0.05488669 0.04114676 0.03799912 0.05099598 0.0452732  0.03643681
  0.03888489 0.03647205 0.03605547 0.05311137 0.06781038 0.06036503
  0.061894   0.0601081  0.05835672 0.05318801 0.05877601 0.09991024
  0.05543205 0.04000233 0.04074667 0.04705264 0.06329235 0.04781461
  0.06259015 0.05328779]
 [0.04639816 0.05541786 0.05758676 0.03239542 0.02647908 0.04151191
  0.04927192 0.04448633 0.04805087 0.03426738 0.03727768 0.03667599
  0.04081301 0.02732517 0.02636321 0.04621415 0.03716665 0.03056419
  0.0358411  0.03490421 0.03354718 0.05030559 0.06850965 0.05338003
  0.05163785 0.0551128  0.06769596 0.03780199 0.04233685 0.09304871
  0.049115   0.02157141 0.02469936 0.03993287 0.06460954 0.04944351
  0.0508247  0.04355093]
 [0.04741466 0.0685457  0.06775808 0.03580115 0.02706852 0.04568554
  0.05786083 0.04665403 0.06273204 0.03651522 0.03551048 0.03701773
  0.04085277 0.02657088 0.02680237 0.05447461 0.04260222 0.03235854
  0.03820334 0.03778233 0.03367991 0.04448155 0.08937486 0.0520244
  0.0453094  0.05342594 0.06640035 0.03340385 0.04129033 0.09802007
  0.0398745  0.02010657 0.03008374 0.04770529 0.07279344 0.04230711
  0.04360421 0.0427615 ]
 [0.04771886 0.05099569 0.05339697 0.03319069 0.02586051 0.03926561
  0.05492423 0.04147639 0.05201756 0.03360714 0.03491956 0.03504245
  0.03548237 0.02607448 0.02693692 0.04897754 0.03911959 0.02930191
  0.03738549 0.03596591 0.03316041 0.04446304 0.066716   0.06025482
  0.05576876 0.05321443 0.06861369 0.03609817 0.04241428 0.09872505
  0.05401902 0.02516353 0.03257088 0.05109848 0.07012197 0.05343779
  0.04922281 0.04206601]
 [0.04811788 0.03252241 0.03473688 0.02348704 0.01882295 0.02677988
  0.03352817 0.02789715 0.03573074 0.0249382  0.02988151 0.02496612
  0.02684204 0.01838418 0.02076566 0.04164225 0.03564294 0.0277959
  0.03633454 0.03545378 0.03179791 0.03768925 0.04352564 0.05841158
  0.06229171 0.04923229 0.04642626 0.03317967 0.03213334 0.05152126
  0.02820327 0.0191948  0.03304714 0.04036514 0.05842615 0.05658715
  0.03781066 0.04167325]
 [0.04708399 0.04498057 0.04767865 0.03612211 0.02700698 0.04249045
  0.04868709 0.04320227 0.04615051 0.03829323 0.04361131 0.05064137
  0.04580904 0.0270634  0.02529918 0.06098321 0.05337079 0.05597349
  0.05188059 0.05618307 0.04783167 0.04908259 0.04654849 0.0639866
  0.06769412 0.05463756 0.05519866 0.03969875 0.03840538 0.08018756
  0.14164385 0.02123424 0.02508301 0.03794527 0.05308852 0.05110031
  0.04568975 0.03745725]
 [0.04854897 0.04739574 0.04918768 0.04771941 0.03249971 0.0515324
  0.0471348  0.04720977 0.04945666 0.05054584 0.04758404 0.05779579
  0.05351511 0.0326886  0.02642595 0.0352126  0.03176195 0.03307006
  0.03618596 0.03772692 0.03700217 0.04645388 0.04042909 0.04299689
  0.046488   0.04611447 0.05042107 0.04557924 0.04194264 0.06884729
  0.17573078 0.04588663 0.04027041 0.04478392 0.04616707 0.04346501
  0.05319494 0.04377276]
 [0.04905916 0.0413727  0.04341672 0.03738454 0.02665397 0.04100643
  0.04384669 0.03888411 0.04052736 0.03843756 0.04346982 0.04219516
  0.04116419 0.02496534 0.02351285 0.04143604 0.03599947 0.03421098
  0.03772762 0.03909709 0.03905525 0.04379339 0.03884085 0.05557501
  0.06104924 0.04133068 0.04434787 0.04147866 0.03583251 0.03551031
  0.11954094 0.03753789 0.0257048  0.04054596 0.05165832 0.04958502
  0.05010094 0.03820363]
 [0.04812138 0.03246693 0.03062312 0.02535573 0.01808454 0.02727725
  0.03434009 0.02971623 0.03094767 0.02624637 0.03991045 0.03150198
  0.03313345 0.01693377 0.0176982  0.05335718 0.05055242 0.04679221
  0.04524234 0.04980091 0.04932171 0.04502564 0.02912475 0.06350352
  0.06393478 0.03504021 0.03093284 0.03617562 0.02712135 0.0188805
  0.06115964 0.02021424 0.01725119 0.03204179 0.07866607 0.07684671
  0.04365566 0.03918227]
 [0.0474062  0.03531995 0.03132305 0.0281445  0.01896221 0.02829903
  0.03972177 0.03469713 0.03297336 0.02792611 0.0394305  0.03227945
  0.03643321 0.01788197 0.0183495  0.06449806 0.05477201 0.0731101
  0.0523713  0.06544484 0.05989405 0.04392498 0.0260533  0.0603288
  0.06713675 0.04057865 0.0310948  0.04034414 0.02385451 0.01355045
  0.04166739 0.01526438 0.01809787 0.03053449 0.07972194 0.12027661
  0.04370368 0.0527815 ]
 [0.04928614 0.03656616 0.03480707 0.03165722 0.02220085 0.03299436
  0.04098786 0.03738605 0.03600512 0.03194583 0.04954544 0.03977732
  0.03980917 0.02046285 0.01971566 0.06222605 0.04689252 0.0753463
  0.053808   0.08993574 0.06505061 0.0403582  0.02562997 0.05374838
  0.04796851 0.03995195 0.03635824 0.03670416 0.0240082  0.01406568
  0.03801582 0.01713099 0.01830954 0.0303791  0.05020693 0.10222231
  0.03994594 0.03425513]
 [0.04932487 0.03192208 0.03084149 0.02631504 0.0193217  0.0259365
  0.03510223 0.03099683 0.0308054  0.02745628 0.04927634 0.03418297
  0.03277896 0.016672   0.01737544 0.05876506 0.04885044 0.0549757
  0.05651646 0.06704113 0.05390174 0.04297765 0.0262336  0.05364875
  0.04208421 0.0406387  0.02925934 0.03404652 0.02209761 0.01136581
  0.02848768 0.01784442 0.01866674 0.03061077 0.04259335 0.07685188
  0.0358812  0.03508241]
 [0.04787088 0.04246635 0.04270315 0.03822617 0.02817289 0.04156597
  0.05457893 0.0542272  0.04815588 0.04109383 0.05088818 0.04618502
  0.0518586  0.02395703 0.02308443 0.04320554 0.04839831 0.04545007
  0.06107054 0.05532203 0.05075161 0.05071366 0.04358679 0.05908034
  0.05128369 0.05769531 0.03692507 0.05177767 0.03697757 0.01981244
  0.02518437 0.02743984 0.03945018 0.0459762  0.03846167 0.04960878
  0.03949316 0.06193638]
 [0.04958226 0.03548637 0.03810783 0.03785172 0.02538443 0.03567316
  0.03816637 0.04212532 0.03634048 0.0408758  0.05057747 0.046631
  0.04199576 0.02515537 0.02289457 0.03932843 0.0438919  0.04220156
  0.05282521 0.04763858 0.04695133 0.04668931 0.02706457 0.03512575
  0.03603734 0.03713704 0.02734291 0.03982511 0.03066564 0.02057873
  0.02823229 0.04202535 0.01897101 0.02902578 0.0226483  0.0251184
  0.03530836 0.03299203]
 [0.04787526 0.04001554 0.04313987 0.06279733 0.05474914 0.05613313
  0.041806   0.04509383 0.04726498 0.0633604  0.04926247 0.05228174
  0.04993374 0.0896406  0.10199494 0.03411095 0.03691768 0.03753105
  0.03947783 0.03787816 0.03949594 0.04649252 0.04133062 0.02911295
  0.03191804 0.04300971 0.04008314 0.05761604 0.06522404 0.03005218
  0.01325259 0.13121346 0.07747159 0.05666009 0.02573116 0.01922046
  0.04794851 0.05478837]
 [0.04719038 0.05567542 0.055177   0.10797404 0.22896829 0.0809262
  0.04879908 0.05676425 0.05715292 0.10734694 0.08348847 0.0851114
  0.05396568 0.1345627  0.16271445 0.05029097 0.07136455 0.0768409
  0.05882963 0.04931424 0.06556596 0.04686759 0.05848782 0.03033272
  0.02918636 0.04979893 0.06154178 0.0688974  0.07014276 0.02764021
  0.00912442 0.1392596  0.08990726 0.08026128 0.02761867 0.01590997
  0.06432753 0.04908092]
 [0.04759545 0.04435648 0.03944919 0.05785457 0.08108896 0.03929805
  0.03619101 0.04080675 0.03657421 0.06113405 0.06534205 0.05648348
  0.04048502 0.04148997 0.05753978 0.04962404 0.08541159 0.10133021
  0.08812381 0.06415404 0.1124727  0.04464776 0.04145135 0.04472389
  0.04251384 0.04843326 0.04205355 0.06597346 0.03986721 0.01439518
  0.01490424 0.08521917 0.03733347 0.04522325 0.03560305 0.03155965
  0.05974312 0.05340783]
 [0.04753075 0.04931162 0.04559253 0.06910951 0.06456868 0.04697764
  0.04518122 0.04997808 0.05174995 0.06371662 0.05554615 0.05044315
  0.04477538 0.05870878 0.0604793  0.03814597 0.06116165 0.05834453
  0.05675773 0.05383656 0.06392349 0.0590992  0.0500809  0.02987229
  0.03535224 0.04572801 0.03757288 0.08031735 0.04924125 0.0132516
  0.00866523 0.104784   0.16182248 0.09032926 0.02777846 0.02078532
  0.05090531 0.08637115]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', ' being', ' in', ' the', ' kitchen', '.', ' In', ' fact', ',', ' sentence', ' ', '10', ' states', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.1944, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02602414 0.03637565 0.03505114 ... 0.01989307 0.05674865 0.04741452]
 [0.02640866 0.0305332  0.03436637 ... 0.02262375 0.01973952 0.02765756]
 [0.02703508 0.0397852  0.04201755 ... 0.02369381 0.03568863 0.03875114]
 ...
 [0.02719226 0.03671994 0.03368921 ... 0.00924704 0.10265251 0.04775281]
 [0.02765209 0.03062806 0.0258463  ... 0.00896623 0.07938362 0.0284498 ]
 [0.02768469 0.03208603 0.0271428  ... 0.00943778 0.08435633 0.04493958]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' (', 'from', ' previous', ' parts', ')', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' has', ' moved', ' from', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.125, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02332616 0.02458316 0.0228673  ... 0.02048062 0.03188051 0.04567282]
 [0.0235316  0.02323401 0.02251602 ... 0.02888219 0.0360927  0.02941576]
 [0.02415786 0.02745182 0.02805826 ... 0.01579984 0.02666889 0.03370028]
 ...
 [0.02440606 0.02690469 0.02442586 ... 0.01599479 0.03390236 0.03890215]
 [0.02474369 0.02167596 0.01931849 ... 0.02260735 0.03364772 0.03523845]
 [0.02468109 0.02345659 0.02124632 ... 0.01703354 0.02922683 0.0430451 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03722049 0.06192299 0.07576098 0.08796579 0.08947363 0.09121011
  0.08453684 0.0997768  0.07460977 0.07949992 0.06258367 0.07701273
  0.09205272 0.09217175 0.05421434 0.03929915 0.03896625 0.04437365
  0.04075106 0.04491104 0.03702319 0.05096393 0.04664397 0.02424327
  0.02968565 0.04502264]
 [0.0378722  0.06924229 0.05939182 0.07631078 0.06562671 0.06696501
  0.06293804 0.06267552 0.05663016 0.05858905 0.04976486 0.04446259
  0.05244546 0.1112524  0.10512884 0.04033162 0.03574939 0.03530856
  0.03522009 0.0368974  0.03041623 0.04997639 0.04878373 0.01751434
  0.01979184 0.03904768]
 [0.04083787 0.06676115 0.04022266 0.06032707 0.04351486 0.04176876
  0.03856799 0.02828985 0.02768523 0.04040613 0.03533269 0.02038189
  0.02480229 0.03070876 0.03786158 0.02754011 0.01735903 0.01851416
  0.02380999 0.0245116  0.02179808 0.05631158 0.05499766 0.00920638
  0.00975905 0.02040485]
 [0.03836653 0.0414854  0.04976883 0.0293599  0.02001295 0.03451383
  0.0392608  0.03455112 0.0439911  0.03169227 0.0332507  0.03367675
  0.03271824 0.01464005 0.01403741 0.04752591 0.03975376 0.0406009
  0.04264983 0.04485459 0.04520574 0.0420125  0.06877775 0.07407799
  0.08871477 0.06453194]
 [0.03888355 0.04796105 0.05024212 0.07485175 0.06547491 0.05500785
  0.04186729 0.03666484 0.04163136 0.05342271 0.04318756 0.03133597
  0.03375587 0.1019043  0.10262655 0.04274452 0.03311759 0.02847921
  0.03029582 0.03271367 0.03004593 0.0497337  0.06436427 0.01599863
  0.01474228 0.0440161 ]
 [0.03958458 0.03098903 0.030816   0.05778041 0.04949667 0.05004611
  0.03127297 0.02872343 0.03542762 0.04991923 0.03815346 0.03561864
  0.03662579 0.11384714 0.13362159 0.04300304 0.03801964 0.03499003
  0.03463524 0.03544955 0.02924941 0.04266248 0.0390102  0.01155212
  0.01208084 0.02876642]
 [0.04018481 0.03445897 0.03976703 0.0601445  0.05331433 0.06259801
  0.04034092 0.03883132 0.04624732 0.0583486  0.04433526 0.0557813
  0.05480955 0.09159932 0.08491828 0.03620809 0.03450846 0.03409661
  0.03297026 0.03456383 0.02740234 0.03821898 0.03688547 0.01557783
  0.01612032 0.02756469]
 [0.03885689 0.05010386 0.06002493 0.05139192 0.04936494 0.06135174
  0.04807136 0.05402098 0.05370549 0.05485188 0.04732617 0.06439384
  0.05766877 0.05740928 0.05016342 0.04947729 0.04486661 0.04260372
  0.0393024  0.04168062 0.03632282 0.04340424 0.05314212 0.03728431
  0.03796823 0.04668209]
 [0.03922592 0.05917606 0.06881879 0.03991324 0.03107703 0.05017085
  0.05716578 0.06077147 0.0604303  0.04357603 0.04203239 0.05397034
  0.055268   0.02678421 0.01906907 0.04919499 0.04056115 0.03966493
  0.03885812 0.04077422 0.03804243 0.03890029 0.06266022 0.04491312
  0.05132445 0.05705827]
 [0.04023156 0.07680115 0.08277292 0.03427376 0.02379549 0.0439194
  0.05601349 0.05194435 0.06198649 0.03509416 0.03357755 0.04308629
  0.0423595  0.01732029 0.01430935 0.05417146 0.04027996 0.03740357
  0.03957918 0.04419546 0.03734117 0.03779493 0.07143211 0.03530149
  0.03953975 0.0454176 ]
 [0.04025669 0.04569846 0.05156574 0.02708164 0.02061013 0.03199788
  0.04588586 0.04359646 0.04766491 0.02986687 0.03010309 0.03601753
  0.03389035 0.01501965 0.0136186  0.05259119 0.04157776 0.03661433
  0.04078165 0.04319286 0.03922804 0.03752576 0.05789742 0.05420199
  0.05953183 0.04750263]
 [0.04051295 0.02646561 0.02978642 0.01823232 0.01542999 0.02294536
  0.0294026  0.0308186  0.04172961 0.02294794 0.02204823 0.02415835
  0.02402598 0.01052752 0.01059202 0.0373668  0.03523114 0.03157126
  0.03829439 0.04287801 0.039881   0.03319345 0.05261751 0.07595805
  0.09083379 0.05297088]
 [0.04043182 0.03389945 0.03638776 0.023619   0.01904818 0.03147442
  0.03598436 0.03548532 0.03517498 0.02712876 0.0302792  0.03669426
  0.03262961 0.01225937 0.01207019 0.04731308 0.03571638 0.03482858
  0.03562213 0.03748417 0.03716854 0.03657572 0.03643473 0.06041387
  0.07049191 0.05149665]
 [0.04110231 0.04359412 0.04692025 0.04008489 0.02874101 0.05117768
  0.04966508 0.05580095 0.04688945 0.05103682 0.05025887 0.07798025
  0.06202865 0.0214498  0.0150917  0.03627216 0.03676321 0.04081798
  0.03846045 0.03932876 0.03424991 0.04008684 0.02604269 0.02687304
  0.02723797 0.02733812]
 [0.04153457 0.03208885 0.03290608 0.025955   0.0212763  0.03047762
  0.03744336 0.03656785 0.03142923 0.03064241 0.03767288 0.0391378
  0.0380256  0.0130974  0.01182225 0.03682916 0.03307145 0.03289721
  0.03379036 0.03549488 0.03476959 0.03755686 0.02362498 0.04276602
  0.03686141 0.02602924]
 [0.04081864 0.02486134 0.02192855 0.01690906 0.01441253 0.01904503
  0.02664817 0.02601781 0.02391843 0.02012178 0.03184181 0.02598834
  0.02877249 0.0080583  0.0088472  0.0401524  0.0367115  0.03677905
  0.03561047 0.03705403 0.0465121  0.03406671 0.02143764 0.07505637
  0.06336262 0.03390093]
 [0.04039158 0.02341532 0.01928837 0.01568098 0.01252189 0.01744235
  0.0281998  0.03052765 0.02278505 0.018569   0.0296046  0.02276073
  0.02921261 0.00707777 0.0074406  0.04036493 0.04070553 0.05038977
  0.04341822 0.04332962 0.06525023 0.03128213 0.01892916 0.08359554
  0.067212   0.04352086]
 [0.04116631 0.02272727 0.01941287 0.0151161  0.01309774 0.01825316
  0.02529622 0.0262831  0.02268329 0.01903636 0.03535508 0.02783127
  0.02882445 0.00723362 0.00716557 0.03727513 0.04018649 0.04041163
  0.04280715 0.03937647 0.05073487 0.03002475 0.01622723 0.07239331
  0.04973434 0.0288177 ]
 [0.04089392 0.02181542 0.01817755 0.01246957 0.0114392  0.01566704
  0.027258   0.02557853 0.02223415 0.01639477 0.05282741 0.02717814
  0.02815511 0.00616213 0.00645721 0.04449671 0.04397768 0.04694809
  0.05285744 0.04550496 0.05760882 0.02961129 0.01619655 0.07408378
  0.04820676 0.03929645]
 [0.03954379 0.03289667 0.02913388 0.02000343 0.02056621 0.02763757
  0.05187704 0.04691251 0.0426349  0.02649207 0.04159658 0.03378484
  0.04325501 0.01142498 0.01147258 0.0441811  0.04685925 0.0576942
  0.06567905 0.06880645 0.06445728 0.03784744 0.03470064 0.06364863
  0.06227777 0.0757455 ]
 [0.04164257 0.02525039 0.02488927 0.02160914 0.01601462 0.02320487
  0.02626568 0.02992149 0.02905896 0.02454305 0.03106274 0.03065619
  0.02990793 0.01101142 0.0095908  0.0281025  0.027327   0.03294248
  0.03908828 0.0342943  0.03756926 0.03272726 0.0171237  0.02836885
  0.03695942 0.03542414]
 [0.04054569 0.03032809 0.02849193 0.04669964 0.04449092 0.04420118
  0.03016759 0.03003131 0.03466268 0.05076081 0.03969369 0.03960672
  0.03919465 0.0736975  0.08510567 0.02919206 0.03439312 0.03527366
  0.03427471 0.03322412 0.02996542 0.03918578 0.03213581 0.0122291
  0.01634168 0.0308438 ]
 [0.04019824 0.03203639 0.0279639  0.05208164 0.09420212 0.04236016
  0.02861236 0.0283526  0.03319245 0.0572581  0.04523671 0.03821139
  0.03339217 0.07441304 0.09565496 0.03553215 0.04795222 0.04862093
  0.0399885  0.03654518 0.03591226 0.03650556 0.03113917 0.01017861
  0.01119918 0.02616625]
 [0.03960764 0.03028088 0.02623144 0.04647026 0.10694105 0.0312461
  0.0251603  0.02750255 0.02933617 0.05274199 0.04761123 0.04275287
  0.03257765 0.03703764 0.04979679 0.03264187 0.08266034 0.06947172
  0.05627989 0.04258304 0.05262934 0.03415915 0.02932808 0.01897359
  0.02117072 0.03165669]
 [0.04008881 0.03573976 0.02932991 0.04566818 0.07005661 0.03531795
  0.03209809 0.03035364 0.03426091 0.0470592  0.04526358 0.03752095
  0.03360153 0.0338923  0.03932346 0.02819258 0.05368513 0.04870384
  0.0449754  0.04035124 0.04121599 0.05967223 0.0394672  0.01558977
  0.01885146 0.03077797]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentence', ' ', '5', ' only', ' mentions', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.1562, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02916818 0.03979078 0.04072927 ... 0.05645379 0.01197775 0.07602034]
 [0.02988218 0.04175816 0.03876706 ... 0.06493483 0.01945924 0.08490289]
 [0.03050917 0.0377822  0.04058041 ... 0.06290475 0.02781118 0.06705794]
 ...
 [0.03043009 0.03287124 0.03060023 ... 0.01950755 0.00880394 0.0916428 ]
 [0.03093385 0.02661956 0.02482188 ... 0.01216395 0.01323271 0.05258497]
 [0.03105542 0.02804391 0.02624166 ... 0.01114761 0.01185012 0.06948138]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 38), x_tokens=38, y_tokens=21, max_supp_attn=0.1429, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 38)
DEBUG result.interpretability.attn_scores 798 
 [[0.0451552  0.05966403 0.06282704 0.07926362 0.06832802 0.07986893
  0.06157076 0.05707943 0.0730924  0.07304651 0.05253209 0.05799234
  0.065266   0.11870763 0.11090748 0.04494295 0.04115452 0.03852217
  0.03443426 0.0376964  0.03521227 0.05047699 0.07448358 0.03240734
  0.02577068 0.05115215 0.05083849 0.06660062 0.13514808 0.06398028
  0.01419924 0.07429495 0.12331093 0.08746045 0.04047567 0.02961492
  0.05749369 0.05550195]
 [0.04603438 0.04819876 0.05132909 0.04542436 0.03896068 0.05396823
  0.05531593 0.05471188 0.05645315 0.0467855  0.04124995 0.05158292
  0.06263188 0.04403067 0.0532661  0.04257489 0.04086845 0.03801711
  0.04167671 0.04280706 0.03575563 0.0524683  0.05004524 0.03813607
  0.03612181 0.04581309 0.05239414 0.03949667 0.07560264 0.07923605
  0.02966483 0.03134316 0.05840433 0.04431611 0.04519674 0.03637743
  0.04945293 0.04232122]
 [0.04707312 0.06409209 0.07300989 0.09665148 0.09499791 0.10547074
  0.07001915 0.06338921 0.07479847 0.08141298 0.06123741 0.07258372
  0.07823744 0.17106123 0.12263142 0.05012505 0.04011101 0.03731518
  0.03277403 0.03561271 0.03151214 0.05263792 0.06252178 0.0341348
  0.02527961 0.04597975 0.05967456 0.05189101 0.08620682 0.07299542
  0.0241546  0.06988112 0.07518251 0.06735067 0.03291741 0.02530436
  0.0512152  0.03442871]
 [0.04572655 0.05297779 0.05841989 0.04896255 0.04082216 0.05733324
  0.0568746  0.05891594 0.05766983 0.04973417 0.04707232 0.05722355
  0.05827546 0.0429725  0.03685683 0.05104422 0.04372919 0.0389783
  0.03890312 0.04123374 0.03681215 0.05600128 0.0611076  0.05796204
  0.04995209 0.05366364 0.06396814 0.05107462 0.05552108 0.09063588
  0.05515926 0.03583138 0.04319366 0.04644209 0.05945782 0.04239376
  0.06265352 0.04173535]
 [0.04646791 0.06093329 0.05747473 0.03465655 0.02639331 0.04512208
  0.05278981 0.05469713 0.0509645  0.03628349 0.04029888 0.04349598
  0.05003424 0.03025224 0.0257824  0.04536799 0.03653183 0.03252635
  0.03653057 0.03835987 0.0351937  0.05235913 0.06473967 0.05302073
  0.04316046 0.05170675 0.0686973  0.03915785 0.04129371 0.09210061
  0.05330045 0.0232532  0.03094384 0.04228493 0.06893213 0.04285772
  0.05147133 0.03847967]
 [0.04768044 0.07297692 0.06945166 0.03715269 0.02628144 0.04748372
  0.0611475  0.05629762 0.06824269 0.03874369 0.03781122 0.04207416
  0.04655119 0.02967321 0.02670282 0.05499936 0.04319388 0.03709261
  0.03927471 0.04316079 0.03672739 0.04546038 0.08773314 0.05134356
  0.04020214 0.04605447 0.06082574 0.03440309 0.03921739 0.0870719
  0.03584233 0.01939668 0.03042134 0.04797752 0.08152254 0.03663763
  0.04712367 0.0346407 ]
 [0.04780648 0.05483864 0.05510329 0.03238175 0.02361197 0.0387443
  0.05624979 0.04648076 0.05179375 0.03198558 0.03644405 0.03521556
  0.03715362 0.02572171 0.02560615 0.05008003 0.03909241 0.03275625
  0.03684327 0.03903742 0.03475832 0.04327469 0.06182643 0.05266517
  0.04255034 0.04145965 0.05665661 0.03187646 0.0374429  0.07509304
  0.03669561 0.02017034 0.02753306 0.04809252 0.06977686 0.03517967
  0.04492139 0.03365654]
 [0.0484718  0.02966536 0.03095484 0.0219647  0.01816735 0.02616488
  0.03096174 0.03082614 0.03597695 0.02286259 0.02989648 0.02533019
  0.02705384 0.0168179  0.01770179 0.03335179 0.03053079 0.02696955
  0.0323127  0.03430161 0.02903106 0.03386438 0.0299903  0.03885932
  0.03925572 0.03399415 0.03503314 0.02349794 0.0235903  0.03475242
  0.01846233 0.01302142 0.0221919  0.03010872 0.05134177 0.03445689
  0.03257676 0.03065269]
 [0.04717732 0.04814578 0.04934042 0.03869533 0.02784459 0.04770254
  0.05241358 0.05487414 0.05155246 0.04227613 0.04583295 0.05444384
  0.05084124 0.02958626 0.02602066 0.05207436 0.04568944 0.04767058
  0.05105895 0.05047833 0.04467219 0.05356804 0.04277207 0.05451752
  0.05566039 0.04689929 0.05581656 0.03758637 0.03757872 0.08560717
  0.13141416 0.02193835 0.02454317 0.0384044  0.05233667 0.04311654
  0.04589337 0.03395976]
 [0.04837901 0.04903316 0.05020432 0.0477298  0.03067877 0.05232709
  0.05146965 0.05171371 0.04693044 0.04939165 0.05197927 0.05892352
  0.05587192 0.03231123 0.0258591  0.03947923 0.03454449 0.03794863
  0.03953833 0.04277714 0.03995965 0.04812979 0.03971073 0.04531997
  0.04196999 0.04162057 0.05958122 0.04204104 0.03908785 0.07523657
  0.17387155 0.04288112 0.03756223 0.04380171 0.04701625 0.04366311
  0.05417274 0.04137817]
 [0.04894686 0.04092535 0.04395605 0.03794274 0.02565991 0.04086845
  0.04530552 0.04329452 0.03769321 0.03852031 0.04471246 0.04243005
  0.04285155 0.02458214 0.02221332 0.04167561 0.03601603 0.03605316
  0.0417987  0.04275074 0.04308625 0.04628985 0.03667287 0.0550812
  0.05750561 0.04010621 0.04800722 0.04476935 0.03476418 0.04101344
  0.122794   0.03695468 0.02807007 0.03800655 0.04360919 0.04819944
  0.0518216  0.03717689]
 [0.04846226 0.03242903 0.03192566 0.0261431  0.01807412 0.02680532
  0.03452585 0.03585995 0.02904392 0.02817019 0.03877121 0.03190373
  0.03563044 0.01648861 0.01685154 0.05015122 0.05019185 0.04111836
  0.05207836 0.04789132 0.04993505 0.04743667 0.02943583 0.06623688
  0.07913644 0.04118092 0.0301173  0.04161026 0.02597536 0.02303127
  0.07159331 0.02201275 0.01986966 0.02810707 0.041846   0.07199766
  0.0420952  0.03962057]
 [0.04799365 0.03546422 0.03317232 0.028234   0.01841907 0.0271976
  0.03979307 0.03953298 0.02967605 0.02893267 0.0410211  0.03273817
  0.04016503 0.01620927 0.01707348 0.0617539  0.06462449 0.06040084
  0.07548277 0.07099664 0.0632797  0.04430909 0.02760444 0.07271488
  0.08934768 0.048724   0.02495255 0.04003072 0.022261   0.01499153
  0.05203477 0.01604353 0.01934716 0.0265188  0.0479803  0.10812315
  0.03393842 0.06160602]
 [0.04884362 0.0310494  0.02998189 0.0262078  0.0184688  0.02530561
  0.03201317 0.03453604 0.02637947 0.02756556 0.03979659 0.03294376
  0.03383128 0.01575233 0.01605025 0.04932523 0.05181077 0.0457103
  0.07183561 0.0563211  0.05755824 0.04133492 0.02280382 0.06353988
  0.09066315 0.04698262 0.0267571  0.04098264 0.02142343 0.01604849
  0.05407231 0.02158562 0.01834569 0.02383025 0.04018069 0.06866872
  0.03275846 0.04764799]
 [0.04911798 0.02959031 0.02841447 0.02359588 0.01739665 0.02293863
  0.03367261 0.03426683 0.02620274 0.02471519 0.04703665 0.03189164
  0.03448107 0.01385243 0.01462148 0.05427806 0.06183419 0.04530063
  0.07374403 0.05584593 0.05651101 0.04140147 0.02001159 0.06233274
  0.06663948 0.05968373 0.02224573 0.03785582 0.01822658 0.01162003
  0.03525649 0.01809547 0.01676367 0.02254968 0.03721879 0.09229346
  0.02686965 0.05757947]
 [0.04747567 0.03829853 0.03542828 0.0288674  0.02180953 0.02885208
  0.03843595 0.03711748 0.03395481 0.02749408 0.03612306 0.03117987
  0.03401993 0.01782982 0.01831377 0.03911806 0.03683524 0.03687127
  0.04118313 0.04499458 0.04125998 0.0446934  0.03865055 0.05499274
  0.0570443  0.069336   0.03123736 0.03874966 0.02905337 0.02080725
  0.01939504 0.02039599 0.03320803 0.03962279 0.06615393 0.08325934
  0.04841965 0.08300047]
 [0.04932012 0.03546863 0.03519093 0.03372688 0.02233472 0.03080278
  0.03557392 0.03892081 0.03365234 0.03271531 0.04321749 0.03930999
  0.03765319 0.02130218 0.01877561 0.03547279 0.03433643 0.0346713
  0.03980755 0.04149948 0.03695728 0.04518849 0.02394167 0.03066946
  0.03152958 0.03620967 0.02874833 0.03304781 0.02588167 0.02143849
  0.02409966 0.0366317  0.01966647 0.02702388 0.02698289 0.03758896
  0.02929304 0.03846169]
 [0.04779813 0.04543729 0.04783716 0.06319363 0.05172692 0.05939867
  0.04549699 0.05065532 0.05847868 0.0682929  0.0517207  0.0566759
  0.05589637 0.08894378 0.09619951 0.04019007 0.03761003 0.04620801
  0.03697788 0.04373099 0.03904361 0.04814968 0.04587856 0.02896975
  0.02958018 0.04689354 0.04545596 0.06438538 0.06543107 0.03297207
  0.01436805 0.11610485 0.08841928 0.05825154 0.03518341 0.02870902
  0.05181503 0.05223985]
 [0.04717324 0.06397289 0.06054755 0.1116011  0.22677805 0.08438674
  0.0545198  0.05721219 0.05792472 0.10726593 0.08530557 0.08481
  0.0568501  0.13685565 0.17484738 0.06213182 0.07148484 0.09015857
  0.05388862 0.05714472 0.07092611 0.04703898 0.06709664 0.03063131
  0.02644925 0.05444524 0.0706263  0.07426923 0.07693445 0.02922949
  0.00920866 0.13937789 0.09312182 0.0868326  0.03482407 0.02410798
  0.06748497 0.04981801]
 [0.04721549 0.05203523 0.04594044 0.06536626 0.10911289 0.04358234
  0.04074373 0.04530067 0.04161852 0.07142623 0.0666199  0.05928805
  0.0459538  0.04699799 0.07087732 0.05675814 0.09878537 0.12298331
  0.08032463 0.07278115 0.12178764 0.04577163 0.05461106 0.04470946
  0.03960393 0.04975273 0.05852338 0.0786287  0.05397547 0.01695294
  0.01456928 0.11209892 0.04081336 0.0540462  0.04196534 0.03537379
  0.06455589 0.05738161]
 [0.04768087 0.05480332 0.04949011 0.07223832 0.07413312 0.05567608
  0.05110686 0.05431728 0.05790093 0.07237934 0.06132063 0.05796297
  0.05075041 0.06005125 0.06284159 0.04510522 0.06102473 0.07272754
  0.04953194 0.06057822 0.06002074 0.06014499 0.05836233 0.0317552
  0.03257719 0.04834181 0.04984288 0.08804467 0.055384   0.01518563
  0.00984415 0.10868688 0.1490878  0.09897152 0.03508151 0.03207652
  0.05397353 0.08871267]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03012326 0.04432252 0.04555106 ... 0.01827377 0.05815234 0.05083847]
 [0.03083121 0.03652566 0.04087016 ... 0.04323824 0.0232519  0.02663142]
 [0.03135158 0.0473487  0.05286084 ... 0.03102329 0.05185119 0.04549731]
 ...
 [0.03156949 0.04389948 0.03936403 ... 0.01148393 0.10136417 0.05115069]
 [0.03215179 0.033311   0.02768371 ... 0.01099247 0.0786566  0.03288932]
 [0.03184665 0.03622409 0.03052802 ... 0.01084158 0.09760594 0.05626136]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' previously', ' stated', ' that', ' Mary', ' travelled', ' to', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' leaving', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 50), x_tokens=50, y_tokens=33, max_supp_attn=0.1818, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 50)
DEBUG result.interpretability.attn_scores 1650 
 [[0.02811538 0.03657562 0.03799032 ... 0.02263672 0.03613057 0.08281973]
 [0.02887419 0.03136216 0.0304328  ... 0.02068612 0.02512591 0.03736877]
 [0.02943837 0.03992397 0.04359616 ... 0.01498723 0.02976489 0.04511894]
 ...
 [0.02960059 0.0383898  0.03574922 ... 0.01612879 0.03466208 0.05021295]
 [0.03007657 0.02943937 0.02605585 ... 0.02554777 0.04402087 0.0382264 ]
 [0.02989639 0.0305883  0.02860649 ... 0.01776765 0.03419504 0.04909195]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' school', '.', ' Sentence', ' ', '1', ' states', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' and', ' sentence', ' ', '2', ' states', ' Julie', ' is', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 26), x_tokens=26, y_tokens=53, max_supp_attn=0.1321, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 26)
DEBUG result.interpretability.attn_scores 1378 
 [[0.01801901 0.03703444 0.02851124 ... 0.00767585 0.00413654 0.0123066 ]
 [0.01850943 0.03407979 0.03033956 ... 0.00776718 0.00354561 0.01269918]
 [0.01742543 0.03242984 0.0380987  ... 0.01305501 0.00652161 0.02017281]
 ...
 [0.01844565 0.02092001 0.02071408 ... 0.00627991 0.00372766 0.01051957]
 [0.0183177  0.01611443 0.01646124 ... 0.00872063 0.00634825 0.01354792]
 [0.01851554 0.01983707 0.01931548 ... 0.0073405  0.00507289 0.01027363]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.0476, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.0446861  0.08042186 0.06562854 0.09111533 0.09603889 0.10196356
  0.08271977 0.0711589  0.0793447  0.09855433 0.08213485 0.09152182
  0.11077932 0.09134947 0.06760798 0.04608542 0.03124435 0.0615749
  0.04484203 0.04966668 0.0457328  0.05444894 0.11624993 0.0422882
  0.02121213 0.04785414 0.05727551 0.05979918 0.10629688 0.03254187
  0.03120875 0.02601947]
 [0.04697233 0.07223277 0.0580689  0.06375241 0.05048878 0.04497449
  0.04899777 0.03565931 0.03739372 0.04233725 0.03856358 0.0245799
  0.03021158 0.05853965 0.08206572 0.05528218 0.02715945 0.02481092
  0.02723319 0.02923742 0.03006354 0.05027057 0.12436845 0.03676456
  0.01447081 0.04478491 0.06865665 0.04903091 0.13021931 0.01258256
  0.01143328 0.01250932]
 [0.04528933 0.0620822  0.06947625 0.07497427 0.06716318 0.06708419
  0.05542859 0.05373461 0.07085847 0.06605135 0.04764154 0.0473628
  0.04915024 0.11188533 0.11588325 0.05705163 0.0343674  0.03718081
  0.03599673 0.04011979 0.03850948 0.04723532 0.07445068 0.04581448
  0.02371838 0.0588722  0.06693099 0.06226425 0.13132031 0.02881181
  0.02608294 0.02143805]
 [0.04690149 0.0570589  0.06067086 0.08964843 0.0919745  0.09051196
  0.05479492 0.05535845 0.06599666 0.0857073  0.06382474 0.06974101
  0.07194191 0.15975356 0.13164008 0.05418687 0.03235741 0.04315688
  0.03520861 0.03727103 0.03628325 0.04769345 0.04646406 0.03387545
  0.02153129 0.04350995 0.05518007 0.04680969 0.10315024 0.03651679
  0.03348744 0.02749804]
 [0.04756941 0.05509941 0.06566837 0.07316086 0.06643732 0.07712085
  0.05571069 0.05762361 0.06029528 0.06586998 0.05191986 0.06325518
  0.06085126 0.10268615 0.07717615 0.04636765 0.02851142 0.03491424
  0.0306071  0.0330785  0.031568   0.04686559 0.04605233 0.04001669
  0.02655812 0.04245345 0.05181092 0.03970799 0.0861968  0.05989894
  0.05474579 0.03720189]
 [0.04569632 0.06049146 0.06588022 0.04472305 0.0342007  0.05235163
  0.0550811  0.06116897 0.05524964 0.04404515 0.04381358 0.05296096
  0.051312   0.02964017 0.02748355 0.05414227 0.03758781 0.03892839
  0.03773195 0.04018319 0.03848282 0.05231727 0.05884002 0.06656393
  0.05084731 0.05924287 0.06257576 0.04694979 0.04978054 0.1245481
  0.12273221 0.0657366 ]
 [0.04713336 0.05654304 0.06366213 0.03490487 0.0244738  0.04248537
  0.05705981 0.05286823 0.05529902 0.03169437 0.03846813 0.03931242
  0.04049686 0.02148801 0.02138865 0.05731631 0.03912621 0.03693728
  0.04077654 0.04274391 0.03857994 0.04655103 0.05138947 0.06331331
  0.05192142 0.0482839  0.0553855  0.0297422  0.02682264 0.07568179
  0.13137895 0.07548823]
 [0.04797579 0.02561472 0.02844416 0.01926963 0.01343142 0.02328744
  0.02714194 0.02708269 0.02835327 0.01822011 0.02788737 0.02217707
  0.02525226 0.01082345 0.01172516 0.03536562 0.02683769 0.02920633
  0.03601149 0.03845629 0.03363426 0.03397996 0.02704271 0.04992069
  0.04729764 0.03632753 0.02493991 0.023842   0.01540066 0.03234296
  0.05744189 0.04359987]
 [0.04716089 0.04713391 0.05098004 0.0316549  0.02147075 0.04287127
  0.04816785 0.04916315 0.04259301 0.03340479 0.03907757 0.04483471
  0.04139336 0.01845095 0.01783412 0.04917318 0.04782353 0.03928685
  0.04696564 0.04603371 0.04322378 0.05479914 0.04301692 0.06422313
  0.0751631  0.05612708 0.04909916 0.03509441 0.02680012 0.08439971
  0.06575172 0.09842157]
 [0.04842953 0.05711579 0.06334525 0.0508082  0.02981099 0.05889016
  0.05948824 0.06876791 0.05551303 0.0559022  0.05826635 0.08221643
  0.06594622 0.02962646 0.02305966 0.05131042 0.04590675 0.04818894
  0.04741194 0.04793977 0.04453685 0.05375574 0.04015344 0.0534801
  0.06800647 0.05383143 0.05361875 0.04183167 0.02980698 0.09307693
  0.06435429 0.0996995 ]
 [0.0492009  0.03917626 0.04237563 0.03330138 0.02143821 0.03861472
  0.04752395 0.04548952 0.03792874 0.03362646 0.04540449 0.04355681
  0.04395355 0.01904305 0.01713717 0.04694382 0.04970026 0.0395322
  0.04704059 0.0444653  0.04298954 0.05140511 0.02911779 0.04919916
  0.06218787 0.03810389 0.04094336 0.03041965 0.02161048 0.05780349
  0.04663595 0.0972798 ]
 [0.04861642 0.03388228 0.03169436 0.02415849 0.016528   0.02794158
  0.04136294 0.03898929 0.03293248 0.02567138 0.04197057 0.03460192
  0.03765479 0.01419313 0.01403061 0.05053391 0.06778401 0.04370414
  0.05876241 0.05182083 0.05198394 0.04960993 0.02457015 0.05720672
  0.0691972  0.03880941 0.03498572 0.03501993 0.01729494 0.04860503
  0.03968205 0.0561904 ]
 [0.04788011 0.03178744 0.02765289 0.02164704 0.01493599 0.02435158
  0.03769987 0.03585292 0.03036713 0.02270145 0.03537932 0.02922657
  0.03492081 0.01279633 0.01227157 0.04355554 0.06818449 0.0428869
  0.06366259 0.05359045 0.05742762 0.04392079 0.02192128 0.05526659
  0.0778003  0.0442889  0.03151385 0.04446433 0.01492767 0.04776475
  0.03457367 0.0538352 ]
 [0.04909222 0.03167564 0.02976778 0.02229956 0.01687161 0.02695429
  0.03896314 0.04223941 0.03485855 0.02640442 0.04608735 0.04113954
  0.04051594 0.01409368 0.01239398 0.04780954 0.08687378 0.04715644
  0.0748041  0.05615944 0.05534422 0.04212869 0.01979256 0.04332907
  0.10554301 0.04239256 0.02948004 0.04219611 0.01340536 0.04597127
  0.04116411 0.05468556]
 [0.04892704 0.02898255 0.02685981 0.01812392 0.01430976 0.02205959
  0.03791246 0.03630305 0.03298187 0.02062577 0.04462371 0.03131022
  0.03682612 0.01154813 0.0106313  0.05177471 0.07493948 0.04614036
  0.06863204 0.06020312 0.05812272 0.04128884 0.02005536 0.05366387
  0.09031521 0.05538753 0.02317316 0.0538839  0.01231894 0.04284516
  0.04907895 0.05071086]
 [0.04818775 0.03281524 0.0329383  0.02224392 0.01705054 0.0275039
  0.04166343 0.04138514 0.0393335  0.02287527 0.03159786 0.02917839
  0.03697447 0.01359532 0.01197571 0.03790208 0.03253693 0.03759308
  0.04321697 0.04819337 0.04399696 0.04504437 0.03234701 0.05712538
  0.05383641 0.05441698 0.02892536 0.0406488  0.01896663 0.04516513
  0.04727325 0.05111215]
 [0.04968447 0.03295647 0.03423294 0.02853899 0.01899836 0.03057437
  0.0396377  0.04679634 0.03877654 0.0308908  0.03754541 0.03793215
  0.04067701 0.01905905 0.01439575 0.03325325 0.03017962 0.03454758
  0.03982602 0.04283212 0.03864088 0.04574613 0.02315976 0.03399897
  0.03409121 0.03968864 0.03262321 0.04146368 0.02186088 0.04300403
  0.05195013 0.04804991]
 [0.04800144 0.04245779 0.04682631 0.06169368 0.05210519 0.05565263
  0.04286743 0.04573879 0.05292848 0.06486237 0.0484321  0.05542039
  0.05200079 0.08029628 0.09216727 0.03881897 0.03348013 0.04390572
  0.0368087  0.04272186 0.04057288 0.04727986 0.04222193 0.03348983
  0.02447742 0.04807618 0.05316679 0.05443367 0.05408515 0.02964421
  0.03437866 0.02478215]
 [0.04757209 0.05566823 0.05070662 0.0836948  0.17509231 0.06540863
  0.04616869 0.04661968 0.05267057 0.08556624 0.06858033 0.06450538
  0.04601781 0.10211349 0.13619469 0.05362606 0.0574965  0.07867038
  0.05068023 0.05441738 0.06145539 0.04618644 0.05478405 0.03442978
  0.02019735 0.05035572 0.07872301 0.0585897  0.05343595 0.01770631
  0.01666198 0.01831968]
 [0.04738749 0.04594526 0.04046535 0.05247743 0.0936214  0.03664681
  0.03670029 0.04070268 0.04201958 0.06322501 0.05795796 0.05008359
  0.03938844 0.03609835 0.0579846  0.05152904 0.09366468 0.11727041
  0.07841877 0.07461786 0.09896887 0.04185731 0.04528472 0.04676195
  0.03645834 0.05080518 0.05522115 0.0764579  0.02838072 0.02188933
  0.02088494 0.01978273]
 [0.04763541 0.05085873 0.04465529 0.05780889 0.06355829 0.042751
  0.04490951 0.0472973  0.05430581 0.06176397 0.05082336 0.04508282
  0.04373526 0.04292001 0.04495305 0.03797154 0.05423811 0.07440723
  0.05536238 0.06624797 0.06988228 0.05761543 0.05871738 0.03926805
  0.02516894 0.04638757 0.0457711  0.08735031 0.03791869 0.01919978
  0.01909916 0.01763892]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Julie', '.', ' We', ' need', ' to', ' refer', ' to', ' the', ' previous', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ',', ' which', ' mentioned', ' Julie', ' journey', 'ed', ' to', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Julie', ' left', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 38), x_tokens=38, y_tokens=61, max_supp_attn=0.0164, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 38)
DEBUG result.interpretability.attn_scores 2318 
 [[0.01505433 0.01564257 0.01374709 ... 0.01400183 0.06220109 0.0294543 ]
 [0.0156126  0.02775477 0.02077866 ... 0.03026281 0.06866828 0.01200539]
 [0.01503821 0.02247736 0.02086915 ... 0.03606831 0.0347564  0.0148224 ]
 ...
 [0.01594667 0.0190747  0.01737025 ... 0.06115288 0.03116014 0.00969016]
 [0.01641632 0.01202833 0.01023608 ... 0.03695073 0.014383   0.01074134]
 [0.01626741 0.01410257 0.01181317 ... 0.04886592 0.03102478 0.01040104]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' park', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' left', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 44), x_tokens=44, y_tokens=33, max_supp_attn=0.1515, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 44)
DEBUG result.interpretability.attn_scores 1452 
 [[0.02829598 0.03104638 0.03146184 ... 0.02608832 0.07004445 0.03198183]
 [0.02929291 0.05407532 0.0443507  ... 0.02822868 0.12881215 0.02591085]
 [0.02847267 0.04191801 0.0422129  ... 0.03749669 0.09477326 0.06024491]
 ...
 [0.02979646 0.04423051 0.04197843 ... 0.0361248  0.04309073 0.01827311]
 [0.03032394 0.03114923 0.02770863 ... 0.04293269 0.02410119 0.01081072]
 [0.03011677 0.03735474 0.03137564 ... 0.02995644 0.04127283 0.00908104]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Julie', ' was', ' ever', ' in', ' the', ' park', ' or', ' moved', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02374363 0.02905557 0.03113807 ... 0.03975761 0.01884277 0.01586241]
 [0.02434405 0.03915772 0.0364834  ... 0.05106573 0.01359948 0.01050603]
 [0.0239216  0.03558768 0.03821207 ... 0.03785658 0.01640221 0.01299965]
 ...
 [0.02505046 0.03772815 0.03562273 ... 0.02989895 0.01605303 0.01089918]
 [0.02553339 0.0268277  0.02459695 ... 0.024731   0.0191028  0.0162371 ]
 [0.02519823 0.03099792 0.02760381 ... 0.03033605 0.01760577 0.01502628]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.12, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03748659 0.05564952 0.0679249  0.08909874 0.09552303 0.08717964
  0.06337325 0.07888477 0.06736592 0.07745145 0.05911573 0.07217944
  0.08109281 0.10846216 0.06729277 0.03881676 0.03386616 0.04219505
  0.03604428 0.04146704 0.03572496 0.04892398 0.04677526 0.0312939
  0.01663452 0.03255703]
 [0.03720073 0.08818106 0.07349607 0.06973069 0.05494293 0.07180895
  0.21020572 0.15071855 0.08455036 0.07425442 0.0907507  0.07140751
  0.11314306 0.03681407 0.02859185 0.05284989 0.04152051 0.06443819
  0.04750589 0.0600933  0.05251164 0.05819271 0.04579961 0.04567145
  0.02820272 0.03610238]
 [0.04085992 0.06816158 0.04149685 0.06062245 0.04396305 0.04056595
  0.03291696 0.0253042  0.02668495 0.03893109 0.03411794 0.01944533
  0.02262974 0.03398422 0.04329001 0.03020826 0.01586868 0.01839334
  0.02177767 0.02359551 0.02206674 0.05502576 0.05817425 0.01499193
  0.00628486 0.01538692]
 [0.0384915  0.04244407 0.04423713 0.02774864 0.01894429 0.03318419
  0.03089927 0.02886848 0.03829689 0.02905579 0.03080442 0.02958751
  0.0285158  0.01409654 0.01379679 0.04170897 0.03489072 0.03725441
  0.04233988 0.0448258  0.04465066 0.04184851 0.0633999  0.07373841
  0.07650343 0.07448974]
 [0.03883441 0.04832766 0.05178526 0.07566734 0.06693693 0.05363093
  0.03568533 0.03317871 0.04046965 0.05192947 0.04183064 0.03018141
  0.03104863 0.11357007 0.11593285 0.04698847 0.03055985 0.02850282
  0.02791351 0.03179109 0.03081128 0.04915871 0.06810112 0.02537284
  0.00903278 0.03358749]
 [0.03960262 0.03123266 0.03184546 0.0583715  0.05019629 0.04906956
  0.02679266 0.02608506 0.03447623 0.04844495 0.03709953 0.03432262
  0.03385118 0.12386463 0.14414114 0.04647572 0.03425819 0.03446903
  0.03174625 0.03427036 0.02975925 0.04220236 0.0412508  0.01849278
  0.00757489 0.02220805]
 [0.04020507 0.03474311 0.0409239  0.0608882  0.05434368 0.06175369
  0.03490056 0.0356997  0.04559227 0.05709465 0.04314677 0.05439905
  0.05136047 0.09899723 0.09018218 0.03881335 0.03110089 0.03383783
  0.03031713 0.03355927 0.0279396  0.03792468 0.03873048 0.02317256
  0.010643   0.02169574]
 [0.03890137 0.04827705 0.05755046 0.0503658  0.04983777 0.06102683
  0.04152774 0.05005508 0.05343807 0.05416706 0.04606458 0.06431798
  0.05578415 0.06177648 0.05445596 0.05118864 0.0421752  0.04214003
  0.03683772 0.04054928 0.03635446 0.04313431 0.05515813 0.04228083
  0.03009835 0.03957304]
 [0.03924561 0.05859709 0.06791941 0.03890537 0.031252   0.04933832
  0.04869186 0.05593349 0.05570457 0.04138553 0.04093776 0.05128147
  0.0521022  0.0289199  0.02019168 0.05003604 0.03882385 0.03875743
  0.03690095 0.03967515 0.03753238 0.03801386 0.06522076 0.05333903
  0.04293031 0.05117771]
 [0.04027913 0.07806168 0.08470248 0.03412504 0.02410068 0.04322639
  0.0486454  0.04790513 0.05925257 0.0337429  0.03278441 0.04188056
  0.03976815 0.01872229 0.01528332 0.05842615 0.03793616 0.0371859
  0.03675651 0.04239476 0.03700795 0.03725589 0.07416798 0.0477704
  0.02994802 0.03688427]
 [0.04034594 0.04505426 0.05171753 0.0271776  0.02064345 0.03219836
  0.04010586 0.04041199 0.04607624 0.02889808 0.02916796 0.03514999
  0.03243094 0.01580785 0.01412104 0.05464846 0.04098268 0.03632379
  0.03902367 0.04132085 0.03792502 0.03720037 0.05665022 0.06066143
  0.05006408 0.04573715]
 [0.04066515 0.0244506  0.02828053 0.0179618  0.01516568 0.02242275
  0.0248328  0.0275873  0.04010156 0.02155117 0.02080589 0.02274677
  0.02201163 0.01093809 0.01055078 0.03734561 0.03347628 0.02955267
  0.03565954 0.03869079 0.03661848 0.03153877 0.04722116 0.07142232
  0.06977094 0.0686594 ]
 [0.04029941 0.03344689 0.03558886 0.02414838 0.02006725 0.03244645
  0.03139285 0.03423882 0.03478298 0.02744743 0.02994488 0.03658949
  0.03193365 0.01291489 0.01248114 0.04604098 0.03948783 0.03665342
  0.03962408 0.03928936 0.03719725 0.03755619 0.03427684 0.05604039
  0.07050116 0.05379647]
 [0.04105397 0.04306732 0.04689321 0.04061375 0.02920456 0.05337631
  0.04329347 0.05305957 0.04856938 0.05253405 0.04884324 0.07980303
  0.06048738 0.02326996 0.01607526 0.0348125  0.03646133 0.03974254
  0.03739885 0.03848718 0.03357019 0.03948193 0.02705197 0.02779081
  0.0260132  0.02401223]
 [0.04159626 0.03011489 0.03159651 0.02529521 0.0211646  0.03130829
  0.03276103 0.03486324 0.0316576  0.03030766 0.03651683 0.03964579
  0.03735473 0.01352914 0.01206259 0.03453891 0.03807661 0.03316131
  0.03652553 0.03554405 0.03362272 0.03772405 0.0228286  0.03163463
  0.04518992 0.02659598]
 [0.04078805 0.02253645 0.02006152 0.0161585  0.01397742 0.01911815
  0.02339027 0.02597129 0.02390893 0.01988694 0.03020433 0.02599131
  0.02907631 0.00820585 0.0090125  0.03516819 0.04998856 0.03582962
  0.04502306 0.03898472 0.04221057 0.03482265 0.01916425 0.04104818
  0.08617939 0.04791127]
 [0.04027029 0.02152079 0.01811386 0.01501958 0.01229618 0.01742396
  0.0239014  0.02761962 0.022411   0.01785799 0.02817216 0.0219464
  0.02844415 0.00719142 0.00762074 0.0337938  0.05661335 0.04162805
  0.06109954 0.04802458 0.06153787 0.03165898 0.01725022 0.04781049
  0.10837081 0.05660719]
 [0.04106982 0.02124112 0.01857972 0.01535176 0.01321427 0.01942609
  0.02242996 0.02622339 0.02330056 0.01967172 0.03387732 0.02903812
  0.02862818 0.00780893 0.00777341 0.03091317 0.05508527 0.03689403
  0.0543786  0.04152904 0.04602376 0.03043548 0.01456686 0.03290402
  0.08889341 0.03919318]
 [0.04086817 0.01977977 0.01735328 0.01293787 0.01165084 0.01685596
  0.02456845 0.02612126 0.02281488 0.01676548 0.04912299 0.02723528
  0.02888385 0.00672358 0.00707624 0.03641516 0.05725696 0.04133781
  0.05795174 0.04731961 0.05401654 0.03056618 0.01487699 0.04157153
  0.06119144 0.06378367]
 [0.03968491 0.02983967 0.02696256 0.01896627 0.01647302 0.02344884
  0.03302022 0.03228538 0.03607811 0.02137538 0.03253365 0.02468678
  0.03047267 0.00961199 0.00988338 0.04267963 0.03634161 0.04141873
  0.04623319 0.04782174 0.06429633 0.037919   0.03185568 0.10392103
  0.07076114 0.07568359]
 [0.04173156 0.02403687 0.02466161 0.02268675 0.01656905 0.02505816
  0.02323022 0.0283255  0.02953937 0.02599349 0.02907084 0.03142975
  0.02935024 0.01210153 0.0106758  0.02467255 0.02780065 0.02977278
  0.03661606 0.03400016 0.03573583 0.03234614 0.01774071 0.0255137
  0.02295781 0.03824149]
 [0.04050193 0.0314999  0.03022729 0.05011587 0.04848946 0.04574428
  0.0265913  0.02805659 0.03474889 0.05128875 0.03940276 0.03874036
  0.03720863 0.08150734 0.09378292 0.03182659 0.03056342 0.03433578
  0.03102071 0.03211411 0.03055088 0.03899301 0.03473338 0.01875418
  0.00941683 0.02455664]
 [0.04024107 0.03249248 0.02918298 0.05300273 0.09623368 0.04173458
  0.02484519 0.02611867 0.03262044 0.05632251 0.0440556  0.03702944
  0.03090534 0.07998408 0.10322082 0.03833092 0.04253899 0.0508463
  0.03671923 0.03611737 0.03596861 0.0360372  0.03289722 0.01614858
  0.00708148 0.02053107]
 [0.03964597 0.03058988 0.02774236 0.04700755 0.10362573 0.0314715
  0.02257245 0.02684135 0.03072885 0.05396499 0.04640666 0.04307638
  0.03083511 0.03602218 0.05179723 0.03447213 0.06963599 0.08086725
  0.05332889 0.04593493 0.05395404 0.03329753 0.03003749 0.0268087
  0.01453882 0.02617586]
 [0.04013054 0.0366537  0.03115627 0.04803259 0.0711842  0.03718192
  0.02942576 0.02964287 0.03682963 0.0496771  0.04522244 0.03788818
  0.032681   0.03517563 0.04070761 0.02882911 0.04469031 0.05446195
  0.04125755 0.0425999  0.042413   0.05874174 0.04207005 0.02184582
  0.01121666 0.02485248]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02920366 0.04204734 0.0438995  ... 0.05578728 0.01065479 0.0723059 ]
 [0.02992176 0.0443932  0.04170686 ... 0.06520983 0.01852655 0.08122997]
 [0.03051523 0.04171241 0.04586746 ... 0.06375787 0.02598057 0.06254123]
 ...
 [0.03045009 0.03455921 0.0324101  ... 0.02055865 0.00792127 0.0922935 ]
 [0.03083839 0.02747246 0.02558231 ... 0.0120467  0.01073679 0.0562194 ]
 [0.03099984 0.02660322 0.0247461  ... 0.01097265 0.00873819 0.0786966 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.0310555  0.04241337 0.04256351 ... 0.02272004 0.03674371 0.03029026]
 [0.0318842  0.05613614 0.05156288 ... 0.03358177 0.03701405 0.04047303]
 [0.03250966 0.04380819 0.04840743 ... 0.01944304 0.02780282 0.02796323]
 ...
 [0.03263876 0.04145576 0.04273658 ... 0.01746915 0.0310741  0.03425467]
 [0.03301111 0.03113077 0.03023711 ... 0.02696048 0.03098046 0.04199622]
 [0.03300952 0.034344   0.03360293 ... 0.02403383 0.03447224 0.03581211]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 44), x_tokens=44, y_tokens=21, max_supp_attn=0.1905, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 44)
DEBUG result.interpretability.attn_scores 924 
 [[0.04535989 0.05797715 0.05917485 0.06981286 0.07250266 0.06809443
  0.05030129 0.05384137 0.05690215 0.06870846 0.04888789 0.05536969
  0.06173233 0.0967393  0.09639521 0.04094974 0.03673748 0.03666056
  0.03824172 0.03793015 0.03669411 0.04577379 0.06041433 0.03258313
  0.01747374 0.0529663  0.05123305 0.05675219 0.11450917 0.05802962
  0.01215909 0.05784619 0.10039639 0.08472974 0.03722558 0.02498032
  0.04821173 0.03761249 0.01831108 0.1480432  0.02272769 0.02174531
  0.02118564 0.06843486]
 [0.04609056 0.04850419 0.05331954 0.04510859 0.04489844 0.05602817
  0.0505813  0.06066643 0.04749053 0.04256031 0.04303836 0.05337684
  0.065313   0.04241545 0.05390117 0.04068577 0.0398832  0.03863932
  0.04703546 0.04806931 0.04147036 0.0480137  0.04474647 0.03780147
  0.03146459 0.04781924 0.04171414 0.03454537 0.07459325 0.07157869
  0.02580241 0.02391864 0.04190991 0.04546924 0.04321119 0.03501881
  0.04712107 0.03950179 0.0359545  0.07087507 0.05550788 0.04788192
  0.05833139 0.03688974]
 [0.04714942 0.0609918  0.06809287 0.09353651 0.10349248 0.09873655
  0.05743844 0.06285443 0.06067517 0.08250038 0.05887811 0.07252104
  0.07656863 0.1529595  0.10027032 0.04501404 0.03587782 0.03579646
  0.03449201 0.03330039 0.03249934 0.05094176 0.05398246 0.0345569
  0.01770236 0.04893124 0.06365541 0.0463631  0.07902883 0.0787389
  0.02799094 0.06971761 0.07063063 0.07095473 0.03510593 0.02334757
  0.04156965 0.03906267 0.01439169 0.09861189 0.04321689 0.03541737
  0.03068424 0.06549447]
 [0.04591158 0.0494191  0.05755178 0.0466185  0.04384464 0.05625237
  0.04692959 0.05286931 0.04806589 0.0462563  0.04372267 0.05203227
  0.05172451 0.04245151 0.0353283  0.04370842 0.0380034  0.03445156
  0.03835499 0.03632041 0.03536347 0.05244891 0.05673419 0.04683683
  0.03406689 0.05541791 0.06670587 0.04837944 0.06057668 0.09509868
  0.05321085 0.03570898 0.03841441 0.0455755  0.05375187 0.03837347
  0.04798153 0.04431855 0.02079624 0.05497476 0.10381915 0.05655197
  0.05296499 0.04775713]
 [0.04651796 0.05651956 0.05993925 0.03396889 0.02816475 0.04814534
  0.04790669 0.04979168 0.04827163 0.03483767 0.03840667 0.04186992
  0.04398808 0.0321425  0.02779126 0.04654439 0.03754888 0.03135678
  0.03891803 0.03558856 0.03473195 0.05264197 0.06889796 0.04620028
  0.03937308 0.0508431  0.07747436 0.03211333 0.04482708 0.08573938
  0.03988979 0.01740288 0.02643243 0.04023855 0.06093949 0.04214586
  0.04344528 0.03604575 0.02274975 0.03432376 0.10855038 0.04701327
  0.05219736 0.02721004]
 [0.04742289 0.07803404 0.07323729 0.0409194  0.03031719 0.05283325
  0.05623968 0.05365932 0.05931521 0.0392829  0.0387005  0.04527538
  0.04774598 0.03299946 0.02840675 0.05391078 0.0408562  0.03500415
  0.0420514  0.04006517 0.03704029 0.04634653 0.08143476 0.04759473
  0.03526925 0.04408656 0.07089566 0.03145396 0.04013043 0.08061855
  0.036447   0.01831822 0.02938739 0.04284738 0.06889297 0.04173576
  0.04113942 0.03665564 0.02435707 0.0331219  0.10551469 0.03979602
  0.04555274 0.02657717]
 [0.04772936 0.05644853 0.05902708 0.03822782 0.02816849 0.04799502
  0.05278048 0.04995998 0.05401485 0.03620641 0.03587818 0.04143373
  0.04015422 0.03154644 0.0295927  0.05404276 0.04041066 0.03236445
  0.04099195 0.03742087 0.03471166 0.04480464 0.06134904 0.05904577
  0.03633331 0.04189183 0.06167077 0.0300731  0.03986793 0.07436603
  0.03493251 0.01943209 0.03073874 0.04341556 0.06121688 0.04130528
  0.03727493 0.03363059 0.01827399 0.03380541 0.09272291 0.04086571
  0.04083426 0.02594939]
 [0.0481297  0.03232003 0.03597528 0.02726045 0.02118055 0.03092237
  0.03246863 0.03469205 0.03798475 0.02689738 0.03045006 0.03042702
  0.03185356 0.02009198 0.02332068 0.04360497 0.03726831 0.03119696
  0.04052886 0.03895582 0.03449801 0.03794076 0.0396978  0.05409304
  0.03805218 0.03753162 0.03076188 0.02529027 0.03010205 0.03677884
  0.01551791 0.01388321 0.02531531 0.03425969 0.04822159 0.04313162
  0.03575028 0.02741244 0.02070969 0.02585991 0.05330801 0.03003099
  0.02596223 0.01959354]
 [0.04693873 0.04232147 0.04565005 0.03646352 0.02621411 0.04457336
  0.04358415 0.04500692 0.04437656 0.03777605 0.04179731 0.04693808
  0.04103673 0.02753738 0.02510311 0.04652894 0.04825533 0.03933954
  0.05184462 0.04296233 0.04184223 0.04806904 0.04037262 0.0513316
  0.0689551  0.04670074 0.04594068 0.03738831 0.04339889 0.10183037
  0.15145639 0.02122186 0.02463063 0.03429439 0.05794232 0.05316501
  0.04360379 0.03985417 0.02898121 0.0323088  0.08782168 0.05852951
  0.06060084 0.02578142]
 [0.04820932 0.04223055 0.04333391 0.04343455 0.02763786 0.04435934
  0.03817077 0.0413591  0.03803357 0.04025399 0.04230378 0.04422893
  0.03853026 0.02924918 0.02493597 0.0317914  0.02909258 0.03030307
  0.03631106 0.03673175 0.03833983 0.0468073  0.03542874 0.04035226
  0.05172127 0.04360535 0.05005697 0.05335977 0.04221061 0.08113082
  0.18114717 0.0502696  0.04209009 0.04018433 0.05543538 0.05237539
  0.04951751 0.05348043 0.03316024 0.04096661 0.06625433 0.06634104
  0.0901477  0.04785553]
 [0.04912042 0.03602795 0.04043428 0.03810063 0.02506316 0.04004851
  0.03888827 0.03919171 0.03830556 0.03641988 0.03950467 0.04354263
  0.03702565 0.02736768 0.02415735 0.03495199 0.03410912 0.03210982
  0.0392845  0.03789631 0.03907953 0.04407659 0.03368507 0.04359683
  0.05711496 0.03973936 0.04024404 0.04635832 0.03595876 0.04096083
  0.11590962 0.03436931 0.02558559 0.03324261 0.04309082 0.04218661
  0.03727493 0.04666052 0.02895648 0.02996606 0.05511875 0.0641182
  0.07336012 0.0328957 ]
 [0.0483628  0.03322357 0.03277498 0.02982894 0.02006697 0.03022173
  0.03694284 0.03553358 0.03393625 0.02884374 0.04168519 0.03730997
  0.03563317 0.02031682 0.02090174 0.04989285 0.05614488 0.04089167
  0.04866128 0.04494422 0.04745149 0.04769666 0.02966961 0.0575872
  0.07950539 0.04292579 0.02863023 0.04601589 0.02888132 0.02297947
  0.07261712 0.02075964 0.01987387 0.02745026 0.04610369 0.05438767
  0.04035445 0.04954191 0.04547478 0.02183338 0.0382967  0.06075487
  0.05652146 0.02140392]
 [0.04806045 0.03480334 0.03159016 0.03032541 0.01886743 0.02843319
  0.03931994 0.03594577 0.03443839 0.02834982 0.03868503 0.03311417
  0.03640355 0.01906108 0.01956667 0.05000106 0.05727051 0.04408667
  0.05246596 0.04623521 0.05200732 0.04380888 0.02608796 0.05160866
  0.10189301 0.04178128 0.02554302 0.04050839 0.02366109 0.01442073
  0.05296651 0.01445605 0.01936937 0.02577176 0.04694457 0.06314747
  0.04333207 0.05016806 0.05410485 0.02088731 0.02767246 0.0660047
  0.05862717 0.01787987]
 [0.04883621 0.03052715 0.02945239 0.02886884 0.01927101 0.02785485
  0.03325614 0.03312919 0.03361195 0.02875165 0.03752904 0.03610745
  0.03303265 0.01905683 0.01893217 0.04150029 0.05605622 0.04170972
  0.05486471 0.04737306 0.05470783 0.04075684 0.02733913 0.04887012
  0.1164173  0.04331597 0.03006358 0.05002309 0.02592051 0.01670358
  0.05581545 0.02248955 0.0205045  0.02565682 0.04133578 0.0664741
  0.04497749 0.05321479 0.06330366 0.02375518 0.02408048 0.06384256
  0.07061177 0.02450549]
 [0.0489192  0.03013789 0.02925364 0.02566028 0.01841153 0.02575548
  0.03858202 0.03449282 0.03415245 0.02631976 0.05303244 0.03493895
  0.03526063 0.01652412 0.01815454 0.05139705 0.06614317 0.04414085
  0.05867106 0.05055335 0.05285926 0.04281442 0.02631221 0.05335116
  0.07904252 0.05199737 0.02704987 0.04025514 0.02161477 0.01199958
  0.03430689 0.01812424 0.01754955 0.02521659 0.04116656 0.08543795
  0.05712571 0.05860891 0.11513353 0.02453863 0.01886388 0.06228986
  0.06146002 0.0205895 ]
 [0.0476645  0.09198208 0.06747881 0.04616716 0.03535074 0.04505744
  0.12892076 0.09870746 0.07406904 0.04598423 0.09449726 0.06820318
  0.10165869 0.02715556 0.03004106 0.12121661 0.08435423 0.13877055
  0.0796801  0.10843773 0.08706382 0.05761387 0.06126521 0.13057525
  0.0876933  0.0798884  0.04818259 0.0487585  0.03571743 0.01570337
  0.01994263 0.01497737 0.0430991  0.05463161 0.10190891 0.12512831
  0.09903879 0.11426325 0.34500495 0.03715944 0.02014784 0.05824881
  0.05199136 0.02471758]
 [0.04912656 0.03110394 0.03430378 0.0346623  0.02507063 0.03495805
  0.03700409 0.0390337  0.04297825 0.0387262  0.04015031 0.04238614
  0.03902938 0.02661678 0.02354986 0.03186275 0.03467587 0.03435539
  0.04367388 0.04635096 0.04027224 0.04277795 0.02539427 0.02824177
  0.02630799 0.04055222 0.03675254 0.04472741 0.03229938 0.02540354
  0.0286453  0.05228215 0.02147748 0.02795988 0.0272327  0.04523815
  0.04440763 0.03702971 0.02680514 0.03632178 0.024412   0.1013854
  0.06837929 0.05856258]
 [0.04784105 0.03980975 0.04120888 0.06044567 0.04981989 0.05116191
  0.03819118 0.03920201 0.04783924 0.06096071 0.04602692 0.04690807
  0.0433913  0.07580733 0.09221987 0.03312556 0.03331343 0.03922442
  0.03696572 0.04297302 0.04173811 0.04907209 0.04447612 0.02796013
  0.0179338  0.04576432 0.04902789 0.06584006 0.06099723 0.03070844
  0.01371141 0.13271411 0.10601802 0.05982976 0.03059797 0.02952452
  0.05029494 0.04065109 0.01324184 0.07015006 0.018722   0.02678778
  0.02345509 0.12644856]
 [0.04738156 0.05736059 0.05463431 0.10777398 0.20283704 0.08092249
  0.0497967  0.05212395 0.0629871  0.11504429 0.0781085  0.07520419
  0.05440821 0.15598221 0.17837888 0.05455051 0.06496254 0.08378106
  0.05426336 0.05447973 0.06587901 0.04805189 0.06439418 0.03133293
  0.01529482 0.04980588 0.06913154 0.06274229 0.06899834 0.02780521
  0.00810581 0.13868354 0.08518919 0.08410735 0.03113704 0.02637873
  0.05081196 0.0513282  0.01562809 0.06452359 0.01187658 0.01631088
  0.01657632 0.10670486]
 [0.04764707 0.04211974 0.03945585 0.05724531 0.09516675 0.03988035
  0.03644992 0.03967259 0.04276205 0.06873357 0.05706487 0.05049961
  0.04055208 0.04844389 0.06933054 0.04548016 0.07622115 0.09462564
  0.07076475 0.06951219 0.09244048 0.04603164 0.05442257 0.04159559
  0.0284474  0.04488317 0.04516888 0.0728431  0.0464472  0.01588647
  0.01179143 0.12152087 0.0461982  0.05319599 0.03685573 0.03503155
  0.04461142 0.06125447 0.03113254 0.03682658 0.0118808  0.01871326
  0.02214695 0.07171798]
 [0.04758075 0.04813766 0.04411105 0.06557034 0.06365376 0.04776572
  0.04624709 0.0482666  0.05978945 0.0665863  0.05165221 0.04831268
  0.04495739 0.05553505 0.05972183 0.03923983 0.05281511 0.06119123
  0.05193457 0.0638995  0.05930963 0.06351074 0.06389539 0.03488433
  0.01993774 0.04955227 0.04009703 0.08620892 0.050259   0.01351888
  0.00763375 0.10190388 0.16518919 0.10096829 0.03168309 0.03148586
  0.05215547 0.04970454 0.02352868 0.06114669 0.00948497 0.01737046
  0.01840913 0.10303065]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.0292417  0.04273395 0.04389179 ... 0.01739411 0.0425919  0.04112753]
 [0.0299076  0.03132567 0.03123636 ... 0.02491323 0.03206063 0.02757341]
 [0.03051507 0.04361342 0.04631048 ... 0.01548977 0.03478851 0.02495304]
 ...
 [0.03051668 0.04351633 0.04164729 ... 0.01566211 0.04310424 0.0456005 ]
 [0.0311961  0.03347103 0.03061509 ... 0.02128034 0.04194295 0.05141908]
 [0.03093326 0.03768751 0.03326361 ... 0.01867803 0.03647352 0.05166212]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' park', '.', ' In', ' fact', ',', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' office', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 26), x_tokens=26, y_tokens=41, max_supp_attn=0.0488, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 26)
DEBUG result.interpretability.attn_scores 1066 
 [[0.02260021 0.03681357 0.04158325 ... 0.01483726 0.00945423 0.01660371]
 [0.02303962 0.04187252 0.04317718 ... 0.01299136 0.00609899 0.01797905]
 [0.02350375 0.02576337 0.02599269 ... 0.00989464 0.00546404 0.01320079]
 ...
 [0.02391855 0.0271886  0.02550375 ... 0.00918853 0.00466094 0.01230622]
 [0.02384555 0.0207058  0.0200546  ... 0.01272302 0.00769389 0.01538981]
 [0.02397173 0.02613238 0.0235227  ... 0.01072498 0.00612558 0.01288243]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 32), x_tokens=32, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 32)
DEBUG result.interpretability.attn_scores 608 
 [[0.04989603 0.07456218 0.07528825 0.10266046 0.07934541 0.07746661
  0.06049325 0.06323545 0.07596349 0.0775545  0.05913337 0.05416185
  0.05481759 0.13979355 0.13574168 0.05595971 0.04282    0.03897739
  0.03295453 0.04142335 0.03631646 0.05652536 0.08650155 0.04107616
  0.02595637 0.06525806 0.07230773 0.06771211 0.15416011 0.02896665
  0.03840335 0.01560783]
 [0.05136731 0.06992535 0.06736656 0.11275762 0.09807688 0.11091735
  0.06424196 0.06452882 0.08054376 0.1009823  0.07779045 0.07972129
  0.07598121 0.19762833 0.1614106  0.06120164 0.0414567  0.04561719
  0.03496694 0.04315297 0.03699385 0.05796685 0.06554279 0.03290593
  0.02293978 0.05481002 0.07473667 0.0535998  0.13322073 0.03719408
  0.05014873 0.02006479]
 [0.05216963 0.06599449 0.07341649 0.09521841 0.07364937 0.0858481
  0.06480544 0.06861496 0.07373479 0.07999101 0.06029657 0.07564192
  0.07146138 0.12719423 0.08887126 0.05040902 0.03837764 0.0383558
  0.03172448 0.03856882 0.03284957 0.05354529 0.06458019 0.03891519
  0.02852561 0.05297298 0.06333933 0.04765537 0.11284919 0.06246327
  0.07145464 0.03552169]
 [0.05035231 0.07261551 0.07715376 0.05714591 0.04313537 0.06034483
  0.06355587 0.07252676 0.06450941 0.05380735 0.05054871 0.06253695
  0.06375881 0.03997711 0.03608415 0.06074282 0.0487484  0.04415733
  0.03991457 0.04684637 0.04147683 0.05877769 0.08805334 0.06919096
  0.05969134 0.07220468 0.07931429 0.05669698 0.07847203 0.13556854
  0.10745969 0.10225024]
 [0.05193202 0.06725162 0.07082307 0.04128658 0.02980387 0.04564201
  0.06184978 0.05945362 0.06236603 0.03970869 0.0423805  0.04504116
  0.04725721 0.02590704 0.02759197 0.06337587 0.05077801 0.04335589
  0.04797446 0.05264289 0.0444162  0.05228864 0.07508585 0.06778633
  0.05943955 0.05956023 0.07067286 0.03774003 0.03704447 0.07832721
  0.05298922 0.1350092 ]
 [0.053174   0.03157594 0.03281811 0.02035489 0.01695723 0.0256981
  0.03080359 0.02940189 0.03379568 0.02330952 0.02897934 0.02567106
  0.02773145 0.01216065 0.01554005 0.03737317 0.03548972 0.03074417
  0.03968957 0.04116102 0.03591682 0.03857622 0.03637978 0.04491707
  0.04646381 0.03910183 0.03907327 0.02499918 0.01828129 0.03111954
  0.02761425 0.06030064]
 [0.05225116 0.05576156 0.0563336  0.03377615 0.02506469 0.04771954
  0.05277409 0.05207383 0.04748528 0.03606278 0.0412489  0.04854859
  0.04665292 0.02093262 0.02200335 0.05562939 0.05365103 0.04296147
  0.05105931 0.05281482 0.04905205 0.05857925 0.06328289 0.07166719
  0.07793512 0.06181687 0.07221431 0.03686412 0.03688332 0.09174111
  0.05031863 0.11470984]
 [0.05330792 0.06589364 0.07071701 0.05385155 0.03639668 0.06220631
  0.06635762 0.07357287 0.06072438 0.06195371 0.06033964 0.08321631
  0.07478905 0.03453137 0.02769531 0.05371476 0.04778751 0.04870833
  0.04644518 0.04985653 0.04453409 0.0570997  0.05095437 0.05506326
  0.05997736 0.05247307 0.07020576 0.04380182 0.03943245 0.09229925
  0.07245665 0.14064784]
 [0.0541383  0.04782947 0.05267744 0.03651749 0.02918385 0.04576932
  0.05566976 0.0523306  0.04579926 0.04149467 0.04715965 0.05156126
  0.05450315 0.02309615 0.02120773 0.04964575 0.0448838  0.04275849
  0.04689174 0.04718726 0.04315234 0.05518056 0.040948   0.05060515
  0.05657208 0.04130829 0.04867226 0.03763788 0.03180809 0.06681791
  0.05885537 0.09607955]
 [0.0535569  0.0361471  0.03491448 0.02346788 0.02019892 0.03108579
  0.04167406 0.03750761 0.03401753 0.02809976 0.03917812 0.03516937
  0.04180224 0.01428728 0.01554628 0.04895321 0.05064124 0.04617462
  0.05683269 0.05191221 0.04982935 0.05389867 0.0317839  0.05514318
  0.06191345 0.03641955 0.03127262 0.03503081 0.02300508 0.04746665
  0.04494042 0.05227599]
 [0.05313051 0.0344162  0.0313415  0.02177313 0.01765663 0.02789909
  0.03905231 0.03466728 0.03167961 0.02562776 0.03607627 0.03035269
  0.03830779 0.01329494 0.01380252 0.05072381 0.05028704 0.05659867
  0.07575865 0.07063416 0.06503773 0.04829425 0.02880896 0.06643646
  0.08502679 0.041756   0.0255506  0.03858986 0.01911232 0.04810376
  0.04157713 0.03632353]
 [0.05394468 0.0340855  0.0330968  0.02156203 0.01927426 0.02910278
  0.04274623 0.03951106 0.03328373 0.02646161 0.04136091 0.03702851
  0.04303816 0.01367683 0.01377886 0.05162937 0.06032814 0.04994625
  0.08594402 0.06267378 0.06234314 0.04661355 0.02621159 0.05746696
  0.09758452 0.04982292 0.02823645 0.04345189 0.01828589 0.04640393
  0.05218761 0.03398908]
 [0.0540333  0.0311866  0.03019973 0.01865716 0.0170409  0.02603954
  0.04503929 0.03895314 0.03203115 0.02290442 0.05425657 0.03442654
  0.04600762 0.01176457 0.01207619 0.0552456  0.06368511 0.04957393
  0.07395183 0.05899519 0.05876634 0.04560116 0.02367092 0.06194579
  0.07590369 0.05154752 0.02524698 0.04423326 0.01642776 0.04015606
  0.0602473  0.02335452]
 [0.05249742 0.04577491 0.04675853 0.02703876 0.02241083 0.0424283
  0.06383239 0.05743432 0.06020219 0.03307628 0.04277397 0.04108858
  0.0526028  0.01616972 0.01585133 0.04911103 0.04788395 0.0466069
  0.05635986 0.06086116 0.05384176 0.05235699 0.0478923  0.06912436
  0.05709522 0.06132097 0.03911998 0.04466034 0.02895432 0.05151144
  0.0597659  0.03443433]
 [0.05465648 0.03764345 0.03915504 0.03011608 0.02196888 0.03672811
  0.04600973 0.04937932 0.03995617 0.03554532 0.04635834 0.04318891
  0.04713963 0.0189366  0.01679137 0.04092212 0.03904045 0.04004598
  0.04759756 0.04711908 0.04420639 0.04754865 0.02877438 0.04243491
  0.04168225 0.0425631  0.03582689 0.04612308 0.02990353 0.04481921
  0.07061381 0.03299669]
 [0.05281237 0.05021707 0.05260257 0.07132535 0.05971501 0.06319974
  0.05018887 0.05159832 0.06388824 0.07591636 0.05804772 0.06294351
  0.05959991 0.08657259 0.10307034 0.04552585 0.04253156 0.04975378
  0.03979465 0.04453874 0.04380275 0.05068366 0.05229317 0.03680751
  0.02945454 0.05324402 0.0538104  0.0703659  0.06815887 0.03194536
  0.05638627 0.02022201]
 [0.05224655 0.06671452 0.05874193 0.10000832 0.20556131 0.08207113
  0.05447758 0.05515825 0.06048546 0.10157073 0.08497065 0.08087894
  0.05742613 0.11450689 0.15397301 0.06487652 0.07018952 0.08646987
  0.05318593 0.05424653 0.06626063 0.05057338 0.06706415 0.03855701
  0.02653085 0.05191895 0.07202747 0.07191993 0.06448174 0.01842104
  0.02468771 0.01326333]
 [0.05210821 0.05436137 0.04703306 0.06436497 0.11198978 0.04540281
  0.04312189 0.04763263 0.04444088 0.06695389 0.06765772 0.05563924
  0.04581895 0.04035616 0.06331254 0.0585755  0.10347779 0.11649673
  0.07820049 0.07110102 0.11315762 0.04836804 0.05693468 0.05620295
  0.05372661 0.06060021 0.05465119 0.09381975 0.04086125 0.02555763
  0.03001365 0.0196994 ]
 [0.05242486 0.05804362 0.04956201 0.06811722 0.07257023 0.05443052
  0.05330627 0.05241936 0.0550929  0.06897939 0.06144253 0.05318335
  0.051304   0.04921331 0.05565147 0.04638485 0.06794248 0.08269719
  0.06075357 0.06426408 0.07804607 0.06752217 0.06523714 0.04375369
  0.03358097 0.05130057 0.04372095 0.10509786 0.0486575  0.02111734
  0.02987968 0.01324949]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' office', ',', ' not', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.02815259 0.04163479 0.04215299 ... 0.06150072 0.03101198 0.01984589]
 [0.02862113 0.0346388  0.03640068 ... 0.03887384 0.03334133 0.02839496]
 [0.02929657 0.04485304 0.04838076 ... 0.04516305 0.02672643 0.01694004]
 ...
 [0.02954787 0.0385871  0.04112982 ... 0.05034649 0.02657265 0.01370759]
 [0.0301245  0.0296879  0.03078229 ... 0.03539635 0.02585349 0.0192204 ]
 [0.03008836 0.03027927 0.0329189  ... 0.04743636 0.02542833 0.01701043]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' bedroom', ',', ' which', ' contrad', 'icts', ' sentence', ' ', '11', "'s", ' claim', ' that', ' Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' office', '.', ' Therefore', ',', ' sentence', ' ', '11', ' is', ' outdated', ',', ' and', ' we', ' should', ' rely', ' on', ' sentence', ' ', '10', '.', ' Sentence', ' ', '10', ' does', ' not', ' mention', ' the', ' cinema', ',', ' so', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(74, 44), x_tokens=44, y_tokens=74, max_supp_attn=0.027, attn_on_target=0.0135)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (74, 44)
DEBUG result.interpretability.attn_scores 3256 
 [[0.01217198 0.01709935 0.01823972 ... 0.05734509 0.0057989  0.03278141]
 [0.0124886  0.01336509 0.0146036  ... 0.03654226 0.01064099 0.01464749]
 [0.0127439  0.01855889 0.02124941 ... 0.04908896 0.01014089 0.03452273]
 ...
 [0.01295266 0.02058755 0.01948008 ... 0.021585   0.00456634 0.05833685]
 [0.01342912 0.01683205 0.01438785 ... 0.0091057  0.0045857  0.02597887]
 [0.01330828 0.01809598 0.01544912 ... 0.01281899 0.00466382 0.0383422 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '13', ' talks', ' about', ' Mary', ',', ' and', ' sentence', ' ', '14', ' talks', ' about', ' Bill', ',', ' but', ' neither', ' mentions', ' Fred', ' or', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 50), x_tokens=50, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 50)
DEBUG result.interpretability.attn_scores 2100 
 [[0.02189729 0.02919233 0.02825829 ... 0.01958825 0.02726369 0.05094541]
 [0.02237017 0.03352866 0.0286483  ... 0.02573431 0.02607161 0.02651764]
 [0.02299271 0.0291938  0.02844511 ... 0.01544842 0.02190482 0.02974449]
 ...
 [0.02340823 0.02657467 0.02257036 ... 0.02127318 0.03744819 0.02770438]
 [0.0237707  0.02911448 0.02725462 ... 0.01567374 0.03186456 0.02595537]
 [0.02384966 0.02612077 0.02474816 ... 0.0153583  0.02661367 0.03368413]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' park', '.', ' Sentence', ' ', '1', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' school', ',', ' and', ' sentence', ' ', '2', ' contrad', 'icts', ' sentence', ' ', '1', ',', ' stating', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' about', ' Fred', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 26), x_tokens=26, y_tokens=59, max_supp_attn=0.1186, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 26)
DEBUG result.interpretability.attn_scores 1534 
 [[0.01563879 0.03226658 0.03401697 ... 0.00914974 0.00496043 0.01503734]
 [0.01613237 0.02030644 0.02019073 ... 0.006284   0.00408946 0.0099183 ]
 [0.01640818 0.02290396 0.02563577 ... 0.00814329 0.00546167 0.01025046]
 ...
 [0.01648461 0.02016078 0.02027483 ... 0.00569973 0.00296231 0.00935399]
 [0.01647983 0.01481007 0.01534624 ... 0.00816675 0.00541926 0.0120272 ]
 [0.01658466 0.0178229  0.01725965 ... 0.00662277 0.00416252 0.00922803]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Bill', ' and', ' Julie', '.', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 32), x_tokens=32, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 32)
DEBUG result.interpretability.attn_scores 1120 
 [[0.02651935 0.03613055 0.04120679 ... 0.0125323  0.01153973 0.01782519]
 [0.0273969  0.03266107 0.03652843 ... 0.01623154 0.01641328 0.02162851]
 [0.02798845 0.03135705 0.03727852 ... 0.02052913 0.01963703 0.02350217]
 ...
 [0.02818913 0.03473398 0.02841872 ... 0.01303158 0.01260491 0.01493152]
 [0.02861307 0.03573543 0.03197606 ... 0.01448966 0.01148594 0.0142451 ]
 [0.02868863 0.03252343 0.03023802 ... 0.01545894 0.01113323 0.01469993]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' at', ' all', '.', ' They', ' only', ' talk', ' about', ' Bill', ' and', ' Julie', '.', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 38), x_tokens=38, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 38)
DEBUG result.interpretability.attn_scores 1330 
 [[0.02685302 0.03348126 0.0393152  ... 0.03230935 0.04705754 0.05356725]
 [0.027134   0.0257974  0.03115331 ... 0.02605959 0.03550299 0.05166942]
 [0.02804326 0.03814418 0.04746072 ... 0.04523654 0.04509232 0.04037956]
 ...
 [0.02841037 0.02849165 0.02713487 ... 0.01835547 0.04903596 0.03297473]
 [0.02817012 0.040596   0.03781201 ... 0.02021891 0.05296538 0.04152157]
 [0.02853642 0.0309469  0.0297409  ... 0.02105766 0.07771657 0.05621979]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 44), x_tokens=44, y_tokens=43, max_supp_attn=0.0465, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 44)
DEBUG result.interpretability.attn_scores 1892 
 [[0.02153117 0.0303729  0.03193055 ... 0.02313584 0.02587772 0.04633608]
 [0.02186562 0.03135486 0.02920957 ... 0.02353418 0.02334745 0.03120482]
 [0.0225172  0.03359123 0.03576654 ... 0.01737433 0.02091959 0.03396904]
 ...
 [0.02272351 0.03113357 0.03068239 ... 0.01962895 0.0317449  0.03575274]
 [0.02317447 0.02584898 0.02550671 ... 0.01915512 0.03459815 0.02441019]
 [0.0230483  0.02629294 0.02517387 ... 0.01979297 0.02935801 0.03740216]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' is', ' redundant', ' and', ' does', ' not', ' provide', ' any', ' new', ' information', '.', ' Sentence', ' ', '13', ' mentions', ' Bill', "'s", ' possible', ' locations', ',', ' but', ' does', ' not', ' provide', ' information', ' about', ' Julie', "'s", ' location', '.', ' We', ' can', ' refer', ' back', ' to', ' sentence', ' ', '8', ',', ' which', ' states', ' that', ' Julie', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 50), x_tokens=50, y_tokens=57, max_supp_attn=0.0175, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 50)
DEBUG result.interpretability.attn_scores 2850 
 [[0.0160465  0.02289017 0.02118204 ... 0.00897832 0.02517824 0.02899305]
 [0.01638828 0.02519655 0.02249286 ... 0.0119343  0.01372142 0.01938787]
 [0.01681776 0.02634786 0.02451907 ... 0.01203137 0.02501926 0.01905257]
 ...
 [0.01710155 0.02249558 0.02029423 ... 0.00596191 0.05007397 0.02093983]
 [0.01738697 0.01620581 0.01435161 ... 0.00755458 0.04851162 0.01813052]
 [0.0173003  0.02208101 0.01894164 ... 0.00638161 0.05818193 0.02525428]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '1', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Mary', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 26), x_tokens=26, y_tokens=29, max_supp_attn=0.069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 26)
DEBUG result.interpretability.attn_scores 754 
 [[0.03234705 0.05786577 0.06205583 0.09276655 0.08164956 0.06644517
  0.04754535 0.04131693 0.04558104 0.06210388 0.04477445 0.03358257
  0.03429331 0.13438076 0.13496086 0.04147076 0.03412157 0.02502993
  0.02666513 0.02836237 0.02645327 0.04958967 0.07995711 0.01018481
  0.00701432 0.03406745]
 [0.03344293 0.03608942 0.03680699 0.06720866 0.058624   0.0560616
  0.03362834 0.03033262 0.03680822 0.05410068 0.03854327 0.03591822
  0.03427688 0.14162226 0.16058283 0.03923949 0.03642668 0.02873537
  0.02924795 0.02942443 0.02493205 0.04119513 0.04670582 0.00822585
  0.00651145 0.02246561]
 [0.03395848 0.04071557 0.04740537 0.07117349 0.06366614 0.07094189
  0.0447358  0.04226642 0.04778045 0.06380078 0.04510373 0.0575527
  0.05355908 0.11160015 0.09812706 0.03284731 0.0330047  0.02897437
  0.02812472 0.02901798 0.02329369 0.03715596 0.04272177 0.01192026
  0.00889732 0.02370998]
 [0.03268529 0.0529246  0.05993249 0.05329228 0.05445986 0.06299651
  0.05031047 0.05302114 0.04929166 0.05369138 0.04390622 0.05998741
  0.05414381 0.06669885 0.05597537 0.04267639 0.04147337 0.03623844
  0.03430676 0.03642198 0.03223885 0.04227003 0.06193734 0.0349258
  0.02211389 0.04819694]
 [0.03406103 0.05586382 0.06322347 0.06357586 0.05600977 0.07595173
  0.06054828 0.06322035 0.06127135 0.06425576 0.04671172 0.06490122
  0.06277773 0.049935   0.03155833 0.03159112 0.03303076 0.0316025
  0.03100972 0.03359047 0.02706062 0.04259525 0.04575412 0.01792783
  0.01571131 0.03420794]
 [0.03335267 0.06797368 0.07016814 0.03778259 0.02954844 0.04696142
  0.05734261 0.0538601  0.0538643  0.03760944 0.03565211 0.04578205
  0.04699565 0.022361   0.01915651 0.05183636 0.04184452 0.03577386
  0.03644212 0.03903862 0.0363511  0.04075344 0.08123863 0.04401317
  0.03337339 0.04378573]
 [0.03413714 0.05368006 0.06125906 0.03235973 0.02634135 0.03639225
  0.06048861 0.0453728  0.05153541 0.03097641 0.02971625 0.03362324
  0.03351824 0.01774832 0.01733256 0.04931386 0.03888848 0.03219553
  0.03687188 0.04019259 0.03582171 0.03641489 0.06951895 0.04400941
  0.02508892 0.03850784]
 [0.03450547 0.02020902 0.02310002 0.01499147 0.0127592  0.01821735
  0.02201052 0.02104605 0.02704567 0.01702525 0.0162247  0.0172545
  0.01728428 0.00810762 0.00873552 0.02251349 0.0225145  0.02078607
  0.0268617  0.02912995 0.02998555 0.02526175 0.04983407 0.06565598
  0.03517086 0.05684861]
 [0.0342486  0.03338354 0.03473969 0.02122943 0.01858899 0.02626947
  0.03451069 0.03019657 0.03032527 0.02229514 0.02675127 0.02658894
  0.0270452  0.01179819 0.01243918 0.04396147 0.03077058 0.0287479
  0.02857768 0.03044636 0.03138811 0.03342827 0.04026043 0.06294812
  0.04869958 0.04286501]
 [0.03440496 0.03264071 0.03228826 0.02370283 0.02004432 0.02905582
  0.03555047 0.03561149 0.03128131 0.0265374  0.03184548 0.03470344
  0.03586125 0.01307398 0.01168969 0.04326317 0.03372739 0.03319809
  0.03006474 0.03179578 0.0352851  0.03456878 0.02966245 0.05746328
  0.03674761 0.03029059]
 [0.03377771 0.02698879 0.02241941 0.01796553 0.01416654 0.01853759
  0.02754457 0.02721773 0.02382814 0.01891187 0.02646629 0.02246774
  0.02747244 0.00851092 0.00858931 0.04611532 0.03321426 0.04415327
  0.03695551 0.04300403 0.05204173 0.03165844 0.02358757 0.0996821
  0.05615161 0.03063099]
 [0.03487728 0.02750216 0.02573178 0.02170373 0.01858194 0.02635924
  0.03242352 0.03408097 0.0271716  0.0234106  0.02956563 0.02961737
  0.03173532 0.01085907 0.00976516 0.0428717  0.02537993 0.04510704
  0.03101765 0.04553848 0.03771221 0.02729118 0.02266929 0.06502394
  0.0372616  0.03114322]
 [0.03498412 0.02228778 0.01944938 0.0157363  0.01280437 0.01778551
  0.02329151 0.02303006 0.02179369 0.01726943 0.027525   0.02250471
  0.02452281 0.0077256  0.00771522 0.04355613 0.02641977 0.04456235
  0.03296377 0.0444104  0.04401881 0.02538375 0.01815926 0.06810941
  0.04828484 0.02632568]
 [0.03482179 0.02151383 0.01881461 0.01400774 0.0115636  0.0164912
  0.02335245 0.02265168 0.02189124 0.01605911 0.03116773 0.02149918
  0.02346839 0.00714157 0.00759515 0.0360265  0.02947512 0.04083006
  0.03622053 0.04121452 0.04093415 0.02690854 0.01866925 0.06100675
  0.06400653 0.03655133]
 [0.03387821 0.02653376 0.02333538 0.01868401 0.01686829 0.0230889
  0.03084798 0.02879643 0.02881761 0.02061229 0.02660952 0.02379711
  0.02733277 0.01018928 0.00973474 0.02463873 0.03246514 0.0301564
  0.04615197 0.03845743 0.03815603 0.0298923  0.02712265 0.0405941
  0.09979282 0.08793239]
 [0.03535212 0.02780357 0.02577254 0.02045122 0.01642929 0.02293969
  0.02834186 0.02888004 0.02775516 0.02193679 0.03224711 0.02741555
  0.02785724 0.01074213 0.00986095 0.02694512 0.02565367 0.02778383
  0.03421886 0.03252776 0.03288309 0.03258241 0.01944223 0.03080495
  0.04105945 0.03441326]
 [0.03555294 0.02886142 0.03100652 0.02750428 0.02164505 0.03041441
  0.03147896 0.0377032  0.03147287 0.03056887 0.03369416 0.04140281
  0.03811935 0.01557877 0.0109717  0.02359027 0.02576128 0.02897123
  0.02836951 0.02700842 0.0263137  0.03361897 0.01887703 0.01862333
  0.02819282 0.02743443]
 [0.03575733 0.03575884 0.03622012 0.03494731 0.0247251  0.03660089
  0.04059574 0.04799736 0.03398091 0.03790455 0.04535918 0.05035426
  0.04862111 0.01849678 0.01238261 0.0271384  0.02602483 0.03171081
  0.02800996 0.02798505 0.02657991 0.03457965 0.02012804 0.01664237
  0.02460086 0.02096999]
 [0.03563454 0.03269321 0.0319286  0.03050468 0.02288582 0.03327717
  0.03715393 0.04179876 0.0341778  0.03466884 0.04142408 0.04441497
  0.04577417 0.01649238 0.01240796 0.03236194 0.02890083 0.03482322
  0.03099751 0.03031756 0.02964289 0.03436803 0.01778657 0.02017893
  0.02305817 0.01830619]
 [0.03539733 0.02512686 0.02310205 0.01878414 0.01382917 0.02065191
  0.02679806 0.02869865 0.02678316 0.02151695 0.02899124 0.02709023
  0.03104515 0.00985049 0.0088249  0.0353932  0.03137848 0.03433895
  0.03287403 0.03144111 0.03651995 0.03244154 0.01558895 0.03220726
  0.03640693 0.02195824]
 [0.03539385 0.02666891 0.02351674 0.01956586 0.0137346  0.01980036
  0.03032746 0.03001518 0.02705454 0.02127454 0.03023453 0.02543332
  0.0315395  0.00948335 0.00863146 0.03800439 0.03446479 0.03908454
  0.03649218 0.03528031 0.04064626 0.02919942 0.01499032 0.03445585
  0.03920496 0.02193609]
 [0.03548875 0.02555272 0.02225944 0.0191425  0.01493161 0.01973728
  0.02579891 0.02765138 0.02647986 0.02229514 0.03073361 0.02723884
  0.02915678 0.0100936  0.00882357 0.03375738 0.03580443 0.03580742
  0.03812575 0.03374191 0.03879836 0.02925847 0.01523951 0.02756808
  0.04282951 0.02332148]
 [0.03578962 0.02191636 0.01992417 0.01429583 0.01188685 0.01611274
  0.02359748 0.0234552  0.02513005 0.01708849 0.03167124 0.02203521
  0.02513355 0.00804171 0.00706259 0.03064869 0.03495262 0.03212437
  0.03944799 0.03488423 0.03781223 0.0274099  0.01487263 0.03175616
  0.04381452 0.02407631]
 [0.03442103 0.0233359  0.02073011 0.01431691 0.01186568 0.01735125
  0.02555007 0.02693713 0.02740219 0.01787722 0.02466633 0.02098976
  0.02590725 0.00833656 0.00730566 0.02136044 0.03111871 0.02649259
  0.04512885 0.03615145 0.03767722 0.02748372 0.02025444 0.03273061
  0.09966841 0.08175757]
 [0.03558126 0.0269499  0.026283   0.02144199 0.01617803 0.02321141
  0.02588016 0.03007895 0.0325034  0.02474564 0.02846558 0.02844696
  0.02785587 0.01278551 0.01034655 0.02250771 0.02822874 0.02650781
  0.03501428 0.03176924 0.03259824 0.03063193 0.01885886 0.02044407
  0.03318083 0.03138096]
 [0.03424573 0.03522602 0.03512279 0.05258082 0.05388112 0.04723313
  0.03190172 0.03279704 0.03870432 0.05367031 0.03880757 0.03999432
  0.03797694 0.08667625 0.10460852 0.02764775 0.03548652 0.03107616
  0.0310085  0.02952992 0.02678414 0.03861657 0.03972864 0.00898841
  0.00829225 0.02740849]
 [0.03408225 0.03828679 0.03587574 0.06159433 0.11409455 0.04866573
  0.02999356 0.03058629 0.03785649 0.06323516 0.04664823 0.03920616
  0.03118072 0.09131586 0.11268688 0.03414337 0.04783477 0.03996625
  0.0367156  0.03223005 0.03187186 0.03591825 0.03975407 0.00770249
  0.0066418  0.02194257]
 [0.03380623 0.03412636 0.03126429 0.04995108 0.10367715 0.0332141
  0.02481245 0.02919182 0.03258322 0.05522492 0.04506386 0.04157434
  0.03112184 0.03999875 0.048714   0.02934684 0.07291868 0.06336389
  0.0515453  0.03922437 0.04963858 0.03195331 0.03407076 0.01510059
  0.01675779 0.03058884]
 [0.03401427 0.04152062 0.03626393 0.04873898 0.06455966 0.03923438
  0.0336385  0.03218767 0.03982886 0.04933319 0.04142999 0.03462286
  0.0344234  0.04035527 0.04341505 0.02523273 0.0487149  0.04185768
  0.04057    0.0378633  0.03656064 0.05757041 0.05260925 0.01110602
  0.01146576 0.02697624]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '5', ',', ' Fred', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.2069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03243139 0.0522108  0.05264828 0.07262766 0.06448617 0.05591552
  0.03723367 0.04516688 0.05836235 0.05604567 0.03834561 0.03889356
  0.03832206 0.11059771 0.10834291 0.03850943 0.03141055 0.02483566
  0.02605995 0.02648648 0.02167199 0.03808772 0.06218898 0.02179001
  0.01122371 0.03852633 0.05037905 0.0455441  0.09892806 0.01377775
  0.00844232 0.04664703]
 [0.03329207 0.05233674 0.05041487 0.08760753 0.08947366 0.08581281
  0.04255917 0.0478373  0.059037   0.07838729 0.05550238 0.06337003
  0.05748308 0.15756059 0.12772241 0.04264094 0.03286774 0.03067923
  0.02840097 0.02789883 0.02325142 0.04091216 0.04937769 0.01958874
  0.01275686 0.03197635 0.04915579 0.03842785 0.09263571 0.01585146
  0.0128072  0.05151595]
 [0.03391051 0.04615044 0.05118438 0.07171722 0.06440558 0.06367078
  0.03818186 0.04427117 0.05423166 0.06042894 0.04005216 0.05290856
  0.04695509 0.11414003 0.08091952 0.03535881 0.03063066 0.02541073
  0.02509834 0.02410392 0.01997668 0.03697989 0.04423087 0.02129714
  0.01439032 0.02951514 0.04538943 0.03175498 0.08351646 0.02671417
  0.01793339 0.04579386]
 [0.03263904 0.04289608 0.04605383 0.04003258 0.03400043 0.03872508
  0.03447377 0.04182259 0.0400358  0.03577053 0.03114909 0.03875292
  0.0369439  0.02960802 0.02818256 0.03623967 0.03404416 0.02784995
  0.02894225 0.02868645 0.02489193 0.03906143 0.05074225 0.0377541
  0.03077449 0.04298504 0.05192422 0.03521291 0.07283068 0.07431312
  0.03095482 0.03111993]
 [0.03414227 0.03127241 0.0358142  0.02916755 0.02175486 0.03047907
  0.02743787 0.02996476 0.03359002 0.02678692 0.02488636 0.02734479
  0.02601986 0.01861971 0.01894203 0.0261052  0.02422848 0.02144667
  0.02635765 0.02660015 0.02307847 0.03323789 0.03575419 0.02820968
  0.02725988 0.03938138 0.04651612 0.02923723 0.05285013 0.06350657
  0.02725893 0.02500204]
 [0.03363187 0.0478028  0.05154308 0.03095942 0.02335927 0.03409212
  0.03693974 0.03849293 0.04555838 0.02866736 0.02495613 0.03097667
  0.03072087 0.0215202  0.0200704  0.03707264 0.03075824 0.02383847
  0.02675515 0.02679884 0.02211608 0.03870896 0.05856347 0.03771288
  0.03013547 0.0396219  0.05514333 0.02717621 0.04665301 0.10759591
  0.02781721 0.02155914]
 [0.03403956 0.0350171  0.03694086 0.02344829 0.01873101 0.02435111
  0.02967966 0.02685276 0.03588853 0.02181227 0.02139633 0.02113719
  0.02141652 0.01442502 0.01619756 0.03362922 0.03102587 0.02421317
  0.03089677 0.03110302 0.0255769  0.03193121 0.0497112  0.04052981
  0.02877322 0.04330912 0.03982037 0.02344029 0.02250402 0.08104374
  0.01512398 0.01496405]
 [0.03461679 0.02047324 0.02054518 0.01523871 0.01284815 0.01676086
  0.01741291 0.01639502 0.021063   0.01695058 0.01849126 0.01606879
  0.01676523 0.00929284 0.01133507 0.02232288 0.02320726 0.02180267
  0.02805506 0.0290024  0.02683326 0.02612898 0.02753843 0.03236404
  0.02634965 0.03328594 0.01942732 0.0216598  0.01524541 0.0344767
  0.01312312 0.0125845 ]
 [0.03444109 0.02654368 0.02971487 0.02104053 0.01737202 0.02373803
  0.02409677 0.02315268 0.02717974 0.02120539 0.02197055 0.02152699
  0.02140231 0.01388412 0.01552141 0.03130308 0.03090487 0.02486705
  0.03080458 0.03054721 0.02693601 0.03317967 0.03642121 0.03899155
  0.0301912  0.03282223 0.03006648 0.0222692  0.02749495 0.05979002
  0.02305382 0.01545902]
 [0.03432698 0.0319038  0.03358692 0.02550124 0.02172921 0.02866259
  0.03115592 0.03066585 0.03089382 0.02745803 0.02760898 0.03194504
  0.03300478 0.01721405 0.01700752 0.03703567 0.03634108 0.03516092
  0.03662415 0.0360373  0.03180103 0.03860109 0.03248114 0.04024391
  0.04134184 0.03561059 0.03112878 0.02564444 0.02707671 0.05404776
  0.03871588 0.01873496]
 [0.03415689 0.02782997 0.02583975 0.02008547 0.01634087 0.02294999
  0.02593504 0.02407352 0.02408113 0.02169931 0.02452859 0.02349583
  0.02617792 0.01238928 0.01419532 0.03758067 0.03247123 0.04344972
  0.04633077 0.05946548 0.04849497 0.03347495 0.02471778 0.04954365
  0.05646902 0.03341027 0.02827987 0.02468453 0.01635544 0.03897059
  0.02778403 0.01358866]
 [0.03483371 0.02669313 0.02743701 0.02025729 0.01880976 0.0256299
  0.0273565  0.0269281  0.02700457 0.02483338 0.03047292 0.03023104
  0.02874421 0.01368582 0.01455306 0.03708416 0.03316958 0.03860268
  0.03732612 0.05461623 0.055863   0.03046389 0.02370882 0.04485695
  0.04848375 0.03510612 0.03006648 0.02686197 0.01619393 0.03949812
  0.03344182 0.0191127 ]
 [0.03565558 0.02134141 0.02145725 0.01506912 0.01476209 0.02025727
  0.0217022  0.02024787 0.02207378 0.01914775 0.0290812  0.02449252
  0.0230149  0.01069967 0.01164638 0.03315211 0.03389357 0.03253202
  0.03491152 0.03820057 0.0510562  0.02748973 0.01806016 0.03944409
  0.04404281 0.03003796 0.02148755 0.02262924 0.01292686 0.02656101
  0.02387898 0.0147136 ]
 [0.03514226 0.02190899 0.02261917 0.01454026 0.01528774 0.01990734
  0.02537874 0.02216697 0.02284074 0.01859624 0.04157268 0.02529761
  0.02490987 0.01053893 0.01252898 0.03714054 0.04556033 0.03574869
  0.04310764 0.04316438 0.04891395 0.03004825 0.02151311 0.04546383
  0.05744241 0.04100996 0.02234061 0.02472397 0.01392626 0.02694696
  0.02290668 0.01625891]
 [0.03351192 0.09124799 0.06269631 0.03687282 0.03598214 0.04316742
  0.14814587 0.08145609 0.05481635 0.04022911 0.08585366 0.05366646
  0.09300265 0.02038793 0.02181539 0.0818724  0.0703655  0.08824661
  0.05984578 0.07353885 0.06461011 0.04364379 0.05838252 0.0989575
  0.09808207 0.06189813 0.04017448 0.04542132 0.02185424 0.0354882
  0.01968396 0.02047742]
 [0.03511782 0.02565368 0.0289377  0.02167204 0.02020356 0.02591013
  0.02780652 0.02959852 0.02704008 0.02625092 0.03032265 0.03256325
  0.03030884 0.01658397 0.0153013  0.03070351 0.03352007 0.02981562
  0.03497833 0.03194435 0.03323491 0.0340021  0.02507864 0.0308477
  0.0348179  0.03205789 0.03016305 0.03132369 0.02643347 0.02805784
  0.08474274 0.03456047]
 [0.03501766 0.02606678 0.03091971 0.02615952 0.0230296  0.02961706
  0.02689984 0.03212663 0.03037541 0.03130531 0.02795065 0.03654907
  0.03218783 0.02022601 0.01595998 0.02340077 0.02279825 0.02388589
  0.02504167 0.02349441 0.02293462 0.03465297 0.02495344 0.02776065
  0.02591373 0.03521312 0.0346698  0.03295979 0.03552097 0.02975275
  0.10703055 0.03317679]
 [0.03522215 0.03302553 0.03765672 0.03445167 0.02859194 0.03820162
  0.03508819 0.04183305 0.03286803 0.04020696 0.03644764 0.04965139
  0.0470208  0.0261455  0.01817248 0.02647743 0.02456122 0.02756008
  0.02686341 0.02455323 0.02407225 0.03467142 0.02695031 0.02757385
  0.02708031 0.02926953 0.04072173 0.02708588 0.03247935 0.03024761
  0.12341534 0.03260485]
 [0.03516845 0.03449654 0.03801081 0.03832327 0.03646567 0.0419754
  0.03875476 0.04883766 0.03793849 0.04740093 0.03887153 0.05456406
  0.05166498 0.03330287 0.02468384 0.02896725 0.02849616 0.02980493
  0.02906488 0.02540082 0.02291293 0.03415285 0.02369725 0.02391762
  0.02491433 0.02618156 0.0335753  0.03224479 0.03276036 0.02862281
  0.09310102 0.04525093]
 [0.03513783 0.02715828 0.0266813  0.02278777 0.01888669 0.02620031
  0.03082214 0.03514445 0.02748748 0.02628192 0.02966436 0.03238109
  0.03570604 0.01539889 0.01394627 0.0315377  0.03132244 0.03244519
  0.03433641 0.03005316 0.03159325 0.03649641 0.02022115 0.03313054
  0.0408118  0.02860506 0.02304882 0.03740879 0.02063732 0.02799726
  0.05734532 0.02801096]
 [0.03508882 0.02678045 0.02509171 0.02244859 0.01630973 0.02361143
  0.02705759 0.02919251 0.02498775 0.02319437 0.02719576 0.0252995
  0.02879038 0.01351217 0.01378679 0.03372379 0.0307076  0.03717201
  0.04165803 0.03969974 0.04337308 0.02975427 0.01992551 0.03942128
  0.04078579 0.02953349 0.02061839 0.04367773 0.01536818 0.02723558
  0.04647982 0.02497007]
 [0.03542768 0.02622462 0.02518368 0.02187734 0.01780792 0.02422167
  0.02804564 0.03067841 0.02549432 0.02467391 0.03301128 0.03086341
  0.03074929 0.0140918  0.01385834 0.03310482 0.0377141  0.03532322
  0.03941596 0.03250194 0.04169033 0.03011844 0.02070616 0.0363737
  0.05607025 0.02946928 0.02430427 0.04329606 0.01683624 0.02551208
  0.04153756 0.04223136]
 [0.03575766 0.0211718  0.02147871 0.01698149 0.01349651 0.0202274
  0.02597821 0.02592146 0.02255431 0.01822857 0.03435649 0.02367988
  0.02635196 0.01115024 0.01128864 0.03114122 0.0380179  0.03112539
  0.03828604 0.03290471 0.04036034 0.02909872 0.01777294 0.03795318
  0.05879971 0.03099594 0.02077935 0.03687827 0.01372787 0.02463059
  0.02438244 0.03642431]
 [0.03468863 0.02787363 0.02979611 0.02270744 0.01607713 0.02986741
  0.03854055 0.03945772 0.03572993 0.02469163 0.03156411 0.02534008
  0.03068713 0.01478759 0.01443127 0.03172017 0.03258367 0.02918711
  0.03458675 0.03390624 0.03650508 0.03441539 0.02463782 0.03800054
  0.04008733 0.03570333 0.03022743 0.03731719 0.01810264 0.02445974
  0.01727269 0.02377409]
 [0.03554022 0.02537493 0.02777271 0.0286253  0.020764   0.03052317
  0.03048338 0.0360318  0.03081807 0.03015799 0.03106144 0.03197713
  0.0312803  0.02190271 0.01943357 0.02620159 0.02914783 0.02972278
  0.03234214 0.03132678 0.02976323 0.03229719 0.02213385 0.02325724
  0.02457501 0.03110601 0.02642888 0.0394889  0.02673222 0.01739559
  0.0299753  0.05426997]
 [0.03441716 0.03641591 0.03756015 0.05470003 0.05365636 0.0496069
  0.03104134 0.03394318 0.04107261 0.05146084 0.03639935 0.03765713
  0.03561547 0.07426059 0.09984407 0.03205906 0.02902486 0.03085823
  0.02738269 0.02589308 0.02402144 0.03627677 0.04154489 0.01742079
  0.01086952 0.03174501 0.03949846 0.04498622 0.04456458 0.00983182
  0.00847947 0.07876757]
 [0.03400586 0.04468279 0.04202389 0.07603288 0.1547016  0.06028532
  0.03473448 0.03750304 0.04323146 0.07489883 0.05607839 0.05536537
  0.03733106 0.09681099 0.1330901  0.04416199 0.05029292 0.05549352
  0.0374606  0.03284563 0.03610837 0.0349719  0.05029301 0.01849775
  0.0125872  0.02879767 0.05214956 0.04260778 0.0418768  0.00816822
  0.00642812 0.0799831 ]
 [0.03426851 0.03248985 0.02844258 0.04283084 0.06514369 0.02967823
  0.02503832 0.0277715  0.02772182 0.04216271 0.0365997  0.03288982
  0.02750812 0.03213305 0.04740149 0.03178322 0.05245306 0.06360932
  0.05179597 0.04310263 0.06216019 0.03226756 0.04086313 0.0282088
  0.02778744 0.03297918 0.0346698  0.04883601 0.02580143 0.01135553
  0.00974966 0.0757107 ]
 [0.03436966 0.03695662 0.03194828 0.04623606 0.04552256 0.03595413
  0.03201943 0.03246566 0.03602346 0.04106634 0.03460872 0.03111069
  0.02991457 0.03512976 0.03982129 0.02796999 0.03848084 0.04531252
  0.0372703  0.03612322 0.03619799 0.04487431 0.04783007 0.02088846
  0.01718294 0.02984636 0.02784529 0.05720095 0.02816667 0.00815052
  0.0071339  0.04273314]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '8', ' only', ' provides', ' information', ' about', ' Fred', "'s", ' possible', ' locations', ',', ' which', ' does', ' not', ' relate', ' to', ' Bill', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 38), x_tokens=38, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 38)
DEBUG result.interpretability.attn_scores 1520 
 [[0.02297889 0.02906183 0.0275018  ... 0.01696323 0.02884974 0.02488459]
 [0.02341631 0.02903547 0.02721959 ... 0.03147968 0.03684581 0.03026904]
 [0.02407897 0.02686172 0.02856533 ... 0.01372865 0.02111759 0.01852173]
 ...
 [0.02456985 0.02438294 0.0207036  ... 0.01866267 0.02210709 0.03216705]
 [0.02490964 0.02635523 0.02343193 ... 0.01555026 0.02245209 0.02855843]
 [0.02505085 0.02349894 0.02153433 ... 0.01429148 0.02186095 0.02473392]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '11', ',', ' Mary', ' travelled', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 44), x_tokens=44, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 44)
DEBUG result.interpretability.attn_scores 1232 
 [[0.0335205  0.04486977 0.05103779 ... 0.01667375 0.04019631 0.04793443]
 [0.03406125 0.03932978 0.04559917 ... 0.0176653  0.01789562 0.02247504]
 [0.03501431 0.04628201 0.05791775 ... 0.0210966  0.03638178 0.03889185]
 ...
 [0.03521647 0.05472643 0.04744371 ... 0.00884502 0.05606288 0.11601087]
 [0.03558366 0.0443538  0.0357531  ... 0.01135297 0.0208622  0.09905127]
 [0.03549325 0.05008273 0.03880726 ... 0.00931906 0.02301586 0.13195156]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '13', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' school', ',', ' and', ' sentence', ' ', '14', ' mentions', ' Mary', ' going', ' back', ' to', ' the', ' school', ',', ' but', ' neither', ' sentence', ' mentions', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 50), x_tokens=50, y_tokens=53, max_supp_attn=0.0, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 50)
DEBUG result.interpretability.attn_scores 2650 
 [[0.01738999 0.02480988 0.023556   ... 0.01462202 0.01772922 0.02234347]
 [0.0178015  0.023132   0.02280012 ... 0.01998888 0.01641944 0.01764829]
 [0.01808656 0.02546719 0.02610448 ... 0.01312954 0.01419164 0.01788291]
 ...
 [0.01835527 0.02268226 0.0209294  ... 0.01138746 0.01621767 0.02292392]
 [0.01875613 0.01801064 0.01635396 ... 0.01583197 0.01615985 0.02880171]
 [0.01858405 0.02091295 0.01891933 ... 0.01436356 0.01602061 0.02299309]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' she', ' is', ' not', ' in', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1212, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02804518 0.05004474 0.06130963 0.07485033 0.07995033 0.07575704
  0.06909835 0.08040608 0.06222222 0.06706146 0.05028762 0.06809213
  0.07782385 0.09292892 0.06094827 0.03254903 0.03180887 0.03566077
  0.03090592 0.035166   0.02945124 0.04142698 0.04600938 0.02187912
  0.01768548 0.02582047]
 [0.02791842 0.08114525 0.0614802  0.05018997 0.03673648 0.05078348
  0.13872933 0.0877928  0.0593728  0.04493247 0.0661173  0.04738104
  0.07906041 0.02244189 0.02161019 0.04519351 0.04608485 0.05701336
  0.04374493 0.05022833 0.04527401 0.04488029 0.04485531 0.03930623
  0.0348122  0.0337588 ]
 [0.03050806 0.06388927 0.04184866 0.06123433 0.04456989 0.04033668
  0.03300177 0.0242404  0.02414379 0.03769378 0.02956388 0.01776311
  0.01944607 0.03527499 0.04564131 0.02444082 0.01423419 0.01405331
  0.0163256  0.01740982 0.01692729 0.04580242 0.05784198 0.00744406
  0.00573061 0.01347825]
 [0.02886873 0.02074892 0.02172799 0.02451121 0.01696758 0.02399009
  0.0218816  0.01917365 0.02339481 0.0244797  0.02443753 0.02302385
  0.02190404 0.01741747 0.01640464 0.02156817 0.02560337 0.0313927
  0.03537296 0.03895292 0.04070157 0.02935366 0.03460398 0.07699731
  0.06549504 0.04471827]
 [0.02906532 0.04523778 0.0520006  0.07250617 0.06666004 0.05171346
  0.03515025 0.03136985 0.03655206 0.04942127 0.03595508 0.0280493
  0.02683396 0.11154313 0.11548345 0.03721166 0.02693401 0.02173174
  0.02164322 0.02389169 0.02361135 0.03981617 0.06674864 0.01224892
  0.00866678 0.02857103]
 [0.02967573 0.02978566 0.03192595 0.05547939 0.05034975 0.04665208
  0.02619956 0.02464616 0.03093545 0.04597705 0.03261242 0.03154047
  0.02889256 0.12082218 0.14141142 0.03642456 0.02991035 0.02596391
  0.02427526 0.0253504  0.0226087  0.0341341  0.03973556 0.00924154
  0.00681455 0.01849144]
 [0.03011306 0.03339338 0.04045434 0.05807966 0.05492689 0.05764411
  0.03401605 0.03351443 0.04011009 0.05447291 0.03802657 0.04943905
  0.04394082 0.09499578 0.08844656 0.03099731 0.02768397 0.02627046
  0.02344748 0.02502716 0.02134091 0.03096766 0.03691608 0.01315486
  0.00954591 0.01741907]
 [0.02908317 0.04005658 0.04680686 0.04287277 0.04662721 0.0507341
  0.03671115 0.04129521 0.04205356 0.04652611 0.03790286 0.05253418
  0.04410732 0.05583265 0.05057409 0.03958528 0.03580904 0.03272977
  0.0290055  0.03095011 0.02905368 0.03466892 0.0494966  0.0328375
  0.03156512 0.03198611]
 [0.03029827 0.04180971 0.05035449 0.04923031 0.0458719  0.05921293
  0.04188651 0.04629296 0.04984684 0.05276609 0.03749513 0.05499861
  0.04864718 0.04280507 0.02827083 0.02852839 0.02714628 0.02780244
  0.02526512 0.02757399 0.02381544 0.03491829 0.04025739 0.01820775
  0.01483358 0.02350462]
 [0.02952698 0.05216712 0.0563379  0.03018328 0.02454461 0.03879461
  0.04208637 0.04230785 0.0454008  0.03157462 0.02941113 0.03897202
  0.03809454 0.01831004 0.01557413 0.04228337 0.03433657 0.03047896
  0.03024816 0.03287358 0.03325189 0.03447013 0.06986518 0.04064456
  0.03795745 0.03618407]
 [0.03018089 0.04123836 0.04821201 0.02574656 0.02200469 0.02927881
  0.04487041 0.03508718 0.04210438 0.02575675 0.02470136 0.02818153
  0.02697951 0.01418442 0.01361696 0.0432121  0.0315228  0.02787306
  0.02964591 0.03312303 0.03178342 0.03003739 0.05488712 0.04298683
  0.04312864 0.036387  ]
 [0.03071553 0.0139094  0.01640248 0.0112854  0.01015466 0.01397022
  0.01530522 0.01496871 0.01979642 0.01303667 0.01299321 0.01396469
  0.01344027 0.00626977 0.00625672 0.01731033 0.01670425 0.01660989
  0.01991529 0.02161029 0.02365011 0.0172646  0.02931335 0.0534713
  0.06867994 0.05353301]
 [0.03029578 0.02451132 0.02478467 0.01614244 0.01485495 0.02011999
  0.0215978  0.02100951 0.0235174  0.01761113 0.0205243  0.02057692
  0.01963236 0.00894372 0.00945953 0.03370398 0.02607    0.02400031
  0.02623516 0.02670669 0.02666593 0.02915205 0.02979181 0.04445951
  0.06633497 0.05712018]
 [0.03041665 0.02430756 0.02490379 0.01821392 0.01636181 0.0236074
  0.02466064 0.02701056 0.02526652 0.02145453 0.02514949 0.02814653
  0.02803326 0.01010804 0.00929918 0.03237608 0.03274608 0.02783795
  0.02873188 0.02712354 0.02884204 0.03016756 0.02177043 0.03375654
  0.05968579 0.03667947]
 [0.0298663  0.02043289 0.017721   0.01384951 0.011752   0.01552463
  0.01915352 0.02127144 0.01873798 0.0155189  0.02093203 0.01821296
  0.02110645 0.00682887 0.00703931 0.03761833 0.03504993 0.03531871
  0.03705876 0.03497437 0.03861704 0.02669356 0.01583507 0.04408156
  0.09443131 0.05373097]
 [0.03074722 0.01990562 0.01816953 0.01455306 0.01244825 0.01716032
  0.01989599 0.02143866 0.01994442 0.01703148 0.02513687 0.02192581
  0.02248273 0.00712369 0.00706782 0.04083447 0.02740552 0.03808085
  0.03087073 0.03501457 0.03430496 0.02263575 0.01370042 0.03631289
  0.05912524 0.0390177 ]
 [0.03051816 0.01850595 0.01641512 0.01169066 0.01009936 0.01438068
  0.01836507 0.01893744 0.01833732 0.01403078 0.02717049 0.01840482
  0.01958695 0.0060192  0.00633736 0.04183039 0.03193453 0.03520193
  0.03554744 0.03432569 0.03516593 0.02388896 0.0141677  0.03353214
  0.0445796  0.06604085]
 [0.02996821 0.02061253 0.01777876 0.01339002 0.01164518 0.01616554
  0.02046859 0.01996412 0.02102528 0.01549137 0.02216786 0.01810925
  0.02062324 0.00718415 0.00727586 0.03236751 0.02429682 0.02831691
  0.03096739 0.03026453 0.039678   0.02497398 0.01963446 0.07726896
  0.05538338 0.06676157]
 [0.03107721 0.02080963 0.01891227 0.01439789 0.01209384 0.01729406
  0.01968114 0.02059674 0.02087429 0.01670878 0.02651281 0.02099112
  0.02044509 0.00766097 0.00742826 0.02952779 0.02623926 0.02877181
  0.03325345 0.02919459 0.03073104 0.02566    0.01472963 0.02342783
  0.02420488 0.04398214]
 [0.031335   0.02225504 0.0249787  0.01912386 0.01552481 0.02471226
  0.02472559 0.03134179 0.02780946 0.02425488 0.02718437 0.03319337
  0.02936413 0.01158339 0.0087847  0.02093929 0.02291616 0.02390483
  0.0248091  0.02407947 0.02371494 0.02892478 0.01634113 0.01946451
  0.01789096 0.02285404]
 [0.03161083 0.02553342 0.02699212 0.0211863  0.0165918  0.02790545
  0.03088326 0.04134899 0.02950327 0.0263364  0.03785741 0.04008561
  0.03704312 0.01216867 0.00921059 0.02392947 0.02607732 0.02656991
  0.0267472  0.02478432 0.02451383 0.02763815 0.01660665 0.01690558
  0.0138508  0.01628154]
 [0.03134628 0.02479242 0.02467096 0.02097237 0.01696883 0.02507952
  0.02722084 0.03374829 0.02840895 0.02647863 0.03095876 0.03588337
  0.03533383 0.01185328 0.00972904 0.02654404 0.02758637 0.02863648
  0.02717744 0.0261384  0.026692   0.02933279 0.0157963  0.02014438
  0.01889131 0.01447751]
 [0.03131808 0.01919955 0.01774988 0.014193   0.01082828 0.01569849
  0.01956723 0.02278106 0.02118375 0.01662619 0.02270688 0.0217696
  0.02382874 0.00728263 0.00698297 0.02790861 0.03121781 0.02997869
  0.03049005 0.02860097 0.03226914 0.0237404  0.01297156 0.02663747
  0.02734112 0.02091422]
 [0.03137453 0.01979751 0.01872635 0.01498543 0.0123452  0.01716032
  0.02078537 0.02535712 0.0226249  0.01914818 0.0266542  0.02558746
  0.02533659 0.00825622 0.00751078 0.03029294 0.03752731 0.03247412
  0.03700373 0.02964283 0.03288829 0.0241171  0.01288678 0.01965201
  0.0186597  0.02017112]
 [0.03119905 0.02012518 0.01913518 0.01509089 0.01199582 0.01806664
  0.0205895  0.02429302 0.02328718 0.01929959 0.02445142 0.02657077
  0.02465427 0.00846253 0.00749138 0.0254603  0.03036172 0.02765527
  0.02952695 0.02807399 0.0303671  0.02541665 0.0136393  0.03228607
  0.01983038 0.0161552 ]
 [0.03115588 0.01835043 0.0173591  0.01125828 0.00979271 0.01404737
  0.019885   0.0201559  0.02207625 0.0140369  0.02808694 0.01933952
  0.02123336 0.00666618 0.00599165 0.02991144 0.04196696 0.02906376
  0.03334514 0.03022654 0.0353515  0.02363605 0.01350851 0.03843369
  0.0237714  0.01986523]
 [0.0303842  0.02234154 0.02147529 0.01289738 0.01081194 0.01642272
  0.0242879  0.02471749 0.02752542 0.01610313 0.02863353 0.02066896
  0.02548097 0.00785731 0.00704141 0.02688725 0.03365646 0.0263971
  0.03120184 0.03190771 0.04187744 0.02549005 0.01990984 0.06806525
  0.03722566 0.02867449]
 [0.03141807 0.02066409 0.02007916 0.01558202 0.01209636 0.01742265
  0.01967615 0.0219824  0.02460424 0.01889736 0.02491849 0.0226103
  0.02221842 0.0093177  0.0079182  0.01930003 0.02662446 0.02325977
  0.0268617  0.02930307 0.03017295 0.02618368 0.01591854 0.02563353
  0.01971142 0.01892168]
 [0.03104028 0.02221845 0.02248245 0.02265968 0.01900479 0.02438615
  0.02154883 0.02636976 0.02809501 0.02706287 0.02341252 0.030937
  0.02918482 0.01601754 0.01174161 0.01788968 0.02324249 0.0260223
  0.02606713 0.02885208 0.02615312 0.03118891 0.02258604 0.02714239
  0.02049908 0.01973043]
 [0.0304345  0.03355804 0.03239885 0.04800099 0.0504704  0.04374385
  0.02610462 0.02627855 0.0324678  0.04620493 0.03322212 0.02998999
  0.02952947 0.0812109  0.09420938 0.02797688 0.02527551 0.02327239
  0.02313074 0.02384378 0.02193193 0.03391463 0.03652503 0.00875969
  0.00680982 0.01747328]
 [0.03012005 0.03187894 0.03155413 0.05330848 0.10785803 0.04009802
  0.02299981 0.02519224 0.03195054 0.05661714 0.0396878  0.03599356
  0.02676177 0.0769413  0.09574183 0.03024983 0.04007759 0.04189914
  0.03282865 0.02945451 0.02770116 0.02848742 0.03308514 0.00812356
  0.00559656 0.01663568]
 [0.03013125 0.02506686 0.02455815 0.03312854 0.06265724 0.0229953
  0.0166143  0.02117556 0.02480308 0.03769072 0.03274875 0.02975988
  0.02328847 0.02500427 0.0343111  0.02427483 0.04838748 0.05761621
  0.05816466 0.04333842 0.03809428 0.02534891 0.02682775 0.01529375
  0.01178026 0.02055511]
 [0.03024313 0.03170678 0.03029338 0.03920588 0.05443423 0.02914096
  0.02235226 0.02393403 0.03202379 0.0396973  0.03237888 0.02730323
  0.02566145 0.03068315 0.03518929 0.02087236 0.03356161 0.03814121
  0.04018548 0.04199259 0.03279773 0.04566801 0.04323723 0.01219872
  0.00948103 0.02010547]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Fred', ' might', ' be', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 32), x_tokens=32, y_tokens=45, max_supp_attn=0.1111, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 32)
DEBUG result.interpretability.attn_scores 1440 
 [[0.02048381 0.03329625 0.03531413 ... 0.012708   0.00656499 0.06190511]
 [0.02106251 0.03125092 0.03271507 ... 0.01680232 0.00958928 0.07399642]
 [0.02138024 0.03197883 0.03536637 ... 0.0300375  0.01339655 0.05289788]
 ...
 [0.02150211 0.03234823 0.02645973 ... 0.00826447 0.00638709 0.07189667]
 [0.02175247 0.02673311 0.02101165 ... 0.00969759 0.00975714 0.04036706]
 [0.0218991  0.02606514 0.02059777 ... 0.00858591 0.00984749 0.06676228]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' provided', ' context', ' sentences', '.', ' Sent', 'ences', ' ', '7', ' and', ' ', '8', ' only', ' mention', ' Bill', "'s", ' movements', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.2045, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02088508 0.0242677  0.02452118 ... 0.01369842 0.0131336  0.02371018]
 [0.0212043  0.02518621 0.02734875 ... 0.03304451 0.03404071 0.06567963]
 [0.02187738 0.02351394 0.02565286 ... 0.01091839 0.00954469 0.01575083]
 ...
 [0.02222861 0.0227749  0.02004336 ... 0.0228359  0.02192496 0.02238029]
 [0.02262767 0.02354063 0.02260188 ... 0.01824712 0.01545603 0.01707116]
 [0.02271594 0.02049612 0.01999607 ... 0.01525857 0.01307012 0.01603525]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 44), x_tokens=44, y_tokens=19, max_supp_attn=0.1053, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 44)
DEBUG result.interpretability.attn_scores 836 
 [[0.049922   0.06166884 0.07081467 0.08737303 0.06385497 0.07937507
  0.05989034 0.07300223 0.07866269 0.071297   0.04612213 0.05316221
  0.06498533 0.10899978 0.09631051 0.03982827 0.03876547 0.03982275
  0.03568354 0.04761196 0.03333016 0.05306414 0.08826148 0.03846782
  0.03526325 0.05834023 0.06693749 0.06151046 0.14807147 0.02280391
  0.017573   0.08139066 0.14639731 0.09165937 0.03631663 0.02834852
  0.03162127 0.0611165  0.10261793 0.04408365 0.15264833 0.01928304
  0.02189727 0.0329745 ]
 [0.05058769 0.04739292 0.04799509 0.05275071 0.03728561 0.05211585
  0.04421937 0.0628842  0.05081284 0.04402098 0.04032566 0.04272246
  0.05837844 0.05789529 0.08681081 0.0394507  0.03144227 0.04069904
  0.03849876 0.05079998 0.03665651 0.04819554 0.05375579 0.04519131
  0.04923807 0.04624457 0.0463329  0.04047891 0.094479   0.04310889
  0.03517332 0.04343586 0.06564688 0.05598712 0.03438512 0.03837993
  0.04025959 0.05117426 0.05331814 0.04527585 0.08695258 0.03119383
  0.03770314 0.03965041]
 [0.05201352 0.06357481 0.07186423 0.10100034 0.08317756 0.10384192
  0.06183819 0.07404366 0.0679547  0.0762818  0.0551142  0.06557161
  0.07654165 0.17284139 0.10645081 0.04237662 0.03409653 0.03495747
  0.03165978 0.03958235 0.02972857 0.05354176 0.06801137 0.03665386
  0.03411351 0.04711184 0.06111843 0.04550996 0.08937913 0.04595209
  0.02551677 0.09053804 0.08532905 0.06840725 0.03082463 0.02471033
  0.02984729 0.04507737 0.09548085 0.04121383 0.10626572 0.03761318
  0.02995583 0.05553511]
 [0.05043553 0.05839682 0.06688999 0.04920375 0.03840148 0.0556207
  0.05342557 0.0640357  0.05417539 0.04415792 0.04178941 0.04755003
  0.05335096 0.0381414  0.03267515 0.04799839 0.03813503 0.03797206
  0.03558283 0.04432087 0.0350964  0.05631049 0.07743999 0.06558993
  0.06123734 0.0572004  0.07118284 0.04842383 0.05434985 0.15177861
  0.04443923 0.04244827 0.05092985 0.04831992 0.06232025 0.04315876
  0.05096263 0.0557912  0.07712838 0.05563338 0.07020824 0.11963795
  0.05003533 0.06794908]
 [0.0521374  0.0560562  0.06264708 0.03695844 0.02775578 0.04612854
  0.06182617 0.05841786 0.05924003 0.03490729 0.03863387 0.03643544
  0.04333733 0.02688781 0.02505531 0.04870064 0.03533457 0.03390646
  0.03605177 0.04417658 0.03338694 0.04946687 0.06674487 0.05869462
  0.05945798 0.04598262 0.06389987 0.03043157 0.03711924 0.13963589
  0.02909529 0.02245571 0.03004356 0.04913352 0.06132152 0.04779339
  0.04692189 0.0516212  0.04965964 0.04363092 0.03694703 0.1399697
  0.05084461 0.06014875]
 [0.05323723 0.03121372 0.03263688 0.02045165 0.01635654 0.02709309
  0.03426771 0.03457064 0.03693897 0.02337994 0.02840608 0.02349553
  0.03202435 0.01417743 0.01570048 0.03400798 0.0291649  0.03089187
  0.0332995  0.03980679 0.03024573 0.03813854 0.04136561 0.04679402
  0.05770599 0.03861266 0.03345045 0.02904102 0.02656044 0.0583192
  0.02373297 0.01467274 0.02470677 0.03729717 0.04359663 0.04439724
  0.03840184 0.04457562 0.01649324 0.03318033 0.02262261 0.05794597
  0.03304666 0.02068995]
 [0.05170329 0.05547846 0.05854932 0.03994917 0.02739665 0.04811898
  0.05351374 0.05515808 0.05222746 0.04251116 0.04316072 0.04648085
  0.04929225 0.02495228 0.02506229 0.05193362 0.04097088 0.04503345
  0.05079193 0.05189014 0.04332526 0.06127187 0.05819537 0.0669504
  0.07299936 0.05197559 0.06119163 0.03927647 0.03987192 0.09172159
  0.05651332 0.02047299 0.02712988 0.04280394 0.07684147 0.05679746
  0.06799781 0.05901252 0.04747054 0.05551265 0.03946035 0.10687945
  0.06190997 0.11728225]
 [0.05338779 0.06593973 0.06919008 0.05749138 0.03653528 0.06530776
  0.0687759  0.07095321 0.060666   0.05981759 0.05793077 0.07408032
  0.07441128 0.03659421 0.0293736  0.05451537 0.04711086 0.05281252
  0.04948739 0.05445751 0.04710089 0.05854695 0.05725581 0.0613536
  0.071877   0.05072248 0.06130142 0.05033999 0.04336324 0.07568528
  0.07754192 0.02722825 0.0379967  0.04513215 0.07501468 0.05535043
  0.06472087 0.05453472 0.05070921 0.05885534 0.04160749 0.07953994
  0.0638678  0.12246566]
 [0.05426088 0.05053535 0.05231616 0.04268319 0.0300741  0.04912219
  0.05730924 0.05066212 0.04880816 0.04687628 0.04902498 0.05012948
  0.05357594 0.02702958 0.02480047 0.04791211 0.03792945 0.03956068
  0.0408655  0.04498733 0.04110852 0.05360488 0.04159089 0.05115992
  0.05761018 0.03955426 0.04823598 0.04124058 0.03395571 0.06679381
  0.07561334 0.02684307 0.02858672 0.04017007 0.06102094 0.04854781
  0.06354314 0.04747649 0.04153297 0.05431291 0.03771268 0.09537586
  0.07670113 0.08522376]
 [0.05357331 0.04308423 0.03695516 0.02747281 0.02067895 0.03245419
  0.04668425 0.03871099 0.03970013 0.03411985 0.04646418 0.0389661
  0.04340161 0.01687731 0.01933367 0.06095443 0.04666772 0.04877649
  0.04876038 0.05178937 0.05286986 0.05519509 0.03339854 0.06461817
  0.06903002 0.03984099 0.03948909 0.04035719 0.02978471 0.05181668
  0.06753026 0.01762718 0.02024707 0.036433   0.07054855 0.06176167
  0.07500505 0.04815954 0.02800852 0.05680798 0.0271869  0.06348324
  0.06772745 0.04488928]
 [0.05309239 0.04473373 0.03663973 0.027875   0.01947971 0.03099411
  0.04760206 0.03831728 0.03923111 0.03257922 0.04325625 0.035848
  0.04309399 0.01585818 0.01744158 0.06921267 0.04359545 0.05130187
  0.0524049  0.05447125 0.06243173 0.05304576 0.02958533 0.06953333
  0.0729218  0.04653484 0.03634168 0.0444901  0.02770546 0.04415708
  0.07044497 0.01235749 0.0197565  0.03472764 0.07599401 0.06056954
  0.08037628 0.0478138  0.02479983 0.053913   0.02129568 0.04425227
  0.05689243 0.03732258]
 [0.05428445 0.04121064 0.0349956  0.02633043 0.02062765 0.03058196
  0.04124149 0.03597616 0.03793374 0.03349333 0.05209732 0.04481407
  0.04089934 0.01604721 0.01685685 0.06142569 0.05625344 0.05270097
  0.06544711 0.05569653 0.06167512 0.05065763 0.02644795 0.05634831
  0.0557122  0.04342331 0.03685405 0.04935517 0.02513408 0.0381803
  0.10046085 0.0139734  0.01807668 0.03184325 0.07226286 0.08273597
  0.07928232 0.05251929 0.02126128 0.06180565 0.02098128 0.05074764
  0.08986439 0.04752805]
 [0.05401185 0.03879443 0.03475834 0.02241552 0.01850172 0.02783112
  0.04334965 0.03478655 0.03771437 0.02959039 0.0570217  0.04286678
  0.04096362 0.01385895 0.01499705 0.07798763 0.05741497 0.06143832
  0.07381565 0.0616672  0.06878573 0.04870803 0.02625289 0.06809681
  0.06286614 0.07511912 0.03012004 0.06488355 0.02529842 0.0372652
  0.11244207 0.01261149 0.01810641 0.03236957 0.05987677 0.11477417
  0.07908522 0.06427457 0.01721294 0.07905982 0.0201167  0.03416606
  0.09994616 0.03600655]
 [0.05263864 0.04604037 0.04297897 0.02711341 0.02280489 0.03795269
  0.05552171 0.04590792 0.05321467 0.03646846 0.06767475 0.06524028
  0.04825921 0.01858065 0.0194096  0.07439564 0.05070736 0.06142085
  0.07662614 0.06254437 0.058213   0.05319838 0.03764306 0.07563715
  0.06715941 0.09442899 0.03711023 0.05558496 0.03822764 0.03653158
  0.06655504 0.0227331  0.03603443 0.04635026 0.04435101 0.08715948
  0.06778099 0.06271451 0.02018172 0.04726788 0.02750592 0.02471408
  0.07269519 0.03785706]
 [0.05457766 0.04379154 0.04660498 0.03715098 0.0247224  0.04122111
  0.04775837 0.04580631 0.04587301 0.04346292 0.05055037 0.05203408
  0.04640432 0.02551732 0.02105906 0.04550941 0.03827322 0.04364778
  0.04918053 0.04457509 0.04342771 0.04953328 0.02960731 0.04108737
  0.03701068 0.05321807 0.03312106 0.04628269 0.03425223 0.03143801
  0.10942355 0.03998596 0.0217485  0.03371868 0.03658812 0.0506025
  0.04071295 0.04829447 0.03091732 0.05181282 0.03673805 0.03112926
  0.09200898 0.08292786]
 [0.05281874 0.05243592 0.05484794 0.08228152 0.06278078 0.07228231
  0.05428326 0.05320221 0.06480396 0.07903782 0.05643312 0.06288239
  0.06329573 0.10814504 0.11267078 0.03786622 0.04288848 0.0452216
  0.04154215 0.04593091 0.03944226 0.0512469  0.053286   0.02891917
  0.02954193 0.05044991 0.05350608 0.05870908 0.07061676 0.01782583
  0.02390507 0.13334392 0.09965958 0.06233738 0.03190868 0.02991915
  0.02956641 0.05152422 0.0800072  0.04286127 0.08121024 0.01885606
  0.02833727 0.03910753]
 [0.05242964 0.0696734  0.06370501 0.10849642 0.22995356 0.08753815
  0.05975407 0.05329535 0.061483   0.10532099 0.08385309 0.08091819
  0.05727194 0.15572162 0.18851045 0.05728821 0.08799037 0.0765207
  0.06322672 0.05724016 0.0704557  0.05030436 0.07096742 0.02999234
  0.0251939  0.0543933  0.08197922 0.06257642 0.07425009 0.01320522
  0.01421848 0.13648717 0.06725238 0.0817651  0.03333404 0.02872187
  0.02788112 0.04898174 0.11569256 0.04649572 0.06835239 0.014405
  0.01754583 0.02293206]
 [0.05220777 0.06233296 0.05566024 0.07652254 0.13566215 0.05080593
  0.04916114 0.05122941 0.04824837 0.0865561  0.07716604 0.07282414
  0.05386978 0.05659672 0.08287042 0.0613691  0.15411392 0.1248268
  0.10272473 0.07767375 0.13388102 0.05005189 0.06508826 0.05321049
  0.04370837 0.05165346 0.07444005 0.09308176 0.04715465 0.01986392
  0.02748905 0.11828432 0.04929462 0.05950815 0.05378941 0.05429991
  0.04735553 0.05389804 0.0617147  0.0752971  0.04185346 0.01768133
  0.02648526 0.02758604]
 [0.05268019 0.06764593 0.0599506  0.07647975 0.08395033 0.06161441
  0.05957772 0.05904019 0.06231135 0.07612089 0.06497528 0.063978
  0.05664293 0.06527782 0.06461109 0.04726737 0.08914504 0.07848832
  0.07435068 0.07077781 0.07883885 0.06591766 0.07510206 0.04170141
  0.03735286 0.05519331 0.0633875  0.09842633 0.06042594 0.01391684
  0.02233161 0.12311034 0.15305713 0.10203629 0.03970453 0.04197178
  0.03867779 0.0514399  0.06579302 0.05297986 0.06033437 0.01312613
  0.02253535 0.02192361]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' (', 'from', ' previous', ' context', ')', ' explicitly', ' stated', ' that', ' Bill', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' would', ' change', ' this', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.1714, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02636553 0.0302185  0.03227045 ... 0.03790632 0.02901829 0.02185651]
 [0.02684105 0.02445476 0.02913301 ... 0.02134788 0.02961538 0.02950628]
 [0.02753864 0.02748509 0.03225375 ... 0.04052377 0.02361514 0.01743337]
 ...
 [0.02794279 0.03166749 0.02634479 ... 0.07742868 0.01907168 0.01391301]
 [0.02834308 0.02548466 0.02116487 ... 0.05313619 0.02440295 0.0181936 ]
 [0.028149   0.027273   0.02169914 ... 0.08587668 0.02038616 0.01544858]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' "', 'Bill', ' moved', ' to', ' the', ' office', '",', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02646929 0.04121321 0.04977081 0.06801746 0.07986196 0.06898448
  0.05298312 0.05996719 0.04940333 0.06163022 0.04448095 0.05637034
  0.06330433 0.09734908 0.06655932 0.0257276  0.0314762  0.03253815
  0.02976508 0.03202615 0.02463113 0.03612343 0.03935632 0.01911163
  0.01308729 0.02429839]
 [0.02681428 0.05371094 0.04934788 0.06892077 0.06219769 0.05758397
  0.04377779 0.04097646 0.04036568 0.04795559 0.03729912 0.03062554
  0.03228095 0.10258041 0.1031829  0.02709214 0.02594405 0.02267097
  0.02332575 0.02370292 0.01953739 0.03881443 0.04148591 0.01425344
  0.00932498 0.02068014]
 [0.02891555 0.05631451 0.03422035 0.04772925 0.03465889 0.03291594
  0.03050052 0.02117451 0.02116154 0.03150996 0.0265413  0.0160967
  0.01785235 0.02435027 0.03226446 0.01897772 0.01408075 0.01371301
  0.01726659 0.01757151 0.01508511 0.04096178 0.04847629 0.00884277
  0.00594526 0.01124638]
 [0.0271131  0.02785177 0.03159551 0.02385542 0.0167259  0.02548387
  0.02721757 0.02492582 0.03041884 0.0241169  0.02466543 0.02384778
  0.0221997  0.01202537 0.01188327 0.0279227  0.02810031 0.02729436
  0.03123982 0.03210362 0.03481956 0.03278987 0.04579085 0.04699581
  0.05846439 0.06173949]
 [0.02739215 0.0406733  0.04453202 0.06268704 0.05634861 0.04529933
  0.03395825 0.02890234 0.03289338 0.04329019 0.03305573 0.02493267
  0.02516511 0.08892465 0.0929625  0.03070323 0.02764645 0.02142153
  0.02233529 0.02403016 0.02142912 0.03741348 0.06047155 0.01630039
  0.00890566 0.02685242]
 [0.02791655 0.02556028 0.02687234 0.04782918 0.0421149  0.04096726
  0.02503904 0.02236556 0.02774411 0.04047306 0.02911215 0.02848519
  0.02732439 0.10168613 0.12355184 0.03082182 0.03167636 0.02610581
  0.0252709  0.02562878 0.02045764 0.03143436 0.03534818 0.01124256
  0.00701388 0.01711399]
 [0.02829383 0.02882023 0.03481542 0.05070608 0.04648709 0.05215828
  0.03324737 0.0312161  0.0366052  0.04800033 0.03422628 0.04524325
  0.04184857 0.08137339 0.07700617 0.0261002  0.02876399 0.02575981
  0.02430233 0.02529576 0.01938873 0.02834769 0.03303616 0.01531489
  0.00904697 0.01704515]
 [0.02734827 0.03745143 0.04454605 0.04041865 0.04162838 0.04828212
  0.0390311  0.04136414 0.03963305 0.04264707 0.0351464  0.04891468
  0.04344932 0.04975244 0.04497243 0.03477546 0.03513902 0.0315372
  0.02882054 0.03102303 0.02689153 0.03258694 0.04644162 0.0342444
  0.02666733 0.03548197]
 [0.02841523 0.04029016 0.04862663 0.0454677  0.04056649 0.0558397
  0.04460682 0.04745721 0.04799089 0.04843093 0.03590686 0.05116719
  0.04811452 0.03822648 0.02497021 0.02528193 0.02814021 0.0270541
  0.02604244 0.02870634 0.02188704 0.0329508  0.03638495 0.02086953
  0.01478558 0.02419792]
 [0.02775697 0.05083558 0.05444023 0.02914903 0.02328797 0.03741135
  0.04682052 0.04482861 0.04562895 0.03076059 0.0295636  0.0380389
  0.03922289 0.01723721 0.01451479 0.04106374 0.03559854 0.03082835
  0.03054517 0.03324318 0.03096256 0.03258333 0.06299572 0.0420436
  0.03324065 0.03769599]
 [0.02831804 0.06576326 0.06460936 0.02693349 0.02157919 0.0320235
  0.0468254  0.04020782 0.04691488 0.02670615 0.02597383 0.03044534
  0.0310015  0.01427921 0.01364967 0.04429038 0.03636595 0.03018532
  0.03118056 0.03626234 0.02939832 0.02946844 0.06682716 0.03878219
  0.02461323 0.02724545]
 [0.02842282 0.0338098  0.03860081 0.02032109 0.01717125 0.02322094
  0.03520815 0.03007099 0.03574328 0.02139903 0.02089761 0.02363816
  0.02280545 0.01191216 0.01176709 0.03675387 0.03128468 0.02509951
  0.02787653 0.02990429 0.02932918 0.02795168 0.05252617 0.04879721
  0.04116705 0.04221519]
 [0.02866674 0.015072   0.0167406  0.01172325 0.01041089 0.01380465
  0.01663247 0.01642375 0.01960452 0.0134062  0.01436711 0.01499282
  0.01428465 0.00637532 0.00687282 0.01918075 0.01900076 0.0179254
  0.02262842 0.02442215 0.02840139 0.02085327 0.03007394 0.05218176
  0.06156217 0.05941477]
 [0.02853504 0.02195674 0.02292417 0.01595446 0.01450785 0.01969456
  0.02433987 0.02204063 0.02243356 0.01741869 0.02085396 0.02085302
  0.0203099  0.0086595  0.00912231 0.03378602 0.02344663 0.02420676
  0.02517105 0.02709384 0.02678812 0.02696511 0.02487805 0.04602616
  0.06270929 0.0511829 ]
 [0.02870255 0.02234647 0.02323651 0.01883004 0.01615595 0.02327262
  0.02672152 0.02732025 0.02442988 0.02194149 0.02461719 0.02841839
  0.02851056 0.01060243 0.00926013 0.03369248 0.02631046 0.02895603
  0.02722245 0.02741357 0.02838379 0.0280465  0.02029005 0.03389488
  0.05039944 0.03074788]
 [0.02917143 0.02280726 0.02148479 0.01608988 0.01606168 0.01838866
  0.02912368 0.02414262 0.02155496 0.01784231 0.03187943 0.02438777
  0.02361964 0.00859233 0.00964685 0.03351767 0.02660206 0.02626502
  0.02582086 0.02798768 0.02750628 0.02566456 0.02046503 0.03772259
  0.05818361 0.02593379]
 [0.02853654 0.01802208 0.0146267  0.0130644  0.01075329 0.01406306
  0.01963028 0.01911174 0.01700624 0.01403953 0.01996944 0.01588647
  0.0191007  0.0060552  0.00645975 0.03331396 0.02161721 0.0289223
  0.02968285 0.03258523 0.04123836 0.02248831 0.01468242 0.0412701
  0.09092828 0.041991  ]
 [0.02904247 0.01782648 0.01539702 0.01317091 0.0109375  0.01545478
  0.01935589 0.019077   0.01807252 0.01507132 0.02285045 0.01953523
  0.02079703 0.00638886 0.00640728 0.03889799 0.02300374 0.0433384
  0.03018155 0.03646412 0.03308624 0.02058588 0.01196381 0.03548761
  0.05877656 0.02935342]
 [0.02888874 0.01618917 0.01372008 0.01053725 0.00900875 0.0129039
  0.01839015 0.01738847 0.01732599 0.01241496 0.02793241 0.01737895
  0.01872873 0.00540196 0.00568386 0.03970602 0.02541769 0.03652386
  0.03329496 0.03389361 0.03683418 0.02162117 0.0122263  0.04544658
  0.04783273 0.04183099]
 [0.02859181 0.02400648 0.02369605 0.02029085 0.01986282 0.02541189
  0.0300943  0.03189734 0.03049808 0.02582955 0.02915006 0.03107727
  0.02923608 0.01217703 0.01096445 0.02375078 0.02636134 0.027844
  0.02929094 0.03011763 0.03381634 0.02754583 0.02137143 0.03391331
  0.02461046 0.03573035]
 [0.02969599 0.01859055 0.01728971 0.01367844 0.01190729 0.01566151
  0.02058334 0.02047534 0.01907346 0.01521951 0.02424615 0.01981963
  0.02032142 0.0071396  0.00702289 0.02489112 0.02300673 0.02300668
  0.02769659 0.02381913 0.02524935 0.02283658 0.01285133 0.02613696
  0.02291379 0.02923435]
 [0.02933327 0.0251808  0.02638087 0.02523076 0.01933404 0.02807444
  0.02995662 0.03460214 0.02822789 0.02912343 0.03173469 0.03816026
  0.03387133 0.01461558 0.01108349 0.02113072 0.02253092 0.02522828
  0.02630728 0.02543683 0.02375645 0.03055639 0.01723462 0.01809516
  0.01620747 0.02033734]
 [0.02955356 0.02718146 0.02973086 0.02768296 0.02002644 0.03172448
  0.03326593 0.04176974 0.02954441 0.03340016 0.03400342 0.04549823
  0.04197064 0.01525257 0.01026349 0.02193419 0.02290632 0.02809537
  0.02488326 0.02410821 0.02130906 0.02760669 0.01635453 0.01534402
  0.01241837 0.01509812]
 [0.02942423 0.02451196 0.0244025  0.02368843 0.01840759 0.02697896
  0.02993806 0.03496742 0.02760091 0.02915    0.0324469  0.03808119
  0.03955225 0.01357018 0.0098835  0.02625384 0.02461172 0.03047124
  0.02795235 0.02698399 0.0247383  0.0283777  0.01370111 0.01776556
  0.01586389 0.01404692]
 [0.02930857 0.01933558 0.01786842 0.01452389 0.01092233 0.01644413
  0.02236151 0.02418071 0.02156747 0.0171251  0.02267584 0.02195936
  0.02578814 0.00760056 0.0067842  0.02928975 0.02433973 0.02930573
  0.02875379 0.02740721 0.03042041 0.02712833 0.01191864 0.02546448
  0.03008376 0.02048711]
 [0.02923417 0.01905721 0.01692675 0.01397428 0.00993954 0.01484291
  0.02273063 0.02307258 0.02039276 0.0157368  0.02194181 0.01930231
  0.0239778  0.00694244 0.00617022 0.03185928 0.02338944 0.03118503
  0.02994555 0.02934232 0.03543086 0.0235177  0.01115864 0.03193125
  0.03537973 0.0237393 ]
 [0.02946284 0.01909896 0.01702723 0.01430826 0.01109678 0.01548616
  0.02141335 0.02345914 0.02092659 0.01745085 0.02483544 0.02237002
  0.02485072 0.00759839 0.0064769  0.02876647 0.02863265 0.03122535
  0.03436819 0.02877919 0.03242937 0.02375048 0.01121011 0.02388207
  0.02086615 0.01838054]
 [0.02957994 0.02192963 0.01978137 0.01603729 0.01169383 0.01762174
  0.0254267  0.02698972 0.02627745 0.01928793 0.02921554 0.02450301
  0.02795548 0.00820071 0.00685995 0.03019975 0.02794204 0.03286892
  0.03305469 0.03101783 0.03207296 0.02465535 0.01211821 0.02481485
  0.01961143 0.01651258]
 [0.02960037 0.01656059 0.01541727 0.01062929 0.00885814 0.01252552
  0.02032164 0.01995657 0.02012723 0.01328037 0.03299369 0.01772035
  0.02185998 0.00605466 0.00515951 0.03232384 0.03038659 0.03065185
  0.03630212 0.03054894 0.03308969 0.02272454 0.01127644 0.03052508
  0.02227927 0.02279416]
 [0.02841414 0.01916783 0.01823606 0.01143661 0.00937933 0.01397631
  0.02137136 0.02139637 0.02446325 0.01431775 0.02143866 0.01695419
  0.02195556 0.00640457 0.00564302 0.02173731 0.0283743  0.02392001
  0.03254424 0.03363517 0.05007031 0.02435384 0.01999154 0.0747196
  0.0447876  0.05875428]
 [0.02966878 0.01910995 0.01915514 0.01598207 0.01197556 0.01793552
  0.02030406 0.02377062 0.02377093 0.01863782 0.02243805 0.02230995
  0.02261774 0.00981269 0.00784085 0.01775043 0.02244847 0.02041893
  0.02725983 0.02343003 0.02697953 0.02458202 0.01325621 0.01902573
  0.01567548 0.02346348]
 [0.02857837 0.02595    0.02594313 0.03965472 0.04019591 0.03536253
  0.02339561 0.02410901 0.029233   0.041242   0.02971408 0.0298888
  0.02899078 0.06524605 0.07780922 0.02045903 0.02814221 0.02533812
  0.02589935 0.02552933 0.02186001 0.03013053 0.02930765 0.01154249
  0.00856947 0.01925219]
 [0.02834724 0.02739318 0.02641825 0.04480895 0.08476292 0.03562925
  0.02202072 0.02285185 0.02826682 0.04821144 0.03506255 0.03072238
  0.02513747 0.06670636 0.0848166  0.02568458 0.04009628 0.03484861
  0.03054143 0.0280374  0.02504537 0.0273972  0.02928592 0.00948853
  0.00659087 0.016567  ]
 [0.02807745 0.02526798 0.02397567 0.03824388 0.08663207 0.02541281
  0.01858642 0.02246641 0.02505269 0.04421292 0.0350637  0.03391267
  0.02499007 0.03164262 0.04092388 0.02293956 0.06459993 0.05161178
  0.04118394 0.03227649 0.03846661 0.02460023 0.02700993 0.01558219
  0.01131743 0.02066758]
 [0.02840981 0.03114323 0.02764344 0.03842402 0.05454122 0.02915884
  0.0248203  0.02507372 0.03004627 0.03871986 0.03370016 0.02846191
  0.02700424 0.02926365 0.03156023 0.01942362 0.0426163  0.03363414
  0.0320434  0.03017198 0.02920975 0.0425855  0.03823319 0.01294055
  0.01017054 0.01866752]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' "', 'Fred', ' journey', 'ed', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.125, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02936829 0.0454832  0.04470365 ... 0.06175919 0.01001472 0.0073257 ]
 [0.03012693 0.04578529 0.04475895 ... 0.06975308 0.01381071 0.01084552]
 [0.03068615 0.04156064 0.04605075 ... 0.07208846 0.02279482 0.01705611]
 ...
 [0.03071535 0.0384303  0.03656579 ... 0.02558673 0.00799038 0.00568369]
 [0.03082006 0.03136507 0.02678873 ... 0.0150283  0.01156134 0.0088453 ]
 [0.03098508 0.03470657 0.0292688  ... 0.0123965  0.00754816 0.00627033]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' "', 'Bill', ' journey', 'ed', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02954055 0.041202   0.03766724 ... 0.02696173 0.01947547 0.01873284]
 [0.02990114 0.08289143 0.07293207 ... 0.04460619 0.02961415 0.0256233 ]
 [0.03080682 0.03983177 0.04270877 ... 0.02145055 0.0150852  0.01348477]
 ...
 [0.03094103 0.0344263  0.03837463 ... 0.02004627 0.01382707 0.01443754]
 [0.03116968 0.02613701 0.02688768 ... 0.02352709 0.02042301 0.02301081]
 [0.03103594 0.03004549 0.03008047 ... 0.0230762  0.01825595 0.02034306]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' possibilities', ' for', ' Mary', "'s", ' location', ' are', ' the', ' office', ' or', ' the', ' kitchen', ',', ' according', ' to', ' context', ' sentence', ' ', '10', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 44), x_tokens=44, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 44)
DEBUG result.interpretability.attn_scores 1848 
 [[0.02197966 0.02580613 0.03041931 ... 0.01126111 0.01372852 0.04502974]
 [0.0225133  0.01913229 0.02506386 ... 0.01999086 0.01855775 0.02675873]
 [0.02300904 0.02488839 0.03118695 ... 0.01928475 0.02593209 0.04203263]
 ...
 [0.02309967 0.02895152 0.02608963 ... 0.00918732 0.01168289 0.07903122]
 [0.02350857 0.02259119 0.01985382 ... 0.00982734 0.01385041 0.04148836]
 [0.02356821 0.02430924 0.0214635  ... 0.00917798 0.01259309 0.04268088]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' or', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' provide', ' information', ' about', ' Julie', ' and', ' Fred', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02654411 0.03128495 0.02785514 ... 0.01757677 0.02563827 0.03704501]
 [0.02722304 0.03071767 0.03330215 ... 0.02403689 0.03189847 0.03067683]
 [0.0278831  0.03035914 0.03102342 ... 0.01593341 0.02247964 0.03361637]
 ...
 [0.02831777 0.03108099 0.02251104 ... 0.03122197 0.02784696 0.04890587]
 [0.02871885 0.03610208 0.02780098 ... 0.02530117 0.0269373  0.04888875]
 [0.02891652 0.02978867 0.02391239 ... 0.02126017 0.0250005  0.03538205]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 26), x_tokens=26, y_tokens=24, max_supp_attn=0.0417, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 26)
DEBUG result.interpretability.attn_scores 624 
 [[0.03909519 0.05581807 0.06998958 0.08954183 0.09312353 0.0911226
  0.06979912 0.08739057 0.07271    0.08091148 0.06467853 0.07950877
  0.08795847 0.11122404 0.07012545 0.04111538 0.03892542 0.04300984
  0.03722111 0.04139052 0.03586831 0.05133076 0.04778848 0.02822977
  0.01996383 0.0324704 ]
 [0.0387605  0.10011229 0.08140811 0.07484315 0.05715498 0.07542413
  0.21819991 0.14945433 0.08912839 0.07268203 0.09306587 0.07351856
  0.11710091 0.03670327 0.02916573 0.05264745 0.04719496 0.06769325
  0.05148051 0.06283907 0.05494796 0.05999643 0.04865178 0.04679365
  0.0286832  0.03652352]
 [0.0426146  0.06911566 0.04454274 0.06346852 0.04629453 0.04333073
  0.0354032  0.02828992 0.02882534 0.04183961 0.03866267 0.02186819
  0.02429762 0.03533664 0.0451324  0.032428   0.01863609 0.01867727
  0.02212375 0.0230337  0.02264981 0.05691288 0.05901143 0.01209257
  0.00705299 0.01488804]
 [0.04013261 0.05311996 0.05106817 0.02850908 0.0191162  0.03457388
  0.03414743 0.03231948 0.04229361 0.0304769  0.03425054 0.03287035
  0.03058283 0.01342656 0.01298852 0.04565344 0.03916707 0.03970473
  0.04646752 0.04751095 0.04321644 0.04374061 0.06421249 0.0681045
  0.09164732 0.07646509]
 [0.04048093 0.04954139 0.05555735 0.07894836 0.07002202 0.05762236
  0.03834847 0.03707049 0.04387188 0.05590682 0.04752133 0.03433982
  0.03361066 0.11723802 0.11857124 0.04990303 0.03570545 0.02930623
  0.02857852 0.0312946  0.03174908 0.05099894 0.06937239 0.02161558
  0.01098569 0.03273695]
 [0.04133097 0.03213127 0.03429185 0.06120744 0.05257951 0.05238838
  0.02883263 0.02909011 0.03729027 0.05219715 0.04208723 0.03886795
  0.0363114  0.12733792 0.14840601 0.04926543 0.03985415 0.03494797
  0.03208936 0.03329347 0.03041217 0.04351175 0.04157602 0.01528813
  0.00880926 0.02130298]
 [0.04198325 0.03586162 0.0435153  0.06369594 0.05668815 0.06577181
  0.03742994 0.03931073 0.04834364 0.06114358 0.04866285 0.06096903
  0.05454586 0.10043483 0.09150164 0.04062854 0.03561852 0.03404021
  0.03051743 0.03246383 0.02827959 0.03917285 0.03854848 0.02060175
  0.01244301 0.02138444]
 [0.04062207 0.04869017 0.05923673 0.05122538 0.05105965 0.06172485
  0.04189279 0.0511174  0.05324468 0.05588573 0.04962585 0.06677803
  0.05587373 0.06160436 0.05419008 0.05124544 0.0448093  0.04214818
  0.03704198 0.03986172 0.03689674 0.04520954 0.05655034 0.04319616
  0.03274052 0.04245302]
 [0.04225228 0.04683232 0.05900241 0.0574549  0.04973343 0.06937451
  0.04708667 0.05644529 0.06126207 0.06173931 0.04997469 0.06735531
  0.06021891 0.04723673 0.02980396 0.03684689 0.03435083 0.03535087
  0.03230942 0.03565564 0.0307696  0.0440567  0.04038134 0.02566069
  0.01880343 0.0300731 ]
 [0.04122824 0.06448929 0.06897978 0.03617238 0.02788388 0.04748528
  0.04914226 0.05370977 0.05916319 0.03909646 0.04034957 0.05110177
  0.04972655 0.02099965 0.01729667 0.05668523 0.04402822 0.03955397
  0.03958203 0.04231359 0.04119607 0.04410975 0.07445658 0.05493929
  0.04759423 0.04925144]
 [0.04194511 0.08248822 0.08140811 0.03372012 0.02636535 0.04018155
  0.05125887 0.05041885 0.06183931 0.03401083 0.03622568 0.04074743
  0.0399889  0.01760705 0.01637968 0.0675074  0.04607034 0.03988476
  0.04021737 0.04671318 0.04159415 0.04022902 0.07838263 0.0507926
  0.03547537 0.03697571]
 [0.04212591 0.04351706 0.04833683 0.02567944 0.02113206 0.02996696
  0.03945448 0.03857782 0.04724944 0.0279499  0.02974014 0.03300729
  0.0308244  0.01490575 0.01437428 0.05389322 0.03980507 0.03409932
  0.03760152 0.03991435 0.03810896 0.03881405 0.05876306 0.06087063
  0.05993236 0.05421449]
 [0.04251369 0.01689079 0.01844199 0.01343465 0.01170128 0.0166217
  0.01692174 0.01878504 0.0235206  0.01638333 0.01872618 0.01928514
  0.01786837 0.00737795 0.00771105 0.02391609 0.02404333 0.02387598
  0.03250533 0.03372424 0.035449   0.02725526 0.03168057 0.0653692
  0.08914673 0.08028767]
 [0.04228568 0.02516613 0.02646251 0.01847924 0.01633644 0.02390461
  0.0246327  0.02646338 0.02830473 0.02212444 0.0278043  0.02884243
  0.02689783 0.01029437 0.01072661 0.04284653 0.03733789 0.03442848
  0.04032069 0.03901205 0.03835694 0.03626309 0.02938817 0.06074815
  0.08935103 0.05881733]
 [0.04274291 0.02722514 0.02949189 0.02288934 0.01962415 0.03057203
  0.02965132 0.03620589 0.03275274 0.02977046 0.03457645 0.04243256
  0.04029948 0.0133573  0.01138195 0.03893118 0.04348671 0.03911583
  0.04148941 0.03739946 0.0380734  0.03830147 0.02322352 0.05481195
  0.0572588  0.03249034]
 [0.04209362 0.02117612 0.01880375 0.01549138 0.0125925  0.01812687
  0.0229332  0.02722205 0.0228502  0.01902456 0.02789765 0.02509578
  0.03053632 0.00762237 0.00764209 0.03691628 0.04761794 0.04403364
  0.05666795 0.05084215 0.06138958 0.03310693 0.01744005 0.08044251
  0.10422924 0.04992308]
 [0.04279331 0.02220105 0.02045276 0.01730091 0.0147569  0.02131655
  0.02314287 0.02957967 0.02503128 0.02221406 0.03100285 0.03191995
  0.03212375 0.00893306 0.0083461  0.0310656  0.04622713 0.03735563
  0.05161067 0.03987728 0.04276896 0.03409094 0.01687625 0.05282123
  0.08005146 0.04339731]
 [0.04292688 0.01735891 0.01599398 0.01227939 0.01093605 0.01562558
  0.02032739 0.02299782 0.02092486 0.01610568 0.03093079 0.02329256
  0.02630517 0.00633633 0.00644022 0.03229866 0.04691048 0.03857736
  0.05997282 0.04708759 0.05070219 0.03025652 0.01434013 0.0550326
  0.05648656 0.064022  ]
 [0.04108154 0.0335585  0.02686937 0.01939719 0.02059362 0.0222259
  0.04118503 0.03768459 0.03423968 0.0215129  0.04051498 0.02943612
  0.03773978 0.008995   0.00986879 0.05515172 0.04911106 0.07512338
  0.07043558 0.08222795 0.07911292 0.03780756 0.03110548 0.07785787
  0.06217145 0.08128848]
 [0.04337902 0.02351856 0.02374293 0.01951255 0.01489616 0.0238618
  0.02353779 0.02890259 0.02719775 0.02267447 0.03013484 0.03226846
  0.02974411 0.01075457 0.00968735 0.02600474 0.02963275 0.03039673
  0.0421583  0.03921445 0.03931979 0.0338079  0.01800386 0.03370523
  0.03678831 0.04245523]
 [0.04226763 0.03148212 0.03220756 0.05020526 0.04971221 0.04628091
  0.02807718 0.03149782 0.03719528 0.05568892 0.04341382 0.04483849
  0.03899262 0.07528999 0.09234355 0.03291155 0.03823002 0.03680631
  0.0331655  0.03274334 0.03252351 0.03947815 0.03333546 0.01606867
  0.01223599 0.02367811]
 [0.04197533 0.03356033 0.0311811  0.05506032 0.10023739 0.04437428
  0.02643204 0.02898275 0.03484797 0.06000309 0.04910013 0.04206683
  0.03278093 0.08077984 0.10422704 0.04011229 0.04999486 0.05109286
  0.03818118 0.0356586  0.03871391 0.03716527 0.03304326 0.0127069
  0.00781604 0.01987769]
 [0.04145005 0.02906197 0.02678015 0.0435143  0.09253866 0.03016827
  0.02205018 0.02748974 0.03029035 0.05056989 0.04611449 0.04216278
  0.031207   0.0318408  0.04427947 0.03297731 0.07432351 0.07750122
  0.05568306 0.04438215 0.06284101 0.03405182 0.03036304 0.02352611
  0.01705193 0.03016066]
 [0.04191875 0.03708313 0.03223501 0.0479689  0.06492135 0.03795445
  0.0301128  0.03099395 0.03762273 0.05008839 0.04493858 0.03742636
  0.03446439 0.03436362 0.03941012 0.02904852 0.04891891 0.05327602
  0.04257895 0.04154622 0.04505994 0.06033184 0.04350517 0.01872426
  0.0132813  0.0248629 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' given', ' context', ' sentences', ' (', '4', ' and', ' ', '5', ')', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' office', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '1', ' (', 'from', ' a', ' previous', ' part', ' of', ' the', ' conversation', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' office', ',', ' but', ' that', ' information', ' is', ' not', ' relevant', ' to', ' the', ' current', ' context', '.\n\n', 'Answer', ':', ' unknown']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(65, 32), x_tokens=32, y_tokens=65, max_supp_attn=0.0, attn_on_target=0.0154)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (65, 32)
DEBUG result.interpretability.attn_scores 2080 
 [[0.01413731 0.01621979 0.01607744 ... 0.00668144 0.03362536 0.04611066]
 [0.01452726 0.01563666 0.01460592 ... 0.00889589 0.04553523 0.04011216]
 [0.01479871 0.01573892 0.01668465 ... 0.01593116 0.03745265 0.02681473]
 ...
 [0.01491896 0.01522363 0.01194324 ... 0.00419762 0.05347522 0.03441866]
 [0.01527305 0.01457416 0.01124872 ... 0.005611   0.02960029 0.01660818]
 [0.01526896 0.0172314  0.01357402 ... 0.00489482 0.02300242 0.04128727]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' given', ' context', ' sentences', ' (', '7', ' and', ' ', '8', ')', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '7', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' implies', ' she', ' is', ' in', ' the', ' office', ',', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 38), x_tokens=38, y_tokens=59, max_supp_attn=0.0508, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 38)
DEBUG result.interpretability.attn_scores 2242 
 [[0.01573287 0.0220315  0.02401931 ... 0.01338202 0.02361059 0.01587977]
 [0.01586908 0.01758257 0.02111525 ... 0.02159487 0.025565   0.0219579 ]
 [0.01642109 0.0229521  0.02790326 ... 0.01040026 0.02076726 0.00906255]
 ...
 [0.01649891 0.02242075 0.01949764 ... 0.00930191 0.01981719 0.01563959]
 [0.01682628 0.01816595 0.01526646 ... 0.01207193 0.01663706 0.02143142]
 [0.01679516 0.01830004 0.01516314 ... 0.01064668 0.01569991 0.01747927]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Fred', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Fred', ' might', ' be', ' in', ' the', ' kitchen', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 44), x_tokens=44, y_tokens=55, max_supp_attn=0.0909, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 44)
DEBUG result.interpretability.attn_scores 2420 
 [[0.01653855 0.02351821 0.02260848 ... 0.01124864 0.0145682  0.01535978]
 [0.01671152 0.02047888 0.02005041 ... 0.01927118 0.02345309 0.028538  ]
 [0.0172819  0.02429147 0.02551058 ... 0.01424879 0.02573291 0.02057973]
 ...
 [0.01745962 0.02142913 0.02275263 ... 0.00690481 0.00885162 0.01464379]
 [0.01784067 0.01688962 0.0172915  ... 0.00871026 0.00797447 0.01209718]
 [0.01784948 0.01620274 0.01673895 ... 0.008192   0.00909057 0.01320205]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' park', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Bill', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' cinema', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 50), x_tokens=50, y_tokens=55, max_supp_attn=0.0, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 50)
DEBUG result.interpretability.attn_scores 2750 
 [[0.01681618 0.0236251  0.0254369  ... 0.02979408 0.03214258 0.02453444]
 [0.01715866 0.01998325 0.02113933 ... 0.01860218 0.02539809 0.02709989]
 [0.01752375 0.02629066 0.02945624 ... 0.03512511 0.03024312 0.02121124]
 ...
 [0.01777753 0.02818166 0.02590959 ... 0.06072611 0.03071099 0.02189302]
 [0.01815374 0.02129062 0.01808929 ... 0.042184   0.01770799 0.01945808]
 [0.01794059 0.02423182 0.02063074 ... 0.04341966 0.0316533  0.01926328]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' park', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' her', ' going', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02580676 0.03907825 0.0486984  0.0670567  0.07028765 0.06753381
  0.0511439  0.06047658 0.04481738 0.05673601 0.04187509 0.05251127
  0.05714262 0.10128424 0.07693629 0.02642847 0.02841926 0.02917893
  0.02313109 0.02729055 0.02429594 0.03454226 0.04530449 0.0261777
  0.01195959 0.02030012]
 [0.02568854 0.07081342 0.05332967 0.04801302 0.03756987 0.04515218
  0.139747   0.07998945 0.05023682 0.04310388 0.07179348 0.04306914
  0.07193734 0.02243477 0.02145607 0.03916118 0.04129324 0.05016384
  0.03455273 0.04148268 0.04203913 0.03779845 0.03956983 0.04480137
  0.02700517 0.02723187]
 [0.02804202 0.05864073 0.03606084 0.05695381 0.03969066 0.03664555
  0.03013689 0.02275973 0.02015059 0.03354405 0.02481676 0.01598496
  0.0165821  0.03368101 0.0432258  0.01985879 0.01374009 0.01233447
  0.01331967 0.01520027 0.01501866 0.04247936 0.05691063 0.00617518
  0.00489454 0.01072799]
 [0.0265345  0.02124084 0.0222392  0.02293304 0.01793256 0.02205784
  0.021532   0.01978625 0.02036327 0.0225329  0.02322553 0.02146812
  0.01902663 0.01331383 0.01362061 0.02526163 0.02854125 0.02910523
  0.03315508 0.03304878 0.02996824 0.02608181 0.02956517 0.03405462
  0.04782813 0.06785155]
 [0.0265998  0.04300676 0.04716641 0.06958671 0.06676366 0.04749534
  0.03266163 0.03003035 0.03190681 0.04589691 0.03205068 0.02554207
  0.02462324 0.10907884 0.11357498 0.03335408 0.02689324 0.01959538
  0.01775588 0.02047024 0.02169134 0.03741086 0.06574342 0.01024818
  0.00685815 0.02405285]
 [0.02721492 0.02810109 0.02786935 0.05179659 0.05121654 0.04051761
  0.02366874 0.02309751 0.02639512 0.04112671 0.02894045 0.02832872
  0.0259211  0.11980621 0.13904436 0.03215772 0.02942006 0.02308147
  0.01979289 0.02104732 0.02079297 0.03200668 0.03730665 0.00878409
  0.00572682 0.0152948 ]
 [0.02761597 0.03164098 0.03524634 0.05510991 0.05546673 0.05106467
  0.03128618 0.03160206 0.03445638 0.04905623 0.03388462 0.04464417
  0.03877726 0.09329643 0.08685723 0.02708844 0.02715348 0.02290667
  0.01902886 0.02065113 0.01981849 0.02925714 0.03407427 0.01267144
  0.00792848 0.01443467]
 [0.0265801  0.03818752 0.04239004 0.04124917 0.04719159 0.04589076
  0.0349749  0.03995144 0.03923651 0.04259745 0.0340634  0.04943284
  0.04088242 0.05307546 0.04905658 0.03475997 0.03484503 0.02948297
  0.02501194 0.02641586 0.02726001 0.03315724 0.04621616 0.02779758
  0.02577743 0.02811228]
 [0.02772691 0.0368266  0.04305543 0.04569027 0.04627828 0.05227648
  0.03722106 0.04119277 0.04473795 0.04821819 0.03478916 0.04922889
  0.04417231 0.04234931 0.02865723 0.02491974 0.0270241  0.0252998
  0.02184135 0.02328169 0.02226158 0.03420129 0.03765699 0.01985464
  0.01183887 0.01876743]
 [0.02700777 0.05101658 0.0538267  0.02834755 0.02517746 0.03502374
  0.03994256 0.04057211 0.04180658 0.02814947 0.02687328 0.03445092
  0.0350287  0.01713184 0.01550443 0.03973187 0.03476143 0.02764487
  0.02593008 0.02796063 0.02905099 0.03244223 0.06803601 0.03879578
  0.03303381 0.03294187]
 [0.02762906 0.03961817 0.04506603 0.02411943 0.02241539 0.02636576
  0.04119297 0.03360021 0.03809753 0.02349027 0.02331314 0.02484065
  0.02570513 0.01367655 0.01383949 0.04100181 0.03313025 0.02606844
  0.0254473  0.02841216 0.02831989 0.02800407 0.05391352 0.02907829
  0.03738593 0.03077379]
 [0.02794074 0.01519639 0.016581   0.0113393  0.01070981 0.01463178
  0.01512729 0.01564111 0.01821087 0.01247357 0.0134319  0.01282101
  0.01371694 0.00620336 0.00692475 0.01792032 0.01882653 0.01715633
  0.01985135 0.02207406 0.02407815 0.01846698 0.03361396 0.03757838
  0.05402741 0.056244  ]
 [0.02758559 0.02332932 0.02442295 0.01603769 0.01525172 0.01973384
  0.0228339  0.02193746 0.02276166 0.01691077 0.02061255 0.01865721
  0.01999437 0.00915253 0.00982478 0.03415643 0.02921092 0.02594561
  0.02467796 0.02549421 0.02497811 0.02700863 0.02990976 0.03900471
  0.05838379 0.04962741]
 [0.0276484  0.02418222 0.0244943  0.01833328 0.01639028 0.02445176
  0.02657044 0.02751181 0.02498453 0.02075968 0.02525245 0.02653471
  0.02801494 0.01030632 0.00941983 0.03081492 0.03389001 0.02772034
  0.02515665 0.02427868 0.02588608 0.02869129 0.02010777 0.03630491
  0.05563652 0.0355324 ]
 [0.02709257 0.01908783 0.01664272 0.01328327 0.01126493 0.01482337
  0.01977682 0.01950336 0.01870797 0.0142898  0.02085881 0.01663265
  0.02010646 0.0070886  0.00695549 0.03789506 0.03506657 0.03687845
  0.03429111 0.03629827 0.03644295 0.0251778  0.01472153 0.04356317
  0.10632455 0.0500938 ]
 [0.02832335 0.01948016 0.01942773 0.01519578 0.0137476  0.019548
  0.02299481 0.02241985 0.02156374 0.01694685 0.02143895 0.01985495
  0.02130765 0.00823813 0.00735182 0.03349337 0.0202403  0.02826718
  0.02244718 0.03209597 0.02654458 0.02095047 0.01603852 0.03066562
  0.07480941 0.02649679]
 [0.02817149 0.01722258 0.01560776 0.01235131 0.01085136 0.01449767
  0.01837102 0.01837287 0.01840304 0.01382638 0.02290941 0.018236
  0.01978663 0.00678238 0.006429   0.03979258 0.02507979 0.03593929
  0.02882474 0.03980957 0.03264575 0.020821   0.01310342 0.03278566
  0.06253883 0.03731688]
 [0.02797643 0.01646981 0.01490309 0.01121495 0.00989497 0.01324946
  0.01765479 0.01756855 0.01808018 0.01283987 0.02431476 0.01658123
  0.01836536 0.00612437 0.00633935 0.03340123 0.02846327 0.03153041
  0.03282681 0.03528362 0.03019307 0.02187944 0.01294615 0.03899024
  0.04612687 0.05851769]
 [0.0274153  0.02117854 0.0190293  0.01398224 0.0131137  0.01693183
  0.02250751 0.02165035 0.02346503 0.01571753 0.02562066 0.01899868
  0.02089834 0.00746833 0.00798007 0.02448642 0.03036297 0.02593778
  0.03300096 0.03011595 0.03142788 0.02529537 0.02071064 0.07509707
  0.03689535 0.05457866]
 [0.02841057 0.01879339 0.01754781 0.01428812 0.01185329 0.01688968
  0.01969407 0.0198137  0.02097568 0.01587987 0.02687091 0.02049167
  0.02012086 0.00791186 0.00758421 0.02259985 0.02317212 0.02280663
  0.03225696 0.02902644 0.0274519  0.02453804 0.01293272 0.02917507
  0.02023938 0.04641924]
 [0.02869045 0.02040574 0.02277632 0.01857342 0.01517171 0.0232275
  0.02224088 0.02794353 0.0263554  0.02281179 0.0251897  0.03144645
  0.02755421 0.01144492 0.00848444 0.01889312 0.02135956 0.02087668
  0.02188345 0.02066647 0.02178697 0.02739374 0.01435329 0.02681986
  0.01589664 0.01983204]
 [0.02850687 0.02465836 0.02539538 0.01852196 0.01536496 0.02355704
  0.02317133 0.02808286 0.02728939 0.0216116  0.02453734 0.03112866
  0.02621625 0.01058945 0.00868633 0.0200445  0.02209983 0.02093008
  0.02303134 0.02133795 0.0227429  0.0270293  0.01774677 0.02547222
  0.01626863 0.01762172]
 [0.02870045 0.02467764 0.02584352 0.01734844 0.01456982 0.02422377
  0.02464333 0.02896425 0.02833741 0.02113014 0.02566328 0.03533146
  0.02716444 0.01027777 0.00851099 0.02029758 0.02479178 0.02380525
  0.02973512 0.02747934 0.02564685 0.02438393 0.02030723 0.02293658
  0.01472179 0.02078933]
 [0.02873567 0.02520199 0.02716147 0.02026724 0.01735528 0.03048208
  0.02346923 0.03055074 0.03309191 0.02608489 0.02276616 0.03707463
  0.0302723  0.01260175 0.00880369 0.01648158 0.02060246 0.01935863
  0.0210303  0.02003359 0.0208208  0.02465032 0.02123041 0.02874364
  0.01576183 0.01694831]
 [0.0282511  0.03756973 0.03458656 0.0220897  0.01750544 0.03180118
  0.03061591 0.03899723 0.03637817 0.0291679  0.02907187 0.04502436
  0.03958045 0.01326522 0.00960146 0.0239505  0.0239245  0.02500075
  0.02686908 0.0264526  0.02667954 0.02826699 0.02576188 0.02753077
  0.01726942 0.01694155]
 [0.02892951 0.0240376  0.02833351 0.02048451 0.01580931 0.02966591
  0.02703016 0.03146378 0.03366717 0.02570332 0.0253448  0.03896976
  0.03203088 0.01241522 0.00841342 0.02015021 0.0205741  0.02004254
  0.02135202 0.02188666 0.02320856 0.02478343 0.01813995 0.02046877
  0.01327734 0.0123908 ]
 [0.02833407 0.01741467 0.0182116  0.01274153 0.01006852 0.01537994
  0.01883901 0.02085869 0.02101796 0.01572585 0.02344101 0.01968682
  0.02269806 0.0081233  0.00630535 0.02802744 0.02632578 0.0266167
  0.02768871 0.02639215 0.03077961 0.02343164 0.01229405 0.02925104
  0.02504625 0.01941   ]
 [0.02849321 0.01881342 0.01891466 0.01373924 0.01002544 0.01435493
  0.0198945  0.02224146 0.02096671 0.01553299 0.02245833 0.01866761
  0.02268674 0.00785232 0.00613583 0.03166322 0.02693429 0.02994792
  0.02851897 0.02973093 0.03456786 0.02329225 0.01192452 0.03127522
  0.03238795 0.01832807]
 [0.02883434 0.01663371 0.01681589 0.01312032 0.00975096 0.01420262
  0.01604212 0.01843304 0.02000966 0.01560514 0.0215905  0.01765186
  0.0201548  0.00786994 0.00576232 0.02601635 0.02132294 0.02683422
  0.02901115 0.04422624 0.04141388 0.02121273 0.01128904 0.02461073
  0.02325796 0.01678736]
 [0.0285211  0.01598403 0.01597894 0.01154085 0.00902598 0.01276473
  0.01549874 0.01628711 0.01862213 0.01450486 0.02427924 0.01549558
  0.01866874 0.00737112 0.00578514 0.031273   0.02609507 0.0281084
  0.03287382 0.03836618 0.03555482 0.02163075 0.01178196 0.03105996
  0.02271363 0.02180831]
 [0.02784909 0.01757783 0.01700508 0.01245137 0.00990359 0.01422944
  0.01546472 0.01786515 0.02082834 0.01625171 0.02364701 0.01625883
  0.01962414 0.00745922 0.00630046 0.03267245 0.02773216 0.02436918
  0.03163518 0.02561744 0.03081447 0.02246084 0.0137616  0.04083985
  0.02392174 0.03203569]
 [0.02868065 0.02068534 0.02118019 0.01628212 0.01246134 0.01789745
  0.01811358 0.02173057 0.02387117 0.01993829 0.02333445 0.020093
  0.02295002 0.01043999 0.00846674 0.02272651 0.02248296 0.02541408
  0.03081392 0.02547655 0.02942646 0.02497508 0.01602701 0.02238169
  0.01405631 0.01780422]
 [0.0278049  0.02613721 0.02762965 0.04331749 0.04581547 0.03572113
  0.0217168  0.02473361 0.02995683 0.04746617 0.03124678 0.03168911
  0.03330714 0.06472757 0.08382285 0.02228129 0.02733958 0.0263771
  0.02322715 0.02162114 0.02284685 0.03040075 0.02965979 0.01043065
  0.00678606 0.01672652]
 [0.0275754  0.02823756 0.02769538 0.04926087 0.09775084 0.03661203
  0.01964626 0.02269007 0.02776087 0.05130952 0.03683502 0.03011985
  0.02515596 0.07369904 0.09476884 0.02775436 0.03814225 0.03645302
  0.02941463 0.02465068 0.02702367 0.02847104 0.03022303 0.00795922
  0.00561655 0.01476503]
 [0.02742671 0.02159831 0.02211494 0.03445817 0.05600708 0.0230953
  0.01500869 0.02019686 0.02398136 0.04198834 0.03339683 0.02910122
  0.02496056 0.02541857 0.02950087 0.02178084 0.04747118 0.05908484
  0.06751363 0.0354208  0.03677908 0.02435995 0.02226098 0.01566339
  0.01039612 0.01672019]
 [0.02765574 0.02725561 0.02675181 0.0389207  0.05034631 0.02800386
  0.01956627 0.02148357 0.02850781 0.04107121 0.03026174 0.02395086
  0.02486492 0.02804027 0.03006881 0.01770318 0.03326761 0.03973654
  0.04310098 0.03090322 0.02974212 0.04304686 0.03485679 0.01295273
  0.0074027  0.01577472]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0312, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02943316 0.04945279 0.05001273 ... 0.03681229 0.0081714  0.00572028]
 [0.03025774 0.04675833 0.04584547 ... 0.04659308 0.01195242 0.0076861 ]
 [0.03069344 0.04457564 0.0489965  ... 0.06228938 0.02050996 0.01085328]
 ...
 [0.03064732 0.04247206 0.03714853 ... 0.01645708 0.00665043 0.00541557]
 [0.03100727 0.03529113 0.02862641 ... 0.01175444 0.00987102 0.00854809]
 [0.03127242 0.03496664 0.02832794 ... 0.00961739 0.00890611 0.00751606]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Fred', ' is', ' explicitly', ' stated', ' to', ' be', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(23, 38), x_tokens=38, y_tokens=23, max_supp_attn=0.0, attn_on_target=0.0435)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (23, 38)
DEBUG result.interpretability.attn_scores 874 
 [[0.04103443 0.05914532 0.05556851 0.07477623 0.05891398 0.06271511
  0.0474337  0.05055175 0.05529555 0.07071935 0.04586427 0.04658948
  0.05114125 0.12144217 0.10740177 0.04155765 0.03812645 0.03653963
  0.02809749 0.03058413 0.03081786 0.0420447  0.06607388 0.02753746
  0.0217125  0.03948355 0.04324638 0.05210716 0.12100809 0.04283741
  0.01598528 0.01330799 0.01179566 0.07699385 0.06367644 0.03769115
  0.02764747 0.01954242]
 [0.04139362 0.06475083 0.06137443 0.06769469 0.05269725 0.08066966
  0.1135805  0.11875795 0.07792772 0.06601642 0.04940273 0.07769489
  0.10041546 0.0739145  0.06563262 0.03795329 0.03353124 0.0390784
  0.0343584  0.03888343 0.03218574 0.04421231 0.05319912 0.04575469
  0.03444696 0.03916481 0.03837681 0.04099539 0.0910169  0.07525896
  0.04110254 0.03380257 0.02710429 0.05181159 0.05455518 0.03965492
  0.0409556  0.03778704]
 [0.04275728 0.06293242 0.06281285 0.08684491 0.07423479 0.08589119
  0.05533166 0.05687512 0.05986069 0.07697202 0.05029844 0.06162474
  0.06140057 0.14832444 0.1020209  0.04245239 0.03128707 0.03209129
  0.02432916 0.02792775 0.02597242 0.04462338 0.05587355 0.02807344
  0.02267698 0.03559396 0.04634783 0.03809596 0.07449517 0.08028945
  0.03007337 0.02074767 0.01694753 0.07088055 0.04939395 0.03181437
  0.02438276 0.01801637]
 [0.04156301 0.05125972 0.05106482 0.04212491 0.03316778 0.04487618
  0.04431935 0.04756295 0.0457511  0.04275344 0.03721552 0.04282112
  0.04277575 0.03522722 0.03181748 0.04156781 0.0344713  0.03365699
  0.02988204 0.03169961 0.02999896 0.04517656 0.05914374 0.03813663
  0.03984163 0.04292989 0.05002899 0.03883097 0.04598885 0.11265633
  0.05667457 0.04014229 0.03216063 0.03815876 0.05745911 0.04826903
  0.04560851 0.03108301]
 [0.04302726 0.03939319 0.03693622 0.02736937 0.01992633 0.03012982
  0.03152163 0.0322556  0.03600106 0.02650668 0.03006951 0.02639117
  0.02862699 0.01707039 0.01881763 0.03145816 0.02357919 0.02468807
  0.02639757 0.02978276 0.02666003 0.03472437 0.04358341 0.02745251
  0.03118201 0.03554914 0.04124638 0.02487797 0.03001303 0.0743104
  0.04068062 0.03335619 0.03745214 0.0245998  0.04204148 0.04221945
  0.04395329 0.04045054]
 [0.04257721 0.05727682 0.05816177 0.03554402 0.02569867 0.04310544
  0.04858436 0.04700915 0.05458508 0.03400083 0.03250744 0.03679609
  0.03814432 0.02667826 0.02376451 0.04177773 0.03012786 0.02848251
  0.02816819 0.03171321 0.02824733 0.04512576 0.06975053 0.03833125
  0.04229438 0.0418915  0.05869565 0.02930021 0.03872943 0.11544157
  0.05111014 0.0428164  0.02913271 0.02679622 0.07020217 0.05018435
  0.0474142  0.03857742]
 [0.04315056 0.04663419 0.04316378 0.02816208 0.02096245 0.02929773
  0.03966539 0.03358592 0.04289109 0.02673009 0.03018302 0.02579362
  0.02835377 0.01803701 0.01983149 0.03861016 0.02953829 0.02819168
  0.03066934 0.03487661 0.02900472 0.03845239 0.04716169 0.02969684
  0.04030541 0.03746405 0.0411884  0.02456258 0.02805746 0.06257289
  0.02880617 0.02578579 0.02447324 0.01958992 0.04720272 0.05334318
  0.04857669 0.03986955]
 [0.04388923 0.02818653 0.02659117 0.019662   0.01530418 0.02111967
  0.02306724 0.02362911 0.02828871 0.019465   0.02704183 0.0227347
  0.02545544 0.01211265 0.01442424 0.0328117  0.02663481 0.02932206
  0.03543812 0.03713848 0.03196174 0.03148734 0.02592584 0.03278298
  0.03806263 0.03358193 0.02927536 0.02636423 0.02499974 0.02757327
  0.02753318 0.02551045 0.03530614 0.0150269  0.02950834 0.04346942
  0.0434163  0.04483061]
 [0.04346059 0.0359088  0.03761532 0.02702169 0.02103137 0.03096645
  0.03585146 0.03356541 0.03886409 0.02812994 0.03251485 0.03094268
  0.03066546 0.0182815  0.01917611 0.0376367  0.03330665 0.03485504
  0.03764684 0.03981217 0.03480493 0.04133591 0.03703003 0.03813663
  0.0546135  0.04307681 0.04602899 0.03198577 0.0315428  0.05923425
  0.05797068 0.0455378  0.04594795 0.02316535 0.04332564 0.0515409
  0.05513856 0.04257267]
 [0.0436184  0.04247034 0.04209662 0.03352191 0.02592681 0.03917852
  0.04657746 0.04342259 0.04326295 0.0360087  0.04102788 0.04519605
  0.0456205  0.02346916 0.02132479 0.04399469 0.04144109 0.0417388
  0.04442298 0.04293229 0.03770871 0.05016125 0.03492909 0.04521871
  0.0624217  0.04151799 0.04588406 0.03723506 0.03368278 0.05610565
  0.07651783 0.0661464  0.05238596 0.02590141 0.04120179 0.04427527
  0.06467155 0.04306689]
 [0.04361692 0.03729167 0.03379633 0.02635414 0.02044914 0.02856314
  0.03949792 0.03381447 0.03541757 0.02491452 0.03793604 0.03395456
  0.03681838 0.01579938 0.01610667 0.05047628 0.04315727 0.05311571
  0.06456928 0.07709287 0.05624312 0.04432742 0.02678515 0.05295416
  0.08779371 0.04260368 0.03478261 0.03564999 0.0241833  0.02614421
  0.05161297 0.06536906 0.05238596 0.01528107 0.03118124 0.05396816
  0.07346546 0.06137753]
 [0.04442303 0.03676466 0.03454632 0.02697997 0.02255466 0.03060822
  0.0384391  0.03701132 0.03700781 0.02835618 0.0429649  0.04216382
  0.03864256 0.01709792 0.01664109 0.044947   0.04912814 0.04099162
  0.06089735 0.05248806 0.04833875 0.04441376 0.02631188 0.0600038
  0.06259475 0.03895315 0.03672464 0.03726755 0.02445504 0.02373878
  0.06182287 0.06554984 0.05320908 0.0170987  0.03031045 0.04048177
  0.06038156 0.05598639]
 [0.04434973 0.0545873  0.05251444 0.04133776 0.0323693  0.04749262
  0.05477524 0.05578509 0.0501439  0.04645244 0.05357535 0.06259225
  0.05708523 0.02769669 0.02426961 0.05747169 0.05397059 0.05600749
  0.05186323 0.05058853 0.04560297 0.04995198 0.04413834 0.08054568
  0.07895643 0.04500417 0.05202898 0.04700812 0.03702376 0.03566811
  0.05962657 0.08873105 0.05870637 0.02476394 0.04958184 0.05306702
  0.05445257 0.04692255]
 [0.04603567 0.04248995 0.0438578  0.03418946 0.02751901 0.03890871
  0.04594541 0.04357496 0.04078992 0.03345786 0.04449724 0.04498627
  0.04306772 0.02063732 0.01903976 0.04597633 0.04006814 0.03694934
  0.03866766 0.03707542 0.03570278 0.04298409 0.03289496 0.0546347
  0.04932037 0.03509842 0.0435942  0.0339837  0.02854029 0.03051197
  0.05008713 0.06769275 0.04488965 0.02119565 0.03579824 0.04001183
  0.04090397 0.03842462]
 [0.04507175 0.02887469 0.03027211 0.02530554 0.01931797 0.02675612
  0.02947961 0.03054144 0.03040499 0.02569787 0.03359316 0.03206404
  0.03272269 0.01424179 0.01537065 0.03811835 0.03705418 0.03693197
  0.04283124 0.0431586  0.03790608 0.04116963 0.02300828 0.04934439
  0.04926268 0.03782761 0.03365218 0.03710376 0.02399587 0.01899409
  0.04425538 0.05799057 0.0497402  0.01658652 0.02703851 0.04053668
  0.0428026  0.04757145]
 [0.04487693 0.03311694 0.033287   0.02569772 0.02146863 0.02781494
  0.03932235 0.0362817  0.03159616 0.02569787 0.04859584 0.0391049
  0.03912472 0.0147081  0.01603116 0.05397737 0.05689942 0.04836192
  0.06284365 0.05955687 0.05419221 0.04246679 0.02458213 0.06876333
  0.0569878  0.04759391 0.03495652 0.04194427 0.02346088 0.01863347
  0.04633898 0.06237094 0.05432618 0.01541886 0.02625973 0.04389415
  0.04680198 0.06840789]
 [0.04451966 0.02701055 0.03013218 0.02185099 0.01892348 0.02501032
  0.03452253 0.03111576 0.03091895 0.02290383 0.04476621 0.03420376
  0.03456829 0.0128882  0.01437585 0.04992691 0.05527018 0.04483727
  0.06414618 0.06102233 0.05136187 0.04221809 0.02316975 0.06678621
  0.05065634 0.06191466 0.02936232 0.04834819 0.02299078 0.01744514
  0.05191352 0.05939785 0.07825556 0.01546058 0.02525936 0.04682365
  0.04246035 0.09198895]
 [0.04311118 0.03103066 0.03374222 0.02402052 0.02021863 0.02964463
  0.03704264 0.03533524 0.03743711 0.0262663  0.04184464 0.03376259
  0.03882203 0.01453809 0.01614993 0.04570545 0.04514334 0.04299447
  0.06020646 0.059986   0.0468607  0.04592125 0.03234374 0.06721716
  0.05326599 0.08247569 0.03113043 0.06427881 0.03304163 0.01733292
  0.05592465 0.05866361 0.11047499 0.02194993 0.03435988 0.05749843
  0.04986015 0.10014169]
 [0.04489316 0.03122448 0.03834666 0.03327437 0.02531369 0.03733749
  0.03449552 0.03895404 0.03551734 0.03199014 0.03879475 0.03993256
  0.0395533  0.02313562 0.01972446 0.0349093  0.03034521 0.03079996
  0.03559344 0.03649542 0.03508218 0.04268351 0.02830333 0.03526828
  0.02701025 0.05036044 0.0335942  0.03898528 0.0304995  0.0261797
  0.07831676 0.05379653 0.1005975  0.03704655 0.02857147 0.0355562
  0.03125443 0.04155593]
 [0.0433541  0.04166458 0.04682419 0.06684635 0.05870723 0.05879499
  0.03885777 0.04243804 0.04890739 0.07151684 0.05156183 0.05148299
  0.04933582 0.10075467 0.11681902 0.03949475 0.03864448 0.04243385
  0.03256314 0.03427064 0.03581202 0.04424074 0.05027784 0.02507534
  0.02063495 0.04105731 0.04823188 0.0542215  0.06530807 0.02661801
  0.0247748  0.02015667 0.02245952 0.11438076 0.04659498 0.03320646
  0.02675495 0.02377724]
 [0.04300679 0.05384251 0.05612261 0.09993714 0.20551807 0.07988065
  0.04262038 0.04476755 0.04945158 0.09878708 0.07248908 0.06671912
  0.04822953 0.13068737 0.16558108 0.05435744 0.06644937 0.06849831
  0.04498105 0.04047379 0.05968855 0.04271122 0.06933479 0.02094966
  0.01979275 0.04454848 0.07298551 0.05855575 0.06691184 0.02168006
  0.01373408 0.01331633 0.01397841 0.11970136 0.0581446  0.03421418
  0.02256379 0.01609231]
 [0.04296769 0.04409058 0.04282423 0.06006798 0.0994368  0.04306917
  0.0341903  0.03784642 0.03803875 0.06774997 0.05949252 0.05213902
  0.04189179 0.04567055 0.06760462 0.05115009 0.0977772  0.10191203
  0.07262223 0.05589261 0.12447866 0.04265971 0.05902496 0.03980791
  0.03312021 0.04068877 0.05747826 0.07330196 0.04259449 0.01705239
  0.01902109 0.02196166 0.02561973 0.09249122 0.04727399 0.04134415
  0.03759501 0.02825351]
 [0.04330168 0.05005324 0.04834843 0.07141625 0.08033983 0.05816922
  0.04487848 0.04531842 0.05164042 0.06890662 0.05376288 0.05030951
  0.04753843 0.06758697 0.06807454 0.0436688  0.06404853 0.06752158
  0.04880507 0.04654832 0.06136765 0.0569078  0.06715404 0.02752819
  0.02304617 0.04162008 0.05115942 0.08499578 0.05746028 0.01372094
  0.01611677 0.01784967 0.02265061 0.11570048 0.06105889 0.03693536
  0.0289383  0.02370367]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '11', ',', ' Julie', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03229899 0.04171275 0.04233108 ... 0.09160929 0.01405877 0.02117972]
 [0.03327839 0.06282166 0.05973317 ... 0.04035283 0.03091233 0.0325344 ]
 [0.03369724 0.04573599 0.05097573 ... 0.08153831 0.01921677 0.03127224]
 ...
 [0.03397897 0.04917141 0.04259155 ... 0.03110843 0.01033813 0.01222518]
 [0.03434499 0.03679692 0.02961945 ... 0.01544608 0.01247879 0.01278163]
 [0.03400145 0.04233104 0.03236769 ... 0.01602259 0.01006763 0.01182516]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Fred', ' travelled', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' him', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03027664 0.04793014 0.04648553 ... 0.0498031  0.02217361 0.0347636 ]
 [0.03098968 0.0343441  0.0330422  ... 0.03184797 0.03055398 0.032192  ]
 [0.03156304 0.04967941 0.04984837 ... 0.0383183  0.01903585 0.02770749]
 ...
 [0.03162569 0.04146015 0.04385688 ... 0.04782802 0.01771542 0.03120828]
 [0.03223231 0.03212835 0.03221599 ... 0.0349184  0.022123   0.03011988]
 [0.03212881 0.03280241 0.03271612 ... 0.03956027 0.02166292 0.03087238]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' that', ' Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' school', '.', ' We', ' don', "'t", ' have', ' any', ' information', ' that', ' confirms', ' Fred', "'s", ' exact', ' location', '.', ' Sentence', ' ', '2', ' informs', ' us', ' that', ' Julie', ' travelled', ' to', ' the', ' school', ',', ' but', ' it', ' doesn', "'t", ' provide', ' any', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(66, 26), x_tokens=26, y_tokens=66, max_supp_attn=0.0303, attn_on_target=0.0152)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (66, 26)
DEBUG result.interpretability.attn_scores 1716 
 [[0.01376673 0.02728396 0.02943342 ... 0.00753708 0.0104274  0.01354957]
 [0.01355462 0.0585843  0.04088807 ... 0.01325165 0.01531693 0.01573643]
 [0.01495035 0.03779547 0.02193491 ... 0.00234555 0.0037374  0.00724045]
 ...
 [0.01475856 0.01674064 0.01705853 ... 0.00266314 0.00410377 0.00909223]
 [0.01475396 0.01348224 0.0133327  ... 0.0093251  0.00922456 0.01072693]
 [0.0149785  0.01368703 0.01314923 ... 0.00609429 0.00685594 0.00862113]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '2', ' (', 'previous', ' part', '),', ' we', ' know', ' that', ' Julie', ' travelled', ' to', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Julie', ' left', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 32), x_tokens=32, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 32)
DEBUG result.interpretability.attn_scores 1120 
 [[0.02668881 0.03484292 0.03702778 ... 0.06501999 0.01217872 0.01666214]
 [0.02725875 0.03472707 0.03561579 ... 0.07337426 0.02167415 0.02645252]
 [0.02802147 0.03252136 0.03651893 ... 0.06843509 0.02280039 0.02380919]
 ...
 [0.02803066 0.03668045 0.03292949 ... 0.02376767 0.01047307 0.0141091 ]
 [0.02840183 0.02925122 0.02410181 ... 0.01232141 0.01489915 0.02037479]
 [0.02835316 0.03163243 0.02658876 ... 0.01280986 0.01093517 0.01462932]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.04981343 0.06326649 0.07260138 0.08579019 0.06448452 0.07036135
  0.05566197 0.06220827 0.06793488 0.07217218 0.04629802 0.05587603
  0.0561532  0.10980469 0.11771461 0.04444768 0.03834721 0.04195473
  0.03480839 0.04421272 0.03547207 0.05134062 0.08123619 0.01938746
  0.03223371 0.06181357 0.06721636 0.06727695 0.14933321 0.09637688
  0.02291321 0.03202372 0.03636667 0.03490223 0.02534843 0.02054683
  0.03784164 0.07852609]
 [0.05074103 0.04926056 0.04991625 0.04822373 0.03566579 0.04730745
  0.0452496  0.06162851 0.04924113 0.04256569 0.04034713 0.05035393
  0.05997514 0.03786873 0.0596848  0.04162484 0.03559367 0.04541812
  0.04200673 0.05164841 0.03964591 0.05025656 0.04440459 0.03647734
  0.04403145 0.05296547 0.05408027 0.04649774 0.0768358  0.08047858
  0.03523296 0.04844456 0.05863917 0.04491268 0.0510791  0.04783382
  0.03952935 0.03950448]
 [0.05194712 0.06890295 0.07742392 0.10105113 0.08592994 0.10482459
  0.06579822 0.07097702 0.07881318 0.09003317 0.05611999 0.07759579
  0.07672622 0.16098677 0.11448572 0.04534576 0.03538605 0.03794046
  0.03217743 0.03945862 0.03138788 0.05558302 0.06676275 0.01959842
  0.02925524 0.05107345 0.06689301 0.04966354 0.09425101 0.11475618
  0.04459366 0.04521997 0.06728112 0.06224489 0.04227839 0.02610989
  0.06302702 0.07828919]
 [0.05052335 0.06410431 0.07192712 0.04874182 0.03844242 0.05506102
  0.05375357 0.06004698 0.05643629 0.04749097 0.04305336 0.05430028
  0.05289252 0.03815303 0.03635532 0.05225931 0.03918816 0.04048573
  0.03667907 0.04436697 0.03570538 0.05857535 0.08007687 0.03577344
  0.05507432 0.06205615 0.06733762 0.04681904 0.05913618 0.12557307
  0.06924702 0.06776848 0.116314   0.06788947 0.08520021 0.0467888
  0.0568292  0.04614953]
 [0.05173096 0.06522524 0.06977002 0.04122783 0.0304062  0.04768233
  0.056749   0.05265514 0.05768112 0.03791839 0.0387072  0.04187601
  0.04337106 0.02843201 0.02569078 0.05176193 0.03640106 0.03618732
  0.03718212 0.04527072 0.03599887 0.04959701 0.07486309 0.03604915
  0.06031738 0.05958569 0.07267289 0.03495454 0.04159456 0.09583292
  0.04998454 0.04784172 0.06687313 0.05131246 0.10853875 0.05846852
  0.06599243 0.03121021]
 [0.05293402 0.03370611 0.03373666 0.02312263 0.0176977  0.0263115
  0.02958386 0.02836523 0.03460696 0.02339703 0.02691803 0.02519444
  0.02922586 0.01553292 0.0147264  0.03379128 0.02921103 0.02988379
  0.03204596 0.03973152 0.03180661 0.0344373  0.038751   0.03516145
  0.05462687 0.04409498 0.03560891 0.02637383 0.02330505 0.03790291
  0.0242649  0.02872584 0.02457207 0.01991435 0.04040189 0.03320163
  0.02212779 0.01560193]
 [0.05182192 0.06169198 0.06590093 0.04155815 0.03158081 0.05268764
  0.05986677 0.05817984 0.05496902 0.04194709 0.0450628  0.05478418
  0.05124213 0.02966059 0.02683816 0.06233858 0.04710171 0.05218807
  0.04807894 0.05381584 0.04514225 0.06190333 0.07107126 0.06046415
  0.07390834 0.06649325 0.07643183 0.04233717 0.04679821 0.06807889
  0.07954717 0.05935711 0.08389741 0.10056785 0.09914728 0.06683838
  0.08306344 0.03045684]
 [0.05345702 0.07740532 0.07937558 0.0612941  0.04374562 0.0718919
  0.07751432 0.08066655 0.0682942  0.06918491 0.06740943 0.09250945
  0.0780158  0.04477924 0.0334135  0.06371113 0.05558358 0.05791259
  0.05425548 0.05658445 0.04900664 0.06022017 0.06564185 0.0743959
  0.06593958 0.06045893 0.07760398 0.05349191 0.05217491 0.06036126
  0.09918424 0.07006636 0.09005433 0.1240975  0.1037029  0.07359602
  0.11452927 0.04261144]
 [0.05451296 0.05602951 0.05708815 0.04263953 0.0348081  0.0506762
  0.06321872 0.05625301 0.04916413 0.04516928 0.05541264 0.05658004
  0.05730914 0.02996723 0.02487239 0.05924164 0.05043406 0.04695144
  0.05105574 0.05043813 0.04662808 0.05526904 0.04787403 0.06306043
  0.06165633 0.04761034 0.05597995 0.04400721 0.03853226 0.05073843
  0.09938243 0.07141861 0.07848228 0.08077859 0.07301082 0.07955534
  0.08139162 0.03386332]
 [0.05363706 0.04100087 0.0348455  0.02828611 0.02380046 0.03291976
  0.04509581 0.03979402 0.036733   0.02972786 0.04770568 0.0377637
  0.04465729 0.01937909 0.01817219 0.06230868 0.05609109 0.04970446
  0.05604613 0.05252646 0.05231599 0.05450212 0.03343048 0.0676389
  0.06863455 0.04141928 0.03674063 0.04266392 0.03068767 0.02951195
  0.08827563 0.06088903 0.05808282 0.05310699 0.04867239 0.08012447
  0.0494395  0.0264513 ]
 [0.0527732  0.03841809 0.02934081 0.02719083 0.02113141 0.02890982
  0.03888823 0.03277305 0.03239964 0.02593015 0.03889372 0.0280996
  0.03826957 0.01744585 0.01578812 0.06279012 0.04601644 0.0512914
  0.05906294 0.05799248 0.06669417 0.04922754 0.02756765 0.07164714
  0.06939282 0.04852463 0.03015238 0.04416151 0.02550133 0.01689401
  0.06655753 0.04492682 0.03445654 0.04426252 0.03655249 0.08210767
  0.03851227 0.02600382]
 [0.05415756 0.03849898 0.0328675  0.02919711 0.02422785 0.03308005
  0.04472182 0.04107715 0.03651056 0.03108251 0.05493755 0.04301502
  0.04587337 0.0200472  0.01712141 0.06136375 0.07127017 0.05775577
  0.08366904 0.06157981 0.0683863  0.05091836 0.02723245 0.10504571
  0.05796056 0.04182978 0.03362839 0.05059114 0.02668863 0.02066925
  0.08579028 0.06852972 0.0353467  0.04818207 0.04779467 0.07622022
  0.04638826 0.02412585]
 [0.05409058 0.03466815 0.03079731 0.02559137 0.02139599 0.02938036
  0.04596264 0.03870698 0.03506896 0.0267445  0.06642056 0.0382214
  0.04557603 0.01731995 0.01493874 0.07361098 0.07878211 0.06567706
  0.08826643 0.06954945 0.07266206 0.04848678 0.02542407 0.1246713
  0.06050866 0.05436116 0.02796977 0.0550494  0.02388967 0.0166028
  0.06170574 0.06670702 0.02344083 0.03447599 0.04446315 0.08034007
  0.03513685 0.02145548]
 [0.0523079  0.03974126 0.03760575 0.02943007 0.02211994 0.03609203
  0.04900351 0.04195104 0.05173505 0.03013504 0.04004448 0.03317099
  0.0441261  0.01987052 0.01626202 0.04584016 0.04963819 0.04613385
  0.05607614 0.0572232  0.05089525 0.05172588 0.04235068 0.08084585
  0.07588261 0.06213451 0.03564933 0.04005359 0.03076893 0.02629063
  0.03261085 0.06305452 0.03746082 0.03736546 0.04178068 0.06723851
  0.04248205 0.026405  ]
 [0.0546913  0.03940902 0.0408875  0.03922155 0.02832446 0.04519518
  0.04906293 0.0493983  0.04537405 0.04147336 0.0479098  0.04743479
  0.05140584 0.03049724 0.02062735 0.03876712 0.03740349 0.0377823
  0.04695853 0.04435115 0.04198885 0.05088092 0.02735415 0.04848537
  0.04174978 0.04253135 0.03249666 0.04947839 0.03320823 0.03030733
  0.04932257 0.08321769 0.07640524 0.07964812 0.06219013 0.07196245
  0.08137255 0.04557589]
 [0.05269824 0.05306539 0.05537616 0.0789751  0.06421704 0.07010282
  0.05523904 0.0572079  0.06778943 0.08298978 0.06126851 0.06391197
  0.06243402 0.11616285 0.12591398 0.04309407 0.04434607 0.04668606
  0.04200244 0.04554363 0.04195079 0.05329761 0.05450547 0.0232683
  0.03377077 0.04967775 0.05028091 0.06694839 0.07467037 0.04676817
  0.02669674 0.04428379 0.0423196  0.03953836 0.03363574 0.02630025
  0.04821265 0.14202571]
 [0.05249286 0.06806225 0.0630722  0.11435447 0.23684448 0.09210964
  0.06237286 0.06263881 0.06644621 0.11936951 0.09529524 0.08593047
  0.06250418 0.15048392 0.18634972 0.05889377 0.08361706 0.0832795
  0.05959599 0.0560327  0.06806458 0.0511719  0.06954043 0.0226751
  0.03031752 0.05371556 0.07331959 0.06824812 0.07218668 0.04067114
  0.01975004 0.02902844 0.02258776 0.02740597 0.01766083 0.01784105
  0.03495886 0.12991469]
 [0.05271691 0.05216113 0.04764326 0.06336297 0.10682584 0.04797189
  0.04675256 0.04944945 0.04555799 0.07227397 0.06865874 0.06004598
  0.04837567 0.05103181 0.07167079 0.05489874 0.1008807  0.10445791
  0.08193556 0.07003593 0.1188051  0.0488928  0.05851721 0.04705251
  0.04765206 0.05106225 0.05905178 0.08126712 0.04582911 0.02303814
  0.0273706  0.04285826 0.02542514 0.02853335 0.02186782 0.02442582
  0.03144994 0.10220537]
 [0.05295264 0.05538238 0.04982406 0.07074135 0.06835145 0.05743441
  0.05550468 0.05602282 0.06524418 0.07039469 0.05953709 0.05333597
  0.05186687 0.06257641 0.05937403 0.04391042 0.06470823 0.06830946
  0.05809688 0.05963783 0.06744323 0.06371371 0.06339578 0.02830211
  0.03708738 0.0485918  0.04688574 0.09011649 0.05460819 0.01914748
  0.0175699  0.02563836 0.02199432 0.02086103 0.01667438 0.02050021
  0.02771536 0.05962388]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Bill', ' went', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 44), x_tokens=44, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 44)
DEBUG result.interpretability.attn_scores 836 
 [[0.04993712 0.06727877 0.06724399 0.08471666 0.06550501 0.0754682
  0.06612676 0.06495591 0.06890836 0.0682489  0.04815486 0.05559696
  0.06515319 0.10509257 0.10761653 0.04475811 0.04240387 0.03984796
  0.03898688 0.04193054 0.0344278  0.05087344 0.09288646 0.03318979
  0.03892289 0.05628788 0.05066559 0.06732881 0.15343422 0.1062533
  0.03289042 0.03626844 0.03692276 0.03561953 0.02611205 0.02433516
  0.03992341 0.06738549 0.05127805 0.09042278 0.05153339 0.03743058
  0.05744909 0.05107358]
 [0.05066307 0.05318493 0.05922532 0.05621315 0.03912629 0.0492208
  0.0480227  0.06365097 0.05566481 0.04013757 0.0403469  0.04239589
  0.05398142 0.03875447 0.06638696 0.04862192 0.0445867  0.0386444
  0.04223793 0.04009283 0.03570038 0.05501705 0.05294134 0.04923321
  0.05063624 0.05563332 0.06053551 0.04366693 0.07888032 0.10020355
  0.04464103 0.0452777  0.05164129 0.03732388 0.04698585 0.03502771
  0.03645925 0.03584248 0.02550526 0.04199903 0.05254244 0.05533022
  0.06422135 0.06085363]
 [0.05212092 0.06616764 0.07318918 0.1034783  0.09100799 0.10879635
  0.06698053 0.07043511 0.07333684 0.08086463 0.05663366 0.06844252
  0.0766667  0.16680628 0.10786799 0.04876539 0.04076192 0.03639368
  0.03470057 0.03451635 0.03006835 0.05439051 0.07832786 0.03213955
  0.03756496 0.05565849 0.06757098 0.05755144 0.10563219 0.15070578
  0.06497606 0.05923476 0.07849881 0.07043411 0.05148156 0.03138068
  0.07612365 0.09102409 0.05653962 0.08432028 0.04997658 0.02989977
  0.04871184 0.05105721]
 [0.05059345 0.049923   0.05650712 0.04772905 0.03903989 0.05115338
  0.05129143 0.05617787 0.05092    0.04112881 0.04041606 0.04593603
  0.05042907 0.03869224 0.03408837 0.04399295 0.04022253 0.03492901
  0.03702301 0.03761352 0.03281359 0.05873212 0.06078399 0.04541245
  0.05404956 0.05690721 0.05891583 0.04535051 0.05230499 0.115526
  0.08043267 0.07715719 0.12695362 0.06828544 0.09047192 0.05145827
  0.06126338 0.0434088  0.03531497 0.03685498 0.06521076 0.04996145
  0.05238379 0.06133477]
 [0.05220662 0.04995549 0.05746198 0.03891017 0.03063184 0.04698939
  0.0595405  0.05447171 0.05561908 0.03561693 0.03959999 0.03818543
  0.04223165 0.03175564 0.02915325 0.04978192 0.04342916 0.03367921
  0.03969115 0.03912447 0.03297284 0.04825518 0.05621251 0.04160299
  0.05107041 0.05133834 0.05734676 0.03496223 0.03524124 0.08382468
  0.04506495 0.04627082 0.05740731 0.04406184 0.07649388 0.04123037
  0.04810512 0.02668851 0.02150334 0.03672675 0.06551588 0.05282182
  0.05108968 0.04336541]
 [0.05348184 0.02976342 0.03170881 0.02218109 0.01805315 0.02812803
  0.02850382 0.03065832 0.03155203 0.02254312 0.03006653 0.0239371
  0.02839351 0.01704708 0.01778165 0.03467003 0.03303213 0.02706305
  0.03210414 0.03089837 0.02838609 0.03297364 0.02785096 0.04228056
  0.04137087 0.03660047 0.02723086 0.02441333 0.01951466 0.02839247
  0.02356082 0.03017445 0.02101563 0.02117338 0.03190104 0.02785522
  0.02134459 0.01515941 0.01238476 0.02330521 0.04724495 0.05063464
  0.04710413 0.03622676]
 [0.05168747 0.05249291 0.05653151 0.04224833 0.03191995 0.04726223
  0.05649132 0.05593876 0.05193375 0.04144045 0.04488368 0.0482747
  0.05034469 0.03334737 0.02965617 0.05350226 0.04719747 0.047752
  0.05656058 0.05672128 0.04425868 0.06066949 0.05433355 0.06211463
  0.06694072 0.05969668 0.06109227 0.03923857 0.04303316 0.06294098
  0.08167463 0.0629118  0.07627333 0.08699674 0.10614619 0.07400503
  0.09183494 0.03164163 0.024881   0.03399937 0.07699978 0.06967396
  0.06126395 0.05797002]
 [0.05347952 0.06081016 0.06503459 0.06096692 0.04519767 0.070437
  0.06362642 0.07561034 0.06109942 0.06193727 0.0579857  0.07857675
  0.07656544 0.05072238 0.03429229 0.04822585 0.04481107 0.04642061
  0.04640656 0.04647925 0.03957802 0.0569384  0.04804648 0.05594118
  0.05320893 0.05353869 0.06205396 0.04390499 0.04578594 0.04471981
  0.06963258 0.06113201 0.06757372 0.09195308 0.07688802 0.05505667
  0.08950392 0.03779217 0.04142375 0.0406674  0.05275146 0.03800321
  0.04219364 0.04429497]
 [0.05404782 0.05039085 0.05553833 0.04684429 0.03669537 0.05425201
  0.05606443 0.06057905 0.05182704 0.05152553 0.05141913 0.05721818
  0.05804427 0.03940552 0.03036405 0.0503423  0.04583042 0.04416037
  0.04766432 0.04885757 0.0418537  0.05340435 0.04318567 0.05378801
  0.05062701 0.04796479 0.06114289 0.0396946  0.03712002 0.04397258
  0.08490703 0.06879932 0.07541349 0.07972001 0.07152133 0.07511265
  0.08894891 0.03459434 0.02285217 0.03520606 0.04790323 0.04099487
  0.03988726 0.04518853]
 [0.05326466 0.04121588 0.03898172 0.02924958 0.02372789 0.03423109
  0.04309521 0.04400776 0.03947148 0.03440792 0.04770879 0.04028638
  0.04351843 0.02228663 0.02186943 0.05956345 0.05165971 0.05216096
  0.04992424 0.05244783 0.04814584 0.05600126 0.03367168 0.05928012
  0.06284381 0.04351372 0.04707192 0.03823761 0.03012365 0.02690124
  0.08459903 0.06080097 0.06216175 0.05600084 0.05372502 0.08607536
  0.05488544 0.02772957 0.0174011  0.02625124 0.04724735 0.06420742
  0.04408321 0.05291634]
 [0.05261432 0.04427637 0.03977279 0.02969435 0.02313489 0.03308453
  0.04899031 0.04776457 0.04051572 0.03309378 0.04613198 0.03726453
  0.04661514 0.0212167  0.02095446 0.070993   0.05041301 0.05922728
  0.05464819 0.06491569 0.06076279 0.05433664 0.03253477 0.06677106
  0.06580911 0.04281887 0.04221288 0.03939632 0.028028   0.01851212
  0.07302065 0.04943528 0.05336098 0.05616183 0.04467202 0.08484887
  0.04736049 0.02653073 0.01526079 0.02439682 0.04902039 0.08339478
  0.04638164 0.05489003]
 [0.05426288 0.04133284 0.040184   0.03007695 0.0257818  0.03460786
  0.04433928 0.04435628 0.04151422 0.03543671 0.05456237 0.04597457
  0.04583463 0.02363422 0.02234276 0.06473072 0.05718141 0.07360332
  0.06540167 0.10808787 0.08095535 0.0483503  0.03052645 0.08377062
  0.07565183 0.05097077 0.04388318 0.04338299 0.02662764 0.01993893
  0.06283657 0.06341014 0.04251176 0.05430508 0.05166456 0.10161171
  0.0532713  0.0269604  0.02194924 0.02443134 0.04795608 0.07508184
  0.05431305 0.04439316]
 [0.05431776 0.0378435  0.03583838 0.02507449 0.02143443 0.02877114
  0.04196904 0.03698451 0.03744398 0.03028528 0.05914064 0.03853238
  0.03865399 0.01940955 0.02038076 0.06485456 0.06606576 0.06528314
  0.06550649 0.08062331 0.06859564 0.04958154 0.02889256 0.09164929
  0.06739799 0.05189221 0.03882168 0.042339   0.02539728 0.01737517
  0.05635851 0.05967615 0.02837489 0.04216645 0.04545503 0.08485427
  0.03835089 0.02358084 0.01623062 0.02452505 0.03967711 0.07699247
  0.06463023 0.04751898]
 [0.05199094 0.05033237 0.04765904 0.03538549 0.02944977 0.04226025
  0.05715807 0.05118095 0.05656042 0.0407233  0.04780561 0.04299341
  0.05250479 0.02448155 0.02290273 0.05189592 0.05479501 0.05612523
  0.06004332 0.06218489 0.06163522 0.0500421  0.05422122 0.08140288
  0.07361493 0.06896638 0.04555348 0.05944439 0.03692059 0.02429131
  0.03704023 0.05449698 0.04026099 0.04538839 0.04954427 0.05603462
  0.0415838  0.03326026 0.03290713 0.03892148 0.06072291 0.07121308
  0.07732128 0.06483373]
 [0.05441711 0.04455578 0.04579464 0.03668632 0.02752546 0.04041861
  0.04603463 0.04429955 0.04575216 0.04326147 0.05092465 0.05046773
  0.04784285 0.02672673 0.02347221 0.04586661 0.04450646 0.04303025
  0.048729   0.04104931 0.04745987 0.051962   0.03136041 0.05106266
  0.04024387 0.04295482 0.04074505 0.04412296 0.03273258 0.02653192
  0.05344073 0.07587574 0.07546406 0.08269724 0.0715354  0.06987983
  0.07805692 0.04106607 0.02967438 0.02389705 0.03796653 0.04239712
  0.04287246 0.0493192 ]
 [0.05298434 0.05400041 0.05332544 0.06551984 0.05695166 0.06076433
  0.05260055 0.05035421 0.05776091 0.07188718 0.05413705 0.06041137
  0.05866023 0.08817953 0.09638228 0.04363367 0.04568034 0.04641652
  0.04806886 0.04105327 0.04426548 0.05229784 0.0568116  0.03288111
  0.04049791 0.05380052 0.05096928 0.06759555 0.06821357 0.04355925
  0.02961165 0.04648439 0.04013454 0.04104381 0.03469525 0.02822263
  0.04388708 0.13702214 0.07798722 0.06796257 0.04558002 0.03675181
  0.04808067 0.04619992]
 [0.0523591  0.07956621 0.07137705 0.12034128 0.24950813 0.09601531
  0.06519167 0.05783135 0.07093967 0.12685575 0.10268956 0.10320347
  0.06387063 0.15230596 0.18973438 0.06873308 0.09400117 0.09021106
  0.07515483 0.05192899 0.07615764 0.05222941 0.08537059 0.03044185
  0.03707074 0.06390102 0.07946551 0.08872776 0.07890865 0.0460908
  0.02506773 0.03421101 0.02313995 0.03247916 0.02375598 0.02079619
  0.03475723 0.14776236 0.19209203 0.1127679  0.05708314 0.03343054
  0.0519114  0.05918107]
 [0.05299814 0.0608459  0.05001481 0.05980478 0.08346783 0.04586232
  0.04816906 0.04136948 0.04730709 0.07320508 0.06974605 0.06573548
  0.05027297 0.04849395 0.06630033 0.05992272 0.09017045 0.0994941
  0.09379689 0.06334137 0.12083144 0.05080695 0.05963006 0.05314431
  0.04918131 0.05300497 0.05552462 0.07718363 0.04549387 0.02166099
  0.0308238  0.04155795 0.02367103 0.03101093 0.02626161 0.02936806
  0.02966968 0.09334569 0.1883465  0.0572717  0.05514193 0.05131062
  0.05070462 0.07111154]
 [0.05257287 0.06606367 0.05461135 0.06487899 0.06184097 0.0522772
  0.05580423 0.04937347 0.06187307 0.06740033 0.05764683 0.05656712
  0.05041641 0.05164152 0.05845336 0.04714555 0.06325141 0.06555785
  0.06335138 0.05813322 0.07113128 0.06313779 0.07241182 0.03389371
  0.04329692 0.05455076 0.04919775 0.10345836 0.05660744 0.01859908
  0.01942095 0.0268249  0.01922007 0.02317824 0.02068905 0.02284663
  0.02467    0.05920496 0.11646806 0.17607304 0.04992612 0.04046972
  0.05539677 0.05827114]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Bill', ' is', ' in', ' the', ' park', ',', ' but', ' sentence', ' ', '14', ' updates', ' the', ' information', ',', ' stating', ' that', ' Bill', ' went', ' back', ' to', ' the', ' school', '.', ' This', ' implies', ' that', ' Bill', ' is', ' no', ' longer', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0217, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.01993141 0.03347541 0.03174295 ... 0.01484379 0.01434404 0.02008627]
 [0.02045254 0.05525537 0.047386   ... 0.03106306 0.03164514 0.02196882]
 [0.02081939 0.03116256 0.03289414 ... 0.02424909 0.02503374 0.02400875]
 ...
 [0.02104346 0.03177911 0.02806445 ... 0.01373896 0.00882991 0.02977345]
 [0.02154359 0.02387622 0.02030789 ... 0.01022784 0.00868508 0.01348476]
 [0.02126888 0.02334663 0.02031208 ... 0.01148279 0.00923179 0.01461059]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' has', ' left', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 26), x_tokens=26, y_tokens=38, max_supp_attn=0.0526, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 26)
DEBUG result.interpretability.attn_scores 988 
 [[0.02423223 0.03934548 0.04781647 0.06695791 0.08000971 0.06459835
  0.05196433 0.05703316 0.04449114 0.05794931 0.04417363 0.04970443
  0.05547895 0.09180209 0.06109361 0.02776435 0.02729583 0.02931279
  0.02566996 0.02738059 0.02277579 0.03450803 0.03597884 0.01602966
  0.01717031 0.02532427]
 [0.02461437 0.04883832 0.04418417 0.06468746 0.06027677 0.05205067
  0.04095677 0.03860344 0.0351344  0.04372521 0.03561838 0.02642177
  0.02881502 0.09985065 0.10010648 0.02902107 0.02266674 0.02067808
  0.02056843 0.02060043 0.01808519 0.03590185 0.03780532 0.0116916
  0.01162538 0.02067498]
 [0.02651628 0.05072157 0.03071493 0.04657497 0.03547464 0.03010503
  0.02785015 0.0191058  0.01818578 0.02939697 0.02585782 0.01365841
  0.01537365 0.02472255 0.03292653 0.02071436 0.01241357 0.0124264
  0.01518785 0.01515193 0.01411455 0.03896324 0.04427626 0.00706311
  0.00718545 0.01141854]
 [0.02482078 0.03542712 0.0404942  0.02411628 0.01712945 0.02852438
  0.02978842 0.02634228 0.0318216  0.02554215 0.02531918 0.0245156
  0.02289953 0.0126837  0.01256629 0.03381348 0.02883733 0.02820413
  0.02978318 0.03011791 0.02833586 0.02959778 0.04997501 0.0512405
  0.05556801 0.04654596]
 [0.02513547 0.036376   0.03911021 0.05947876 0.05578341 0.0405069
  0.03046145 0.02543723 0.02785798 0.03960621 0.03185786 0.02112834
  0.02138735 0.08772328 0.09292994 0.03311714 0.02412779 0.01935586
  0.01954617 0.02053877 0.01977555 0.03501241 0.05404496 0.0127692
  0.01079763 0.02663059]
 [0.0256487  0.02311403 0.02375995 0.04581108 0.04203626 0.03688289
  0.02262314 0.01977497 0.02354958 0.03714344 0.02812384 0.02414726
  0.02321558 0.09930799 0.12210745 0.03291405 0.0274053  0.0234567
  0.02206833 0.02190102 0.01892121 0.02949296 0.03167569 0.00881104
  0.00840747 0.01693367]
 [0.02600909 0.02610002 0.03068198 0.04825379 0.04604674 0.04682783
  0.02975415 0.02715456 0.03097025 0.04399956 0.03311836 0.0380729
  0.03520798 0.07942396 0.0767774  0.02767533 0.02481852 0.02299427
  0.02103863 0.02143938 0.01775184 0.02654132 0.02964071 0.01193009
  0.01081968 0.01662003]
 [0.02514813 0.03504413 0.04158506 0.03874133 0.04102243 0.04422758
  0.03430637 0.03656139 0.03474624 0.03988183 0.03419894 0.04222624
  0.03666473 0.0491211  0.04476803 0.0353859  0.0315899  0.02853202
  0.02515278 0.02624078 0.02389281 0.03020482 0.04145108 0.02914545
  0.02697205 0.03208254]
 [0.02528289 0.04141891 0.04740456 0.02976559 0.02527325 0.03498496
  0.04040587 0.04174793 0.03666005 0.03063153 0.03038434 0.03457576
  0.03575158 0.02206201 0.01619948 0.03512736 0.02866493 0.0270396
  0.02516906 0.02590589 0.02503193 0.0274733  0.05018813 0.03500367
  0.03854518 0.04341408]
 [0.02606806 0.0571188  0.06283995 0.02689476 0.01985153 0.03297217
  0.04141014 0.03657521 0.04092857 0.02614673 0.02460946 0.02916677
  0.02773072 0.01520569 0.01286805 0.04064238 0.02865344 0.02510314
  0.02503651 0.02712856 0.02345764 0.02662857 0.05661068 0.02571734
  0.02683273 0.0295807 ]
 [0.02603875 0.03333058 0.03874362 0.02118928 0.01718286 0.02364114
  0.03334338 0.02965851 0.03119188 0.02197819 0.02184454 0.02370567
  0.0215799  0.01302246 0.01229112 0.03954206 0.03017539 0.0244378
  0.02635689 0.0270023  0.02499557 0.02617044 0.04678433 0.0410493
  0.04055222 0.03324188]
 [0.02619953 0.01734014 0.02075992 0.0139997  0.01236474 0.01692772
  0.02056976 0.02058824 0.02794241 0.01691548 0.01533566 0.01579621
  0.01491173 0.00894208 0.00903342 0.0253049  0.0242091  0.02011089
  0.02416215 0.02636507 0.02480009 0.02212157 0.04244051 0.05928665
  0.06283319 0.03916315]
 [0.02604218 0.02579561 0.02665082 0.01874407 0.01601412 0.02311977
  0.02679139 0.02491512 0.02392249 0.02048452 0.02309952 0.02460794
  0.02180162 0.01051575 0.01101419 0.03454363 0.02758028 0.02426944
  0.02370683 0.02361937 0.0241389  0.02587077 0.02826622 0.04763457
  0.05092918 0.03774098]
 [0.02658802 0.03277063 0.03551223 0.03134206 0.0236024  0.03831316
  0.03630087 0.0383715  0.03166916 0.03818876 0.03664819 0.05223069
  0.04007224 0.01815706 0.0135052  0.02526039 0.02684185 0.0264419
  0.02422354 0.02405043 0.02167099 0.02811025 0.02084085 0.02099486
  0.01902225 0.01819879]
 [0.02685279 0.02386218 0.0243421  0.02011459 0.01755464 0.02277026
  0.02747673 0.02546092 0.02127695 0.0229257  0.02795496 0.02666062
  0.02505937 0.01117641 0.01052549 0.02629676 0.02562647 0.0223429
  0.02202043 0.02218561 0.02239327 0.02648444 0.01900819 0.03363254
  0.02450678 0.01860263]
 [0.02630075 0.01822828 0.01587543 0.01303984 0.01175686 0.01402422
  0.02006455 0.01860442 0.01619693 0.01514112 0.02327502 0.01749242
  0.01944243 0.00684841 0.00783645 0.02735111 0.03093824 0.02521636
  0.02389519 0.02398582 0.03051695 0.02381227 0.01707978 0.05911618
  0.0428934  0.0282849 ]
 [0.02613977 0.01669501 0.01396764 0.01219482 0.0102548  0.01292529
  0.02087465 0.020303   0.01513684 0.01389513 0.02110612 0.01502755
  0.01903691 0.00604076 0.00665883 0.02394481 0.03215908 0.03118493
  0.02890789 0.02731598 0.04182645 0.0215076  0.0163009  0.06289484
  0.04605307 0.0333884 ]
 [0.02659417 0.01576461 0.01371706 0.0115882  0.01038194 0.01355325
  0.01803314 0.0177428  0.01503833 0.0140666  0.02395824 0.01811045
  0.0188327  0.0061946  0.00635445 0.02298725 0.0327843  0.02630994
  0.02876464 0.02499049 0.03251711 0.02074903 0.0135169  0.05688026
  0.03296814 0.02312051]
 [0.02653175 0.01427689 0.01212231 0.00925159 0.00867903 0.01130581
  0.01791804 0.01587643 0.0143617  0.01140696 0.02982474 0.01511577
  0.01761517 0.0050935  0.00544394 0.02540608 0.03424592 0.02861657
  0.03429079 0.02896183 0.0363551  0.02027811 0.01388601 0.05830502
  0.03550088 0.03206697]
 [0.02559307 0.02441619 0.02140867 0.01601803 0.01837297 0.01829189
  0.03057216 0.02505527 0.0246343  0.01767629 0.02357303 0.01816255
  0.0222402  0.00917336 0.010569   0.02602313 0.03032135 0.03386576
  0.0639377  0.05541617 0.04361077 0.02769035 0.03256988 0.04395978
  0.04656463 0.05089488]
 [0.02687321 0.01678811 0.01579649 0.0140334  0.01115754 0.01481413
  0.01736713 0.01818002 0.01814357 0.01575713 0.01974077 0.01753988
  0.01790011 0.0078199  0.00711368 0.01842006 0.0193197  0.01993849
  0.02531556 0.02320458 0.02424566 0.02293347 0.0142304  0.02217069
  0.03030043 0.03626845]
 [0.02693065 0.01774096 0.0203947  0.02038544 0.01533894 0.0216928
  0.01912001 0.02295697 0.02300194 0.0240777  0.02005755 0.02517799
  0.02220616 0.01202568 0.00857695 0.01572396 0.01914817 0.01954443
  0.02013264 0.01959576 0.0198381  0.0243057  0.01577169 0.01555606
  0.02624934 0.03169701]
 [0.02677802 0.02257718 0.02214803 0.01759823 0.01375569 0.02044266
  0.0240641  0.0280004  0.02566625 0.01937571 0.0190443  0.02380317
  0.02579747 0.0103498  0.008053   0.02092839 0.0193809  0.02238811
  0.0224111  0.02332393 0.02370257 0.02712154 0.01971758 0.01778182
  0.03844287 0.03600471]
 [0.02702575 0.02154377 0.02141553 0.01727246 0.01347045 0.0225546
  0.02618864 0.02909593 0.02952199 0.02024955 0.02100127 0.03078611
  0.02901437 0.00968229 0.0078566  0.0214968  0.02252854 0.02776229
  0.02787261 0.02882965 0.02744806 0.02285933 0.01732894 0.01499609
  0.02444039 0.02556237]
 [0.0274331  0.02157679 0.02206703 0.01984498 0.01518297 0.02913333
  0.02777722 0.0295835  0.03497492 0.02415772 0.02019773 0.03357082
  0.03117129 0.01243767 0.00837188 0.01605036 0.01771298 0.01942496
  0.02281154 0.02197846 0.01886827 0.02427904 0.0176409  0.01084713
  0.01654393 0.02108799]
 [0.02688796 0.03238962 0.02914421 0.02181212 0.01614232 0.02841779
  0.03397952 0.03785531 0.03757004 0.0263944  0.02631588 0.03948486
  0.039904   0.01271742 0.00875341 0.02499479 0.02230816 0.02951533
  0.02687546 0.02945701 0.02497666 0.02573065 0.02039916 0.01401953
  0.02011176 0.02027114]
 [0.02734569 0.02576127 0.02690002 0.02169979 0.01521715 0.03916834
  0.03433448 0.03494868 0.03884238 0.02648331 0.02408628 0.05558442
  0.0450279  0.01300982 0.00816279 0.02086029 0.01998744 0.02278107
  0.02347429 0.024082   0.01973396 0.02437415 0.01653513 0.01056319
  0.01374017 0.0143572 ]
 [0.02754097 0.01830686 0.01822809 0.01604424 0.01133167 0.01837617
  0.02093264 0.0255606  0.02380757 0.02032195 0.02174851 0.02878502
  0.03040596 0.00951001 0.00624406 0.02037482 0.01889963 0.02359124
  0.02188323 0.02304428 0.02292066 0.02256598 0.0107746  0.01421174
  0.01579619 0.01385948]
 [0.02746988 0.01839732 0.01787797 0.01677692 0.01220342 0.01890911
  0.02056449 0.02460916 0.02337485 0.0213825  0.02301342 0.02587442
  0.02918261 0.00995519 0.00683348 0.01996281 0.01986418 0.02440913
  0.02308919 0.02408348 0.02365224 0.02339684 0.01079056 0.01554815
  0.01580381 0.01312459]
 [0.02696771 0.01749994 0.01582326 0.01291877 0.00958497 0.01292446
  0.01881249 0.02074615 0.01915558 0.01484391 0.02097478 0.01844474
  0.02318349 0.00711394 0.0059272  0.0286521  0.0234997  0.03550669
  0.02668756 0.03238175 0.03659974 0.02169689 0.01183147 0.02284863
  0.03029716 0.02209486]
 [0.02701073 0.01860665 0.01696492 0.01358655 0.01009456 0.01446132
  0.02192638 0.02436044 0.02186914 0.01620802 0.02503552 0.02130013
  0.02735243 0.00775405 0.00582466 0.03261635 0.02613963 0.04238358
  0.02998224 0.03839399 0.03866448 0.02139214 0.01116688 0.0206113
  0.02740306 0.01951701]
 [0.0273345  0.01524625 0.0144475  0.01117879 0.00857434 0.01265097
  0.01707191 0.01777142 0.01968328 0.01369572 0.02357634 0.01641011
  0.01991991 0.00690742 0.00529367 0.02285348 0.02273311 0.02551704
  0.02716242 0.03036403 0.03559734 0.02071851 0.01108966 0.02463861
  0.02302219 0.02287188]
 [0.0266082  0.01867598 0.01632372 0.01025763 0.00807116 0.01206928
  0.02037471 0.01805863 0.0206953  0.01249546 0.02738211 0.01454263
  0.02116952 0.00631472 0.00523847 0.02776775 0.02917551 0.03026742
  0.0337578  0.03325868 0.0388361  0.02154829 0.0143313  0.04285508
  0.03082504 0.03925793]
 [0.0274751  0.01701724 0.01705073 0.01305233 0.00958497 0.01429937
  0.0175165  0.01934958 0.02242382 0.01504713 0.01789087 0.01595459
  0.02029236 0.00833463 0.0058992  0.0194895  0.01734521 0.02078946
  0.02445236 0.027024   0.02490481 0.02170876 0.01349168 0.01685832
  0.02514351 0.02956055]
 [0.02626158 0.02442279 0.02323889 0.03758051 0.03811339 0.03204262
  0.02155647 0.02197098 0.02552084 0.03844532 0.02849801 0.02452024
  0.02717836 0.06243438 0.07691175 0.02300574 0.02380052 0.02325636
  0.02273712 0.02215108 0.01959928 0.02841053 0.02709455 0.00908425
  0.01064635 0.01775602]
 [0.02599914 0.02531687 0.02372356 0.0427605  0.08218694 0.03214094
  0.01903918 0.02042933 0.02398464 0.04507662 0.0338656  0.02565363
  0.02256111 0.06550165 0.08474902 0.02815934 0.03400601 0.03233953
  0.02642665 0.02379101 0.02280255 0.0256898  0.02759647 0.00808934
  0.00819632 0.01571068]
 [0.02568781 0.02375916 0.02185833 0.03799241 0.08749222 0.02338417
  0.01635143 0.0196516  0.02100371 0.04247541 0.03482588 0.0281608
  0.02187747 0.03169161 0.04162938 0.02440936 0.05559068 0.04880465
  0.03644833 0.02796406 0.03524012 0.02336833 0.02449073 0.01426847
  0.01457063 0.01957608]
 [0.02601329 0.02838871 0.02490573 0.03644091 0.05342883 0.0259646
  0.02155735 0.02195914 0.02504357 0.03681067 0.03286339 0.02387901
  0.0227381  0.02937245 0.03298535 0.02139854 0.0372045  0.03188078
  0.028993   0.02677394 0.02740181 0.04078096 0.03337811 0.01189594
  0.01271923 0.01749365]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Fred', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' he', ' has', ' moved', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.0294, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02755822 0.0450833  0.04527759 ... 0.05806696 0.01008167 0.0103346 ]
 [0.02818382 0.0468667  0.04397897 ... 0.06348453 0.01805236 0.01605771]
 [0.02882772 0.04305901 0.04469327 ... 0.05846087 0.02082621 0.01977523]
 ...
 [0.02866295 0.03929472 0.03523839 ... 0.02213283 0.00781737 0.00645986]
 [0.02915493 0.02707571 0.0234248  ... 0.01251034 0.01021391 0.00823676]
 [0.02915539 0.02809608 0.02455054 ... 0.01186946 0.00856663 0.00865516]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Fred', ' might', ' be', ' in', ' the', ' bedroom', ',', ' but', ' we', ' are', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 38), x_tokens=38, y_tokens=53, max_supp_attn=0.0189, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 38)
DEBUG result.interpretability.attn_scores 2014 
 [[0.01722335 0.03059702 0.02848866 ... 0.02035295 0.01382959 0.03160468]
 [0.01769049 0.02176915 0.02129118 ... 0.01747437 0.01534944 0.02549776]
 [0.01801758 0.03031721 0.03053425 ... 0.01887995 0.0128421  0.02727468]
 ...
 [0.01819186 0.02436933 0.0238599  ... 0.01773173 0.01393823 0.03216352]
 [0.01851172 0.01966598 0.01815063 ... 0.02127907 0.02077335 0.02544808]
 [0.01858866 0.01946092 0.01794318 ... 0.02016921 0.01774209 0.02705217]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' has', ' left', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02757044 0.03858699 0.04163896 ... 0.0105171  0.00980755 0.00491759]
 [0.0280614  0.03158223 0.03423271 ... 0.0201596  0.01695142 0.01204091]
 [0.02874757 0.03944156 0.04236127 ... 0.01530628 0.01403196 0.00669056]
 ...
 [0.02889063 0.04096078 0.03957112 ... 0.00724108 0.00625028 0.00415008]
 [0.02913942 0.03260504 0.02954605 ... 0.00923043 0.00721555 0.00536946]
 [0.02910476 0.03894681 0.03656427 ... 0.00736525 0.00757315 0.00531706]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 50), x_tokens=50, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 50)
DEBUG result.interpretability.attn_scores 1700 
 [[0.02754374 0.03568982 0.0433834  ... 0.02399064 0.02004171 0.02100415]
 [0.02785849 0.03221028 0.03591586 ... 0.03169046 0.0263381  0.0265683 ]
 [0.02868875 0.04094214 0.0486693  ... 0.02198231 0.01704597 0.01838239]
 ...
 [0.02877673 0.03843432 0.04024443 ... 0.02259829 0.01796525 0.02289783]
 [0.02933329 0.02991864 0.02991577 ... 0.0254814  0.02296817 0.02578678]
 [0.02914954 0.03242874 0.03188686 ... 0.02325802 0.02246233 0.02562647]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0588, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02727467 0.04382671 0.05382835 0.07097965 0.08017187 0.07207768
  0.05568676 0.06244242 0.05210654 0.06259334 0.0456729  0.05870541
  0.06416564 0.09620981 0.0636839  0.0288546  0.02972344 0.02989186
  0.02743053 0.02996023 0.02527339 0.03665947 0.03990238 0.02000437
  0.01660573 0.02538593]
 [0.02767065 0.0549082  0.05230373 0.06853491 0.06048769 0.05718055
  0.04440778 0.04276035 0.04296734 0.04796331 0.03731786 0.03144481
  0.0324884  0.10303266 0.10184818 0.03077728 0.02557913 0.02157643
  0.02196413 0.02260271 0.02050439 0.03828521 0.04310724 0.01519702
  0.01048032 0.02123358]
 [0.02982865 0.05768324 0.03590641 0.05004124 0.03670199 0.03406397
  0.02988852 0.02097473 0.0217364  0.03247569 0.02692475 0.01612394
  0.01739086 0.02552491 0.03354116 0.02125296 0.0134451  0.01251597
  0.01593844 0.01643169 0.01591264 0.04141866 0.04957959 0.00914955
  0.00607638 0.0114684 ]
 [0.02791644 0.02631172 0.02857988 0.02209419 0.01604479 0.02527761
  0.02618591 0.02426049 0.02985905 0.02441116 0.02308498 0.02397979
  0.02327316 0.01141731 0.01168508 0.02795001 0.03158247 0.03246572
  0.03953338 0.04090413 0.0336851  0.03217414 0.04769936 0.04981344
  0.06354327 0.06325391]
 [0.02829173 0.04116227 0.04595434 0.064189   0.05802412 0.04622192
  0.0328735  0.02819366 0.03346629 0.04400028 0.03326953 0.02513517
  0.02451253 0.09122963 0.09517577 0.03427883 0.02635135 0.01964296
  0.02065978 0.02239592 0.02237607 0.03733114 0.0605675  0.01630172
  0.00916835 0.02666732]
 [0.02883362 0.02618167 0.02784482 0.04936984 0.04345547 0.04185214
  0.02436485 0.02179103 0.02827648 0.04121273 0.02951202 0.02867838
  0.02638758 0.10274269 0.12442479 0.03404249 0.02986333 0.02373738
  0.02326505 0.02383917 0.02140128 0.03152089 0.03557241 0.01135327
  0.00741222 0.01687986]
 [0.02924147 0.02970784 0.0359537  0.05214423 0.04783405 0.0531887
  0.03244045 0.03035132 0.03706227 0.04874886 0.0345846  0.04536319
  0.04036826 0.0817785  0.07754787 0.02875568 0.02712921 0.02348681
  0.02238274 0.02352227 0.02012675 0.02859424 0.03307626 0.01519064
  0.01046003 0.01669031]
 [0.02818275 0.03790143 0.04483211 0.04083409 0.04237385 0.04901163
  0.03826669 0.04063515 0.04013871 0.0433758  0.03524503 0.05008379
  0.04376079 0.05035289 0.04557942 0.03779021 0.03461613 0.03074187
  0.02835304 0.0304415  0.02767358 0.03338761 0.04606503 0.03450368
  0.03232312 0.03537339]
 [0.02938042 0.0400965  0.04828376 0.04599671 0.04118362 0.05548633
  0.04235507 0.04468416 0.04697164 0.04824447 0.03543273 0.05018533
  0.0455012  0.0376424  0.02479211 0.0274285  0.02686386 0.02523747
  0.02428216 0.0267058  0.02256588 0.032976   0.03615816 0.0210105
  0.0166006  0.0238559 ]
 [0.02863431 0.0499463  0.05388526 0.02920776 0.02321497 0.03783503
  0.04538071 0.04306131 0.04568334 0.03092721 0.02860132 0.03785291
  0.03902074 0.01701225 0.01435248 0.04310772 0.03502765 0.03009589
  0.03060195 0.03285372 0.03091156 0.03320844 0.06374684 0.04315265
  0.03924496 0.03678432]
 [0.02923005 0.06582078 0.06523818 0.02727699 0.02176098 0.03259147
  0.04567287 0.03898524 0.0475109  0.02703482 0.02560157 0.03029982
  0.03036283 0.01431652 0.01365498 0.04793268 0.03496554 0.02831768
  0.02973679 0.03473741 0.03017741 0.02978995 0.06780192 0.03896926
  0.02728168 0.02601867]
 [0.0293404  0.03305762 0.03752081 0.02003156 0.01689701 0.02325409
  0.0340308  0.02882374 0.0353206  0.02140604 0.02049192 0.02360486
  0.02262975 0.01163492 0.01157956 0.03891175 0.03157965 0.02579856
  0.0302451  0.03203676 0.03001335 0.02875599 0.05212213 0.04709354
  0.04960101 0.0394171 ]
 [0.02953644 0.01455011 0.01568471 0.01114733 0.00997951 0.01344896
  0.01574936 0.01550857 0.01911615 0.01300243 0.01379723 0.01460525
  0.01407227 0.00611777 0.00663167 0.01928573 0.02014162 0.01965375
  0.02632961 0.02851537 0.02962548 0.02139266 0.03040148 0.05178176
  0.07395889 0.06101841]
 [0.02947201 0.02141559 0.02184332 0.01556859 0.01412979 0.01938387
  0.02293619 0.02087621 0.0224066  0.01734552 0.02013853 0.02067818
  0.01987622 0.0086318  0.00924353 0.03401279 0.0251764  0.0246667
  0.02700016 0.02807224 0.02769635 0.02788427 0.02562146 0.0443169
  0.06982427 0.05007003]
 [0.0295323  0.0233147  0.02384088 0.01901303 0.01641494 0.02371156
  0.02784906 0.02816551 0.02583222 0.0225561  0.02436066 0.02934628
  0.03003064 0.01103756 0.00962674 0.03286834 0.02867489 0.0313804
  0.03032549 0.03050273 0.02950796 0.02979193 0.02136745 0.03485253
  0.0574348  0.03210878]
 [0.02912272 0.01972277 0.01670272 0.01463079 0.01167287 0.01556978
  0.02143661 0.02134174 0.0188247  0.01608385 0.02015012 0.01880902
  0.02216292 0.00709216 0.00711916 0.03256631 0.02270072 0.03741239
  0.03753004 0.0421132  0.03973721 0.02627168 0.01567457 0.04903491
  0.08888294 0.04590722]
 [0.0297866  0.0193274  0.01822094 0.01509767 0.012729   0.0177514
  0.02397625 0.02469137 0.0212408  0.01807878 0.02569427 0.02453944
  0.0258148  0.00737723 0.00716462 0.03872424 0.02710756 0.04318301
  0.03225334 0.03793062 0.03512567 0.02291846 0.01428963 0.04335615
  0.04872808 0.02972783]
 [0.02959097 0.01711663 0.01496969 0.01163305 0.00993518 0.01416931
  0.02250787 0.02106026 0.01828263 0.01407336 0.03226266 0.02003963
  0.02203159 0.0059736  0.00643483 0.03499616 0.03212792 0.04012662
  0.0378516  0.03697883 0.03670389 0.02376322 0.01410578 0.04951706
  0.045261   0.0443431 ]
 [0.02898184 0.02226164 0.01840851 0.01380063 0.01207515 0.01713115
  0.02862627 0.02449434 0.02312608 0.01599908 0.02721094 0.01944941
  0.02326213 0.00699477 0.00751635 0.02498935 0.03215332 0.03099431
  0.03214207 0.0337432  0.0389169  0.02702291 0.02145851 0.06893079
  0.05087241 0.06953403]
 [0.03025174 0.02165177 0.02045657 0.01663825 0.01346153 0.01906112
  0.02258729 0.02348317 0.02234747 0.01832744 0.02474649 0.02346112
  0.0229807  0.00884017 0.00804066 0.02419953 0.02402058 0.02727332
  0.02872704 0.02735626 0.02783103 0.0263021  0.01576562 0.02673677
  0.02493709 0.02981965]
 [0.03043748 0.02276164 0.02525889 0.02206594 0.01702667 0.0255302
  0.02571315 0.03237908 0.02606735 0.02618429 0.02667217 0.03453784
  0.03067956 0.01254021 0.00903784 0.0200836  0.02057415 0.02308135
  0.02329789 0.02223639 0.02244275 0.02739211 0.01481623 0.0177737
  0.01839319 0.0213804 ]
 [0.03056077 0.0274754  0.02882998 0.02694869 0.01940491 0.0306035
  0.03173794 0.04036017 0.02878898 0.03271022 0.03353139 0.04319616
  0.04027224 0.01440247 0.00996242 0.02304124 0.02227039 0.0261396
  0.02379885 0.02296097 0.02291744 0.02778679 0.01603762 0.01599328
  0.01356433 0.01466482]
 [0.03041059 0.02479901 0.02490539 0.02431828 0.01916443 0.02719823
  0.02873689 0.03462227 0.02802444 0.03047651 0.03132647 0.03844681
  0.03865764 0.01389706 0.01023003 0.02598404 0.02435619 0.02892345
  0.02722025 0.02587326 0.0256923  0.02885363 0.01402226 0.01710365
  0.01729124 0.01394117]
 [0.03024678 0.01954713 0.01825139 0.01521877 0.01161857 0.01712834
  0.02254569 0.02529548 0.02230523 0.018586   0.02289265 0.02384951
  0.02716012 0.00811278 0.00723332 0.02779774 0.02581625 0.02969267
  0.02995394 0.02810931 0.03197086 0.02806608 0.01229688 0.02414379
  0.02986145 0.01961764]
 [0.0301556  0.02053069 0.01855199 0.01597762 0.01138362 0.01658481
  0.02582945 0.02720847 0.02220667 0.01815508 0.02394123 0.02191246
  0.02686987 0.0078141  0.00732259 0.02990139 0.0264078  0.03283097
  0.03570759 0.03240522 0.0360285  0.02458381 0.01195935 0.02751389
  0.02734844 0.02279588]
 [0.03035196 0.02015401 0.0179492  0.0154919  0.01222476 0.01652681
  0.0227641  0.02481587 0.02174063 0.01866088 0.02536057 0.02371801
  0.02563381 0.00816664 0.00727466 0.02824751 0.03046273 0.03078655
  0.03493899 0.02887793 0.03402675 0.02508731 0.01199357 0.0235574
  0.01877419 0.01881308]
 [0.03047059 0.02245072 0.0201167  0.01653196 0.01231342 0.01810315
  0.02661989 0.02754192 0.02656437 0.01994233 0.03045517 0.02522019
  0.02838293 0.00852408 0.00737669 0.03063633 0.02965757 0.03322973
  0.03386944 0.03205233 0.0350811  0.02555942 0.01238794 0.02519601
  0.01765736 0.01681122]
 [0.03049123 0.0171525  0.01564783 0.01106795 0.00944202 0.01285211
  0.0217855  0.02078094 0.02035658 0.01372157 0.03474566 0.01846834
  0.02249732 0.00630166 0.00552629 0.02935119 0.03379373 0.03259566
  0.0375472  0.0320389  0.03457571 0.02362694 0.01159977 0.03232691
  0.02031826 0.02352226]
 [0.02917984 0.02634012 0.02437875 0.01471287 0.01307255 0.01882911
  0.04688691 0.04134103 0.03222867 0.01905789 0.04916972 0.02935485
  0.04035832 0.00809809 0.00784422 0.02756391 0.04081394 0.03856845
  0.03753103 0.03923529 0.04279958 0.02832481 0.02191087 0.05667135
  0.03396115 0.04532448]
 [0.03056819 0.02129302 0.02062009 0.01784515 0.01389706 0.02081989
  0.02279909 0.02718573 0.02599132 0.02129584 0.02522269 0.02619758
  0.02607967 0.01132482 0.00914974 0.01766961 0.02393966 0.02381557
  0.02708888 0.02452132 0.02702723 0.02530791 0.01418697 0.01781199
  0.01487887 0.02122403]
 [0.02946999 0.02687375 0.02689815 0.04133999 0.04358403 0.036907
  0.02303074 0.02362066 0.02948311 0.04254222 0.030118   0.03067659
  0.02865884 0.06906528 0.08254471 0.02313084 0.02669981 0.02324778
  0.02366013 0.02345083 0.02257876 0.03040737 0.03058591 0.01172765
  0.00875422 0.01895899]
 [0.02927835 0.02791935 0.02698151 0.04526477 0.08806793 0.03617169
  0.02146497 0.02224789 0.02858905 0.04875875 0.03532498 0.03135551
  0.02402915 0.06694242 0.08470652 0.02827746 0.03774891 0.03256513
  0.02811825 0.02591676 0.02629143 0.02739589 0.0296661  0.00997896
  0.00677241 0.01621667]
 [0.02898324 0.02544625 0.02377195 0.03707884 0.08535612 0.02491276
  0.01818689 0.02160915 0.02498743 0.04309323 0.03396356 0.03259284
  0.02404239 0.03008835 0.04011339 0.02468379 0.05968463 0.05239425
  0.03950544 0.03118864 0.04113487 0.02501071 0.02680921 0.01646692
  0.01277228 0.02122494]
 [0.02929559 0.03129155 0.0275795  0.03790766 0.05489561 0.02956414
  0.02467592 0.02440664 0.03038985 0.03895501 0.03317568 0.02808754
  0.02658513 0.02976247 0.03203468 0.02090613 0.03894425 0.03392969
  0.03120977 0.02948918 0.03166684 0.04314829 0.03764402 0.01346801
  0.01095555 0.01994674]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' we', ' don', "'t", ' have', ' enough', ' information', ' to', ' determine', ' his', ' exact', ' location', '.', ' \n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.1316, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02442231 0.03738694 0.0363504  ... 0.05507552 0.01028269 0.03274353]
 [0.02520861 0.03461991 0.03385828 ... 0.06192749 0.01541629 0.04004306]
 [0.02557409 0.0346911  0.03834007 ... 0.06326037 0.0244614  0.03756526]
 ...
 [0.02560717 0.03240818 0.02975679 ... 0.01926047 0.00719463 0.0139081 ]
 [0.02592123 0.02567333 0.02171952 ... 0.01065943 0.01102759 0.01301218]
 [0.02625137 0.02511091 0.02204352 ... 0.01090111 0.01015071 0.01612191]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' was', ' initially', ' in', ' the', ' office', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '8', ',', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 38), x_tokens=38, y_tokens=46, max_supp_attn=0.0, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 38)
DEBUG result.interpretability.attn_scores 1748 
 [[0.02010396 0.03053667 0.02857365 ... 0.0149106  0.01432102 0.01793597]
 [0.02051305 0.02602324 0.02584197 ... 0.01826597 0.01980049 0.02385629]
 [0.02099659 0.03368428 0.03485817 ... 0.01121779 0.01217919 0.01403359]
 ...
 [0.02113915 0.02794288 0.02553298 ... 0.01340653 0.01349618 0.01276292]
 [0.02145591 0.02214306 0.01920865 ... 0.0148582  0.01996524 0.01718626]
 [0.02136867 0.02485486 0.02106992 ... 0.01508162 0.01588461 0.01675402]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ' (', 'from', ' previous', ' parts', '),', ' Mary', ' was', ' initially', ' in', ' the', ' office', ',', ' but', ' then', ' according', ' to', ' context', ' sentence', ' ', '8', ' (', 'from', ' previous', ' parts', '),', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 44), x_tokens=44, y_tokens=55, max_supp_attn=0.1636, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 44)
DEBUG result.interpretability.attn_scores 2420 
 [[0.01683664 0.01916372 0.01832087 ... 0.02628326 0.01279947 0.01799485]
 [0.01708624 0.02077963 0.01969963 ... 0.03923906 0.01645498 0.02223973]
 [0.0175861  0.01975148 0.01936849 ... 0.03806956 0.01372451 0.02670712]
 ...
 [0.01775857 0.02136563 0.02005662 ... 0.01002762 0.00858755 0.00970761]
 [0.01813739 0.01730541 0.01585779 ... 0.00846782 0.01095854 0.00978376]
 [0.01803503 0.01693162 0.01591201 ... 0.00720889 0.00890811 0.00903577]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ' (', 'from', ' previous', ' parts', '),', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' left', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 50), x_tokens=50, y_tokens=37, max_supp_attn=0.0, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 50)
DEBUG result.interpretability.attn_scores 1850 
 [[0.02524389 0.03367516 0.02973851 ... 0.0207258  0.0094439  0.01163507]
 [0.0254917  0.02872787 0.02897091 ... 0.02589526 0.01534504 0.01180373]
 [0.02639062 0.03560367 0.03518336 ... 0.01751217 0.00891301 0.00809743]
 ...
 [0.02668436 0.03521909 0.03060935 ... 0.01471324 0.00847349 0.01039512]
 [0.02703169 0.02562695 0.02144636 ... 0.02126731 0.01665666 0.01756364]
 [0.02683581 0.02826675 0.02336954 ... 0.01606815 0.01159524 0.01028833]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Mary', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02625154 0.04781843 0.05825188 0.07070605 0.07364815 0.07208789
  0.07508743 0.07925121 0.05884695 0.06198758 0.04652334 0.06183529
  0.07242882 0.0852726  0.05334893 0.03187238 0.03088961 0.03438322
  0.03077552 0.03215722 0.02475565 0.0393981  0.0402933  0.01557541
  0.01972087 0.03415944]
 [0.02661614 0.05260735 0.0502772  0.06115129 0.05565308 0.05654532
  0.05716442 0.05537568 0.0465841  0.04853262 0.04091755 0.03963741
  0.04262817 0.09336691 0.09190034 0.03307648 0.02940635 0.02974842
  0.02772126 0.02773467 0.0213389  0.038157   0.04392242 0.01092732
  0.01431094 0.03205935]
 [0.02874204 0.05689941 0.03580518 0.05448369 0.03935433 0.03656757
  0.0317225  0.02250566 0.02205977 0.03379229 0.02700276 0.01637462
  0.01830943 0.02921712 0.03752664 0.02308401 0.01388301 0.01371028
  0.01659856 0.01608661 0.01373766 0.04234762 0.04811449 0.00485788
  0.00642347 0.01714667]
 [0.02728195 0.02556359 0.02754718 0.02346685 0.01627486 0.02422094
  0.02612021 0.02209304 0.02400078 0.0229417  0.02471473 0.02431685
  0.02258415 0.01257398 0.01181088 0.02855049 0.02507068 0.03042942
  0.03155508 0.03364466 0.03549042 0.0295252  0.03831176 0.06348249
  0.06222729 0.03923737]
 [0.02735139 0.04070329 0.04459825 0.0657091  0.05997749 0.04754003
  0.03415908 0.02877485 0.03315302 0.04490922 0.03324412 0.02548512
  0.02505975 0.09658097 0.10004183 0.0356115  0.02618691 0.0208643
  0.02173455 0.0218634  0.01916346 0.03742103 0.05712974 0.008047
  0.00958819 0.03710628]
 [0.02790914 0.02665209 0.02747616 0.04994088 0.04529883 0.04273234
  0.02539891 0.0228484  0.02823367 0.04177921 0.02995668 0.02874397
  0.02709363 0.10523985 0.12503967 0.03545208 0.02972731 0.02535035
  0.02465727 0.02343138 0.01848636 0.03194985 0.03399681 0.00632129
  0.00778579 0.02386289]
 [0.02830307 0.02999591 0.03541927 0.05222933 0.04862093 0.05292458
  0.03326381 0.03106979 0.0367468  0.04890267 0.03468668 0.04499469
  0.0411428  0.08375112 0.07884055 0.03024129 0.02729603 0.02533694
  0.02367399 0.02305087 0.01746438 0.02887231 0.0324185  0.00961739
  0.01074988 0.02229526]
 [0.02739875 0.04021687 0.04667853 0.04055796 0.04304732 0.0483288
  0.03860709 0.0403427  0.03984489 0.04257678 0.03498172 0.04843485
  0.04231663 0.05061891 0.04601717 0.04149023 0.03563746 0.032603
  0.02982807 0.02974975 0.02474861 0.03301848 0.04789668 0.02829374
  0.03043139 0.0357215 ]
 [0.02846672 0.04060854 0.04833581 0.04727875 0.04318839 0.05669452
  0.04352131 0.04584544 0.04844991 0.049176   0.0358167  0.0512942
  0.04629873 0.03917847 0.02599015 0.02857023 0.0271204  0.02714201
  0.02568252 0.02580683 0.01973217 0.03371764 0.03491498 0.01315411
  0.01704816 0.02882242]
 [0.02783595 0.05137711 0.05371488 0.02873793 0.0233912  0.03682986
  0.04426411 0.0416083  0.04442866 0.03015768 0.02836718 0.03731174
  0.03749894 0.01721541 0.01499457 0.04569132 0.03536536 0.03173183
  0.03212478 0.03284079 0.02965442 0.03261252 0.06381606 0.03515635
  0.04041702 0.03532727]
 [0.02828902 0.0661505  0.06492599 0.02709592 0.02259026 0.03171996
  0.04534703 0.03872659 0.04685561 0.02661136 0.02558002 0.03000714
  0.02980511 0.01451584 0.01427872 0.05015495 0.03578402 0.03061446
  0.03284087 0.03521728 0.02801192 0.03016913 0.06734353 0.02567546
  0.02932601 0.03249573]
 [0.02845915 0.03607477 0.04030747 0.02069016 0.01808836 0.02354431
  0.0353329  0.0299739  0.03646414 0.02160588 0.02100163 0.02428965
  0.02305924 0.01227519 0.0124463  0.04110456 0.0309428  0.02582579
  0.02967144 0.03030941 0.02695024 0.028735   0.05416301 0.0380547
  0.04824982 0.03777945]
 [0.02866234 0.01517551 0.01642366 0.01120086 0.01041454 0.01353358
  0.01561837 0.01533358 0.01869852 0.01302043 0.01378301 0.01417949
  0.01407031 0.0062493  0.007101   0.02079996 0.02030211 0.01954846
  0.02537797 0.02730924 0.02861526 0.02115308 0.03632686 0.0564924
  0.0816464  0.04513351]
 [0.02855637 0.02193105 0.02308436 0.01575185 0.01492782 0.0195539
  0.022847   0.02126225 0.02308597 0.01783249 0.02034857 0.02105921
  0.02057029 0.00906277 0.00970345 0.0338986  0.02359731 0.02311798
  0.02425853 0.02524769 0.02641954 0.02646689 0.02975559 0.05356113
  0.06155816 0.04076347]
 [0.02870077 0.0223742  0.02263926 0.01798166 0.01570828 0.02285723
  0.02518976 0.02591201 0.02373901 0.02139422 0.02442551 0.02770564
  0.02829305 0.01020291 0.00914248 0.03450079 0.02704372 0.02872574
  0.02736603 0.02807387 0.03038191 0.02751944 0.02170653 0.04859627
  0.04071769 0.02396889]
 [0.02814302 0.01738384 0.01493053 0.01297925 0.01047257 0.01377497
  0.01861694 0.0185314  0.01701511 0.01437028 0.01922904 0.01684543
  0.02038337 0.00638576 0.00641989 0.03044834 0.02754803 0.03681642
  0.03289769 0.04133276 0.05171828 0.0243026  0.01665605 0.08082658
  0.05229087 0.02839471]
 [0.02889391 0.01708094 0.01595963 0.01394073 0.01191859 0.01647579
  0.01916036 0.0197493  0.01845625 0.01638172 0.02182028 0.02044817
  0.02109767 0.00707358 0.00669387 0.02442544 0.02034942 0.0304448
  0.02693197 0.03848024 0.04857997 0.02107912 0.01422994 0.06314495
  0.0354007  0.02004391]
 [0.02947835 0.01424369 0.0126711  0.01077809 0.00894463 0.01287026
  0.01552357 0.0153846  0.0154612  0.01276392 0.02083603 0.01630028
  0.01689416 0.00574746 0.00559962 0.02073788 0.01934079 0.02459321
  0.02448375 0.02824012 0.04188922 0.01993553 0.01141232 0.04808003
  0.03010667 0.02070655]
 [0.02911212 0.0157179  0.01433233 0.01067444 0.00924043 0.01289116
  0.01860619 0.01725915 0.01714461 0.01279196 0.03153917 0.01843557
  0.01850191 0.00592244 0.00633326 0.02573188 0.02742837 0.02747028
  0.02825871 0.03086081 0.03960792 0.02186865 0.01349719 0.05054208
  0.0318287  0.02355048]
 [0.02814567 0.0241155  0.02212314 0.01645148 0.0170997  0.02316798
  0.03449041 0.03095111 0.02885051 0.0205574  0.03175258 0.02620918
  0.02831864 0.00945896 0.00963956 0.02510734 0.0348595  0.03362016
  0.03779772 0.03728916 0.04101701 0.02652145 0.02256885 0.03766961
  0.04278085 0.0655357 ]
 [0.02940448 0.0201338  0.01940125 0.01556092 0.01251247 0.01731873
  0.02078475 0.02183127 0.02107396 0.01715266 0.02405933 0.02154332
  0.02190211 0.00846904 0.00768741 0.02222927 0.02274545 0.02366719
  0.02563799 0.02599476 0.02714845 0.025748   0.01531286 0.02617237
  0.02959716 0.02376061]
 [0.02957053 0.02171842 0.02406216 0.02232535 0.01822033 0.02558276
  0.02511548 0.03156228 0.02585963 0.02676135 0.02756136 0.03538194
  0.03224288 0.01316165 0.00906783 0.01845621 0.02037941 0.02356343
  0.02284273 0.02117208 0.01971077 0.02818095 0.01487388 0.01572536
  0.0224477  0.02109024]
 [0.02974843 0.02565983 0.02681798 0.02578258 0.01857871 0.02811633
  0.02954101 0.03738113 0.02692621 0.03088376 0.0329689  0.04146991
  0.03860267 0.0143172  0.00977458 0.02089152 0.02086889 0.02455848
  0.02337455 0.02120461 0.01989912 0.02821096 0.01530951 0.01361653
  0.01600783 0.0159181 ]
 [0.02964974 0.02344629 0.02299992 0.02253538 0.01705874 0.02560842
  0.02667731 0.03110861 0.02725481 0.02746921 0.02960333 0.0353221
  0.0356542  0.01260754 0.00939185 0.0245483  0.02278751 0.0266141
  0.02593589 0.02360588 0.02139183 0.02779754 0.01264883 0.0166361
  0.01794963 0.01438951]
 [0.02945197 0.01839474 0.0171868  0.01389573 0.01064095 0.0160491
  0.0200439  0.02246573 0.02183978 0.0173531  0.02299695 0.0227527
  0.02526447 0.00765686 0.00667422 0.02792937 0.02593027 0.02723434
  0.02761684 0.02597824 0.02810624 0.02563175 0.01098395 0.02862292
  0.02767285 0.01726754]
 [0.02946628 0.01913483 0.01734859 0.0145258  0.01071149 0.01528598
  0.02175919 0.02347732 0.02105168 0.0170209  0.02227742 0.02086097
  0.02481942 0.00756166 0.00646001 0.02638852 0.02784703 0.02956456
  0.02942524 0.02661432 0.02983207 0.02309599 0.01075776 0.027197
  0.02959497 0.01914015]
 [0.02950215 0.01941759 0.01735174 0.01485993 0.01184236 0.01562905
  0.02008495 0.02255114 0.02095699 0.01807078 0.02433572 0.02241364
  0.02365338 0.00809101 0.00680801 0.02475902 0.02874002 0.02874902
  0.03104271 0.0262431  0.02908233 0.02327376 0.01177869 0.02295373
  0.02972071 0.02010032]
 [0.02964919 0.02131555 0.01928524 0.01581595 0.01187763 0.01670197
  0.02285091 0.02479948 0.02457305 0.01879406 0.02793103 0.02271945
  0.02512873 0.00828305 0.0070154  0.02658504 0.02797474 0.02949117
  0.0312408  0.0288163  0.03086644 0.02401471 0.01270468 0.02410899
  0.02279758 0.01643878]
 [0.02965425 0.01584995 0.01541272 0.01046851 0.00898218 0.0122516
  0.01820449 0.01849036 0.01924434 0.01300081 0.02907505 0.01702252
  0.01969576 0.00623279 0.00546956 0.02442097 0.03184135 0.02621836
  0.03072382 0.02826335 0.03125777 0.02172654 0.01168319 0.03209028
  0.02479678 0.01929636]
 [0.02832448 0.02059934 0.01960407 0.01237646 0.01063185 0.01533255
  0.0270233  0.0259464  0.02702368 0.01598364 0.03220856 0.02171134
  0.02791364 0.00732615 0.00673502 0.02399504 0.04128788 0.03908865
  0.04294497 0.04423018 0.04552219 0.02607635 0.02025835 0.04485303
  0.04300936 0.06297566]
 [0.02959691 0.01983761 0.02015728 0.01674061 0.01337713 0.02019442
  0.02109067 0.02543284 0.0240342  0.02023921 0.02456195 0.0245036
  0.0235577  0.01108883 0.00885692 0.01752728 0.02493989 0.02211226
  0.02617647 0.0273872  0.02451691 0.02423493 0.01302358 0.01679859
  0.0202424  0.02324117]
 [0.02857195 0.02662075 0.02668698 0.04083344 0.04252625 0.03621785
  0.02351357 0.02420052 0.02967063 0.04228102 0.03066104 0.02996846
  0.02936229 0.06621766 0.08110595 0.02425628 0.0264621  0.02540559
  0.02497667 0.02325894 0.01905591 0.03047957 0.02897704 0.00679429
  0.00988613 0.02648615]
 [0.02834012 0.02821209 0.02683218 0.04610043 0.08716293 0.03653716
  0.02177776 0.02266316 0.0284119  0.04936664 0.03640212 0.03061575
  0.02519326 0.06844236 0.08743591 0.03014027 0.03703662 0.03443964
  0.02981476 0.02560703 0.02230514 0.02778908 0.02862184 0.00573451
  0.0073274  0.02296595]
 [0.02811263 0.02550316 0.02379936 0.03800083 0.08565206 0.02494319
  0.01782039 0.02164159 0.02445192 0.04374721 0.03506219 0.03208804
  0.02433877 0.03057901 0.04140323 0.02528596 0.05579332 0.05262453
  0.04186904 0.03224034 0.0365476  0.02498848 0.026542   0.01171852
  0.01462255 0.02693308]
 [0.02835953 0.03146563 0.02755192 0.03837179 0.05236511 0.02936981
  0.02367092 0.02364924 0.02950772 0.03979019 0.03376773 0.02771772
  0.02631591 0.03005572 0.0332452  0.02203722 0.03758638 0.03459154
  0.03214116 0.03065688 0.02699388 0.04398075 0.03804926 0.00890169
  0.01171805 0.02588551]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '4', ' and', ' ', '5', '.', ' The', ' information', ' about', ' Julie', "'s", ' location', ' was', ' provided', ' in', ' context', ' sentence', ' ', '2', ',', ' which', ' is', ' not', ' part', ' of', ' the', ' current', ' context', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 32), x_tokens=32, y_tokens=50, max_supp_attn=0.0, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 32)
DEBUG result.interpretability.attn_scores 1600 
 [[0.01849029 0.01962795 0.0204664  ... 0.04332596 0.01135571 0.0101416 ]
 [0.01909912 0.01738789 0.01738097 ... 0.04854272 0.01781653 0.01370565]
 [0.0194003  0.01773816 0.01983297 ... 0.04645942 0.02375791 0.01687181]
 ...
 [0.01973782 0.02022572 0.01561763 ... 0.00919651 0.01073332 0.01342932]
 [0.02000503 0.0203736  0.01603296 ... 0.00894514 0.01082925 0.01381943]
 [0.02011286 0.01773189 0.01442403 ... 0.00967302 0.0118927  0.01398834]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03031511 0.03775948 0.04550852 ... 0.02335751 0.01428315 0.04378464]
 [0.0308082  0.03240208 0.04197849 ... 0.02408634 0.02818763 0.04410248]
 [0.03162911 0.0391373  0.05165398 ... 0.01753073 0.01390448 0.0344804 ]
 ...
 [0.03179971 0.04068512 0.03865384 ... 0.01772263 0.01490179 0.04166828]
 [0.03196029 0.03313752 0.02959931 ... 0.02137842 0.02877975 0.03000271]
 [0.03203089 0.03670196 0.03229016 ... 0.02189985 0.02120645 0.03777045]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' bedroom', ',', ' which', ' means', ' Bill', ' is', ' definitely', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 44), x_tokens=44, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 44)
DEBUG result.interpretability.attn_scores 1452 
 [[0.02823092 0.03985354 0.03845363 ... 0.01302822 0.02935251 0.01751152]
 [0.0284392  0.0362976  0.03656708 ... 0.04866923 0.05084474 0.05718982]
 [0.02943084 0.04162781 0.04534702 ... 0.01928812 0.04171347 0.02490447]
 ...
 [0.02963199 0.04430309 0.04531108 ... 0.0123476  0.01765124 0.01521145]
 [0.02988159 0.03753719 0.03535131 ... 0.01342307 0.01475776 0.01540269]
 [0.03015257 0.036305   0.03488616 ... 0.01262706 0.01598036 0.01541303]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '13', ' and', ' ', '14', '.', ' The', ' information', ' about', ' Bill', "'s", ' location', ' was', ' provided', ' in', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ',', ' which', ' mentioned', ' Bill', "'s", ' possible', ' location', ' as', ' the', ' bedroom', ',', ' but', ' did', ' not', ' mention', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 50), x_tokens=50, y_tokens=61, max_supp_attn=0.082, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 50)
DEBUG result.interpretability.attn_scores 3050 
 [[0.01512271 0.01790419 0.02021008 ... 0.01816723 0.01119567 0.01009953]
 [0.01548164 0.01696379 0.01825801 ... 0.0148301  0.0141005  0.01469996]
 [0.0157963  0.02025346 0.02366342 ... 0.01746815 0.00969806 0.00900513]
 ...
 [0.01646823 0.01634297 0.0149699  ... 0.0112076  0.0087949  0.00864935]
 [0.01654037 0.01898433 0.01819886 ... 0.01336612 0.00847853 0.00843392]
 [0.01646747 0.01685612 0.01596429 ... 0.01573117 0.00917946 0.00878108]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(24, 26), x_tokens=26, y_tokens=24, max_supp_attn=0.0417, attn_on_target=0.0417)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (24, 26)
DEBUG result.interpretability.attn_scores 624 
 [[0.03895556 0.06149304 0.0772174  0.08977578 0.09754065 0.09433021
  0.06846622 0.09039123 0.07404733 0.08038521 0.06538425 0.08137023
  0.08670861 0.09860178 0.05905648 0.04256533 0.04147933 0.04446413
  0.03862557 0.03938386 0.03424924 0.05194941 0.04495267 0.02504966
  0.03247728 0.04429335]
 [0.03862939 0.09889033 0.08266397 0.08063008 0.06350289 0.08445556
  0.23507428 0.15823509 0.1012423  0.0855283  0.09449965 0.08458823
  0.1220389  0.04665956 0.03344654 0.05272844 0.0461965  0.06349815
  0.04708919 0.05328567 0.04327963 0.06083946 0.04428289 0.03215482
  0.03971991 0.04462447]
 [0.04255449 0.06945867 0.04366913 0.06425477 0.04438408 0.04350891
  0.03426137 0.02771462 0.0274414  0.04121581 0.03654331 0.02100272
  0.02386555 0.03524495 0.04538374 0.03092106 0.01958117 0.01895637
  0.02200717 0.02157325 0.02028092 0.0569004  0.05452359 0.00958536
  0.01215561 0.02288698]
 [0.04013273 0.03658282 0.04304848 0.02825688 0.01960991 0.03345551
  0.03016537 0.02966755 0.03816016 0.03117146 0.03206827 0.03278446
  0.03062239 0.01535513 0.01454608 0.04217776 0.03878819 0.0412367
  0.04618498 0.04923207 0.05038084 0.04188829 0.06754605 0.07723821
  0.0752099  0.06548011]
 [0.04053978 0.04912928 0.05408753 0.07685547 0.06737704 0.0561167
  0.03680437 0.03539914 0.04127239 0.05427058 0.04482617 0.03264711
  0.03253366 0.11467734 0.11772849 0.04746662 0.03702666 0.02869043
  0.02871035 0.02907713 0.02792751 0.04972284 0.06318938 0.01668939
  0.01621142 0.04778473]
 [0.04139154 0.03230167 0.03329906 0.05912819 0.05096313 0.0507752
  0.02733877 0.02799883 0.03504793 0.05047372 0.04052306 0.03691579
  0.03519408 0.12382235 0.14397243 0.04635112 0.04125791 0.03447932
  0.0323772  0.03108497 0.02703472 0.04284222 0.03807588 0.01166108
  0.01402251 0.0316935 ]
 [0.04202273 0.03581064 0.04246005 0.06226039 0.05501921 0.06349879
  0.03540415 0.03777704 0.04594074 0.05973671 0.04703924 0.05790842
  0.05333016 0.09936067 0.09117561 0.03883604 0.03718579 0.03401718
  0.0307161  0.03014449 0.0251707  0.03841086 0.03576608 0.01595359
  0.01820209 0.02954548]
 [0.04065695 0.04924088 0.05866423 0.05071601 0.05002799 0.06119512
  0.0415942  0.05164788 0.05221346 0.05432132 0.04830273 0.06579007
  0.05647166 0.06118274 0.05347839 0.05189781 0.04760905 0.04306262
  0.03856745 0.03831857 0.03521466 0.04403929 0.05352206 0.03675951
  0.04229093 0.04934942]
 [0.04228548 0.04703595 0.0580919  0.05552777 0.04733581 0.06761707
  0.0454202  0.05488789 0.06094356 0.0591008  0.04726323 0.06517161
  0.05865391 0.04495144 0.02903203 0.03669235 0.03672248 0.03568832
  0.03325506 0.03349617 0.02846044 0.04384015 0.03853783 0.02075039
  0.0282145  0.0383194 ]
 [0.04130843 0.06112586 0.065986   0.03458999 0.02686455 0.04612401
  0.0479454  0.05245721 0.05950117 0.03794662 0.03907817 0.04989253
  0.04947429 0.02073907 0.01756358 0.05825287 0.04755146 0.04243007
  0.04219646 0.04295412 0.04204027 0.04331696 0.07323478 0.04982917
  0.05748082 0.04873864]
 [0.0419123  0.08128425 0.08061061 0.03253169 0.02582509 0.03901962
  0.04962818 0.04918472 0.06051619 0.03283397 0.03557322 0.03980865
  0.03983099 0.0171094  0.01667154 0.06649141 0.04983646 0.04175169
  0.04318514 0.04646025 0.0402659  0.04054275 0.0755934  0.04127566
  0.04831019 0.04500535]
 [0.0421437  0.04410925 0.04954778 0.02508474 0.02103361 0.02890438
  0.03897794 0.03830215 0.0476778  0.02699745 0.02932835 0.03223972
  0.0310484  0.01477251 0.01492676 0.05457151 0.04379461 0.0361785
  0.04049752 0.04229909 0.04042114 0.03917809 0.06348734 0.05903405
  0.06458273 0.05232095]
 [0.04240599 0.01957611 0.02099314 0.01386476 0.01243798 0.01680139
  0.01783132 0.0200301  0.02454975 0.01651677 0.0194476  0.01906898
  0.01919967 0.0077516  0.00873125 0.02756189 0.02758335 0.02756393
  0.03526891 0.04009957 0.04334853 0.03089836 0.04692319 0.08344433
  0.08763463 0.05800839]
 [0.04244595 0.02712685 0.02871478 0.01914315 0.01745083 0.02515375
  0.02559216 0.02782695 0.03060016 0.0229858  0.02897186 0.02989005
  0.02902845 0.01123129 0.01194501 0.04530786 0.0352246  0.03404468
  0.03531284 0.03548539 0.03834502 0.03572333 0.03443029 0.06968129
  0.06995897 0.05402632]
 [0.04270381 0.03090131 0.03129782 0.02505118 0.02058449 0.03240205
  0.0330265  0.03820877 0.03334878 0.03138118 0.03813805 0.04347206
  0.04363035 0.01470586 0.01252479 0.04283719 0.0374904  0.03929754
  0.03835255 0.03676374 0.03990024 0.03887471 0.02508846 0.05517679
  0.0449205  0.03250844]
 [0.04197218 0.02447734 0.0205222  0.01725904 0.01320135 0.01922986
  0.0277333  0.03205899 0.02359506 0.0201056  0.0313332  0.02595427
  0.032993   0.00843805 0.00845828 0.04431357 0.03708937 0.05402132
  0.05756194 0.05678008 0.07005702 0.03402485 0.0193215  0.0876453
  0.07446622 0.03901939]
 [0.04278815 0.02503532 0.02203071 0.01840325 0.01500038 0.02221148
  0.02560158 0.03055944 0.02522011 0.02280315 0.03594549 0.03359225
  0.03425801 0.00977698 0.00901936 0.03749834 0.03795457 0.04051842
  0.04624107 0.03982997 0.05286661 0.03410953 0.0188489  0.0709075
  0.05166084 0.02751071]
 [0.04280014 0.01926922 0.01706267 0.01295866 0.01150029 0.01621676
  0.02209894 0.02424589 0.02167016 0.01676031 0.03973437 0.02689708
  0.02766926 0.00707732 0.00717894 0.03885762 0.04228693 0.04543263
  0.05539806 0.04671124 0.05780786 0.02995021 0.01650593 0.07494862
  0.05063777 0.03067697]
 [0.04110814 0.03113891 0.02581715 0.01878199 0.01868114 0.02184046
  0.0308728  0.03034831 0.03553906 0.02312449 0.03270238 0.02498196
  0.02899078 0.01040383 0.01108161 0.0330894  0.04000193 0.0544263
  0.07424252 0.11063804 0.08156571 0.03941368 0.03873439 0.07468522
  0.06550513 0.07414766]
 [0.04353942 0.02483643 0.02481084 0.02077317 0.01582356 0.02374276
  0.02330242 0.02973522 0.02945936 0.02468213 0.03293426 0.03429374
  0.03100638 0.0117152  0.01004658 0.02835795 0.03042381 0.03314359
  0.04100166 0.03541782 0.03784654 0.03275198 0.01713439 0.02999656
  0.03432826 0.03486062]
 [0.04232656 0.0312541  0.03139921 0.04867209 0.04749994 0.04387768
  0.02658843 0.02990846 0.03543739 0.05213622 0.04129913 0.04133888
  0.03732416 0.07643212 0.09193437 0.03188728 0.03907104 0.03574494
  0.03280633 0.02964253 0.02865386 0.03889849 0.03115151 0.01249031
  0.01598852 0.03365193]
 [0.04201312 0.03329253 0.03022803 0.05392332 0.09599481 0.04305582
  0.02536716 0.02734921 0.03316956 0.05778839 0.04775853 0.03986762
  0.03199027 0.07857223 0.1030683  0.03833684 0.05198707 0.04891297
  0.03852083 0.03270255 0.03515697 0.03674261 0.03059816 0.01010279
  0.01282841 0.02870996]
 [0.04144134 0.03031364 0.02709446 0.04550633 0.09638032 0.03086964
  0.02204557 0.02679702 0.02924739 0.05126354 0.04668275 0.04320123
  0.03129619 0.03629354 0.04863206 0.03381253 0.08125643 0.07243628
  0.0575714  0.04085388 0.05770285 0.0344049  0.02854251 0.01917072
  0.02457726 0.03441798]
 [0.04192214 0.03631553 0.03068286 0.04605127 0.06596097 0.03559728
  0.02885933 0.02926831 0.03415872 0.04647053 0.04462269 0.0373224
  0.03284086 0.0351251  0.04039773 0.02918721 0.05260098 0.05000388
  0.04430966 0.03776559 0.04202284 0.06073656 0.04000884 0.01576973
  0.01861553 0.03241922]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 32), x_tokens=32, y_tokens=33, max_supp_attn=0.0, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 32)
DEBUG result.interpretability.attn_scores 1056 
 [[0.02836386 0.04594205 0.04649948 ... 0.01158139 0.0738909  0.07847859]
 [0.02907265 0.04357203 0.04223108 ... 0.01618855 0.07905162 0.05493345]
 [0.0295979  0.04283068 0.04629791 ... 0.03005235 0.05143896 0.04641489]
 ...
 [0.02960925 0.03684695 0.03514457 ... 0.00728152 0.11789272 0.04702616]
 [0.0298997  0.02853757 0.02506194 ... 0.00990279 0.0708832  0.02943798]
 [0.03008573 0.02841878 0.02582897 ... 0.00791741 0.10052796 0.04367135]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '7', ' and', ' ', '8', '.', ' The', ' previous', ' information', ' about', ' Julie', "'s", ' location', ' is', ' in', ' context', ' sentence', ' ', '4', ',', ' which', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' office', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(62, 38), x_tokens=38, y_tokens=62, max_supp_attn=0.0161, attn_on_target=0.0161)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (62, 38)
DEBUG result.interpretability.attn_scores 2356 
 [[0.01481645 0.02148553 0.02007316 ... 0.00726788 0.01589571 0.01321193]
 [0.01507214 0.02165867 0.02113975 ... 0.01605275 0.02579375 0.01637774]
 [0.01549723 0.02151841 0.02196477 ... 0.00536334 0.01123161 0.00808999]
 ...
 [0.01610909 0.01482874 0.01308356 ... 0.00930949 0.01233589 0.01457903]
 [0.01610314 0.01760411 0.01691497 ... 0.00833294 0.01385912 0.01320106]
 [0.01623525 0.01542853 0.01531244 ... 0.00693382 0.01114563 0.01182661]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' has', ' moved', ' from', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 44), x_tokens=44, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 44)
DEBUG result.interpretability.attn_scores 1540 
 [[0.02658284 0.03299293 0.03291262 ... 0.01203784 0.02933419 0.05070005]
 [0.02695898 0.0331403  0.03258908 ... 0.01844448 0.02267478 0.02822747]
 [0.02773415 0.03742381 0.04047577 ... 0.01570991 0.03491472 0.043576  ]
 ...
 [0.02785741 0.03983789 0.03964691 ... 0.01098955 0.05110903 0.06965379]
 [0.02830499 0.0310402  0.02882168 ... 0.015514   0.03131497 0.05420609]
 [0.02821933 0.03252197 0.03129993 ... 0.01430468 0.02360552 0.10071552]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Julie', ' went', ' back', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03029026 0.03667025 0.04477364 ... 0.01787048 0.03283876 0.0368283 ]
 [0.03077517 0.03267435 0.03889597 ... 0.02253327 0.02607044 0.03504489]
 [0.03158344 0.04156008 0.05182183 ... 0.01375647 0.03380112 0.02422364]
 ...
 [0.0317086  0.04480907 0.04606486 ... 0.01550722 0.04371662 0.03243115]
 [0.03222045 0.03185977 0.03130124 ... 0.0215207  0.04374551 0.04140187]
 [0.03194867 0.03767389 0.03661869 ... 0.02025144 0.03852334 0.04868316]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '1', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' school', ',', ' and', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' is', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 26), x_tokens=26, y_tokens=58, max_supp_attn=0.1552, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 26)
DEBUG result.interpretability.attn_scores 1508 
 [[0.0158616  0.02801058 0.03134907 ... 0.01001354 0.00706438 0.01378655]
 [0.01600761 0.0382675  0.03379141 ... 0.0087845  0.00508103 0.01261134]
 [0.01724673 0.0401168  0.02397683 ... 0.00538905 0.00312942 0.00661669]
 ...
 [0.01692927 0.01824876 0.01872174 ... 0.00545355 0.00270357 0.00932682]
 [0.01680109 0.01417534 0.01475673 ... 0.00787146 0.00507131 0.01179196]
 [0.01700133 0.0167572  0.01671901 ... 0.00666748 0.00412974 0.00955549]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 32), x_tokens=32, y_tokens=19, max_supp_attn=0.0526, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 32)
DEBUG result.interpretability.attn_scores 608 
 [[0.04982452 0.07442994 0.07317062 0.09197557 0.0794056  0.0834919
  0.05999858 0.0553713  0.06509479 0.07388183 0.05373236 0.05260189
  0.05751599 0.12667729 0.12996227 0.05532591 0.03580695 0.03784093
  0.03763999 0.0403351  0.03842298 0.05317432 0.08787057 0.04591719
  0.02787529 0.05794298 0.06297124 0.0704935  0.1676504  0.10291111
  0.02440374 0.0167893 ]
 [0.05119272 0.06725129 0.0687779  0.10579468 0.09455229 0.11302772
  0.06197223 0.05996673 0.07681017 0.09754127 0.0695185  0.07233621
  0.07631171 0.17679495 0.15364127 0.05752401 0.03537653 0.04395009
  0.04004616 0.0428252  0.03953318 0.05683905 0.06252407 0.03859052
  0.02745659 0.0533333  0.0666112  0.05819619 0.12525652 0.11982603
  0.03529314 0.02379409]
 [0.05214306 0.06507303 0.07592943 0.08866939 0.07280841 0.09167565
  0.06401697 0.06525134 0.07039955 0.07856995 0.05806065 0.07047318
  0.07273584 0.12020025 0.09200921 0.04894869 0.03279811 0.03699244
  0.03536719 0.03864463 0.03447275 0.05430238 0.05980815 0.04448699
  0.03306881 0.05083341 0.05730331 0.04989488 0.08668111 0.10922908
  0.05115517 0.04146181]
 [0.05020586 0.07203079 0.0787909  0.05758897 0.0447201  0.0628966
  0.06480832 0.06975254 0.06285626 0.05445741 0.05045982 0.06207398
  0.06356706 0.04045195 0.03603825 0.05990927 0.04290802 0.04318788
  0.04266873 0.04601233 0.04171945 0.06007732 0.08210061 0.07733543
  0.05941349 0.07021853 0.07134315 0.06272022 0.05902768 0.11867455
  0.09051349 0.11327562]
 [0.05183797 0.06431639 0.07157949 0.04142775 0.02763465 0.04678722
  0.06271383 0.05505094 0.05818821 0.03729538 0.04114768 0.04243436
  0.04611773 0.02470533 0.02460578 0.06081289 0.0411676  0.03751496
  0.04440667 0.04750086 0.04132379 0.05128491 0.06860711 0.07153124
  0.06143489 0.0564195  0.06213925 0.038209   0.03666257 0.05876457
  0.05729764 0.14948136]
 [0.05323073 0.02782634 0.03040257 0.02240393 0.01439963 0.02504014
  0.02954556 0.02846098 0.0318822  0.0214433  0.02852351 0.02502307
  0.02812831 0.0127442  0.01296382 0.03592056 0.03007703 0.02847681
  0.0356666  0.03749973 0.03376035 0.03638811 0.02998313 0.04465379
  0.04797278 0.0394004  0.03062763 0.02512265 0.02235431 0.02088827
  0.03287441 0.06610995]
 [0.05207909 0.05146768 0.0541348  0.03467936 0.02267603 0.04381878
  0.05221059 0.04946481 0.04581601 0.03497751 0.03925472 0.04579377
  0.04365021 0.02014596 0.01955783 0.05399054 0.04863958 0.04136243
  0.05046837 0.05215861 0.04784529 0.05888058 0.05851046 0.07601169
  0.07909229 0.06237954 0.06349124 0.03920105 0.03429748 0.06411585
  0.06906468 0.10784079]
 [0.05323013 0.06694582 0.07061712 0.05734944 0.03397229 0.06327792
  0.06723689 0.07279462 0.06138849 0.06169148 0.0606434  0.08905073
  0.07220598 0.03378341 0.02678459 0.05674937 0.04947514 0.0518291
  0.05217909 0.05494185 0.04925303 0.06014988 0.05410394 0.0621409
  0.06815068 0.0615347  0.07316312 0.05083738 0.03962691 0.06990377
  0.10236304 0.08916374]
 [0.05417766 0.04800173 0.05249234 0.03923053 0.02562818 0.04293489
  0.05517699 0.05152696 0.04550771 0.03898446 0.04719254 0.04978907
  0.04990862 0.02299229 0.02029043 0.05249238 0.04355691 0.03990033
  0.04650799 0.04889167 0.04510871 0.05442772 0.04148704 0.06237335
  0.06856661 0.0491345  0.05662732 0.04088064 0.03087369 0.04602101
  0.07397316 0.09259076]
 [0.05359729 0.03710805 0.03434832 0.02534045 0.01803565 0.02786974
  0.04050372 0.03845409 0.03611462 0.02641191 0.04113715 0.03524606
  0.03841822 0.01510652 0.01531414 0.05601562 0.05282962 0.04387435
  0.05425183 0.0523866  0.05195121 0.05126745 0.03074233 0.06148436
  0.06858048 0.04253276 0.03655556 0.03801083 0.02295355 0.02684271
  0.05866569 0.0561485 ]
 [0.05337228 0.0383182  0.03309295 0.0252399  0.017424   0.02679031
  0.04849311 0.04580623 0.03737798 0.02634409 0.04816404 0.0359266
  0.04694451 0.01470646 0.01416869 0.07030442 0.06074506 0.05792101
  0.06517487 0.0642378  0.07208307 0.04934117 0.02795597 0.06107623
  0.08517588 0.04331297 0.02878165 0.0388325  0.01990648 0.02011147
  0.06166531 0.04722165]
 [0.05414807 0.03510367 0.0325583  0.02489095 0.01944401 0.02748842
  0.04267877 0.04291222 0.03730761 0.02803934 0.05159454 0.04083786
  0.04280551 0.0155197  0.014418   0.05155573 0.07317254 0.05342159
  0.07317186 0.05970871 0.06043823 0.04822747 0.02517274 0.04432197
  0.09108479 0.04542968 0.03083563 0.03902221 0.0187599  0.01916154
  0.05804926 0.03526141]
 [0.05396487 0.03348701 0.03053731 0.02193373 0.01825909 0.0244574
  0.04378998 0.03982975 0.03669436 0.02443618 0.05667844 0.03549771
  0.0409907  0.01406636 0.0133779  0.05697822 0.07618546 0.05752121
  0.07145298 0.06316131 0.06174146 0.04950338 0.02575036 0.04901359
  0.07666329 0.05126045 0.03127762 0.04021122 0.01859904 0.01589493
  0.05436447 0.02721749]
 [0.05287829 0.04558143 0.04615776 0.02981769 0.02247516 0.04808958
  0.07200872 0.07420529 0.06112376 0.03402818 0.04969894 0.0510825
  0.0583786  0.01975902 0.01585624 0.04938437 0.05668218 0.05333818
  0.05651646 0.05986994 0.05015741 0.05230819 0.03969    0.05308948
  0.0525341  0.05725049 0.03918153 0.04213007 0.02931238 0.02934066
  0.05226771 0.03497612]
 [0.05452051 0.0388986  0.0402124  0.03203265 0.0219899  0.03542773
  0.04851206 0.05622469 0.04497489 0.03507306 0.04537329 0.04270225
  0.04717488 0.02197312 0.01686326 0.03685956 0.03761585 0.04095399
  0.04349211 0.04762789 0.04359005 0.05013124 0.03188662 0.03792511
  0.0391219  0.04555663 0.04763143 0.04174219 0.02931649 0.03293322
  0.06033621 0.03195717]
 [0.05276611 0.05030688 0.05291792 0.07181913 0.06027757 0.06628744
  0.04784154 0.0497421  0.060162   0.07657264 0.05448533 0.06272341
  0.0626123  0.0945807  0.1063978  0.04131316 0.03850929 0.04635176
  0.04226044 0.04776469 0.04314    0.05123718 0.05739591 0.03645055
  0.02773942 0.05432126 0.06572721 0.06677542 0.07732762 0.05400427
  0.04448679 0.02020277]
 [0.05226578 0.06508712 0.05715666 0.09531427 0.19586203 0.07410942
  0.04876795 0.05012707 0.06115057 0.10156671 0.07431541 0.07117403
  0.05518924 0.12175984 0.1575787  0.05762782 0.06731788 0.07943729
  0.05883146 0.0598504  0.06603722 0.05051968 0.07666094 0.03833323
  0.02228803 0.05593937 0.08023503 0.07243893 0.07524518 0.04392721
  0.01980119 0.01536107]
 [0.05197925 0.05596755 0.04701107 0.0642309  0.12308297 0.04200798
  0.0400417  0.04536742 0.04827235 0.07451369 0.06814419 0.05879575
  0.04664759 0.0459085  0.06945789 0.05571756 0.11104517 0.12891553
  0.08871535 0.07414772 0.10908657 0.0469539  0.06359792 0.05406187
  0.03744988 0.05502067 0.05257137 0.088122   0.04339194 0.02414067
  0.027935   0.01743841]
 [0.0525859  0.06279843 0.05011206 0.07026067 0.08735248 0.05452121
  0.04968251 0.04969095 0.05887853 0.07417157 0.06187554 0.05643754
  0.050697   0.0581241  0.06071386 0.04256989 0.06609104 0.07721011
  0.06118183 0.06243496 0.07033512 0.06498613 0.0761522  0.0412025
  0.02633082 0.04817887 0.04292548 0.09715919 0.06275674 0.02330904
  0.02548993 0.01370805]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Julie', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.1071, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.03330481 0.05058089 0.04835404 ... 0.01687308 0.06323384 0.06477048]
 [0.03390231 0.04696164 0.03952909 ... 0.0447437  0.02879008 0.03707346]
 [0.0347223  0.05311946 0.05220706 ... 0.02526536 0.06183473 0.04985534]
 ...
 [0.0349813  0.04684471 0.046918   ... 0.01229727 0.12197401 0.06044725]
 [0.03554516 0.03684508 0.03460644 ... 0.01775703 0.07827699 0.0374987 ]
 [0.03535623 0.0402531  0.0358026  ... 0.01252437 0.09670743 0.07175852]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.', ' The', ' sentences', ' only', ' mention', ' Mary', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ' and', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 44), x_tokens=44, y_tokens=37, max_supp_attn=0.0811, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 44)
DEBUG result.interpretability.attn_scores 1628 
 [[0.02502277 0.03024295 0.03292399 ... 0.02470635 0.02437186 0.04773317]
 [0.0257007  0.0266311  0.03144048 ... 0.01964314 0.01710863 0.02546821]
 [0.02619082 0.02805854 0.03335278 ... 0.02049121 0.02148076 0.03271728]
 ...
 [0.02670762 0.03179439 0.02643019 ... 0.0282969  0.03901212 0.02868516]
 [0.02707929 0.03672843 0.03134949 ... 0.02470635 0.03646689 0.03391046]
 [0.02719275 0.03198327 0.02821426 ... 0.02074678 0.02921401 0.03930806]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' he', ' is', ' in', ' the', ' park', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.0, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02317168 0.04144115 0.03851994 ... 0.04366235 0.04142543 0.01483591]
 [0.02369057 0.03585256 0.0336194  ... 0.01747061 0.03545856 0.01967686]
 [0.02414344 0.04167483 0.04200344 ... 0.03478946 0.03192824 0.01336826]
 ...
 [0.02435507 0.03627041 0.0291618  ... 0.09349648 0.03182066 0.01167515]
 [0.02491255 0.03059468 0.02237131 ... 0.08202442 0.02794369 0.01568893]
 [0.02469998 0.03220472 0.02225641 ... 0.08552039 0.03303396 0.01387231]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.08, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03740204 0.05964039 0.07365672 0.09387125 0.09582573 0.09148908
  0.06950484 0.08833607 0.07324226 0.08119318 0.05969826 0.07608856
  0.08604607 0.10418338 0.06101413 0.03924801 0.03264431 0.04029248
  0.03780831 0.04231515 0.03588435 0.04981244 0.04696597 0.0330282
  0.01845245 0.03282545]
 [0.03723582 0.09217786 0.07101254 0.06300788 0.04710904 0.06365583
  0.19166157 0.1293598  0.07639799 0.05970412 0.07751963 0.06134644
  0.10274367 0.02992131 0.0248314  0.05036132 0.04522761 0.06213394
  0.05123374 0.06235721 0.05504995 0.05821216 0.04670234 0.05255739
  0.03677629 0.03956435]
 [0.04081258 0.06611336 0.04133796 0.06156342 0.04413775 0.04153318
  0.03322997 0.0262805  0.0278151  0.04023936 0.03318608 0.01940104
  0.02294674 0.03543374 0.04489689 0.0301217  0.01508627 0.01675652
  0.02265683 0.02407692 0.02270443 0.05543687 0.05887895 0.01473855
  0.00664793 0.01555173]
 [0.03837105 0.04893785 0.05261129 0.02989775 0.02030334 0.03691863
  0.03429977 0.03191516 0.04181132 0.03190403 0.03189612 0.03326854
  0.03155458 0.01566291 0.01482043 0.04565734 0.04202188 0.04311191
  0.04808943 0.04720057 0.04179943 0.04327199 0.06716303 0.06648563
  0.07098727 0.06601318]
 [0.03885888 0.04705892 0.05110008 0.07593197 0.06631041 0.05437735
  0.03561581 0.03400826 0.04143025 0.05300064 0.04043565 0.03011654
  0.03131028 0.11569011 0.11767319 0.046337   0.028715   0.02589077
  0.02893303 0.03215989 0.0312345  0.04900059 0.06742934 0.0244622
  0.00958553 0.03311665]
 [0.03965202 0.03078582 0.03161848 0.05881084 0.04956959 0.04978475
  0.02693016 0.02678719 0.03547176 0.04960948 0.03602512 0.0341721
  0.03394276 0.12426132 0.1450244  0.0456275  0.03208417 0.03119728
  0.03281925 0.03463917 0.03021451 0.04227993 0.04131278 0.01750503
  0.00787137 0.02172141]
 [0.0402775  0.0343606  0.04057419 0.06155073 0.05411834 0.06258503
  0.03492468 0.03645817 0.04623673 0.05826682 0.04212479 0.05379741
  0.05116685 0.1001087  0.09073187 0.03800537 0.0291335  0.03068873
  0.0311415  0.03365867 0.02817779 0.03804008 0.03846668 0.02297914
  0.01103627 0.02097965]
 [0.03890194 0.04847313 0.05739801 0.05011075 0.04953688 0.05991789
  0.04127105 0.04965081 0.05248675 0.05382075 0.04481116 0.06250176
  0.05478071 0.0619357  0.05426779 0.05167337 0.04118521 0.04050331
  0.03795049 0.04084984 0.03696936 0.04302365 0.05510344 0.04308635
  0.03260568 0.03876182]
 [0.03924695 0.05687735 0.06612241 0.03869931 0.03112299 0.04867115
  0.0494518  0.05680026 0.05489613 0.04141335 0.04035161 0.05097385
  0.05270843 0.02872805 0.01996885 0.05098566 0.03860874 0.03804893
  0.03795325 0.03959541 0.03701534 0.03839347 0.06462628 0.05429146
  0.04401423 0.05113442]
 [0.040324   0.07539732 0.08232306 0.03382523 0.02364824 0.04295398
  0.04858272 0.0482899  0.05887198 0.03405578 0.03188071 0.0411829
  0.03984371 0.01883188 0.01527103 0.05805454 0.03645111 0.03457943
  0.03782005 0.04273226 0.03726848 0.03753284 0.07320897 0.0460407
  0.03039346 0.03648037]
 [0.04030158 0.04424007 0.05126063 0.02703735 0.02049078 0.03183121
  0.04052509 0.04051173 0.04563614 0.0289875  0.02874895 0.03415185
  0.03195893 0.01611804 0.01434865 0.05631431 0.04313039 0.03571462
  0.0404709  0.04280618 0.03887649 0.03724823 0.05624537 0.05885464
  0.05145409 0.04653941]
 [0.04066677 0.02318637 0.02754292 0.01785525 0.01484383 0.02245289
  0.02493541 0.02765468 0.04059258 0.0218748  0.02025704 0.02238665
  0.02202152 0.01124983 0.01072054 0.03718187 0.03495396 0.02975071
  0.03696289 0.04049732 0.03705993 0.03109085 0.0470386  0.06830534
  0.07274373 0.07190026]
 [0.04032604 0.03253485 0.03502279 0.02372032 0.01991589 0.03136164
  0.03136145 0.03376818 0.03387193 0.02704539 0.02962993 0.03536071
  0.03115444 0.01302471 0.01265837 0.04907878 0.04112782 0.03604307
  0.03946605 0.03895419 0.03665398 0.0374724  0.03479877 0.05610153
  0.07062853 0.05232215]
 [0.04108078 0.0428494  0.04694378 0.04092389 0.02964112 0.05331313
  0.04389485 0.05394711 0.0484951  0.05276584 0.04974411 0.08012749
  0.06076309 0.02359641 0.01620221 0.034766   0.03597153 0.038638
  0.03772412 0.0384616  0.03382719 0.03947849 0.02671376 0.02722387
  0.02575694 0.02367211]
 [0.04153426 0.03011795 0.031672   0.02555008 0.02162922 0.03112356
  0.03305512 0.03495135 0.03173123 0.03051034 0.03714281 0.03961883
  0.03654294 0.01382282 0.01225514 0.03545639 0.03916854 0.0329191
  0.03585796 0.03584847 0.03520993 0.03771657 0.02310839 0.03277611
  0.04664497 0.02810891]
 [0.04076945 0.02236242 0.02007121 0.016211   0.01417712 0.01885758
  0.02354799 0.02527772 0.02367418 0.01968614 0.03134708 0.02624761
  0.02789439 0.00839515 0.00907073 0.0370179  0.05277511 0.0383769
  0.04019139 0.03744996 0.04357836 0.03368483 0.01893407 0.04234134
  0.08535258 0.04994669]
 [0.04025137 0.02198838 0.01831961 0.01565287 0.01273047 0.0178131
  0.02467676 0.0278165  0.02251866 0.01840985 0.02993947 0.02274692
  0.02831839 0.00761856 0.00797031 0.03367794 0.05462868 0.04901481
  0.04776575 0.04424193 0.06327996 0.0314293  0.01743705 0.05203823
  0.10462855 0.05484781]
 [0.04103149 0.02184452 0.01913962 0.01573532 0.01393182 0.01979014
  0.02444293 0.02736021 0.0236373  0.02026978 0.04058832 0.03228033
  0.02974203 0.00811738 0.00806552 0.03305461 0.05552777 0.0415365
  0.04988727 0.04090353 0.04719012 0.03053109 0.014673   0.03484201
  0.08181597 0.04219317]
 [0.04089627 0.02003184 0.01731093 0.01314131 0.01224365 0.0167017
  0.02511544 0.02554698 0.02242382 0.01705808 0.05145286 0.02849894
  0.02827487 0.00701411 0.00728763 0.03492158 0.05491227 0.0445331
  0.05213645 0.04525356 0.05277449 0.03049724 0.01517201 0.04451215
  0.05749285 0.06542161]
 [0.03980422 0.02790246 0.02456312 0.01798209 0.01544639 0.02213143
  0.03590033 0.03443139 0.03436364 0.02123246 0.0364313  0.02532162
  0.03284905 0.00943257 0.00956299 0.03566495 0.03600543 0.04149648
  0.04681749 0.04840286 0.05958043 0.03657529 0.02992167 0.10248154
  0.06695767 0.07447979]
 [0.04171718 0.02431983 0.02439259 0.02168284 0.01603511 0.02502129
  0.02465814 0.02959524 0.02984341 0.02511333 0.03211042 0.03207704
  0.03038365 0.01198795 0.01056273 0.02493555 0.02890831 0.03492399
  0.03628861 0.03476913 0.03495354 0.03232334 0.01792395 0.02751609
  0.02451264 0.03920779]
 [0.04055186 0.03074397 0.02982697 0.04969533 0.04692915 0.04596013
  0.02659081 0.02885775 0.03526453 0.0522996  0.03845098 0.03930631
  0.03773914 0.08013183 0.09357493 0.03133282 0.02913015 0.03211626
  0.03225746 0.03238245 0.0309507  0.03901499 0.0346219  0.01798833
  0.00996006 0.02395758]
 [0.04029059 0.03175973 0.02862961 0.05268574 0.09524456 0.04200495
  0.02467366 0.02648079 0.03311154 0.05682449 0.04275506 0.03641475
  0.03072201 0.08029614 0.10371254 0.0375564  0.03989177 0.04643598
  0.03795739 0.03609904 0.0361844  0.03604585 0.03304148 0.01491998
  0.00735441 0.0201949 ]
 [0.03958033 0.02999588 0.02697145 0.04684604 0.11019783 0.03172588
  0.02213159 0.02649273 0.03030702 0.0548002  0.04801295 0.04369611
  0.03133977 0.03775831 0.05329066 0.03408131 0.06951963 0.08095635
  0.05618485 0.04372833 0.05194912 0.03329122 0.02957062 0.02470572
  0.0147782  0.02587675]
 [0.04011505 0.0362997  0.03057804 0.04801144 0.07486071 0.03802454
  0.02901803 0.02942148 0.03586864 0.04991472 0.04545964 0.03891566
  0.033252   0.03667916 0.04221711 0.02888778 0.04319081 0.05434084
  0.04362556 0.04061638 0.04161318 0.05859632 0.04094155 0.02021854
  0.01154843 0.025182  ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ' do', ' not', ' mention', ' the', ' kitchen', ' as', ' a', ' possible', ' location', ' for', ' Fred', '.', ' They', ' only', ' mention', ' the', ' bedroom', ',', ' park', ',', ' and', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.1842, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02451275 0.038253   0.03844829 ... 0.01171447 0.07315916 0.07638028]
 [0.02505313 0.04102827 0.03880829 ... 0.02201582 0.07683756 0.05114235]
 [0.02564066 0.03686112 0.03866474 ... 0.02341592 0.06301814 0.04584371]
 ...
 [0.02555088 0.03364006 0.03029837 ... 0.00804452 0.09526836 0.0531285 ]
 [0.02570225 0.02623973 0.02249948 ... 0.01159258 0.05497295 0.0320195 ]
 [0.02586628 0.02741962 0.02433874 ... 0.00932665 0.08128052 0.05199324]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '7', ' and', ' ', '8', '.', ' They', ' only', ' mention', ' Julie', ' and', ' Mary', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 38), x_tokens=38, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 38)
DEBUG result.interpretability.attn_scores 1368 
 [[0.02586485 0.02994183 0.02733562 ... 0.01756679 0.02677415 0.02186159]
 [0.0261467  0.03291307 0.03163765 ... 0.02823622 0.03240285 0.0312789 ]
 [0.02695807 0.03184507 0.03290751 ... 0.01386709 0.02302359 0.01669358]
 ...
 [0.02733531 0.02671445 0.02154051 ... 0.03398591 0.03982216 0.04600914]
 [0.02784281 0.029532   0.02637907 ... 0.02076219 0.02370336 0.03388231]
 [0.02801327 0.02508294 0.02316479 ... 0.01719931 0.02128615 0.03016956]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' she', ' left', ' the', ' cinema', ' afterwards', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02725824 0.03089627 0.03791538 ... 0.01254452 0.01493316 0.03138641]
 [0.0277144  0.02813559 0.03258007 ... 0.02108781 0.02294536 0.0240693 ]
 [0.02839144 0.03581118 0.04660944 ... 0.02124916 0.02652496 0.04042561]
 ...
 [0.0286562  0.04153173 0.03617064 ... 0.00951902 0.01030068 0.02040781]
 [0.02923214 0.03314923 0.02624602 ... 0.01244272 0.01127886 0.01582653]
 [0.02903508 0.03804299 0.03026711 ... 0.01117546 0.01161502 0.02006714]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' explicitly', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(22, 50), x_tokens=50, y_tokens=22, max_supp_attn=0.0909, attn_on_target=0.0455)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (22, 50)
DEBUG result.interpretability.attn_scores 1100 
 [[0.0432259  0.06193344 0.05728503 ... 0.02390695 0.01771461 0.04235483]
 [0.04373655 0.05015527 0.04396392 ... 0.04584995 0.04369588 0.05368297]
 [0.04491631 0.06791192 0.06894833 ... 0.02299444 0.01678276 0.03833204]
 ...
 [0.04519684 0.05497004 0.05763152 ... 0.02020795 0.0154744  0.06038241]
 [0.04577147 0.03903893 0.03985138 ... 0.03014458 0.02717432 0.05530396]
 [0.04550188 0.04580785 0.04507535 ... 0.02288866 0.01965361 0.05427327]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' cinema', '.', ' According', ' to', ' the', ' context', ' sentences', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 26), x_tokens=26, y_tokens=43, max_supp_attn=0.0, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 26)
DEBUG result.interpretability.attn_scores 1118 
 [[0.02165597 0.03669662 0.03919313 ... 0.01697742 0.00820582 0.02271649]
 [0.02235194 0.02294201 0.02303302 ... 0.01157197 0.00657153 0.01486104]
 [0.02272155 0.02589143 0.02956967 ... 0.01521108 0.00884424 0.01412928]
 ...
 [0.02277591 0.02412839 0.02317313 ... 0.0107221  0.00569047 0.01399616]
 [0.02268969 0.01943089 0.01948575 ... 0.01404194 0.00919556 0.01530155]
 [0.02284903 0.02214278 0.02124219 ... 0.01241188 0.00799736 0.01427509]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', "'s", ' locations', ',', ' which', ' are', ' the', ' park', ' and', ' the', ' school', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 32), x_tokens=32, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 32)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02091946 0.0315794  0.03404022 ... 0.00828678 0.01840975 0.00787619]
 [0.02158997 0.02937404 0.02980249 ... 0.01004404 0.02469328 0.01030898]
 [0.02205227 0.02690608 0.02985145 ... 0.01414611 0.02875681 0.01277794]
 ...
 [0.02218739 0.02902492 0.02280332 ... 0.00949733 0.01018675 0.00865796]
 [0.02258473 0.03042038 0.02504317 ... 0.01001188 0.01162447 0.00760158]
 [0.02271382 0.02676522 0.02313568 ... 0.00943559 0.01256769 0.00822607]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' provide', ' information', ' about', ' Bill', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ' and', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 38), x_tokens=38, y_tokens=37, max_supp_attn=0.1351, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 38)
DEBUG result.interpretability.attn_scores 1406 
 [[0.02517417 0.03445065 0.03580253 ... 0.06413224 0.03248287 0.01993742]
 [0.0256099  0.03052768 0.03141424 ... 0.03744771 0.02808687 0.02226101]
 [0.02631143 0.03710439 0.04071327 ... 0.04881565 0.02755397 0.01469617]
 ...
 [0.02683076 0.02804457 0.02412499 ... 0.03081071 0.0322267  0.02617189]
 [0.02704448 0.03127755 0.02822957 ... 0.03957615 0.03044287 0.0175003 ]
 [0.02695909 0.02882139 0.02575858 ... 0.0658071  0.02451267 0.01603114]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' was', ' that', ' he', ' was', ' in', ' the', ' cinema', ' and', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' update', ' or', ' change', ' to', ' that', ' information', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 44), x_tokens=44, y_tokens=50, max_supp_attn=0.0, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 44)
DEBUG result.interpretability.attn_scores 2200 
 [[0.018358   0.02218034 0.02313913 ... 0.0723988  0.06290985 0.00971385]
 [0.01861834 0.0219186  0.0223018  ... 0.0337632  0.04353061 0.0221594 ]
 [0.01924321 0.02420417 0.02627036 ... 0.0414399  0.07241371 0.01395027]
 ...
 [0.0193921  0.02686564 0.02622272 ... 0.03031419 0.02006211 0.00585477]
 [0.01986091 0.02268764 0.02108234 ... 0.02053508 0.01207529 0.00775135]
 [0.01984157 0.02299784 0.02017833 ... 0.02685809 0.01245791 0.00773171]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' the', ' context', ' sentence', ' ', '13', ',', ' Fred', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 50), x_tokens=50, y_tokens=21, max_supp_attn=0.0, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 50)
DEBUG result.interpretability.attn_scores 1050 
 [[0.04502434 0.04875353 0.05997151 ... 0.05570611 0.05736759 0.05817252]
 [0.04550035 0.04713888 0.04824244 ... 0.03299709 0.02822432 0.03345286]
 [0.04716107 0.05549113 0.06199946 ... 0.06988554 0.05678944 0.05747442]
 ...
 [0.04750516 0.05433975 0.05242992 ... 0.08245986 0.16159569 0.06836242]
 [0.04735674 0.04664311 0.0421457  ... 0.0333057  0.10950446 0.04435948]
 [0.04767942 0.0490109  0.04546369 ... 0.03728653 0.13575242 0.07936213]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' went', ' to', ' the', ' park', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' bedroom', '.', ' \n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 26), x_tokens=26, y_tokens=29, max_supp_attn=0.1724, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 26)
DEBUG result.interpretability.attn_scores 754 
 [[0.03240329 0.06313236 0.06810551 0.09608173 0.08308257 0.06767734
  0.05017006 0.04338962 0.0470308  0.06346978 0.04603268 0.0341279
  0.03620831 0.13730206 0.13841952 0.04686055 0.03627046 0.0274862
  0.02601551 0.02815425 0.02671244 0.04972337 0.08219158 0.00803948
  0.00939677 0.02966751]
 [0.03344003 0.03895764 0.0404019  0.06985939 0.05926231 0.05761965
  0.03561013 0.03155664 0.037815   0.05514369 0.03898795 0.03659033
  0.03624025 0.14300878 0.16415696 0.04450531 0.03899781 0.03187884
  0.02879377 0.0294363  0.0253225  0.0414386  0.04913555 0.00677937
  0.00753313 0.01936931]
 [0.03399242 0.04353802 0.05083472 0.07356387 0.0657749  0.07200418
  0.04686397 0.0436886  0.04901627 0.06475668 0.04551575 0.05775746
  0.05572664 0.11308239 0.10151292 0.03786894 0.03582171 0.03209793
  0.02798417 0.02934165 0.02389558 0.03734696 0.04460312 0.00948519
  0.01090753 0.01830542]
 [0.03281697 0.05051246 0.05737153 0.05375662 0.05497261 0.06218357
  0.05051299 0.05321689 0.05070875 0.05512929 0.045101   0.06027419
  0.05536656 0.0674337  0.05763212 0.04794661 0.04269834 0.03899065
  0.0334168  0.03575649 0.03289938 0.04130345 0.06008415 0.02565778
  0.03640532 0.03653944]
 [0.03409407 0.05807825 0.06521075 0.06448698 0.05726489 0.07770292
  0.06321224 0.06696846 0.06429951 0.06764543 0.04959862 0.06940217
  0.06867062 0.05388069 0.03333044 0.03561192 0.03501564 0.03492
  0.03078229 0.03441634 0.02748908 0.04301323 0.04737767 0.01873796
  0.01906742 0.02414202]
 [0.03334594 0.06657348 0.06814934 0.03736291 0.02869242 0.04525529
  0.05582444 0.05338966 0.05250859 0.03683206 0.03533335 0.04441054
  0.04610613 0.0214979  0.01803887 0.04995121 0.04040438 0.03484862
  0.03416264 0.03668408 0.03745212 0.04067655 0.08469144 0.03847497
  0.04660143 0.04452422]
 [0.03424485 0.05291181 0.06090345 0.0321694  0.02559222 0.0357792
  0.05876616 0.04437821 0.0510618  0.03091416 0.02959598 0.03270926
  0.03333203 0.01719049 0.01617946 0.05115079 0.03853448 0.03298709
  0.03392566 0.03743934 0.03573897 0.03505876 0.06977207 0.02812742
  0.04537464 0.04002181]
 [0.03475571 0.01827173 0.02121063 0.01454146 0.01185593 0.01803593
  0.0208841  0.01986487 0.02577294 0.01651179 0.01550502 0.01692028
  0.01689905 0.00777088 0.00764281 0.01993677 0.02037174 0.01955957
  0.02307845 0.02449413 0.02557792 0.02029083 0.04488165 0.03761553
  0.0707022  0.06822252]
 [0.03437314 0.03158155 0.03204238 0.0215836  0.0180838  0.02619198
  0.03202273 0.02816119 0.02934352 0.0222803  0.02608263 0.02554219
  0.02517362 0.011586   0.01168619 0.04052732 0.02846475 0.03048306
  0.02977841 0.03250501 0.03226373 0.03464096 0.03471723 0.03379487
  0.07033453 0.06236042]
 [0.03445005 0.0303469  0.03042195 0.02318466 0.01956091 0.0278837
  0.03434155 0.03390941 0.03069386 0.025745   0.03075607 0.03294231
  0.03452987 0.01268805 0.01109391 0.04029574 0.03179907 0.0345025
  0.03037809 0.0311159  0.03436945 0.03556015 0.02565236 0.03271974
  0.06413864 0.04394994]
 [0.03380501 0.02454882 0.02110275 0.01773094 0.01415977 0.01872496
  0.02599059 0.02520895 0.02290484 0.01885699 0.02570545 0.02239721
  0.02665168 0.00862715 0.00856426 0.04442595 0.02882165 0.04394012
  0.03739202 0.04644701 0.05267097 0.03192306 0.02019072 0.04445092
  0.10418215 0.06089668]
 [0.03490762 0.02309374 0.0212185  0.01782671 0.01525676 0.02039075
  0.02637505 0.02635078 0.02359092 0.02047325 0.02994461 0.02715766
  0.02773192 0.00880478 0.00852041 0.03734428 0.02718889 0.04389531
  0.03726331 0.0588243  0.048547   0.02660145 0.01712766 0.0328209
  0.07051649 0.0476404 ]
 [0.03462416 0.02054178 0.01774501 0.01409873 0.011973   0.01606761
  0.02160747 0.02113741 0.020721   0.01622202 0.02908656 0.02044989
  0.02207809 0.00704368 0.00744845 0.03451448 0.02818068 0.03719608
  0.04005    0.04960122 0.04405743 0.02741896 0.01722511 0.05042436
  0.05498174 0.07359552]
 [0.03397315 0.0272979  0.0242335  0.01832908 0.01578286 0.02259245
  0.03052508 0.03006324 0.02747816 0.02086202 0.02826157 0.02500143
  0.02832866 0.00925285 0.00940396 0.02860605 0.03438601 0.03180203
  0.03856552 0.03669061 0.03820565 0.03132759 0.02653782 0.08925965
  0.05785083 0.05390847]
 [0.0351184  0.02401787 0.0212421  0.01783575 0.01412363 0.02003018
  0.02471129 0.02442169 0.02394398 0.0198883  0.02884312 0.02425026
  0.02423567 0.00922457 0.00884172 0.02458285 0.02523766 0.02864517
  0.03723985 0.03590205 0.03495347 0.03050269 0.01780288 0.04556786
  0.03030978 0.05634021]
 [0.03541747 0.02739964 0.02973759 0.02430866 0.01890908 0.02988165
  0.03186332 0.03730636 0.03207514 0.02913951 0.03129856 0.03911008
  0.03600213 0.014497   0.01066458 0.02361356 0.02489573 0.02777323
  0.02882385 0.02753999 0.02707958 0.03487389 0.01901752 0.02858891
  0.02365994 0.02714702]
 [0.03563184 0.03143424 0.03157041 0.02649521 0.01980373 0.03148693
  0.0386175  0.04805761 0.03463023 0.03171689 0.04126907 0.04533894
  0.04356815 0.01473916 0.01094069 0.02569493 0.02742966 0.03051556
  0.03048034 0.02893693 0.02854657 0.03364168 0.01982778 0.03081358
  0.02063609 0.02276906]
 [0.0354119  0.03016356 0.02857114 0.02527002 0.02003209 0.02857644
  0.03479701 0.03905967 0.03204602 0.02982345 0.03597501 0.03852785
  0.04047263 0.01406125 0.01148073 0.03334808 0.02907456 0.03345382
  0.03077688 0.02976987 0.03161615 0.03447356 0.01871443 0.02718103
  0.02416173 0.01913164]
 [0.03528074 0.02542421 0.022558   0.01914768 0.01442137 0.02003265
  0.02997451 0.03041781 0.02673747 0.02123639 0.03124897 0.02624886
  0.03111928 0.00942251 0.00894215 0.04013831 0.03056408 0.03628131
  0.03469857 0.03152911 0.0398433  0.02910245 0.01636957 0.03737977
  0.03344806 0.02644983]
 [0.03523755 0.02413233 0.02173317 0.01886578 0.0154302  0.02055251
  0.02862957 0.03068974 0.02659916 0.02322882 0.03231289 0.02939309
  0.0304964  0.01003008 0.00913922 0.03219144 0.03534665 0.03675101
  0.04408958 0.03671999 0.04614966 0.02898373 0.01687905 0.04368428
  0.02672506 0.02928806]
 [0.03524734 0.02378684 0.02180284 0.01830016 0.01410051 0.02088098
  0.02618617 0.02858637 0.02659916 0.02159096 0.0281669  0.0286585
  0.02907351 0.01000036 0.00875402 0.02916258 0.03205279 0.03129542
  0.03410791 0.02960537 0.03619933 0.02893505 0.01597211 0.05380443
  0.02491394 0.02221825]
 [0.03531179 0.02095298 0.0194958  0.01357288 0.0112171  0.01618986
  0.02476621 0.02363442 0.02458457 0.01588544 0.03195374 0.02113092
  0.02443749 0.00760268 0.00682342 0.03285856 0.03773975 0.03044417
  0.03479721 0.03167206 0.04065423 0.0266526  0.01452498 0.06244147
  0.02674288 0.02402879]
 [0.03464219 0.02619785 0.02327045 0.01485951 0.01186749 0.01853974
  0.02901269 0.02699682 0.029662   0.01735592 0.03340687 0.02225316
  0.02721358 0.00851404 0.00747633 0.02947418 0.03628746 0.02560548
  0.03290794 0.03091093 0.03884554 0.0288231  0.01942035 0.09381101
  0.03284404 0.02859546]
 [0.03543924 0.02638331 0.02477065 0.01985063 0.01509488 0.02168609
  0.02619822 0.02836401 0.02956918 0.02309383 0.02985595 0.02759509
  0.02770143 0.01140982 0.00973989 0.02169092 0.0284688  0.02541494
  0.02949992 0.03030188 0.03112189 0.03103551 0.01854256 0.04597667
  0.02292461 0.02160725]
 [0.0349375  0.03036386 0.02977242 0.03136887 0.0254737  0.03398623
  0.0304581  0.03661375 0.0361298  0.03718663 0.03164568 0.04280864
  0.041126   0.02112668 0.01539065 0.02212222 0.03073443 0.03119055
  0.02959976 0.02940301 0.02719476 0.03690164 0.02777087 0.03054522
  0.02551327 0.02322093]
 [0.03471284 0.04233517 0.03830387 0.05352531 0.05539031 0.05155046
  0.03458401 0.03274354 0.03659387 0.04996373 0.03849957 0.03500502
  0.03487688 0.0860264  0.10042337 0.03278993 0.03210539 0.0263041
  0.02554995 0.02600531 0.02258577 0.0397697  0.04364936 0.00657977
  0.0081681  0.01785916]
 [0.03408341 0.04176501 0.03916129 0.06469298 0.12606917 0.04918699
  0.03127926 0.03203741 0.03816805 0.06587438 0.0469854  0.04198732
  0.03340898 0.09170701 0.11362978 0.03752188 0.05381855 0.04907913
  0.03965722 0.03374985 0.03177333 0.03452019 0.04222526 0.00668678
  0.00671222 0.01792495]
 [0.03409848 0.03405084 0.03171875 0.04604045 0.08735348 0.03102264
  0.02413795 0.02860891 0.03093044 0.04957857 0.04201893 0.03836721
  0.03067499 0.03357257 0.04206632 0.02920909 0.065169   0.06828126
  0.06891715 0.04361918 0.04248411 0.02997029 0.03226954 0.01728744
  0.01435391 0.02133796]
 [0.03420297 0.04220587 0.0373397  0.05128997 0.06939831 0.03828714
  0.03207765 0.03117803 0.03878499 0.04959477 0.04101211 0.0336422
  0.03254943 0.03889647 0.04205685 0.02605565 0.04411988 0.04437682
  0.04726723 0.04342791 0.03575014 0.05548988 0.0528255  0.01326363
  0.01089346 0.01893784]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' Sentence', ' ', '5', ' only', ' mentions', ' Fred', ' journey', 'ing', ' to', ' the', ' office', ',', ' which', ' does', ' not', ' imply', ' Fred', ' being', ' in', ' the', ' park', '.', ' \n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 32), x_tokens=32, y_tokens=41, max_supp_attn=0.1463, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 32)
DEBUG result.interpretability.attn_scores 1312 
 [[0.02248958 0.03449467 0.03679306 ... 0.01475636 0.01062575 0.04851754]
 [0.02308804 0.03425052 0.03324397 ... 0.01822921 0.01490939 0.06076119]
 [0.02352285 0.03333243 0.0352916  ... 0.02772437 0.01851074 0.05042884]
 ...
 [0.02357577 0.03028002 0.02779052 ... 0.00800887 0.00724172 0.05444827]
 [0.02408236 0.02503701 0.02172134 ... 0.01002184 0.01198264 0.02366557]
 [0.02418482 0.02953294 0.02591214 ... 0.00914205 0.01111868 0.0198968 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.', ' \n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(20, 38), x_tokens=38, y_tokens=20, max_supp_attn=0.1, attn_on_target=0.05)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (20, 38)
DEBUG result.interpretability.attn_scores 760 
 [[0.04695136 0.06200305 0.0615292  0.08136456 0.06631781 0.07476856
  0.05677566 0.06227866 0.06558879 0.07957369 0.0509673  0.05497921
  0.06578658 0.12754461 0.10968041 0.04470303 0.04144178 0.04274568
  0.03712672 0.04122323 0.03799766 0.05034041 0.07753302 0.02141072
  0.03492875 0.05691979 0.05940902 0.06507825 0.12708263 0.02353791
  0.01979282 0.06807442 0.0482543  0.08354694 0.05549569 0.03132576
  0.03389561 0.07129214]
 [0.04817813 0.05441743 0.05199518 0.04514559 0.03523538 0.04877594
  0.05012511 0.05822324 0.04505396 0.04277388 0.0407124  0.04240192
  0.05282508 0.0433686  0.05788724 0.04015362 0.03386582 0.03607585
  0.03725103 0.04186337 0.03810551 0.04673502 0.05517061 0.05319783
  0.06110133 0.04773445 0.04102298 0.05232764 0.08933228 0.07689562
  0.03445715 0.04105565 0.02676881 0.04106189 0.05482854 0.04164662
  0.04045643 0.05282455]
 [0.04908186 0.0665621  0.06909017 0.0939216  0.08319363 0.09789094
  0.06550861 0.06860302 0.06887653 0.08762287 0.05663496 0.07180839
  0.07623463 0.16793106 0.11044994 0.04776021 0.03403189 0.03714855
  0.031889   0.03591576 0.03247747 0.05158616 0.06373516 0.02037702
  0.03076802 0.04560708 0.05453603 0.04663619 0.12192291 0.04338714
  0.03318666 0.08174536 0.04376348 0.06285562 0.0475749  0.02784367
  0.03235766 0.06436502]
 [0.04776435 0.06215653 0.06218754 0.04725368 0.03733166 0.05301272
  0.05417841 0.05876163 0.05211664 0.04840366 0.04295395 0.04964076
  0.05035435 0.03706469 0.03345645 0.05020786 0.03881205 0.03925775
  0.03712948 0.03995592 0.03782834 0.05397969 0.06818097 0.04241125
  0.05558567 0.05638046 0.05819941 0.04768088 0.09147257 0.13122317
  0.06266563 0.04532677 0.02995348 0.03303717 0.07028715 0.05403427
  0.05383049 0.06444529]
 [0.04939547 0.06867235 0.06703335 0.04027347 0.02654138 0.04411213
  0.06121265 0.05219955 0.05715472 0.03774586 0.03811678 0.03903129
  0.03992929 0.02684824 0.02742221 0.05460984 0.03731648 0.03659355
  0.0383436  0.04235441 0.03880945 0.04665379 0.07310595 0.03852749
  0.06043233 0.04981855 0.0596855  0.03338291 0.04399974 0.13703112
  0.04894612 0.02525055 0.01523357 0.02879346 0.07806813 0.05400806
  0.04748938 0.05642741]
 [0.05050225 0.03531682 0.03398051 0.02247822 0.01519404 0.02368141
  0.03035709 0.0292165  0.03254177 0.02236091 0.02701056 0.02378926
  0.02580143 0.0135612  0.01640791 0.03604272 0.02886582 0.0293797
  0.0328766  0.03762712 0.03285786 0.03521719 0.03679777 0.04852813
  0.06777432 0.04280387 0.03224469 0.02721245 0.01923768 0.0588705
  0.02942529 0.01548107 0.00826252 0.01765418 0.04960373 0.0477328
  0.03582155 0.03334175]
 [0.04936205 0.05492073 0.05529688 0.03722268 0.02527411 0.04567795
  0.05263054 0.05218207 0.04953986 0.04047544 0.04041301 0.04634057
  0.04521903 0.02324878 0.0244446  0.05234553 0.04330251 0.04482307
  0.04720159 0.04811564 0.0439017  0.05640097 0.05496645 0.05646137
  0.06546813 0.05612744 0.0600311  0.0372371  0.04406704 0.08180882
  0.06814843 0.024663   0.01636361 0.02296527 0.07005008 0.06551957
  0.06917958 0.05599299]
 [0.05066413 0.06785985 0.06899441 0.05537183 0.03681947 0.06456614
  0.06833871 0.0722494  0.06235519 0.06233075 0.05781952 0.07981608
  0.07101718 0.0368825  0.03167725 0.05936809 0.0497877  0.0535319
  0.05043648 0.0522579  0.04676501 0.05573932 0.05709768 0.07001761
  0.06131021 0.05531177 0.0657681  0.0464534  0.04729484 0.0687559
  0.0808104  0.03355256 0.02257151 0.02775558 0.06490581 0.05254034
  0.06333164 0.05751818]
 [0.05165713 0.04828303 0.04904261 0.03701523 0.02706149 0.04211409
  0.05123353 0.04732955 0.04472915 0.03938051 0.04718192 0.04538887
  0.04701294 0.02250059 0.02295772 0.05340869 0.0459483  0.0426305
  0.04557032 0.04740744 0.0435306  0.05190454 0.04104775 0.05882576
  0.05611917 0.04476146 0.04828063 0.03681323 0.03624064 0.06546526
  0.07878477 0.0283503  0.01700935 0.02367686 0.05138332 0.05523241
  0.05517444 0.04549371]
 [0.05098189 0.03956892 0.03771511 0.02780185 0.02086771 0.03058137
  0.03926057 0.03740775 0.03815367 0.02955709 0.04322471 0.03518106
  0.03906848 0.01572795 0.01850013 0.05423276 0.05576241 0.04343009
  0.04953314 0.04913986 0.04668267 0.05008285 0.03163945 0.06230916
  0.0585665  0.04110597 0.04067738 0.03673129 0.02626038 0.04608577
  0.06157051 0.02491627 0.01243781 0.01949859 0.04695941 0.06277508
  0.0556419  0.03873895]
 [0.05078395 0.03839531 0.03442738 0.02692627 0.01970869 0.02884732
  0.04106094 0.03703367 0.03721895 0.02670654 0.04071761 0.03382322
  0.0410661  0.01447035 0.01573965 0.05584311 0.06210228 0.0516311
  0.06287467 0.05899312 0.05940809 0.04569255 0.02677906 0.07968517
  0.06200743 0.04114592 0.03673752 0.03761999 0.0175592  0.03712127
  0.0616063  0.02238265 0.00824051 0.01741545 0.04857184 0.09237103
  0.0779959  0.03280345]
 [0.05161524 0.03612481 0.03431167 0.02671271 0.02134294 0.03004045
  0.03815543 0.03689034 0.03741745 0.02881266 0.0451955  0.03964127
  0.03928533 0.01544318 0.01600972 0.04906909 0.0604331  0.04461358
  0.06331114 0.0521477  0.05005857 0.04510886 0.02425407 0.07563569
  0.04852032 0.03687119 0.03884569 0.03616561 0.01711095 0.03216592
  0.06815917 0.02728508 0.01076476 0.01739609 0.03149472 0.05087043
  0.05592005 0.03042122]
 [0.05155584 0.03267844 0.03141496 0.02260025 0.01904337 0.0253844
  0.03813247 0.03343624 0.0354614  0.02282928 0.04695542 0.03436725
  0.03745528 0.0129722  0.01367351 0.05392846 0.06364409 0.0480324
  0.06959447 0.05947119 0.05616208 0.04537254 0.02247074 0.09208465
  0.05107209 0.04206478 0.03134612 0.04009227 0.01456691 0.02779752
  0.04723006 0.0286464  0.00807174 0.01657113 0.03212997 0.06619353
  0.06622523 0.02836953]
 [0.04969532 0.044866   0.04107466 0.02667305 0.02319896 0.03485438
  0.07161152 0.05605569 0.05214551 0.02766499 0.06910538 0.04752756
  0.05953089 0.01595082 0.01752115 0.06020634 0.06834686 0.06525483
  0.0822951  0.0781     0.06410024 0.05157024 0.041579   0.10575248
  0.0769906  0.06597529 0.03614999 0.05169262 0.02035449 0.03117249
  0.04142159 0.02983639 0.00932652 0.02680526 0.05291064 0.08852387
  0.08875218 0.04106688]
 [0.05154881 0.03637534 0.04076544 0.03621592 0.02763704 0.03775309
  0.04033292 0.04317623 0.04182396 0.03570797 0.04523455 0.04602583
  0.04309656 0.02402527 0.02052791 0.03898083 0.0336856  0.03682498
  0.04426228 0.04608827 0.04082617 0.04772117 0.02874572 0.0412512
  0.04075774 0.04495122 0.03663383 0.04265595 0.03186888 0.02736237
  0.10429481 0.05818297 0.02387766 0.0257471  0.03163758 0.04423947
  0.04421481 0.0384273 ]
 [0.05046638 0.04308075 0.05115131 0.05090852 0.03624128 0.0552851
  0.050699   0.05818478 0.05819409 0.05287956 0.0471741  0.06179092
  0.05741499 0.03852746 0.02812883 0.03709549 0.03180223 0.03728236
  0.03338214 0.03802416 0.03312343 0.05249026 0.04173941 0.02995762
  0.03883545 0.04568032 0.04351132 0.04935113 0.05288218 0.04532931
  0.06635901 0.0735644  0.0348699  0.04109415 0.04395036 0.037616
  0.03810744 0.05035969]
 [0.05061998 0.05170457 0.05169793 0.07755717 0.07192813 0.07472456
  0.04940037 0.04702888 0.0546032  0.06925088 0.05784816 0.05659484
  0.05425429 0.12788068 0.13419175 0.04722155 0.0350217  0.04002992
  0.03402581 0.03897708 0.03633117 0.05102492 0.05776852 0.01546941
  0.02386921 0.04964876 0.05906342 0.0568121  0.06677129 0.01586538
  0.02302631 0.14380836 0.08729215 0.08622    0.03591863 0.02454129
  0.02599318 0.05438989]
 [0.04959446 0.05792022 0.05805194 0.10658543 0.23108138 0.08154688
  0.05103021 0.05158075 0.05812552 0.10163061 0.07751705 0.0756811
  0.05366618 0.1331357  0.17297122 0.06185542 0.07088885 0.0833646
  0.05700158 0.05500968 0.0708358  0.04936692 0.07281637 0.01895281
  0.02490233 0.06162732 0.08702264 0.07224771 0.05927484 0.01495629
  0.01852591 0.11789393 0.2707407  0.12808934 0.04260845 0.02707049
  0.03018631 0.0704115 ]
 [0.0497208  0.04923321 0.04818876 0.0666506  0.10389765 0.0483049
  0.03987709 0.04482288 0.04543289 0.07508538 0.06837121 0.06077778
  0.04826145 0.04635783 0.06978386 0.05641485 0.09804869 0.11398809
  0.08529519 0.07060149 0.11857612 0.04849425 0.0568456  0.04091484
  0.04327846 0.05470585 0.05965094 0.08073289 0.03267203 0.02009632
  0.0281047  0.06403795 0.24350226 0.09767176 0.04700805 0.04038857
  0.04717384 0.05456696]
 [0.04986064 0.04986064 0.05205105 0.07132136 0.07208389 0.05807769
  0.0500792  0.05333926 0.06346674 0.06920746 0.05684584 0.05539286
  0.05271994 0.05655836 0.05856854 0.04655246 0.06689187 0.0733615
  0.06059974 0.06672663 0.07162207 0.06451831 0.06772681 0.02822986
  0.03771199 0.06075839 0.05118369 0.10307641 0.04002848 0.01507182
  0.0234844  0.04594598 0.06269537 0.18214415 0.04461296 0.03552675
  0.03825235 0.05874353]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' (', 'from', ' previous', ' context', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', '.', ' \n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02573566 0.02701455 0.02888322 ... 0.01707582 0.01090565 0.01660332]
 [0.0260333  0.03467829 0.03553946 ... 0.03030682 0.0265701  0.02567055]
 [0.02674016 0.02880013 0.03182851 ... 0.02393974 0.01828838 0.02535663]
 ...
 [0.02709333 0.03089666 0.02466668 ... 0.00793001 0.00949831 0.01377703]
 [0.02773002 0.02337006 0.01867328 ... 0.01015664 0.01132268 0.01411424]
 [0.02750662 0.02593641 0.02001348 ... 0.00794772 0.00854249 0.01316134]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' only', ' mentions', ' Fred', ' moving', ' to', ' the', ' kitchen', ' and', ' then', ' journey', 'ing', ' to', ' the', ' cinema', ' (', 'sent', 'ences', ' ', '10', ' and', ' ', '11', '),', ' but', ' not', ' about', ' being', ' in', ' the', ' school', '.', ' \n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 50), x_tokens=50, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 50)
DEBUG result.interpretability.attn_scores 2650 
 [[0.01740921 0.02508768 0.02487317 ... 0.0251113  0.00946371 0.01304756]
 [0.01765856 0.02341551 0.02150398 ... 0.01587593 0.01099749 0.01176868]
 [0.01805497 0.02800596 0.02858043 ... 0.01962747 0.00810797 0.01027873]
 ...
 [0.01875589 0.02265707 0.01713787 ... 0.02143912 0.01125131 0.01345538]
 [0.01879428 0.0270101  0.02296703 ... 0.02472974 0.0109229  0.0110323 ]
 [0.01884699 0.02324611 0.02071822 ... 0.02328683 0.01053795 0.00956432]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' cinema', '.', ' In', ' fact', ',', ' sentence', ' ', '2', ' states', ' that', ' Bill', ' is', ' in', ' the', ' park', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 26), x_tokens=26, y_tokens=40, max_supp_attn=0.075, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 26)
DEBUG result.interpretability.attn_scores 1040 
 [[0.02313252 0.03795306 0.04431748 ... 0.0179236  0.01083871 0.01736704]
 [0.02362428 0.04248384 0.04416915 ... 0.01515913 0.0065838  0.0188236 ]
 [0.02410086 0.02633056 0.02659504 ... 0.01131356 0.00586923 0.01364839]
 ...
 [0.02452796 0.02794122 0.02615225 ... 0.01079578 0.00531885 0.01257939]
 [0.02448113 0.02189311 0.02120965 ... 0.01393458 0.00877147 0.01462912]
 [0.02460229 0.02678025 0.02448171 ... 0.01228042 0.00719418 0.01432069]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '4', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02332934 0.03748137 0.03950094 ... 0.0102406  0.01333396 0.00586568]
 [0.0240904  0.03556288 0.03521958 ... 0.0108283  0.01562118 0.00775128]
 [0.02446394 0.03434705 0.0374254  ... 0.01737425 0.02357913 0.01095099]
 ...
 [0.02439168 0.03404433 0.02853198 ... 0.00616224 0.00759089 0.00535655]
 [0.02476419 0.02812149 0.02339658 ... 0.00850592 0.00839517 0.00809361]
 [0.02484349 0.02783599 0.02239444 ... 0.00674283 0.00802104 0.00626202]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.04957327 0.07376296 0.06656519 0.08677184 0.06990305 0.07630324
  0.06107762 0.06122589 0.06918602 0.08000507 0.05526105 0.05599285
  0.06016463 0.13207527 0.11870225 0.05017141 0.03953225 0.04670531
  0.0356851  0.04594142 0.04046334 0.05143317 0.08762174 0.04358972
  0.02873935 0.06550924 0.06971104 0.06349488 0.14221951 0.02716318
  0.03291195 0.01397145 0.01921981 0.0587775  0.08582456 0.08327452
  0.04211066 0.03890909]
 [0.05049269 0.07456941 0.0690444  0.07708633 0.06417943 0.09188797
  0.12057549 0.12721412 0.09220049 0.07887229 0.06208029 0.10258388
  0.14912166 0.08052744 0.07068764 0.04606805 0.04140796 0.05603441
  0.0524543  0.06352245 0.04764022 0.05360514 0.06436989 0.05079047
  0.04343452 0.06774025 0.06454854 0.05754923 0.11280964 0.06580965
  0.07371201 0.04186767 0.06217951 0.05935648 0.05573376 0.07459878
  0.05181659 0.05696934]
 [0.05196038 0.07062981 0.06950352 0.09553131 0.08220604 0.09565748
  0.06364353 0.06203428 0.06946436 0.08284812 0.05906916 0.06697946
  0.06825164 0.16679123 0.11666159 0.04974007 0.03278237 0.03876698
  0.03116469 0.03978204 0.03378806 0.05216206 0.06473491 0.04018435
  0.02629431 0.0529039  0.0643753  0.0461035  0.11912445 0.04074535
  0.05448269 0.02219382 0.02199263 0.07085879 0.06320839 0.06332976
  0.03648664 0.03388352]
 [0.05051688 0.06624691 0.06650805 0.05280273 0.04029597 0.05657205
  0.05651706 0.06048269 0.06047428 0.05231076 0.04731651 0.05359691
  0.05150433 0.04045229 0.03696248 0.05139323 0.03828719 0.04116432
  0.03741466 0.04430951 0.03924735 0.05671407 0.07048121 0.06559861
  0.04564596 0.05983863 0.06416742 0.05026678 0.08065864 0.1011287
  0.1359323  0.0534213  0.03578076 0.04997712 0.03613874 0.07378464
  0.05930844 0.05747635]
 [0.05198766 0.06844337 0.06803435 0.04053037 0.02937906 0.04555969
  0.06235738 0.05128723 0.06077348 0.03663277 0.0414486  0.0410741
  0.03940134 0.02732984 0.02821053 0.05730353 0.03835886 0.037663
  0.03963371 0.0463062  0.04086107 0.04897705 0.07166807 0.07386947
  0.05568776 0.05196642 0.06499896 0.03685617 0.04004085 0.08171386
  0.12191386 0.085355   0.03866753 0.03529707 0.02789703 0.07529976
  0.07246076 0.07281489]
 [0.05339903 0.03571187 0.03487215 0.02099843 0.016825   0.02367694
  0.03073987 0.02777869 0.03489222 0.01970776 0.03018985 0.02541089
  0.02423495 0.01317067 0.01545454 0.03919568 0.02969505 0.02885876
  0.03304749 0.03742754 0.03216674 0.03613777 0.03163633 0.05686877
  0.05048309 0.03715293 0.03603354 0.02456365 0.0178739  0.03415745
  0.04811615 0.05299959 0.03752801 0.02094856 0.01510194 0.03873906
  0.05808296 0.05886925]
 [0.05193284 0.0584178  0.05871539 0.03757917 0.02857202 0.04803435
  0.05269692 0.05240855 0.05352297 0.04039599 0.04363468 0.04810776
  0.04231127 0.02416977 0.02471133 0.05337364 0.04268359 0.04471214
  0.05009336 0.05078131 0.04667249 0.05883643 0.05673949 0.07195038
  0.07061652 0.05670608 0.06988428 0.04166893 0.04149783 0.10557545
  0.06645846 0.12323187 0.04926501 0.0417175  0.02341432 0.06360322
  0.0768274  0.0741075 ]
 [0.05333661 0.07017399 0.07060335 0.05661317 0.04000134 0.06370475
  0.06642327 0.07002366 0.06468751 0.06425726 0.06354235 0.07956893
  0.06557913 0.0371734  0.03186513 0.06024414 0.05193122 0.05404235
  0.05455134 0.05596155 0.05022927 0.05912606 0.05702145 0.06186982
  0.06506924 0.05996603 0.07525466 0.05442677 0.04438502 0.10844481
  0.0778622  0.10494567 0.05059445 0.05318255 0.03107649 0.06193252
  0.06613061 0.05625061]
 [0.05423506 0.05080658 0.05362842 0.03988669 0.03182838 0.04376795
  0.05242246 0.04913261 0.04732664 0.04011359 0.05041182 0.04886058
  0.04551364 0.02456241 0.02423883 0.05220902 0.04439686 0.04174787
  0.04846738 0.04836224 0.04509551 0.05490151 0.042106   0.05767969
  0.06203552 0.04774939 0.05287229 0.04564476 0.03567842 0.07271819
  0.0638206  0.11127552 0.05086033 0.0481685  0.027064   0.04454175
  0.05754994 0.05625339]
 [0.05346213 0.04046043 0.03947347 0.02840678 0.02263062 0.03084391
  0.04084075 0.03885821 0.03781817 0.02944265 0.04541947 0.0373545
  0.03890911 0.01558679 0.01880465 0.05600576 0.05755357 0.04504102
  0.05650223 0.05163305 0.04971121 0.0554135  0.03133688 0.06011482
  0.07334188 0.04186973 0.03752339 0.04195174 0.02524767 0.05361459
  0.04174498 0.07534517 0.05549436 0.0355235  0.01890146 0.03302596
  0.05285073 0.05800565]
 [0.05328236 0.0402776  0.03703712 0.02790581 0.02121124 0.03021239
  0.04346092 0.04055649 0.03736588 0.02844632 0.04532125 0.03625444
  0.04169743 0.01464652 0.01716864 0.06242803 0.07216556 0.05481415
  0.0741199  0.06169855 0.06295283 0.05224403 0.02721896 0.06021469
  0.08946048 0.04298033 0.03357356 0.03910881 0.01805526 0.04963296
  0.02684069 0.06023119 0.06179967 0.03147443 0.01621767 0.02951166
  0.06582993 0.06970596]
 [0.0541555  0.03564926 0.03597402 0.02714675 0.02175439 0.03037639
  0.03800676 0.03914832 0.03654481 0.02892862 0.04724073 0.04095466
  0.03886278 0.015003   0.01699747 0.05560442 0.06955696 0.04715266
  0.07361196 0.05489163 0.05792167 0.05039868 0.02454581 0.04701887
  0.10157666 0.04143529 0.03967154 0.04305175 0.0179518  0.04789702
  0.03152469 0.06700169 0.07292894 0.04188757 0.01671146 0.02749518
  0.05210132 0.05137269]
 [0.0540323  0.03118621 0.03293367 0.022975   0.01906424 0.02702789
  0.03699189 0.03373405 0.03386935 0.02415954 0.04917145 0.03478354
  0.03623081 0.01254211 0.0146318  0.05881697 0.06648493 0.04551162
  0.06951863 0.05537859 0.0545169  0.05060844 0.0222486  0.05068345
  0.07901687 0.045244   0.03603354 0.04155383 0.01543464 0.04014047
  0.02763622 0.04835071 0.10886163 0.04575415 0.01487578 0.02328619
  0.05014692 0.049236  ]
 [0.05310014 0.03638558 0.04027947 0.02520358 0.02027353 0.0358789
  0.05097035 0.0519685  0.04168696 0.02618394 0.05130421 0.03854205
  0.05014926 0.01515799 0.01534332 0.05138573 0.05319635 0.0527014
  0.05579991 0.05547633 0.04802022 0.05093001 0.03513787 0.05691633
  0.05318042 0.05541909 0.03565241 0.04344638 0.02401343 0.04417613
  0.04126789 0.04185892 0.16576138 0.05456695 0.01742575 0.03840429
  0.05839958 0.06298385]
 [0.05459619 0.03313974 0.03883888 0.0320138  0.02386552 0.03628522
  0.03700784 0.03900816 0.03814173 0.03187955 0.04172922 0.03938931
  0.03963876 0.01939781 0.01826037 0.0399299  0.0349457  0.03434992
  0.0426913  0.04164608 0.04181486 0.04947517 0.02940469 0.04122831
  0.03604022 0.04098452 0.0330192  0.04060509 0.02911287 0.03820368
  0.04784403 0.03464045 0.05089832 0.07065529 0.0221007  0.02988572
  0.03820869 0.04317969]
 [0.0526133  0.04841477 0.05518125 0.07647302 0.06212723 0.06990486
  0.04887678 0.05236618 0.0631393  0.081214   0.05880537 0.06453768
  0.0631817  0.11323714 0.11371535 0.04595834 0.04058047 0.0492488
  0.04144131 0.04765362 0.04418858 0.05214651 0.06056235 0.03484799
  0.02564957 0.05651009 0.05100132 0.06695934 0.07345042 0.02856203
  0.0455825  0.01785574 0.02649371 0.12496906 0.07820857 0.05612826
  0.03652992 0.03623194]
 [0.05231944 0.06073197 0.06152516 0.10816497 0.22182769 0.08562666
  0.0483087  0.04894029 0.05589922 0.1047548  0.07920975 0.07243805
  0.05042722 0.13913591 0.18057957 0.06263151 0.0713782  0.08339608
  0.05778628 0.05703145 0.07121016 0.0504693  0.08135961 0.03565653
  0.02172505 0.06026654 0.07185919 0.07300859 0.07297084 0.01681211
  0.01954892 0.01236638 0.02233449 0.08244327 0.14313391 0.06418004
  0.03742284 0.03304221]
 [0.05242463 0.05083413 0.04883733 0.06913146 0.10441904 0.04809065
  0.03908866 0.04315769 0.04424065 0.07617521 0.06820076 0.05816656
  0.04445969 0.04739755 0.07067265 0.05919861 0.10693926 0.12026513
  0.08499811 0.07353385 0.11898085 0.04979715 0.06503217 0.05104967
  0.04240978 0.05641862 0.05366918 0.08518929 0.04012849 0.02364431
  0.0224207  0.01880273 0.03564781 0.03650759 0.12858418 0.05259981
  0.04693059 0.04844761]
 [0.05257954 0.05415762 0.05244493 0.07477881 0.0796363  0.06058878
  0.04999378 0.05067442 0.05876603 0.07367168 0.06064348 0.05540393
  0.05036063 0.06164282 0.06633178 0.04834197 0.06812366 0.07782409
  0.06101838 0.06866255 0.07451867 0.0666239  0.07677394 0.03986807
  0.02959278 0.05933886 0.04615065 0.1045505  0.04934631 0.01986
  0.02037919 0.01428517 0.03369165 0.03793404 0.17838119 0.06637883
  0.04080544 0.04226038]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' cinema', '.', ' In', ' fact', ',', ' sentence', ' ', '10', ' states', ' that', ' Fred', ' is', ' in', ' the', ' cinema', ',', ' which', ' is', ' a', ' different', ' person', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 44), x_tokens=44, y_tokens=40, max_supp_attn=0.025, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 44)
DEBUG result.interpretability.attn_scores 1760 
 [[0.02324273 0.03051241 0.03366794 ... 0.0940842  0.01047212 0.01179844]
 [0.02358742 0.03007999 0.03450256 ... 0.04672302 0.02723354 0.01605607]
 [0.0242465  0.03176872 0.03727452 ... 0.06764098 0.01409038 0.0179471 ]
 ...
 [0.02490935 0.03108443 0.02694556 ... 0.01981167 0.00816053 0.00776696]
 [0.02495883 0.03801686 0.03395271 ... 0.02474846 0.00964848 0.00868355]
 [0.02517523 0.03247273 0.02998714 ... 0.02889856 0.0112437  0.01087284]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' office', ',', ' but', ' sentence', ' ', '14', ' states', ' that', ' Julie', ' went', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Julie', ' is', ' no', ' longer', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0244, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02244382 0.03688972 0.03285217 ... 0.04762544 0.03425894 0.02849203]
 [0.02303878 0.03613627 0.03526831 ... 0.02402231 0.02648736 0.02846863]
 [0.02342893 0.03923627 0.03849327 ... 0.04262074 0.03529658 0.02451973]
 ...
 [0.02361965 0.03472937 0.02787109 ... 0.08277984 0.0329091  0.02129334]
 [0.0241974  0.03051385 0.02248338 ... 0.050856   0.02218529 0.01999751]
 [0.02398115 0.03073626 0.02069779 ... 0.07723715 0.03139243 0.01960994]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Mary', ' being', ' in', ' the', ' office', '.', ' Sentence', ' ', '1', ' only', ' mentions', ' Mary', ' being', ' in', ' the', ' park', ' or', ' the', ' bedroom', ',', ' and', ' sentence', ' ', '2', ' is', ' about', ' Fred', "'s", ' location', ',', ' which', ' is', ' not', ' related', ' to', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 26), x_tokens=26, y_tokens=54, max_supp_attn=0.0741, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 26)
DEBUG result.interpretability.attn_scores 1404 
 [[0.01767095 0.0385417  0.02875737 ... 0.00283473 0.00500708 0.01580839]
 [0.0181294  0.03533459 0.03017368 ... 0.00252067 0.00446515 0.0166668 ]
 [0.01707666 0.03310888 0.03773383 ... 0.00383459 0.00790601 0.02542865]
 ...
 [0.01809075 0.02060332 0.02057341 ... 0.0028164  0.00450665 0.01313541]
 [0.01792311 0.01694078 0.01683851 ... 0.00850873 0.00891223 0.01403119]
 [0.01812246 0.01943394 0.01842235 ... 0.00550572 0.00700575 0.01299423]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.0952, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.04470441 0.08106225 0.06792019 0.09971656 0.08965085 0.12208726
  0.08268034 0.07545679 0.07686298 0.09604556 0.08011231 0.08681026
  0.09822453 0.10037336 0.07558583 0.04670275 0.0311638  0.05064547
  0.04292213 0.04451025 0.04200965 0.05559031 0.10921266 0.01877109
  0.02973861 0.05342277 0.0575164  0.05282546 0.1103775  0.03902854
  0.03066876 0.0147783 ]
 [0.0470528  0.07061258 0.0558835  0.06537776 0.04338239 0.04601591
  0.04814817 0.03711509 0.03748534 0.04254976 0.03745072 0.02373971
  0.03127948 0.05127086 0.07854284 0.05357998 0.0304221  0.02755873
  0.03076195 0.0304196  0.0311072  0.05135005 0.11785149 0.0108442
  0.01780815 0.04913584 0.06715199 0.04909116 0.12556703 0.01539035
  0.01119653 0.0086058 ]
 [0.04536531 0.05892981 0.06710107 0.07782161 0.06469762 0.06998926
  0.0547597  0.05332856 0.06228425 0.06395812 0.04751295 0.0475899
  0.05154282 0.11783377 0.12028838 0.05497998 0.03798945 0.03891548
  0.03997129 0.04028967 0.03878663 0.04927268 0.06692286 0.01464478
  0.0286939  0.06294055 0.06685485 0.06157905 0.12764423 0.03939753
  0.02408241 0.01354787]
 [0.04686186 0.05078428 0.0573632  0.08612727 0.08342066 0.09152441
  0.05320453 0.05590446 0.06708889 0.08469244 0.0609198  0.07103501
  0.07462467 0.1545074  0.1331794  0.04971948 0.03586304 0.04490097
  0.03993788 0.03952149 0.03622321 0.04977458 0.04038901 0.0143844
  0.02734328 0.04901348 0.05543647 0.04718706 0.09853588 0.05410196
  0.03560787 0.01961853]
 [0.04750474 0.05081781 0.06592964 0.07459733 0.06308231 0.07808923
  0.05404416 0.05814917 0.06090905 0.06660939 0.0508481  0.06388198
  0.06288242 0.09866527 0.07440121 0.04376529 0.03193682 0.03652814
  0.03439571 0.03530239 0.03169481 0.04844516 0.04381574 0.01744058
  0.03376353 0.04747962 0.05297451 0.04200505 0.08506424 0.08453551
  0.05933592 0.03387926]
 [0.04560322 0.06186727 0.07157365 0.04827904 0.03591587 0.05398693
  0.05633968 0.06012649 0.05403025 0.04617377 0.04328842 0.05456895
  0.05267158 0.03203038 0.02904556 0.05732336 0.04150135 0.04093448
  0.04127965 0.04294151 0.03993229 0.05335732 0.06689109 0.04030021
  0.06618221 0.06123408 0.06282233 0.05027139 0.05286763 0.12525953
  0.12024366 0.06712234]
 [0.04697955 0.05624196 0.06651271 0.03644933 0.02499174 0.04149118
  0.05840152 0.05256069 0.05432006 0.03391134 0.0357311  0.04049402
  0.04040454 0.02197276 0.02225095 0.06232435 0.04488245 0.03964824
  0.04597453 0.04668822 0.04078414 0.0457022  0.06240542 0.03483215
  0.0654665  0.05504839 0.0591294  0.03457573 0.03084852 0.0725294
  0.11797892 0.10513018]
 [0.04791716 0.02691396 0.02860057 0.01836358 0.01344743 0.02020721
  0.02651851 0.02627912 0.02815449 0.01870952 0.02346199 0.0221359
  0.02293934 0.01084949 0.01211477 0.03568375 0.03226577 0.02891158
  0.03808425 0.03811905 0.0334409  0.0353588  0.03228071 0.03135323
  0.05851332 0.03847313 0.02699663 0.02582308 0.01694151 0.02691828
  0.04851655 0.0624714 ]
 [0.04714141 0.05206767 0.05157474 0.03281805 0.02308863 0.04076106
  0.04867345 0.0481056  0.04262241 0.03441358 0.03927677 0.04754291
  0.04110578 0.01897325 0.01785903 0.05062358 0.04650448 0.04231673
  0.04770789 0.04825107 0.04493196 0.0527338  0.04558523 0.06117173
  0.07042839 0.04955535 0.048942   0.03276983 0.02786845 0.07835495
  0.05261011 0.1006266 ]
 [0.04861441 0.05927627 0.06307063 0.04726277 0.03008494 0.05424147
  0.05812854 0.06473122 0.05328583 0.05247812 0.05442926 0.08535375
  0.06436406 0.02808958 0.02157655 0.0510367  0.04489733 0.04812197
  0.04797517 0.04885737 0.04483731 0.05329669 0.04134523 0.06537156
  0.06548382 0.04820067 0.05212556 0.03954264 0.02998237 0.0851772
  0.06990882 0.09107552]
 [0.0494512  0.04274493 0.04473287 0.03202355 0.02289406 0.03555311
  0.0459912  0.04647175 0.04013343 0.03346462 0.04293834 0.04411053
  0.04427715 0.0192143  0.01678182 0.04931547 0.04223678 0.0404819
  0.04470894 0.04434542 0.04273332 0.05046891 0.03264922 0.06082761
  0.05981199 0.0399764  0.04227773 0.03638349 0.02401107 0.06099252
  0.05607126 0.07012832]
 [0.04880103 0.03238094 0.02982309 0.0212613  0.0164389  0.02307577
  0.03475759 0.0345907  0.03146461 0.02326927 0.03682626 0.02955051
  0.03429025 0.01292297 0.01325987 0.04890375 0.04825103 0.04146642
  0.04579411 0.04451613 0.04497238 0.04624582 0.02588895 0.0684451
  0.06082591 0.03495095 0.03344865 0.03615343 0.01825189 0.04683738
  0.04305819 0.05934082]
 [0.04822987 0.03176625 0.02844908 0.02052529 0.01550051 0.02185333
  0.03739228 0.03490471 0.03190217 0.02247099 0.03593215 0.02706797
  0.03431514 0.01216382 0.01203826 0.04695806 0.05503595 0.04552989
  0.04939179 0.04740342 0.05170335 0.0435719  0.02243999 0.09579659
  0.0587692  0.03577032 0.03105036 0.04137472 0.01464171 0.04085056
  0.04181442 0.06317707]
 [0.04899606 0.0324331  0.03118125 0.0212808  0.01751915 0.02358318
  0.03844491 0.0398112  0.03414964 0.02461209 0.05053824 0.03702481
  0.03968069 0.01359704 0.0125414  0.05442096 0.06865356 0.05127831
  0.05571577 0.05072337 0.05483172 0.04217624 0.02263907 0.12765731
  0.05785725 0.03708786 0.03007407 0.04477609 0.01462433 0.03787395
  0.05453277 0.07649969]
 [0.04904277 0.02794402 0.02695352 0.0168867  0.01528973 0.01977349
  0.03784104 0.03538065 0.03138221 0.02045941 0.05984356 0.03105401
  0.03663599 0.01152684 0.01077206 0.0489816  0.06852512 0.05011452
  0.05597504 0.0559461  0.05985801 0.0396243  0.02135563 0.13104944
  0.05524644 0.03919636 0.02328247 0.04837666 0.01286809 0.02733599
  0.05144178 0.06334959]
 [0.04734793 0.03891897 0.03954158 0.02345469 0.02065654 0.03551124
  0.06585475 0.06166467 0.05730059 0.02992519 0.04211756 0.03889909
  0.05305839 0.01595193 0.01368093 0.04530346 0.05659688 0.05647521
  0.06136887 0.06886534 0.0577698  0.04754404 0.03802969 0.07600746
  0.07591166 0.06489173 0.03198421 0.0411643  0.01967177 0.03704637
  0.04330905 0.04687362]
 [0.04974802 0.02955525 0.02991117 0.0243613  0.01926215 0.0251037
  0.03334926 0.03694091 0.03667272 0.028474   0.03470453 0.03080258
  0.03592344 0.01726735 0.01361658 0.03116042 0.0331508  0.03403501
  0.03994323 0.04577288 0.03996187 0.042927   0.02187557 0.03851428
  0.03659944 0.03595385 0.03068956 0.03877202 0.0190351  0.03168332
  0.04473    0.03768675]
 [0.04812826 0.040994   0.04352973 0.05666755 0.04826076 0.05364699
  0.04092656 0.04510774 0.05332277 0.06299067 0.04485428 0.05047879
  0.05268515 0.07717789 0.08727195 0.03627573 0.03487385 0.04274286
  0.04096693 0.04450877 0.03960792 0.04610141 0.0410032  0.01687285
  0.03108153 0.05046212 0.05280472 0.0522129  0.05168478 0.03176955
  0.03353346 0.0193873 ]
 [0.04748283 0.0551914  0.04943269 0.08469182 0.17501517 0.06570735
  0.04426232 0.04753646 0.05464966 0.09180037 0.06936885 0.07056643
  0.04964497 0.10287658 0.12894809 0.04984362 0.06457932 0.07421225
  0.05861716 0.05480709 0.06275666 0.04501664 0.0536014  0.01539632
  0.02496142 0.05363908 0.07678757 0.05842551 0.05241128 0.02347636
  0.01776095 0.01324356]
 [0.04724526 0.04909296 0.0412908  0.05670654 0.1082908  0.03690282
  0.03635205 0.04119483 0.04213939 0.06406914 0.05872947 0.05076578
  0.03883243 0.03909941 0.0603043  0.0482788  0.09493172 0.10005271
  0.08188708 0.06717447 0.09866732 0.04353511 0.04490751 0.03732673
  0.04158826 0.04644395 0.05552136 0.07878976 0.03062428 0.02343437
  0.02347895 0.01908419]
 [0.04778187 0.0504043  0.03962437 0.05532714 0.06910984 0.04089503
  0.04392936 0.04463918 0.04983933 0.05892257 0.05111539 0.04652704
  0.04061718 0.04363576 0.04594037 0.03481892 0.05573848 0.06512918
  0.05662054 0.0610364  0.06338962 0.05790707 0.0489103  0.02299237
  0.03392514 0.04712347 0.04212917 0.08790059 0.03647821 0.01800637
  0.02011955 0.01437335]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' or', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Bill', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ',', ' school', ',', ' or', ' office', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 38), x_tokens=38, y_tokens=43, max_supp_attn=0.0698, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 38)
DEBUG result.interpretability.attn_scores 1634 
 [[0.02146992 0.0298939  0.03091218 ... 0.01423382 0.03979234 0.02737152]
 [0.02230692 0.0379725  0.03010727 ... 0.01921833 0.06955924 0.02197607]
 [0.02149983 0.03038634 0.03067687 ... 0.03825189 0.04078482 0.02628113]
 ...
 [0.02280196 0.02324794 0.02050653 ... 0.02432817 0.02709245 0.02152849]
 [0.02318881 0.02589779 0.02416205 ... 0.02536401 0.03500874 0.0212774 ]
 [0.02336975 0.02189373 0.02107526 ... 0.0218077  0.04267449 0.01920258]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Fred', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 44), x_tokens=44, y_tokens=48, max_supp_attn=0.0833, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 44)
DEBUG result.interpretability.attn_scores 2112 
 [[0.01916217 0.02108257 0.02007224 ... 0.01239827 0.04363218 0.02554496]
 [0.0196107  0.03167984 0.02713688 ... 0.0132557  0.11289524 0.00866823]
 [0.01907144 0.02629781 0.02691651 ... 0.01645853 0.10324346 0.01604498]
 ...
 [0.02014854 0.0282034  0.02814778 ... 0.02101966 0.03678343 0.00851664]
 [0.02053734 0.02187657 0.02088493 ... 0.02542602 0.0151546  0.00780081]
 [0.02069561 0.02227528 0.02176757 ... 0.01789211 0.02118018 0.00682193]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03236004 0.04194893 0.03691835 ... 0.01707862 0.01243728 0.01756865]
 [0.03321959 0.06240771 0.0485732  ... 0.01452116 0.00740822 0.0106174 ]
 [0.0322852  0.04480908 0.0439481  ... 0.01748125 0.0124028  0.01885299]
 ...
 [0.03400306 0.04530716 0.04497348 ... 0.01326027 0.01152291 0.01340413]
 [0.03447642 0.03723735 0.03551967 ... 0.01847508 0.02339828 0.03034068]
 [0.03432917 0.04142067 0.03891092 ... 0.01526832 0.01527874 0.0205221 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' going', ' to', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' She', ' went', ' to', ' the', ' park', ' and', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' her', ' going', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 26), x_tokens=26, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 26)
DEBUG result.interpretability.attn_scores 1170 
 [[0.02130907 0.03898193 0.03020721 ... 0.00912717 0.00600112 0.01490963]
 [0.02187734 0.03605786 0.0322912  ... 0.00928195 0.00516924 0.0157242 ]
 [0.02059584 0.034306   0.0405036  ... 0.01551557 0.00945477 0.0236578 ]
 ...
 [0.02178028 0.02246642 0.02194213 ... 0.00778031 0.00540505 0.01309298]
 [0.02161221 0.01791206 0.01773781 ... 0.01117282 0.01004965 0.01476312]
 [0.02184679 0.02160195 0.02023848 ... 0.00905082 0.00849149 0.0127211 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' going', ' to', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' He', ' was', ' in', ' the', ' cinema', ' and', ' then', ' went', ' back', ' to', ' the', ' office', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' him', ' going', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 32), x_tokens=32, y_tokens=49, max_supp_attn=0.1429, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 32)
DEBUG result.interpretability.attn_scores 1568 
 [[0.01870274 0.03925717 0.03341326 ... 0.015714   0.01246975 0.00604407]
 [0.01968043 0.03595074 0.03068113 ... 0.00566916 0.00384074 0.00299968]
 [0.01901094 0.03061535 0.03619667 ... 0.01640277 0.01038753 0.00464661]
 ...
 [0.01987853 0.02951417 0.02535078 ... 0.00851171 0.00514212 0.00354773]
 [0.02014666 0.02220186 0.01891503 ... 0.00964464 0.00682701 0.00586205]
 [0.02021234 0.02425104 0.01971083 ... 0.00671481 0.0060738  0.00473762]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' journeys', ' to', ' the', ' park', ' and', ' the', ' cinema', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.1277, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01969454 0.0215621  0.02688746 ... 0.05845781 0.01891679 0.01475085]
 [0.02043737 0.03209708 0.03059785 ... 0.09165574 0.01505789 0.00728657]
 [0.01970548 0.02418951 0.03013917 ... 0.04715265 0.02138264 0.01190101]
 ...
 [0.02097322 0.02230959 0.01907602 ... 0.02427127 0.02191152 0.02071452]
 [0.02123831 0.02421777 0.02265648 ... 0.03308432 0.01796392 0.01167797]
 [0.02133068 0.02113817 0.02043635 ... 0.0467301  0.01616753 0.01134084]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' it', ' is', ' possible', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' but', ' it', ' is', ' also', ' possible', ' that', ' she', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 44), x_tokens=44, y_tokens=57, max_supp_attn=0.0175, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 44)
DEBUG result.interpretability.attn_scores 2508 
 [[0.01601553 0.02378923 0.02094089 ... 0.04132804 0.01687432 0.02041741]
 [0.01649179 0.03378614 0.02604583 ... 0.0863101  0.00892583 0.00612383]
 [0.01592362 0.0261231  0.02594509 ... 0.09143588 0.02173442 0.01019556]
 ...
 [0.01673756 0.02173844 0.0233166  ... 0.02982953 0.01206284 0.0083182 ]
 [0.01713475 0.01765514 0.01855144 ... 0.01283679 0.01141436 0.0101136 ]
 [0.01721368 0.01726905 0.01863844 ... 0.01757941 0.0107022  0.00987391]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' which', ' contrad', 'icts', ' the', ' possibility', ' of', ' her', ' being', ' in', ' the', ' office', '.', ' Sentence', ' ', '14', ' also', ' does', ' not', ' mention', ' the', ' office', ' as', ' a', ' possible', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.125, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01900405 0.03396893 0.03052371 ... 0.01276643 0.02859234 0.03722061]
 [0.01951889 0.0336847  0.03126978 ... 0.01254861 0.04850077 0.05647092]
 [0.01917108 0.02817929 0.02952016 ... 0.01611374 0.03254401 0.03780491]
 ...
 [0.02028107 0.02971542 0.02547804 ... 0.01167732 0.06457951 0.03296221]
 [0.02062947 0.02308132 0.01859125 ... 0.01261157 0.05325459 0.02568906]
 [0.02056632 0.02549148 0.01975921 ... 0.01640985 0.08697415 0.03190045]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Bill', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 26), x_tokens=26, y_tokens=55, max_supp_attn=0.0727, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 26)
DEBUG result.interpretability.attn_scores 1430 
 [[0.01670156 0.03398238 0.03502898 ... 0.0122799  0.00365799 0.02140075]
 [0.01723619 0.02113615 0.02054396 ... 0.00988674 0.00319442 0.01393386]
 [0.01752323 0.02398954 0.02687147 ... 0.0140712  0.00447517 0.01366829]
 ...
 [0.01763175 0.02000958 0.02008802 ... 0.00854375 0.00299953 0.01274937]
 [0.01768178 0.01604044 0.01661198 ... 0.01412728 0.00770672 0.01408496]
 [0.01778653 0.01795446 0.01802238 ... 0.01185828 0.00605492 0.0140279 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Mary', ' has', ' moved', ' to', ' the', ' cinema', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0625, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02921307 0.03948822 0.04703056 ... 0.01153923 0.01458458 0.02057527]
 [0.02995373 0.03972175 0.04575175 ... 0.01396671 0.01679158 0.03222548]
 [0.0305825  0.03597335 0.04851702 ... 0.02249539 0.01824671 0.0336462 ]
 ...
 [0.03081354 0.04191286 0.03648075 ... 0.00807221 0.01196074 0.01548644]
 [0.0307145  0.03675266 0.0297345  ... 0.01095957 0.01946231 0.01665076]
 [0.03106706 0.03742254 0.02955444 ... 0.00788705 0.0157209  0.01409514]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' has', ' moved', ' to', ' the', ' cinema', '.', ' The', ' context', ' sentence', ' ', '8', ' is', ' contradictory', ',', ' but', ' since', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' we', ' can', ' conclude', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 38), x_tokens=38, y_tokens=56, max_supp_attn=0.0357, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 38)
DEBUG result.interpretability.attn_scores 2128 
 [[0.01642617 0.02393171 0.02779179 ... 0.03033599 0.02851004 0.02234433]
 [0.01680293 0.01763168 0.02253899 ... 0.01944944 0.02084601 0.016927  ]
 [0.01720961 0.02483617 0.03030948 ... 0.03073663 0.02519265 0.01748145]
 ...
 [0.01740468 0.02430749 0.02227959 ... 0.04894913 0.02629639 0.01769574]
 [0.01776402 0.01796547 0.01614369 ... 0.0269969  0.01868076 0.01654062]
 [0.01764248 0.01994129 0.01763714 ... 0.01769379 0.02970058 0.01581139]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Bill', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' office', '.', ' The', ' context', ' sentence', ' ', '11', ' is', ' irrelevant', ' to', ' the', ' office', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 44), x_tokens=44, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 44)
DEBUG result.interpretability.attn_scores 1936 
 [[0.02111166 0.0303285  0.03080106 ... 0.02765546 0.1068489  0.00960772]
 [0.02161677 0.01963732 0.02099056 ... 0.01891489 0.05969512 0.03313644]
 [0.02206118 0.0299229  0.0313191  ... 0.02257497 0.07897694 0.01877328]
 ...
 [0.02212742 0.02880448 0.0267946  ... 0.03351812 0.03676542 0.00593166]
 [0.02249028 0.02316988 0.02141189 ... 0.03375857 0.01929339 0.00639802]
 [0.02253961 0.02343947 0.02212669 ... 0.02731112 0.02279731 0.00519119]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03225274 0.03437958 0.03680522 ... 0.05311695 0.0376261  0.0263329 ]
 [0.03301166 0.02629499 0.02806855 ... 0.03295791 0.02964387 0.02596138]
 [0.03373292 0.03529803 0.03772683 ... 0.06096824 0.02816033 0.02220457]
 ...
 [0.03418886 0.03404352 0.02860077 ... 0.05073614 0.03106765 0.03471126]
 [0.03474781 0.03673393 0.03312214 ... 0.05558995 0.02584643 0.02549378]
 [0.03495509 0.03112398 0.02929114 ... 0.07128934 0.02468228 0.02310134]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02794649 0.05124142 0.06347863 0.076828   0.081429   0.07688028
  0.06851795 0.07667425 0.06136046 0.06663485 0.04686136 0.06316529
  0.07116187 0.09744753 0.06160155 0.03231341 0.03183528 0.03217303
  0.03093002 0.03431723 0.02801788 0.04131738 0.04722448 0.02229048
  0.01581738 0.02578609]
 [0.02789784 0.07502666 0.05889071 0.04510625 0.03405541 0.04836541
  0.10703167 0.08262715 0.05728914 0.03983986 0.05071613 0.04431161
  0.06969132 0.02091944 0.0197901  0.04162571 0.03738928 0.05298001
  0.04417492 0.05403351 0.04251389 0.04392333 0.04962293 0.0479741
  0.03583536 0.03723861]
 [0.03049011 0.06049876 0.03900031 0.05714956 0.04100186 0.03808783
  0.03144057 0.02289124 0.02349498 0.03575151 0.02702457 0.01691669
  0.01848436 0.03255863 0.04316124 0.02317681 0.01432126 0.01281618
  0.0170738  0.01786586 0.01675683 0.04460327 0.05587849 0.0080206
  0.00545921 0.01236421]
 [0.02882579 0.03652831 0.03541256 0.02497403 0.01729963 0.02658714
  0.02800769 0.02477266 0.02876916 0.0245376  0.02494821 0.0254642
  0.02343875 0.01381434 0.01352166 0.03308885 0.03175267 0.03436511
  0.03740622 0.03881309 0.03174629 0.03141429 0.04936869 0.05644003
  0.06444487 0.05549894]
 [0.02901028 0.04293467 0.04857708 0.06809515 0.06220694 0.04949
  0.03374918 0.02959829 0.03519872 0.04663441 0.03310175 0.02637388
  0.02540024 0.10671514 0.11203419 0.03614824 0.02729067 0.01966125
  0.0225157  0.02442037 0.02344075 0.03936718 0.06636799 0.01298339
  0.00822566 0.02678224]
 [0.02962043 0.02827539 0.02993475 0.05272263 0.04724535 0.04499362
  0.02527748 0.02340682 0.030193   0.04433378 0.03032698 0.02999571
  0.02759593 0.11658829 0.13987681 0.03553673 0.03047493 0.02350996
  0.02525401 0.02583027 0.02234325 0.03361056 0.03916262 0.010207
  0.00660524 0.01717604]
 [0.03007336 0.03187432 0.03820361 0.05532146 0.05129923 0.05576184
  0.0330126  0.03180307 0.03898231 0.05170982 0.03501794 0.04663962
  0.04157968 0.09219462 0.0860546  0.03002345 0.0276306  0.02343147
  0.02402453 0.0252842  0.02099902 0.03047865 0.03681345 0.01492439
  0.0092522  0.01673304]
 [0.02910948 0.04036073 0.0464263  0.04141258 0.04434447 0.04884311
  0.03630009 0.03964529 0.04100684 0.04409819 0.03450444 0.04934114
  0.04154253 0.054412   0.04892221 0.03906802 0.03496088 0.03044819
  0.02955955 0.03192934 0.02870429 0.03397534 0.05084486 0.0410784
  0.02915236 0.03355515]
 [0.03027875 0.04123612 0.05029359 0.04878695 0.04436228 0.05808069
  0.04205127 0.04600975 0.04943869 0.05086143 0.03518872 0.05181367
  0.04636742 0.04244142 0.02802282 0.02776616 0.02728184 0.02517135
  0.02586533 0.02777878 0.02326019 0.03464634 0.03960235 0.02004841
  0.01486907 0.02382041]
 [0.02964406 0.05123667 0.05571669 0.02998296 0.02407271 0.03850383
  0.0429061  0.04222319 0.04549048 0.03163333 0.02824943 0.03880786
  0.03799902 0.01893951 0.01582241 0.0437107  0.03435828 0.02906553
  0.03089793 0.03322051 0.03115464 0.0336744  0.06652365 0.04387212
  0.03680656 0.0361479 ]
 [0.03015833 0.03844848 0.04606556 0.02477235 0.02104359 0.0283626
  0.04427944 0.03368787 0.04083034 0.02486562 0.02307088 0.02703831
  0.02610623 0.01431866 0.01381556 0.04238859 0.03129984 0.02587661
  0.03030029 0.03365243 0.03095719 0.02963473 0.05336395 0.04900191
  0.04387689 0.0366143 ]
 [0.03066203 0.01372691 0.016377   0.01130141 0.01007651 0.01400863
  0.01559235 0.01550354 0.02102253 0.01342508 0.01255949 0.01426773
  0.0135525  0.00653571 0.00654599 0.01822563 0.01768998 0.01637661
  0.02126307 0.02326399 0.02356963 0.01712622 0.03025241 0.05672665
  0.06688338 0.06415581]
 [0.03020793 0.02413745 0.02634357 0.01651922 0.01512664 0.02117815
  0.02405727 0.02238245 0.02442345 0.0182992  0.02143617 0.02191306
  0.02076338 0.00963997 0.0101894  0.03792683 0.02743857 0.02544788
  0.02791341 0.02852847 0.02815296 0.02890814 0.03010064 0.05367867
  0.06740809 0.04607544]
 [0.03041363 0.02350663 0.02414065 0.018634   0.01652542 0.02359055
  0.02531528 0.02721035 0.02533412 0.02202077 0.02499061 0.02890897
  0.02863748 0.01102641 0.00986766 0.0356651  0.03098199 0.03041518
  0.02892087 0.02902808 0.03014431 0.02904581 0.02130459 0.05181644
  0.051533   0.02748643]
 [0.0299842  0.02109177 0.01842092 0.01575427 0.01293108 0.01695248
  0.02240964 0.02265833 0.02003177 0.01723611 0.02362206 0.02055855
  0.0236313  0.00791913 0.00784907 0.03488391 0.03062471 0.03903277
  0.03180491 0.03465967 0.04274855 0.02760665 0.01711735 0.05676748
  0.09294562 0.04107448]
 [0.03064379 0.01919139 0.01754129 0.01511321 0.01306526 0.01759737
  0.02154319 0.02244351 0.02007775 0.0176193  0.02756399 0.02350406
  0.02397923 0.00771366 0.00765989 0.03685413 0.0270094  0.04409103
  0.03230049 0.03770949 0.03626518 0.02346141 0.01401389 0.03723452
  0.06561642 0.03368323]
 [0.03056697 0.01710738 0.01522297 0.01202459 0.01042917 0.01439975
  0.02019213 0.01947214 0.01798499 0.01423321 0.03483893 0.01964949
  0.02074424 0.00635133 0.00702929 0.0331929  0.03337695 0.0384643
  0.03518505 0.03445833 0.03714043 0.02468713 0.01433623 0.03889103
  0.04771973 0.05454273]
 [0.03009468 0.01924996 0.01773278 0.01363661 0.01220319 0.01741525
  0.02080951 0.0208979  0.0220919  0.01570335 0.02332056 0.0200474
  0.0213275  0.00749374 0.00737198 0.02477945 0.0264235  0.02951444
  0.03548072 0.03455986 0.03779204 0.02506823 0.0183756  0.05525659
  0.05137845 0.06535028]
 [0.03108617 0.02105853 0.01930141 0.01515354 0.01238843 0.01757448
  0.0208318  0.02135016 0.02094837 0.01660392 0.02451126 0.02065114
  0.02090976 0.00822703 0.00775586 0.023147   0.02404903 0.02743568
  0.02923127 0.0276503  0.02870842 0.02603456 0.01571901 0.02665596
  0.02917621 0.03797861]
 [0.03133402 0.02364514 0.02707873 0.02360691 0.01851674 0.02709072
  0.0258464  0.03235935 0.0278481  0.028453   0.02779718 0.03677328
  0.03200083 0.01399088 0.01007203 0.02154881 0.02284035 0.02487905
  0.02505778 0.02333741 0.02321298 0.02850021 0.01568658 0.01772621
  0.01853685 0.01912794]
 [0.03146297 0.02926001 0.03095543 0.02834357 0.02087259 0.03188566
  0.03305136 0.0419213  0.03007732 0.03369689 0.03703896 0.04418086
  0.04107636 0.01554121 0.01096246 0.02477762 0.02311248 0.02721783
  0.02489048 0.02402974 0.02324296 0.0291449  0.01738132 0.01618758
  0.01535324 0.01377076]
 [0.03134297 0.02685544 0.02689922 0.02545951 0.01998321 0.02860345
  0.02944016 0.03542343 0.02950778 0.03138135 0.03424063 0.03951608
  0.03895048 0.01460547 0.01100296 0.02770707 0.0247188  0.02950673
  0.02747938 0.02679219 0.0260503  0.02978731 0.0154252  0.01962619
  0.01691117 0.01278608]
 [0.03122109 0.02040871 0.01940826 0.01544742 0.01187665 0.01747596
  0.02192117 0.02493095 0.02305597 0.01864213 0.02414263 0.0238369
  0.02651272 0.00835055 0.00759683 0.03053823 0.02733451 0.02931529
  0.02849526 0.02712201 0.03103885 0.02781308 0.01307085 0.02947511
  0.02727673 0.01770762]
 [0.03134606 0.02032561 0.0183551  0.01535523 0.01110601 0.01598413
  0.02240286 0.02299413 0.02182345 0.0172212  0.02410023 0.02160712
  0.02533155 0.00775464 0.0072263  0.03052594 0.02729067 0.03186752
  0.03023663 0.02989421 0.03573452 0.02398544 0.01237622 0.03072636
  0.03095071 0.02043717]
 [0.03150304 0.02022746 0.01822004 0.0159329  0.01256773 0.01681912
  0.02111868 0.02336838 0.0220652  0.01933694 0.02584447 0.0237587
  0.02467509 0.00871207 0.00791121 0.02760694 0.03114186 0.02977263
  0.03261141 0.0277088  0.03072528 0.02514171 0.01202729 0.01991512
  0.01971507 0.0167436 ]
 [0.0315054  0.0230808  0.02092987 0.01721502 0.01288596 0.01862145
  0.02584445 0.02705997 0.02706054 0.0204388  0.03140815 0.02513448
  0.02761507 0.00915132 0.00816483 0.02968226 0.03021225 0.03121947
  0.03307227 0.03073855 0.03345784 0.02614032 0.01292816 0.02256476
  0.02063619 0.01824977]
 [0.03152988 0.01784823 0.01655737 0.01176096 0.01004207 0.01346525
  0.02155772 0.02061184 0.02115602 0.01434951 0.03798822 0.01870227
  0.02221592 0.00684963 0.006117   0.02825061 0.03541213 0.03011811
  0.03502354 0.03037087 0.03359085 0.02489688 0.01193875 0.02377825
  0.02112132 0.02956228]
 [0.03024864 0.02236133 0.02113076 0.01305317 0.01123187 0.01601498
  0.0253996  0.02598811 0.02763601 0.01625055 0.03281673 0.0207087
  0.02722322 0.00755399 0.00694115 0.02802655 0.03959063 0.03600889
  0.04168019 0.04095203 0.04869712 0.02771153 0.02163666 0.04840095
  0.03583345 0.05889182]
 [0.03151496 0.02132685 0.02055717 0.01735476 0.01354142 0.01961965
  0.02109639 0.02458836 0.02613207 0.02037469 0.02388941 0.02483981
  0.02409295 0.01078238 0.00849002 0.01793882 0.02406637 0.02314467
  0.02732576 0.02515515 0.02723119 0.02491898 0.01514826 0.01737642
  0.01636928 0.02374191]
 [0.03027424 0.0285065  0.0289363  0.04383277 0.0466742  0.03941744
  0.02373937 0.02497504 0.03128314 0.04448735 0.0310242  0.03250203
  0.03003934 0.07690106 0.09152213 0.02461134 0.02756375 0.02366289
  0.025768   0.02522742 0.02355343 0.03215264 0.03396813 0.01063056
  0.00786099 0.01923398]
 [0.03009405 0.02981405 0.02899785 0.04882008 0.09551308 0.03870387
  0.02210435 0.02337856 0.03025382 0.05188128 0.03651604 0.03242632
  0.02465933 0.07556222 0.09639198 0.02994736 0.03845732 0.03265971
  0.03097316 0.02794398 0.02733525 0.02913595 0.03272545 0.00919325
  0.00566552 0.01633045]
 [0.02985189 0.02621275 0.02482965 0.03925746 0.08516227 0.02705489
  0.01829349 0.02223207 0.02616618 0.04558623 0.03618038 0.03576474
  0.02510185 0.03372755 0.04252743 0.02640222 0.06108797 0.0543425
  0.04341524 0.03261938 0.04016691 0.02600317 0.02764771 0.0170428
  0.01157527 0.02145168]
 [0.03005646 0.03339557 0.03006383 0.0412714  0.05892014 0.03257037
  0.02485879 0.0249106  0.0319654  0.0418587  0.03515927 0.03088036
  0.02759255 0.0352604  0.03818138 0.02291458 0.04098126 0.03600816
  0.03386877 0.0311045  0.03154678 0.04608417 0.04204621 0.01348824
  0.00918852 0.01990099]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' park', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '4', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' and', ' sentence', ' ', '5', ' provides', ' alternative', ' locations', ' (', 'bed', 'room', ' or', ' office', '),', ' but', ' neither', ' of', ' them', ' mentions', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 32), x_tokens=32, y_tokens=54, max_supp_attn=0.0741, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 32)
DEBUG result.interpretability.attn_scores 1728 
 [[0.01701405 0.02505431 0.02686458 ... 0.04778284 0.00769539 0.03591237]
 [0.01753357 0.02433948 0.02504042 ... 0.05144205 0.01102505 0.04389946]
 [0.01779667 0.02361199 0.02710581 ... 0.0514363  0.01704099 0.03570208]
 ...
 [0.01785106 0.02467155 0.02135419 ... 0.01728246 0.00576039 0.03330537]
 [0.01803987 0.01852373 0.01557916 ... 0.01047819 0.00802925 0.01489113]
 [0.01815084 0.01921236 0.01577764 ... 0.00935444 0.00680958 0.0150563 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' bedroom', '.', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02044355 0.02777733 0.02983944 ... 0.01876023 0.00986564 0.0271787 ]
 [0.02071784 0.02375735 0.02819823 ... 0.02651083 0.01832116 0.03071606]
 [0.02136085 0.02765525 0.03338044 ... 0.01754736 0.01015407 0.02106739]
 ...
 [0.02154455 0.02827936 0.02551846 ... 0.01321833 0.00835158 0.02047038]
 [0.0220031  0.0212634  0.018961   ... 0.01409635 0.01294313 0.01839865]
 [0.02195176 0.02275952 0.01896628 ... 0.01257045 0.00870758 0.0165174 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '10', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' park', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 44), x_tokens=44, y_tokens=49, max_supp_attn=0.0408, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 44)
DEBUG result.interpretability.attn_scores 2156 
 [[0.01891587 0.02950507 0.02646135 ... 0.00886856 0.01378343 0.00558548]
 [0.0192962  0.02184667 0.02065609 ... 0.01012104 0.02648497 0.01965928]
 [0.0197193  0.02945175 0.02889253 ... 0.01207435 0.0159719  0.00837757]
 ...
 [0.01982773 0.02897699 0.02878295 ... 0.00508247 0.00575589 0.00407577]
 [0.02039292 0.02256135 0.02160792 ... 0.00718717 0.00545008 0.00453302]
 [0.02019164 0.02561049 0.02315735 ... 0.00586104 0.00523963 0.00368263]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Julie', "'s", ' locations', ',', ' which', ' are', ' the', ' cinema', ' and', ' the', ' office', '.', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' or', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 50), x_tokens=50, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 50)
DEBUG result.interpretability.attn_scores 2250 
 [[0.02048902 0.02893235 0.02531477 ... 0.03291165 0.04088052 0.03219195]
 [0.02090391 0.02226496 0.02166772 ... 0.01874367 0.02135975 0.02254454]
 [0.02142513 0.02795339 0.02826837 ... 0.03810576 0.03430982 0.02447544]
 ...
 [0.02179137 0.02763355 0.02330011 ... 0.03978693 0.05681496 0.02811954]
 [0.02217254 0.03091119 0.02863857 ... 0.03932941 0.05383455 0.02615189]
 [0.02226784 0.02552916 0.02500627 ... 0.03453499 0.06139252 0.02694206]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' going', ' to', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '2', ' states', ' that', ' Fred', ' went', ' back', ' to', ' the', ' kitchen', ',', ' implying', ' that', ' Fred', ' was', ' in', ' the', ' kitchen', ' previously', ' and', ' is', ' now', ' back', ' there', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 26), x_tokens=26, y_tokens=48, max_supp_attn=0.0417, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 26)
DEBUG result.interpretability.attn_scores 1248 
 [[0.01923376 0.0397314  0.04301922 ... 0.01397813 0.00501058 0.01871535]
 [0.01985173 0.02491688 0.02538276 ... 0.00968051 0.00427403 0.01215551]
 [0.02017942 0.02815832 0.03236752 ... 0.01286797 0.00584588 0.0114752 ]
 ...
 [0.02022611 0.02730724 0.02589473 ... 0.00877968 0.00418172 0.01149959]
 [0.02027714 0.0212051  0.02019557 ... 0.01249913 0.00741773 0.0123656 ]
 [0.02036598 0.02672017 0.02358378 ... 0.01046653 0.00574917 0.01107752]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' going', ' to', ' the', ' cinema', '.', ' In', ' fact', ',', ' sentence', ' ', '5', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' school', ',', ' which', ' is', ' a', ' different', ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 32), x_tokens=32, y_tokens=40, max_supp_attn=0.15, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 32)
DEBUG result.interpretability.attn_scores 1280 
 [[0.02339827 0.03587855 0.04114482 ... 0.011103   0.01262121 0.00665834]
 [0.02401917 0.03594436 0.03878569 ... 0.01368187 0.01726625 0.0096538 ]
 [0.0244793  0.03199212 0.03885996 ... 0.01725274 0.02150084 0.01137698]
 ...
 [0.02446503 0.03539595 0.0309703  ... 0.00661343 0.0071383  0.00536521]
 [0.02486938 0.02495168 0.02175545 ... 0.00831483 0.00730904 0.00647968]
 [0.02490451 0.02786194 0.02328836 ... 0.00687626 0.00709816 0.00522739]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' going', ' to', ' the', ' office', '.', ' The', ' previous', ' context', ' sentences', ' (', '4', ' and', ' ', '5', ')', ' mentioned', ' Bill', ' going', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' going', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 38), x_tokens=38, y_tokens=49, max_supp_attn=0.0408, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 38)
DEBUG result.interpretability.attn_scores 1862 
 [[0.01889466 0.02764073 0.02863108 ... 0.04834374 0.03090026 0.0076739 ]
 [0.01917315 0.02071224 0.02368725 ... 0.02496886 0.0245816  0.00951857]
 [0.01970566 0.02716921 0.03138276 ... 0.0395838  0.02176941 0.00609573]
 ...
 [0.02028017 0.02359569 0.02079952 ... 0.04583469 0.02006746 0.00620927]
 [0.02038705 0.02602205 0.02442403 ... 0.05137194 0.02421881 0.00606615]
 [0.02053148 0.02275917 0.02188984 ... 0.06966797 0.02503633 0.0060799 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' (', 'from', ' previous', ' context', ')', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Fred', ' leaving', ' the', ' cinema', '.', ' Sentence', ' ', '10', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' imply', ' that', ' Fred', ' is', ' not', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 44), x_tokens=44, y_tokens=58, max_supp_attn=0.0517, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 44)
DEBUG result.interpretability.attn_scores 2552 
 [[0.01565376 0.02111967 0.01986603 ... 0.02456667 0.08041812 0.00931514]
 [0.01606311 0.01717479 0.0167935  ... 0.01148576 0.03622021 0.00921042]
 [0.0164478  0.02419141 0.02356267 ... 0.01491584 0.06494646 0.01169953]
 ...
 [0.01662143 0.02181878 0.02127051 ... 0.02155503 0.02282643 0.00681477]
 [0.01708323 0.01859562 0.01699212 ... 0.02075241 0.01166421 0.00927013]
 [0.01688993 0.01959265 0.0190047  ... 0.0277563  0.01376602 0.00765342]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.0336054  0.0495908  0.05080318 ... 0.03425377 0.05616798 0.04234469]
 [0.03379868 0.03713714 0.03731715 ... 0.01762402 0.02905602 0.05009431]
 [0.03488526 0.05223486 0.05702769 ... 0.03637868 0.05227715 0.03999623]
 ...
 [0.0350849  0.05415985 0.0498285  ... 0.07215124 0.05880405 0.02995787]
 [0.03532816 0.04165582 0.03751658 ... 0.05428128 0.03749738 0.03144806]
 [0.0354806  0.04282257 0.0381298  ... 0.03997109 0.06670956 0.03034771]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '2', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(23, 26), x_tokens=26, y_tokens=23, max_supp_attn=0.087, attn_on_target=0.0435)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (23, 26)
DEBUG result.interpretability.attn_scores 598 
 [[0.04074095 0.06281726 0.07757201 0.09438065 0.10107198 0.09648325
  0.07676531 0.09469493 0.080657   0.08515908 0.06504714 0.0827248
  0.09443258 0.11897102 0.07540029 0.04395192 0.04106706 0.04624864
  0.04181096 0.04729914 0.03761475 0.05427925 0.05630556 0.0294443
  0.01755708 0.03266513]
 [0.04043894 0.11286794 0.08371561 0.06354575 0.04627221 0.0639854
  0.18614453 0.13375998 0.08163952 0.05643073 0.09515154 0.06561046
  0.11567304 0.02605122 0.02346779 0.06319299 0.05475896 0.08831279
  0.06266366 0.07917871 0.06364154 0.06117544 0.05616607 0.06299606
  0.03783755 0.0439335 ]
 [0.04439706 0.08067784 0.05128615 0.06752507 0.04818965 0.04698285
  0.04077538 0.03162485 0.03296803 0.04496329 0.03896009 0.02316887
  0.02647817 0.03569165 0.04491521 0.0334588  0.01904785 0.01976495
  0.02487104 0.0265044  0.02397333 0.06045754 0.06944961 0.01437017
  0.00668832 0.01459575]
 [0.04173079 0.0497181  0.0474362  0.02978057 0.01972663 0.03318353
  0.03675279 0.03355852 0.03952587 0.03056973 0.03584156 0.03380897
  0.03381194 0.01459787 0.01405932 0.04989708 0.03913613 0.04663179
  0.04818366 0.05278008 0.0473894  0.04467183 0.0674663  0.1025668
  0.08898363 0.07622438]
 [0.04216332 0.05658447 0.0631939  0.08296633 0.0729005  0.0622328
  0.04402361 0.04140163 0.04969188 0.05883345 0.04748308 0.03571587
  0.03636289 0.11988817 0.11949385 0.05233207 0.03674332 0.0308218
  0.03203282 0.03584281 0.03334064 0.05419618 0.08225538 0.024244
  0.01010896 0.03270438]
 [0.04304948 0.03683048 0.03907144 0.06471645 0.05472128 0.05692847
  0.03312504 0.03249055 0.04242713 0.05589595 0.04245933 0.04093272
  0.03962071 0.13179389 0.15268892 0.05188757 0.04113922 0.03692901
  0.03604205 0.03818946 0.03195342 0.04606058 0.04916676 0.0173083
  0.00824786 0.02121395]
 [0.04368006 0.04159401 0.04988277 0.06733642 0.05998161 0.07119582
  0.04321858 0.04407156 0.05506312 0.06461554 0.04887185 0.06364114
  0.05930671 0.10437591 0.09376889 0.04320601 0.03686344 0.03606185
  0.03424819 0.03730033 0.02975153 0.04174355 0.04601382 0.02294918
  0.01172516 0.02221732]
 [0.04225332 0.05546043 0.06686036 0.0518458  0.0522544  0.06329216
  0.04701372 0.05470271 0.05849037 0.05633591 0.0482147  0.06538066
  0.05716319 0.06186562 0.05347078 0.05532983 0.04580213 0.04350574
  0.04041582 0.04477536 0.03912674 0.04716792 0.06835616 0.0532224
  0.03362058 0.05074312]
 [0.04339894 0.0521188  0.06460634 0.03597611 0.02829483 0.04343614
  0.05628945 0.05120268 0.05946237 0.03862937 0.03841054 0.0449659
  0.0429178  0.02174958 0.01846688 0.0598839  0.04295046 0.03953048
  0.04303978 0.04767748 0.04140951 0.03998745 0.06422759 0.06387722
  0.05413326 0.05794206]
 [0.04415185 0.02230836 0.02876867 0.01868536 0.01534231 0.02588001
  0.02580822 0.02929959 0.03962896 0.02354741 0.02140595 0.02654735
  0.02600528 0.01117821 0.00976354 0.03277508 0.0283443  0.02750098
  0.03205637 0.0342374  0.03238887 0.02693074 0.04196382 0.0688497
  0.07477225 0.08747661]
 [0.04346006 0.03785454 0.04549141 0.02840535 0.0217576  0.03848912
  0.03551586 0.04086926 0.04062199 0.03320001 0.03447431 0.04246673
  0.03606509 0.01507162 0.01378652 0.05060293 0.04166375 0.03938731
  0.04369216 0.04266261 0.04093411 0.04283985 0.04156459 0.05576465
  0.07678971 0.06161573]
 [0.0445453  0.048553   0.0562597  0.04515659 0.03093831 0.05871755
  0.0495502  0.06004903 0.05464024 0.05695983 0.05274021 0.08159228
  0.06279197 0.02407555 0.0172224  0.04051844 0.04126884 0.0424983
  0.04115327 0.04220428 0.03769759 0.04407374 0.03291626 0.02959565
  0.03128112 0.03002065]
 [0.0450361  0.0352244  0.03943842 0.0286945  0.02268688 0.03547713
  0.03915638 0.03988543 0.0382488  0.03377652 0.04003932 0.04421841
  0.03913474 0.01469924 0.01307439 0.04294656 0.04170394 0.03649021
  0.03921738 0.03914823 0.03831206 0.04207657 0.02760284 0.042406
  0.04875832 0.02894522]
 [0.04426109 0.02645619 0.02550998 0.01788668 0.01505217 0.02096822
  0.02624268 0.02802288 0.02803229 0.02126986 0.03084761 0.02799551
  0.02901766 0.00878879 0.00933221 0.04152875 0.04713896 0.03840306
  0.04320838 0.03962891 0.0473608  0.03823663 0.02252992 0.06514405
  0.08721014 0.04896974]
 [0.04400144 0.02674246 0.02390159 0.01789197 0.01442424 0.02034292
  0.03111119 0.0342705  0.02834787 0.02095316 0.0324317  0.02672078
  0.032858   0.0081654  0.00834303 0.04434109 0.05082279 0.05104062
  0.05034814 0.04658887 0.06907354 0.03586275 0.02111659 0.06633653
  0.10687447 0.04920634]
 [0.04472378 0.024507   0.02267378 0.01709152 0.01493163 0.02026743
  0.02548749 0.02980768 0.02659323 0.02150311 0.03515131 0.03108435
  0.03078157 0.00814678 0.0082245  0.03780721 0.0529434  0.04053908
  0.05563707 0.04268496 0.0534265  0.03430449 0.01715558 0.03548376
  0.09013044 0.04469221]
 [0.04444648 0.0221326  0.02032916 0.01420356 0.01291468 0.01730828
  0.02501086 0.02700345 0.02484279 0.01799101 0.04078916 0.02635136
  0.02874768 0.00674554 0.00729108 0.04186833 0.05272909 0.04330634
  0.05985895 0.04800338 0.06133509 0.03368503 0.01782897 0.04759283
  0.06560019 0.07326426]
 [0.04372367 0.02783073 0.02632551 0.0170686  0.01435135 0.02279882
  0.02970559 0.03148893 0.0321454  0.0201472  0.03044538 0.02654301
  0.03133463 0.00832745 0.00829677 0.04241889 0.03761222 0.04184561
  0.04800442 0.0488564  0.0536282  0.03705893 0.03030765 0.09138522
  0.07290094 0.07629321]
 [0.04525232 0.02495325 0.02523814 0.02108671 0.01544603 0.02378017
  0.02502747 0.02907952 0.02917681 0.02418839 0.02872059 0.03020677
  0.02911257 0.01087755 0.00979529 0.02561394 0.02758299 0.02883128
  0.03893182 0.03558484 0.03970026 0.03506225 0.02061555 0.02860891
  0.03033369 0.04589293]
 [0.0439942  0.03682522 0.0367404  0.05476021 0.05317247 0.0539429
  0.03297298 0.0348773  0.04154771 0.05883535 0.04442414 0.04745812
  0.04362467 0.08864436 0.09828247 0.03542144 0.03665518 0.03683395
  0.03524309 0.03629855 0.03306498 0.04260023 0.04083348 0.0177233
  0.01054831 0.02326264]
 [0.04368942 0.03882914 0.03565417 0.05871661 0.10813343 0.0480032
  0.0304365  0.03206336 0.03926498 0.06469518 0.05001398 0.04440485
  0.03535986 0.0849199  0.10830905 0.04268558 0.05183773 0.05408959
  0.04312029 0.04119821 0.04020426 0.03932381 0.03883734 0.01443615
  0.00744317 0.02023477]
 [0.04319543 0.03462554 0.03193562 0.04937569 0.10035153 0.03452094
  0.02555138 0.03077533 0.03487626 0.05610266 0.04909034 0.04583046
  0.0332147  0.03728804 0.04915574 0.03635468 0.08008351 0.07793703
  0.05982781 0.0484084  0.05843046 0.03562145 0.03587439 0.02511117
  0.0162858  0.03323619]
 [0.04366586 0.04448833 0.03810867 0.05290366 0.07708438 0.04178294
  0.0343147  0.03500028 0.04210734 0.05539721 0.04898606 0.04263063
  0.03618454 0.03808659 0.04339119 0.03197689 0.05210475 0.05348965
  0.04639283 0.04494733 0.04624235 0.06258387 0.05144588 0.0205836
  0.01216915 0.02464995]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' explicitly', ' states', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' office', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03220696 0.05190782 0.05142857 0.0705935  0.05962449 0.0519978
  0.04022171 0.04239381 0.05145426 0.05655939 0.03787075 0.03379089
  0.03864905 0.09995251 0.10087388 0.02495985 0.02769691 0.02554541
  0.02508386 0.02863427 0.02608811 0.03635333 0.06649353 0.02245864
  0.01242958 0.03643583 0.05813915 0.04024807 0.11081631 0.03350046
  0.06680235 0.08700824]
 [0.03306468 0.05412187 0.05143936 0.08775956 0.08992324 0.08735119
  0.04779977 0.04922398 0.05950725 0.08019411 0.05622249 0.05831325
  0.0606228  0.17195414 0.1332202  0.02914229 0.02925444 0.03070669
  0.02764159 0.03039711 0.02732111 0.04076554 0.05061698 0.01937724
  0.01168945 0.03184849 0.05595769 0.03559452 0.08762489 0.04537347
  0.07956646 0.06720833]
 [0.03363836 0.0473735  0.05178735 0.06994502 0.06323013 0.06335899
  0.04216253 0.04608255 0.05406509 0.06132859 0.0419989  0.04877973
  0.04819178 0.11223873 0.08087861 0.0245288  0.02750299 0.02524957
  0.02436717 0.02605677 0.02312281 0.03583193 0.04713247 0.02097007
  0.01325499 0.0290503  0.04690134 0.03077267 0.05952991 0.06369661
  0.06239049 0.05597029]
 [0.03243516 0.04462997 0.04498595 0.03667823 0.03234483 0.03750474
  0.03672259 0.04185095 0.03944631 0.03257871 0.03328519 0.03680711
  0.03617225 0.02958587 0.02990333 0.03125576 0.0324702  0.0264497
  0.02771713 0.02929386 0.02702505 0.03720456 0.05335793 0.0417928
  0.03381865 0.04059072 0.04541398 0.03433207 0.04386175 0.09426634
  0.03831059 0.03714822]
 [0.03357422 0.04257612 0.04500751 0.0300522  0.02354259 0.03095172
  0.041023   0.0380799  0.04254506 0.02587536 0.02928421 0.02767796
  0.02808542 0.02069794 0.02193783 0.02848881 0.03075293 0.02375219
  0.02769996 0.02837908 0.02615043 0.03154378 0.0466026  0.03298225
  0.03030223 0.03249717 0.04465378 0.02276685 0.03027479 0.08175183
  0.02424029 0.0400396 ]
 [0.03416764 0.02279135 0.0247773  0.01842365 0.01415577 0.01843035
  0.02069471 0.02007004 0.02355144 0.01691511 0.02106778 0.0182946
  0.01840748 0.0116645  0.01408161 0.02174273 0.02307527 0.01930263
  0.02390112 0.02478568 0.02273462 0.02455737 0.02547312 0.03116218
  0.03889429 0.03266039 0.02409519 0.02255241 0.02291051 0.03983108
  0.01598097 0.02750325]
 [0.03341603 0.04037894 0.04073912 0.02887337 0.02149652 0.03160641
  0.03674876 0.03650473 0.03448737 0.02707346 0.03085575 0.03455059
  0.03086594 0.01952329 0.01909834 0.04132261 0.03672017 0.03264853
  0.03379475 0.03601835 0.03113866 0.0379566  0.03952128 0.04836284
  0.04531438 0.03670929 0.04319947 0.02703992 0.030221   0.08138454
  0.01944569 0.02663887]
 [0.03453599 0.04522016 0.04648728 0.04353586 0.03159349 0.04486774
  0.04410335 0.0519516  0.0448744  0.04419058 0.04055262 0.05613035
  0.05011208 0.03145367 0.02452412 0.02790295 0.02974731 0.02942771
  0.02990236 0.03214326 0.02756364 0.0372584  0.03341031 0.03006555
  0.02703428 0.02910542 0.04534788 0.02978996 0.03296087 0.08235055
  0.03258769 0.03094203]
 [0.0348316  0.03399142 0.03533433 0.03078637 0.02383489 0.03064113
  0.03304631 0.03395509 0.03169122 0.02881722 0.03152765 0.03311953
  0.03166345 0.02047571 0.01917955 0.03021482 0.02924636 0.02595081
  0.02929125 0.02990045 0.02751486 0.0340882  0.03004136 0.0348871
  0.03489884 0.02631041 0.03366386 0.02673712 0.02775847 0.06243334
  0.02886295 0.02926475]
 [0.03421529 0.02630212 0.02370097 0.02002399 0.01627835 0.02053298
  0.0242804  0.02412364 0.02394318 0.01970372 0.02733307 0.02272422
  0.0243036  0.01179678 0.01367494 0.03855745 0.03209791 0.02784032
  0.02925091 0.02934392 0.02878173 0.03312191 0.02318028 0.04225564
  0.04248756 0.02462089 0.02088911 0.02519606 0.02208688 0.03732717
  0.01729262 0.02477912]
 [0.03361425 0.02788551 0.02334681 0.02030886 0.0157938  0.02030612
  0.0247354  0.02378325 0.02407219 0.01999861 0.02570079 0.02123917
  0.02423109 0.01166715 0.01394784 0.04763854 0.03965376 0.03780283
  0.04048007 0.03959997 0.04095795 0.03255707 0.02366436 0.05780997
  0.05388538 0.03455235 0.01986448 0.03476546 0.02116223 0.0253116
  0.01489289 0.02411359]
 [0.03498611 0.03049245 0.0294984  0.02582553 0.02027241 0.02796907
  0.03132091 0.02934083 0.02846111 0.02495588 0.03222421 0.02886463
  0.02688033 0.01514216 0.01624451 0.05031384 0.02982252 0.03950953
  0.03196314 0.0458965  0.03549007 0.02961095 0.02614473 0.06196854
  0.05119437 0.03497208 0.02331846 0.02604145 0.0240318  0.02111131
  0.01507211 0.02828575]
 [0.03500583 0.02545394 0.02419525 0.02009579 0.01556036 0.02201746
  0.02561119 0.02411697 0.02445221 0.02036082 0.02923296 0.0248551
  0.02493651 0.01214203 0.01366658 0.05324982 0.03411226 0.04601957
  0.0356856  0.04789392 0.03923243 0.02859438 0.02167352 0.06068775
  0.05816193 0.03762188 0.02348372 0.03022053 0.02050416 0.01946859
  0.01338592 0.02082335]
 [0.03493765 0.02336299 0.02277399 0.01805309 0.01423816 0.02007165
  0.02395827 0.02170972 0.02320661 0.01860082 0.0297625  0.02181435
  0.02310831 0.01096209 0.01253914 0.04465273 0.03422538 0.03609892
  0.03592334 0.0407886  0.03597717 0.03039796 0.02148382 0.05194461
  0.04307503 0.03958697 0.02328541 0.02717444 0.01828729 0.01621125
  0.01489502 0.01977417]
 [0.03406411 0.03921879 0.03652    0.03171045 0.02793292 0.03612227
  0.04166524 0.03964172 0.03888098 0.03495867 0.03835095 0.040425
  0.04047725 0.01988441 0.02016247 0.04273856 0.04114914 0.03907344
  0.04245158 0.03991602 0.03906238 0.03718489 0.03944824 0.03874754
  0.04050194 0.05385033 0.03483722 0.04397688 0.03569117 0.02217375
  0.02799844 0.03200174]
 [0.03523235 0.02848582 0.02955846 0.02548971 0.01964858 0.02713624
  0.02846001 0.02970793 0.02809517 0.02664855 0.03139858 0.0310387
  0.0284832  0.01661841 0.01687511 0.02900128 0.03052048 0.02802593
  0.03319566 0.03126675 0.03152889 0.03571989 0.02688176 0.02469221
  0.03125609 0.03744275 0.02564865 0.03045186 0.02607893 0.02350453
  0.03068614 0.02221056]
 [0.03546216 0.03461196 0.03872503 0.03514042 0.02757981 0.03868471
  0.0374353  0.04432272 0.03729759 0.03922634 0.03710586 0.04827227
  0.04355562 0.02592434 0.02052077 0.02780064 0.03014384 0.03080228
  0.03006801 0.03059636 0.02828583 0.03863567 0.03094629 0.02504733
  0.02824713 0.03352211 0.03184598 0.03312309 0.03190533 0.03096678
  0.02563699 0.02354982]
 [0.03564107 0.03694067 0.03853563 0.0359487  0.02792311 0.04019963
  0.04125453 0.04538173 0.03598162 0.04056143 0.04065891 0.04926459
  0.04868361 0.02579074 0.0221737  0.03756322 0.03569652 0.0394593
  0.0367559  0.03574941 0.03485459 0.03805525 0.03113818 0.02931014
  0.03778567 0.02996396 0.03229218 0.03478459 0.02996877 0.02939115
  0.0204232  0.0227872 ]
 [0.03546416 0.02760897 0.02757362 0.02041076 0.01751619 0.02551778
  0.03088805 0.03136763 0.02675105 0.0247562  0.02997698 0.03072167
  0.03394039 0.01386168 0.01544791 0.04277548 0.03812046 0.03781749
  0.03790945 0.03419564 0.03879274 0.03554308 0.02473392 0.03857519
  0.05200715 0.03219933 0.02897042 0.04060885 0.02350642 0.02533341
  0.01460249 0.01849457]
 [0.03575699 0.02861734 0.02693768 0.01992672 0.01692375 0.02371509
  0.03162491 0.02949657 0.02552656 0.02300316 0.02897104 0.02795868
  0.03227874 0.01296879 0.01486866 0.04715899 0.04041885 0.04285735
  0.0409178  0.03924956 0.04400928 0.03143338 0.02375594 0.04002416
  0.05270832 0.0318273  0.03103619 0.03660313 0.02043005 0.01750136
  0.01146645 0.01795068]
 [0.03589427 0.02721776 0.02632329 0.01938247 0.01811844 0.02414597
  0.02961765 0.0284954  0.0251747  0.02380654 0.02983273 0.0288077
  0.03061317 0.01371749 0.01493256 0.03845336 0.03739701 0.03453526
  0.03797297 0.03299228 0.0392453  0.03245131 0.02338525 0.03286966
  0.05946426 0.03457461 0.03121798 0.04292888 0.02061235 0.01794663
  0.01522582 0.01797466]
 [0.03597835 0.03194431 0.03001886 0.02122599 0.0194014  0.02699616
  0.03639241 0.03338777 0.03124084 0.02587536 0.0368743  0.03150591
  0.03540609 0.01480219 0.0159734  0.0468694  0.04214234 0.04081782
  0.04309102 0.04005638 0.04442118 0.03305196 0.02548185 0.03786217
  0.05275781 0.03459475 0.02968104 0.03422063 0.02029497 0.01593411
  0.01208977 0.01890863]
 [0.03596716 0.02368338 0.02357624 0.01434057 0.01525629 0.02000009
  0.02968208 0.02412809 0.02342711 0.01821538 0.03799412 0.02273992
  0.0273996  0.01075176 0.01180882 0.04354151 0.03960901 0.03229687
  0.04212114 0.03497007 0.04217266 0.03046218 0.02253484 0.04236544
  0.04371936 0.04511764 0.02017848 0.03414296 0.01783901 0.01432577
  0.01304966 0.01853317]
 [0.03421881 0.03128836 0.03516496 0.02115419 0.02201637 0.03328578
  0.04759642 0.0428143  0.04115637 0.02769806 0.03107782 0.03254534
  0.04044982 0.01712901 0.01673478 0.02897904 0.03747284 0.03143724
  0.04501533 0.03744354 0.03826364 0.03659271 0.03438501 0.0321219
  0.02359367 0.03882595 0.02989588 0.03071414 0.0233307  0.01690767
  0.01562132 0.03068237]
 [0.03570695 0.02623973 0.02818494 0.02290971 0.02098843 0.02850652
  0.03272015 0.032925   0.02924929 0.0267275  0.02870722 0.03134494
  0.03172028 0.01764358 0.01654907 0.02143489 0.02815062 0.02582033
  0.0324704  0.02972083 0.03114137 0.03376902 0.02375703 0.02048499
  0.0202257  0.03500918 0.02221121 0.03467765 0.02562109 0.02032308
  0.03617999 0.02447267]
 [0.03403278 0.03586822 0.03709435 0.05106975 0.0523112  0.04505654
  0.03661991 0.03507195 0.04065672 0.04905498 0.03625176 0.03826369
  0.03888614 0.07066163 0.09206101 0.02178143 0.02730597 0.0313242
  0.02916165 0.03029699 0.02957235 0.03636672 0.04357709 0.01924173
  0.01428359 0.03303455 0.04174517 0.04150602 0.05275197 0.02074528
  0.09093328 0.05420411]
 [0.0337637  0.04376155 0.04220195 0.07610322 0.16579665 0.05807121
  0.03983314 0.03844921 0.04311508 0.07800687 0.05559615 0.05617255
  0.03992664 0.09864029 0.12740326 0.03073306 0.04964224 0.05708034
  0.04097445 0.03693118 0.04335281 0.03492386 0.052924   0.01938419
  0.01211584 0.03158139 0.05870104 0.04535246 0.05020994 0.01640663
  0.09656504 0.0635169 ]
 [0.03410633 0.03287344 0.03095662 0.04172708 0.06153913 0.02975044
  0.02826472 0.02870676 0.0284963  0.04161094 0.0357412  0.03353569
  0.02947862 0.02934512 0.04308024 0.0264839  0.05005929 0.06045258
  0.04790523 0.04013    0.05894348 0.03156482 0.04144125 0.02477213
  0.02158279 0.03436475 0.04161296 0.05282134 0.03275705 0.01472408
  0.07051554 0.03701956]
 [0.0340811  0.03515156 0.03312623 0.04250525 0.04515877 0.03520418
  0.03551662 0.0329161  0.03919297 0.04269759 0.03454356 0.03044193
  0.03247076 0.033004   0.03763773 0.02071425 0.03579286 0.04189515
  0.03728718 0.03735324 0.03725488 0.04440331 0.04681302 0.01777608
  0.01330974 0.02752932 0.03191208 0.0508559  0.03697145 0.00979761
  0.07527976 0.07819372]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' suggesting', ' she', ' has', ' left', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.02985072 0.03827863 0.03792391 ... 0.01996769 0.04462583 0.03192014]
 [0.03050891 0.06291334 0.05424444 ... 0.04136209 0.05475308 0.03670362]
 [0.03116057 0.03940887 0.04448776 ... 0.01672454 0.03665671 0.02460351]
 ...
 [0.031365   0.04011309 0.03959341 ... 0.01779501 0.03863429 0.03086849]
 [0.0317801  0.03145087 0.02899572 ... 0.02735516 0.03229427 0.04090818]
 [0.03177315 0.03329112 0.03077941 ... 0.02250895 0.03464554 0.03917449]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' explicitly', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' implying', ' that', ' he', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 44), x_tokens=44, y_tokens=28, max_supp_attn=0.1786, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 44)
DEBUG result.interpretability.attn_scores 1232 
 [[0.03332895 0.05062455 0.05287177 ... 0.00891023 0.02799915 0.04864928]
 [0.03414994 0.04411785 0.04586493 ... 0.01601831 0.02190206 0.03303058]
 [0.03481004 0.05377997 0.05954526 ... 0.01184251 0.02923199 0.04743354]
 ...
 [0.03490718 0.04978794 0.04672949 ... 0.00643141 0.04671108 0.0765833 ]
 [0.03537579 0.03816729 0.03330079 ... 0.00918661 0.02780423 0.07023809]
 [0.0351949  0.04171442 0.03576114 ... 0.00666713 0.0167108  0.10628416]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' current', ' location', ' in', ' the', ' provided', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' (', 'sentence', ' ', '11', ')', ' is', ' not', ' relevant', ' in', ' this', ' context', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0732, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02238652 0.02404122 0.02190388 ... 0.0266621  0.0214839  0.06624339]
 [0.02293173 0.02164068 0.02462305 ... 0.02134353 0.0181715  0.03242554]
 [0.02352458 0.02256633 0.02332755 ... 0.02308709 0.01755992 0.03771441]
 ...
 [0.02411588 0.02199425 0.01996322 ... 0.02515031 0.03033893 0.02308372]
 [0.02439411 0.02329434 0.02426003 ... 0.02787686 0.02687456 0.02743802]
 [0.02457954 0.0185439  0.02000967 ... 0.02337613 0.0241481  0.03269256]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' office', '.', ' Sentence', ' ', '1', ' only', ' mentions', ' Julie', ' being', ' in', ' either', ' the', ' school', ' or', ' the', ' bedroom', ',', ' and', ' sentence', ' ', '2', ' talks', ' about', ' Bill', "'s", ' journey', ' to', ' the', ' cinema', ',', ' which', ' does', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(60, 26), x_tokens=26, y_tokens=60, max_supp_attn=0.0667, attn_on_target=0.0167)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (60, 26)
DEBUG result.interpretability.attn_scores 1560 
 [[0.01588287 0.03390913 0.02493092 ... 0.00259857 0.00492774 0.01433872]
 [0.01629609 0.03172749 0.02625329 ... 0.00231625 0.00441001 0.01497348]
 [0.01533924 0.02979909 0.03346279 ... 0.00387836 0.00710494 0.02316551]
 ...
 [0.01626559 0.01715231 0.01801723 ... 0.0029056  0.00409112 0.01227819]
 [0.0161152  0.01465745 0.01488848 ... 0.00841935 0.00736444 0.01248424]
 [0.01630974 0.01646491 0.01643959 ... 0.0055702  0.00570007 0.01148301]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' back', ' to', ' the', ' previous', ' context', ' sentence', ' ', '1', ',', ' which', ' mentions', ' Julie', ' being', ' either', ' in', ' the', ' school', ' or', ' the', ' bedroom', '.', ' Since', ' sentence', ' ', '5', ' mentions', ' Fred', ' journey', 'ing', ' to', ' the', ' school', ',', ' it', ' does', ' not', ' provide', ' any', ' new', ' information', ' about', ' Julie', "'s", ' location', '.', ' Therefore', ',', ' we', ' can', ' still', ' consider', ' the', ' possibility', ' of', ' Julie', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(92, 32), x_tokens=32, y_tokens=92, max_supp_attn=0.0543, attn_on_target=0.0109)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (92, 32)
DEBUG result.interpretability.attn_scores 2944 
 [[0.00976587 0.01727204 0.01297319 ... 0.00685739 0.00551223 0.00281241]
 [0.01030196 0.01633719 0.01302719 ... 0.00362962 0.00225952 0.00183891]
 [0.00991383 0.01468079 0.01585137 ... 0.01051556 0.00605126 0.00267553]
 ...
 [0.01052419 0.01305269 0.01165025 ... 0.00497273 0.00306868 0.00210071]
 [0.01073233 0.01072437 0.00912435 ... 0.00553408 0.00456826 0.00477819]
 [0.01074176 0.01081433 0.00920535 ... 0.00467302 0.00403929 0.00279606]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' now', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02903008 0.03054922 0.03290498 ... 0.02006167 0.02088188 0.08773571]
 [0.03024703 0.05115747 0.04686394 ... 0.01209365 0.0477901  0.14435075]
 [0.02920161 0.03964037 0.04748134 ... 0.01855597 0.06350006 0.07128622]
 ...
 [0.03075053 0.04446263 0.0396912  ... 0.0163609  0.10667272 0.05805355]
 [0.03075252 0.03968813 0.03245689 ... 0.01749384 0.07645616 0.03403086]
 [0.03093515 0.04241218 0.03413293 ... 0.01669089 0.09191935 0.07690735]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' only', ' mentions', ' Mary', ' being', ' in', ' either', ' the', ' park', ' or', ' the', ' park', ' (', 'which', ' is', ' essentially', ' the', ' same', ' location', '),', ' and', ' sentence', ' ', '11', ' talks', ' about', ' Fred', "'s", ' location', ' in', ' the', ' cinema', '.', ' Neither', ' of', ' these', ' sentences', ' provides', ' any', ' information', ' about', ' Mary', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 44), x_tokens=44, y_tokens=58, max_supp_attn=0.0345, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 44)
DEBUG result.interpretability.attn_scores 2552 
 [[0.01597741 0.02536102 0.02233341 ... 0.01494657 0.01122888 0.04263834]
 [0.01650988 0.0395184  0.03169882 ... 0.02203427 0.00964251 0.10325583]
 [0.01590011 0.02863251 0.02907274 ... 0.02765469 0.01886175 0.07320461]
 ...
 [0.01669511 0.02395786 0.02403896 ... 0.02615406 0.01963559 0.03705   ]
 [0.01699283 0.01832618 0.01750793 ... 0.02004038 0.02955364 0.02358556]
 [0.01692569 0.02062918 0.01981932 ... 0.01946514 0.02493991 0.02927659]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 50), x_tokens=50, y_tokens=21, max_supp_attn=0.0, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 50)
DEBUG result.interpretability.attn_scores 1050 
 [[0.0454216  0.04268684 0.04218804 ... 0.05615715 0.06458174 0.0362522 ]
 [0.0463823  0.0736734  0.06597305 ... 0.06189647 0.05737774 0.03258309]
 [0.04545813 0.06203611 0.0685964  ... 0.06744236 0.04523761 0.03305589]
 ...
 [0.04787709 0.06756178 0.06234656 ... 0.02886103 0.02573859 0.01646283]
 [0.04787725 0.05831558 0.04953341 ... 0.02552228 0.02673225 0.01910424]
 [0.04774002 0.06261577 0.05443362 ... 0.02736575 0.02771129 0.0159051 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' kitchen', ' or', ' the', ' school', ',', ' and', ' Julie', ' being', ' in', ' the', ' school', ' or', ' the', ' office', '.', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02217722 0.04624623 0.04871532 ... 0.00498365 0.00359362 0.02411126]
 [0.02292463 0.02931483 0.02826516 ... 0.00446212 0.00326834 0.01575041]
 [0.02331575 0.03279006 0.03533145 ... 0.00638757 0.00417198 0.01487274]
 ...
 [0.02334325 0.02991825 0.0286321  ... 0.00418897 0.0029527  0.01529821]
 [0.02310992 0.02258637 0.02307338 ... 0.00999641 0.00667874 0.01637816]
 [0.02334842 0.02835905 0.02711673 ... 0.00736323 0.005161   0.01543278]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Julie', ' is', ' in', ' the', ' park', ',', ' not', ' in', ' the', ' kitchen', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 32), x_tokens=32, y_tokens=26, max_supp_attn=0.0385, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 32)
DEBUG result.interpretability.attn_scores 832 
 [[0.03609671 0.04952745 0.05389304 0.07308794 0.07099909 0.06391761
  0.04413272 0.04466261 0.05156532 0.06257969 0.03782639 0.0468483
  0.04699199 0.10793376 0.11003699 0.03707468 0.02983457 0.02888829
  0.02767905 0.03058804 0.02961584 0.03999879 0.05818065 0.01755086
  0.01312596 0.04860956 0.05209713 0.05078789 0.11976091 0.01542538
  0.0167835  0.01974019]
 [0.03692285 0.05139014 0.05215592 0.08728961 0.09582861 0.10197007
  0.05782833 0.06099534 0.06359019 0.09425727 0.06014967 0.0890595
  0.09425458 0.136888   0.10191251 0.03693302 0.03000861 0.0389217
  0.03282801 0.03680103 0.0341543  0.04536198 0.0455406  0.02400559
  0.01663378 0.04584891 0.05247071 0.04522335 0.10470305 0.02544159
  0.02685844 0.03000998]
 [0.0377643  0.04497804 0.05268232 0.07138436 0.07272586 0.07071997
  0.04593595 0.04536386 0.05059508 0.06611655 0.04244216 0.05773214
  0.05253178 0.11833883 0.08969722 0.0353415  0.02774941 0.02757585
  0.02604604 0.02795956 0.0269134  0.03973816 0.04188214 0.01878534
  0.0137807  0.0391933  0.04747835 0.03652729 0.09087968 0.02840603
  0.02610795 0.02396687]
 [0.03639917 0.05347562 0.05951201 0.0431038  0.04034647 0.0478048
  0.05049044 0.05137329 0.04538564 0.04217878 0.03764755 0.04993374
  0.04710252 0.03260229 0.03179927 0.04519057 0.03709356 0.03302809
  0.03112133 0.03398043 0.03346005 0.04222128 0.05793024 0.03568911
  0.03081684 0.05191284 0.05488198 0.04435258 0.07413653 0.08263969
  0.05383115 0.03281523]
 [0.03822704 0.05328395 0.06376684 0.05229447 0.0437521  0.06467067
  0.06147407 0.06332269 0.08782497 0.06227149 0.04027192 0.05710641
  0.05826786 0.04572493 0.03537233 0.04316546 0.03363712 0.0318533
  0.03368229 0.03802599 0.03329898 0.04333482 0.05174206 0.03146838
  0.0217437  0.05138708 0.06469689 0.03654352 0.05879721 0.06413897
  0.04383671 0.03573334]
 [0.03744738 0.07213525 0.0734     0.03729217 0.0295407  0.04300798
  0.05723738 0.0520246  0.05210145 0.03543813 0.0351779  0.04109774
  0.04347793 0.0260742  0.0276799  0.06280855 0.04475449 0.03542428
  0.03621993 0.03924079 0.03797946 0.0441671  0.08701013 0.04730063
  0.03706433 0.05348707 0.06659874 0.03873549 0.05243678 0.08554351
  0.04337273 0.04030799]
 [0.03831853 0.09610606 0.08613893 0.03918248 0.0289538  0.04243696
  0.05918165 0.05112579 0.05852784 0.03456075 0.0344344  0.03533874
  0.0391349  0.02405079 0.02765371 0.0735873  0.04934644 0.03642792
  0.03802547 0.04324001 0.03851821 0.04038114 0.10591993 0.03948256
  0.0283332  0.05030795 0.07729665 0.03530961 0.03965168 0.0826003
  0.03024475 0.03278702]
 [0.03838284 0.05956662 0.05615507 0.03123241 0.02376351 0.03300514
  0.04757849 0.03985593 0.04300392 0.02783004 0.02981059 0.0284347
  0.03090811 0.01984519 0.02411696 0.05938808 0.045029   0.03323785
  0.03650718 0.03978321 0.03722887 0.03831818 0.07079984 0.03848209
  0.03010357 0.05089043 0.06272712 0.03416842 0.0305782  0.05952105
  0.03392363 0.038153  ]
 [0.03878488 0.02068449 0.02206828 0.01704865 0.01407166 0.01917948
  0.02112993 0.01976731 0.02209502 0.0167025  0.02041628 0.01693883
  0.01887569 0.01042106 0.01290265 0.02656663 0.02363819 0.02138217
  0.0251927  0.02684646 0.02675471 0.02584617 0.0264373  0.02734997
  0.0271682  0.03837476 0.02552216 0.02282454 0.01645175 0.02532707
  0.02622654 0.03271313]
 [0.03859942 0.03066141 0.03241283 0.0246048  0.0178945  0.0274615
  0.03157081 0.02857738 0.02863765 0.02330894 0.03050386 0.02475408
  0.02627161 0.01573067 0.01862823 0.04215894 0.03813713 0.03238207
  0.03386228 0.03686092 0.03727727 0.03662238 0.03325435 0.03750057
  0.03475444 0.03569075 0.03192393 0.0278521  0.02416112 0.03611742
  0.03577952 0.03913645]
 [0.03866881 0.03250444 0.03454702 0.028278   0.02107854 0.03042237
  0.03655558 0.03569405 0.03043818 0.02810345 0.03770783 0.03324667
  0.03613537 0.01793624 0.0179248  0.04148104 0.04114371 0.03738785
  0.03301733 0.03402903 0.03864357 0.04034247 0.02593648 0.046411
  0.04682696 0.03286571 0.02888436 0.03450298 0.02620438 0.04505273
  0.04848335 0.03846738]
 [0.03820096 0.02919846 0.02714731 0.02385276 0.014425   0.02393274
  0.03209749 0.03042711 0.02499389 0.02171822 0.0346253  0.02491841
  0.03034213 0.01377742 0.01454337 0.04308919 0.04430265 0.04787209
  0.03743233 0.04000696 0.05417114 0.03623889 0.02138735 0.0604858
  0.07765843 0.03142484 0.02643912 0.03427582 0.01887867 0.04560925
  0.05003281 0.05287249]
 [0.03900604 0.02852677 0.02811288 0.02478641 0.01654902 0.0253237
  0.03179219 0.03217262 0.02583841 0.02408689 0.04088682 0.0310008
  0.03209153 0.01498359 0.01477844 0.0404682  0.04327878 0.03900182
  0.03980023 0.03625069 0.04453643 0.03540058 0.02068639 0.0629396
  0.07018557 0.0270777  0.02959755 0.03462506 0.01866085 0.04484443
  0.04540694 0.04981735]
 [0.03904583 0.02297148 0.02266537 0.01989052 0.01403972 0.02080073
  0.03017107 0.02837765 0.02374847 0.01964781 0.04358354 0.02646377
  0.02879662 0.01225001 0.01267829 0.04175919 0.0485485  0.04058301
  0.04651879 0.04096298 0.04996672 0.03249617 0.01870777 0.06849808
  0.07844485 0.03075499 0.02246561 0.03744673 0.01491362 0.03941609
  0.05168614 0.05875976]
 [0.03815155 0.02836787 0.02541319 0.02166061 0.01532531 0.02412878
  0.03634133 0.0338834  0.03032431 0.02313744 0.05452916 0.03184669
  0.03211821 0.01373311 0.01428152 0.03969911 0.04450624 0.0419814
  0.05114828 0.04811503 0.04884321 0.03565004 0.02182841 0.06214283
  0.0818978  0.04017892 0.02367125 0.0416893  0.01832274 0.0342116
  0.0560506  0.06137422]
 [0.03954485 0.02437382 0.02403401 0.02375556 0.01510572 0.02436839
  0.02961404 0.03066592 0.02675647 0.02356494 0.037744   0.02941015
  0.02854508 0.01550175 0.01413929 0.03069196 0.03144885 0.03130415
  0.04223622 0.03960918 0.04036136 0.03564947 0.01795653 0.03974026
  0.04517365 0.02826872 0.02125998 0.02998767 0.01847165 0.02991287
  0.05330831 0.04879897]
 [0.03991694 0.02416576 0.02773387 0.02680207 0.01878284 0.0294935
  0.03289734 0.03893541 0.03222684 0.03110095 0.03186829 0.03867279
  0.03670707 0.01953134 0.01513789 0.0250359  0.02830961 0.02821022
  0.03030716 0.02985125 0.02864071 0.03972413 0.01817754 0.03240158
  0.03366991 0.02833156 0.02328069 0.0328109  0.02442915 0.03356803
  0.05797574 0.0408857 ]
 [0.03983659 0.02471622 0.02460854 0.02362255 0.0172557  0.02542484
  0.03173863 0.03572879 0.02781685 0.02482508 0.03673726 0.0355863
  0.0320782  0.01653315 0.01445292 0.03077627 0.03585298 0.03341265
  0.03447408 0.03398608 0.03453515 0.03863809 0.01728877 0.05044226
  0.04768289 0.02628368 0.0229241  0.03497583 0.0185026  0.03932282
  0.04925029 0.04269943]
 [0.03949691 0.02421164 0.02288646 0.01884176 0.01526542 0.02007724
  0.03047102 0.03073106 0.02696522 0.01937192 0.03601987 0.02623202
  0.02794669 0.01312264 0.01215221 0.03032319 0.0405927  0.03250297
  0.03466526 0.03442567 0.03797788 0.03319098 0.01916401 0.06104383
  0.0739092  0.03594367 0.01922228 0.03675599 0.01525523 0.03894974
  0.05083784 0.06000116]
 [0.03868781 0.02228014 0.02066805 0.01811787 0.01411957 0.01914992
  0.02892666 0.02835594 0.02706486 0.01838021 0.02731683 0.02118408
  0.02871659 0.01273125 0.01182668 0.02729844 0.03839326 0.03244398
  0.03762818 0.03784293 0.03831033 0.03754832 0.02065509 0.06054738
  0.06280782 0.04061884 0.01947699 0.03247171 0.01563071 0.03482511
  0.05298284 0.05998772]
 [0.03999303 0.02192956 0.02114933 0.02179618 0.0151197  0.02193497
  0.02725912 0.02863817 0.02585976 0.02182013 0.02867122 0.02470879
  0.02768752 0.01588083 0.01360726 0.02261163 0.02596241 0.02713667
  0.02721461 0.02986481 0.0300316  0.03588747 0.01771181 0.03519456
  0.03281033 0.02932944 0.01889964 0.02762494 0.01942174 0.03109222
  0.05189735 0.04602865]
 [0.03903235 0.02767325 0.02843473 0.03203049 0.02407693 0.03407404
  0.03812671 0.04273256 0.03650636 0.03647955 0.03117904 0.04144115
  0.04516064 0.02425756 0.01962564 0.02571954 0.03041251 0.03323275
  0.03100382 0.03518167 0.03100595 0.04331992 0.02632253 0.02743808
  0.02624278 0.03470206 0.02759382 0.03830591 0.03228918 0.03181766
  0.04286375 0.03334054]
 [0.03877109 0.04480111 0.04135264 0.06407633 0.05814914 0.06342439
  0.0427544  0.0410652  0.0445862  0.05982577 0.04259287 0.04241661
  0.04534549 0.09614529 0.11556619 0.03769064 0.03167477 0.03478409
  0.03160536 0.03633771 0.03389564 0.04350064 0.04546757 0.0145684
  0.01234685 0.03747038 0.04431992 0.04212429 0.05176232 0.01111732
  0.01289773 0.02221225]
 [0.03800402 0.04347249 0.03954633 0.08161354 0.16405289 0.05775939
  0.03674661 0.03868574 0.04345939 0.08288367 0.05648438 0.05864966
  0.04196673 0.0983361  0.1301298  0.04004322 0.05421554 0.07482231
  0.05455792 0.05035929 0.0508268  0.03690019 0.04930435 0.01591752
  0.01448483 0.0410649  0.06004415 0.05238185 0.04440682 0.01063749
  0.01069213 0.02175009]
 [0.03827477 0.03348247 0.0290965  0.04554151 0.08112014 0.02978134
  0.02653605 0.03162335 0.03187101 0.04948115 0.04731715 0.04334782
  0.03281188 0.0365408  0.05168319 0.03361405 0.06180488 0.08681054
  0.09208538 0.06759021 0.06015525 0.03319385 0.03778925 0.02661288
  0.0248199  0.03585936 0.04306334 0.05664218 0.02477778 0.01364236
  0.01539764 0.01948761]
 [0.03842532 0.03551554 0.03041852 0.04881312 0.05765807 0.03572951
  0.03141191 0.03521425 0.03821674 0.05032871 0.04405577 0.04363014
  0.03573328 0.04112917 0.04767272 0.02748369 0.04032409 0.05939201
  0.0551408  0.05226003 0.04289719 0.04632888 0.04291888 0.01800088
  0.01751347 0.03412265 0.03316353 0.06105395 0.02651562 0.01081937
  0.01327168 0.01815351]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Fred', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0645, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03019538 0.04267772 0.04080822 ... 0.05600288 0.03651305 0.02021726]
 [0.03079091 0.04073159 0.03854974 ... 0.03902501 0.03175797 0.02396501]
 [0.03145726 0.04577355 0.04638156 ... 0.04173118 0.02830357 0.01514164]
 ...
 [0.0316153  0.04196014 0.03872186 ... 0.05277847 0.02517615 0.01595831]
 [0.03180661 0.03298648 0.0285205  ... 0.03844747 0.02957847 0.03006094]
 [0.03192535 0.03744177 0.03184507 ... 0.06440514 0.02655729 0.02500714]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Mary', ',', ' but', ' context', ' sentence', ' ', '5', ' mentioned', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 44), x_tokens=44, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 44)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02422946 0.0276431  0.03284447 ... 0.08198414 0.01216523 0.01014777]
 [0.02462224 0.02802467 0.03336835 ... 0.04005346 0.0363199  0.02009912]
 [0.02530575 0.02733813 0.03378089 ... 0.06295379 0.02717614 0.01314645]
 ...
 [0.02554625 0.03505885 0.03154691 ... 0.03513353 0.00725727 0.00826114]
 [0.02623769 0.02601612 0.02176594 ... 0.02644331 0.00964992 0.01595518]
 [0.02616128 0.02857361 0.02379151 ... 0.03064029 0.00612718 0.01030084]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Mary', ' travelled', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02929088 0.04490262 0.04475927 ... 0.03618659 0.02225847 0.02908748]
 [0.0299717  0.03436076 0.03282662 ... 0.0331507  0.02949481 0.02695832]
 [0.03047551 0.04748341 0.0510294  ... 0.03105644 0.02058058 0.0260074 ]
 ...
 [0.0307077  0.04758376 0.03945659 ... 0.03576635 0.01618014 0.02866886]
 [0.03138758 0.0362005  0.02728046 ... 0.036143   0.02048696 0.02348457]
 [0.0310822  0.03963812 0.02861421 ... 0.0336965  0.01855776 0.02623196]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' that', ' Bill', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' kitchen', ',', ' but', ' we', ' don', "'t", ' have', ' any', ' additional', ' information', ' to', ' confirm', ' his', ' exact', ' location', '.', ' \n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 26), x_tokens=26, y_tokens=41, max_supp_attn=0.0488, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 26)
DEBUG result.interpretability.attn_scores 1066 
 [[0.02239363 0.04032538 0.04640267 ... 0.01103553 0.01836535 0.0276387 ]
 [0.02289289 0.04261974 0.04458068 ... 0.00439428 0.00824738 0.03199996]
 [0.02339541 0.02645853 0.02697252 ... 0.00405531 0.00728279 0.02305991]
 ...
 [0.0238297  0.02631093 0.02680782 ... 0.00434705 0.00652145 0.02035354]
 [0.02375605 0.02286171 0.02218961 ... 0.01541609 0.01652613 0.02268235]
 [0.02413209 0.02284002 0.02206903 ... 0.01073056 0.01324361 0.02137954]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '4', ' and', ' ', '5', ',', ' which', ' only', ' talk', ' about', ' Julie', "'s", ' movements', '.', ' The', ' original', ' information', ' about', ' Bill', "'s", ' location', ' is', ' in', ' sentence', ' ', '1', ',', ' but', ' it', ' doesn', "'t", ' mention', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 32), x_tokens=32, y_tokens=57, max_supp_attn=0.1053, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 32)
DEBUG result.interpretability.attn_scores 1824 
 [[0.01608617 0.02081966 0.02344644 ... 0.01071099 0.00537147 0.01575361]
 [0.01664949 0.01932704 0.0197654  ... 0.01345595 0.00586104 0.02149284]
 [0.01699825 0.01880611 0.02113895 ... 0.02118097 0.00656283 0.0213264 ]
 ...
 [0.01733876 0.01688636 0.01489276 ... 0.00750066 0.00923227 0.01295406]
 [0.0174513  0.01984662 0.01862915 ... 0.00635989 0.0084382  0.01213124]
 [0.01764873 0.01668258 0.01600356 ... 0.00655324 0.00732038 0.01057277]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.0309501  0.04267193 0.04865412 ... 0.0624436  0.03504385 0.02731771]
 [0.03134843 0.03783183 0.04044425 ... 0.04003088 0.0369579  0.035135  ]
 [0.03231476 0.05091037 0.05664171 ... 0.04849226 0.02954039 0.0222855 ]
 ...
 [0.03258542 0.04693837 0.04481909 ... 0.06164984 0.03093578 0.02039205]
 [0.03254135 0.04179054 0.03778584 ... 0.04704086 0.03253009 0.02919307]
 [0.03282634 0.04485454 0.03904184 ... 0.07466331 0.02900994 0.0250459 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' The', ' last', ' information', ' about', ' Bill', "'s", ' location', ' was', ' in', ' sentence', ' ', '8', ',', ' which', ' stated', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 44), x_tokens=44, y_tokens=49, max_supp_attn=0.0, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 44)
DEBUG result.interpretability.attn_scores 2156 
 [[0.01901977 0.02373444 0.02184216 ... 0.07538371 0.01043848 0.00543462]
 [0.01927505 0.01879126 0.01859874 ... 0.02811212 0.00987798 0.00947974]
 [0.01980419 0.02473715 0.02413208 ... 0.06015834 0.01774567 0.00757329]
 ...
 [0.02008027 0.0236708  0.02420651 ... 0.02991521 0.00571497 0.00403094]
 [0.02039005 0.01952598 0.01869473 ... 0.01555328 0.0063787  0.00441157]
 [0.02027065 0.02312143 0.02165772 ... 0.02451361 0.00569845 0.00418686]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ' provide', ' information', ' about', ' Bill', "'s", ' movements', ',', ' but', ' they', ' do', ' not', ' mention', ' the', ' park', '.', ' The', ' last', ' information', ' about', ' Bill', "'s", ' location', ' was', ' in', ' sentence', ' ', '14', ',', ' which', ' stated', ' that', ' Bill', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0385, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01780215 0.02834578 0.0247493  ... 0.00911796 0.01127373 0.03168429]
 [0.01822562 0.02490308 0.02076365 ... 0.01980991 0.01526749 0.01238081]
 [0.01860067 0.03135937 0.02872757 ... 0.01264619 0.01993343 0.03151403]
 ...
 [0.01882105 0.02623627 0.02532099 ... 0.00651666 0.00955515 0.07618179]
 [0.01916298 0.02079379 0.01903973 ... 0.00703857 0.00930908 0.05885125]
 [0.01909114 0.0211885  0.01920329 ... 0.00661706 0.00925248 0.0456716 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' Sentence', ' ', '2', ' only', ' mentions', ' the', ' bedroom', ' or', ' the', ' kitchen', ' as', ' possible', ' locations', ' for', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02678405 0.04915697 0.05272162 0.08295225 0.07657585 0.05518552
  0.03853662 0.03234734 0.03610513 0.05196088 0.03604381 0.0278125
  0.02656428 0.12523292 0.13165872 0.04164007 0.02631056 0.02042221
  0.01705697 0.0213952  0.02149662 0.03960579 0.06881622 0.01461118
  0.00365187 0.02535588]
 [0.02765869 0.03066381 0.03116008 0.05982039 0.05503306 0.04660296
  0.02703951 0.0236097  0.02882081 0.04504387 0.03112994 0.0298167
  0.02654856 0.13116013 0.15475592 0.03896384 0.02815728 0.02380225
  0.01881347 0.02220973 0.02028211 0.03287747 0.04034533 0.01164731
  0.00332484 0.0166763 ]
 [0.02811785 0.03446358 0.03948228 0.06361769 0.06039145 0.05837287
  0.03574244 0.03281846 0.03800944 0.05344279 0.03624576 0.04747711
  0.04138125 0.10296424 0.09512424 0.03280171 0.02595291 0.02423942
  0.01840324 0.02224299 0.01914785 0.02989849 0.03683855 0.01574956
  0.00449737 0.01614537]
 [0.02712824 0.04046105 0.04601084 0.04690675 0.05075487 0.05264146
  0.03914997 0.0408538  0.04150158 0.0458797  0.03566021 0.05185566
  0.04220815 0.06014989 0.05381141 0.04091027 0.03171942 0.03062733
  0.02397706 0.02903493 0.02690989 0.03388486 0.0513659  0.03631816
  0.01272776 0.03054306]
 [0.02727195 0.0547865  0.05889267 0.03600648 0.03071851 0.04475337
  0.04628137 0.04778804 0.04404842 0.03419684 0.03066627 0.04312284
  0.04115802 0.02466176 0.01891296 0.0376977  0.02869319 0.02897598
  0.02526978 0.029287   0.02770804 0.03136719 0.06116869 0.03903503
  0.02781861 0.04272638]
 [0.02817633 0.07145155 0.07758112 0.0334687  0.02485532 0.04144057
  0.04813873 0.04294864 0.050234   0.03014079 0.025707   0.03641061
  0.03238711 0.01846807 0.01601939 0.04340792 0.02894343 0.02690562
  0.02326559 0.02972512 0.0266244  0.03038958 0.07393686 0.03360723
  0.01372133 0.0291916 ]
 [0.02822786 0.04388051 0.05300573 0.02930619 0.02182249 0.03825824
  0.0434282  0.04091406 0.04337164 0.02713931 0.02361573 0.03613574
  0.02843605 0.01626831 0.01446759 0.03705232 0.02728532 0.02617653
  0.02303833 0.02854573 0.0273602  0.03114882 0.05494342 0.04281312
  0.01696599 0.03727184]
 [0.02841562 0.03389931 0.03499345 0.04468893 0.03812809 0.05134785
  0.03767914 0.03783644 0.04523622 0.05074842 0.03444369 0.05381253
  0.04164536 0.02905736 0.01965882 0.02107761 0.02036234 0.02499066
  0.02183073 0.0247825  0.02395249 0.03482286 0.03570692 0.02160733
  0.00945125 0.02327874]
 [0.02853717 0.03408575 0.03613422 0.03113382 0.02451301 0.04087556
  0.03737297 0.04742976 0.04009048 0.03534701 0.02981184 0.05558009
  0.04026197 0.01700308 0.0131764  0.02728095 0.02383722 0.02664129
  0.02419816 0.02586838 0.02585959 0.02937727 0.0268596  0.02625577
  0.02046308 0.02438509]
 [0.02813574 0.02626512 0.02580165 0.02063779 0.01795188 0.02595844
  0.03314051 0.03232871 0.02815088 0.02354536 0.0295107  0.03268921
  0.03280527 0.01138285 0.01094319 0.03475215 0.02881615 0.03261817
  0.03231121 0.03514489 0.04223151 0.02967308 0.02314835 0.03975603
  0.03084768 0.0258717 ]
 [0.02828282 0.02036582 0.01777566 0.01591964 0.01338599 0.01607524
  0.02420363 0.0237598  0.01905267 0.01629663 0.02110622 0.01880723
  0.02202948 0.00797675 0.00847069 0.03149751 0.02493984 0.03736236
  0.04111954 0.04672281 0.04891022 0.0258265  0.01697709 0.04299807
  0.04035072 0.02857127]
 [0.02872732 0.02110663 0.01825062 0.01646122 0.01402399 0.01743509
  0.0230115  0.0242375  0.01909651 0.01777998 0.02348906 0.02259356
  0.02385304 0.00825629 0.00838134 0.03332603 0.02694984 0.03391769
  0.03661272 0.03794032 0.03847719 0.02397032 0.01463923 0.03561496
  0.04226268 0.02093844]
 [0.02863739 0.01751393 0.01525318 0.01234084 0.01125888 0.01381821
  0.02022242 0.0187221  0.01690724 0.01374856 0.02366473 0.0172478
  0.0190227  0.00665219 0.00718874 0.03257733 0.02956803 0.03074207
  0.04074667 0.03767042 0.04344972 0.02382758 0.01423673 0.03615398
  0.04417618 0.02541422]
 [0.02806553 0.01986177 0.01708567 0.01322267 0.01190487 0.01552629
  0.02220183 0.01857091 0.02035966 0.01428598 0.02488722 0.01726236
  0.01914741 0.00724785 0.00781931 0.03582196 0.02917496 0.02896363
  0.03664353 0.03533189 0.03979941 0.02522425 0.02033148 0.06421968
  0.04860623 0.03873074]
 [0.02897667 0.02191015 0.01905806 0.01643781 0.0142078  0.0180573
  0.02245918 0.02256447 0.02096383 0.01809432 0.02440205 0.02225072
  0.02182407 0.00943651 0.00886583 0.02658835 0.02302977 0.0289295
  0.03837192 0.03394863 0.03623397 0.02554706 0.01625117 0.02426584
  0.02629717 0.0225795 ]
 [0.02850976 0.02804621 0.02672135 0.0276237  0.02318373 0.03359864
  0.02823672 0.03054941 0.03152246 0.03358408 0.02648136 0.04221327
  0.03585397 0.01967376 0.01443986 0.02511415 0.02766861 0.02777414
  0.02662761 0.02590549 0.02391792 0.03140026 0.02776747 0.02459519
  0.02329266 0.0330546 ]
 [0.02878045 0.0341501  0.03487946 0.02311313 0.02065305 0.02475014
  0.03865867 0.02957102 0.03205676 0.02209967 0.02207178 0.02357655
  0.02414334 0.01373479 0.01376256 0.03563764 0.02763808 0.02462793
  0.02462843 0.02863104 0.02628644 0.02792036 0.04410416 0.04186563
  0.01642279 0.03526311]
 [0.02902484 0.01539048 0.01587927 0.01142    0.01123491 0.01280259
  0.01548137 0.01385861 0.01698122 0.01168577 0.01350956 0.01205313
  0.01278485 0.00680894 0.00762778 0.02084837 0.0205763  0.01944222
  0.02522664 0.02876166 0.02763706 0.01941477 0.03180021 0.05447378
  0.02557443 0.04689996]
 [0.02885287 0.02478184 0.02417124 0.01847303 0.01544117 0.02197425
  0.0270273  0.02753096 0.02482176 0.018526   0.020584   0.02397702
  0.02564936 0.01120977 0.01045639 0.02742062 0.02749352 0.02245699
  0.02465616 0.02310042 0.02221792 0.02899438 0.0245809  0.03378723
  0.04059317 0.0427759 ]
 [0.0295033  0.02550038 0.0238923  0.02001349 0.01578747 0.02569851
  0.02892433 0.03386588 0.02643426 0.0217607  0.02352611 0.02876636
  0.0308266  0.01174338 0.00946046 0.02000666 0.027683   0.02125479
  0.02459646 0.02141496 0.01953582 0.02764076 0.016527   0.01906553
  0.03823927 0.02523207]
 [0.02911774 0.01999046 0.01852264 0.01565275 0.01284522 0.01860024
  0.02429823 0.02535613 0.02189269 0.01720344 0.02447972 0.02098255
  0.02529827 0.0095593  0.00815591 0.02169809 0.02872774 0.02121557
  0.02631791 0.02375445 0.02369168 0.02584876 0.01344137 0.02775613
  0.0648303  0.03551535]
 [0.0288893  0.01947569 0.01776443 0.01314775 0.01103645 0.01561962
  0.02358315 0.02434487 0.02055557 0.01533042 0.02784606 0.01792315
  0.02621843 0.00860964 0.00681825 0.02231685 0.03271636 0.0213216
  0.0275101  0.02430775 0.02551884 0.02459221 0.01244283 0.03098037
  0.08201649 0.04616757]
 [0.02927604 0.01514794 0.01381793 0.01177585 0.00995625 0.01318796
  0.01555766 0.01473073 0.01685244 0.01292576 0.02061507 0.01432918
  0.01556841 0.00712114 0.00604646 0.01543637 0.02702875 0.01818737
  0.02409685 0.02548184 0.02529353 0.02077624 0.01084247 0.02569499
  0.07385766 0.05023833]
 [0.02950587 0.01645468 0.01511069 0.01184609 0.01044107 0.01402294
  0.01906182 0.01885905 0.0186951  0.01399916 0.02543334 0.01829147
  0.01950374 0.00755286 0.00628857 0.01843172 0.03549926 0.02227944
  0.02727551 0.02397905 0.02242255 0.02343978 0.01128548 0.02312253
  0.05132072 0.04575206]
 [0.02820371 0.02365164 0.02232925 0.03503726 0.05509167 0.0306381
  0.02142064 0.02186436 0.02889205 0.0446542  0.03247312 0.03326019
  0.02931744 0.03144    0.02732228 0.01863005 0.03196419 0.04539
  0.03897591 0.03347437 0.03338336 0.02675941 0.02209387 0.0184093
  0.01848897 0.02774696]
 [0.02953311 0.0192282  0.01810295 0.01456335 0.0113348  0.01619467
  0.02196687 0.0238102  0.021294   0.01605181 0.02586235 0.01934424
  0.02268554 0.00921444 0.00701158 0.01991937 0.02775068 0.02320424
  0.02675472 0.02383301 0.02365495 0.02518955 0.01326713 0.02170821
  0.0371989  0.0333698 ]
 [0.02950965 0.0219316  0.02110989 0.01581975 0.01229646 0.01889027
  0.02671198 0.03136018 0.02381892 0.0193459  0.03572713 0.02396974
  0.03152773 0.01153438 0.00755871 0.02337578 0.03089526 0.02254196
  0.0288398  0.02350094 0.02397039 0.02789253 0.01431967 0.02395628
  0.04100364 0.01941448]
 [0.02924288 0.02842239 0.02507107 0.01885853 0.01400534 0.02067462
  0.03542203 0.03732916 0.02775906 0.02315135 0.04473988 0.02600732
  0.03738723 0.01321098 0.00902039 0.03049467 0.03713346 0.02982017
  0.03122264 0.02781699 0.02722008 0.02732073 0.01731143 0.02959573
  0.0382738  0.01828252]
 [0.029576   0.02440153 0.02476451 0.01851985 0.01363639 0.02048394
  0.03501313 0.0345386  0.02803032 0.02133482 0.04477453 0.02509714
  0.03525031 0.01095047 0.00810841 0.02820509 0.03021134 0.02753922
  0.02690456 0.02677545 0.02794539 0.0257674  0.01552654 0.0246931
  0.02468367 0.01533155]
 [0.02916682 0.02120975 0.01973769 0.01517829 0.01103112 0.01613044
  0.02690423 0.02495294 0.02253111 0.01682681 0.02093533 0.01623205
  0.0266628  0.00913084 0.00736923 0.02590749 0.03143376 0.02813869
  0.03014139 0.028191   0.03059909 0.02895559 0.01685878 0.03299205
  0.03352075 0.02387515]
 [0.02949723 0.02175588 0.02118243 0.01864627 0.01319552 0.01794992
  0.02466034 0.02451031 0.02419978 0.02003688 0.02179215 0.01860275
  0.02564412 0.01078588 0.00900396 0.02378161 0.02236629 0.02539842
  0.02614341 0.02695763 0.03128582 0.02594747 0.01693465 0.02657127
  0.02107764 0.02137284]
 [0.02839169 0.03175441 0.03142779 0.04996582 0.05128632 0.04281647
  0.02621865 0.02733155 0.03381859 0.0490188  0.03187443 0.03049023
  0.03335758 0.08886304 0.10298105 0.0285345  0.02403909 0.02387996
  0.01922563 0.0211894  0.02059446 0.03210579 0.03499708 0.01160231
  0.00350265 0.01924701]
 [0.02813927 0.03277901 0.03045368 0.05623067 0.10541632 0.04077219
  0.02264024 0.0237346  0.02993737 0.05499278 0.0376487  0.03100478
  0.02628551 0.08340022 0.10671394 0.03375646 0.03531841 0.03838447
  0.02677129 0.02571077 0.02621051 0.02948532 0.03466916 0.01082963
  0.00350917 0.0164677 ]
 [0.02798418 0.02559773 0.0240702  0.03930122 0.06141705 0.02750294
  0.01765609 0.02178877 0.02625616 0.0456769  0.03574745 0.03269103
  0.0285964  0.02948386 0.03180051 0.02404434 0.03914346 0.06808881
  0.05205763 0.04292005 0.03750311 0.02661077 0.02649825 0.01828963
  0.01048971 0.01865355]
 [0.02815207 0.03045757 0.0277844  0.04189207 0.05518357 0.03134261
  0.02194856 0.02338291 0.03170193 0.0441443  0.03349366 0.02831309
  0.02816566 0.03005404 0.03079919 0.02104442 0.03097215 0.04373937
  0.0403684  0.03444314 0.03266792 0.04649683 0.03916612 0.0153579
  0.00694084 0.01765925]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' kitchen', '.', ' Sentence', ' ', '5', ' mentions', ' Bill', ' travelling', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 32), x_tokens=32, y_tokens=41, max_supp_attn=0.122, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 32)
DEBUG result.interpretability.attn_scores 1312 
 [[0.02265668 0.03700276 0.03887115 ... 0.01035456 0.01242664 0.00961814]
 [0.02317416 0.03908975 0.03808942 ... 0.01505811 0.01930145 0.0129302 ]
 [0.02367677 0.03367768 0.0374131  ... 0.01657467 0.02246583 0.01125963]
 ...
 [0.02375736 0.03203217 0.02771617 ... 0.00611464 0.00728463 0.01100666]
 [0.02408177 0.02648996 0.02221663 ... 0.00806862 0.00864425 0.01327549]
 [0.02421495 0.02769886 0.02207281 ... 0.00670461 0.00802123 0.01007052]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' being', ' in', ' the', ' bedroom', ' and', ' Fred', ' being', ' in', ' either', ' the', ' park', ' or', ' the', ' office', ',', ' but', ' do', ' not', ' mention', ' Julie', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 38), x_tokens=38, y_tokens=53, max_supp_attn=0.0566, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 38)
DEBUG result.interpretability.attn_scores 2014 
 [[0.01739756 0.02453259 0.02502163 ... 0.01886664 0.01349833 0.02585642]
 [0.01765975 0.02125552 0.02329307 ... 0.02345819 0.01947944 0.02501794]
 [0.01817822 0.02371559 0.02636126 ... 0.01540136 0.01016049 0.01852132]
 ...
 [0.01858432 0.01804479 0.01702786 ... 0.01632991 0.01282748 0.01710079]
 [0.01876183 0.02087837 0.01988158 ... 0.01596007 0.01099107 0.01883771]
 [0.01891471 0.01901355 0.01859397 ... 0.01442735 0.01072638 0.01826673]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ' being', ' in', ' the', ' kitchen', '.', ' Sentence', ' ', '10', ' mentions', ' Bill', ' travelling', ' to', ' the', ' cinema', ',', ' and', ' sentence', ' ', '11', ' mentions', ' Bill', ' going', ' back', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 44), x_tokens=44, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 44)
DEBUG result.interpretability.attn_scores 2332 
 [[0.01743966 0.02554684 0.02394878 ... 0.00776301 0.00733188 0.0048608 ]
 [0.01782313 0.02245973 0.02208425 ... 0.01641287 0.02367325 0.00974214]
 [0.01826624 0.02763136 0.02733524 ... 0.01138025 0.01200332 0.00661255]
 ...
 [0.01843861 0.02568889 0.02515723 ... 0.00497065 0.00406448 0.00323019]
 [0.01876598 0.01999642 0.01942146 ... 0.00728118 0.00539293 0.0046772 ]
 [0.01858734 0.02312734 0.02108439 ... 0.00569733 0.00471001 0.00410502]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' explicitly', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03212065 0.04628953 0.04772004 ... 0.04966407 0.03042161 0.02360079]
 [0.03281036 0.0321812  0.03431514 ... 0.03346517 0.03389981 0.03308986]
 [0.03357311 0.04608861 0.05015881 ... 0.04355343 0.02689509 0.022324  ]
 ...
 [0.03389582 0.04720999 0.04053877 ... 0.03731325 0.02239732 0.0184144 ]
 [0.03379533 0.04031819 0.03340736 ... 0.03525449 0.0323514  0.03056066]
 [0.03400441 0.04419395 0.03536003 ... 0.04056028 0.0225397  0.02285117]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' two', ' possible', ' locations', ' for', ' Bill', ':', ' the', ' office', ' or', ' the', ' bedroom', '.', ' There', ' is', ' no', ' mention', ' of', ' the', ' school', ' as', ' a', ' possible', ' location', ' for', ' Bill', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 26), x_tokens=26, y_tokens=41, max_supp_attn=0.1707, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 26)
DEBUG result.interpretability.attn_scores 1066 
 [[0.02249869 0.03687872 0.04269944 ... 0.01241735 0.01765332 0.02913912]
 [0.02350051 0.04574257 0.03473939 ... 0.00461791 0.00507911 0.02074681]
 [0.02415317 0.0414732  0.03647701 ... 0.00402692 0.0041729  0.02181618]
 ...
 [0.02393585 0.0253506  0.02451183 ... 0.00487499 0.00569245 0.01906931]
 [0.02361633 0.01944478 0.0193458  ... 0.01222783 0.01436813 0.02237185]
 [0.02401653 0.02480597 0.02310531 ... 0.0080365  0.0095812  0.01986585]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' mentions', ' that', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' kitchen', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Bill', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' bedroom', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 32), x_tokens=32, y_tokens=57, max_supp_attn=0.1053, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 32)
DEBUG result.interpretability.attn_scores 1824 
 [[0.015892   0.03185124 0.02908033 ... 0.01264302 0.00899094 0.00649596]
 [0.01669988 0.02768885 0.02372623 ... 0.00617571 0.00449379 0.00391397]
 [0.01607448 0.02449427 0.03018903 ... 0.01532298 0.00933221 0.00702593]
 ...
 [0.01691184 0.02363619 0.02342557 ... 0.00711414 0.00552855 0.00477329]
 [0.0171975  0.02045229 0.018872   ... 0.00736325 0.00816043 0.00745233]
 [0.01729559 0.01936863 0.01806847 ... 0.00624096 0.00777713 0.00673782]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' only', ' provide', ' information', ' about', ' Mary', "'s", ' locations', ',', ' but', ' they', ' do', ' not', ' mention', ' Bill', "'s", ' location', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' (', 'sentence', ' ', '5', ')', ' is', ' no', ' longer', ' relevant', ',', ' as', ' it', ' is', ' not', ' mentioned', ' again', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 38), x_tokens=38, y_tokens=59, max_supp_attn=0.1017, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 38)
DEBUG result.interpretability.attn_scores 2242 
 [[0.01555484 0.01887698 0.0164967  ... 0.03341285 0.02390597 0.02335845]
 [0.01617659 0.02976281 0.02083576 ... 0.0118205  0.0058847  0.004754  ]
 [0.01557651 0.0220882  0.02037894 ... 0.01333711 0.00862822 0.00684584]
 ...
 [0.01654067 0.01998811 0.01533315 ... 0.01212103 0.01236025 0.01638239]
 [0.01686023 0.02119601 0.01829803 ... 0.01138574 0.01035274 0.00920717]
 [0.01696916 0.01705734 0.01522043 ... 0.01098026 0.00868471 0.00730265]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' explicitly', ' states', ' that', ' Fred', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0294, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02725624 0.0403984  0.03594017 ... 0.0725924  0.0210968  0.01596591]
 [0.02843019 0.05466006 0.04402146 ... 0.12705858 0.00761371 0.00807642]
 [0.02751205 0.03981271 0.04289723 ... 0.1295927  0.01828821 0.01139486]
 ...
 [0.02878322 0.03495807 0.03848647 ... 0.04435907 0.01007568 0.00891278]
 [0.02897076 0.02821639 0.02961969 ... 0.02395981 0.00976934 0.01399065]
 [0.02908424 0.02858127 0.03074246 ... 0.03922196 0.00765926 0.01058741]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['*T', 'ASK', '*\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ' only', ' mention', ' Fred', ' and', ' Bill', ' going', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' school', ' as', ' a', ' location', ' for', ' Fred', ' or', ' anyone', ' else', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02105528 0.02927107 0.03068015 ... 0.01218396 0.01420957 0.0161991 ]
 [0.021561   0.03435222 0.03281206 ... 0.0142412  0.01708087 0.04753294]
 [0.02117447 0.03164094 0.03241334 ... 0.01775538 0.01844896 0.05400559]
 ...
 [0.02222959 0.03286881 0.02960791 ... 0.01675699 0.02064297 0.1030857 ]
 [0.02266113 0.02229321 0.01876335 ... 0.02399379 0.02648185 0.06887311]
 [0.02256994 0.02677341 0.02131733 ... 0.01848073 0.02306838 0.08078443]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' travelled', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1515, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02809705 0.04548492 0.05585502 0.071889   0.07190279 0.07360745
  0.06389    0.07231645 0.05544922 0.06240925 0.0470797  0.06260949
  0.06867389 0.0855896  0.05780983 0.0296599  0.03011132 0.03199484
  0.02803531 0.03034795 0.02730199 0.03942989 0.04561869 0.02689201
  0.02007321 0.02514629]
 [0.0284062  0.05826809 0.05589386 0.06558733 0.05704115 0.05862091
  0.05750599 0.05646681 0.04598517 0.04872005 0.04040308 0.03766631
  0.04058977 0.10280563 0.09628069 0.03411573 0.02974914 0.02614612
  0.02384645 0.02543784 0.02406053 0.03853546 0.05121449 0.01660148
  0.01318217 0.02318788]
 [0.03069882 0.06167891 0.0376576  0.05559722 0.03709238 0.03728577
  0.03411605 0.02461704 0.02245665 0.03370786 0.02666419 0.01665424
  0.01792073 0.0280423  0.03677834 0.02241468 0.01405278 0.01268517
  0.01530127 0.01595513 0.01603096 0.04499862 0.05571244 0.00633976
  0.00556729 0.0123671 ]
 [0.02886654 0.02913803 0.02884502 0.02476804 0.01771146 0.02777529
  0.03131733 0.02690056 0.02811285 0.02538016 0.02785063 0.02887736
  0.02566894 0.01220712 0.01110219 0.03009801 0.02987399 0.03620047
  0.03883046 0.04446117 0.03454294 0.03038009 0.03166882 0.03980861
  0.07630829 0.05890878]
 [0.02910706 0.04560835 0.04968879 0.06800529 0.0627502  0.04905472
  0.03722939 0.03267742 0.03506904 0.04678847 0.03521015 0.02620552
  0.0262696  0.09627111 0.10096755 0.03728847 0.0271502  0.01965179
  0.02018048 0.02154529 0.02294945 0.03982427 0.06705475 0.00967546
  0.00886273 0.02803239]
 [0.02969424 0.02978388 0.02991789 0.05122256 0.04819071 0.04247827
  0.02710916 0.02561071 0.02971408 0.04302527 0.03171618 0.02971359
  0.02839984 0.10867589 0.12836355 0.0372561  0.03095134 0.02399285
  0.02293091 0.02264725 0.02241213 0.03380003 0.0390043  0.00866875
  0.00718563 0.01821855]
 [0.03011292 0.0336303  0.03794588 0.05401119 0.05121688 0.05335777
  0.035973   0.03461459 0.03842212 0.05085016 0.03687578 0.04734444
  0.04288186 0.08534963 0.08020642 0.03152548 0.02854948 0.02411777
  0.02192139 0.02209453 0.02125566 0.03082518 0.03575881 0.01217988
  0.01065066 0.01731117]
 [0.02901771 0.04359117 0.04700014 0.04206435 0.04629905 0.04891841
  0.04121222 0.04291621 0.04178542 0.04430914 0.0372845  0.05338828
  0.04530731 0.05165309 0.04765259 0.04171553 0.03939049 0.03299157
  0.02932489 0.02962547 0.0296902  0.03593698 0.04936438 0.0280679
  0.03518675 0.03193088]
 [0.03023461 0.04248821 0.05009275 0.04758361 0.04515513 0.05549785
  0.04511001 0.0475967  0.04933531 0.04957499 0.03713844 0.05165425
  0.04764271 0.03930733 0.02665468 0.02869986 0.02770123 0.02544724
  0.02407307 0.02445072 0.02359437 0.03642042 0.03921867 0.02013085
  0.01764012 0.0229858 ]
 [0.02955229 0.05584238 0.05681654 0.02861779 0.02464909 0.03705296
  0.04716892 0.04384419 0.0440403  0.02963168 0.02987885 0.0373067
  0.03892455 0.01630178 0.01459527 0.04509654 0.03618347 0.02967989
  0.03061113 0.03130611 0.03215439 0.03487787 0.06956617 0.04148559
  0.04124332 0.03413793]
 [0.03014614 0.04438275 0.05017043 0.02462938 0.0221649  0.02833046
  0.04936708 0.03777711 0.04296404 0.02482517 0.02554693 0.02744384
  0.02871214 0.01312416 0.01335285 0.04644573 0.03490934 0.02804242
  0.03007297 0.03178095 0.0308917  0.03064001 0.05746121 0.03098892
  0.04199288 0.03448662]
 [0.0304287  0.01751356 0.01962159 0.01217462 0.01121354 0.01598743
  0.01856421 0.01882944 0.02273887 0.01448763 0.01512905 0.01468869
  0.01597285 0.00624332 0.00706603 0.02219617 0.02142534 0.01973995
  0.02494233 0.02659222 0.02796067 0.02229964 0.0394954  0.03945729
  0.06812824 0.06226096]
 [0.03018674 0.02599718 0.02737856 0.01685772 0.01557175 0.0220495
  0.0265373  0.02417396 0.02538273 0.01860584 0.02234636 0.02188709
  0.02281037 0.00889253 0.00953517 0.03552688 0.03021526 0.02887447
  0.02997755 0.02972483 0.02749107 0.02919552 0.03287581 0.03957152
  0.06342843 0.0504273 ]
 [0.03031721 0.02435827 0.02417374 0.01804334 0.01580218 0.02490294
  0.027613   0.02694714 0.02599836 0.02163291 0.02649378 0.02913168
  0.0296308  0.00977004 0.00896217 0.03417436 0.03571989 0.0326637
  0.03118841 0.03001243 0.02875032 0.03018855 0.02164588 0.03827563
  0.06040443 0.03468969]
 [0.02981704 0.02129707 0.01782109 0.0138229  0.01118062 0.01618045
  0.02343565 0.02157037 0.02045914 0.01531069 0.02279736 0.01917337
  0.02263371 0.00675389 0.00676016 0.03877319 0.03617522 0.04576902
  0.04054131 0.04873268 0.04126686 0.0267301  0.01679065 0.04309344
  0.09188109 0.04802807]
 [0.03073801 0.01998466 0.01793157 0.01426009 0.01191189 0.01738629
  0.02296371 0.02093978 0.02084519 0.01658586 0.02737656 0.02201949
  0.02283431 0.00723552 0.00686434 0.03677125 0.02662419 0.0494716
  0.03595026 0.05485659 0.03778372 0.02251733 0.0137394  0.03520774
  0.05258116 0.03319488]
 [0.03062239 0.0169561  0.01505907 0.01088288 0.00934658 0.01353892
  0.01938373 0.01742852 0.0190407  0.01327332 0.0267859  0.01799971
  0.01920298 0.00570378 0.0058193  0.03414975 0.03047477 0.04040235
  0.04141343 0.0476487  0.03636564 0.02308753 0.01391479 0.04119377
  0.04329734 0.0558097 ]
 [0.02990412 0.02493723 0.02371111 0.01572161 0.01521787 0.02086355
  0.02946251 0.02868605 0.02836729 0.0188971  0.02897685 0.02328121
  0.02568603 0.00810968 0.00853662 0.02684728 0.03100806 0.03136536
  0.04008569 0.0370166  0.03382755 0.02718014 0.02227081 0.07327603
  0.04318156 0.05746053]
 [0.03108816 0.02190787 0.02076696 0.01618001 0.01320512 0.01880108
  0.02288186 0.02318268 0.02361041 0.01816533 0.02651684 0.02308293
  0.02349424 0.00842149 0.00786504 0.02393785 0.02415864 0.02524242
  0.03255719 0.03092265 0.03087107 0.02723651 0.01643336 0.03036402
  0.0219244  0.03746435]
 [0.03124154 0.02299889 0.02630827 0.02297969 0.0179854  0.02690971
  0.02647671 0.03180438 0.02799441 0.02831594 0.02938941 0.04029814
  0.03594289 0.01327672 0.00906936 0.02116782 0.02350146 0.02702243
  0.02591131 0.02376319 0.02462845 0.02922927 0.01552844 0.02754379
  0.02020828 0.02052714]
 [0.03143249 0.02728171 0.02868965 0.02677144 0.01934212 0.03010043
  0.03315728 0.0397716  0.02927392 0.03217477 0.03666053 0.04520955
  0.04294569 0.0147667  0.00969811 0.02360456 0.02315354 0.02760239
  0.02508117 0.02416862 0.02423517 0.02980601 0.01604878 0.02588794
  0.01664227 0.01476286]
 [0.03132448 0.02491811 0.02541406 0.02367296 0.01837337 0.02727783
  0.0298239  0.03374752 0.02942015 0.02982875 0.03379565 0.03943297
  0.04005863 0.01325166 0.00974374 0.02676624 0.02543847 0.02925523
  0.02724382 0.0255392  0.02671517 0.02937929 0.01397521 0.02492562
  0.01870229 0.01410956]
 [0.03115525 0.01981982 0.01890087 0.01444826 0.0111865  0.01709578
  0.02136824 0.02306206 0.02330332 0.01848412 0.02399662 0.02479293
  0.02668334 0.00790813 0.00654189 0.02812096 0.02947284 0.02921134
  0.03000523 0.02788191 0.03168514 0.02747204 0.01213224 0.03300954
  0.03112588 0.02086543]
 [0.03128646 0.02007624 0.01825956 0.01453173 0.01060101 0.01533974
  0.02157657 0.02172324 0.02201942 0.01706984 0.0231369  0.02127809
  0.02454625 0.00718764 0.00607545 0.03024654 0.02913981 0.03300808
  0.03228477 0.03264374 0.03712711 0.02311915 0.01209587 0.03579041
  0.03070307 0.02211407]
 [0.03144494 0.01971231 0.0181042  0.01476377 0.01196479 0.01602225
  0.02015755 0.02270735 0.02244056 0.01906664 0.02538421 0.02410511
  0.02440834 0.00798218 0.00652596 0.02636131 0.02993832 0.02853235
  0.03312302 0.02829283 0.03243938 0.0235934  0.0120309  0.03344342
  0.02032663 0.01928443]
 [0.03149873 0.02139263 0.01995562 0.01520802 0.01181901 0.01736043
  0.02363973 0.02501356 0.02597057 0.0189681  0.02801463 0.02441115
  0.02591057 0.00818095 0.00681096 0.02967843 0.02883118 0.03117742
  0.03215786 0.03150134 0.03339473 0.02412808 0.01348864 0.03411728
  0.02156033 0.02027156]
 [0.03164068 0.01653881 0.01635895 0.01105266 0.00954879 0.01327228
  0.01996516 0.01978727 0.02134237 0.01411522 0.0299237  0.01907423
  0.02063682 0.0065451  0.00527536 0.02557801 0.03128152 0.02640459
  0.03830852 0.03393093 0.03217948 0.02253376 0.0115216  0.03196323
  0.01887424 0.03059605]
 [0.03019907 0.02337875 0.02330112 0.01368991 0.01176963 0.01708682
  0.02551476 0.02762909 0.02897123 0.01698869 0.02693453 0.02039938
  0.02387607 0.00784911 0.00705247 0.02453279 0.02603704 0.02364285
  0.03416546 0.03037292 0.0423635  0.02645498 0.02256899 0.09379133
  0.0449517  0.04776556]
 [0.03144865 0.02182426 0.02228349 0.01887244 0.01465943 0.02254497
  0.02280108 0.02637745 0.02810846 0.02345437 0.02647584 0.0283478
  0.02718826 0.01188362 0.00874864 0.01928841 0.02452178 0.02478063
  0.03101618 0.02779903 0.02989991 0.02609188 0.01452608 0.02247592
  0.01397333 0.0223008 ]
 [0.03026895 0.02939366 0.02989286 0.04476102 0.04711026 0.03937411
  0.02583151 0.02660915 0.03141328 0.0449728  0.03354068 0.0314082
  0.03245745 0.07105063 0.08672249 0.02608555 0.02762898 0.0248429
  0.02371048 0.02266223 0.02368203 0.03224334 0.033224   0.01044699
  0.00886637 0.020226  ]
 [0.03012102 0.03055157 0.02996881 0.04860512 0.09293317 0.03805285
  0.02356852 0.02531452 0.03032825 0.05174712 0.03954976 0.0314162
  0.02681669 0.06908516 0.08948588 0.03213204 0.03906665 0.0348965
  0.02893988 0.02513975 0.02862244 0.02935296 0.03279071 0.009016
  0.00650725 0.01733246]
 [0.02985636 0.02608876 0.02541752 0.03795427 0.08186424 0.02590981
  0.01912756 0.02349559 0.02645606 0.04554083 0.03672075 0.03282263
  0.02636534 0.02894375 0.03802378 0.02641884 0.0585103  0.05737044
  0.04281178 0.03116381 0.04877423 0.02631062 0.02852403 0.02231033
  0.01450549 0.02200511]
 [0.03004532 0.03317557 0.03079742 0.04076978 0.05321904 0.03196292
  0.02615039 0.02586151 0.03318121 0.04309193 0.03440553 0.02687548
  0.02890704 0.03163083 0.03505311 0.02332576 0.03905397 0.03777378
  0.03345603 0.02998147 0.03505208 0.04618106 0.04273569 0.01399963
  0.01033313 0.02179015]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' provided', ' (', '4', ' and', ' ', '5', ').', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' and', ' Mary', "'s", ' movements', ',', ' but', ' not', ' Bill', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 32), x_tokens=32, y_tokens=43, max_supp_attn=0.1163, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 32)
DEBUG result.interpretability.attn_scores 1376 
 [[0.0214481  0.02667587 0.02674204 ... 0.05630813 0.00961025 0.00980704]
 [0.02203629 0.02412857 0.02360709 ... 0.06415754 0.01642039 0.01741411]
 [0.02250072 0.02336014 0.02572423 ... 0.0603441  0.01941092 0.01918187]
 ...
 [0.02267076 0.02567452 0.02052449 ... 0.01182274 0.01394488 0.01357618]
 [0.02312702 0.02542087 0.020695   ... 0.01077805 0.01271825 0.01346845]
 [0.02320004 0.02256188 0.01880745 ... 0.01228179 0.01205856 0.01288569]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' school', ',', ' but', ' it', ' doesn', "'t", ' specify', ' which', ' one', '.', ' There', ' is', ' no', ' additional', ' information', ' to', ' determine', ' his', ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 38), x_tokens=38, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 38)
DEBUG result.interpretability.attn_scores 1596 
 [[0.02186164 0.03304197 0.03324843 ... 0.01749304 0.01463428 0.04279937]
 [0.02214312 0.02715372 0.02965096 ... 0.03198421 0.0270818  0.04022902]
 [0.02281928 0.0341897  0.03752663 ... 0.01616049 0.013404   0.03708972]
 ...
 [0.02296146 0.02959083 0.02765725 ... 0.016394   0.01488395 0.04145888]
 [0.0234635  0.02641239 0.02333172 ... 0.02069657 0.02344765 0.02657845]
 [0.02360282 0.02468748 0.02167161 ... 0.01882367 0.01843728 0.02649656]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' implies', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', ',', ' as', ' it', ' lists', ' the', ' kitchen', ' as', ' both', ' options', '.', ' Sentence', ' ', '11', ' confirms', ' that', ' Mary', ' is', ' also', ' in', ' the', ' kitchen', '.', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 44), x_tokens=44, y_tokens=50, max_supp_attn=0.08, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 44)
DEBUG result.interpretability.attn_scores 2200 
 [[0.01836795 0.02550811 0.02490216 ... 0.01309739 0.02928702 0.00752555]
 [0.0187746  0.01953137 0.01929881 ... 0.02417458 0.02974042 0.01453466]
 [0.01915006 0.02856651 0.0294638  ... 0.01721317 0.02937396 0.01138667]
 ...
 [0.01934821 0.02546313 0.02690638 ... 0.00803144 0.01275978 0.00583725]
 [0.01969736 0.02178534 0.02122909 ... 0.00742294 0.00968693 0.00620104]
 [0.01963768 0.0230858  0.02311976 ... 0.00822559 0.01219233 0.00667191]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', ' provided', ' (', '13', ' and', ' ', '14', ').', ' Sentence', ' ', '13', ' mentions', ' Mary', ' being', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', ',', ' but', ' not', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 50), x_tokens=50, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 50)
DEBUG result.interpretability.attn_scores 2350 
 [[0.0197448  0.02768386 0.02333216 ... 0.01907229 0.00930492 0.01223989]
 [0.02008646 0.02496594 0.02216548 ... 0.0244542  0.01053254 0.02196241]
 [0.02051325 0.029811   0.02865181 ... 0.01605864 0.00677733 0.01136467]
 ...
 [0.02078163 0.02781648 0.02571446 ... 0.01327899 0.00720619 0.01110166]
 [0.02122058 0.02115775 0.0193214  ... 0.01680525 0.01155778 0.01410969]
 [0.0211261  0.02387395 0.02120522 ... 0.01315709 0.00961049 0.01185974]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Fred', ' moving', ' to', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.0284019  0.04979007 0.05448314 0.08416517 0.08057003 0.05465404
  0.0387454  0.03305457 0.03734348 0.05541635 0.04184132 0.02699023
  0.02857059 0.1293952  0.12924048 0.03968681 0.02855406 0.02103515
  0.02027043 0.02149604 0.02271484 0.04180096 0.06401203 0.01395178
  0.01010201 0.03248848]
 [0.02928043 0.03135321 0.03237582 0.06229432 0.05720438 0.04661154
  0.02723275 0.02402875 0.03007431 0.04768771 0.03625301 0.02902487
  0.02836761 0.13205461 0.15477313 0.0380901  0.0309729  0.02476167
  0.02244923 0.02238929 0.02143382 0.03569277 0.03797572 0.00959784
  0.0081016  0.02135464]
 [0.02976567 0.03517062 0.04143053 0.06454507 0.06364933 0.05932388
  0.03671044 0.03434128 0.03937874 0.05626661 0.04167376 0.04675653
  0.04570205 0.105274   0.09615131 0.03209703 0.02838661 0.02543077
  0.02165988 0.02253782 0.02031369 0.03233413 0.03518397 0.01361847
  0.01104894 0.02007177]
 [0.02878645 0.0412223  0.04846558 0.04936858 0.05155159 0.05371523
  0.04153056 0.04286231 0.04199712 0.04851773 0.04017723 0.04909565
  0.04518271 0.06175306 0.05568067 0.04101875 0.03508962 0.03239294
  0.02709182 0.02943826 0.0281195  0.03588571 0.05176749 0.03462608
  0.03358077 0.03411709]
 [0.029871   0.04485467 0.05416799 0.05959181 0.0522913  0.06771968
  0.05089885 0.05092694 0.05261932 0.05905565 0.04336854 0.05529265
  0.05363052 0.04890216 0.03170355 0.03076101 0.02813926 0.02829615
  0.02379642 0.02714798 0.02308896 0.03707676 0.03968513 0.0190742
  0.01856896 0.02616606]
 [0.02928945 0.05421745 0.06127868 0.0356985  0.02677239 0.04310665
  0.04969122 0.04526472 0.04627773 0.03487465 0.03246565 0.0382264
  0.03985549 0.02202594 0.01879713 0.04383906 0.03468409 0.03058576
  0.02840575 0.03258299 0.03165643 0.03539727 0.07105747 0.04191247
  0.04171472 0.03688961]
 [0.02992393 0.07157832 0.0724494  0.03298473 0.02489082 0.03696196
  0.0495047  0.04066866 0.04866315 0.03101111 0.02961585 0.02999596
  0.03079083 0.01863827 0.01723574 0.04988698 0.03524845 0.02940389
  0.02855364 0.03491971 0.0302656  0.03189853 0.07179745 0.03470344
  0.03076599 0.03091786]
 [0.03003842 0.03810993 0.04499893 0.02527431 0.01993606 0.02718418
  0.03772427 0.03104844 0.03697187 0.02526329 0.02475918 0.02346684
  0.02355406 0.01556659 0.01493112 0.04049168 0.03020305 0.02450279
  0.02629753 0.03069697 0.02973697 0.03064456 0.0585931  0.0511776
  0.0484622  0.03789183]
 [0.03021988 0.01509662 0.01666423 0.01345787 0.01112535 0.01515324
  0.01634423 0.01562211 0.01763982 0.01419746 0.01585038 0.01354887
  0.01439188 0.00780262 0.00770738 0.01865809 0.01805613 0.01795699
  0.02103191 0.02476328 0.02869824 0.01947912 0.03695224 0.06579269
  0.0786308  0.05181899]
 [0.03024071 0.02396167 0.02490406 0.01958635 0.01580306 0.02202778
  0.02495189 0.02222193 0.02324106 0.02024115 0.02406976 0.02016205
  0.01992775 0.01143033 0.01223431 0.03316068 0.02586039 0.02467333
  0.02406209 0.02608732 0.02800107 0.0289018  0.03067681 0.05971143
  0.06015428 0.04030329]
 [0.03019858 0.02803181 0.02757743 0.02441581 0.01937388 0.02724878
  0.0371043  0.03516684 0.02816054 0.02660097 0.03151529 0.03117842
  0.03406563 0.01453456 0.01286349 0.03375646 0.02956423 0.03042482
  0.02690662 0.02826224 0.03156577 0.03251213 0.02410827 0.05092376
  0.03884059 0.02448549]
 [0.02998125 0.02249501 0.01832012 0.01773269 0.01313469 0.01775668
  0.02928646 0.02687342 0.01907336 0.01790995 0.0262071  0.02020469
  0.02421855 0.00920556 0.00924819 0.02969545 0.02788967 0.03675745
  0.03758395 0.03813795 0.04765175 0.0288792  0.01840945 0.07053344
  0.04969689 0.03179535]
 [0.03048308 0.02357701 0.02063242 0.01877125 0.01585954 0.02024807
  0.03088378 0.03023584 0.02054978 0.02051056 0.0360637  0.02745806
  0.02831318 0.01047492 0.00984257 0.02933185 0.02994036 0.02994355
  0.02917802 0.02640736 0.0365098  0.02835616 0.01831335 0.06271096
  0.03660863 0.02153572]
 [0.03047959 0.018711   0.0159574  0.01330193 0.01279442 0.01499072
  0.0252947  0.02174311 0.01733825 0.01519878 0.03900048 0.02019028
  0.02260383 0.00754088 0.00791414 0.02858509 0.03392958 0.03120032
  0.0338314  0.02921061 0.03815983 0.02512459 0.01615887 0.06649377
  0.03701532 0.02775528]
 [0.0292237  0.03462148 0.02558388 0.02097699 0.02616179 0.02187837
  0.03717724 0.03149189 0.02744449 0.02260818 0.03766767 0.02329869
  0.02712709 0.01179784 0.01428924 0.02806209 0.05199146 0.04280508
  0.06116325 0.04921213 0.04889733 0.03260148 0.03531371 0.06063734
  0.05087028 0.0537906 ]
 [0.03084969 0.01971676 0.01725492 0.01552374 0.0134252  0.0168532
  0.02148945 0.02152846 0.01821724 0.01735557 0.03440985 0.02075959
  0.02091427 0.00861021 0.00864441 0.02353456 0.03029732 0.02965509
  0.03017145 0.02702752 0.0301826  0.02604151 0.0160952  0.03785044
  0.03323147 0.03023403]
 [0.03123511 0.02207095 0.02387847 0.02141588 0.01750306 0.02618884
  0.02670655 0.03315363 0.02733872 0.0264141  0.02594873 0.03219094
  0.02921012 0.01281903 0.01025584 0.0203159  0.02457955 0.02248551
  0.02383643 0.02186406 0.02234902 0.02886668 0.01698174 0.01817488
  0.02298523 0.02245588]
 [0.03102987 0.02358558 0.02293752 0.0193677  0.01556769 0.02333
  0.02639084 0.03024292 0.02598522 0.02146983 0.02266533 0.02844475
  0.02746614 0.01152593 0.00969448 0.02066945 0.02654875 0.02452737
  0.02884403 0.02803051 0.02757651 0.03036192 0.01892119 0.01973902
  0.03111918 0.03309955]
 [0.03121045 0.02556111 0.02449887 0.02035964 0.01688574 0.02693383
  0.03093692 0.03665405 0.03010004 0.02423239 0.03122494 0.04272508
  0.03403841 0.01185616 0.01021749 0.02448254 0.03107421 0.02904745
  0.03053735 0.0278197  0.027656   0.02656003 0.01872899 0.01749798
  0.01904473 0.02186724]
 [0.03143072 0.02557139 0.02535247 0.02110882 0.01710092 0.03014396
  0.02878527 0.03170181 0.03251404 0.02540967 0.02299149 0.03500028
  0.03160159 0.01269697 0.00959567 0.0190923  0.02424272 0.02208028
  0.0257226  0.02517417 0.02409481 0.02659028 0.02126607 0.01573621
  0.02244912 0.02673829]
 [0.03058592 0.04284658 0.03482318 0.02435311 0.01919096 0.03155622
  0.03862557 0.04475522 0.04030489 0.02898512 0.02963376 0.04352861
  0.04414063 0.01448845 0.01093049 0.0357203  0.02833196 0.03740389
  0.03162742 0.03742642 0.0317972  0.02968261 0.02609637 0.01928513
  0.02649956 0.02524043]
 [0.03134478 0.0326965  0.03455395 0.02722603 0.01961462 0.04932199
  0.03828797 0.04157679 0.04489136 0.03406643 0.02834317 0.06667175
  0.05147831 0.01665151 0.01107502 0.02518558 0.02434594 0.02618783
  0.0240095  0.02598881 0.02248149 0.02802329 0.02114113 0.01298448
  0.01531732 0.01740539]
 [0.03080475 0.02232881 0.02231443 0.01745135 0.01313873 0.01904074
  0.02595738 0.03012852 0.02598522 0.02036106 0.02506616 0.02501445
  0.03576539 0.0095941  0.00844324 0.03292172 0.02757841 0.03352834
  0.03141301 0.03481661 0.03617749 0.02879107 0.0155198  0.02772649
  0.02974244 0.02180815]
 [0.0305599  0.02263208 0.02044423 0.01704139 0.01227931 0.01669673
  0.02604387 0.02825684 0.02438017 0.01847212 0.02279707 0.02025394
  0.02810681 0.00890382 0.00837872 0.03917548 0.02808653 0.04245402
  0.0372095  0.04518641 0.04239935 0.02687396 0.01511377 0.02800752
  0.03899919 0.02938499]
 [0.03116643 0.01927385 0.0180644  0.01543693 0.01155573 0.01676336
  0.02260851 0.0243578  0.02382133 0.01752375 0.02282777 0.02037945
  0.02481386 0.0086197  0.0074902  0.03536701 0.02622438 0.03977801
  0.03129973 0.0370783  0.03352831 0.02307433 0.01195263 0.01945435
  0.03996826 0.02916288]
 [0.03110739 0.0174174  0.01581513 0.01253024 0.00990549 0.01343108
  0.0192586  0.01993039 0.02043687 0.01484061 0.02336498 0.01659482
  0.02113538 0.00735509 0.00652852 0.03072055 0.02878128 0.0317611
  0.03420764 0.03443124 0.03420122 0.02486733 0.01169315 0.02230642
  0.03125734 0.03463133]
 [0.0304103  0.01951116 0.01752775 0.01429065 0.01190676 0.01467778
  0.01948054 0.01966503 0.02267507 0.01609731 0.02026577 0.01659362
  0.02091994 0.00811182 0.00722222 0.02796542 0.02870266 0.027783
  0.04311254 0.0390072  0.0341294  0.02671491 0.01652946 0.0268864
  0.03161733 0.05492631]
 [0.0313828  0.02067968 0.01939073 0.01604463 0.01188793 0.01685724
  0.019765   0.02129612 0.0245574  0.01773709 0.01974007 0.01953328
  0.02158329 0.00961647 0.00773125 0.01996343 0.02157813 0.02140312
  0.03024337 0.02997727 0.02597883 0.02732903 0.01756796 0.01692442
  0.02535341 0.03923433]
 [0.03087421 0.02428978 0.02501571 0.02557816 0.01940884 0.02713875
  0.02610117 0.03094111 0.03418484 0.03077285 0.02507767 0.0366752
  0.03466888 0.01758251 0.01222872 0.02082206 0.0258949  0.02455157
  0.02370652 0.02416353 0.02431699 0.03192825 0.02288298 0.01620582
  0.0349254  0.03400112]
 [0.03010949 0.03532312 0.03333477 0.05304052 0.05546268 0.04707389
  0.02932084 0.02833939 0.03298998 0.05193122 0.03633487 0.03074844
  0.03170364 0.08800545 0.10189292 0.02907497 0.02746496 0.02371769
  0.02157402 0.0223801  0.02087775 0.03509863 0.03714564 0.00987041
  0.00856643 0.02094543]
 [0.02984445 0.03422655 0.03211739 0.05865132 0.1170677  0.04149754
  0.0246591  0.02557138 0.03083753 0.0589591  0.04118899 0.03370732
  0.02670527 0.08647774 0.10637134 0.03181217 0.04235253 0.03982179
  0.02998579 0.02661204 0.02704661 0.02969826 0.03437912 0.0088611
  0.00729623 0.01986936]
 [0.02986733 0.02593977 0.02448536 0.03729171 0.07157911 0.02450503
  0.01832083 0.02206272 0.02436302 0.04095571 0.03411566 0.02981339
  0.02427411 0.02881755 0.03620178 0.02468131 0.05089852 0.05666182
  0.05224578 0.03598446 0.03719867 0.02574306 0.02722076 0.0146985
  0.01504538 0.02400845]
 [0.03000242 0.03353777 0.02890106 0.0411228  0.05540081 0.02940906
  0.02418084 0.02428704 0.0296441  0.03905587 0.03347484 0.02647497
  0.02517219 0.03187093 0.03448519 0.02137412 0.03450736 0.03698138
  0.03797143 0.03374165 0.0311942  0.0471697  0.04075906 0.0123251
  0.01241984 0.02360471]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Julie', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.1935, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.03019334 0.04677182 0.04904974 0.06817653 0.05924265 0.05151175
  0.03716691 0.04238744 0.0524728  0.05150942 0.03461113 0.03553291
  0.03692419 0.10682851 0.09945868 0.02995512 0.02537325 0.02087709
  0.02124642 0.02230169 0.01712616 0.03521835 0.05278182 0.02339315
  0.01601744 0.0346746  0.046725   0.04160209 0.09736719 0.01545785
  0.01530874 0.01126978]
 [0.03103161 0.04667374 0.04360313 0.0788477  0.07972822 0.08126309
  0.04278293 0.04301681 0.05313671 0.06790198 0.0495793  0.05262078
  0.05105264 0.15672629 0.12782887 0.03533965 0.02501628 0.02278904
  0.02186745 0.02262036 0.01745529 0.0384444  0.04244336 0.01831992
  0.01343636 0.02808914 0.04746128 0.03374449 0.08996026 0.0172368
  0.01692859 0.014014  ]
 [0.03159154 0.04410843 0.04831691 0.06756681 0.06060501 0.06053665
  0.03916387 0.04281301 0.05002477 0.05594845 0.03761262 0.04730299
  0.04528506 0.11206434 0.07794537 0.02910124 0.02423044 0.01983626
  0.02009986 0.02021882 0.01542142 0.03435693 0.03953044 0.02051753
  0.01607314 0.02568209 0.0401835  0.02894511 0.08140596 0.03071684
  0.02649921 0.01970795]
 [0.03038906 0.03856403 0.04116498 0.0369365  0.03152291 0.03445002
  0.03254937 0.03923861 0.03815005 0.0336272  0.0287521  0.03498018
  0.03487118 0.02841659 0.02676431 0.03078933 0.02873486 0.02446096
  0.02519694 0.02547353 0.02121534 0.03565593 0.04779084 0.03802256
  0.04327019 0.03999417 0.04570555 0.03669271 0.07590202 0.09502599
  0.05180037 0.03828135]
 [0.03154799 0.0301509  0.03381054 0.02820006 0.02175445 0.03016132
  0.02906663 0.03062725 0.03299879 0.02588401 0.02424251 0.02571762
  0.02631015 0.01782876 0.01896841 0.0231548  0.02025026 0.01828077
  0.02169717 0.02226901 0.01875999 0.03127351 0.0356517  0.02848112
  0.02863896 0.04189137 0.03497295 0.03783152 0.05663726 0.06755909
  0.04975621 0.04380581]
 [0.03142248 0.04454211 0.04700278 0.03004645 0.02223742 0.03353697
  0.03568623 0.03869715 0.04511787 0.02832046 0.02303047 0.02924433
  0.03012037 0.02224442 0.01998962 0.03002703 0.02429215 0.01918045
  0.02081771 0.02168664 0.01697604 0.03493951 0.05603397 0.03395724
  0.03231159 0.0380751  0.05522046 0.02510102 0.05067322 0.12066714
  0.04874786 0.04069771]
 [0.03149663 0.06109561 0.05301003 0.0280277  0.02086641 0.03034893
  0.03886739 0.03504681 0.04615159 0.02533902 0.0236095  0.02644021
  0.02728972 0.0164045  0.01781583 0.03996428 0.03323928 0.02791631
  0.02915081 0.0348509  0.0270027  0.03246636 0.074581   0.04841188
  0.04546227 0.05100313 0.05352136 0.02706688 0.02568409 0.08665743
  0.0294394  0.03225053]
 [0.03179901 0.03376594 0.03318792 0.02201884 0.01710477 0.02325853
  0.02813119 0.024905   0.03167961 0.02063497 0.01995047 0.02016835
  0.02009441 0.0142809  0.01589695 0.02729089 0.02442321 0.01968741
  0.02338529 0.02475671 0.01938237 0.02877454 0.04424223 0.03621029
  0.03553502 0.03834644 0.04230737 0.02096692 0.02220828 0.07194402
  0.02983126 0.02309466]
 [0.0320681  0.0219615  0.02549325 0.01899394 0.01489592 0.02061665
  0.0234881  0.02237354 0.02649591 0.01960269 0.02053277 0.01935158
  0.01981277 0.01228624 0.01357399 0.02134638 0.0204063  0.02019821
  0.02372051 0.02483991 0.02115538 0.02614765 0.02888004 0.02861168
  0.02890129 0.03568118 0.03035709 0.02859864 0.01987117 0.03315049
  0.03333803 0.02638285]
 [0.03189805 0.0250739  0.02788595 0.02163965 0.01765352 0.02407847
  0.02439286 0.02338652 0.02688734 0.0216352  0.0220556  0.02230004
  0.02173116 0.01420074 0.01527355 0.02535781 0.02756095 0.02349428
  0.02737454 0.03063093 0.02801985 0.03171629 0.03376371 0.03624539
  0.04688891 0.03616478 0.03369864 0.02409985 0.02769104 0.05004682
  0.0407035  0.03200688]
 [0.03184728 0.02884372 0.03108173 0.02609943 0.02215086 0.02817817
  0.03000547 0.02991996 0.03029772 0.02851708 0.0275924  0.03197803
  0.03241783 0.01818541 0.01707466 0.03124048 0.03646372 0.03470892
  0.03364423 0.03609141 0.03622404 0.03383785 0.03028785 0.036251
  0.06209151 0.03076424 0.02936596 0.02893511 0.02714526 0.0437622
  0.04691834 0.04343504]
 [0.03161579 0.02483484 0.02266388 0.01942484 0.01546891 0.02101272
  0.02316606 0.02062929 0.02150684 0.0207055  0.02272459 0.02134069
  0.02369384 0.01175883 0.01347297 0.03108563 0.03220204 0.04291695
  0.03709927 0.06424949 0.06862675 0.03105957 0.02380266 0.03550279
  0.07518289 0.03497877 0.02721377 0.02555395 0.01588038 0.02606031
  0.03249441 0.04419141]
 [0.03257816 0.02418968 0.02416672 0.02022631 0.0181088  0.02497206
  0.02668118 0.02491498 0.024688   0.0244542  0.02908251 0.02931386
  0.02810632 0.0137105  0.01449313 0.03004861 0.02929071 0.03492752
  0.03555806 0.05849114 0.0657683  0.02779538 0.02142267 0.02941463
  0.04056153 0.02717009 0.02979073 0.02481396 0.01564552 0.0212115
  0.03264916 0.04671263]
 [0.03334422 0.01949886 0.01928627 0.01494351 0.0141931  0.01994958
  0.02115206 0.0194225  0.02049692 0.01914746 0.02607775 0.02371795
  0.02232634 0.01054136 0.01168181 0.0282186  0.02809895 0.03021603
  0.03493035 0.04018583 0.05315543 0.02583421 0.01679273 0.02703173
  0.0331444  0.02710882 0.02578371 0.0234422  0.01304563 0.01606216
  0.02700588 0.03969557]
 [0.03278792 0.02046277 0.02065825 0.01423899 0.01463972 0.01943816
  0.02407594 0.01991201 0.02086023 0.01830539 0.03580518 0.02497126
  0.02366904 0.01033922 0.01201994 0.03579751 0.03732299 0.0364539
  0.04606608 0.0463713  0.04847627 0.02883733 0.01937371 0.03384494
  0.0387926  0.03491531 0.02568459 0.02576984 0.01249986 0.01792608
  0.02866192 0.03671459]
 [0.03138033 0.048882   0.03880671 0.02373381 0.02346129 0.03077141
  0.07169449 0.04980599 0.04138959 0.02777546 0.05694152 0.0353428
  0.04829462 0.01419145 0.01619792 0.06495581 0.05126767 0.06494417
  0.05546026 0.06244741 0.05354408 0.03422924 0.03965685 0.0741023
  0.06321271 0.07006913 0.029281   0.04511501 0.01787963 0.02196517
  0.03530607 0.04752197]
 [0.03284013 0.02580947 0.02687763 0.0209416  0.01989008 0.02613666
  0.02807837 0.0281877  0.02602231 0.02543519 0.0292608  0.03055221
  0.02958718 0.01575162 0.0151181  0.03104343 0.02812598 0.02922188
  0.0344963  0.02992525 0.03058243 0.03232706 0.02335976 0.02989894
  0.02539037 0.02727075 0.0234333  0.0307351  0.02305918 0.02351784
  0.05551181 0.04694569]
 [0.03293591 0.02708141 0.03195368 0.02781871 0.0247821  0.03248772
  0.03253915 0.04094889 0.03243003 0.03645476 0.03272028 0.04340398
  0.03910652 0.02190288 0.01737511 0.02507734 0.02655736 0.0272995
  0.02633082 0.02314479 0.02133089 0.03454694 0.02406185 0.02525245
  0.02183723 0.02590092 0.02572707 0.03394331 0.0300936  0.0260949
  0.06387565 0.04931331]
 [0.03333043 0.03453216 0.03904501 0.03351086 0.02711386 0.03942665
  0.04004989 0.05024955 0.03493213 0.04324261 0.0387854  0.05460637
  0.04892522 0.02489312 0.01911497 0.03109425 0.02779808 0.02937677
  0.02861058 0.0249179  0.02237036 0.03641121 0.02684836 0.0261256
  0.02013208 0.02247744 0.03140486 0.02568454 0.02750238 0.02509675
  0.04146476 0.04784189]
 [0.0333565  0.03181054 0.03331327 0.02938502 0.02572381 0.03583837
  0.03587877 0.03867517 0.03298365 0.03752979 0.03478288 0.04505864
  0.04472176 0.02221073 0.01803201 0.03371964 0.02915354 0.03120963
  0.03034211 0.02764183 0.02471367 0.03473386 0.02256219 0.03024426
  0.02623396 0.02144132 0.02674652 0.02808688 0.02301635 0.02395431
  0.03283885 0.0427168 ]
 [0.03332428 0.02491146 0.02448768 0.01971785 0.01623577 0.02373382
  0.02811074 0.02786203 0.02520269 0.02367839 0.02932459 0.02917656
  0.03167563 0.01341078 0.01282497 0.0356556  0.03352435 0.03355329
  0.03274675 0.02944836 0.03032026 0.03156088 0.01664085 0.03446611
  0.03587462 0.02382648 0.02239968 0.03003275 0.0155483  0.02050969
  0.02872807 0.03689997]
 [0.03328189 0.02731127 0.025912   0.02209425 0.01664777 0.02387418
  0.03134472 0.03032156 0.02485019 0.02354802 0.02877991 0.02735555
  0.03198208 0.01348513 0.01357399 0.0397332  0.03597366 0.04233145
  0.03511065 0.03231491 0.03750029 0.02834147 0.01743479 0.03720627
  0.03837125 0.02468864 0.02184748 0.0303251  0.01321408 0.018929
  0.02459357 0.03531308]
 [0.03335894 0.02650214 0.02546983 0.02252514 0.01827325 0.02416741
  0.02851286 0.02950038 0.02418844 0.0253091  0.03088504 0.03027937
  0.03074566 0.01465381 0.01478468 0.03613599 0.03994415 0.03750791
  0.03919873 0.03163597 0.0351443  0.03058646 0.01952376 0.04081045
  0.02820145 0.02150477 0.02443859 0.03730564 0.0164146  0.02198246
  0.03026805 0.03458743]
 [0.03357852 0.02901229 0.02704155 0.02307454 0.01740079 0.0253459
  0.03218815 0.03202185 0.02789726 0.02539459 0.03283641 0.02984194
  0.03214681 0.01466194 0.01494641 0.03732835 0.03473498 0.03693669
  0.03550196 0.03128982 0.03431709 0.03076864 0.02034408 0.04075149
  0.03013119 0.02506502 0.02462266 0.03247038 0.01540439 0.01945252
  0.02736779 0.03405989]
 [0.03351731 0.02236913 0.02250684 0.01669726 0.01354914 0.02025393
  0.02951986 0.02590399 0.02183555 0.01809808 0.03803789 0.024562
  0.0274208  0.01128717 0.01162999 0.03817504 0.04012008 0.03466552
  0.042792   0.03391791 0.03639035 0.02901525 0.0170601  0.04058024
  0.03185521 0.02744143 0.01854841 0.02989628 0.01361354 0.01736559
  0.02805666 0.03108949]
 [0.03225078 0.02326715 0.02287326 0.01721434 0.01200675 0.02070698
  0.02968003 0.02684904 0.0252481  0.01791    0.02978095 0.02136182
  0.02776444 0.01103044 0.01175352 0.03478159 0.03474467 0.0349039
  0.04360134 0.03546967 0.03514036 0.0314455  0.02052869 0.04080765
  0.03634358 0.04716936 0.021182   0.03565624 0.01501503 0.01457508
  0.03317954 0.03023779]
 [0.03342232 0.02462643 0.02627429 0.02595077 0.01863332 0.02867431
  0.03105847 0.03424562 0.02783455 0.02760876 0.03178957 0.03139274
  0.0325684  0.01901138 0.01680091 0.02776937 0.02712494 0.02930208
  0.03408496 0.0258598  0.02658472 0.03087146 0.01866253 0.0215114
  0.01845209 0.02052007 0.01874664 0.02784335 0.02154218 0.01523574
  0.03956286 0.03249948]
 [0.03210379 0.03446167 0.03565914 0.0555534  0.05297442 0.04658376
  0.03227164 0.03320267 0.03688494 0.0516633  0.03640711 0.03812844
  0.03810038 0.07284037 0.09843695 0.02620785 0.02714279 0.02803165
  0.02442233 0.02267384 0.02018112 0.03374973 0.0373778  0.0182736
  0.01457822 0.02810227 0.03163141 0.04016974 0.0440373  0.01060485
  0.01548969 0.01067337]
 [0.03177298 0.04084431 0.03818546 0.07266647 0.15151772 0.05425368
  0.0336569  0.03439147 0.03701253 0.06876116 0.05083878 0.04869009
  0.03497923 0.09509292 0.12861453 0.03471207 0.04479738 0.04393417
  0.03138249 0.02749623 0.03015395 0.03263789 0.04515894 0.01759909
  0.01306622 0.02953993 0.0457905  0.03878681 0.0416126  0.00835724
  0.00918562 0.00758699]
 [0.03194087 0.03105198 0.02823997 0.04352276 0.07710563 0.02790856
  0.02534193 0.02755833 0.02627749 0.04209705 0.0374147  0.03277808
  0.02702224 0.0318901  0.04708944 0.02993929 0.05980531 0.05715961
  0.04687942 0.0352639  0.05209013 0.02960256 0.0377243  0.02645969
  0.02189024 0.02925656 0.03616232 0.04719617 0.02347116 0.01084187
  0.01268802 0.01089319]
 [0.03199386 0.03698868 0.03297165 0.05020597 0.05451162 0.0365235
  0.03369779 0.03298488 0.03404547 0.04396072 0.03615522 0.03248851
  0.03125404 0.03786942 0.04144849 0.02495365 0.04227974 0.04367766
  0.03718474 0.03151489 0.03487075 0.04281403 0.04567641 0.02169459
  0.01812148 0.03118657 0.03004559 0.05358848 0.02695853 0.00803227
  0.0118001  0.00955895]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Julie', ' was', ' mentioned', ' in', ' context', ' sentence', ' ', '5', ',', ' but', ' it', ' didn', "'t", ' mention', ' the', ' office', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 38), x_tokens=38, y_tokens=39, max_supp_attn=0.0513, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 38)
DEBUG result.interpretability.attn_scores 1482 
 [[0.02380257 0.02815501 0.02666538 ... 0.01544437 0.00941763 0.01391068]
 [0.02412834 0.021716   0.02079624 ... 0.01441285 0.01266518 0.01545376]
 [0.02485423 0.0287411  0.02881749 ... 0.01198921 0.00803639 0.01004368]
 ...
 [0.02553412 0.02404644 0.02056209 ... 0.01184141 0.01013911 0.01251786]
 [0.02577488 0.02617324 0.0246527  ... 0.01254027 0.008844   0.01275828]
 [0.0259237  0.02239845 0.02200904 ... 0.01162658 0.00770589 0.01171135]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' went', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Fred', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.1333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03140176 0.04083686 0.04593998 ... 0.01546946 0.01035039 0.00510115]
 [0.03153941 0.03027845 0.03538372 ... 0.02797815 0.01260314 0.00793948]
 [0.03279654 0.04174999 0.05148532 ... 0.0255466  0.0146823  0.00629626]
 ...
 [0.0330103  0.04997679 0.04480841 ... 0.00691919 0.00548004 0.0046485 ]
 [0.03334628 0.03651633 0.03020187 ... 0.01002044 0.00842377 0.00950581]
 [0.03311535 0.04593605 0.03680737 ... 0.00673733 0.00575643 0.00563934]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' mention', ' Bill', "'s", ' movements', ',', ' but', ' not', ' Fred', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 50), x_tokens=50, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 50)
DEBUG result.interpretability.attn_scores 1700 
 [[0.02739814 0.03229246 0.03074389 ... 0.02520909 0.01480587 0.02926826]
 [0.02807415 0.03836377 0.02878233 ... 0.03061478 0.02574678 0.02354609]
 [0.02857104 0.03639022 0.03587289 ... 0.02231483 0.01396096 0.02372104]
 ...
 [0.02927262 0.02617322 0.02584431 ... 0.03104344 0.02074254 0.03791514]
 [0.02967496 0.03270498 0.03045998 ... 0.01968888 0.01298716 0.0244774 ]
 [0.02945392 0.02812625 0.02740867 ... 0.02057728 0.01112867 0.02540518]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 26), x_tokens=26, y_tokens=30, max_supp_attn=0.1333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 26)
DEBUG result.interpretability.attn_scores 780 
 [[0.03131693 0.05477686 0.05840094 0.08729773 0.07550617 0.0628152
  0.04374602 0.03791966 0.04233418 0.05872803 0.03879085 0.03083899
  0.03254361 0.12987424 0.13102202 0.03510442 0.03171948 0.02262226
  0.0255091  0.02768303 0.02654945 0.04714666 0.07951782 0.01067011
  0.0090536  0.02953154]
 [0.03233865 0.03421765 0.03475313 0.06310889 0.05398217 0.05286353
  0.03090585 0.02795055 0.03430162 0.05125652 0.03350195 0.03308681
  0.03265666 0.13748014 0.15684296 0.03351749 0.03426554 0.02618915
  0.02820636 0.02893034 0.02519215 0.03936164 0.04701597 0.00886192
  0.00707377 0.01930796]
 [0.03283666 0.03823609 0.04518718 0.06707727 0.05861775 0.06640917
  0.04103342 0.0391699  0.04503551 0.06039151 0.03925294 0.05308852
  0.05093114 0.10827866 0.09455701 0.02849034 0.03134666 0.02666123
  0.02726125 0.02860709 0.02382048 0.03557856 0.04330195 0.01438579
  0.00994659 0.01866606]
 [0.03162614 0.05077411 0.05852264 0.05227527 0.05147787 0.06017482
  0.04844957 0.05062433 0.04809735 0.05191092 0.03965325 0.05658893
  0.05142935 0.0652656  0.05461851 0.04043572 0.0400581  0.03377597
  0.03279265 0.03463631 0.03194139 0.03990423 0.05888085 0.03349698
  0.03253736 0.03667533]
 [0.03289765 0.0529873  0.06117968 0.0612177  0.0524209  0.07176987
  0.05661188 0.06036624 0.05892926 0.06200504 0.04159684 0.06070672
  0.05989881 0.04879472 0.0308859  0.02803633 0.03202257 0.02962778
  0.0303275  0.03315653 0.0273521  0.04094864 0.04649628 0.02601406
  0.0174373  0.02508748]
 [0.03223114 0.06450085 0.0665865  0.03599192 0.02808998 0.04516395
  0.05506466 0.05112337 0.05156788 0.03565411 0.03196123 0.04228615
  0.04418502 0.02172985 0.01828106 0.04794325 0.04177848 0.03248881
  0.03467038 0.03608388 0.03417393 0.03878502 0.0805139  0.04248947
  0.03805026 0.0406499 ]
 [0.03293237 0.0502988  0.05681212 0.02971757 0.02407918 0.03348438
  0.05615881 0.04172817 0.04851934 0.0287987  0.02610341 0.03019696
  0.03126458 0.01680517 0.01633786 0.04713695 0.03935586 0.02985699
  0.03506437 0.03744454 0.03529873 0.03414867 0.06964213 0.03020572
  0.03776989 0.04197145]
 [0.03342656 0.01968888 0.02286354 0.01450573 0.01244328 0.01751649
  0.0214357  0.02049111 0.02797192 0.01634341 0.0147855  0.01607557
  0.01651302 0.0081046  0.00854517 0.02174171 0.02377182 0.0197513
  0.02605843 0.02750144 0.02823123 0.02446815 0.04994747 0.0320533
  0.06605598 0.06932046]
 [0.03307816 0.03195001 0.03328987 0.0200822  0.01760189 0.02534284
  0.03218917 0.02721905 0.0284155  0.02060618 0.02310306 0.02360684
  0.02338008 0.01110845 0.01149935 0.0410102  0.02885895 0.0262057
  0.02873545 0.03044103 0.02937855 0.03256088 0.03732247 0.04034209
  0.06586906 0.05487886]
 [0.03326759 0.02892095 0.02969305 0.02258239 0.01923621 0.02830184
  0.0320759  0.03181159 0.02972795 0.02578645 0.02848078 0.03292596
  0.03218869 0.0126758  0.01113447 0.04130547 0.03141283 0.03143046
  0.02947583 0.02945902 0.02980044 0.03328334 0.02497747 0.03983603
  0.06291807 0.03448534]
 [0.03249805 0.02686467 0.02182816 0.01800008 0.01424064 0.01917586
  0.02829368 0.02704307 0.0236973  0.01876619 0.02658609 0.02252879
  0.02698056 0.00855466 0.00864459 0.05928008 0.02999982 0.04808529
  0.03801398 0.04328057 0.04810479 0.03121766 0.01900919 0.04602708
  0.11317489 0.05018191]
 [0.03384065 0.02597588 0.02438475 0.02153063 0.0189323  0.0257848
  0.0292839  0.0289749  0.02566433 0.02308225 0.02650629 0.02831123
  0.02805321 0.01075155 0.00987817 0.03795732 0.02226312 0.0353784
  0.02864023 0.0414022  0.0313196  0.02626411 0.02000453 0.03400877
  0.0742494  0.03100859]
 [0.03372236 0.02249828 0.01967721 0.01613028 0.01330283 0.01866081
  0.02462239 0.02408687 0.02225028 0.01795693 0.02923119 0.02523247
  0.02556876 0.00809638 0.00809688 0.04867919 0.02783192 0.04841008
  0.03632015 0.04720089 0.03746219 0.02507267 0.01511521 0.03664312
  0.06880479 0.03757855]
 [0.03356981 0.02213003 0.01916531 0.01450738 0.01227111 0.01714076
  0.02486177 0.02317283 0.02206587 0.0164583  0.03755905 0.02407297
  0.02375472 0.00741751 0.00785259 0.04126819 0.03139006 0.04331938
  0.03834786 0.04049488 0.03628381 0.02680215 0.01569016 0.04333927
  0.05025142 0.05802473]
 [0.03252542 0.03020014 0.02543367 0.01931189 0.01749363 0.0243093
  0.03362545 0.03034728 0.03094738 0.02150869 0.03469128 0.02502165
  0.02820438 0.0102919  0.01059037 0.02531871 0.03516627 0.03227408
  0.04291809 0.03932484 0.0400029  0.03154377 0.02876094 0.0877021
  0.04554816 0.07000607]
 [0.0341543  0.02782175 0.02596488 0.02007891 0.01596235 0.02258597
  0.02814771 0.02856122 0.02642854 0.02091923 0.03119023 0.02662879
  0.0270384  0.0103926  0.00977617 0.02742679 0.02675686 0.03163154
  0.03252959 0.03043073 0.03123537 0.03074809 0.0189293  0.03254503
  0.02270489 0.03747621]
 [0.03428895 0.02852779 0.03175321 0.02932584 0.02227921 0.03198261
  0.03176529 0.03855659 0.03188935 0.03275841 0.03226371 0.0426277
  0.03827887 0.01637428 0.0113816  0.02307855 0.02571489 0.02906757
  0.02808733 0.02734367 0.02647881 0.03305221 0.01949528 0.03122976
  0.0189757  0.02100063]
 [0.03448273 0.03406999 0.03549876 0.0340316  0.02401396 0.03622755
  0.03935309 0.04809495 0.03360884 0.03766394 0.0398682  0.04873116
  0.04734907 0.01790533 0.01231485 0.02448772 0.02516563 0.03031128
  0.0275618  0.02754587 0.02538    0.03333004 0.02030171 0.03040432
  0.01590969 0.01549982]
 [0.03438397 0.0309957  0.03086946 0.03050598 0.0227905  0.03273064
  0.03532214 0.04050813 0.0332583  0.03509462 0.03697468 0.04275296
  0.04469505 0.01665926 0.01246282 0.02941859 0.02677323 0.03264438
  0.03007575 0.02983186 0.0290626  0.03287927 0.01756733 0.0267784
  0.01926775 0.01435217]
 [0.03417443 0.02411341 0.02253709 0.0183556  0.01333544 0.02005523
  0.02625135 0.02835635 0.02643519 0.02099582 0.02699154 0.02653502
  0.03017747 0.00941985 0.00855421 0.03533031 0.02941925 0.03301013
  0.03234985 0.03033929 0.03554597 0.030943   0.01480683 0.03656864
  0.03181039 0.01998612]
 [0.03413648 0.02623153 0.02324892 0.01960652 0.01349196 0.01962925
  0.03013516 0.0302107  0.02662956 0.02093755 0.03012189 0.02555759
  0.0312304  0.00930545 0.0084943  0.04207597 0.03020152 0.03789313
  0.03464181 0.03318422 0.03994313 0.02832188 0.01398846 0.0401855
  0.03376394 0.02186261]
 [0.03428613 0.02502988 0.0220194  0.01941394 0.01504802 0.01973432
  0.02583915 0.02829725 0.02608963 0.02245782 0.03024289 0.02794983
  0.02898652 0.01004323 0.00880031 0.03170937 0.03343523 0.03381817
  0.03698733 0.03125368 0.036899   0.02800349 0.01385779 0.04041084
  0.02380747 0.02076315]
 [0.03445799 0.0275421  0.0247199  0.02028465 0.01489672 0.02175343
  0.02987593 0.03121667 0.03113344 0.02316551 0.03373364 0.02908879
  0.03136317 0.01052275 0.00908436 0.03369203 0.03032497 0.03523483
  0.03416152 0.03296979 0.03583436 0.02901881 0.0157484  0.03566633
  0.02474201 0.02202408]
 [0.03452152 0.02227678 0.02034655 0.01424073 0.01204546 0.0161038
  0.02561495 0.02476847 0.02507289 0.01685461 0.04112188 0.02323106
  0.02549383 0.00808267 0.00704019 0.03161703 0.03474543 0.03301468
  0.03951795 0.034201   0.03669097 0.02709165 0.01422292 0.03724751
  0.0219923  0.03318815]
 [0.03303644 0.02842719 0.02583642 0.01617143 0.01360022 0.01978228
  0.03141614 0.03126001 0.0312946  0.01909256 0.0394576  0.02485464
  0.02940716 0.00915201 0.00845092 0.02325655 0.03071558 0.02827773
  0.03837524 0.03675101 0.04444043 0.03158611 0.02638423 0.07877644
  0.03553778 0.06642697]
 [0.03445403 0.02650195 0.02654825 0.02415756 0.01792406 0.0268035
  0.0274576  0.03387081 0.03173983 0.0273417  0.03011031 0.03181027
  0.02985936 0.01485283 0.01163906 0.01891892 0.02880772 0.02744734
  0.03142378 0.02789811 0.03016452 0.02994252 0.01840736 0.02648574
  0.01376383 0.02506562]
 [0.03304366 0.03466897 0.03371678 0.05300772 0.05449999 0.04737378
  0.0296167  0.0297563  0.03573036 0.05184765 0.0350195  0.03607523
  0.03602578 0.09242088 0.10846748 0.02423443 0.03151066 0.02648291
  0.02888365 0.02834049 0.02659835 0.03807047 0.04153379 0.01108928
  0.00839875 0.02229832]
 [0.03293862 0.03612074 0.03380756 0.05761802 0.10859825 0.04502462
  0.02722172 0.02771941 0.03463222 0.05899945 0.04071128 0.03542018
  0.02968321 0.08792845 0.11086388 0.02933515 0.04469237 0.03695725
  0.03535362 0.03184675 0.03184164 0.03450605 0.03987763 0.00917056
  0.00666109 0.01856223]
 [0.03267403 0.0328591  0.0303025  0.04960884 0.10997561 0.03261644
  0.02314407 0.02738058 0.03065664 0.05450023 0.04198299 0.04079262
  0.03037991 0.04066067 0.05032462 0.02584999 0.07238092 0.05941939
  0.04873457 0.03711484 0.0482321  0.03052864 0.03498085 0.02192743
  0.01383303 0.02275739]
 [0.03285862 0.04079261 0.03505254 0.0502557  0.07184232 0.03868292
  0.0304808  0.02941354 0.0358749  0.04811772 0.038406   0.03337566
  0.0324792  0.04105045 0.04355815 0.02234335 0.04811426 0.03871276
  0.03897456 0.03530214 0.03674103 0.05489172 0.05370182 0.01543848
  0.01009081 0.02136231]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' Sent', 'ences', ' ', '4', ' and', ' ', '5', ' only', ' mention', ' Julie', ' and', ' Fred', ' travelling', ' to', ' the', ' park', ',', ' but', ' do', ' not', ' provide', ' any', ' information', ' about', ' Bill', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0638, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01956752 0.02520947 0.02633344 ... 0.01103934 0.01149212 0.03161732]
 [0.02015803 0.02446938 0.02323314 ... 0.01723005 0.02115111 0.04159452]
 [0.02059486 0.02267939 0.02456163 ... 0.0232485  0.02046524 0.03523862]
 ...
 [0.02078397 0.02391531 0.01932499 ... 0.00909307 0.01208458 0.01393573]
 [0.02113311 0.02388781 0.01989203 ... 0.00769772 0.01116905 0.01348878]
 [0.02135439 0.0218673  0.01831316 ... 0.00790705 0.01149934 0.01564225]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', '.', ' Sentence', ' ', '8', ' mentions', ' Julie', ' moving', ' to', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' provide', ' any', ' new', ' information', ' about', ' Bill', "'s", ' location', '.', ' Since', ' Bill', ' could', ' be', ' in', ' either', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' and', ' Julie', "'s", ' movement', ' does', ' not', ' affect', ' Bill', "'s", ' location', ',', ' we', ' cannot', ' determine', ' Bill', "'s", ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(77, 38), x_tokens=38, y_tokens=77, max_supp_attn=0.0, attn_on_target=0.013)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (77, 38)
DEBUG result.interpretability.attn_scores 2926 
 [[0.01173144 0.02112003 0.02086466 ... 0.00995777 0.0167384  0.01493329]
 [0.01194777 0.01620393 0.01632348 ... 0.0140816  0.01439804 0.01513443]
 [0.01226825 0.02164942 0.02411826 ... 0.00948032 0.01392351 0.01426219]
 ...
 [0.01241339 0.01882684 0.01688364 ... 0.00929052 0.01550366 0.01542035]
 [0.01270309 0.01618736 0.0133251  ... 0.0114318  0.01394934 0.01870096]
 [0.01272786 0.01545251 0.01282837 ... 0.01151247 0.01431088 0.01395062]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' mentions', ' Mary', ' going', ' to', ' the', ' school', ',', ' but', ' sentence', ' ', '11', ' overrides', ' this', ' information', ',', ' stating', ' that', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', '.', ' There', ' is', ' no', ' information', ' about', ' Mary', ' leaving', ' the', ' school', ' or', ' going', ' back', ' to', ' the', ' school', ',', ' so', ' we', ' can', ' conclude', ' that', ' Mary', ' is', ' no', ' longer', ' in', ' the', ' school', '.', ' However', ',', ' we', ' cannot', ' determine', ' Mary', "'s", ' exact', ' location', ' between', ' the', ' park', ' and', ' the', ' cinema', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(82, 44), x_tokens=44, y_tokens=82, max_supp_attn=0.0366, attn_on_target=0.0122)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (82, 44)
DEBUG result.interpretability.attn_scores 3608 
 [[0.01097564 0.02019562 0.01953889 ... 0.00848427 0.00643543 0.0069488 ]
 [0.01123969 0.01637715 0.01464389 ... 0.01646058 0.01100552 0.00804637]
 [0.01151247 0.02063747 0.02179394 ... 0.01226649 0.00897016 0.01081849]
 ...
 [0.01170665 0.01646299 0.01686687 ... 0.00530422 0.00477013 0.00558638]
 [0.01199963 0.01287673 0.01231975 ... 0.00486333 0.00611894 0.0045976 ]
 [0.01194522 0.01425467 0.01344234 ... 0.00480116 0.00508733 0.00499289]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 50), x_tokens=50, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 50)
DEBUG result.interpretability.attn_scores 950 
 [[0.04995134 0.06570832 0.07198527 0.09116433 0.07134447 0.07838043
  0.06168023 0.06986631 0.07981171 0.07858984 0.05080084 0.05824602
  0.06040918 0.12346623 0.12332982 0.04892692 0.03883255 0.04312562
  0.03765683 0.04998117 0.03856862 0.04998825 0.09741459 0.03366253
  0.04442704 0.07082443 0.07091209 0.08023357 0.1502482  0.02796087
  0.02576831 0.07964166 0.14066939 0.06279793 0.08163339 0.03663083
  0.07255564 0.05535553 0.02921134 0.15671219 0.07942329 0.03577335
  0.02223342 0.03637483 0.04707792 0.06601715 0.0760278  0.08639197
  0.03763782 0.03371354]
 [0.05060687 0.05163982 0.05612398 0.04505135 0.03133101 0.04724123
  0.04601334 0.05004522 0.05522458 0.03706496 0.03762246 0.0416807
  0.04569723 0.03002112 0.05892561 0.04445847 0.03184284 0.0324217
  0.03541549 0.04435248 0.03267511 0.05298422 0.06580078 0.02916859
  0.04857178 0.04815067 0.05996281 0.03084733 0.08070575 0.08716033
  0.03656657 0.02999741 0.03258587 0.03072027 0.05872958 0.04888438
  0.05268658 0.04100515 0.02951198 0.05785963 0.06277768 0.08713853
  0.05497194 0.04296466 0.03386439 0.03400248 0.03202657 0.06930371
  0.04085905 0.04407745]
 [0.05206283 0.06706072 0.0786726  0.1107261  0.08883445 0.10723772
  0.06474391 0.07304598 0.07709662 0.07781494 0.05467593 0.06781725
  0.06933127 0.17114878 0.10433448 0.04583748 0.02990084 0.03199978
  0.02854408 0.03596953 0.0298232  0.0520231  0.07273705 0.02812761
  0.03793875 0.05948215 0.07783287 0.05628251 0.1550394  0.05513527
  0.04230509 0.09491821 0.16944651 0.05271884 0.06101633 0.03166635
  0.05551019 0.05199511 0.02655577 0.0934475  0.11837193 0.05153215
  0.03481515 0.05176516 0.09136213 0.0797288  0.06331744 0.0652713
  0.03405063 0.02902292]
 [0.05066162 0.05468361 0.06432279 0.04952416 0.03812428 0.05515183
  0.05305061 0.06121438 0.06129445 0.04464978 0.04271019 0.05123211
  0.05096031 0.03648768 0.03171773 0.04851335 0.03252917 0.03251745
  0.0327856  0.03927834 0.03163359 0.05706508 0.06594513 0.0358375
  0.05400212 0.05908246 0.07055056 0.04373275 0.08857101 0.12525564
  0.06137724 0.04584264 0.0576389  0.03284442 0.06635934 0.05012086
  0.05596003 0.05735578 0.03226776 0.04894401 0.10496233 0.10196905
  0.05884481 0.05544821 0.05579885 0.05228988 0.03661657 0.06743407
  0.04925044 0.04496862]
 [0.05212577 0.05335286 0.05823182 0.03681708 0.02726798 0.04545472
  0.06261918 0.05655433 0.06586028 0.03452546 0.03911435 0.04132197
  0.04411688 0.02593024 0.02477273 0.05877036 0.0354385  0.03387897
  0.03759558 0.04441025 0.03375559 0.04856842 0.06335395 0.02940259
  0.05245538 0.04943613 0.05784526 0.03085843 0.03337605 0.11257619
  0.03783609 0.02283303 0.01895905 0.02648885 0.06207622 0.05397869
  0.04225723 0.04209672 0.02249724 0.03244492 0.03959433 0.07737077
  0.06594844 0.04831415 0.04873905 0.03057122 0.0322385  0.06464148
  0.04665898 0.04694592]
 [0.05332823 0.03142604 0.03118249 0.02263884 0.01727432 0.02838921
  0.03689972 0.03778737 0.04465237 0.0247928  0.02961597 0.02901737
  0.03566463 0.01510912 0.01525964 0.037662   0.02618713 0.03052142
  0.03220756 0.03842341 0.03152012 0.03566033 0.03399207 0.0283676
  0.04114607 0.0473189  0.02949076 0.02785691 0.0177603  0.04889244
  0.02656084 0.01917424 0.0097546  0.01948748 0.03954991 0.04799411
  0.0401326  0.04173096 0.02981261 0.02923101 0.02650009 0.03943278
  0.06225032 0.04090165 0.02287828 0.02037784 0.02194375 0.05267494
  0.04581644 0.04605873]
 [0.05175465 0.0560324  0.05914322 0.04061627 0.02849724 0.04974938
  0.0539944  0.05483777 0.05627936 0.0418997  0.04328017 0.05187254
  0.04922335 0.02496256 0.02249707 0.05404173 0.03938621 0.03952303
  0.04713516 0.05946629 0.03872104 0.0614003  0.05494164 0.05821418
  0.07310541 0.0557932  0.05996281 0.03396535 0.03793301 0.081971
  0.0733753  0.03176318 0.01807035 0.02884428 0.06568421 0.06806843
  0.05398074 0.0549612  0.03777933 0.03561699 0.06601934 0.06385017
  0.11153691 0.06530342 0.06897463 0.04940298 0.03688018 0.06261735
  0.06657787 0.05218955]
 [0.05319792 0.06950945 0.07312921 0.05953676 0.03947    0.06939324
  0.06862555 0.07328215 0.06467365 0.06005526 0.06142005 0.08004262
  0.0706506  0.03533056 0.02783316 0.0568696  0.04433364 0.04791123
  0.04662028 0.04897373 0.04303956 0.05700586 0.05730907 0.07732091
  0.07314559 0.05603625 0.06770995 0.04694786 0.04436576 0.08118128
  0.10651856 0.0523838  0.03286094 0.0321933  0.06692921 0.06333888
  0.05282499 0.07029455 0.06653973 0.03978452 0.08304787 0.08277743
  0.1068716  0.07973185 0.08275446 0.06795587 0.04512115 0.05739263
  0.08010536 0.05748489]
 [0.05420434 0.050612   0.05280845 0.03987261 0.0299551  0.04970647
  0.05644341 0.05229173 0.05010206 0.04250194 0.05078936 0.05516712
  0.05420643 0.0246784  0.02229928 0.05270106 0.04394921 0.040005
  0.04588529 0.04578507 0.04042982 0.0529216  0.04288797 0.05871817
  0.05592383 0.04560676 0.05769032 0.03880328 0.03505213 0.07281353
  0.08922227 0.04966762 0.03233195 0.02877846 0.04717967 0.0613605
  0.0463127  0.06325939 0.06894478 0.03364423 0.06144123 0.0627927
  0.07430782 0.07581677 0.08033827 0.0525286  0.03626853 0.04396048
  0.06643745 0.04989795]
 [0.05351425 0.03811227 0.03470806 0.02471897 0.02039276 0.03078423
  0.0409072  0.03722286 0.03661943 0.02950541 0.04565573 0.03877566
  0.04342874 0.01536256 0.0160189  0.05411979 0.06224511 0.04392728
  0.05889119 0.05266381 0.04574245 0.05445113 0.0298202  0.05795018
  0.06281387 0.03886621 0.04131804 0.03569635 0.02282494 0.05030253
  0.06203034 0.04725267 0.01761541 0.02629849 0.03858802 0.06926163
  0.04638883 0.05820732 0.0777132  0.02772596 0.0408069  0.04476588
  0.0634004  0.05367208 0.04832377 0.03410733 0.02871158 0.03365761
  0.0630843  0.05388438]
 [0.05299953 0.0415744  0.03615579 0.02605003 0.02000026 0.03131863
  0.04709265 0.03915831 0.03666338 0.02988865 0.04597706 0.03792396
  0.04760029 0.01571072 0.01592426 0.06132434 0.06866444 0.05208829
  0.06630618 0.056511   0.05126846 0.05166438 0.026648   0.06469709
  0.06436062 0.03798043 0.03522363 0.03390987 0.01694933 0.04084546
  0.04990386 0.04795897 0.01129926 0.02327147 0.03351724 0.07282271
  0.04547531 0.04792602 0.06959615 0.02666315 0.03453382 0.04204268
  0.0632094  0.05282831 0.04081093 0.02789627 0.02704719 0.0284131
  0.06784169 0.04807183]
 [0.05419856 0.03638842 0.03341785 0.02472974 0.02095779 0.03101047
  0.03992953 0.03596136 0.03322558 0.03101311 0.05097298 0.04443388
  0.04344772 0.0158592  0.0152203  0.05192734 0.07222146 0.04867231
  0.07663817 0.05388613 0.04954274 0.04941498 0.02416508 0.08373782
  0.04720582 0.03257394 0.0348621  0.03468383 0.01698572 0.03650284
  0.06124515 0.06628149 0.01194463 0.02321366 0.03025408 0.05441147
  0.043323   0.04247963 0.09900792 0.02534373 0.03173891 0.04246806
  0.04494638 0.05554102 0.04398218 0.02633234 0.0282705  0.02528381
  0.07443735 0.05394007]
 [0.05398078 0.03531011 0.0324727  0.0224179  0.01903842 0.02818247
  0.0436466  0.03569639 0.03184851 0.02834726 0.05790454 0.04030961
  0.04481926 0.01392384 0.01421858 0.0611518  0.07709786 0.05036002
  0.07291345 0.05943163 0.05413731 0.05131197 0.02381502 0.08776076
  0.04779506 0.04010846 0.03057535 0.0375827  0.01574733 0.03055309
  0.05584785 0.06114776 0.00920974 0.02353388 0.02989111 0.06310394
  0.0522229  0.03978214 0.11744664 0.03023376 0.02768075 0.04922438
  0.04165465 0.05756607 0.04028239 0.02198638 0.02680253 0.02583441
  0.06884593 0.08336881]
 [0.05216714 0.04278254 0.03830488 0.02519319 0.01953012 0.03492286
  0.05438644 0.04397966 0.04172242 0.03180486 0.05428575 0.03878887
  0.05322405 0.01572864 0.01595935 0.06586126 0.07258186 0.06370097
  0.07960877 0.07168026 0.06998374 0.05668112 0.03826499 0.1490919
  0.10245337 0.09401669 0.03666976 0.05112557 0.02046387 0.03063939
  0.05251261 0.04521943 0.01748846 0.02855608 0.04889292 0.08573778
  0.06950365 0.04101087 0.04003407 0.04849996 0.03305472 0.05090204
  0.04891271 0.06779253 0.04077318 0.02617841 0.03081705 0.05013983
  0.0832883  0.15902336]
 [0.0546065  0.03992989 0.04072777 0.03390168 0.02422718 0.0402668
  0.04688453 0.04323658 0.03731285 0.03896853 0.0454568  0.04834688
  0.04786131 0.02291712 0.01791493 0.03840697 0.03419537 0.03416134
  0.04052981 0.03923906 0.03827564 0.04817912 0.02483995 0.03910145
  0.029281   0.03274678 0.03098853 0.03156026 0.02764228 0.0303235
  0.10603424 0.06582187 0.05856992 0.02386389 0.02976043 0.03754583
  0.0410392  0.03227834 0.04439323 0.03494363 0.04793779 0.05382004
  0.04309325 0.0764496  0.07048475 0.04897463 0.03018128 0.02904687
  0.03109322 0.04243434]
 [0.0529048  0.05407413 0.05657781 0.07894226 0.06398616 0.07045813
  0.05513179 0.05812112 0.06299382 0.08145363 0.05757938 0.06522471
  0.06219834 0.11825919 0.11482057 0.04321914 0.03818382 0.04558253
  0.03821573 0.04314864 0.0425586  0.05085374 0.05502465 0.0281726
  0.03378062 0.05853696 0.05846503 0.07577846 0.07309245 0.02680316
  0.03567497 0.12399897 0.22141463 0.09299694 0.05005807 0.03470191
  0.05310182 0.05000629 0.0374787  0.08070648 0.05038357 0.03944669
  0.02681746 0.04044601 0.05515705 0.13385925 0.06942537 0.05217188
  0.03106344 0.0350503 ]
 [0.05267106 0.07378303 0.06574802 0.11385167 0.21789801 0.08830378
  0.0591683  0.05879507 0.05845241 0.1118982  0.08440284 0.07482455
  0.0603902  0.17190655 0.20224714 0.06477667 0.07075164 0.0894741
  0.05959747 0.0574468  0.08809443 0.05109888 0.07623045 0.02487865
  0.03357974 0.06095124 0.07561202 0.08278015 0.07539847 0.01831655
  0.02160385 0.03898209 0.05713107 0.15372053 0.06219238 0.03237732
  0.05712961 0.0559556  0.03161639 0.07248969 0.03326119 0.02246344
  0.02092892 0.03052752 0.04990939 0.11385175 0.11110748 0.06186077
  0.02969324 0.0295083 ]
 [0.05232327 0.06743939 0.05724916 0.07547718 0.14667432 0.05207029
  0.04865111 0.05618567 0.0463322  0.09359524 0.08126987 0.07306832
  0.05631831 0.05931519 0.09498516 0.06364278 0.11321328 0.1564174
  0.09991483 0.08714759 0.15778181 0.05188184 0.06712524 0.0497513
  0.05569618 0.05395684 0.05722549 0.10122751 0.04100054 0.02406927
  0.0293237  0.03885485 0.03764303 0.15757836 0.05883847 0.04518111
  0.0563891  0.08797677 0.07836457 0.04920607 0.02902471 0.0249521
  0.02671587 0.03118144 0.0326563  0.06678238 0.10661913 0.05478225
  0.04916108 0.04935688]
 [0.05274052 0.07058056 0.0590382  0.07876982 0.07519614 0.06197803
  0.06013145 0.06271782 0.05983436 0.08163051 0.06646571 0.06190593
  0.06045189 0.06388223 0.06172127 0.04778892 0.06844506 0.08371158
  0.06353848 0.07220478 0.08244818 0.06684566 0.07968415 0.0360385
  0.04231784 0.05853156 0.04710257 0.12612729 0.04684349 0.01869757
  0.026293   0.0382602  0.0453663  0.13209288 0.06884936 0.04281325
  0.0632059  0.06632262 0.06122858 0.07650254 0.02943953 0.02727775
  0.02854054 0.0373747  0.04583208 0.04715638 0.1605774  0.0691215
  0.03409744 0.04100209]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' "', 'Bill', ' went', ' back', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Bill', ' was', ' not', ' in', ' the', ' kitchen', ' previously', ',', ' but', ' now', ' he', ' is', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02174633 0.0402614  0.05078376 ... 0.02135676 0.00985692 0.02152884]
 [0.02167463 0.07047483 0.05235102 ... 0.03611391 0.01783737 0.02971105]
 [0.02369703 0.05038748 0.03261217 ... 0.00874406 0.00403593 0.01066235]
 ...
 [0.02339853 0.02460636 0.02486875 ... 0.00944767 0.00440047 0.01401483]
 [0.02337808 0.02015486 0.02012023 ... 0.01465668 0.00856365 0.01740173]
 [0.02353869 0.02523312 0.02389299 ... 0.01212806 0.00663746 0.01632248]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Context', ' sentence', ' ', '5', ' explicitly', ' states', ' "', 'Bill', ' is', ' in', ' the', ' school', '",', ' which', ' contrad', 'icts', ' the', ' possibility', ' mentioned', ' in', ' sentence', ' ', '4', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.1935, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.02989385 0.04762046 0.0486643  0.06532893 0.06618192 0.05578006
  0.0400136  0.03771882 0.04935674 0.05418879 0.0366644  0.03772291
  0.03808515 0.10640232 0.10702935 0.03523376 0.02996931 0.02850078
  0.02490732 0.02884592 0.02594231 0.0350077  0.06099243 0.0214746
  0.01924682 0.04638416 0.04661746 0.05137446 0.11379806 0.01328638
  0.01428842 0.01151249]
 [0.03091473 0.04315536 0.04346868 0.07222485 0.08500194 0.07547133
  0.04225426 0.0387996  0.04910807 0.07077581 0.04910107 0.05670634
  0.05280104 0.15067244 0.13564163 0.03722905 0.03064283 0.03350873
  0.02649361 0.02902119 0.02635314 0.0363322  0.04045891 0.0173475
  0.01693228 0.03894545 0.05189766 0.04219708 0.08349736 0.01671093
  0.01835785 0.01815738]
 [0.03141737 0.04263866 0.04802739 0.06335672 0.06768487 0.06366578
  0.04294135 0.04059315 0.0476734  0.05851631 0.03965674 0.05437862
  0.04919061 0.10167045 0.08063193 0.03232484 0.02818457 0.02803225
  0.02389073 0.02562485 0.02330543 0.034809   0.0408631  0.02098929
  0.01903908 0.03528017 0.04527553 0.03637002 0.05633827 0.03060655
  0.02576269 0.0231933 ]
 [0.03020565 0.03771444 0.04169175 0.03397396 0.03637853 0.03856537
  0.0348249  0.03742054 0.03589639 0.03390801 0.03047066 0.03914174
  0.03643501 0.02810638 0.02883899 0.03361155 0.03057308 0.02846148
  0.02786242 0.02920665 0.02765197 0.03703996 0.04646972 0.03610711
  0.03245368 0.04229843 0.04332098 0.03940528 0.04104252 0.07939028
  0.03958761 0.0384558 ]
 [0.03133261 0.06138927 0.05417767 0.02791385 0.02683975 0.03469155
  0.03942806 0.0368724  0.04091453 0.02874635 0.02921428 0.03269529
  0.03197638 0.02146056 0.02237009 0.04395667 0.0346042  0.02912195
  0.03010626 0.03159621 0.029791   0.0328705  0.06383097 0.03702544
  0.03444796 0.03709453 0.04346685 0.03013018 0.03132083 0.09191759
  0.03642336 0.03196567]
 [0.03161006 0.03955558 0.04090293 0.02168522 0.02178768 0.02570421
  0.03559491 0.0283908  0.03178156 0.02122382 0.02455771 0.02449994
  0.02438197 0.01530707 0.01769743 0.03902979 0.03263813 0.02601079
  0.02805602 0.02919034 0.02789019 0.02849488 0.04754506 0.04093565
  0.03787042 0.03430368 0.03736982 0.0267967  0.02645461 0.07860792
  0.0370045  0.02761817]
 [0.0319971  0.01728611 0.0188801  0.01352992 0.0137257  0.01712405
  0.01828231 0.01612841 0.01818731 0.01476847 0.01917969 0.01656387
  0.01641229 0.00952022 0.01123375 0.0205703  0.01939304 0.01804961
  0.02188143 0.02188613 0.0213875  0.0204325  0.01885283 0.02461953
  0.02627178 0.02408479 0.02090201 0.01894446 0.0160694  0.03411056
  0.02302673 0.02027449]
 [0.03154215 0.02828    0.03011869 0.02169205 0.02054026 0.02631498
  0.02861572 0.02487923 0.02500144 0.02182057 0.02613176 0.02641723
  0.02402212 0.01469483 0.01710661 0.0340891  0.03235318 0.0274209
  0.03285924 0.03324393 0.03401558 0.03630957 0.03565694 0.04950057
  0.04788853 0.03982444 0.03725313 0.03110234 0.02806638 0.05565849
  0.05160991 0.03604513]
 [0.03216655 0.0455412  0.04906986 0.0390548  0.0317369  0.0448837
  0.04659679 0.04528234 0.03862332 0.04162874 0.04289503 0.05748894
  0.04648321 0.02656253 0.02533058 0.04366926 0.03773596 0.03809802
  0.03739296 0.03626018 0.03599413 0.03799765 0.03805793 0.04993435
  0.0397262  0.03664361 0.04405029 0.03712399 0.0330602  0.04138774
  0.04764263 0.05752895]
 [0.03269723 0.03155762 0.03418403 0.02609195 0.02279166 0.03072429
  0.03544937 0.03001778 0.02700997 0.02615245 0.03360032 0.03129847
  0.03131324 0.01700887 0.01881935 0.0400396  0.03307053 0.03094165
  0.03380504 0.03255203 0.03357336 0.03430417 0.02943292 0.05255397
  0.04166854 0.02872198 0.03176872 0.03097176 0.02572931 0.04919524
  0.05434588 0.04906848]
 [0.03254372 0.02305074 0.02279214 0.01881799 0.01606563 0.0210676
  0.02540705 0.02027914 0.02038925 0.01763896 0.03501246 0.02233582
  0.02161631 0.01108137 0.01548837 0.0375032  0.03461416 0.03204345
  0.03774603 0.03772143 0.03810678 0.02841704 0.02202417 0.04939443
  0.05032251 0.02575594 0.02046442 0.02373954 0.01829231 0.0341828
  0.04727633 0.02858818]
 [0.03199434 0.02110067 0.01940551 0.01730126 0.01255674 0.01914742
  0.02455919 0.02041085 0.02009807 0.01630608 0.02644534 0.0176201
  0.02286377 0.0099549  0.0120304  0.0479959  0.03727301 0.04170189
  0.0511843  0.05240016 0.05418913 0.02336823 0.01690516 0.06704573
  0.07722615 0.03205516 0.01427988 0.03345439 0.01543342 0.02304147
  0.04017298 0.03329464]
 [0.03279468 0.01940271 0.01991142 0.01680251 0.0134742  0.01919205
  0.02433918 0.02191    0.01953908 0.01678086 0.02792922 0.02080027
  0.02360231 0.01038957 0.01182515 0.03694496 0.04575833 0.03897839
  0.0669568  0.04801947 0.04770355 0.02366143 0.0148963  0.06266022
  0.04457686 0.02347848 0.01395898 0.02559035 0.01483606 0.01628764
  0.03966157 0.03016445]
 [0.03250324 0.01720518 0.01738887 0.01513775 0.01143808 0.0167601
  0.02150114 0.01915575 0.01849549 0.0146465  0.02612766 0.01711399
  0.02149979 0.00945219 0.01036578 0.03895517 0.03970602 0.03591559
  0.05019671 0.04174343 0.04356884 0.02581256 0.01382745 0.07564757
  0.04617297 0.03211305 0.01270457 0.0350828  0.01605563 0.01261079
  0.03738771 0.03992358]
 [0.03232969 0.02132011 0.0228005  0.01940783 0.01406773 0.02299057
  0.02498058 0.02485793 0.02340524 0.0180201  0.02503935 0.02036687
  0.02370683 0.01192189 0.01158511 0.02399822 0.02355833 0.02415935
  0.0280654  0.02737142 0.02729106 0.02949509 0.01831145 0.02398116
  0.03194126 0.02918052 0.01610315 0.02232764 0.01886449 0.0169314
  0.02600431 0.02292925]
 [0.0328773  0.02028671 0.02131485 0.02145065 0.01431118 0.0219001
  0.02399395 0.02366481 0.02080584 0.02008041 0.02851129 0.02123366
  0.02362801 0.01351648 0.01372054 0.02610959 0.02516041 0.02545384
  0.03268781 0.03094302 0.03098284 0.02837974 0.01629147 0.03629324
  0.02989679 0.02932524 0.01600105 0.03114193 0.02105449 0.01538756
  0.05872736 0.03552663]
 [0.03250222 0.02835781 0.03313599 0.03592568 0.02378155 0.03595493
  0.03416827 0.0396034  0.03312483 0.03745802 0.03819131 0.04354269
  0.03913213 0.02488378 0.02106089 0.02674741 0.02755623 0.03063408
  0.02862401 0.02864619 0.02851643 0.03662888 0.02412944 0.02204298
  0.02739875 0.03161642 0.02837014 0.0374576  0.02991186 0.02486036
  0.05616116 0.05122388]
 [0.03281541 0.03467805 0.04063813 0.04796391 0.02875717 0.04538292
  0.04239472 0.05446316 0.03898252 0.05483128 0.04207111 0.05894318
  0.05243434 0.03222946 0.02205293 0.02577851 0.02598536 0.02973028
  0.02488429 0.02553212 0.0245044  0.0354991  0.02584072 0.01870577
  0.02354697 0.03013721 0.03395665 0.0309903  0.02981315 0.02215155
  0.04738199 0.07819272]
 [0.03365258 0.02991414 0.03128658 0.03674325 0.0248982  0.04202086
  0.03566092 0.03924121 0.04024715 0.04091002 0.03348964 0.04097483
  0.04187208 0.02478001 0.0178389  0.02430664 0.02617267 0.03217267
  0.02872977 0.03069541 0.02668338 0.03061716 0.02304946 0.01672528
  0.02366468 0.02733417 0.02624056 0.02491052 0.0247421  0.01670236
  0.0232923  0.03540458]
 [0.03266275 0.02790803 0.02578854 0.02328166 0.01636943 0.02501673
  0.02704354 0.03274103 0.02843188 0.02243909 0.02707045 0.02751555
  0.02896398 0.01690972 0.01422671 0.02436688 0.02461376 0.0238412
  0.02442631 0.02569211 0.02497158 0.03390826 0.02494058 0.02220911
  0.03065503 0.02936942 0.03302313 0.02557772 0.02550635 0.04035174
  0.02945173 0.04635787]
 [0.03239369 0.03675263 0.03288095 0.02429054 0.01874155 0.02666918
  0.03354549 0.04291935 0.03457012 0.02512447 0.0336987  0.03307894
  0.03668176 0.01834865 0.01498683 0.03261391 0.0366978  0.03108977
  0.03041072 0.02847093 0.02720904 0.03677685 0.02717192 0.0257163
  0.03592116 0.0350471  0.04154147 0.02550695 0.02475016 0.03074087
  0.03627332 0.05037034]
 [0.03335796 0.03049309 0.02743447 0.02559548 0.01894677 0.02535559
  0.02970897 0.03694213 0.0303639  0.02612631 0.03316377 0.03166106
  0.03325297 0.0181757  0.01519614 0.02747755 0.0324196  0.03035599
  0.02902229 0.02797263 0.02672902 0.03539291 0.02084222 0.01933337
  0.02650895 0.02623276 0.03130196 0.02334192 0.02034531 0.02146927
  0.0289051  0.05041341]
 [0.0336931  0.03297855 0.03252277 0.02589837 0.02032699 0.0281515
  0.03598753 0.03985133 0.03658078 0.02564499 0.03122489 0.03214039
  0.03416628 0.01897126 0.01612557 0.02872336 0.02891986 0.0267166
  0.02648593 0.02740199 0.02542734 0.03450013 0.02794413 0.02010018
  0.02767401 0.02821012 0.03596954 0.0192351  0.02240905 0.03378146
  0.0270398  0.03696888]
 [0.03296271 0.03233734 0.03129773 0.02049187 0.01805144 0.021168
  0.03135223 0.03182489 0.03269337 0.01913737 0.02356777 0.02090264
  0.02518733 0.01582937 0.01508076 0.02929763 0.02781129 0.02422207
  0.02431715 0.02642273 0.02423907 0.03522207 0.03934093 0.0279329
  0.03364298 0.03165908 0.03661134 0.02112044 0.02392614 0.0589736
  0.02274003 0.02596373]
 [0.03270327 0.04797219 0.04894582 0.02742649 0.02363266 0.02775407
  0.05436462 0.03924314 0.04202401 0.02378069 0.02727541 0.02481088
  0.02902052 0.01981986 0.02043991 0.04517485 0.03471446 0.02915974
  0.02736692 0.03149634 0.02775325 0.03430318 0.05423074 0.03783917
  0.03889699 0.03724992 0.04927215 0.02513797 0.02663728 0.05232519
  0.02126709 0.01836159]
 [0.0330767  0.02203291 0.02246881 0.02032107 0.01781604 0.0246207
  0.027228   0.02658369 0.02920766 0.02278974 0.02359237 0.02451525
  0.02882861 0.01731788 0.01493465 0.02199298 0.02285094 0.0257531
  0.02456447 0.02846175 0.02367346 0.02875575 0.02530212 0.02341278
  0.02861401 0.02916986 0.02644476 0.02360307 0.02545934 0.02462009
  0.0227351  0.02086479]
 [0.03316602 0.02172475 0.02116433 0.01831014 0.01629298 0.01888666
  0.02343378 0.02504387 0.02568582 0.0191635  0.0252525  0.02043479
  0.02369827 0.01449421 0.01300738 0.02538332 0.0277887  0.02475408
  0.0262821  0.02867371 0.02532035 0.03105659 0.02183228 0.02295285
  0.02870403 0.02553048 0.03001838 0.02129904 0.01856161 0.02577597
  0.03188761 0.02896629]
 [0.03236635 0.03128059 0.03020509 0.04323607 0.03869633 0.03624359
  0.02979866 0.03148981 0.03552657 0.04313368 0.03290142 0.03360131
  0.03906187 0.05875856 0.07132372 0.0262754  0.02718493 0.03330847
  0.02801338 0.03248783 0.02920614 0.03343054 0.03720044 0.01784743
  0.01859245 0.03498616 0.03699058 0.04306731 0.04684625 0.01207941
  0.01494424 0.01633622]
 [0.03147867 0.04102008 0.03596793 0.07338403 0.15185586 0.04984661
  0.03310718 0.03573351 0.04122484 0.07670847 0.05270008 0.04892813
  0.03928292 0.09057757 0.1193137  0.03622533 0.05312579 0.06554385
  0.04042226 0.04082938 0.04985756 0.03192599 0.05038175 0.01797587
  0.01886943 0.03875502 0.04559643 0.0576202  0.05327791 0.00898798
  0.01148554 0.00991389]
 [0.03213533 0.03098178 0.02530215 0.03806186 0.05922049 0.02591198
  0.02364871 0.0267309  0.02846376 0.04180079 0.0366521  0.02970359
  0.02734125 0.02982203 0.04307555 0.02930205 0.05089868 0.06278332
  0.04731495 0.04284497 0.06752618 0.02845385 0.0339744  0.02354892
  0.02286144 0.03009151 0.02685318 0.04693151 0.03080573 0.00987362
  0.01606144 0.0139072 ]
 [0.03221298 0.03446328 0.02816197 0.04529937 0.04802988 0.03303352
  0.02977497 0.03120703 0.03658716 0.04574936 0.03861147 0.03286272
  0.03305763 0.04135998 0.0416214  0.02507325 0.03802489 0.04353595
  0.03504337 0.03874553 0.04063596 0.0407966  0.03940211 0.01814662
  0.01876729 0.02912111 0.02237521 0.05844746 0.03709434 0.00799318
  0.01309373 0.01250803]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' provided', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', ' and', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 38), x_tokens=38, y_tokens=29, max_supp_attn=0.1034, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 38)
DEBUG result.interpretability.attn_scores 1102 
 [[0.03209835 0.03603439 0.03117658 ... 0.03852868 0.02400497 0.02384883]
 [0.0329918  0.02619353 0.0233448  ... 0.03533836 0.04284463 0.05106469]
 [0.03362023 0.03713241 0.03756526 ... 0.02618299 0.01726777 0.01572444]
 ...
 [0.03429905 0.03138721 0.02595067 ... 0.03103913 0.03780294 0.03766424]
 [0.03474082 0.03652337 0.03296109 ... 0.03189828 0.02626039 0.02373043]
 [0.03484851 0.02831953 0.02708181 ... 0.03441695 0.02225856 0.02257464]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' "', 'Bill', ' journey', 'ed', ' to', ' the', ' office', '",', ' which', ' implies', ' that', ' Bill', ' has', ' moved', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 44), x_tokens=44, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 44)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02918728 0.03548232 0.04206173 ... 0.12116489 0.02278777 0.0156992 ]
 [0.02971988 0.03254809 0.03995126 ... 0.06139437 0.04865835 0.02783292]
 [0.0304699  0.03678944 0.04933178 ... 0.08513807 0.04026737 0.01920494]
 ...
 [0.03067122 0.04373425 0.03931579 ... 0.0494133  0.01062698 0.00951284]
 [0.03104405 0.03582947 0.02981672 ... 0.02537379 0.00962796 0.01517672]
 [0.03092792 0.04190157 0.03309903 ... 0.04152745 0.00759947 0.01124808]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' provided', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' movements', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03251826 0.04165114 0.03727708 ... 0.03725713 0.02446921 0.01644716]
 [0.03280414 0.03682867 0.03179136 ... 0.04438165 0.09229729 0.0758893 ]
 [0.03386185 0.04306763 0.04149435 ... 0.03717361 0.02089506 0.01453265]
 ...
 [0.03447688 0.03031724 0.02845677 ... 0.03305658 0.02870321 0.02708257]
 [0.03456616 0.04046105 0.03639276 ... 0.03786757 0.02149506 0.01842988]
 [0.03475302 0.03275352 0.0299083  ... 0.03290148 0.02029182 0.01696209]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Fred', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' cinema', '"', ' implies', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' cinema', ',', ' as', ' the', ' two', ' options', ' are', ' the', ' same', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02172082 0.0423467  0.05349888 ... 0.02346051 0.00660609 0.01971896]
 [0.02162448 0.06123099 0.04877673 ... 0.06384479 0.01827783 0.0267045 ]
 [0.02369141 0.05495115 0.03436885 ... 0.00898972 0.0021959  0.00791235]
 ...
 [0.02337032 0.02637669 0.02718814 ... 0.01059351 0.00238743 0.01114575]
 [0.02319548 0.02268802 0.02302808 ... 0.01875529 0.0067801  0.01609293]
 [0.02347645 0.02833126 0.02696879 ... 0.01420904 0.0045188  0.01354099]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Julie', ' and', ' Bill', ',', ' but', ' not', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 32), x_tokens=32, y_tokens=33, max_supp_attn=0.0606, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 32)
DEBUG result.interpretability.attn_scores 1056 
 [[0.0281952  0.03299731 0.03530929 ... 0.01264866 0.01736639 0.01191614]
 [0.02902756 0.0324825  0.03375448 ... 0.01629709 0.02719305 0.01703337]
 [0.02965373 0.03017335 0.03467603 ... 0.02236426 0.03339161 0.01966057]
 ...
 [0.02976339 0.03055732 0.02404885 ... 0.01620518 0.02045038 0.02222576]
 [0.03026556 0.03224011 0.02633931 ... 0.01295487 0.01766103 0.01759442]
 [0.03046209 0.02915445 0.02506683 ... 0.01171192 0.01656586 0.01582593]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' kitchen', '"', ' does', ' not', ' mention', ' the', ' cinema', ' as', ' a', ' possible', ' location', ' for', ' Mary', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.02824993 0.04026486 0.04280147 ... 0.02747211 0.01051915 0.02497463]
 [0.02881407 0.0350245  0.03384213 ... 0.03287924 0.02066851 0.03212983]
 [0.02944374 0.04514485 0.051312   ... 0.02359644 0.00876976 0.01874441]
 ...
 [0.02965108 0.03863168 0.03634415 ... 0.02221098 0.00949563 0.01579828]
 [0.03005407 0.02936519 0.02644599 ... 0.02676772 0.01797504 0.02255628]
 [0.03007152 0.0301942  0.0278611  ... 0.02330972 0.01362257 0.01909882]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Mary', ' is', ' in', ' the', ' bedroom', '"', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 44), x_tokens=44, y_tokens=26, max_supp_attn=0.0769, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 44)
DEBUG result.interpretability.attn_scores 1144 
 [[0.03617743 0.04383767 0.05183202 ... 0.13561088 0.01857895 0.02648327]
 [0.03681717 0.03711066 0.04044636 ... 0.0834311  0.04068697 0.03845019]
 [0.03770057 0.04664302 0.05452746 ... 0.10396204 0.02971979 0.03739512]
 ...
 [0.03790954 0.05174742 0.04662128 ... 0.04975663 0.01103146 0.01475305]
 [0.03801182 0.04398707 0.03811752 ... 0.02835711 0.01500478 0.01415029]
 [0.03825717 0.0487408  0.04050145 ... 0.0370874  0.01222125 0.01439801]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' "', 'Fred', ' is', ' in', ' the', ' office', '"', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 50), x_tokens=50, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 50)
DEBUG result.interpretability.attn_scores 1900 
 [[0.02443214 0.03767258 0.03705642 ... 0.03721778 0.01380568 0.01801245]
 [0.02499737 0.03812051 0.03401108 ... 0.02953169 0.02168457 0.01982662]
 [0.02540059 0.03940669 0.04289848 ... 0.03213276 0.01427708 0.01565074]
 ...
 [0.0255938  0.03948135 0.03398116 ... 0.02655337 0.01150929 0.01460501]
 [0.02618715 0.02917055 0.0242095  ... 0.02726479 0.01706247 0.01722756]
 [0.02601335 0.03147843 0.02573685 ... 0.02626742 0.01358269 0.01622883]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' being', ' in', ' the', ' bedroom', ' or', ' the', ' bedroom', ',', ' which', ' is', ' the', ' same', ' location', '.', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 26), x_tokens=26, y_tokens=42, max_supp_attn=0.0952, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 26)
DEBUG result.interpretability.attn_scores 1092 
 [[0.02192206 0.04062008 0.04662716 ... 0.0103459  0.01404486 0.02751691]
 [0.02177962 0.0450099  0.03440039 ... 0.02496096 0.03434858 0.04039817]
 [0.02386133 0.05256871 0.03274965 ... 0.00294065 0.00512144 0.01384103]
 ...
 [0.02347357 0.02552808 0.02525594 ... 0.0035996  0.00548407 0.01840287]
 [0.02318009 0.02159032 0.02205485 ... 0.00903956 0.01110316 0.02094867]
 [0.02354471 0.02632444 0.02525311 ... 0.00615549 0.00920662 0.01934173]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.03011542 0.04287948 0.0460638  0.05868074 0.06218798 0.05511903
  0.03772211 0.03544785 0.04342465 0.0525534  0.03154342 0.037409
  0.03718714 0.09460721 0.10319509 0.02983671 0.02601992 0.02123734
  0.02178105 0.02129686 0.01921326 0.03313875 0.05280856 0.01250494
  0.01492906 0.04042673 0.0392362  0.0428851  0.10861111 0.04154336
  0.00976439 0.01448673]
 [0.03082203 0.04508199 0.04689218 0.07792135 0.09143603 0.09361244
  0.04724807 0.04663011 0.0535293  0.08157449 0.05074338 0.06863534
  0.06593094 0.13887443 0.11416384 0.03187019 0.02697114 0.02706712
  0.0247052  0.02396486 0.0210205  0.03746464 0.04067822 0.01381989
  0.01614954 0.03719462 0.04193455 0.03577808 0.08504605 0.05627443
  0.01201622 0.02129709]
 [0.03150758 0.04026044 0.04894193 0.06297888 0.06645228 0.06514653
  0.04078654 0.03926823 0.04500723 0.05807803 0.03659698 0.05246539
  0.04722644 0.10445189 0.08028655 0.02929401 0.02534236 0.02170562
  0.0215146  0.02030692 0.01778974 0.03359757 0.0373854  0.01457319
  0.01552103 0.03375924 0.04017236 0.03011904 0.05806495 0.06518739
  0.01332721 0.02694211]
 [0.03025673 0.04714273 0.05030021 0.03639054 0.03469234 0.0404131
  0.04129703 0.04127137 0.03868947 0.03519765 0.03063929 0.03970687
  0.03866224 0.02871103 0.02806159 0.03956779 0.03327237 0.02866456
  0.02801139 0.02795467 0.0253681  0.03619695 0.0576811  0.03176634
  0.02996043 0.04752618 0.05203959 0.03779817 0.04244412 0.08597897
  0.02948135 0.04818181]
 [0.0307624  0.05295811 0.05530477 0.02700603 0.02192353 0.03429088
  0.04165268 0.03874876 0.04052116 0.02581071 0.02608487 0.03076149
  0.03233139 0.02080706 0.02040843 0.0379472  0.02956787 0.02456234
  0.02706269 0.02691117 0.02359626 0.03523455 0.06073853 0.03677313
  0.03255122 0.04464473 0.06140121 0.02899417 0.02975456 0.08641074
  0.03610696 0.04653759]
 [0.03157926 0.06377919 0.06102132 0.02756519 0.02030821 0.03436263
  0.03984836 0.0347534  0.04152388 0.02463231 0.02383964 0.027582
  0.02919245 0.01740545 0.01863646 0.04161533 0.03369241 0.02736517
  0.03118472 0.03409397 0.02755075 0.03138961 0.08409165 0.03315596
  0.02814248 0.04627857 0.06063026 0.02834262 0.02604566 0.08230028
  0.02941244 0.03637972]
 [0.03166985 0.04782672 0.05184745 0.02882724 0.02085097 0.03176497
  0.03916925 0.03501769 0.03843618 0.02564717 0.02524646 0.02858525
  0.02732664 0.01959793 0.02069163 0.04356586 0.03567731 0.02591388
  0.02827783 0.02795629 0.02517701 0.03252911 0.0653533  0.03502594
  0.03202502 0.04728225 0.0696064  0.0323641  0.0293506  0.07035629
  0.03639496 0.04123583]
 [0.03216108 0.02737569 0.03232216 0.02042182 0.0170294  0.02364692
  0.0264133  0.02551961 0.03327604 0.02043619 0.02086079 0.01942677
  0.02037164 0.0140998  0.01726411 0.03436529 0.03309432 0.02376791
  0.02854278 0.02880262 0.02366395 0.02793415 0.04701593 0.02575239
  0.02285492 0.03948658 0.04243017 0.02514359 0.02558741 0.02887369
  0.02068694 0.02204661]
 [0.03156026 0.03518166 0.03667632 0.02739901 0.01925788 0.03118951
  0.03336844 0.03114445 0.03123502 0.02517222 0.02811162 0.02943859
  0.02856003 0.0183075  0.01970546 0.0405693  0.03595574 0.03294447
  0.03230155 0.03476827 0.03066696 0.03553329 0.04051801 0.03726177
  0.03406221 0.03697356 0.03962168 0.02633188 0.02760976 0.04425025
  0.03437724 0.03607361]
 [0.03265294 0.03415276 0.03858093 0.032427   0.02305351 0.03749623
  0.03753049 0.0356611  0.03298298 0.03139583 0.03333925 0.03750141
  0.03646863 0.02262584 0.02004575 0.03718751 0.03172963 0.03043453
  0.02853227 0.02833118 0.02656512 0.03592326 0.02933729 0.03757289
  0.03500864 0.03126656 0.0327106  0.02708224 0.02682582 0.0404186
  0.03737202 0.04193358]
 [0.03219863 0.02399667 0.02299082 0.02001311 0.01343939 0.02115615
  0.0246427  0.02148233 0.02181071 0.01850279 0.02712756 0.02086376
  0.0239642  0.01286244 0.01357857 0.0380578  0.03551061 0.03621731
  0.03167709 0.03473582 0.03456366 0.03285241 0.02169553 0.0378367
  0.03794658 0.02655307 0.02315624 0.02425572 0.02029799 0.02551884
  0.03597622 0.02634114]
 [0.03179179 0.02349829 0.02188859 0.02126618 0.01290033 0.02046646
  0.02378423 0.0214477  0.02128319 0.01881868 0.02560527 0.01954746
  0.0236662  0.01272471 0.01270601 0.03642736 0.0308047  0.04711626
  0.03165907 0.04475539 0.04786574 0.03039073 0.01926552 0.03951835
  0.05202604 0.02955395 0.02387213 0.02568567 0.01895859 0.02373748
  0.04843061 0.02607892]
 [0.03261674 0.02051533 0.020544   0.02116737 0.01402846 0.02199519
  0.02390994 0.02301522 0.02194469 0.0203757  0.02941365 0.02451848
  0.02555685 0.01339306 0.01239147 0.03221278 0.02711275 0.03978361
  0.03337634 0.05802394 0.05480732 0.02596874 0.01645244 0.04052137
  0.04016283 0.02174176 0.02182084 0.02388588 0.01775112 0.01506939
  0.04317076 0.02884516]
 [0.03336434 0.01712753 0.01682653 0.01755414 0.0110053  0.01810163
  0.01990272 0.01914745 0.01917308 0.01692785 0.0251239  0.02003023
  0.02060838 0.01133945 0.01046727 0.02644039 0.02359228 0.02862215
  0.02955077 0.03645118 0.04291    0.02484847 0.01383358 0.03648774
  0.03667494 0.01998468 0.0161901  0.0206922  0.01684945 0.01177498
  0.04036856 0.02659661]
 [0.03290584 0.01847797 0.01828476 0.01663792 0.01181481 0.01757595
  0.02258697 0.02028664 0.01999996 0.01644618 0.03288985 0.02165109
  0.02066136 0.01136203 0.01143888 0.0325099  0.02965451 0.0325954
  0.03752539 0.04038339 0.03794646 0.02784341 0.0167129  0.04493249
  0.05188536 0.02604233 0.0174842  0.02570169 0.01803547 0.01272673
  0.04843238 0.03035995]
 [0.03166096 0.03316769 0.03114325 0.02399912 0.01819829 0.02774695
  0.05780725 0.04937326 0.03495073 0.02496835 0.05594437 0.03572025
  0.04273823 0.01484041 0.01501752 0.04037153 0.03892532 0.04733521
  0.05491796 0.05095636 0.04511973 0.03348006 0.02730558 0.05624525
  0.06028626 0.04083075 0.02241282 0.04053924 0.02984482 0.01934576
  0.05217099 0.043822  ]
 [0.03297672 0.02415013 0.02384659 0.02234184 0.01588275 0.02270391
  0.02677508 0.02751911 0.02525638 0.02186103 0.03088086 0.02616103
  0.02675713 0.01651694 0.01431847 0.02824142 0.02601096 0.02703559
  0.03304985 0.03216195 0.02963812 0.03271156 0.01919392 0.0313872
  0.03180943 0.02553796 0.01916379 0.02365623 0.02333467 0.01933713
  0.04020601 0.04475383]
 [0.03305372 0.02514834 0.02917976 0.02913714 0.02204023 0.03026993
  0.03073631 0.03820559 0.03071587 0.03228972 0.03188802 0.04062338
  0.03782453 0.02250053 0.01618783 0.02349866 0.02468033 0.02712673
  0.02573571 0.02435272 0.02362437 0.03518468 0.02047113 0.02847024
  0.02745002 0.02661024 0.02077454 0.02954559 0.02664529 0.02706951
  0.0336334  0.0539146 ]
 [0.03331973 0.03243839 0.03645451 0.03919759 0.02502079 0.03767926
  0.03719017 0.04949174 0.03379101 0.04252573 0.04168606 0.05190058
  0.04744001 0.02781463 0.01857545 0.02574819 0.02406072 0.02657648
  0.02323787 0.02239068 0.02121107 0.03634753 0.02296736 0.02940606
  0.02689094 0.02346707 0.02427138 0.02461688 0.02790137 0.02928757
  0.03451505 0.06765687]
 [0.0334134  0.02941305 0.03013001 0.03197113 0.02209395 0.03295545
  0.03241953 0.03791031 0.03189233 0.03445611 0.03435174 0.04169358
  0.04205282 0.02362386 0.01744936 0.02920778 0.0262398  0.03011814
  0.02709271 0.02717732 0.02550295 0.03567391 0.02061254 0.03126939
  0.03013765 0.02374657 0.02085714 0.02682322 0.02516703 0.02327117
  0.03170225 0.03677586]
 [0.03334373 0.02294291 0.02205426 0.02043529 0.01488799 0.02051039
  0.02587215 0.02685929 0.02552643 0.02184759 0.02708315 0.02564432
  0.02961296 0.01503121 0.01267131 0.03255723 0.02913648 0.03229563
  0.02867713 0.02890161 0.02944859 0.03235298 0.01672453 0.03665781
  0.03445503 0.02455714 0.01781461 0.02885198 0.01997356 0.01864876
  0.03459279 0.03095416]
 [0.0332661  0.0252375  0.02352482 0.02203868 0.01627732 0.02098922
  0.02953905 0.02960792 0.02652705 0.0228871  0.02735315 0.02503614
  0.03104833 0.01536764 0.01353267 0.03689976 0.03137472 0.03984781
  0.03260702 0.03272022 0.03533737 0.02950886 0.01741549 0.0380383
  0.03707141 0.02447329 0.02045789 0.02793006 0.01889295 0.01769948
  0.03807345 0.02731574]
 [0.03332331 0.02442489 0.02247462 0.02137846 0.01746102 0.02038593
  0.02634278 0.02801853 0.02473933 0.02365105 0.02868892 0.02570466
  0.02858486 0.0158023  0.01374367 0.03130265 0.03302859 0.03278513
  0.03371184 0.03060481 0.03489689 0.02956652 0.01887887 0.04704554
  0.04261477 0.0247312  0.02439528 0.03617396 0.02034154 0.01941361
  0.04835994 0.03336815]
 [0.03351202 0.02769577 0.02546777 0.02253047 0.01775926 0.02188976
  0.03035613 0.03216152 0.02981782 0.02506693 0.0348349  0.02732741
  0.03158473 0.01618164 0.01454906 0.03672729 0.03384179 0.03622419
  0.03437232 0.03354463 0.03435695 0.0306486  0.02047113 0.04695843
  0.03915793 0.0263841  0.02665308 0.02939138 0.01940864 0.01788021
  0.04608249 0.03390271]
 [0.03364884 0.02067171 0.01944176 0.01607202 0.0150473  0.01637669
  0.02452926 0.02459185 0.02407573 0.01834373 0.03531449 0.02132485
  0.02342283 0.01246166 0.01132806 0.0301254  0.03129525 0.02912425
  0.03634027 0.03152741 0.03111266 0.02729386 0.01757302 0.04280699
  0.04512152 0.02738651 0.01930146 0.02888803 0.01704102 0.01396776
  0.04802954 0.03340416]
 [0.03197812 0.02561018 0.02322907 0.01939557 0.0171776  0.02226901
  0.03324887 0.03228546 0.03412595 0.0232097  0.02753077 0.02244502
  0.02907822 0.01498041 0.01484178 0.02546981 0.03500453 0.02984129
  0.05193301 0.04392691 0.03425542 0.03196374 0.02555132 0.03799682
  0.0427317  0.03983469 0.02274323 0.03851114 0.02502565 0.01657997
  0.04018834 0.02789982]
 [0.03345992 0.02366052 0.02193788 0.02280893 0.01849838 0.02259116
  0.02666164 0.03024586 0.02897838 0.02464127 0.0268842  0.02553683
  0.02687136 0.01875006 0.01553747 0.02168311 0.02467196 0.02446318
  0.03138587 0.02768609 0.02829375 0.02957381 0.01832574 0.0226554
  0.02357479 0.02599279 0.01937029 0.02693403 0.02228058 0.0174065
  0.030022   0.03872506]
 [0.03199051 0.0314621  0.03195657 0.04913453 0.04448059 0.04248948
  0.030629   0.03282316 0.03908721 0.04964323 0.03247064 0.03707898
  0.03660439 0.06683887 0.08801527 0.02260307 0.0266467  0.0261529
  0.02489209 0.02487529 0.02230239 0.03276898 0.03222556 0.01490587
  0.0167068  0.03480104 0.03397717 0.04391651 0.0499989  0.02421798
  0.01277596 0.02103712]
 [0.03163094 0.04216187 0.0357959  0.07379162 0.16227856 0.05566961
  0.03363518 0.03432142 0.04121616 0.07433602 0.05009858 0.05086433
  0.03483459 0.10220071 0.1340081  0.03242086 0.04929612 0.04345309
  0.03426499 0.02949396 0.03498592 0.03201142 0.04156161 0.01349219
  0.0156069  0.03470956 0.05049768 0.04292716 0.05068375 0.01924769
  0.00855411 0.00943255]
 [0.03167696 0.03400514 0.02658232 0.04341489 0.07912661 0.02702798
  0.0242242  0.02659864 0.02961685 0.04464284 0.03556317 0.03288304
  0.02501382 0.03522298 0.05199381 0.02883004 0.06542324 0.05809259
  0.05154047 0.03693642 0.06898569 0.02966918 0.03555059 0.02699517
  0.02555169 0.03327138 0.03995209 0.05322453 0.03217268 0.01437609
  0.0142866  0.01198215]
 [0.03178018 0.03755517 0.02829524 0.04609619 0.05338893 0.03210762
  0.03017064 0.03114445 0.03684522 0.04406035 0.03226104 0.03193258
  0.02881664 0.04069626 0.04518913 0.02284583 0.04236572 0.04153008
  0.04053811 0.03400715 0.04222324 0.04039877 0.04160368 0.0181663
  0.02093283 0.03495095 0.03505101 0.06300986 0.04005505 0.01182926
  0.01148882 0.0117188 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' current', ' location', '.', ' The', ' sentences', ' only', ' mention', ' Bill', "'s", ' movements', ' and', ' possible', ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.028167   0.03524051 0.03529602 ... 0.04932471 0.01502169 0.01871504]
 [0.02891867 0.02530431 0.02658379 ... 0.02905972 0.01528548 0.01968545]
 [0.02950293 0.03625373 0.0399602  ... 0.03492338 0.01328686 0.0152785 ]
 ...
 [0.02977879 0.03227263 0.02554571 ... 0.04200148 0.0303082  0.03249577]
 [0.03035636 0.03516873 0.02967886 ... 0.04693008 0.01916995 0.0156443 ]
 [0.03053937 0.02988452 0.02733778 ... 0.05492163 0.01623927 0.01575303]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Fred', ' went', ' back', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0968, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03022847 0.03776571 0.04363903 ... 0.08298808 0.00991445 0.00884317]
 [0.03082223 0.03169636 0.03412782 ... 0.05187698 0.01522009 0.01164522]
 [0.03163224 0.04160976 0.05120803 ... 0.07013426 0.02091679 0.01320449]
 ...
 [0.0317563  0.04841418 0.04671746 ... 0.02811444 0.00568445 0.00492126]
 [0.03204672 0.03639398 0.03171417 ... 0.01722328 0.00760533 0.00746374]
 [0.032028   0.04323254 0.03774504 ... 0.01932067 0.00451505 0.00498247]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' answer', '.', ' Bill', ' could', ' be', ' in', ' either', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.0, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02303432 0.03300079 0.03684058 ... 0.02907885 0.01377649 0.00981828]
 [0.02363734 0.02512592 0.02965878 ... 0.02761913 0.02322563 0.01519023]
 [0.02415048 0.03369255 0.04081346 ... 0.02584564 0.01277952 0.0083184 ]
 ...
 [0.02421109 0.03449275 0.03216339 ... 0.02701771 0.01253847 0.00814394]
 [0.02466304 0.03029731 0.02620004 ... 0.02867277 0.02087796 0.01611221]
 [0.0249008  0.02865952 0.02528781 ... 0.0278314  0.01497457 0.0115217 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '2', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(23, 26), x_tokens=26, y_tokens=23, max_supp_attn=0.0435, attn_on_target=0.0435)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (23, 26)
DEBUG result.interpretability.attn_scores 598 
 [[0.04052964 0.06848034 0.08555776 0.09352919 0.09536543 0.09621982
  0.0886413  0.10655323 0.08878512 0.08381271 0.06684262 0.08475633
  0.10043781 0.10695031 0.06402872 0.04702727 0.04081216 0.04762812
  0.04132643 0.04807764 0.04066236 0.05561447 0.05870886 0.03381612
  0.02069265 0.03373925]
 [0.04043857 0.11340877 0.09180732 0.08187827 0.06527798 0.08417474
  0.23158537 0.16544303 0.0988761  0.08130593 0.10458715 0.08070432
  0.12681484 0.04509064 0.03366911 0.05629482 0.04653079 0.06857591
  0.05063891 0.06380698 0.05358584 0.06232246 0.0571914  0.05121887
  0.02680988 0.03328755]
 [0.04435586 0.08048423 0.05133465 0.06751311 0.04882053 0.04638283
  0.03830072 0.03006065 0.03164683 0.04361493 0.03919528 0.02189106
  0.02533776 0.03657079 0.04646874 0.03512605 0.01858471 0.01923553
  0.02320535 0.02517768 0.02451301 0.06067348 0.07091759 0.01444116
  0.00709297 0.01460306]
 [0.04203549 0.03858354 0.03800511 0.02740294 0.01809623 0.03062663
  0.02889352 0.02682531 0.03668833 0.02931319 0.03087253 0.02932303
  0.0285785  0.01259545 0.01206995 0.03966813 0.03760549 0.0447086
  0.05143783 0.05413258 0.04775674 0.04360413 0.05776948 0.07815509
  0.08371618 0.08744153]
 [0.04217817 0.05684326 0.06302706 0.08238719 0.07292282 0.0607801
  0.0410891  0.03903232 0.04753924 0.05703548 0.04760601 0.03403973
  0.0348017  0.12075926 0.12159332 0.05431416 0.03579158 0.03009756
  0.02995453 0.03404378 0.03407178 0.05406647 0.08233789 0.0244285
  0.01050889 0.03185915]
 [0.04306462 0.03711843 0.03923607 0.06433018 0.05481126 0.05564086
  0.03106266 0.03075849 0.04062394 0.0537223  0.04249848 0.03878511
  0.03770326 0.13095444 0.15247154 0.05349386 0.03976718 0.03598031
  0.03374869 0.03637191 0.03278796 0.04623511 0.04974701 0.01770261
  0.00880364 0.02102922]
 [0.04371975 0.04155509 0.0498047  0.06650227 0.05937503 0.06953039
  0.04043272 0.04162759 0.05301069 0.06247047 0.04883599 0.06064421
  0.05660157 0.1036949  0.09444823 0.04474386 0.03585417 0.03532007
  0.03226589 0.03559776 0.03050755 0.04168825 0.04625926 0.02342824
  0.01230525 0.02095537]
 [0.04227301 0.05899745 0.06846087 0.05232073 0.05264573 0.06321753
  0.04503332 0.05398359 0.05886811 0.05611779 0.04938376 0.06574693
  0.05749616 0.06292312 0.05513117 0.05862574 0.04631193 0.04443621
  0.03973776 0.04404345 0.04020768 0.04735655 0.06812675 0.05068228
  0.03324614 0.04366687]
 [0.04342115 0.05632274 0.06713852 0.03663693 0.02869812 0.04381815
  0.05400213 0.05083947 0.06026397 0.038886   0.03965507 0.04524425
  0.0429961  0.02205745 0.01905343 0.06452727 0.04415273 0.04050392
  0.04308588 0.0477109  0.0423387  0.0406851  0.06514803 0.06265599
  0.05476449 0.05077974]
 [0.04404817 0.02269532 0.02789794 0.01832983 0.01512246 0.02503894
  0.02341018 0.02701992 0.03661634 0.02298605 0.02163185 0.02621681
  0.02530198 0.01051379 0.00951644 0.03404226 0.02948185 0.02921481
  0.03420391 0.03624912 0.03485782 0.0273677  0.04083815 0.06933453
  0.08392345 0.08430985]
 [0.04344674 0.03901395 0.04370294 0.02675061 0.0208972  0.03759054
  0.0332833  0.03992325 0.04090391 0.03233993 0.03456083 0.04460169
  0.03765037 0.01469286 0.01348895 0.05468642 0.04619089 0.04436391
  0.04705225 0.04472734 0.04135215 0.04249711 0.04162338 0.05845904
  0.07966557 0.06055535]
 [0.04448686 0.05049731 0.05609601 0.04386673 0.03064904 0.0586824
  0.04666466 0.05878338 0.05457454 0.05648085 0.0538738  0.08676185
  0.06510247 0.02412678 0.01703634 0.04287433 0.0420184  0.04512952
  0.04159461 0.0424976  0.03780245 0.04406459 0.033238   0.03303355
  0.02935539 0.03000709]
 [0.04509917 0.0347448  0.03823528 0.02730675 0.02202317 0.03455888
  0.03640107 0.03799696 0.03714228 0.03283982 0.04002689 0.0444427
  0.03954378 0.01434752 0.01274874 0.04357251 0.04329759 0.03785398
  0.0397794  0.0388269  0.03744953 0.04181376 0.02758326 0.04290225
  0.04898797 0.02980442]
 [0.04427232 0.02568808 0.02441945 0.01723155 0.01462219 0.02089544
  0.02401385 0.0260925  0.02708729 0.02100654 0.03076464 0.02859606
  0.02930039 0.00872335 0.00937306 0.04199434 0.05128029 0.04052185
  0.04750676 0.04206255 0.04485221 0.03855859 0.02286628 0.06605839
  0.08957398 0.05277734]
 [0.04391439 0.02484845 0.02227232 0.01656173 0.01370804 0.01929066
  0.02742268 0.03010778 0.02608739 0.01974768 0.03146843 0.02623566
  0.03254734 0.00777914 0.00797761 0.04179643 0.05312984 0.0477845
  0.05662093 0.05168572 0.0655333  0.03528129 0.02089037 0.07998472
  0.11266922 0.05335408]
 [0.04466225 0.02316178 0.02110906 0.01610878 0.01437414 0.01931908
  0.02186987 0.02622325 0.02520748 0.0206453  0.03196806 0.03010164
  0.02899078 0.00795318 0.00800393 0.03578025 0.0585894  0.04207212
  0.05932892 0.04558931 0.05022062 0.03351064 0.01712884 0.03903618
  0.08445721 0.05883158]
 [0.04453409 0.02066941 0.01911651 0.01345051 0.01232288 0.01652461
  0.02150216 0.02429543 0.02360364 0.01748721 0.03598337 0.02583571
  0.02709737 0.00656838 0.00703687 0.03804127 0.05172547 0.04439586
  0.06109332 0.05313887 0.05799477 0.03188257 0.01754313 0.04810708
  0.05988804 0.07984085]
 [0.04393292 0.02770551 0.02592119 0.01628541 0.01360353 0.02168238
  0.02728853 0.0307068  0.03038696 0.01864937 0.0295861  0.02498334
  0.0298138  0.00828756 0.0077277  0.03613405 0.03159712 0.04011662
  0.04280993 0.04707336 0.05450372 0.03595166 0.03063423 0.09616408
  0.07815641 0.06818353]
 [0.04515322 0.02617786 0.02631045 0.02254459 0.01652295 0.0250723
  0.02475527 0.02983564 0.03078692 0.02613685 0.03113811 0.03239729
  0.03079084 0.01194587 0.01079858 0.02649895 0.02840246 0.03250648
  0.04201384 0.04215037 0.04151306 0.03540488 0.02124525 0.02914789
  0.02751433 0.04356337]
 [0.04398682 0.03708769 0.03666922 0.0542165  0.05291468 0.05222253
  0.03076682 0.03274105 0.03972403 0.05703183 0.04437749 0.04479348
  0.04171567 0.08707524 0.09929831 0.03665984 0.03639469 0.03659179
  0.03335276 0.03480573 0.03403619 0.04276209 0.04133273 0.01826369
  0.01108871 0.02323596]
 [0.04370565 0.0389143  0.03557028 0.0576915  0.1061429  0.04660273
  0.0284252  0.03025982 0.03748425 0.06184833 0.05013736 0.04213721
  0.03353216 0.08331689 0.10756595 0.04395419 0.05036711 0.05301822
  0.04103212 0.03925301 0.04124787 0.03936649 0.03928376 0.01498373
  0.00783332 0.020073  ]
 [0.04315963 0.03401436 0.03130762 0.04678383 0.09735677 0.03259955
  0.02351319 0.0286984  0.03333867 0.05320416 0.04774212 0.04283222
  0.0322673  0.03593903 0.04818904 0.03756888 0.08045747 0.08291401
  0.06070727 0.04765641 0.06238514 0.03587183 0.03658605 0.02651282
  0.01644899 0.03210818]
 [0.04358158 0.04298733 0.03699981 0.05037076 0.07372688 0.03952887
  0.03164238 0.0321922  0.04075392 0.05331728 0.04726407 0.03892936
  0.03557804 0.03713403 0.04230421 0.03257522 0.05165666 0.05703011
  0.04750252 0.04532096 0.04981958 0.06342082 0.05300032 0.02148323
  0.01249728 0.02599357]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Mary', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01949382 0.03376862 0.03300254 ... 0.0090747  0.05160189 0.05257156]
 [0.02004341 0.03370775 0.03215381 ... 0.01483693 0.05163648 0.03726779]
 [0.02037964 0.03150912 0.03347245 ... 0.022195   0.0367292  0.03466198]
 ...
 [0.02049837 0.0286189  0.02532276 ... 0.00600146 0.07054584 0.0341791 ]
 [0.02078453 0.02394773 0.02007503 ... 0.00837798 0.05118828 0.02704631]
 [0.02092656 0.02250052 0.01900094 ... 0.00721024 0.08630484 0.03950455]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.0501515  0.077672   0.06874344 0.08901962 0.06688252 0.07749035
  0.06630855 0.06532998 0.0638807  0.0808433  0.05700273 0.05802658
  0.06336516 0.11658829 0.10900573 0.04700038 0.04269691 0.04358824
  0.03555918 0.04194339 0.03582325 0.05469752 0.08197663 0.03458834
  0.02625416 0.05089927 0.06765163 0.05710766 0.13924582 0.01478912
  0.05883979 0.0776365  0.04584264 0.04325634 0.02982856 0.02430583
  0.04851214 0.08008073]
 [0.05066604 0.06231619 0.06120697 0.06745633 0.05848139 0.07788038
  0.07854966 0.08950661 0.07133245 0.07633246 0.06083243 0.08630145
  0.12082553 0.07947059 0.07178321 0.04206886 0.04342663 0.05080262
  0.0444007  0.04978152 0.03913919 0.05360939 0.05605794 0.03642063
  0.03518732 0.05211388 0.06110679 0.04851693 0.10159167 0.06111829
  0.04551583 0.05564502 0.06008964 0.04538792 0.04464671 0.03962387
  0.05678655 0.07115645]
 [0.05227686 0.0724497  0.07209218 0.09691866 0.08479557 0.09658692
  0.06323676 0.06604575 0.07035308 0.0870977  0.05963077 0.06790706
  0.06928138 0.1751683  0.1210112  0.05063025 0.03990702 0.04073605
  0.03244799 0.03854427 0.03097715 0.0549452  0.06399902 0.03304067
  0.0260209  0.04348964 0.0629212  0.04354417 0.08354854 0.02925235
  0.04828609 0.05527196 0.04311594 0.03650408 0.02895081 0.02161302
  0.04617387 0.05602054]
 [0.05076527 0.06299886 0.065726   0.05039298 0.03962538 0.0537554
  0.05738882 0.05783109 0.05597758 0.04899945 0.0475229  0.05324722
  0.05120151 0.04055036 0.03883798 0.05337215 0.04353539 0.04269128
  0.03866882 0.04340347 0.03721021 0.05721004 0.07558435 0.06110719
  0.0528456  0.05597116 0.06674442 0.04559967 0.05740794 0.07346057
  0.03050197 0.06222526 0.09509365 0.07047138 0.05702052 0.04141515
  0.0654994  0.05932668]
 [0.05215862 0.06640935 0.06645295 0.04156822 0.03106862 0.04780292
  0.06637383 0.056269   0.06579261 0.0394379  0.04206817 0.04386926
  0.04361399 0.02949732 0.02982622 0.05859419 0.04544885 0.04132068
  0.04123968 0.04591588 0.03667649 0.04908435 0.07095488 0.06125601
  0.0520355  0.04531664 0.0621436  0.03027452 0.04049913 0.0662982
  0.02586547 0.05417767 0.07014435 0.08475737 0.06638155 0.04521919
  0.04991557 0.04858997]
 [0.05310548 0.03628246 0.03580656 0.02475865 0.02032689 0.02851734
  0.03670796 0.03522918 0.04081007 0.02562144 0.03388445 0.03250291
  0.03155695 0.01757139 0.01984844 0.03699259 0.03450936 0.03405985
  0.03819077 0.04169946 0.03293452 0.04087935 0.03861425 0.04459057
  0.04224496 0.03661871 0.03687144 0.02748582 0.03002167 0.0371132
  0.02127006 0.03366597 0.02982328 0.06080608 0.06066362 0.04873708
  0.03836108 0.04258117]
 [0.05196853 0.05637089 0.05618266 0.03901265 0.03033928 0.04685784
  0.05490067 0.05279955 0.05256681 0.03970183 0.04715491 0.05159324
  0.04588301 0.02837347 0.02611038 0.06376182 0.05078075 0.05229195
  0.05075234 0.05233665 0.04671661 0.05565995 0.05242004 0.07307378
  0.07574903 0.05739413 0.06424961 0.04075971 0.04193342 0.14688422
  0.02244459 0.051529   0.08064214 0.06417881 0.05617286 0.05175522
  0.05644092 0.04156005]
 [0.05333853 0.05413564 0.05248355 0.04543553 0.03323222 0.04743089
  0.0486918  0.04933853 0.04890906 0.04465657 0.04895578 0.05089007
  0.04653403 0.02878809 0.02406068 0.03905697 0.03218235 0.03553499
  0.03686719 0.04201996 0.03820429 0.05090068 0.04193645 0.049907
  0.05314505 0.04955507 0.06450881 0.04549795 0.0397224  0.1521972
  0.03331333 0.05356214 0.07852895 0.06266356 0.06220178 0.06141915
  0.0673482  0.05441693]
 [0.0543168  0.04632667 0.04903232 0.03759726 0.02946041 0.04098336
  0.04924089 0.04723328 0.04531519 0.03655064 0.04499255 0.04580884
  0.04443632 0.02413338 0.02182831 0.04451512 0.03564378 0.03751345
  0.04050315 0.04378096 0.04018532 0.04906441 0.03906978 0.0528461
  0.05955335 0.04333718 0.05109513 0.04085153 0.03450397 0.10167336
  0.02493663 0.03882861 0.05020535 0.04796896 0.05056695 0.05114964
  0.05205666 0.03662632]
 [0.05317564 0.04046779 0.03785871 0.02851516 0.02333274 0.03119056
  0.04504021 0.04172596 0.03796137 0.02834874 0.04447802 0.03844819
  0.04210258 0.01736626 0.01881164 0.06450606 0.05095654 0.05389228
  0.05680967 0.05606163 0.05248814 0.05458341 0.0333428  0.07213438
  0.07634164 0.04157117 0.03612623 0.04215264 0.02988676 0.06135293
  0.02082661 0.03576543 0.04478604 0.0493378  0.0652714  0.06659507
  0.04988773 0.03252786]
 [0.0526599  0.04066942 0.03722471 0.0299234  0.02303674 0.03215063
  0.04841534 0.04398699 0.03880448 0.02936448 0.04143314 0.03613081
  0.04327516 0.01726806 0.01887189 0.0686954  0.05121074 0.07233991
  0.08472011 0.08619443 0.08148662 0.04949715 0.03454837 0.09773244
  0.1048874  0.06185617 0.03755184 0.05890181 0.03016707 0.05317543
  0.02025903 0.03882861 0.04475196 0.05486253 0.08249877 0.08950549
  0.0589578  0.03654039]
 [0.05390298 0.03661371 0.03644056 0.02794328 0.02263392 0.03187761
  0.04045171 0.04015124 0.03625811 0.0284887  0.04450733 0.04068784
  0.04110512 0.01697127 0.01779014 0.06134841 0.05216937 0.05189703
  0.07029619 0.05991659 0.06504066 0.0481748  0.02957989 0.07236505
  0.10790399 0.06053483 0.04247667 0.0530687  0.02813615 0.05722073
  0.02094218 0.0333012  0.04386578 0.0561173  0.06332697 0.08648736
  0.04769096 0.03369885]
 [0.05381401 0.03523685 0.03763466 0.02581662 0.02237453 0.03121756
  0.04517459 0.04271122 0.03812743 0.0289166  0.06032116 0.04397772
  0.04548327 0.01597399 0.01737121 0.07093326 0.06241076 0.05888684
  0.07802123 0.06886936 0.06756844 0.0497453  0.03001636 0.07414339
  0.08915823 0.08927891 0.04011146 0.05922674 0.02665406 0.03861932
  0.01960071 0.03283696 0.04461562 0.04890025 0.07005808 0.09628651
  0.04166899 0.03827289]
 [0.05304316 0.05849092 0.05533892 0.03496306 0.03125172 0.04806094
  0.06718785 0.05983528 0.05508763 0.0363147  0.05327072 0.05192584
  0.05730809 0.02277821 0.02115687 0.05474361 0.05739124 0.05301339
  0.05632384 0.06046145 0.04588703 0.05525317 0.05678043 0.07626958
  0.06563383 0.06543647 0.04484189 0.04058029 0.03334344 0.02604295
  0.02270141 0.04907514 0.06649739 0.08168088 0.09888851 0.10246194
  0.04440393 0.05325793]
 [0.05441039 0.03437559 0.04314758 0.03794396 0.0288806  0.04284951
  0.03857024 0.04282069 0.0446935  0.04237715 0.04707024 0.04868477
  0.04661017 0.02751367 0.02325248 0.03943475 0.03963764 0.0412355
  0.05011079 0.04851552 0.0465959  0.04686543 0.03033841 0.03054987
  0.03322354 0.05556713 0.03661224 0.05460856 0.03707651 0.03463703
  0.03104473 0.03537372 0.03677636 0.03023194 0.04075785 0.04600508
  0.04168523 0.03908219]
 [0.05277565 0.04969971 0.05367289 0.07217788 0.06335179 0.06452329
  0.04687944 0.04992379 0.05663759 0.07192559 0.05587596 0.0532888
  0.05064568 0.09091207 0.10683457 0.04048285 0.04126908 0.04319461
  0.03878872 0.04248825 0.04053443 0.05403008 0.05550282 0.02795677
  0.02280887 0.04484401 0.05326594 0.06587499 0.06943495 0.01363658
  0.08250857 0.06254857 0.03338503 0.03869524 0.03150215 0.02988547
  0.04941451 0.07559761]
 [0.05242351 0.0632437  0.0658118  0.1100575  0.20759612 0.09094646
  0.05262754 0.05638268 0.06329308 0.11115155 0.086201   0.08077735
  0.05825605 0.14790341 0.18535985 0.06140282 0.08483989 0.07867926
  0.0607337  0.0539837  0.07296364 0.05406022 0.07389782 0.02860412
  0.02000347 0.04868858 0.07063245 0.06746712 0.07371683 0.00928658
  0.15007006 0.08031833 0.03657186 0.03696547 0.0234101  0.02433522
  0.05501893 0.06529053]
 [0.05241024 0.05279911 0.04993565 0.06832486 0.1124067  0.05037713
  0.04218344 0.04530067 0.04559197 0.07458091 0.06784054 0.06054099
  0.04738681 0.0512106  0.07247664 0.05831394 0.12256786 0.10277451
  0.08727384 0.06651187 0.12706834 0.05253147 0.06529781 0.04227464
  0.0336144  0.0501827  0.05333074 0.0855626  0.05030464 0.01416451
  0.16962625 0.06333198 0.05930571 0.04495377 0.03572873 0.03813832
  0.06934083 0.05269242]
 [0.05263691 0.05344145 0.05520783 0.0721743  0.07092287 0.05950087
  0.05207078 0.05757846 0.06860724 0.06929026 0.05695713 0.05539106
  0.05112918 0.05196129 0.05576252 0.04414659 0.06941583 0.06554756
  0.05829208 0.05757157 0.06249985 0.06920817 0.07008195 0.03113955
  0.02338886 0.04734438 0.0477579  0.09291862 0.05280514 0.00907747
  0.15144664 0.08607786 0.03595835 0.04226036 0.0321241  0.03506138
  0.06083677 0.08268048]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', ',', ' so', ' we', ' cannot', ' determine', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 44), x_tokens=44, y_tokens=27, max_supp_attn=0.0741, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 44)
DEBUG result.interpretability.attn_scores 1188 
 [[0.03451873 0.03652583 0.03759239 ... 0.01756039 0.01903072 0.02269844]
 [0.0351635  0.04693529 0.05090867 ... 0.02715905 0.02731865 0.02754728]
 [0.03607069 0.03295208 0.03654832 ... 0.03572696 0.03342589 0.03088885]
 ...
 [0.03679443 0.03612448 0.02787641 ... 0.02004646 0.01737622 0.02920844]
 [0.03728769 0.03765313 0.03058428 ... 0.02196389 0.01771021 0.02674159]
 [0.03733658 0.0324372  0.02687462 ... 0.01670129 0.01710943 0.01942024]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 50), x_tokens=50, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 50)
DEBUG result.interpretability.attn_scores 950 
 [[0.05001575 0.05933071 0.06103634 0.07563835 0.05740436 0.06702749
  0.05233117 0.05944978 0.06340706 0.05930069 0.0509492  0.05485274
  0.05918624 0.0917965  0.09643813 0.04494566 0.04024553 0.04016444
  0.04342796 0.04328827 0.03899564 0.05227374 0.08021516 0.02766764
  0.02306681 0.0538208  0.06182688 0.06906538 0.14972222 0.020865
  0.05814802 0.07831158 0.05098142 0.04044833 0.03079892 0.03239612
  0.04912869 0.08350574 0.06365014 0.10749026 0.01518692 0.02856717
  0.03335357 0.03716217 0.0234004  0.06613553 0.06227925 0.04175616
  0.03000076 0.02707215]
 [0.05106628 0.06345246 0.07472259 0.06415161 0.05043082 0.06433985
  0.06835747 0.08854476 0.07101201 0.05571864 0.05450307 0.06911115
  0.07951467 0.05565235 0.07117134 0.05936911 0.05047479 0.06213659
  0.05845825 0.06811072 0.0553473  0.05905447 0.06015512 0.04747413
  0.05136117 0.06720161 0.04797994 0.06382429 0.10500135 0.04029131
  0.03330829 0.0580929  0.07677513 0.04555103 0.04542634 0.05214233
  0.04713842 0.05869306 0.08313487 0.05846716 0.03253877 0.03980364
  0.04642611 0.05149299 0.05008028 0.03600755 0.05722953 0.05058715
  0.04412461 0.04994219]
 [0.0521796  0.05643853 0.06399208 0.08994475 0.07781547 0.09287554
  0.05389204 0.05883896 0.06931063 0.07604448 0.05355093 0.06383485
  0.0652196  0.14662264 0.09993647 0.04484241 0.03520032 0.03295503
  0.03521926 0.0360931  0.03024169 0.05321844 0.06495886 0.02549982
  0.01901591 0.03907105 0.06678443 0.04661668 0.09251817 0.03734687
  0.05356556 0.05991125 0.04605454 0.03712983 0.02527745 0.02507945
  0.04377573 0.05802906 0.05252552 0.10651949 0.0184256  0.04969302
  0.05205507 0.0527465  0.02603081 0.07048199 0.05914189 0.03527749
  0.02494079 0.02312027]
 [0.050814   0.04924592 0.05685227 0.04574736 0.03593999 0.04976576
  0.04473777 0.0501873  0.05175877 0.04355328 0.04252493 0.04908193
  0.04688537 0.0361733  0.03324863 0.0468946  0.0387889  0.03483616
  0.04099998 0.04106025 0.0362173  0.05596587 0.06453352 0.04338619
  0.04346338 0.05085225 0.06137102 0.04500206 0.0582787  0.07342496
  0.02881189 0.05559616 0.08035832 0.05633219 0.04482319 0.03956294
  0.05739867 0.05835691 0.09412627 0.11402485 0.03687612 0.06551474
  0.06461076 0.05915397 0.03627916 0.04015274 0.05212197 0.05950555
  0.04740439 0.03863013]
 [0.0521318  0.05443066 0.06110012 0.04134376 0.0314646  0.04870778
  0.05508167 0.05087447 0.06150582 0.04124463 0.03856748 0.04364217
  0.04329111 0.03327185 0.02969602 0.04891324 0.03738275 0.03207844
  0.04227928 0.04356705 0.03536436 0.05075392 0.06353274 0.04106379
  0.03902997 0.04189824 0.06672745 0.02903104 0.04389146 0.07856274
  0.02662759 0.05022502 0.06091424 0.06437694 0.05058937 0.03841696
  0.04607492 0.04412873 0.05082685 0.10776319 0.03872715 0.06306992
  0.04657102 0.04266304 0.02596249 0.03124595 0.05644179 0.06664249
  0.05376179 0.0425173 ]
 [0.05347332 0.03815567 0.04115856 0.02631545 0.02171533 0.03003913
  0.03327596 0.03645821 0.04316477 0.03027004 0.03262348 0.03202191
  0.03198929 0.01954223 0.02134921 0.0474625  0.03962072 0.03261112
  0.045462   0.04322411 0.03589891 0.04227127 0.04452074 0.04727672
  0.05071273 0.04305144 0.03373412 0.02658562 0.0339454  0.05170693
  0.02011512 0.03409413 0.03137926 0.056019   0.05216102 0.04122462
  0.03468533 0.03471659 0.05125985 0.05846341 0.03371716 0.03034493
  0.02492622 0.02383125 0.01954019 0.01972497 0.03739647 0.04825528
  0.04355737 0.0370209 ]
 [0.05214582 0.04517566 0.0494047  0.0363414  0.02699682 0.04299099
  0.04078921 0.04284794 0.04611655 0.03888251 0.03964501 0.04616652
  0.04229986 0.02695866 0.02260926 0.04928109 0.04122883 0.03988451
  0.05097939 0.05270704 0.04339943 0.05266581 0.04648893 0.05196435
  0.06761212 0.05206125 0.04957547 0.03742874 0.04075322 0.13813193
  0.02312359 0.050802   0.07303385 0.06876469 0.05775487 0.05538635
  0.05961176 0.04552934 0.07594051 0.08379518 0.06126089 0.10027006
  0.0650616  0.0643779  0.0547262  0.02854957 0.04965156 0.06247711
  0.05647733 0.05001553]
 [0.05344018 0.04861902 0.05283735 0.05188777 0.03645331 0.05622499
  0.04631973 0.05360406 0.05150767 0.05419737 0.04519327 0.05966968
  0.05315288 0.03706269 0.02692183 0.03676527 0.03522557 0.03655254
  0.04045259 0.04223732 0.03738025 0.05184055 0.03958913 0.0346069
  0.03874947 0.03889249 0.04592854 0.03608323 0.03634094 0.12673153
  0.03002597 0.04543086 0.0569095  0.04307402 0.03534156 0.03956735
  0.05117972 0.04146029 0.06131863 0.05697866 0.0503565  0.09305217
  0.07942062 0.08525319 0.06172924 0.04594379 0.05074725 0.04787035
  0.03867844 0.0469567 ]
 [0.05416736 0.04458813 0.05036129 0.0423714  0.0303505  0.04646933
  0.0468133  0.04793968 0.04442542 0.04348037 0.04053445 0.05022409
  0.04652633 0.02897557 0.02308048 0.0423901  0.03694097 0.03375803
  0.03947808 0.04071509 0.03714564 0.04993551 0.03832425 0.04179757
  0.0501153  0.03577885 0.04684028 0.03543184 0.03126673 0.09783794
  0.0244772  0.03927993 0.04832038 0.04831908 0.04063211 0.04156841
  0.05488678 0.03414182 0.04909487 0.06047153 0.07564063 0.08213952
  0.0808182  0.07590143 0.07816076 0.03037139 0.04566691 0.05478973
  0.05160745 0.0483157 ]
 [0.05319515 0.03891278 0.03760391 0.029581   0.02262029 0.03230357
  0.03618255 0.03746033 0.03511909 0.03304042 0.03834414 0.03912318
  0.04068029 0.02019105 0.01839139 0.05796097 0.04989289 0.04595341
  0.05099598 0.04832622 0.048874   0.0555552  0.03250584 0.08237714
  0.08912706 0.04356851 0.04057211 0.04473296 0.02856813 0.0732953
  0.02027943 0.03516416 0.04294559 0.06218464 0.06287999 0.0606667
  0.06094874 0.03566901 0.05052709 0.03754839 0.10431541 0.05162945
  0.06996924 0.06610365 0.09045879 0.02493543 0.04046067 0.06083699
  0.06428    0.06280308]
 [0.05292176 0.04150515 0.03762609 0.02982305 0.02288265 0.03284184
  0.04177213 0.0419842  0.03621577 0.03355075 0.03768196 0.03848589
  0.04379454 0.02011572 0.01749399 0.06121222 0.0522634  0.05223345
  0.05544763 0.05441291 0.05536908 0.05111417 0.0285194  0.10963506
  0.1110427  0.0465817  0.04307938 0.05325027 0.0251697  0.06171874
  0.01801819 0.03388781 0.0428929  0.06556641 0.0659716  0.06690791
  0.06985682 0.03551339 0.03893617 0.02276933 0.11452971 0.04557406
  0.06242262 0.07198057 0.11949578 0.02324006 0.04366608 0.07208168
  0.09717131 0.08813226]
 [0.05356605 0.03873108 0.03664731 0.0287317  0.02421729 0.03224046
  0.03324643 0.03541791 0.03513959 0.0337646  0.038399   0.0399467
  0.04016906 0.02016432 0.0172145  0.05025814 0.04816993 0.04494726
  0.05384487 0.05083302 0.05260247 0.04837457 0.03120204 0.07214146
  0.09601212 0.06408054 0.0399453  0.04871397 0.02557843 0.05556966
  0.01955568 0.03404517 0.04402582 0.06372526 0.06816709 0.07265987
  0.05189379 0.03917781 0.04240012 0.02275807 0.12131101 0.05882791
  0.05881274 0.05745736 0.10917911 0.02774561 0.04249042 0.06264075
  0.08042544 0.09022469]
 [0.05393885 0.03880073 0.03677209 0.02663819 0.02345301 0.03063308
  0.03607708 0.03617189 0.03520621 0.03243288 0.0518504  0.04023017
  0.04211644 0.01885454 0.01698928 0.05972276 0.05831967 0.04985964
  0.05831726 0.05361639 0.05381402 0.05091055 0.03424052 0.09800258
  0.09221259 0.0632361  0.03094193 0.04546124 0.02276119 0.03832865
  0.01833378 0.03352764 0.04257673 0.05727491 0.08146411 0.08834665
  0.04513802 0.0401821  0.03480607 0.01788644 0.09859043 0.04490376
  0.05349613 0.0388238  0.07481297 0.02626518 0.04001321 0.04853979
  0.07760429 0.10129515]
 [0.05268384 0.1069776  0.07806929 0.0459427  0.03816437 0.05289514
  0.19921704 0.12323732 0.07954965 0.05136866 0.13883981 0.06760688
  0.11567971 0.02633414 0.02679132 0.12010893 0.10856348 0.12515777
  0.08219071 0.09496206 0.08832209 0.05727326 0.08163016 0.13839406
  0.09805943 0.10934164 0.04695424 0.05662046 0.03745448 0.02629965
  0.02658586 0.07982572 0.11603215 0.0981598  0.15782036 0.16230679
  0.06037141 0.07738453 0.03274102 0.01447047 0.05641532 0.03466627
  0.05790785 0.03517988 0.03795306 0.0235667  0.06975854 0.1012115
  0.13078979 0.14079246]
 [0.05407591 0.03878862 0.04119183 0.03950927 0.02978015 0.0418365
  0.03390452 0.03929755 0.04313914 0.04462741 0.04286974 0.04746386
  0.04389991 0.03298025 0.02390742 0.03463435 0.04054595 0.04105702
  0.04492083 0.04620218 0.04305926 0.04622136 0.03315356 0.03053944
  0.03266219 0.04280219 0.03607043 0.04609129 0.03487152 0.03104222
  0.03115138 0.0376539  0.03443551 0.0343776  0.04536086 0.0558756
  0.04641929 0.04610411 0.06278415 0.03134769 0.0607701  0.10502046
  0.10179802 0.0789769  0.07802412 0.05973335 0.04219268 0.03582792
  0.03926379 0.04334133]
 [0.05266499 0.05199274 0.05133729 0.07324758 0.0619672  0.06603634
  0.04159073 0.04636491 0.05724725 0.0720736  0.05015379 0.05648942
  0.04925422 0.10051784 0.1206828  0.03878778 0.04415724 0.04388672
  0.04412464 0.0456579  0.0434363  0.05235793 0.05438396 0.02105802
  0.01910698 0.04213632 0.05795202 0.06213706 0.06370382 0.01239561
  0.07266481 0.05558567 0.02827032 0.03386828 0.02832426 0.02600946
  0.04245395 0.06349457 0.04150083 0.03452917 0.01809675 0.03108485
  0.03424557 0.04162233 0.02213644 0.11256401 0.05269704 0.03335472
  0.02710116 0.02460007]
 [0.05243317 0.06837675 0.0650679  0.11462106 0.23312321 0.0959344
  0.04998566 0.05504998 0.06709679 0.11491727 0.08353741 0.08439377
  0.05664567 0.16241048 0.19709876 0.05983634 0.08063748 0.07936912
  0.06399222 0.05893533 0.0764781  0.0520804  0.07285389 0.02285336
  0.01734746 0.04934938 0.09368055 0.06502885 0.06968421 0.00999481
  0.15415029 0.07599669 0.03282835 0.03695584 0.02741435 0.02517201
  0.05649216 0.06329952 0.02857761 0.02982636 0.01620835 0.02422154
  0.02070288 0.03412168 0.01991596 0.12509969 0.07077938 0.03424544
  0.02363431 0.02079918]
 [0.05252171 0.05458208 0.04898879 0.06400724 0.10234456 0.05139913
  0.03702204 0.04175037 0.04559384 0.07043567 0.06384029 0.06042699
  0.04725611 0.05701073 0.0745207  0.0527169  0.09494129 0.10240181
  0.0853983  0.06998695 0.11894248 0.05076126 0.05813132 0.03743586
  0.03751817 0.06043122 0.06877885 0.09296425 0.04756204 0.01716679
  0.18670093 0.06200586 0.05696219 0.04831908 0.04548149 0.04282459
  0.07234846 0.06084273 0.05429081 0.01870994 0.02789251 0.02965034
  0.0269453  0.05299137 0.04680081 0.096685   0.04940486 0.04684016
  0.03944784 0.03709856]
 [0.05256443 0.06189583 0.05523022 0.07415633 0.07287619 0.06543867
  0.0494035  0.05452029 0.06348392 0.07109668 0.05639168 0.0572281
  0.05243871 0.06536514 0.06245842 0.04389762 0.06740028 0.070157
  0.06401089 0.06606412 0.06911165 0.06737167 0.07106082 0.02682584
  0.02378446 0.05584448 0.06125705 0.09593078 0.05292834 0.00928933
  0.15435633 0.08056355 0.03430378 0.03955306 0.03431102 0.0338859
  0.05019725 0.07977076 0.03155861 0.01618033 0.0191406  0.02196615
  0.02045653 0.03016001 0.02531343 0.11155143 0.07786055 0.03725977
  0.0297292  0.02732238]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02584241 0.03798989 0.04598817 0.06796603 0.07626163 0.06522221
  0.04504707 0.05294434 0.04419491 0.05881665 0.0396586  0.04841846
  0.05686249 0.10296416 0.07464983 0.02759351 0.02669613 0.02918812
  0.02510613 0.02872028 0.0225037  0.03466913 0.03758051 0.01507619
  0.01619213 0.02790241]
 [0.02548521 0.06224132 0.04572439 0.04138079 0.0321649  0.03904928
  0.09905439 0.05954244 0.04735918 0.03679082 0.05909485 0.03467641
  0.05842695 0.01934848 0.02040818 0.04155072 0.03922333 0.05261008
  0.03832281 0.04835983 0.04119938 0.03824813 0.03781214 0.04133015
  0.04093163 0.04312437]
 [0.02797953 0.05345944 0.03456498 0.05272054 0.03975359 0.03374393
  0.02807342 0.02019478 0.01999573 0.0325507  0.02434451 0.01453512
  0.0165263  0.03145574 0.04038634 0.02140294 0.01231973 0.01249647
  0.01491626 0.01620177 0.01452608 0.04061183 0.04697296 0.00725654
  0.00626615 0.01561572]
 [0.02639771 0.02872548 0.0332702  0.02404159 0.01755246 0.02439311
  0.02712744 0.02460639 0.02397569 0.02308212 0.02741783 0.02415428
  0.02299925 0.01474417 0.01595369 0.03494757 0.03271026 0.03201435
  0.03112097 0.03155216 0.03089163 0.02947846 0.04265941 0.05678081
  0.06136228 0.04261348]
 [0.02660806 0.03826083 0.04332776 0.06603914 0.06048011 0.04502183
  0.03038927 0.02653062 0.03056307 0.04335289 0.02977924 0.02276303
  0.02302055 0.10408796 0.10712769 0.03311867 0.02366408 0.01964243
  0.0193077  0.02197838 0.02026692 0.03612025 0.05488914 0.01255092
  0.00933908 0.03357048]
 [0.02716577 0.02465575 0.02634485 0.05043399 0.04511133 0.04063693
  0.02261996 0.02063289 0.02577752 0.04024927 0.02635252 0.02565381
  0.02469763 0.11348855 0.13442972 0.03270322 0.02659101 0.02364934
  0.02179036 0.0234674  0.01937924 0.03081912 0.03284851 0.0088752
  0.00750661 0.02183058]
 [0.02758003 0.02767383 0.03332145 0.05281217 0.04995371 0.05048433
  0.02922787 0.0278419  0.0333258  0.04728171 0.03071164 0.03999296
  0.03693738 0.08975217 0.08433689 0.0275429  0.02432741 0.02346505
  0.02095048 0.02316418 0.01835774 0.02774412 0.03074244 0.01219503
  0.01039034 0.02044976]
 [0.0266822  0.03501232 0.04192219 0.04094591 0.04344533 0.04653765
  0.03393688 0.03598609 0.03658855 0.04228437 0.03196034 0.04474597
  0.03856374 0.05383342 0.04808104 0.03572712 0.03060391 0.02961426
  0.02553757 0.02871352 0.02534901 0.0312819  0.04362224 0.03190253
  0.02804306 0.03446747]
 [0.02773611 0.03490967 0.0418408  0.04536721 0.04151875 0.05305978
  0.03644818 0.03926532 0.04266455 0.04777383 0.03213652 0.04627961
  0.04230648 0.0417983  0.02710658 0.02579326 0.02401976 0.02527317
  0.02277585 0.02592741 0.02035968 0.03210605 0.03320611 0.01560157
  0.01653139 0.02727027]
 [0.02709756 0.04774172 0.05411787 0.02955146 0.02388674 0.03749485
  0.04075501 0.03963634 0.04169986 0.03006154 0.02607538 0.03505589
  0.03479563 0.01859908 0.01612331 0.04027264 0.03143355 0.02813634
  0.02663396 0.03078867 0.02841262 0.03136178 0.06106858 0.03762488
  0.03982648 0.03634623]
 [0.02761349 0.06125811 0.06142608 0.02717602 0.02217577 0.03091614
  0.04020428 0.03545446 0.04250798 0.02601309 0.02316484 0.02727135
  0.02743088 0.01537433 0.01464687 0.04472169 0.03132213 0.02770078
  0.0276722  0.03371728 0.02777633 0.02857397 0.06294729 0.03141375
  0.02887703 0.03153868]
 [0.02771932 0.03425046 0.03884275 0.02112322 0.01847366 0.02307396
  0.03212833 0.02802589 0.03234344 0.02130939 0.01953928 0.0221172
  0.0212826  0.01325968 0.01346749 0.03941334 0.02938429 0.02452842
  0.02588876 0.02965696 0.02714919 0.02779737 0.05032794 0.04461873
  0.04591278 0.03633917]
 [0.02786996 0.01501565 0.0165262  0.01163925 0.01073047 0.01336485
  0.01543265 0.01548737 0.01711557 0.01266601 0.01344929 0.01372689
  0.01378392 0.00683522 0.0076852  0.01993695 0.01983067 0.01852222
  0.02119618 0.02511243 0.0273666  0.02067963 0.03503144 0.06083409
  0.07694793 0.04517029]
 [0.0278442  0.02116912 0.02204372 0.01562703 0.01501482 0.01860734
  0.02125355 0.02013786 0.02068642 0.01691973 0.01969279 0.01910895
  0.01863965 0.00962118 0.01052919 0.03153091 0.0244811  0.02283181
  0.02224704 0.0250313  0.02640005 0.02581372 0.02681211 0.05585168
  0.0616119  0.04169999]
 [0.02790155 0.02391765 0.02425646 0.0195861  0.01727114 0.02316825
  0.02849819 0.02961061 0.02350092 0.02232491 0.02678215 0.02797835
  0.02940827 0.01178353 0.01059236 0.03010098 0.02824371 0.0273503
  0.02356478 0.02576774 0.02911774 0.0275216  0.02002636 0.04782283
  0.03842177 0.02410958]
 [0.02761448 0.01960352 0.01655032 0.01429503 0.01197335 0.01493364
  0.02259129 0.02267301 0.01695016 0.01542433 0.02292478 0.01778536
  0.0217493  0.00746002 0.00772473 0.0270532  0.029934   0.03570917
  0.02852244 0.03018641 0.0459515  0.02453789 0.01665536 0.06545386
  0.0531882  0.02891595]
 [0.02813296 0.02050084 0.01848043 0.01578567 0.01417548 0.01774526
  0.02422351 0.02545618 0.01844264 0.01812964 0.03061686 0.02500311
  0.02549914 0.00884436 0.00830095 0.02558292 0.02912302 0.02830216
  0.02597351 0.02543593 0.03379012 0.02428494 0.01604478 0.05519396
  0.03789869 0.02084647]
 [0.02805059 0.017716   0.01539044 0.01192096 0.01154215 0.0141928
  0.02218215 0.02073454 0.01672793 0.01398875 0.0370829  0.01953607
  0.02139521 0.0066516  0.0069853  0.02672132 0.03295095 0.03051796
  0.0303406  0.02820903 0.03683423 0.02205532 0.01494424 0.0581458
  0.03687637 0.0248818 ]
 [0.02705349 0.02429263 0.02001714 0.0145494  0.01434035 0.01840888
  0.02700583 0.02486051 0.02464491 0.01781696 0.03436605 0.02104101
  0.02450081 0.00804845 0.00903045 0.02807533 0.05278381 0.03873381
  0.04654215 0.04136361 0.03948044 0.02691015 0.02703627 0.05990383
  0.05264584 0.0546818 ]
 [0.0283907  0.0178787  0.01594211 0.01364271 0.01193184 0.01625549
  0.02054212 0.02081688 0.01818127 0.01560106 0.03699945 0.02159156
  0.02011483 0.00799241 0.00761077 0.02219921 0.02686793 0.02776957
  0.02592031 0.02500529 0.02721831 0.02346286 0.01309916 0.03238006
  0.03109529 0.02627439]
 [0.02876458 0.01959374 0.02175959 0.01862197 0.01582995 0.02380582
  0.0232645  0.02890923 0.02549721 0.02320855 0.02481226 0.03076627
  0.02653197 0.01186938 0.00905474 0.01777999 0.02044405 0.02056097
  0.02243683 0.02129291 0.02031684 0.02602166 0.01418369 0.01525751
  0.02166628 0.0215304 ]
 [0.0286403  0.02096242 0.02146039 0.01792042 0.01518084 0.02199188
  0.02260779 0.02833084 0.02596945 0.02115714 0.02230249 0.02917851
  0.02562292 0.01072948 0.00910201 0.01935032 0.02099046 0.02056641
  0.02359859 0.02241318 0.02259498 0.02600993 0.01675463 0.01469271
  0.02014925 0.02282529]
 [0.02868087 0.02165793 0.02247406 0.01716279 0.01472312 0.02373129
  0.02570979 0.03067692 0.02795564 0.02091787 0.02686252 0.03805603
  0.0301621  0.01022392 0.00883433 0.02129216 0.02599602 0.0255668
  0.0271524  0.02521489 0.02465836 0.02345984 0.01805959 0.01626042
  0.02095712 0.02379998]
 [0.0289023  0.02198474 0.02355707 0.01973379 0.0162404  0.02821677
  0.02380481 0.02892041 0.03376647 0.02454761 0.0193497  0.03327216
  0.02869909 0.01210905 0.00908765 0.01633406 0.01943849 0.01952766
  0.02299179 0.02224571 0.02001021 0.02400093 0.01896531 0.01238902
  0.0197907  0.02590829]
 [0.02838171 0.03162554 0.02882965 0.02147058 0.01706015 0.02991577
  0.03028416 0.03831286 0.03425387 0.0274378  0.02785364 0.04329084
  0.03915624 0.01288408 0.01011773 0.02368812 0.02258058 0.02437201
  0.02571023 0.02597422 0.02427877 0.02785585 0.02138521 0.0152699
  0.01958419 0.0219224 ]
 [0.02896541 0.02298261 0.02556406 0.02019603 0.01538376 0.02858046
  0.0287223  0.03117703 0.03250759 0.02464549 0.02371707 0.03556259
  0.03181686 0.01187654 0.00890566 0.02052956 0.01953592 0.02060985
  0.02310945 0.02453826 0.02259025 0.02513222 0.01577151 0.01274491
  0.01591811 0.01698771]
 [0.02834054 0.01778653 0.01719695 0.01341843 0.01051718 0.01537097
  0.02124573 0.02357871 0.02182661 0.01644936 0.02404882 0.02087752
  0.02535    0.00814921 0.0071748  0.02817776 0.02563952 0.02610736
  0.02885335 0.02880974 0.03352337 0.0248547  0.01209149 0.02390916
  0.02591898 0.02017666]
 [0.02840546 0.01896177 0.01805989 0.01430461 0.01058866 0.01476123
  0.0222169  0.02530879 0.02227991 0.01620737 0.02155348 0.01903965
  0.02431818 0.0079316  0.00682783 0.03156577 0.0266964  0.03275585
  0.02979285 0.0316671  0.04079704 0.02352055 0.01253929 0.02460629
  0.02730894 0.02187002]
 [0.02865278 0.01906931 0.01766874 0.01439623 0.01148911 0.01519675
  0.01967693 0.02387247 0.02199834 0.01746759 0.02379537 0.02228989
  0.02419745 0.00828394 0.00694599 0.02979178 0.02704522 0.0277826
  0.03088699 0.02912179 0.03447456 0.02265424 0.01156524 0.01853201
  0.02057871 0.01762809]
 [0.02851091 0.01681728 0.01677717 0.01175549 0.01017821 0.01332174
  0.01843127 0.02099985 0.02127988 0.0150097  0.02493486 0.01872405
  0.01993525 0.0072919  0.00638501 0.02840769 0.02838697 0.02347844
  0.03071794 0.02749911 0.03274469 0.02289039 0.0118764  0.01977142
  0.02288604 0.02212193]
 [0.02770822 0.01933048 0.01847365 0.01303552 0.01119626 0.01509169
  0.01966564 0.02140848 0.02462218 0.01630933 0.0249668  0.01969685
  0.01987438 0.00814861 0.00742967 0.03387888 0.03229667 0.02521452
  0.03528293 0.02894392 0.03427221 0.02486009 0.01580674 0.02330719
  0.02776734 0.03797308]
 [0.02884277 0.01967125 0.01984983 0.01520856 0.01176466 0.01829034
  0.01961439 0.02280617 0.02533812 0.01773948 0.02109191 0.02142807
  0.02160016 0.00986561 0.00767637 0.02076497 0.02220597 0.020137
  0.02870187 0.02479518 0.02570526 0.02438463 0.01561353 0.0139235
  0.01767229 0.02183175]
 [0.02778547 0.02471371 0.02512995 0.04244475 0.04365285 0.03598262
  0.02217433 0.02305623 0.02914129 0.04616832 0.02896223 0.03152199
  0.03149321 0.06479005 0.08071526 0.0222589  0.02459801 0.02582966
  0.02359093 0.02377269 0.020339   0.0293214  0.02677261 0.00877891
  0.0097382  0.02320845]
 [0.02755799 0.02684703 0.02570424 0.04731597 0.09277298 0.03508912
  0.01953708 0.0209968  0.02628765 0.04835431 0.03251154 0.02797347
  0.02354914 0.07286532 0.09191034 0.02796909 0.03408357 0.0360629
  0.02938847 0.02681208 0.02329479 0.02679223 0.02751555 0.00739141
  0.00685503 0.02057748]
 [0.02741833 0.02339741 0.02246879 0.03797285 0.06944887 0.02563504
  0.01626743 0.02029033 0.02332288 0.04350651 0.03203762 0.0313807
  0.02475343 0.02816482 0.03323518 0.02303367 0.04344535 0.05700259
  0.05668604 0.03657256 0.03178522 0.02327631 0.02320628 0.01236593
  0.01303892 0.02292535]
 [0.02767719 0.02832535 0.02512769 0.03843782 0.05621536 0.02870797
  0.02003569 0.0209165  0.02670686 0.03843576 0.0290498  0.02550602
  0.0239986  0.02887367 0.03142083 0.01918892 0.03010607 0.03636956
  0.03676928 0.03196719 0.02628396 0.04088665 0.03356584 0.00998735
  0.01030496 0.02106424]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Julie', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.1429, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03340549 0.0402723  0.04051293 0.06898121 0.06351647 0.04994522
  0.032793   0.03634994 0.04668669 0.0543239  0.03805292 0.0372152
  0.03571206 0.09966173 0.09733085 0.03647519 0.03182515 0.029237
  0.02967309 0.0315125  0.02761082 0.03705804 0.04690108 0.0215606
  0.0183228  0.03814672 0.03632502 0.04800689 0.11364461 0.0704807
  0.01795247 0.01079681]
 [0.03457598 0.0368641  0.03615136 0.07417627 0.08020308 0.06981414
  0.03335086 0.03413353 0.04393921 0.06660296 0.04643291 0.04958097
  0.04353086 0.16481087 0.14346002 0.04085554 0.03093085 0.0307014
  0.02858736 0.03074628 0.02657385 0.0387507  0.03362781 0.01621063
  0.01439336 0.03264134 0.04059712 0.03535197 0.08693518 0.07932508
  0.02127734 0.01270369]
 [0.03509771 0.03715851 0.03993138 0.06739778 0.06565052 0.05901688
  0.03450291 0.03664334 0.04433304 0.05741699 0.03947506 0.04985277
  0.04262433 0.1073069  0.07893449 0.03371494 0.02917567 0.02722918
  0.02669601 0.02819361 0.02397067 0.03601448 0.03385012 0.01942091
  0.0173302  0.03096626 0.03605649 0.03118471 0.05917273 0.07430931
  0.03356674 0.01806117]
 [0.03384809 0.03446383 0.03717665 0.03693164 0.03362856 0.03710545
  0.03140467 0.03561291 0.03601406 0.03474955 0.03171946 0.03838878
  0.03467307 0.02869123 0.02868931 0.03230244 0.03209697 0.02831166
  0.02986298 0.03222052 0.03006288 0.03788886 0.04168953 0.0424917
  0.03665788 0.04278461 0.03986476 0.03927558 0.04336066 0.07506067
  0.06136649 0.03872711]
 [0.0353319  0.02919276 0.03106462 0.02611942 0.02238984 0.03036089
  0.02703972 0.02958581 0.0308532  0.02729877 0.02674664 0.03417866
  0.02855401 0.01811291 0.01960193 0.02896075 0.03026097 0.02594593
  0.0305163  0.03111034 0.03039804 0.03195516 0.03281978 0.03356064
  0.0371808  0.0388076  0.03503118 0.02808257 0.0278099  0.03422545
  0.07403478 0.06451527]
 [0.03595134 0.03126905 0.03256518 0.02744547 0.02498984 0.03515996
  0.02856228 0.03107049 0.03379853 0.0313144  0.02819487 0.03903767
  0.03262859 0.02093793 0.01949903 0.02759316 0.02759546 0.02485327
  0.02910531 0.02876616 0.0273795  0.03187027 0.03043561 0.02893885
  0.02891643 0.0311752  0.03742356 0.02474903 0.0278918  0.03434455
  0.06638506 0.0753527 ]
 [0.0350314  0.04567708 0.04285428 0.03407158 0.02949838 0.04174541
  0.04065186 0.04153749 0.04122532 0.03760838 0.03390393 0.04907608
  0.04396497 0.02514326 0.02380915 0.03505627 0.03562004 0.03202685
  0.03409313 0.03436149 0.03331774 0.03655786 0.04193607 0.04275336
  0.0399224  0.0383498  0.04691982 0.03378457 0.03279025 0.03891841
  0.04975755 0.08788662]
 [0.03612432 0.03438669 0.03660912 0.02831028 0.02514454 0.03769014
  0.03638059 0.03579672 0.03663374 0.03262253 0.03109879 0.0429319
  0.03833269 0.02161107 0.0203351  0.03272875 0.0324997  0.02873796
  0.03274982 0.03308411 0.03135767 0.03325489 0.03134624 0.03579303
  0.03286907 0.03136772 0.04123183 0.03033805 0.02941801 0.03662647
  0.04938256 0.09277359]
 [0.03509152 0.03155445 0.02628383 0.02246249 0.02218855 0.02542471
  0.03403174 0.02919696 0.02462283 0.02535419 0.03478554 0.02910456
  0.03580303 0.01613601 0.01727498 0.03746486 0.04232422 0.03828818
  0.03797171 0.03796824 0.04572417 0.0359789  0.02416665 0.06181318
  0.04892268 0.03218589 0.02763436 0.03941851 0.02528527 0.02102816
  0.03729863 0.06341176]
 [0.03554532 0.03060695 0.02781126 0.01995454 0.01865478 0.02462012
  0.03709923 0.0304448  0.02645946 0.02258451 0.0290243  0.02845207
  0.03375218 0.01405096 0.01530993 0.03416341 0.03842847 0.03709658
  0.03634451 0.03636489 0.04595119 0.0323862  0.02688429 0.05996357
  0.05658767 0.03961521 0.02699965 0.04625301 0.02473862 0.02188138
  0.044214   0.05737156]
 [0.03584447 0.03674196 0.04223186 0.02132588 0.02275328 0.02894963
  0.03874622 0.03295462 0.0396276  0.02244147 0.0280234  0.02900646
  0.02838643 0.01580916 0.01759596 0.03762174 0.03485331 0.02763293
  0.034346   0.03337197 0.03743197 0.03401151 0.04856415 0.04243937
  0.03769963 0.03855874 0.03874181 0.04000245 0.02401646 0.04483804
  0.0450546  0.04467151]
 [0.0351923  0.05477804 0.05639556 0.02466365 0.02385106 0.0338884
  0.0478522  0.03473801 0.05189795 0.02443788 0.02815387 0.03046983
  0.03095599 0.01789542 0.02075371 0.04152504 0.03412065 0.02714771
  0.03568649 0.03376884 0.03416852 0.03603151 0.06543292 0.03729574
  0.02848225 0.04227281 0.04596775 0.03728145 0.0232566  0.03392435
  0.03486434 0.0277672 ]
 [0.03593032 0.07341707 0.07061414 0.02532873 0.02435988 0.03467617
  0.0473307  0.03853808 0.05117562 0.0253998  0.02578302 0.02992894
  0.0305937  0.01865726 0.0216424  0.05193153 0.03724432 0.02766712
  0.03261822 0.03385879 0.03160259 0.03509826 0.08553379 0.04307484
  0.03193382 0.04389743 0.06171348 0.03040203 0.02620438 0.05901155
  0.03073325 0.02587426]
 [0.0359213  0.03981847 0.04604692 0.0244948  0.02379887 0.03083174
  0.03816739 0.03342123 0.04200552 0.02484213 0.0252369  0.02853847
  0.026642   0.01897439 0.02084901 0.04126261 0.03425156 0.02682617
  0.03297167 0.03375296 0.03109914 0.03364247 0.05419041 0.04623578
  0.03466449 0.04232446 0.05058162 0.03053815 0.02684139 0.05157917
  0.03916106 0.02708448]
 [0.03570382 0.02668835 0.02906542 0.02749694 0.02572418 0.03120946
  0.03061752 0.0321787  0.03525066 0.03369848 0.03006434 0.0374627
  0.03574398 0.02285044 0.0211162  0.03037149 0.03125878 0.02971058
  0.03027096 0.03099075 0.03097812 0.03696095 0.02784765 0.0397599
  0.0373542  0.03460521 0.03114968 0.0431917  0.03460117 0.04534563
  0.04218907 0.03224793]
 [0.03595159 0.04473343 0.04250862 0.02991842 0.02528619 0.03465418
  0.04087836 0.04515375 0.03617458 0.03017833 0.03318447 0.03482755
  0.03959193 0.02311167 0.02131323 0.03656208 0.03259588 0.0288318
  0.03212094 0.03132835 0.02969479 0.03660259 0.033957   0.03195625
  0.03511095 0.03430469 0.04167124 0.0279587  0.02673349 0.03226411
  0.03105824 0.02901259]
 [0.03642169 0.04221617 0.04396715 0.02802407 0.0223302  0.03322092
  0.04693363 0.0443195  0.03510508 0.02627466 0.02916782 0.0319467
  0.03421342 0.01935349 0.0194657  0.04263953 0.03482727 0.03034785
  0.03412415 0.0339678  0.03184966 0.03783143 0.03860421 0.03999316
  0.04221479 0.03513344 0.04103653 0.02494709 0.02542112 0.04006549
  0.03166446 0.02940549]
 [0.03723584 0.03106977 0.03224522 0.02524225 0.01860073 0.03168807
  0.04080286 0.04583423 0.02910989 0.02570455 0.02830298 0.03117451
  0.03746766 0.01716638 0.01615126 0.0326302  0.03075854 0.02847025
  0.03001527 0.02974405 0.02956374 0.0360981  0.02470248 0.03398678
  0.04588618 0.03289607 0.02946526 0.02170066 0.02475356 0.02208007
  0.03109105 0.03338055]
 [0.03769685 0.03056581 0.03498945 0.02747635 0.02088948 0.03367108
  0.0415914  0.04346404 0.03208695 0.02878105 0.0311137  0.03142921
  0.03674467 0.01933162 0.01738139 0.03231294 0.02693827 0.02706696
  0.02843131 0.0289175  0.02773829 0.03541062 0.02534234 0.02824955
  0.03150101 0.02710193 0.02983144 0.02181024 0.02734384 0.02210234
  0.02954266 0.02741189]
 [0.0363455  0.02346271 0.02276305 0.01809313 0.01373808 0.02070196
  0.03144102 0.03057383 0.02189774 0.01792415 0.0303812  0.02025232
  0.03088736 0.01274963 0.01358401 0.03532338 0.03804912 0.03109205
  0.03400101 0.03214008 0.03650672 0.03371974 0.01824184 0.04970473
  0.07862145 0.03748232 0.0187606  0.02573589 0.02026982 0.01538682
  0.02848645 0.02833229]
 [0.03655288 0.01956469 0.01920023 0.01770602 0.01260861 0.01921826
  0.02613793 0.0272386  0.02016937 0.01745355 0.02963752 0.01972223
  0.02635313 0.01264878 0.01278478 0.03195311 0.04067389 0.03167839
  0.0389484  0.03476154 0.03699513 0.03236002 0.01458435 0.04119234
  0.06379665 0.03499727 0.01514763 0.02618917 0.02135078 0.01402379
  0.03729082 0.03342784]
 [0.0362975  0.03387244 0.03007553 0.02341585 0.01568948 0.02425146
  0.04515941 0.05205752 0.02836702 0.02365839 0.05865622 0.02908926
  0.04644994 0.01560381 0.01653129 0.05049571 0.06015461 0.05060569
  0.05173568 0.04759154 0.04660932 0.03648594 0.01939972 0.05987385
  0.06375842 0.03891325 0.02027415 0.02990383 0.02387736 0.01423083
  0.03651741 0.03766119]
 [0.03706019 0.02399111 0.0259265  0.02266222 0.01587213 0.02449594
  0.03431976 0.0375589  0.02765962 0.02359205 0.05396671 0.02811547
  0.03682766 0.01605946 0.01514389 0.03883828 0.04740411 0.03783714
  0.04425207 0.04091566 0.04016405 0.03164788 0.01635289 0.03950422
  0.0408044  0.03319775 0.01581896 0.02938726 0.02120323 0.01548366
  0.04503585 0.02761562]
 [0.03552848 0.02894849 0.03110199 0.05218736 0.04827803 0.04511123
  0.03276924 0.03415651 0.04087256 0.05491474 0.04047969 0.04121833
  0.04201306 0.06907014 0.08866618 0.03080072 0.03045666 0.04110639
  0.03619317 0.03655539 0.0360133  0.0377689  0.03252978 0.01873235
  0.01849483 0.03141467 0.02924555 0.04824101 0.05276366 0.02803588
  0.01807043 0.01206281]
 [0.03497782 0.03671754 0.03274035 0.07525728 0.13980743 0.05412856
  0.03153469 0.03275666 0.0378451  0.07597344 0.05638788 0.05061865
  0.03969887 0.08329365 0.10674039 0.03857584 0.0461131  0.08104302
  0.05316547 0.05189043 0.05079803 0.03713225 0.04028155 0.01834583
  0.0151716  0.03391498 0.04399038 0.04784219 0.05023384 0.02587195
  0.01194487 0.0093192 ]
 [0.03535566 0.03595902 0.02886924 0.04698201 0.05877123 0.0348909
  0.02948644 0.03079653 0.0330762  0.0495433  0.05051481 0.04671632
  0.03975473 0.0337714  0.0402849  0.03584942 0.04786161 0.07685134
  0.05739656 0.05741486 0.05549735 0.03416755 0.03523958 0.0248419
  0.02358889 0.03383985 0.0381071  0.04820903 0.02906311 0.01580647
  0.01663376 0.01532726]
 [0.03591144 0.03533548 0.03180147 0.05878053 0.06317353 0.03947265
  0.03095168 0.03414413 0.03883994 0.06067592 0.04460631 0.04622763
  0.03666328 0.0361104  0.03449968 0.02737855 0.03362441 0.05623485
  0.04149213 0.04420492 0.0481791  0.0382495  0.03825079 0.02234186
  0.02024382 0.03634486 0.04657805 0.05264989 0.03185489 0.01695633
  0.01781575 0.01902462]
 [0.03606921 0.0306738  0.02849673 0.04509383 0.03860304 0.03405656
  0.02946267 0.02974311 0.03427262 0.04463001 0.03690477 0.03543684
  0.03143638 0.03108004 0.0312513  0.02461247 0.0280563  0.03742176
  0.03663028 0.04049657 0.04276365 0.04506538 0.03728743 0.01996518
  0.01956935 0.0327599  0.033835   0.05756444 0.03916422 0.01679326
  0.01761029 0.018773  ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.0300621  0.03921674 0.04033665 ... 0.02951797 0.02035984 0.02643058]
 [0.03061793 0.03333037 0.03114679 ... 0.02818779 0.03117759 0.0383811 ]
 [0.03128774 0.04372052 0.04944995 ... 0.02157403 0.01830246 0.01854025]
 ...
 [0.03153666 0.03687435 0.04090162 ... 0.02161017 0.01697205 0.01778552]
 [0.03180325 0.02956535 0.03030067 ... 0.02631149 0.02839581 0.02705716]
 [0.03180834 0.03224299 0.03323768 ... 0.02655644 0.02105496 0.02465979]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', "'s", ' current', ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Bill', ' and', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 44), x_tokens=44, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 44)
DEBUG result.interpretability.attn_scores 1540 
 [[0.02676414 0.03020536 0.03336153 ... 0.03237899 0.01323602 0.01351551]
 [0.02721537 0.0290933  0.03194968 ... 0.03200087 0.03003286 0.01449327]
 [0.02788563 0.0329955  0.03803848 ... 0.04417664 0.01616353 0.01449807]
 ...
 [0.02841758 0.03142896 0.02635764 ... 0.0148193  0.00989885 0.00927576]
 [0.02901668 0.03492329 0.02999339 ... 0.01313895 0.00975865 0.00891098]
 [0.02876236 0.0307281  0.02718199 ... 0.01396344 0.01171168 0.01027185]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '13', ',', ' Bill', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 50), x_tokens=50, y_tokens=30, max_supp_attn=0.0, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 50)
DEBUG result.interpretability.attn_scores 1500 
 [[0.03123933 0.04412443 0.04130626 ... 0.02279956 0.02040853 0.02818211]
 [0.03211806 0.04023015 0.03757362 ... 0.02197433 0.02361697 0.02750874]
 [0.03271823 0.04793566 0.04984029 ... 0.01884931 0.01720979 0.0214044 ]
 ...
 [0.03292793 0.04212654 0.0445145  ... 0.0159954  0.01468702 0.02279514]
 [0.0332773  0.03095585 0.03125685 ... 0.02053547 0.02061067 0.02544271]
 [0.03301919 0.03568759 0.03533045 ... 0.01698064 0.01621847 0.02254645]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' going', ' to', ' the', ' kitchen', ',', ' but', ' not', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0571, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02678757 0.0464577  0.0499487  0.07858317 0.07706419 0.0479445
  0.03491832 0.03083831 0.0331291  0.05003469 0.03838016 0.02341835
  0.02515892 0.12456378 0.12997645 0.04111891 0.0279401  0.01802579
  0.0166317  0.01650968 0.01985081 0.03983327 0.0628809  0.01478461
  0.00935858 0.02625952]
 [0.02761493 0.02909814 0.02946735 0.05853707 0.05478735 0.04134151
  0.0245092  0.02225303 0.02638449 0.04314832 0.03320467 0.02522714
  0.02499872 0.12714131 0.15501913 0.03915134 0.0301795  0.02143668
  0.0183537  0.01709061 0.01869834 0.03369563 0.0376252  0.01145833
  0.00773541 0.01723386]
 [0.02807116 0.0328307  0.03774578 0.06172298 0.06203562 0.05345635
  0.03330002 0.03189392 0.03543762 0.05151646 0.03836465 0.04096663
  0.03982606 0.10199714 0.09540201 0.03263503 0.0278632  0.02206598
  0.01797518 0.01743503 0.01793579 0.03070034 0.0346358  0.01532212
  0.0105766  0.01653535]
 [0.02710462 0.03823659 0.04434418 0.04701428 0.05025455 0.04862502
  0.03898792 0.04182545 0.04037286 0.04605849 0.03790185 0.04739801
  0.04311927 0.06036402 0.05535094 0.04024385 0.03605459 0.03008801
  0.02453728 0.02451367 0.02561204 0.03499373 0.04893239 0.03310816
  0.03020043 0.03054138]
 [0.02814353 0.03338268 0.03928185 0.03586136 0.03227216 0.04193474
  0.03738831 0.04089301 0.03718336 0.03675072 0.03182821 0.0424927
  0.03779476 0.02312156 0.01763646 0.02892904 0.02787002 0.02649337
  0.02364997 0.02372456 0.0238878  0.02808872 0.03612327 0.03016523
  0.02647473 0.03133202]
 [0.02851767 0.03194659 0.03491473 0.02974514 0.02449977 0.04043296
  0.03758464 0.03907678 0.03842496 0.03426612 0.03109345 0.04503926
  0.0378353  0.02003312 0.01494452 0.02770791 0.02747436 0.02442072
  0.0234765  0.02305753 0.02275123 0.02807395 0.03309895 0.02917141
  0.0236134  0.02855049]
 [0.02791491 0.04983045 0.04380775 0.03382562 0.02863881 0.04561969
  0.04583883 0.05192985 0.04704884 0.04187582 0.03833245 0.06064409
  0.05270419 0.02340919 0.01666489 0.03435118 0.03085299 0.03050229
  0.02742204 0.02676313 0.02568428 0.0297856  0.03823464 0.0308131
  0.0237331  0.02598718]
 [0.02862389 0.03875535 0.04319645 0.03372038 0.0243694  0.05546317
  0.04563221 0.04745029 0.0465784  0.03892633 0.03384878 0.06975307
  0.05461781 0.02176483 0.01514277 0.03324448 0.02989174 0.02704659
  0.02416349 0.02448191 0.02425317 0.02868804 0.03096831 0.02574488
  0.01880923 0.01888042]
 [0.02877311 0.04613348 0.05606003 0.03895555 0.02621834 0.07780895
  0.06783409 0.05035995 0.06216277 0.04149098 0.03283372 0.05907417
  0.0446828  0.02174316 0.01584762 0.03000957 0.02432735 0.02083671
  0.01976541 0.02115097 0.02125821 0.02903792 0.03704828 0.02314974
  0.01635766 0.0195369 ]
 [0.02811502 0.02360685 0.0235362  0.02017389 0.01624143 0.02259162
  0.03202014 0.03226235 0.02596022 0.02352715 0.02967165 0.02931833
  0.03897359 0.01209828 0.0106975  0.03039267 0.03499163 0.03437193
  0.0359373  0.03339747 0.03802981 0.0294372  0.01965269 0.03234742
  0.04014716 0.02668838]
 [0.02802452 0.02089363 0.01788313 0.01745858 0.01350358 0.01611333
  0.02559087 0.02491851 0.01977589 0.01726017 0.02346084 0.01976362
  0.02302477 0.00903283 0.00918867 0.03326369 0.02866537 0.04151707
  0.04263077 0.04881113 0.04588066 0.02672958 0.01695236 0.04590214
  0.0534743  0.03338999]
 [0.02866236 0.02100276 0.01794072 0.01814568 0.01565014 0.01805869
  0.02515428 0.02621937 0.02051212 0.0206535  0.02843593 0.02640755
  0.02622897 0.01020044 0.00975735 0.03289117 0.03345177 0.03401086
  0.03653283 0.03456008 0.03752135 0.02470547 0.01425865 0.0314784
  0.0283888  0.01962097]
 [0.02865705 0.01708278 0.01515327 0.01339614 0.01321913 0.01364868
  0.02211494 0.02098241 0.0179141  0.01566323 0.02753777 0.0199251
  0.02065425 0.00778052 0.00820662 0.02933803 0.0372208  0.03211553
  0.04551371 0.0403039  0.04301985 0.0246674  0.01366848 0.03017349
  0.02647243 0.02344133]
 [0.02811001 0.02018429 0.0178206  0.01421103 0.01399874 0.01512284
  0.02454192 0.0223373  0.0209838  0.01594554 0.02846933 0.01846764
  0.02162046 0.00809442 0.00901724 0.0325877  0.03702886 0.03195304
  0.04437273 0.0361406  0.03803428 0.02687055 0.02101189 0.0514659
  0.04196455 0.04289012]
 [0.02877918 0.02501368 0.02255384 0.01884932 0.01640078 0.01952661
  0.0248654  0.02554409 0.02381142 0.02137542 0.02611001 0.02433048
  0.02399196 0.01122422 0.01059148 0.02361103 0.02530472 0.025797
  0.03744555 0.04283349 0.03859879 0.02695014 0.02278782 0.02540626
  0.02171199 0.02228444]
 [0.02838831 0.02929347 0.02818305 0.03008493 0.02636188 0.03312719
  0.02948097 0.03093339 0.03119244 0.03650493 0.02855521 0.04162184
  0.03918819 0.02275381 0.01600602 0.02514816 0.02959283 0.03170222
  0.02574976 0.02419106 0.02438622 0.03156124 0.03612568 0.02531083
  0.028802   0.03023372]
 [0.02824383 0.0442933  0.04255142 0.02414312 0.02025669 0.0278594
  0.03808948 0.03675164 0.03412488 0.02347799 0.02526194 0.02725881
  0.03190159 0.01526683 0.01357798 0.03313395 0.02943251 0.02623159
  0.02539919 0.02814542 0.02732345 0.03002717 0.05390669 0.0369559
  0.04006544 0.04125072]
 [0.02866173 0.06826629 0.07101667 0.02902948 0.02275618 0.03266668
  0.04732624 0.04186866 0.0442599  0.02601034 0.02561262 0.02749149
  0.02973876 0.0157935  0.0144512  0.04283729 0.03043965 0.02250282
  0.02015009 0.02273952 0.02252113 0.03052047 0.06589438 0.03067912
  0.02397366 0.02404816]
 [0.02874619 0.03872846 0.04195247 0.02487532 0.01977075 0.02820857
  0.03836995 0.03677    0.03492351 0.02332068 0.0230863  0.02561769
  0.02573647 0.01410055 0.01276991 0.03365375 0.02708087 0.02183354
  0.0201167  0.02194773 0.0237079  0.0311838  0.04639827 0.03981257
  0.0360048  0.03349463]
 [0.02947437 0.02892733 0.02821349 0.02127595 0.01678664 0.02509012
  0.02947349 0.03217807 0.02691607 0.02098637 0.02307676 0.02451776
  0.02560395 0.01199321 0.01019524 0.02424721 0.02053848 0.02055527
  0.01880116 0.0199761  0.02115166 0.02848635 0.02374414 0.02917325
  0.02683613 0.02829917]
 [0.02887174 0.02102648 0.0190687  0.01492068 0.01287805 0.01627544
  0.0223552  0.0221439  0.020144   0.01555929 0.02231338 0.0157364
  0.020677   0.00876096 0.00820534 0.02821435 0.02480363 0.02468669
  0.02518979 0.02712363 0.03038145 0.02585423 0.0204428  0.06161335
  0.05847413 0.04012827]
 [0.02856467 0.01769565 0.0154182  0.01354649 0.01125035 0.01290759
  0.01909242 0.017042   0.01687215 0.01373061 0.01875293 0.01235716
  0.01754894 0.00771616 0.00762261 0.02413918 0.02376238 0.03542551
  0.03449148 0.04571822 0.04025164 0.02545003 0.01700595 0.04551948
  0.08866421 0.05052994]
 [0.02899215 0.01507179 0.01392903 0.01227754 0.01070515 0.01252725
  0.01713756 0.01634943 0.01582021 0.01307469 0.01908571 0.0129128
  0.01670735 0.00728603 0.00689041 0.02428034 0.02328486 0.029892
  0.02515785 0.04119634 0.03931225 0.02142003 0.01433513 0.03914727
  0.07663652 0.0425127 ]
 [0.0288249  0.01497531 0.01307585 0.01094243 0.00963319 0.01122232
  0.01690477 0.01495564 0.01526492 0.0116786  0.02368866 0.01182938
  0.01616342 0.00667727 0.00647297 0.02883661 0.03118726 0.03270873
  0.03146809 0.03847884 0.03662214 0.02268268 0.01461395 0.04462017
  0.05505919 0.0602094 ]
 [0.02818626 0.02039306 0.01746518 0.01568596 0.01419496 0.01511215
  0.02133243 0.01822077 0.02052958 0.01592026 0.02430294 0.01473036
  0.01960102 0.00904991 0.00868513 0.02395988 0.02946538 0.03216808
  0.03899698 0.05100969 0.03834582 0.02827187 0.02336113 0.04281055
  0.04123023 0.06822977]
 [0.02930406 0.01702664 0.015071   0.01314355 0.01107389 0.01308662
  0.01657849 0.01565469 0.0173613  0.01367162 0.02226925 0.01330283
  0.01637407 0.00813579 0.00743126 0.01971655 0.02515124 0.02565741
  0.02591633 0.02420714 0.0257303  0.02441533 0.01722516 0.0309379
  0.03296162 0.05182859]
 [0.02999567 0.01915704 0.01948419 0.0164768  0.01355758 0.01774337
  0.02014885 0.02326649 0.02366293 0.01870823 0.0215834  0.02032648
  0.02136135 0.01126428 0.00797874 0.01890887 0.01792047 0.01691355
  0.01915609 0.01782461 0.01934068 0.02644452 0.01493192 0.02402244
  0.0201225  0.01969073]
 [0.03014453 0.0217129  0.02156655 0.0200025  0.01600308 0.02003522
  0.02084628 0.02844078 0.0276211  0.02291337 0.02375545 0.02719587
  0.02665719 0.01237278 0.00862841 0.01667263 0.01706372 0.01634066
  0.01786813 0.01692108 0.01855805 0.02685282 0.01371424 0.012894
  0.0104825  0.01132825]
 [0.03003359 0.01748372 0.01684236 0.01455684 0.01191802 0.01470775
  0.01826597 0.02190944 0.02094262 0.01705371 0.02282389 0.02006955
  0.02125257 0.00953192 0.00704191 0.01988666 0.02081042 0.02175907
  0.02425821 0.02631921 0.02484698 0.02365961 0.01132104 0.01719552
  0.01494599 0.01157152]
 [0.02960514 0.01757703 0.01644498 0.01253614 0.01075256 0.01293164
  0.01965242 0.01997219 0.01948639 0.01460141 0.02811865 0.01666659
  0.01946949 0.00878854 0.00693614 0.02442567 0.02880305 0.02503423
  0.0369872  0.03328113 0.0301282  0.02333533 0.01288198 0.02289647
  0.0169999  0.01724862]
 [0.02959148 0.01960226 0.01948583 0.01979201 0.01563302 0.01731404
  0.01960755 0.02158207 0.0232162  0.02264089 0.02521303 0.02180251
  0.02263413 0.01490631 0.01408484 0.01911991 0.02198873 0.02167525
  0.02941113 0.02961112 0.02885524 0.02630996 0.01544682 0.01540104
  0.01327074 0.01513832]
 [0.02815988 0.03100238 0.02961626 0.05472721 0.06149042 0.04185636
  0.02610974 0.02614482 0.0313035  0.05299121 0.03651464 0.02995085
  0.03285396 0.08826894 0.10274819 0.02729196 0.02739157 0.02411219
  0.01910419 0.01746527 0.01959672 0.03322563 0.03408537 0.01157625
  0.00866655 0.01952572]
 [0.02809616 0.03113523 0.02904693 0.05478435 0.10937717 0.0364799
  0.02178492 0.0231336  0.02707704 0.05274963 0.03875231 0.02726913
  0.02408987 0.08411009 0.10576688 0.03271132 0.03863446 0.03627565
  0.02548665 0.02074723 0.02323347 0.0291121  0.03348316 0.01049938
  0.00702584 0.01682781]
 [0.0280039  0.02433122 0.02316761 0.03863832 0.06266905 0.02534309
  0.01700574 0.02139298 0.02510794 0.04492925 0.03500577 0.03000966
  0.02860839 0.03108595 0.03262619 0.02334041 0.04123107 0.06769997
  0.05638207 0.0331824  0.03442207 0.02538521 0.02759229 0.01519228
  0.01108849 0.01819711]
 [0.02821193 0.02784473 0.02474563 0.03836017 0.05377728 0.02781665
  0.02015633 0.02250477 0.02849335 0.04098395 0.0327538  0.02710661
  0.02860047 0.02956833 0.02843692 0.0199997  0.03230045 0.04614401
  0.04150068 0.02914041 0.03026822 0.04354408 0.03561018 0.01325097
  0.00967107 0.01653445]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' leaving', ' the', ' school', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 32), x_tokens=32, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 32)
DEBUG result.interpretability.attn_scores 1088 
 [[0.02725643 0.03820011 0.04091962 ... 0.01300201 0.01790308 0.01045899]
 [0.02803489 0.03885719 0.03804903 ... 0.01659447 0.02178132 0.01297545]
 [0.02859204 0.03812768 0.04187219 ... 0.02216422 0.0292046  0.0156044 ]
 ...
 [0.02882877 0.03675918 0.03249744 ... 0.00771717 0.00824265 0.00718155]
 [0.02921852 0.02719654 0.02361886 ... 0.01157882 0.01010983 0.01097605]
 [0.02918384 0.03205612 0.02699382 ... 0.00923976 0.00949007 0.00952528]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Fred', ' moved', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Fred', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03123566 0.04243198 0.04072431 ... 0.03265668 0.02586943 0.02070476]
 [0.03155786 0.0365921  0.03523922 ... 0.04614625 0.04430722 0.03156148]
 [0.03252799 0.04827701 0.05085884 ... 0.02824009 0.01687303 0.01470392]
 ...
 [0.03274842 0.04243026 0.04759125 ... 0.02685069 0.01591575 0.01480833]
 [0.03329562 0.03258707 0.033812   ... 0.029718   0.02320662 0.02052337]
 [0.03304154 0.03480196 0.03622513 ... 0.0249531  0.02023439 0.01979693]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' school', '.', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Mary', ' moved', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.122, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02269877 0.02934027 0.03416929 ... 0.01014484 0.00901868 0.00675932]
 [0.02299869 0.03499111 0.03832749 ... 0.02720235 0.01552238 0.01122867]
 [0.02355602 0.03176512 0.03765307 ... 0.01892996 0.01678703 0.01269934]
 ...
 [0.02372172 0.03541542 0.03118128 ... 0.0075117  0.00669424 0.00444761]
 [0.02420012 0.02744848 0.02327579 ... 0.0083027  0.0095844  0.00689995]
 [0.02410942 0.03089505 0.02552536 ... 0.00736984 0.00852209 0.00600802]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', "'s", ' possible', ' locations', ' as', ' the', ' cinema', ' or', ' the', ' office', ' (', 'sentence', ' ', '10', '),', ' but', ' not', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02115477 0.02963252 0.02935665 ... 0.0191743  0.01290027 0.03173999]
 [0.02148871 0.02411541 0.02563841 ... 0.01892652 0.01782922 0.02464085]
 [0.02204673 0.03047811 0.03286012 ... 0.01546191 0.01140512 0.02743404]
 ...
 [0.02220544 0.02899486 0.02709215 ... 0.0149718  0.01102881 0.03415935]
 [0.02281995 0.02179428 0.02006776 ... 0.01824539 0.01641135 0.02969095]
 [0.02253266 0.02600065 0.02347056 ... 0.01432669 0.01287843 0.02768034]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Mary', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 26), x_tokens=26, y_tokens=55, max_supp_attn=0.0545, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 26)
DEBUG result.interpretability.attn_scores 1430 
 [[0.01670257 0.03444625 0.03530074 ... 0.01789871 0.00659016 0.02206115]
 [0.01722786 0.0213384  0.0207884  ... 0.01263773 0.00603263 0.01443202]
 [0.01751444 0.02414918 0.02694441 ... 0.01681704 0.00705522 0.01399514]
 ...
 [0.01762317 0.02026096 0.02016171 ... 0.01069977 0.00531522 0.01312285]
 [0.01766254 0.01625703 0.01659148 ... 0.01450629 0.00896617 0.01447371]
 [0.01778184 0.01774905 0.01774962 ... 0.01354433 0.0084538  0.014771  ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03120216 0.04363352 0.05135456 0.07107671 0.05767754 0.06216336
  0.04337168 0.04269555 0.04546272 0.05146734 0.03674497 0.04050833
  0.04286367 0.1036443  0.10255097 0.03307577 0.02733351 0.02645708
  0.02679091 0.02759322 0.02530255 0.03798731 0.05739456 0.01823862
  0.03206    0.04143317 0.04380856 0.04750406 0.10699634 0.01252682
  0.02339604 0.00895317]
 [0.03197194 0.0431562  0.04810723 0.08865927 0.08634743 0.0936389
  0.04674336 0.0472656  0.04912499 0.0740758  0.0528575  0.06538475
  0.06119201 0.13743544 0.11531169 0.03332107 0.02754734 0.03093929
  0.02808445 0.02876846 0.02592254 0.03963965 0.04274689 0.01389234
  0.0374397  0.03748759 0.04408671 0.04150001 0.098308   0.01604723
  0.03699397 0.01566046]
 [0.03266737 0.04098764 0.05119045 0.07308055 0.06267367 0.0691938
  0.04426218 0.04334193 0.04369847 0.05551175 0.04049881 0.05092788
  0.04789647 0.11154473 0.09013183 0.03201134 0.02579477 0.02500628
  0.02409391 0.02465665 0.02207685 0.03711068 0.04154178 0.01642598
  0.0280305  0.03318235 0.03866279 0.03288316 0.08150128 0.02391512
  0.0346809  0.01660009]
 [0.03130713 0.04171687 0.04849209 0.03978035 0.03291609 0.04273487
  0.04253579 0.04377043 0.03766368 0.0349336  0.03109853 0.04106728
  0.04069953 0.03017637 0.02782236 0.03724577 0.03046992 0.02855359
  0.02871274 0.02993049 0.02762274 0.03909702 0.0592386  0.03910577
  0.03152639 0.04923104 0.04686821 0.04202505 0.07481241 0.07468154
  0.0430251  0.03186358]
 [0.03187125 0.04655784 0.04913255 0.02663875 0.02017347 0.0320262
  0.04048829 0.03888445 0.03635303 0.02414389 0.02625732 0.03021762
  0.03242595 0.02005268 0.01814882 0.03587421 0.02601042 0.02419228
  0.02666487 0.02733826 0.02579677 0.03668746 0.06363839 0.03362547
  0.03016915 0.04503867 0.05663821 0.02914657 0.06391723 0.09461881
  0.037818   0.03645368]
 [0.03269249 0.05973423 0.06649618 0.03244545 0.02304046 0.04002689
  0.05016304 0.04274821 0.05144735 0.0300521  0.02699202 0.03710476
  0.03798804 0.02042199 0.01866926 0.04149354 0.03271274 0.02915602
  0.03065067 0.03259789 0.02718291 0.03335781 0.08162029 0.02811056
  0.02739412 0.04471062 0.06021939 0.02729318 0.04401861 0.10351513
  0.03250388 0.03270609]
 [0.03279299 0.03708216 0.04242731 0.02413335 0.0185912  0.02691286
  0.03619299 0.03142022 0.03642619 0.02221071 0.02188045 0.02482343
  0.0259245  0.01673526 0.01639898 0.03458244 0.02806006 0.02329308
  0.02759357 0.0278045  0.0246071  0.03013326 0.05400949 0.03223481
  0.02355328 0.04643814 0.05799419 0.02684681 0.02953225 0.09948502
  0.03664999 0.02671869]
 [0.03306307 0.02078993 0.02503609 0.016271   0.01412384 0.01869689
  0.02195316 0.02126153 0.02569859 0.01658924 0.01786995 0.01732227
  0.01956215 0.01106654 0.01194543 0.02419085 0.02253382 0.02002261
  0.02515527 0.02645861 0.02308773 0.02468644 0.03589702 0.03630355
  0.01966035 0.04543443 0.03570746 0.02430275 0.01948853 0.05752017
  0.02424376 0.01593361]
 [0.03254679 0.03224561 0.03589925 0.02538841 0.01896917 0.02895632
  0.03499131 0.03138935 0.03065269 0.02416933 0.02706256 0.03118695
  0.03118491 0.01694266 0.01606813 0.0419926  0.03352615 0.03416442
  0.03343391 0.0359042  0.03084912 0.03589016 0.03784971 0.03955341
  0.03109275 0.03909772 0.04147906 0.02384147 0.02791332 0.06998881
  0.03832862 0.04616559]
 [0.03348938 0.03181396 0.03858164 0.0303427  0.02339431 0.03661541
  0.0407283  0.03765887 0.03395542 0.02993879 0.03073803 0.03896447
  0.0392905  0.02181562 0.01661973 0.03630597 0.02648001 0.02837292
  0.02794609 0.03044548 0.02707142 0.03476458 0.03149524 0.03774017
  0.03383118 0.03537184 0.03751543 0.02702817 0.02978132 0.06710419
  0.06112155 0.0616998 ]
 [0.03309644 0.023701   0.02274002 0.01745777 0.01484963 0.01930993
  0.0269006  0.02413211 0.02419773 0.01829118 0.02545797 0.02149466
  0.02759006 0.01180304 0.01092657 0.03953069 0.03126694 0.0337454
  0.0304185  0.03340745 0.03129848 0.03275483 0.022595   0.04222253
  0.03615426 0.02936166 0.02294734 0.02475823 0.01724172 0.04271736
  0.03421614 0.03647067]
 [0.03289202 0.02589902 0.02331658 0.01832665 0.01549702 0.01895896
  0.02843333 0.02616203 0.02450919 0.01934332 0.02516996 0.02027598
  0.02900813 0.01178293 0.01125634 0.0433806  0.03244423 0.03915703
  0.03501743 0.03799363 0.03824614 0.0305825  0.02191818 0.04362036
  0.04149736 0.02966864 0.02355579 0.02980246 0.01422687 0.02991637
  0.026433   0.03403419]
 [0.03393162 0.02513737 0.02438692 0.01934624 0.0171195  0.02171373
  0.02893818 0.02782156 0.02734787 0.02151468 0.03221723 0.02560887
  0.03268608 0.01299773 0.01198088 0.05312505 0.031516   0.05183087
  0.03481084 0.04392568 0.04199598 0.02698415 0.02080378 0.04147647
  0.0365161  0.02548078 0.02804096 0.02194998 0.01282399 0.01937429
  0.02648193 0.03274979]
 [0.03384117 0.02234122 0.02067631 0.01543508 0.01385443 0.01697165
  0.02572705 0.02252887 0.02358317 0.01714653 0.0357732  0.01938353
  0.0248894  0.01064326 0.01097705 0.04227878 0.03451087 0.03940089
  0.03383761 0.03710077 0.04025226 0.028836   0.02065526 0.05808926
  0.04171982 0.02722334 0.02762373 0.0234688  0.01162442 0.01615941
  0.02597666 0.02895365]
 [0.0329441  0.02607875 0.02372322 0.01964293 0.01726225 0.02373848
  0.03139121 0.03008026 0.03090353 0.02111    0.02895319 0.02440058
  0.02906774 0.0133226  0.01258349 0.02992435 0.0353662  0.0332405
  0.04268578 0.04117805 0.04219992 0.03188184 0.02600797 0.05205628
  0.04984358 0.04723116 0.03061384 0.03521936 0.01857162 0.02215578
  0.03792196 0.02570501]
 [0.03417002 0.0252022  0.02464397 0.02081793 0.01657465 0.02248276
  0.02852934 0.02727322 0.02768441 0.02147305 0.02844184 0.02457512
  0.02698309 0.01470777 0.01297449 0.02598419 0.02588042 0.02582923
  0.02933913 0.03082132 0.02992254 0.03296268 0.02064829 0.02903687
  0.02706889 0.02677491 0.02303427 0.02365265 0.01729501 0.01875765
  0.04700763 0.03932962]
 [0.03407937 0.02562943 0.02942638 0.02590173 0.01984374 0.03146463
  0.03132004 0.03598483 0.03282873 0.03090307 0.03108873 0.04063404
  0.03750391 0.01961459 0.01429359 0.02302571 0.02309392 0.02697434
  0.02661654 0.02758509 0.02462274 0.03443943 0.0215095  0.02134643
  0.02747014 0.02881843 0.02280827 0.02823643 0.02381358 0.02328733
  0.06244243 0.05572697]
 [0.03443328 0.03578573 0.03694345 0.03661092 0.02524398 0.03958856
  0.03954316 0.04630692 0.03682127 0.04230788 0.04152739 0.05350549
  0.04805544 0.02468966 0.01688988 0.02731037 0.02479486 0.02917251
  0.02679186 0.02773847 0.0250381  0.0346275  0.02518862 0.0216735
  0.02888371 0.02443495 0.02738035 0.02437397 0.02376609 0.02486342
  0.04550941 0.07318899]
 [0.03449537 0.03381605 0.03155834 0.03215818 0.02419851 0.03358297
  0.03558553 0.03989941 0.034501   0.03633723 0.03833193 0.04310465
  0.04358264 0.02219128 0.01709774 0.03075595 0.02752365 0.03274798
  0.03138605 0.03216213 0.03001704 0.03547604 0.02287908 0.0270207
  0.02808259 0.0238541  0.02491177 0.0286091  0.02152102 0.02280796
  0.03658579 0.05501315]
 [0.0343235  0.02654576 0.02294043 0.01949929 0.01459832 0.02007896
  0.02647025 0.02975343 0.02660789 0.02302237 0.02617895 0.02578445
  0.02882387 0.01261467 0.01223975 0.03291972 0.0304596  0.03156234
  0.03106953 0.03139726 0.03307482 0.03361482 0.01899762 0.03859725
  0.03327364 0.0238872  0.02213028 0.03440363 0.01678935 0.02261356
  0.02918332 0.04550882]
 [0.03436051 0.0291224  0.02415746 0.02180219 0.0158569  0.02108821
  0.0301051  0.03168349 0.02659953 0.02492548 0.02876707 0.02625509
  0.02989871 0.01324429 0.01359859 0.035427   0.03321208 0.03715257
  0.03610912 0.03518707 0.03759352 0.03096749 0.01883614 0.04052926
  0.03556434 0.02334246 0.02359056 0.03302974 0.0143068  0.01882663
  0.02560745 0.04292545]
 [0.03443236 0.02715567 0.02264126 0.02059894 0.01605192 0.02076999
  0.02646031 0.02896362 0.02520109 0.02465956 0.02990341 0.02660106
  0.02687831 0.01361571 0.01346808 0.0311907  0.03266718 0.03240795
  0.03600393 0.03232566 0.03693411 0.03158478 0.01805566 0.04382986
  0.04370641 0.02336955 0.0247727  0.03332373 0.01557993 0.02013307
  0.03003486 0.04408724]
 [0.03470559 0.03068548 0.02554875 0.02174804 0.01612229 0.02245312
  0.03162791 0.03218825 0.0305858  0.02583657 0.03723869 0.02822077
  0.03000168 0.01426227 0.01417328 0.03844132 0.03575924 0.03775157
  0.03775234 0.03755075 0.04143446 0.03138214 0.01918202 0.0473686
  0.04054279 0.02520691 0.02466839 0.02862318 0.01436704 0.01560896
  0.02630305 0.04366234]
 [0.03486545 0.02361702 0.02000099 0.01484405 0.01275468 0.01654268
  0.0261061  0.02334774 0.02383192 0.01884615 0.04019513 0.02029572
  0.02157635 0.01091098 0.01093946 0.03100174 0.03476784 0.02981754
  0.03432659 0.0331911  0.03818224 0.02844217 0.01660734 0.06034178
  0.04239844 0.02347037 0.01769727 0.0263259  0.01323437 0.01363363
  0.02639784 0.03513043]
 [0.03358337 0.02706875 0.02367529 0.01683142 0.01404543 0.02090415
  0.02984358 0.02848428 0.03106448 0.02274488 0.02797163 0.02215543
  0.02438901 0.01275012 0.01237564 0.02397896 0.03270727 0.02557644
  0.0363792  0.0337518  0.03490284 0.03116493 0.01982694 0.04286176
  0.03960651 0.03409125 0.02122629 0.02894284 0.01709808 0.01625696
  0.03074117 0.02543065]
 [0.03464893 0.02624228 0.02369417 0.02110049 0.01563574 0.02424388
  0.02661591 0.03025456 0.02899505 0.02663436 0.02620442 0.02677456
  0.02556863 0.01591304 0.01382632 0.01959309 0.02557365 0.02338994
  0.02971535 0.03078577 0.02921418 0.02982553 0.01760412 0.02243509
  0.02544132 0.02474042 0.02009631 0.0283913  0.01958178 0.0148049
  0.03894778 0.03740909]
 [0.03314901 0.03463221 0.03524281 0.05125247 0.04258464 0.04559728
  0.03245552 0.03470114 0.04162904 0.05369188 0.03476225 0.04076391
  0.03816326 0.07815676 0.09116142 0.02353524 0.02800295 0.02720514
  0.02954477 0.0299437  0.02606666 0.03413612 0.03455834 0.01432207
  0.0272308  0.034326   0.03682005 0.04367388 0.04671315 0.01173076
  0.02648269 0.0158547 ]
 [0.03279275 0.0459273  0.03905508 0.07383171 0.15632327 0.05644166
  0.03188281 0.03382236 0.04092042 0.07476952 0.05421915 0.04973517
  0.03344841 0.10876592 0.14381616 0.03510394 0.05547193 0.04941837
  0.04551546 0.03765334 0.04308028 0.03371159 0.04525977 0.01439369
  0.02980309 0.03592259 0.0512143  0.04682912 0.04656082 0.00826156
  0.01747651 0.00988491]
 [0.03258213 0.04441727 0.03543016 0.05590536 0.11309125 0.03453138
  0.02787718 0.03230809 0.03333041 0.06087886 0.05273016 0.04374256
  0.03079833 0.04287146 0.06966975 0.03763415 0.08979206 0.07451396
  0.06483417 0.04765557 0.0700878  0.0330415  0.03912758 0.02509526
  0.03722429 0.03557649 0.03591607 0.06185912 0.028441   0.01073787
  0.02015421 0.01465164]
 [0.03306852 0.043277   0.03348118 0.04907201 0.06058474 0.03857151
  0.03275676 0.03386775 0.03837439 0.05247093 0.0428675  0.03918057
  0.03205924 0.04530635 0.05208434 0.02576482 0.05472048 0.04894783
  0.04871944 0.04714769 0.04631618 0.04422962 0.04430684 0.01845229
  0.0332145  0.03579318 0.02797142 0.07215545 0.03017403 0.00794976
  0.01733433 0.01152804]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '7', ' and', ' ', '8', '.', ' The', ' previous', ' information', ' about', ' Bill', "'s", ' location', ' (', 'if', ' any', ')', ' is', ' not', ' provided', ' in', ' this', ' task', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.1333, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02041245 0.02172976 0.02220542 ... 0.04926633 0.02989148 0.01757941]
 [0.02075887 0.01341661 0.01498536 ... 0.02934612 0.02518815 0.02833874]
 [0.02140531 0.02007254 0.02306745 ... 0.04648514 0.02482414 0.01176159]
 ...
 [0.02197573 0.0221352  0.01819591 ... 0.04822164 0.02195285 0.01591743]
 [0.0222888  0.02258203 0.01963544 ... 0.0506749  0.02417004 0.0152115 ]
 [0.02232228 0.01850062 0.01637653 ... 0.06619929 0.03231074 0.01428355]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' (', 'from', ' a', ' previous', ' task', ')', ' states', ' that', ' Julie', ' travelled', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' moving', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02386706 0.02761444 0.02494861 ... 0.02209666 0.04325104 0.07643048]
 [0.02418559 0.02340225 0.02098561 ... 0.02128769 0.0285807  0.05858629]
 [0.02484304 0.03051074 0.02968457 ... 0.02212734 0.03195708 0.07579604]
 ...
 [0.02504979 0.02928604 0.0283673  ... 0.02930588 0.03611645 0.02306318]
 [0.02538197 0.02614871 0.02335546 ... 0.03567417 0.03185456 0.01205736]
 [0.02546049 0.02438983 0.0227018  ... 0.02563673 0.04000244 0.01211427]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Julie', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' bedroom', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 50), x_tokens=50, y_tokens=55, max_supp_attn=0.0, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 50)
DEBUG result.interpretability.attn_scores 2750 
 [[0.01680369 0.02698639 0.02326273 ... 0.02248429 0.02293975 0.01599992]
 [0.01713941 0.02158243 0.02218868 ... 0.01326817 0.01610195 0.01775996]
 [0.01753665 0.02779592 0.02663969 ... 0.02259217 0.02085499 0.01451686]
 ...
 [0.01778746 0.02482055 0.02439345 ... 0.05400405 0.02369478 0.01459326]
 [0.01803926 0.02001804 0.0180086  ... 0.04166576 0.01976862 0.0172224 ]
 [0.01795168 0.02162495 0.01924715 ... 0.05144752 0.02772357 0.01781044]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' going', ' back', ' to', ' the', ' park', ' and', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0541, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.02532526 0.04485856 0.04767094 0.07717759 0.07606524 0.04737812
  0.03559545 0.03094064 0.03223599 0.04940153 0.03860839 0.02430322
  0.02585249 0.12293359 0.12829795 0.03744032 0.02703822 0.01933294
  0.01695116 0.01750153 0.01737928 0.03852665 0.05813097 0.00899876
  0.00815276 0.02584589]
 [0.02613984 0.02815288 0.02818058 0.05734474 0.05399831 0.0407573
  0.02485392 0.02222108 0.02552471 0.04228524 0.03301518 0.02610637
  0.02559486 0.12492379 0.15238518 0.03550805 0.02895746 0.02281553
  0.01863959 0.01800892 0.01621136 0.03248665 0.03465303 0.00654619
  0.00637238 0.01699524]
 [0.02657056 0.0316333  0.03606993 0.05947088 0.06013946 0.051704
  0.03339969 0.03148703 0.03377127 0.04943705 0.03765357 0.04126404
  0.03985015 0.09896594 0.09421671 0.02993152 0.02675215 0.02328054
  0.01809954 0.01824548 0.01550756 0.02941459 0.03234513 0.00956056
  0.00849099 0.01606526]
 [0.02566315 0.03614239 0.04192351 0.04414226 0.04749925 0.04529158
  0.03650878 0.03865457 0.03725835 0.04286984 0.03628802 0.04431026
  0.03964607 0.05730094 0.0528726  0.03913336 0.03426506 0.03169761
  0.02473515 0.02601391 0.02348662 0.03297461 0.04719882 0.02605648
  0.02448334 0.02757106]
 [0.02663461 0.03071816 0.03604807 0.03307174 0.02936034 0.03853878
  0.03535158 0.03859326 0.03449269 0.03403663 0.03052013 0.0406566
  0.0358514  0.02122785 0.01656471 0.02741788 0.02553719 0.02656112
  0.02265396 0.02389488 0.02228215 0.0268191  0.03382504 0.02384039
  0.02590339 0.02827359]
 [0.02695971 0.02989763 0.03300614 0.02749862 0.02243643 0.03703489
  0.03490245 0.03641848 0.03471476 0.03107811 0.02885125 0.04163318
  0.03496739 0.01818512 0.01389548 0.02579843 0.02490331 0.02443255
  0.02260486 0.02309934 0.02122342 0.02674822 0.03113045 0.02304457
  0.02542664 0.02685622]
 [0.02651215 0.04650642 0.04233098 0.03131258 0.02572458 0.04203284
  0.04277782 0.04799903 0.03959788 0.03713993 0.03614757 0.05635788
  0.04900647 0.02072917 0.01548334 0.03403021 0.02786957 0.02970175
  0.0255779  0.02519056 0.02337429 0.02859215 0.03511885 0.02238574
  0.02164154 0.02261027]
 [0.02709177 0.03768428 0.0422295  0.03199119 0.02297201 0.05312281
  0.04432577 0.04514234 0.0432422  0.03661679 0.03250531 0.06676724
  0.05183733 0.02009637 0.01448567 0.03075212 0.02808226 0.02799304
  0.02385845 0.02504185 0.02193763 0.02705707 0.02948673 0.01654368
  0.01681881 0.01872348]
 [0.02720294 0.04505461 0.05487493 0.03773761 0.02520574 0.07652619
  0.06813925 0.04939834 0.05948924 0.03978976 0.03223031 0.05908548
  0.044054   0.02069324 0.01551116 0.02803541 0.02327968 0.02200925
  0.01971747 0.02185243 0.01886242 0.02774819 0.03481128 0.01439965
  0.01443166 0.01977026]
 [0.02665394 0.02279602 0.02308494 0.01884259 0.0149898  0.02099819
  0.0283839  0.02943594 0.02332443 0.02103608 0.02764503 0.02671594
  0.03408035 0.01051701 0.01016342 0.03625633 0.0284238  0.03235497
  0.02914376 0.02945481 0.03325702 0.02727209 0.0196723  0.03536022
  0.02921344 0.02213166]
 [0.02664798 0.01997187 0.01768565 0.01645432 0.01260416 0.01524654
  0.02388786 0.02346442 0.01860097 0.01623771 0.02219227 0.01871185
  0.02161126 0.00850179 0.00869561 0.03745372 0.02637212 0.03821259
  0.03564353 0.03905976 0.04388883 0.02551202 0.01663225 0.04218205
  0.03328919 0.02488912]
 [0.02716032 0.01998777 0.01755295 0.01683586 0.01413107 0.01644654
  0.02272783 0.02398392 0.01858416 0.01823054 0.02602691 0.02372717
  0.02350456 0.00907427 0.00896627 0.03877705 0.02825616 0.03319433
  0.03197357 0.03058888 0.0344765  0.02371002 0.01371144 0.02890737
  0.02470514 0.01612673]
 [0.02708173 0.01690324 0.01484902 0.01216854 0.01174542 0.01227173
  0.01984566 0.0186599  0.01588573 0.01358105 0.02544858 0.01763634
  0.01899055 0.00692427 0.00745936 0.03947955 0.03140081 0.03360247
  0.04002298 0.03481808 0.04000643 0.02383391 0.013259   0.02899853
  0.02504592 0.01880691]
 [0.02658887 0.01909155 0.01770907 0.0133685  0.01284105 0.01423323
  0.02159982 0.02004522 0.02015065 0.01452898 0.0225912  0.01663902
  0.01927748 0.00755644 0.00828135 0.03644042 0.03009188 0.03039048
  0.03528953 0.03142836 0.03359476 0.02565253 0.02341331 0.04227375
  0.04040389 0.0396222 ]
 [0.02728317 0.02577987 0.02243315 0.0167878  0.01472459 0.01741122
  0.02308375 0.02450664 0.02185518 0.01854333 0.02402402 0.0216086
  0.021684   0.00971028 0.00964767 0.03058623 0.02420858 0.02899993
  0.03515738 0.0301359  0.03166445 0.02501916 0.02164477 0.02193489
  0.02114609 0.01891756]
 [0.02688389 0.02892118 0.02899551 0.02901314 0.02508085 0.03145517
  0.02791217 0.03046094 0.03048585 0.03469226 0.02786102 0.03973482
  0.03494112 0.02166234 0.01585449 0.0257218  0.02674768 0.02900131
  0.02394446 0.02529051 0.02252547 0.02962076 0.03677037 0.02888172
  0.02619233 0.01956916]
 [0.02674853 0.04328488 0.04134588 0.02295654 0.01918818 0.02616372
  0.03531392 0.03519126 0.03369085 0.02236236 0.02428014 0.02673721
  0.0292774  0.01461933 0.01327247 0.03098502 0.02609828 0.02602338
  0.02462847 0.02835782 0.02692427 0.02837665 0.05353858 0.03382533
  0.03405913 0.02814538]
 [0.0271431  0.06580991 0.0686124  0.0282253  0.02201028 0.0314352
  0.04597918 0.04120256 0.04452661 0.02542196 0.02490331 0.02763294
  0.0295037  0.01547997 0.01421125 0.03783431 0.02824214 0.02345186
  0.02042178 0.02429064 0.02036879 0.02894277 0.06327053 0.01923956
  0.01950764 0.02152836]
 [0.02729739 0.03585627 0.03834689 0.02358564 0.01866677 0.02618369
  0.03605306 0.03472554 0.03331033 0.02211514 0.0218559  0.02505001
  0.02519175 0.01360338 0.0122976  0.02855508 0.02491047 0.02299167
  0.02095187 0.02442    0.02215069 0.02943579 0.04412534 0.02515749
  0.02827864 0.03037418]
 [0.02789824 0.02733387 0.02685749 0.02084204 0.01640085 0.02458602
  0.0288481  0.03184089 0.02620893 0.02056075 0.02267263 0.02538511
  0.02613133 0.01195719 0.0100925  0.02092718 0.01912918 0.02144979
  0.01956169 0.0225722  0.02093338 0.02735738 0.02275247 0.02298671
  0.02296981 0.02259095]
 [0.02732709 0.01969332 0.01827812 0.01461506 0.01270586 0.01582223
  0.02180697 0.02210492 0.01950005 0.01526793 0.02230558 0.01616509
  0.02066764 0.00873155 0.00822822 0.02392559 0.02265862 0.02476071
  0.02474401 0.02921059 0.03161845 0.02524099 0.0199275  0.05212497
  0.03822325 0.02770102]
 [0.02717107 0.01623183 0.01413088 0.0128923  0.01068714 0.01209894
  0.01753597 0.01599251 0.01583651 0.01297186 0.01758221 0.01216837
  0.01652745 0.0073517  0.00715537 0.0202578  0.01897824 0.02798235
  0.02859079 0.04020592 0.03987763 0.02264471 0.01699443 0.07080996
  0.03979712 0.0247249 ]
 [0.02745136 0.01380811 0.01268446 0.01170399 0.01007045 0.01157275
  0.01456999 0.01428021 0.01473577 0.01229302 0.01619895 0.01194869
  0.01497563 0.00694994 0.00637999 0.01769334 0.01509978 0.02198443
  0.01989133 0.03841776 0.04119008 0.01955208 0.01445474 0.07914048
  0.0375213  0.01785146]
 [0.02769961 0.0136113  0.0121685  0.0111375  0.00954259 0.01109692
  0.0145973  0.0137661  0.01474897 0.01180949 0.01815109 0.01243059
  0.01510293 0.00683699 0.00640655 0.01882675 0.01700709 0.0232178
  0.02267241 0.03281874 0.04343488 0.02102751 0.01247391 0.06468679
  0.02921854 0.01556251]
 [0.02752666 0.01433721 0.0125986  0.01063364 0.00952457 0.01087029
  0.01561797 0.01442434 0.01528674 0.01158958 0.02330407 0.01297314
  0.01575659 0.00671762 0.00652659 0.02134064 0.02050253 0.0239372
  0.02693447 0.03418051 0.03776526 0.02210248 0.01423186 0.06210172
  0.02808998 0.02000342]
 [0.02691417 0.03339545 0.02731101 0.04461409 0.05314473 0.04424441
  0.03348631 0.02960803 0.03116046 0.05152959 0.05004149 0.0387992
  0.03585342 0.04705155 0.0333066  0.02345675 0.02641329 0.02695202
  0.02666464 0.02363696 0.02235575 0.03636691 0.02699607 0.01938748
  0.01121934 0.01769953]
 [0.02776478 0.01690853 0.01513003 0.01311074 0.01089313 0.01297419
  0.01567258 0.01624526 0.01770789 0.01381872 0.01892652 0.01379705
  0.01640621 0.007946   0.0068792  0.01720325 0.01827485 0.01842429
  0.02535161 0.02736964 0.02709399 0.02228174 0.01546771 0.03656542
  0.03757738 0.03396194]
 [0.02778324 0.01993932 0.01881438 0.01357092 0.01113646 0.01431225
  0.02005092 0.02166931 0.02105093 0.01476255 0.01818296 0.01574276
  0.02034334 0.00831054 0.0067747  0.01714028 0.02503814 0.01765008
  0.0210663  0.02166059 0.02415338 0.02631121 0.01658935 0.01893662
  0.05891639 0.04625765]
 [0.02753471 0.01622729 0.0149138  0.01167486 0.00953229 0.01210155
  0.01674504 0.01740149 0.01713771 0.01310026 0.01703811 0.01308537
  0.01748622 0.00720088 0.00605445 0.01764529 0.03309334 0.02065007
  0.02807031 0.02512245 0.02838683 0.02180217 0.01389921 0.01761898
  0.07864753 0.05484968]
 [0.02789329 0.01622805 0.01539464 0.01177098 0.01013225 0.01278751
  0.01793049 0.0195752  0.01808841 0.01356466 0.02021535 0.01583371
  0.0200059  0.00761099 0.00605144 0.01758561 0.03331229 0.01946083
  0.02701125 0.02388763 0.02426983 0.01981568 0.01245329 0.01480411
  0.06016987 0.05168255]
 [0.02761479 0.01344023 0.01268212 0.0092429  0.00826158 0.01020083
  0.01472912 0.01456094 0.01533595 0.01071814 0.01780174 0.01145934
  0.01620213 0.00631521 0.00498786 0.01890008 0.03785476 0.02164697
  0.03707911 0.03101648 0.02813843 0.02025111 0.01254523 0.01718013
  0.04677584 0.08047866]
 [0.02698936 0.02116254 0.02379605 0.01929549 0.01676649 0.02214174
  0.02444904 0.02826142 0.04171053 0.02504634 0.02158326 0.02280432
  0.02456739 0.0127068  0.01056841 0.02050487 0.02679153 0.0263674
  0.02965723 0.02791693 0.02717824 0.02605979 0.02525428 0.02131427
  0.0284877  0.04714461]
 [0.02826818 0.018813   0.01913129 0.01614705 0.01234795 0.01653511
  0.02059798 0.02372579 0.02277586 0.01802293 0.02190783 0.01795707
  0.02334897 0.01045989 0.00789492 0.0177338  0.02149169 0.01873625
  0.02451367 0.02209504 0.01931297 0.02499337 0.01433828 0.01134025
  0.016116   0.03006945]
 [0.02675738 0.02998695 0.0292492  0.05136532 0.0555484  0.03956078
  0.02679169 0.02698043 0.03165141 0.04962281 0.03446689 0.02916695
  0.03286395 0.08490946 0.09876451 0.02513689 0.02630739 0.02404406
  0.0191298  0.01811007 0.01661301 0.03126833 0.03229164 0.00677844
  0.0075139  0.01866552]
 [0.02660953 0.03016408 0.02780668 0.05403902 0.10581826 0.03529654
  0.0210603  0.023074   0.02607448 0.05195029 0.03798876 0.02788506
  0.02510386 0.08018717 0.10294591 0.02982581 0.03848088 0.0358217
  0.02683075 0.02160941 0.02085276 0.02816431 0.03170046 0.00610652
  0.00588097 0.01611575]
 [0.02647715 0.02346591 0.02240974 0.03875699 0.05916486 0.02424998
  0.01625542 0.02144345 0.02371575 0.04405407 0.03561055 0.03019778
  0.02728408 0.0292714  0.0312055  0.02237669 0.04257471 0.05867756
  0.05723179 0.03399392 0.03125481 0.02521092 0.02485867 0.01052395
  0.01019998 0.01693026]
 [0.02673049 0.02620225 0.02369301 0.03660173 0.04893863 0.02531626
  0.01861313 0.0225147  0.02653183 0.03991269 0.03337397 0.0275223
  0.02665062 0.02677997 0.02721507 0.01938258 0.03555489 0.04218914
  0.04498344 0.02948141 0.02644829 0.0418063  0.03003277 0.0094563
  0.00911221 0.01488763]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' based', ' on', ' the', ' given', ' information', ',', ' it', ' is', ' possible', ' that', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 32), x_tokens=32, y_tokens=51, max_supp_attn=0.0784, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 32)
DEBUG result.interpretability.attn_scores 1632 
 [[0.01798216 0.02752877 0.03147653 ... 0.01136206 0.01135697 0.04621582]
 [0.01854053 0.02491736 0.02731178 ... 0.01434773 0.01453964 0.05579273]
 [0.01882069 0.02536181 0.03028375 ... 0.02172518 0.01706347 0.04425222]
 ...
 [0.01894194 0.02593425 0.02169177 ... 0.00666706 0.00820045 0.04515373]
 [0.01922631 0.02085497 0.01738581 ... 0.00918403 0.00911748 0.01499379]
 [0.01937977 0.02069068 0.01728613 ... 0.00945951 0.00914469 0.01950445]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Julie', ' has', ' arrived', ' at', ' the', ' bedroom', '.', ' \n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02904957 0.03656199 0.04657748 ... 0.01463568 0.02510296 0.02156762]
 [0.02936932 0.03660656 0.04846502 ... 0.02350716 0.03377892 0.02886998]
 [0.03040893 0.03632877 0.04905145 ... 0.0127423  0.02045497 0.0151364 ]
 ...
 [0.03075194 0.03726614 0.03552182 ... 0.01336876 0.01771956 0.01432048]
 [0.03067979 0.03381375 0.03059089 ... 0.02880103 0.027993   0.02215656]
 [0.0309675  0.03336809 0.03025972 ... 0.01902589 0.02339315 0.02300315]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' kitchen', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' being', ' either', ' in', ' the', ' office', ' or', ' the', ' park', ',', ' and', ' Bill', ' being', ' either', ' in', ' the', ' park', ' or', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 44), x_tokens=44, y_tokens=45, max_supp_attn=0.0, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 44)
DEBUG result.interpretability.attn_scores 1980 
 [[0.02062934 0.03145666 0.03233911 ... 0.01028781 0.00863361 0.01266578]
 [0.02102953 0.02379088 0.02371762 ... 0.02831637 0.01702875 0.01737976]
 [0.02149048 0.03243897 0.03280819 ... 0.0198662  0.01261232 0.0212839 ]
 ...
 [0.02152207 0.03130911 0.03196793 ... 0.00621813 0.006461   0.00908814]
 [0.02177904 0.02752075 0.02677817 ... 0.00671065 0.00843115 0.01046384]
 [0.02184993 0.03013007 0.02990399 ... 0.00583455 0.00819269 0.01117373]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' has', ' arrived', ' at', ' the', ' cinema', '.', ' The', ' context', ' sentence', ' ', '14', ' is', ' contradictory', ',', ' but', ' since', ' Bill', ' has', ' already', ' arrived', ' at', ' the', ' cinema', ',', ' it', ' takes', ' precedence', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01758633 0.02685272 0.02426461 ... 0.03492324 0.02246901 0.00847547]
 [0.01792399 0.02317357 0.02049125 ... 0.01745504 0.02545349 0.01130096]
 [0.01844765 0.02750451 0.0274057  ... 0.03535085 0.01844159 0.00859866]
 ...
 [0.01867746 0.02482161 0.02367548 ... 0.06815388 0.01877304 0.00835923]
 [0.01907291 0.01816411 0.01636065 ... 0.04497823 0.01633655 0.01117677]
 [0.01888991 0.02259898 0.01998436 ... 0.05371469 0.01686391 0.0085162 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' traveling', ' to', ' the', ' park', ',', ' and', ' Julie', ' being', ' in', ' the', ' park', '.', ' There', ' is', ' no', ' connection', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 26), x_tokens=26, y_tokens=45, max_supp_attn=0.1333, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 26)
DEBUG result.interpretability.attn_scores 1170 
 [[0.02067814 0.03677028 0.03897522 ... 0.01176641 0.00806968 0.02110754]
 [0.02134262 0.02290869 0.02288031 ... 0.00802726 0.00633179 0.01370017]
 [0.02170657 0.02566698 0.02890758 ... 0.0104319  0.0080387  0.01297272]
 ...
 [0.02175534 0.02401789 0.02302694 ... 0.00753521 0.00538626 0.01301309]
 [0.0216625  0.02031325 0.0197114  ... 0.01040173 0.00885377 0.01402707]
 [0.02185258 0.02309533 0.02142872 ... 0.00941292 0.00809642 0.01217903]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', '.', ' The', ' information', ' only', ' mentions', ' Mary', ' being', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' park', ',', ' and', ' Fred', ' moving', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0385, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01776543 0.02830224 0.03258153 ... 0.00979801 0.00606535 0.00814885]
 [0.0183218  0.02542627 0.02856185 ... 0.01187683 0.00766169 0.01054849]
 [0.01860731 0.02504367 0.02979116 ... 0.01699278 0.01055451 0.01218993]
 ...
 [0.01858847 0.02668589 0.02492504 ... 0.00595451 0.0046813  0.00557164]
 [0.01888955 0.02052917 0.01973345 ... 0.00827228 0.00554877 0.00567418]
 [0.01891041 0.02347907 0.02238304 ... 0.00808515 0.0054716  0.00568627]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' explicitly', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03004114 0.03791426 0.04223517 ... 0.04191473 0.01976487 0.02477143]
 [0.03049638 0.03967191 0.04624104 ... 0.03107678 0.03151831 0.03780835]
 [0.03137108 0.04079341 0.04550626 ... 0.03029912 0.01757812 0.02125308]
 ...
 [0.03164871 0.0380195  0.03577496 ... 0.03282114 0.01743272 0.0170728 ]
 [0.03177338 0.03102818 0.02859107 ... 0.03275663 0.02829948 0.02687873]
 [0.03184075 0.03700795 0.03219413 ... 0.03633045 0.02127593 0.02296007]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' and', ' Mary', ' moving', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 44), x_tokens=44, y_tokens=44, max_supp_attn=0.0455, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 44)
DEBUG result.interpretability.attn_scores 1936 
 [[0.02112802 0.03082356 0.02897669 ... 0.09108604 0.01197702 0.01194069]
 [0.02133201 0.02844384 0.02629322 ... 0.03843294 0.01822435 0.00988361]
 [0.02203509 0.03087473 0.0302064  ... 0.06751037 0.0171085  0.0124712 ]
 ...
 [0.02245047 0.02620974 0.02413124 ... 0.01811684 0.00826539 0.00896815]
 [0.02271447 0.03064646 0.03071588 ... 0.0189811  0.00831568 0.00808697]
 [0.02282496 0.02766066 0.02844453 ... 0.02442483 0.00842829 0.00910709]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' (', 'from', ' previous', ' parts', ')', ' explicitly', ' stated', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', '.', ' Although', ' the', ' current', ' context', ' sentences', ' do', ' not', ' mention', ' Bill', ',', ' the', ' previous', ' information', ' is', ' still', ' valid', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02099436 0.02242114 0.01778141 ... 0.01301801 0.02855175 0.02991107]
 [0.02119235 0.02238909 0.0200483  ... 0.01643799 0.01589418 0.01693132]
 [0.02195635 0.0238623  0.02029132 ... 0.0233997  0.03857387 0.02985852]
 ...
 [0.02226227 0.02179981 0.01869768 ... 0.01149125 0.06345203 0.04846015]
 [0.02266875 0.01609682 0.01379885 ... 0.00998605 0.03029226 0.03682058]
 [0.02248644 0.02030317 0.01646285 ... 0.01079635 0.02181067 0.06238755]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.08, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03724033 0.06197111 0.07527774 0.08762129 0.08824337 0.08944459
  0.08795661 0.10323042 0.07687326 0.07983859 0.06464061 0.07903796
  0.09521002 0.09044618 0.05255575 0.0413367  0.0369601  0.04505895
  0.03850024 0.04391631 0.0390285  0.05092786 0.04880573 0.03563105
  0.02333091 0.03358318]
 [0.03761547 0.07002336 0.06310432 0.07295836 0.06119479 0.06805274
  0.08665388 0.08421624 0.06805837 0.06305536 0.05862699 0.05435743
  0.06792887 0.09605102 0.09540174 0.04468521 0.03525486 0.04379129
  0.03707216 0.04319834 0.03644774 0.05105808 0.05089699 0.0330856
  0.01875512 0.02960282]
 [0.04078238 0.06789947 0.04180175 0.0619874  0.04546108 0.04212953
  0.03893419 0.02788346 0.02806048 0.04062385 0.0366242  0.02039909
  0.02437582 0.03381652 0.04214178 0.03037828 0.01637877 0.01809425
  0.02131755 0.02300638 0.0224255  0.05573181 0.0581994  0.0135815
  0.00693212 0.01561507]
 [0.03843052 0.0442138  0.04397218 0.02762702 0.01879262 0.03468443
  0.03443025 0.03020277 0.03883618 0.0302465  0.03126681 0.03050396
  0.03024157 0.01284179 0.01207121 0.03836526 0.0388171  0.04375679
  0.05746642 0.05343805 0.04452755 0.04331267 0.0660593  0.0727598
  0.07658371 0.06754144]
 [0.03881169 0.04856116 0.0520701  0.07689689 0.06832454 0.05531197
  0.04181395 0.03625954 0.04240579 0.05418815 0.04470946 0.0319051
  0.03351769 0.11048417 0.11074477 0.04666326 0.03138403 0.02818582
  0.02744195 0.03098158 0.03111313 0.04919209 0.06676991 0.02314136
  0.01009076 0.03320402]
 [0.03960311 0.03171011 0.03209156 0.05930233 0.05089956 0.05035784
  0.03145986 0.02843255 0.0359108  0.04999781 0.03949039 0.0358745
  0.03610136 0.11922531 0.13713238 0.04597853 0.0349394  0.03379277
  0.03097867 0.03319376 0.02990294 0.04247657 0.04075542 0.01640174
  0.008271   0.02203117]
 [0.04020555 0.03510993 0.04104136 0.06139249 0.05482529 0.06272814
  0.0404206  0.03853833 0.04693644 0.05864111 0.04572531 0.05644248
  0.05432254 0.0950058  0.08590851 0.03863753 0.03188053 0.03337771
  0.02977272 0.03264533 0.0281794  0.03824478 0.03825781 0.02237363
  0.01188728 0.02122741]
 [0.03888246 0.05033061 0.05911117 0.0510419  0.05034095 0.06143426
  0.04835777 0.05391426 0.05384508 0.05507201 0.04880358 0.06521589
  0.05860235 0.05852009 0.0512706  0.0512943  0.04289571 0.04241282
  0.03672319 0.04009199 0.03725317 0.04381292 0.05465551 0.04352017
  0.03242204 0.03848728]
 [0.03924908 0.0612129  0.06996513 0.03947921 0.03168445 0.05056478
  0.05694509 0.05993051 0.05767342 0.04279057 0.04310808 0.05323577
  0.05496734 0.02690938 0.01870718 0.05010377 0.04004028 0.03989528
  0.03780938 0.03989075 0.03812539 0.03873714 0.06404656 0.05367155
  0.04450155 0.04883131]
 [0.04025701 0.07931028 0.08435839 0.03437629 0.02446097 0.0440264
  0.05613783 0.0516215  0.06099837 0.03500251 0.03484916 0.04358304
  0.04248384 0.01791242 0.01449408 0.05752295 0.03869207 0.03744414
  0.03678371 0.04215306 0.03767565 0.03786159 0.0740985  0.04610547
  0.03043362 0.03607833]
 [0.04028091 0.04689938 0.05210578 0.02718003 0.02095902 0.03256839
  0.04646652 0.0444442  0.04766691 0.02996704 0.0311746  0.03640315
  0.03453775 0.0150426  0.01336111 0.05515704 0.04300014 0.03725177
  0.0393276  0.04132819 0.03862873 0.03781029 0.05620629 0.06005982
  0.05372061 0.04330285]
 [0.04064528 0.02458476 0.02731425 0.01770273 0.01502356 0.02239758
  0.02803992 0.02920938 0.04005598 0.02195675 0.0219444  0.02320592
  0.02313983 0.01007354 0.00971315 0.03513265 0.03229898 0.02982567
  0.03546702 0.03856241 0.03627875 0.03161431 0.0448928  0.07111528
  0.08224601 0.06608769]
 [0.04039146 0.03377567 0.03598863 0.02380778 0.0192973  0.03262735
  0.03648826 0.03676531 0.03503952 0.02728011 0.03058906 0.03742181
  0.03335686 0.01221227 0.01165216 0.04706392 0.03888864 0.03624026
  0.0378493  0.03823733 0.03736538 0.03787211 0.03494294 0.05919456
  0.06802405 0.05281983]
 [0.04107966 0.04452426 0.04825172 0.04049725 0.02914821 0.05323042
  0.05005444 0.05690003 0.04906448 0.05239518 0.05068005 0.08038153
  0.06291343 0.02202372 0.0150827  0.0362595  0.03666921 0.0405414
  0.03695562 0.03801029 0.03416726 0.03989177 0.02694169 0.02985109
  0.02223422 0.02351055]
 [0.04159899 0.03104074 0.03271744 0.02536825 0.02116706 0.03130121
  0.03813419 0.03718866 0.03221798 0.03060005 0.0381349  0.04009686
  0.03866715 0.01287941 0.01140877 0.03563172 0.03718052 0.03310537
  0.03444135 0.03446977 0.03366164 0.03804946 0.02288546 0.03678054
  0.04148326 0.02584262]
 [0.04083552 0.02239717 0.02044062 0.01592117 0.01370985 0.01890199
  0.0256665  0.02606853 0.02383962 0.01961494 0.02981451 0.02565981
  0.02872562 0.00767021 0.00840971 0.03575876 0.04580823 0.03638349
  0.04120703 0.03751419 0.04081791 0.03496287 0.0192107  0.04627223
  0.08433881 0.04862164]
 [0.0402721  0.02136709 0.01834156 0.01459931 0.01197365 0.01686828
  0.02673115 0.0294469  0.02247197 0.01757954 0.02773825 0.02144199
  0.02846204 0.00665007 0.00701708 0.03588445 0.05380068 0.04495753
  0.05663713 0.04984003 0.06318707 0.03127759 0.01690547 0.05490389
  0.10845836 0.05533361]
 [0.04111709 0.02135183 0.01880273 0.01468679 0.01263371 0.0183702
  0.02451725 0.02606434 0.02279056 0.01875802 0.03295732 0.02741085
  0.02780979 0.00707079 0.00696718 0.03308587 0.05256051 0.03674366
  0.04770808 0.03889929 0.0442836  0.0306491  0.01383139 0.04303876
  0.0863387  0.04442578]
 [0.04096027 0.02018177 0.01792249 0.01243916 0.01122883 0.01586699
  0.02630215 0.02541744 0.02216922 0.01645157 0.04497533 0.02636492
  0.02770555 0.00614595 0.00630813 0.04323083 0.05008775 0.04369301
  0.05375908 0.04595527 0.05340871 0.02998969 0.01385494 0.04521818
  0.05263093 0.06961665]
 [0.03960167 0.02617924 0.02195772 0.01614704 0.01483607 0.01893759
  0.02996862 0.0266735  0.02899865 0.01873276 0.02982373 0.02251065
  0.02780979 0.00790534 0.0081688  0.03711643 0.03545144 0.04703283
  0.06206358 0.06935234 0.07072629 0.03490631 0.03230857 0.09179141
  0.07143059 0.09098211]
 [0.04167156 0.02573059 0.02579714 0.02241752 0.01680343 0.0247684
  0.02682178 0.03063171 0.02992801 0.02585751 0.03239638 0.03168622
  0.03062726 0.01132505 0.01002111 0.02905498 0.02874903 0.03487224
  0.03896318 0.03540226 0.0379614  0.03295593 0.01732032 0.02643828
  0.02242645 0.03735036]
 [0.04050291 0.03155129 0.03002819 0.04973435 0.04777773 0.0459611
  0.03077708 0.03012593 0.03569958 0.05291202 0.04187708 0.0403536
  0.03961723 0.07653408 0.08861722 0.03129047 0.03213456 0.03475462
  0.03077328 0.03130077 0.0309396  0.03922863 0.03400789 0.01691251
  0.01047488 0.02410522]
 [0.04024339 0.03288017 0.02911866 0.05321159 0.09680753 0.04232088
  0.02882541 0.02812796 0.03349058 0.0572303  0.04650602 0.03808224
  0.03268972 0.07659177 0.09769704 0.03792348 0.04383596 0.04843849
  0.03578186 0.03446535 0.03619834 0.03629199 0.03264556 0.01395907
  0.00743782 0.02026989]
 [0.03962757 0.03042968 0.02728588 0.0461251  0.10397323 0.03076163
  0.02520607 0.02774654 0.03022548 0.05207867 0.04766478 0.04187895
  0.03193622 0.03406357 0.04781568 0.03439097 0.07513904 0.07671265
  0.05280102 0.04294107 0.05394794 0.03379466 0.03023825 0.02470146
  0.01410612 0.02620839]
 [0.04009392 0.03676363 0.03113354 0.04747877 0.07043315 0.03638328
  0.03289068 0.03096004 0.03674335 0.04912911 0.04587899 0.03654629
  0.03425035 0.03259888 0.03733217 0.02805315 0.04715247 0.05363717
  0.04239881 0.04120582 0.04374846 0.05934978 0.04126253 0.01949099
  0.01144109 0.02532076]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', ' and', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 32), x_tokens=32, y_tokens=33, max_supp_attn=0.1212, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 32)
DEBUG result.interpretability.attn_scores 1056 
 [[0.02830332 0.03188643 0.03309185 ... 0.03230631 0.01038001 0.07524675]
 [0.02899605 0.03218211 0.03117429 ... 0.04639596 0.0179392  0.08610096]
 [0.02958971 0.029925   0.03285844 ... 0.05379227 0.02152468 0.06660485]
 ...
 [0.02989185 0.02877156 0.02409991 ... 0.01257945 0.01631254 0.04161774]
 [0.03030265 0.02928778 0.02798171 ... 0.01197444 0.01463338 0.04478284]
 [0.03054411 0.02423392 0.02453011 ... 0.01118444 0.01374483 0.07207597]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' explicitly', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02907471 0.03732571 0.03908863 ... 0.01728204 0.04135973 0.02959106]
 [0.02957281 0.03249345 0.03490986 ... 0.02664991 0.03716724 0.03788494]
 [0.03040755 0.04110157 0.0466333  ... 0.01257824 0.03165507 0.01910729]
 ...
 [0.03070113 0.03725101 0.03955945 ... 0.01136131 0.03945394 0.02467042]
 [0.03106588 0.02743255 0.02749971 ... 0.02029125 0.03410519 0.03880826]
 [0.03088865 0.03156969 0.03213356 ... 0.01665619 0.04018628 0.04046368]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' (', 'from', ' previous', ' parts', ' of', ' the', ' conversation', ')', ' explicitly', ' states', ' that', ' Julie', ' journey', 'ed', ' to', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Julie', ' leaving', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.0732, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02265532 0.01896283 0.01862703 ... 0.01709272 0.00828686 0.05955519]
 [0.02298128 0.02507995 0.02443345 ... 0.03943065 0.03135937 0.02490333]
 [0.02359135 0.02133651 0.02293519 ... 0.02218664 0.01190648 0.04893447]
 ...
 [0.02384799 0.02452056 0.01900481 ... 0.0071931  0.00620122 0.07690587]
 [0.02435577 0.01989869 0.01464426 ... 0.0079208  0.00991556 0.05414793]
 [0.0242459  0.02213093 0.01542096 ... 0.00667962 0.00707541 0.06551813]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', "'s", ' possible', ' locations', ' as', ' the', ' bedroom', ' or', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02386478 0.03183807 0.03130734 ... 0.0172454  0.03095361 0.02227812]
 [0.02418883 0.02893733 0.02555415 ... 0.02324019 0.0264049  0.01595765]
 [0.02487068 0.0355619  0.03569693 ... 0.01629175 0.02711084 0.01438065]
 ...
 [0.0250606  0.03054213 0.02807941 ... 0.01488274 0.03732102 0.02228595]
 [0.02546029 0.0241102  0.02118071 ... 0.02100939 0.03009612 0.02877539]
 [0.02544581 0.02663362 0.02236392 ... 0.01888592 0.03110318 0.0272203 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' office', '.', ' Sentence', ' ', '1', ' only', ' mentions', ' Mary', ' traveling', ' to', ' the', ' school', ',', ' which', ' does', ' not', ' imply', ' she', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 26), x_tokens=26, y_tokens=57, max_supp_attn=0.1228, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 26)
DEBUG result.interpretability.attn_scores 1482 
 [[0.01604681 0.03315518 0.03684462 ... 0.01080545 0.00575913 0.01677225]
 [0.01595304 0.04001702 0.03101745 ... 0.03418842 0.01710398 0.02645627]
 [0.01742081 0.04532349 0.02680118 ... 0.00539901 0.00189572 0.00737916]
 ...
 [0.01720061 0.0204761  0.02099905 ... 0.00528281 0.00191723 0.01005106]
 [0.0170814  0.01625454 0.01706538 ... 0.00773624 0.00609921 0.01278047]
 [0.01726594 0.01979775 0.01969876 ... 0.00641476 0.00356229 0.01073045]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' implies', ' she', ' is', ' currently', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' recent', ' information', ' suggesting', ' she', ' is', ' in', ' the', ' bedroom', '.', ' Sentence', ' ', '5', ' is', ' about', ' Julie', "'s", ' movement', ' and', ' does', ' not', ' provide', ' any', ' information', ' about', ' Mary', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 32), x_tokens=32, y_tokens=59, max_supp_attn=0.0169, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 32)
DEBUG result.interpretability.attn_scores 1888 
 [[0.0155515  0.02219325 0.02501346 ... 0.02732118 0.00466429 0.0084176 ]
 [0.01594185 0.02255082 0.02482477 ... 0.03763095 0.00600597 0.01209814]
 [0.01628555 0.02058904 0.02502059 ... 0.04543217 0.00665774 0.01401248]
 ...
 [0.01633125 0.02380713 0.02220608 ... 0.01271749 0.00408881 0.00721648]
 [0.01672011 0.01727189 0.01604825 ... 0.00947687 0.00801741 0.01017493]
 [0.01674186 0.01877946 0.01663177 ... 0.00733838 0.00545829 0.0083218 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' the', ' cinema', '.', ' Sentence', ' ', '8', ' is', ' about', ' Fred', "'s", ' location', ' and', ' does', ' not', ' provide', ' any', ' information', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 38), x_tokens=38, y_tokens=50, max_supp_attn=0.08, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 38)
DEBUG result.interpretability.attn_scores 1900 
 [[0.01856412 0.03212906 0.03301489 ... 0.04640343 0.05065664 0.02597629]
 [0.01893238 0.02365687 0.0265206  ... 0.02354309 0.02961456 0.02459848]
 [0.01928806 0.03241216 0.03593092 ... 0.04240349 0.03879688 0.0230957 ]
 ...
 [0.01938171 0.03217972 0.02762879 ... 0.09805012 0.04350013 0.02139394]
 [0.01981447 0.02332162 0.01926659 ... 0.05569839 0.02370327 0.021003  ]
 [0.01975095 0.02668457 0.02150167 ... 0.07354213 0.03260564 0.01921325]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' (', 'from', ' previous', ' context', ')', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' school', '.', ' There', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Julie', "'s", ' location', ' has', ' changed', '.', ' Sent', 'ences', ' ', '10', ' and', ' ', '11', ' are', ' about', ' Fred', ' and', ' Bill', "'s", ' locations', ',', ' respectively', ',', ' and', ' do', ' not', ' provide', ' any', ' new', ' information', ' about', ' Julie', "'s", ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(69, 44), x_tokens=44, y_tokens=69, max_supp_attn=0.0435, attn_on_target=0.0145)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (69, 44)
DEBUG result.interpretability.attn_scores 3036 
 [[0.01324345 0.01856852 0.01856351 ... 0.0234731  0.06099414 0.01186435]
 [0.01353926 0.01479536 0.01422837 ... 0.01076893 0.04393349 0.01150756]
 [0.01381638 0.02076937 0.02075367 ... 0.0124262  0.05441906 0.01166692]
 ...
 [0.01401233 0.01907532 0.01858046 ... 0.02303138 0.01583584 0.00523975]
 [0.01427897 0.01506999 0.01354591 ... 0.02960367 0.01013835 0.00920393]
 [0.01431211 0.0157193  0.01454943 ... 0.02351404 0.01083082 0.00663025]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' which', ' implies', ' that', ' Fred', "'s", ' location', ' is', ' one', ' of', ' these', ' two', ' options', '.', ' There', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Fred', "'s", ' location', ' has', ' changed', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0833, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01909277 0.02718236 0.02641013 ... 0.0156138  0.01063954 0.01900106]
 [0.01925669 0.0197198  0.01987541 ... 0.02317257 0.0132431  0.01499203]
 [0.01994831 0.03008509 0.03266689 ... 0.02491226 0.01738268 0.02736852]
 ...
 [0.02018997 0.03100191 0.03296676 ... 0.00949564 0.00694616 0.0339402 ]
 [0.02074046 0.02372564 0.02218168 ... 0.01036643 0.00732654 0.01114245]
 [0.02062604 0.02688107 0.02614396 ... 0.01024001 0.00750502 0.0133469 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.0272468  0.0458406  0.05522672 0.07179555 0.08004538 0.07433557
  0.05866662 0.06555493 0.05509292 0.06422033 0.0479648  0.06087548
  0.06651193 0.09600656 0.06525867 0.03024998 0.03115947 0.03175405
  0.02887861 0.02986315 0.02535957 0.03872961 0.04281286 0.02049853
  0.01370077 0.02381906]
 [0.02766283 0.05706124 0.05259018 0.07127708 0.06231934 0.05990817
  0.04600946 0.04284345 0.04265448 0.04914025 0.03896113 0.03235617
  0.03323261 0.10383267 0.10394959 0.03081802 0.02541955 0.02185969
  0.02185236 0.02157235 0.01995041 0.03976607 0.04577315 0.01556506
  0.00812584 0.02060325]
 [0.02978158 0.06078837 0.03758869 0.05290686 0.03732759 0.03561478
  0.03241666 0.02252756 0.02263015 0.03370431 0.02766059 0.0166628
  0.01807136 0.02602648 0.03467515 0.02185109 0.01388429 0.01298334
  0.01584199 0.01576542 0.01537202 0.04303508 0.05268177 0.0097167
  0.00510105 0.01119036]
 [0.02789021 0.03517551 0.03244013 0.02316913 0.01609029 0.02581354
  0.02915667 0.02620154 0.0295829  0.02416851 0.02461361 0.02525496
  0.02436215 0.01171018 0.01108415 0.03035665 0.02850148 0.03325565
  0.03995947 0.04286104 0.03368622 0.03225475 0.04785438 0.05609453
  0.06156363 0.05276135]
 [0.02826584 0.04315707 0.04764184 0.06589888 0.0599437  0.04827946
  0.03577235 0.02976653 0.03476228 0.04563532 0.03458064 0.02612248
  0.0256178  0.09360911 0.09801669 0.03495273 0.0266866  0.01994473
  0.02098944 0.0216809  0.02160009 0.03829455 0.06480346 0.01728703
  0.0070013  0.02521246]
 [0.02880755 0.02776675 0.02907758 0.05013204 0.04524942 0.0429372
  0.02621127 0.02324509 0.02939383 0.04262715 0.03117087 0.02974857
  0.02760155 0.10574435 0.12687683 0.0348704  0.03060016 0.02419977
  0.02360535 0.02298043 0.0207193  0.03227883 0.03769808 0.01162416
  0.00590619 0.01636209]
 [0.02921585 0.03171515 0.03795549 0.05386636 0.04980798 0.05510805
  0.0352409  0.03252315 0.03915318 0.05119703 0.0368334  0.04772366
  0.04266139 0.08387298 0.07850283 0.02929928 0.02777081 0.02428403
  0.02274489 0.02277767 0.01959835 0.02934589 0.03525934 0.01579354
  0.00885929 0.01609418]
 [0.02820232 0.04158931 0.04833253 0.04199699 0.04421245 0.05103467
  0.04154097 0.04337366 0.04332278 0.04530414 0.03746829 0.05313512
  0.04560795 0.05141592 0.04598853 0.03914078 0.03591933 0.03259443
  0.02973759 0.03084983 0.02820491 0.03426117 0.05016226 0.03850683
  0.0269017  0.03113986]
 [0.02933412 0.04257171 0.05031034 0.04706411 0.04315827 0.05790578
  0.04615913 0.04759715 0.05008061 0.05018752 0.03712878 0.05313638
  0.04834031 0.03773997 0.02509671 0.02791595 0.02790045 0.02664233
  0.02541803 0.02642435 0.02274285 0.03414298 0.03958834 0.02219379
  0.0142602  0.02298507]
 [0.02865316 0.05517648 0.05803655 0.03020642 0.02429201 0.03911798
  0.04841628 0.04574086 0.04771075 0.03180296 0.03001753 0.04009213
  0.04036772 0.01761633 0.01471183 0.04277711 0.03457552 0.03104197
  0.03181127 0.0333767  0.03162035 0.03403657 0.06660418 0.04453005
  0.03390845 0.03374775]
 [0.02921811 0.03939933 0.04581293 0.02415076 0.02069932 0.02785941
  0.04752848 0.03516851 0.04133691 0.02463186 0.02394441 0.02756562
  0.02723009 0.01332431 0.01280333 0.04181165 0.03178408 0.02722383
  0.03025909 0.03230092 0.03031343 0.02969542 0.0544299  0.05050781
  0.03969697 0.03535521]
 [0.02962534 0.01437183 0.01667309 0.01124169 0.01006231 0.01424185
  0.01715619 0.01676113 0.02269463 0.01416644 0.0133719  0.01495733
  0.01438758 0.00626331 0.00635229 0.01837503 0.01875945 0.01798613
  0.02322643 0.02419958 0.02456503 0.01926379 0.03071997 0.0575632
  0.06319319 0.06050047]
 [0.02924528 0.0236465  0.02434882 0.01527188 0.01409091 0.01920336
  0.02421068 0.02214835 0.02363407 0.01724288 0.02083247 0.02100103
  0.02067495 0.0084234  0.0088632  0.03364552 0.02604511 0.0257006
  0.02784103 0.02822619 0.02746264 0.02837526 0.03023535 0.05134446
  0.06685774 0.04984015]
 [0.02946233 0.02367318 0.02417047 0.01765544 0.01572781 0.0225616
  0.02693209 0.02829739 0.02548804 0.02130558 0.02477172 0.02837903
  0.02937906 0.00993817 0.00885626 0.03428087 0.03001888 0.03137942
  0.02957181 0.02928302 0.02893629 0.02940381 0.02235375 0.04706727
  0.05348105 0.02879453]
 [0.02887643 0.02008336 0.0173175  0.01445478 0.01185063 0.01558322
  0.02222537 0.02254686 0.01974733 0.01624355 0.02219294 0.01955851
  0.02352125 0.00696494 0.00688641 0.0353952  0.02701307 0.03715768
  0.03639034 0.03914677 0.04290039 0.02738426 0.01677815 0.05512679
  0.10591199 0.04270805]
 [0.03007001 0.01880515 0.01826393 0.01491656 0.01371695 0.01838288
  0.02277413 0.0221983  0.02058711 0.01724434 0.02188776 0.02116145
  0.02145774 0.00735357 0.0070669  0.03219979 0.02013128 0.02918889
  0.02530998 0.03136545 0.02559748 0.0215172  0.01527421 0.03423646
  0.08032541 0.02956711]
 [0.02987357 0.01741631 0.01598325 0.01263947 0.01092034 0.01494056
  0.02042433 0.02097327 0.0185265  0.01488544 0.02403633 0.02073807
  0.02197846 0.00628705 0.00623441 0.03652222 0.02475736 0.0370271
  0.02954517 0.03576327 0.03174091 0.02217231 0.01259817 0.03533228
  0.06786139 0.03510688]
 [0.02971972 0.01628326 0.01512263 0.01089881 0.00946467 0.01316431
  0.01971369 0.02020691 0.01767792 0.01328331 0.0252007  0.01838148
  0.02030806 0.00557825 0.00590789 0.03043251 0.03114514 0.03513948
  0.03375717 0.03559994 0.03514737 0.02301802 0.01309531 0.03619545
  0.04263276 0.05355795]
 [0.02924773 0.01874787 0.01651072 0.01224405 0.01115434 0.01512708
  0.02022376 0.01876161 0.02067798 0.01407203 0.02245646 0.01706856
  0.0199309  0.00649627 0.00643886 0.02359378 0.0285706  0.02758671
  0.03293174 0.04014011 0.0376198  0.02371606 0.01876608 0.06094767
  0.04317562 0.06362193]
 [0.03020122 0.02152871 0.02024595 0.01500366 0.01242074 0.01737589
  0.02232107 0.0230816  0.02145621 0.01661539 0.02398117 0.02105827
  0.02207189 0.00770742 0.00731358 0.02222366 0.02417385 0.02487768
  0.0282757  0.02853136 0.03045804 0.02566524 0.01552403 0.02317973
  0.02182315 0.03634407]
 [0.03032608 0.0248847  0.02775511 0.02291197 0.01828239 0.0265712
  0.02894694 0.03607111 0.02807187 0.0274512  0.03023815 0.03739268
  0.03396754 0.0126558  0.00913194 0.02312594 0.02376552 0.02699457
  0.02541803 0.02325591 0.02380801 0.02845338 0.01599863 0.01726714
  0.01801918 0.01867982]
 [0.03044956 0.02983668 0.0317301  0.02800122 0.02076241 0.03144476
  0.03513298 0.04319768 0.02997567 0.03291123 0.03767543 0.04539161
  0.04264202 0.0147789  0.01015101 0.02474461 0.02374863 0.02872011
  0.02439821 0.02364198 0.02266493 0.02889787 0.01755266 0.01582802
  0.01581461 0.01433719]
 [0.03034434 0.02625    0.02660931 0.02429593 0.01911747 0.02733369
  0.03104526 0.03606203 0.02900252 0.02988127 0.03400581 0.03911074
  0.03989371 0.01350869 0.00999111 0.0280397  0.0252087  0.03134108
  0.02709701 0.02564555 0.02525024 0.02871081 0.01494048 0.01945803
  0.01721774 0.013359  ]
 [0.03022452 0.01996802 0.01918091 0.01463313 0.01104078 0.01652353
  0.02253589 0.0251116  0.02250117 0.01780937 0.02320166 0.02312862
  0.02656922 0.00771791 0.00687632 0.03126748 0.0273679  0.03030484
  0.02929354 0.02752931 0.03126893 0.02714955 0.01276472 0.02965386
  0.02546792 0.01843461]
 [0.03014017 0.02175234 0.01997759 0.01593275 0.01143997 0.01672647
  0.02590278 0.02621857 0.02322518 0.01837004 0.0255733  0.02244983
  0.02790919 0.00785702 0.00709527 0.03339568 0.02760009 0.03539265
  0.03332792 0.03202955 0.03517526 0.02484024 0.01246355 0.03039957
  0.02693483 0.02032956]
 [0.03035353 0.02052434 0.01868288 0.01520967 0.01221426 0.01607801
  0.02223555 0.02476646 0.02208934 0.01872591 0.02511246 0.02333496
  0.02511303 0.00808722 0.00710451 0.02743801 0.03218827 0.03075577
  0.03430581 0.02805363 0.03291284 0.02445351 0.01242473 0.02007717
  0.01881715 0.01941145]
 [0.03043903 0.02315138 0.02150617 0.01651481 0.01241615 0.01764745
  0.02648515 0.02826219 0.0271295  0.01988357 0.03002488 0.02469947
  0.02778613 0.0084107  0.00731253 0.02978162 0.03128942 0.03229343
  0.03338367 0.03089028 0.03405816 0.02538339 0.01357617 0.02176031
  0.01927102 0.02034291]
 [0.03054234 0.01717385 0.01654269 0.01073981 0.00916528 0.01243275
  0.02103621 0.02140583 0.02053142 0.01360432 0.02920002 0.01787758
  0.02179159 0.00616064 0.00540361 0.02640264 0.03397099 0.02846466
  0.03540161 0.03060559 0.03394529 0.02347985 0.01214611 0.02322141
  0.01856105 0.03109847]
 [0.02916692 0.02238242 0.02104348 0.01246388 0.01154206 0.01544212
  0.0278545  0.02730396 0.02620471 0.01599952 0.03269436 0.02129859
  0.02704664 0.0073613  0.00712888 0.02588484 0.03688793 0.03820606
  0.0443629  0.04797366 0.05272987 0.02670322 0.02344946 0.05016073
  0.02587334 0.05842261]
 [0.03053714 0.02232827 0.0219899  0.01722684 0.01325812 0.02024127
  0.02326079 0.02633097 0.02630584 0.02033094 0.02431088 0.02509139
  0.02505264 0.010451   0.00830912 0.01820285 0.02500167 0.02151693
  0.02695146 0.02677612 0.03010117 0.02570884 0.01535685 0.01659646
  0.01306521 0.02331172]
 [0.02944355 0.02828463 0.02850216 0.04204123 0.0441161  0.03797183
  0.02491216 0.02514566 0.0312947  0.04319944 0.03187194 0.03175601
  0.03050253 0.06688873 0.08131967 0.02376802 0.02750358 0.0241842
  0.02454228 0.0231873  0.02244049 0.03121577 0.03272606 0.01212129
  0.00666239 0.01842081]
 [0.02921858 0.02940198 0.02850636 0.04653873 0.09034628 0.03718325
  0.02301237 0.02340404 0.02999033 0.05049109 0.03760924 0.03195606
  0.02527597 0.06874685 0.08693402 0.02979741 0.03933538 0.03349516
  0.02908583 0.02547812 0.02622722 0.02836263 0.03183697 0.00997209
  0.00537643 0.01578132]
 [0.02896847 0.0261425  0.02476525 0.03725062 0.07909788 0.02516701
  0.01884524 0.0222721  0.02581194 0.04343039 0.03522166 0.03304753
  0.02526799 0.02999722 0.03864701 0.02569376 0.06126212 0.05310094
  0.04260745 0.03204542 0.0435593  0.02576272 0.02939134 0.01666467
  0.01096497 0.02049466]
 [0.02924579 0.03312127 0.02955879 0.03944891 0.05464642 0.03074122
  0.02569407 0.02492995 0.03165524 0.04023339 0.03418476 0.02848787
  0.02786703 0.03146672 0.03371092 0.0217452  0.04005331 0.03340217
  0.03187689 0.03017907 0.03226291 0.04452141 0.04235955 0.01350793
  0.00766653 0.01826416]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' mention', ' Bill', ' and', ' Julie', ',', ' but', ' not', ' Fred', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0312, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02904242 0.03382997 0.03363248 ... 0.01409285 0.01369201 0.03884513]
 [0.03012254 0.02958238 0.02860602 ... 0.01977519 0.02221755 0.05240498]
 [0.03054271 0.03003141 0.03233867 ... 0.03357559 0.03187934 0.05057054]
 ...
 [0.03066669 0.03088243 0.026058   ... 0.01539165 0.01729869 0.02330445]
 [0.03129384 0.0312224  0.02755473 ... 0.01254627 0.01559391 0.02159753]
 [0.03143933 0.02697588 0.02506952 ... 0.01266921 0.01601175 0.02514803]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '7', ',', ' Bill', ' moved', ' to', ' the', ' school', ',', ' but', ' then', ' according', ' to', ' sentence', ' ', '8', ',', ' Bill', ' went', ' back', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' no', ' longer', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.0222, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02041218 0.03247131 0.03164245 ... 0.01499462 0.0182756  0.02612068]
 [0.02087851 0.03127554 0.03074597 ... 0.01886806 0.02328011 0.02242135]
 [0.02135623 0.03414514 0.03715471 ... 0.01248432 0.01447991 0.02040985]
 ...
 [0.02153931 0.03137017 0.02667027 ... 0.0148234  0.01188182 0.02396227]
 [0.02201703 0.02599597 0.02075132 ... 0.02061184 0.01593136 0.01899816]
 [0.02186944 0.02482355 0.01987342 ... 0.01657969 0.01482356 0.02336247]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '11', ',', ' Fred', ' went', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Fred', ' going', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.129, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03011615 0.03887821 0.04505657 ... 0.02672778 0.0294091  0.01550533]
 [0.03071365 0.03125254 0.03419795 ... 0.02475544 0.03688002 0.02462467]
 [0.03140333 0.04162978 0.05100573 ... 0.03917074 0.03556424 0.02035275]
 ...
 [0.03149288 0.04689964 0.04444612 ... 0.01331788 0.01446568 0.01094513]
 [0.0321007  0.04025295 0.03493782 ... 0.01390535 0.01210314 0.0117299 ]
 [0.03215516 0.04062372 0.0354512  ... 0.0121965  0.01268644 0.01134445]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 50), x_tokens=50, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 50)
DEBUG result.interpretability.attn_scores 1450 
 [[0.03250748 0.04728829 0.04482863 ... 0.03443212 0.02591242 0.02400264]
 [0.03282588 0.05658941 0.05263788 ... 0.04254341 0.03575869 0.04052311]
 [0.03387803 0.04743955 0.05052579 ... 0.02871745 0.02121944 0.01795442]
 ...
 [0.03401775 0.04748997 0.04120501 ... 0.02681634 0.01635525 0.01798646]
 [0.03415271 0.03766785 0.03019414 ... 0.03424913 0.02588997 0.02692662]
 [0.03419865 0.04194387 0.03175437 ... 0.02911419 0.02123348 0.02339582]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' journey', 'ing', ' to', ' the', ' cinema', ' and', ' moving', ' to', ' the', ' park', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.1667, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02598282 0.04749677 0.05107415 0.08088483 0.07815501 0.05122136
  0.03530411 0.03051972 0.03497983 0.05111762 0.03424912 0.02413134
  0.0257782  0.12891516 0.13054232 0.03743168 0.02577103 0.01865777
  0.01972008 0.02084088 0.02187566 0.04003104 0.0665736  0.00998676
  0.00806379 0.02424795]
 [0.02680083 0.02960879 0.0300586  0.06017449 0.05546441 0.04410749
  0.02472091 0.02199382 0.02799528 0.04415748 0.02941607 0.02596628
  0.02564137 0.13165976 0.15651834 0.0358708  0.02780815 0.02211902
  0.02178607 0.02151402 0.02045012 0.03383243 0.03969208 0.00786886
  0.0068352  0.0159592 ]
 [0.02724295 0.03350317 0.0385473  0.06311627 0.06272716 0.05695374
  0.03360483 0.03150084 0.03688591 0.05249289 0.03424169 0.04198455
  0.04075456 0.1045679  0.09668222 0.02994703 0.0258291  0.02303495
  0.02116593 0.02178532 0.01952328 0.03054319 0.03683713 0.01123985
  0.00931841 0.01520478]
 [0.02634734 0.03986039 0.04691328 0.04904975 0.0512237  0.05411371
  0.04066376 0.04181118 0.04236258 0.04754365 0.03543458 0.04956893
  0.04412745 0.06203268 0.05572875 0.03722636 0.0336487  0.02978892
  0.02624118 0.02795605 0.02645909 0.03408644 0.0522394  0.0287779
  0.02743285 0.02679459]
 [0.02646378 0.05862333 0.06622492 0.04068213 0.03302209 0.04916721
  0.05411061 0.05315513 0.05112446 0.03869829 0.03348037 0.04246793
  0.04623003 0.0287617  0.0210939  0.03707185 0.03073043 0.02811447
  0.02569943 0.02798917 0.02692667 0.03211646 0.06664574 0.03365319
  0.03454695 0.03571567]
 [0.0273996  0.07227849 0.0818432  0.03543318 0.02451529 0.0424206
  0.04924335 0.04197077 0.05056299 0.03150556 0.02515454 0.0322897
  0.03170911 0.01994717 0.01656228 0.04049444 0.02821408 0.02399865
  0.02421657 0.02821322 0.02434203 0.03044938 0.07354519 0.02461901
  0.02341866 0.02650256]
 [0.02731097 0.04317494 0.05401948 0.03055815 0.0214372  0.03825427
  0.04511139 0.04181011 0.04405098 0.02921007 0.02456817 0.03321863
  0.03021821 0.01789383 0.01492821 0.03890241 0.02830032 0.02594892
  0.02612491 0.02942847 0.02673015 0.03102479 0.05176485 0.0340973
  0.03672142 0.03437924]
 [0.02786849 0.03495554 0.03639757 0.02869316 0.02046011 0.03922188
  0.03998613 0.0439041  0.03600986 0.02983703 0.02827196 0.03864617
  0.03382904 0.01601314 0.01280102 0.02818236 0.02520554 0.02576224
  0.02354112 0.02489918 0.02280159 0.02909742 0.02849503 0.02616781
  0.02742274 0.02645801]
 [0.02744998 0.02600714 0.02415624 0.01940547 0.01498869 0.02315598
  0.0306618  0.02976032 0.025095   0.0206623  0.02728584 0.02327436
  0.02710265 0.01088288 0.01012064 0.03470908 0.03022906 0.02857732
  0.02836814 0.0297928  0.03331881 0.02820542 0.02559073 0.05719603
  0.04976427 0.03174598]
 [0.02732467 0.02455477 0.02069164 0.0175017  0.01328012 0.01734653
  0.032483   0.03240163 0.02190404 0.01713166 0.0235969  0.01874803
  0.02605494 0.00899537 0.00888915 0.04081852 0.03392583 0.03578001
  0.03341857 0.03450085 0.04315314 0.02825463 0.02092234 0.06623084
  0.05382195 0.02800315]
 [0.02822002 0.01788798 0.01601984 0.01523485 0.01270881 0.01542368
  0.01797764 0.01669298 0.01782507 0.01474372 0.01586593 0.01521406
  0.01554004 0.00817649 0.00787585 0.02906444 0.01709904 0.02229359
  0.02090811 0.02681776 0.02558645 0.02168921 0.01666017 0.06205893
  0.05409098 0.03489484]
 [0.02796907 0.01825608 0.01538453 0.01380586 0.01203206 0.01383003
  0.01789542 0.01694683 0.01667956 0.01377727 0.01782439 0.01550664
  0.01646521 0.0076333  0.0074173  0.03534855 0.02032721 0.02849054
  0.02521603 0.03625967 0.03266765 0.02255578 0.01589898 0.06984824
  0.0549365  0.03269097]
 [0.0278699  0.01730093 0.01463567 0.01194553 0.01120047 0.01246948
  0.01642296 0.01580505 0.01608623 0.0126577  0.01885822 0.01406022
  0.01605879 0.00673799 0.00685558 0.03122009 0.02232351 0.02605791
  0.02816128 0.03223499 0.03322209 0.02365373 0.0175612  0.06695035
  0.04371213 0.04829172]
 [0.02738658 0.02081116 0.01726209 0.01532329 0.01492862 0.01534091
  0.01911081 0.01826749 0.01896527 0.01569861 0.01946792 0.01650379
  0.01852591 0.00807549 0.00840764 0.02805646 0.02335299 0.02320381
  0.02879797 0.0279765  0.03291992 0.02476457 0.02068    0.06584007
  0.04469115 0.05460223]
 [0.02796424 0.01882067 0.01604405 0.01418599 0.01294908 0.01418777
  0.01669609 0.01694683 0.01686274 0.01474372 0.01888155 0.01466299
  0.01638249 0.00787282 0.00807314 0.02707938 0.02056381 0.02447462
  0.0295357  0.02935102 0.03268397 0.02455713 0.01869381 0.04712042
  0.05058349 0.05536449]
 [0.0282488  0.01729532 0.01622438 0.01412548 0.01216688 0.01552739
  0.01819879 0.01846993 0.01811576 0.01509187 0.01652228 0.01587011
  0.01781927 0.00807549 0.00742606 0.02199529 0.0192063  0.0238382
  0.02405282 0.03072798 0.02833927 0.02362598 0.01528964 0.03246476
  0.07518648 0.04623304]
 [0.02830127 0.01677484 0.01464235 0.01402928 0.01210548 0.01485187
  0.01868646 0.01888444 0.0166424  0.01483328 0.01902576 0.01602041
  0.01856165 0.00766128 0.00745418 0.02481697 0.01997907 0.0310271
  0.02737521 0.03364214 0.03226629 0.02081867 0.01326486 0.02741207
  0.06223973 0.04649661]
 [0.02802661 0.01556467 0.01343015 0.01177951 0.01045564 0.01277965
  0.01707129 0.01677331 0.01589642 0.01296829 0.02211348 0.01458411
  0.01750067 0.00678917 0.00713515 0.02469899 0.02622439 0.02973779
  0.03412451 0.03671801 0.03520239 0.02306941 0.01496694 0.0297269
  0.03916696 0.06530315]
 [0.02738361 0.02259876 0.02277958 0.01946133 0.01803074 0.02797594
  0.03304816 0.03163366 0.02927485 0.02794603 0.0422579  0.03934379
  0.0339914  0.01185871 0.01136089 0.02419079 0.03009538 0.02880504
  0.03070152 0.03082734 0.02834205 0.02841665 0.02377095 0.02440005
  0.02612412 0.03828706]
 [0.02854593 0.0207847  0.01845258 0.01637681 0.01383006 0.01791549
  0.02224948 0.02183316 0.02140761 0.01724434 0.02478342 0.01910884
  0.02102265 0.0093509  0.00860081 0.02034835 0.02187302 0.02213987
  0.02936412 0.02888831 0.02696979 0.02578506 0.01684113 0.01955825
  0.02250537 0.03837946]
 [0.02869389 0.02347612 0.02677766 0.02320371 0.01933486 0.03156475
  0.03144717 0.03488335 0.03102829 0.0277279  0.02827832 0.03590841
  0.03229219 0.01508304 0.01072439 0.01766125 0.02089183 0.02013746
  0.02022526 0.01965632 0.01862538 0.02835571 0.01960876 0.0133897
  0.01475512 0.01648923]
 [0.02879918 0.02277279 0.02270779 0.02224329 0.01849659 0.0266525
  0.02711295 0.03028408 0.02698649 0.02569533 0.02734097 0.0346304
  0.03022536 0.01323033 0.0106269  0.01680497 0.02046204 0.01898169
  0.01971181 0.01906599 0.01942224 0.02727344 0.01755044 0.01202759
  0.01254423 0.01389062]
 [0.02862813 0.0219243  0.02074507 0.01733257 0.01488591 0.0214101
  0.02629544 0.02738356 0.02466361 0.02010323 0.02679808 0.02818227
  0.02736202 0.0107116  0.00961927 0.01926708 0.02448769 0.02323946
  0.02396311 0.02302833 0.02386028 0.0245388  0.0200251  0.01568406
  0.01656348 0.01843778]
 [0.02867188 0.02675939 0.02669501 0.0259112  0.02197913 0.03819243
  0.03255199 0.03470234 0.0385982  0.0337606  0.02715966 0.05116244
  0.0439947  0.01919107 0.01245028 0.0168305  0.02030824 0.02030935
  0.02069472 0.02031631 0.01871224 0.02677979 0.02174111 0.01147617
  0.01108935 0.013262  ]
 [0.0281969  0.03740957 0.03228429 0.02513386 0.02068436 0.03312034
  0.03735308 0.0418733  0.03606295 0.03064024 0.03282826 0.04677308
  0.04388339 0.0158173  0.01206033 0.02375511 0.02504657 0.02444871
  0.02415124 0.02495616 0.02452037 0.02881781 0.02603618 0.01679682
  0.01718649 0.01672764]
 [0.02882462 0.02635199 0.02844818 0.02417499 0.01878625 0.03193961
  0.03409344 0.03441314 0.03362194 0.02912773 0.02800263 0.03985862
  0.03567122 0.01466882 0.01075379 0.01900684 0.02005554 0.01904762
  0.02085019 0.02164358 0.02097315 0.02721168 0.01896146 0.01254179
  0.01255232 0.01167809]
 [0.02798278 0.01938045 0.01810946 0.0146856  0.01217756 0.01629805
  0.02387789 0.02382325 0.02161998 0.01748559 0.02898557 0.02128113
  0.02630614 0.00930586 0.00798442 0.0258791  0.0317855  0.02805023
  0.0278978  0.02775148 0.03330403 0.02510842 0.01560032 0.02712923
  0.02666319 0.02105867]
 [0.02811095 0.02201332 0.01954957 0.01644042 0.01279558 0.01591843
  0.02556772 0.0258112  0.02188147 0.01766328 0.02734416 0.0205931
  0.02567302 0.00933384 0.0079607  0.0289416  0.0327641  0.03099582
  0.02831632 0.02905488 0.03684694 0.02437447 0.01546112 0.02954702
  0.02984602 0.01902185]
 [0.02829835 0.02198926 0.01945606 0.01623251 0.0136819  0.01624287
  0.02270218 0.02439628 0.02153503 0.01857339 0.02750215 0.02268918
  0.02486426 0.00975215 0.00830732 0.02989212 0.03953064 0.032235
  0.03235161 0.02959602 0.03491808 0.02344316 0.01508337 0.02151705
  0.02209121 0.01623061]
 [0.02836842 0.01730254 0.01615676 0.01220619 0.01109368 0.01335812
  0.01898606 0.01829748 0.0190635  0.01432334 0.02763151 0.01720089
  0.0189742  0.0082263  0.00700542 0.02644399 0.03931646 0.02836272
  0.03179418 0.02825121 0.03337487 0.02252209 0.01429623 0.02124662
  0.0198252  0.01904412]
 [0.02772732 0.02040857 0.01896184 0.01514176 0.01452417 0.01631708
  0.02299233 0.02224874 0.02353138 0.01872796 0.03987106 0.02266999
  0.02181303 0.0100756  0.00917748 0.02622539 0.04143379 0.02959181
  0.03183947 0.02852836 0.03023733 0.02538935 0.01923987 0.02267075
  0.01787424 0.0248147 ]
 [0.02857874 0.02148883 0.02072336 0.01757152 0.01426788 0.01976507
  0.02517645 0.02496182 0.02493572 0.02012201 0.03134483 0.02265774
  0.02574757 0.01227906 0.00966183 0.01994179 0.03054989 0.02827223
  0.02795573 0.02660052 0.02516969 0.02570513 0.01786745 0.01439949
  0.01506865 0.01804015]
 [0.02743334 0.02997529 0.02962615 0.05261059 0.05549778 0.04062334
  0.02462451 0.02507214 0.03104554 0.05187171 0.03150707 0.03199498
  0.03354005 0.08436687 0.09885429 0.02476028 0.02660933 0.02507773
  0.02310344 0.02248427 0.02115119 0.03223405 0.0347883  0.00800423
  0.00815835 0.01778276]
 [0.02726806 0.03220879 0.02965119 0.05595267 0.11073795 0.03889649
  0.02163422 0.02306813 0.02851427 0.05389128 0.03454601 0.02849831
  0.02520533 0.08546621 0.10617925 0.03031222 0.03550901 0.03655332
  0.02983968 0.0261568  0.02477942 0.02948323 0.0357602  0.00707058
  0.0061816  0.01543741]
 [0.02699736 0.02724137 0.02599207 0.04393422 0.07190672 0.02977129
  0.01890667 0.02372578 0.02773379 0.05249867 0.03707599 0.03662576
  0.03228402 0.0354724  0.03815342 0.02588191 0.04761501 0.07113586
  0.06754352 0.03958394 0.03291653 0.02564501 0.02878546 0.01218576
  0.01086381 0.01723664]
 [0.0273126  0.03313907 0.02931392 0.04545786 0.06346799 0.03366456
  0.02343085 0.02397427 0.03045089 0.04572633 0.03248364 0.02810286
  0.02884986 0.03511823 0.03600741 0.02092193 0.03292739 0.04171021
  0.04124268 0.03296218 0.02740781 0.04654048 0.04326076 0.00909559
  0.00815355 0.01529304]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Mary', ' being', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' sentence', ' ', '5', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Mary', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(43, 32), x_tokens=32, y_tokens=43, max_supp_attn=0.0698, attn_on_target=0.0233)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (43, 32)
DEBUG result.interpretability.attn_scores 1376 
 [[0.0215147  0.03413242 0.03552509 ... 0.00945018 0.00757361 0.01343986]
 [0.02207451 0.0369329  0.03465013 ... 0.01256472 0.00996103 0.01787563]
 [0.02255038 0.0323878  0.03499327 ... 0.01543626 0.00970024 0.02175451]
 ...
 [0.02267984 0.02988867 0.02631415 ... 0.00511136 0.00573239 0.0070194 ]
 [0.02307418 0.02202538 0.01857945 ... 0.00606388 0.00787302 0.00955291]
 [0.02293023 0.02402491 0.0189848  ... 0.00505191 0.00705202 0.00823462]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' is', ' indeed', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 38), x_tokens=38, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 38)
DEBUG result.interpretability.attn_scores 1102 
 [[0.03229024 0.0483952  0.04807266 ... 0.0341251  0.02101267 0.0403739 ]
 [0.03270738 0.04433502 0.04106416 ... 0.03709967 0.03989046 0.03780027]
 [0.03357982 0.05067929 0.05305173 ... 0.03130292 0.01776287 0.03198971]
 ...
 [0.03386644 0.04709236 0.04053589 ... 0.02836676 0.01643021 0.03419284]
 [0.03391756 0.04077732 0.03278224 ... 0.03359858 0.02442029 0.03251383]
 [0.03405972 0.04580048 0.03515093 ... 0.03214908 0.02127569 0.03436634]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Fred', ' and', ' Bill', ',', ' but', ' not', ' Mary', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 44), x_tokens=44, y_tokens=32, max_supp_attn=0.0625, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 44)
DEBUG result.interpretability.attn_scores 1408 
 [[0.02902205 0.03302913 0.03680432 ... 0.01556643 0.02026641 0.01003642]
 [0.029679   0.02719142 0.03377943 ... 0.03297431 0.02581153 0.02751453]
 [0.03035817 0.03062743 0.03579751 ... 0.02521494 0.03215938 0.02022303]
 ...
 [0.03074465 0.03721804 0.0312111  ... 0.01326844 0.01454536 0.01173068]
 [0.03130262 0.03974903 0.03451855 ... 0.01392465 0.01421754 0.01018286]
 [0.03147244 0.03418055 0.03110551 ... 0.01308404 0.01636233 0.01099545]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', "'s", ' movements', ',', ' but', ' not', ' Bill', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 50), x_tokens=50, y_tokens=37, max_supp_attn=0.0, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 50)
DEBUG result.interpretability.attn_scores 1850 
 [[0.02515791 0.03398183 0.02999933 ... 0.0423319  0.0351065  0.01771952]
 [0.02556788 0.0333748  0.03209871 ... 0.0241978  0.03704138 0.02499184]
 [0.02626199 0.03520465 0.03536794 ... 0.03891632 0.03013959 0.0140777 ]
 ...
 [0.02690442 0.02721171 0.02211293 ... 0.03691503 0.02824698 0.02902627]
 [0.02714845 0.03094665 0.02476682 ... 0.04236419 0.02649463 0.0150439 ]
 [0.02691277 0.02945267 0.0226689  ... 0.06801902 0.02555121 0.01156204]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' that', ' Bill', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Bill', ' has', ' moved', ' or', ' changed', ' locations', '.', ' Sentence', ' ', '2', ' mentions', ' Fred', ' going', ' back', ' to', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' any', ' information', ' about', ' Bill', "'s", ' current', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(66, 26), x_tokens=26, y_tokens=66, max_supp_attn=0.0303, attn_on_target=0.0152)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (66, 26)
DEBUG result.interpretability.attn_scores 1716 
 [[0.01376077 0.02701144 0.0294397  ... 0.00695552 0.0078158  0.0134595 ]
 [0.01361506 0.04669816 0.03267077 ... 0.02136655 0.01795176 0.02012339]
 [0.01496399 0.03866981 0.02213791 ... 0.00233725 0.00305979 0.00721421]
 ...
 [0.01476689 0.01703849 0.016995   ... 0.00285803 0.00348102 0.00902692]
 [0.01479346 0.01306759 0.01271512 ... 0.01079007 0.00750096 0.01061145]
 [0.01495454 0.01426528 0.01338992 ... 0.00700049 0.00567822 0.0087622 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '4', ' states', ' that', ' Bill', ' went', ' back', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.', ' Sentence', ' ', '5', ' provides', ' alternative', ' locations', ' for', ' Bill', ',', ' but', ' it', ' does', ' not', ' update', ' Bill', "'s", ' current', ' location', '.', ' Since', ' Bill', ' is', ' in', ' the', ' kitchen', ',', ' the', ' alternatives', ' in', ' sentence', ' ', '5', ' do', ' not', ' apply', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(64, 32), x_tokens=32, y_tokens=64, max_supp_attn=0.1406, attn_on_target=0.0156)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (64, 32)
DEBUG result.interpretability.attn_scores 2048 
 [[0.01419314 0.0235134  0.024648   ... 0.02906597 0.00619036 0.00885774]
 [0.01465562 0.02311696 0.02334737 ... 0.03934255 0.00728469 0.01282636]
 [0.01493457 0.02179777 0.02372758 ... 0.04994128 0.00716013 0.01735048]
 ...
 [0.01503794 0.02114681 0.02200559 ... 0.01141554 0.00850803 0.0055087 ]
 [0.01535598 0.01461995 0.01462696 ... 0.00677128 0.01071944 0.00613351]
 [0.01528563 0.01496908 0.01567311 ... 0.00655702 0.00916048 0.00667578]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' went', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Fred', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.0334236  0.05059356 0.05237352 ... 0.0204407  0.05380566 0.06877925]
 [0.03363642 0.04950805 0.05150404 ... 0.03680713 0.03506036 0.03557158]
 [0.03486615 0.05365802 0.06199981 ... 0.02966684 0.05659687 0.05245224]
 ...
 [0.03514048 0.05563463 0.04839992 ... 0.0210917  0.08106551 0.10637964]
 [0.03513771 0.04589967 0.03669389 ... 0.01831205 0.04527053 0.09832267]
 [0.03531968 0.05118145 0.03959149 ... 0.017075   0.02784247 0.16180588]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' park', ',', ' but', ' sentence', ' ', '11', ' updates', ' Bill', "'s", ' location', ' to', ' the', ' bedroom', '.', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.0244, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02256142 0.03773303 0.03657785 ... 0.01126505 0.0242621  0.02833615]
 [0.02327105 0.02570292 0.02400371 ... 0.01760832 0.02235596 0.02367067]
 [0.02354872 0.03721341 0.03784732 ... 0.01032118 0.01904251 0.02483119]
 ...
 [0.02373022 0.03125756 0.03369512 ... 0.01197651 0.02505404 0.03494623]
 [0.02428681 0.02485608 0.02568457 ... 0.01818006 0.02519117 0.0376164 ]
 [0.02421207 0.02636889 0.02735221 ... 0.01294746 0.02229083 0.02803968]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' provide', ' information', ' about', ' Fred', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03007904 0.03333158 0.03205014 ... 0.01771804 0.02206733 0.01172903]
 [0.03077519 0.02379166 0.02301547 ... 0.03038017 0.03538316 0.02269439]
 [0.03141772 0.0316891  0.03432157 ... 0.02486974 0.02815947 0.01701223]
 ...
 [0.03208766 0.03380408 0.02772127 ... 0.02123791 0.01833547 0.01482839]
 [0.03246432 0.03693905 0.03240896 ... 0.0196168  0.0167429  0.01458276]
 [0.03260165 0.03143785 0.02862819 ... 0.02008925 0.01754109 0.01213841]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.0373102  0.05827586 0.07151993 0.08800513 0.09307948 0.0900999
  0.07852791 0.0922046  0.07123909 0.0788065  0.06202024 0.07540624
  0.08854698 0.09723938 0.05870711 0.0402735  0.03838108 0.04332097
  0.03883961 0.04206569 0.03544033 0.04999756 0.04392146 0.02374483
  0.02946537 0.04218338]
 [0.03788204 0.07139346 0.06090093 0.0774186  0.06467278 0.06706651
  0.06386299 0.06364437 0.05647781 0.05766042 0.04941813 0.04271964
  0.05143884 0.11071786 0.10529074 0.04309791 0.03568102 0.034505
  0.03356322 0.03504281 0.02945412 0.05038567 0.04810928 0.01770571
  0.01960218 0.03829186]
 [0.04086627 0.06770182 0.04104866 0.06010315 0.04300603 0.04159399
  0.03952467 0.02901864 0.02792465 0.04015986 0.03556122 0.02028032
  0.0249172  0.03004882 0.03697651 0.02911947 0.01741998 0.01842615
  0.0228353  0.02349897 0.02133625 0.0560273  0.05423791 0.00942673
  0.00984447 0.02033719]
 [0.03837294 0.04120262 0.04936295 0.02967315 0.02007047 0.03507635
  0.03899828 0.03474808 0.04362871 0.03212148 0.03296596 0.03375926
  0.03321319 0.01466623 0.01376706 0.04469783 0.03940381 0.042422
  0.04469863 0.04719062 0.04639328 0.04249464 0.06749645 0.07365459
  0.08734046 0.06461192]
 [0.03886213 0.04864722 0.05115298 0.07498888 0.06508616 0.05490661
  0.04294195 0.03774472 0.04204144 0.05326588 0.04350178 0.03118016
  0.03397926 0.10087688 0.10110002 0.04540394 0.03325224 0.02833273
  0.02906761 0.03137714 0.02938679 0.04948169 0.06362841 0.01648046
  0.01505805 0.04404345]
 [0.03958622 0.03144064 0.0314789  0.05778735 0.04903999 0.05013977
  0.03221327 0.02965983 0.03587699 0.04979917 0.03846905 0.03562958
  0.03696816 0.11254171 0.13162063 0.04550217 0.03810299 0.03476937
  0.03321295 0.03403214 0.02864054 0.04234251 0.03829347 0.01180529
  0.01210463 0.02858885]
 [0.04016458 0.03505583 0.04057198 0.06040433 0.05315768 0.06301247
  0.04171946 0.04017829 0.04691688 0.0584904  0.04493541 0.0561097
  0.05558145 0.09053697 0.08333406 0.03831531 0.0346839  0.0340756
  0.03171628 0.0332195  0.02684026 0.0380259  0.03615943 0.01592495
  0.01656922 0.0272573 ]
 [0.03883756 0.05092549 0.06036546 0.05086491 0.04914209 0.06109682
  0.04955355 0.05527795 0.05391758 0.0547116  0.0478177  0.06451248
  0.05845497 0.05655057 0.04918497 0.05171716 0.04543894 0.04358643
  0.03882008 0.04104436 0.03646988 0.04344318 0.05293539 0.03854057
  0.03860466 0.04591262]
 [0.03920595 0.06053368 0.06997863 0.0398118  0.0308833  0.05009522
  0.05857792 0.06207014 0.06049215 0.04344438 0.04240777 0.05423557
  0.05626445 0.02654548 0.01884013 0.05096732 0.04145527 0.04085153
  0.03879426 0.04055464 0.03816655 0.0392091  0.06281231 0.04601075
  0.05279251 0.05636482]
 [0.04019061 0.07852605 0.08522332 0.03447017 0.02378349 0.04431042
  0.05803542 0.0539543  0.06319088 0.03531658 0.034081   0.04359631
  0.04325514 0.01736097 0.01427337 0.05791903 0.04149288 0.03837447
  0.03913267 0.04355466 0.03710597 0.03808209 0.07063979 0.03537064
  0.03940171 0.04506941]
 [0.04021379 0.04595205 0.05234242 0.02722003 0.02056978 0.03223184
  0.04758171 0.04519726 0.04864265 0.03003976 0.03065472 0.03654879
  0.03463303 0.01515798 0.01364481 0.05484265 0.04333227 0.03780827
  0.04124965 0.04352191 0.039816   0.03780989 0.05789855 0.05540485
  0.05899879 0.04742616]
 [0.04044563 0.02598631 0.02952786 0.01809259 0.01518951 0.02280397
  0.03003955 0.03126354 0.0418266  0.02280775 0.02207549 0.02391689
  0.02420344 0.01042976 0.01043897 0.03798329 0.03638084 0.03278795
  0.03974041 0.04521194 0.04269785 0.03345178 0.05414284 0.07986984
  0.09115984 0.05378361]
 [0.04036684 0.03431448 0.03629182 0.02349352 0.01892992 0.03148785
  0.03690629 0.03636211 0.03595156 0.02730182 0.03066073 0.03707676
  0.03354085 0.01228475 0.01207213 0.0494034  0.03707986 0.03576279
  0.03534807 0.03743658 0.03752565 0.03671252 0.03765085 0.06231432
  0.0709571  0.05244145]
 [0.04105921 0.04439202 0.0474689  0.03981804 0.02848142 0.05180594
  0.05148699 0.05769088 0.04814196 0.05130563 0.05145286 0.08019144
  0.06410664 0.02143152 0.01496824 0.0374003  0.03733595 0.04181455
  0.03802534 0.03877093 0.03411001 0.04011571 0.02606768 0.02738721
  0.02820897 0.02718602]
 [0.04153594 0.03246022 0.03311155 0.0257469  0.02106161 0.03058906
  0.0386589  0.03770639 0.03196207 0.03069936 0.0384976  0.03985566
  0.03886487 0.01308796 0.01176327 0.03787665 0.03379562 0.03344046
  0.03315922 0.03480062 0.03454719 0.03740839 0.0238145  0.04357805
  0.03794371 0.02596973]
 [0.04079614 0.02478451 0.02171377 0.01670841 0.01414857 0.0190395
  0.02734809 0.02632711 0.02408607 0.02003101 0.0317322  0.02629848
  0.02930902 0.00803091 0.00879932 0.03897802 0.03818782 0.03783922
  0.03594604 0.03760032 0.04666345 0.03386009 0.0219916  0.07601164
  0.06474572 0.03464451]
 [0.04039162 0.02346004 0.01928424 0.01580487 0.01253362 0.01765178
  0.02996399 0.03133724 0.02309003 0.0187506  0.03047138 0.0232499
  0.03076885 0.00719475 0.00753311 0.03714195 0.04185539 0.05197247
  0.04388715 0.04486921 0.06624357 0.03140894 0.0200977  0.08325487
  0.06565081 0.04470694]
 [0.04116694 0.02268224 0.01940725 0.01543503 0.01330063 0.01870761
  0.02683407 0.0274621  0.02323562 0.01959577 0.03733898 0.02936225
  0.03027198 0.00744213 0.00734497 0.0348329  0.04115557 0.04098344
  0.0428168  0.039988   0.05197467 0.02995859 0.01697967 0.07212079
  0.04956688 0.02894903]
 [0.04095991 0.02055864 0.01747612 0.01271974 0.01168941 0.01599229
  0.02702853 0.02587754 0.02257514 0.01698435 0.05185109 0.0286831
  0.02859833 0.00635441 0.00674156 0.03647587 0.04485275 0.04498591
  0.05233342 0.04648231 0.05700129 0.02950726 0.01697597 0.07162536
  0.04618642 0.03896673]
 [0.03969275 0.02695966 0.02380229 0.01946272 0.02153476 0.0240625
  0.03356705 0.03192979 0.03615219 0.02532638 0.03435601 0.02700118
  0.03148416 0.01448175 0.01983802 0.03273511 0.04403249 0.04821971
  0.07567738 0.07415266 0.06292062 0.03874372 0.03857064 0.0529944
  0.06078343 0.07883734]
 [0.04164347 0.02465117 0.02451957 0.02149138 0.01584695 0.02374843
  0.027005   0.03118247 0.0300055  0.02513407 0.03090268 0.03176967
  0.03127033 0.01121739 0.00964786 0.02497906 0.02680298 0.03119466
  0.039402   0.03677168 0.03734554 0.03250983 0.01737228 0.02873929
  0.03704373 0.0358517 ]
 [0.04052572 0.03101397 0.02932977 0.04743647 0.04464588 0.04510564
  0.03135245 0.03127828 0.03530529 0.05154686 0.0404572  0.04002051
  0.0400555  0.07316882 0.08395004 0.03086136 0.03426336 0.0349116
  0.03268894 0.03174805 0.02912274 0.03891056 0.03174136 0.01242051
  0.01599163 0.03070522]
 [0.04020005 0.03255533 0.02852204 0.05193074 0.09305832 0.04261419
  0.02962462 0.02926185 0.03359551 0.05730616 0.0459092  0.03827174
  0.03363315 0.073412   0.09412849 0.0375833  0.04751841 0.04837551
  0.03842166 0.03514944 0.03524273 0.03629565 0.03070428 0.0104076
  0.01121103 0.02606755]
 [0.03961056 0.03074996 0.02652668 0.04605853 0.10661668 0.03119828
  0.02588779 0.02809886 0.029535   0.0523313  0.04726919 0.04250845
  0.03277016 0.03568207 0.04770461 0.03321851 0.07806178 0.07126991
  0.05627571 0.0422104  0.05400621 0.03404207 0.02899002 0.01918796
  0.02155695 0.03152037]
 [0.04011294 0.03577673 0.02907199 0.04505357 0.07047141 0.03556306
  0.0327595  0.03052359 0.03418852 0.04706291 0.04519238 0.03781593
  0.03387004 0.03353898 0.03833006 0.02867408 0.05003281 0.04996933
  0.04434766 0.03970544 0.04154852 0.05977536 0.03876818 0.01601877
  0.01921174 0.03028286]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' explicitly', ' states', ' that', ' Bill', ' travelled', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Bill', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.1333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03127972 0.04696045 0.04684323 0.0641015  0.05460944 0.04798942
  0.03840679 0.0396681  0.05070228 0.05196018 0.0329324  0.02927107
  0.03597414 0.1009941  0.10203181 0.02607877 0.026121   0.02233484
  0.02021792 0.02240453 0.02026234 0.03278268 0.05771109 0.02282462
  0.01723644 0.04208054 0.04651163 0.04397042 0.11244635 0.05492401
  0.01010353 0.06668465]
 [0.03189616 0.04946072 0.04627063 0.07998417 0.08006449 0.08535375
  0.04839167 0.04945127 0.05595097 0.07287182 0.05102025 0.05398862
  0.05895598 0.14831081 0.11799739 0.03009842 0.02796474 0.0278413
  0.02300151 0.02545007 0.02258085 0.03775379 0.04765167 0.02216318
  0.01657082 0.03854851 0.04922184 0.03920573 0.09252182 0.06450943
  0.01743292 0.07352316]
 [0.03258476 0.04293046 0.04683124 0.0641822  0.0572147  0.05940115
  0.04120686 0.04390877 0.05080107 0.05679322 0.0367474  0.04375446
  0.04655246 0.10808446 0.07804323 0.02506078 0.0260324  0.02240806
  0.02032179 0.02151783 0.01911828 0.03294585 0.04177551 0.02335595
  0.01771696 0.0329555  0.04552609 0.03251239 0.06239571 0.06585009
  0.02716336 0.05998909]
 [0.03140763 0.04255864 0.04588713 0.03751688 0.0309486  0.03743951
  0.03837154 0.04497353 0.04315821 0.0356019  0.03063276 0.03672744
  0.03945861 0.03120865 0.02790043 0.02973495 0.03046538 0.02613083
  0.02584126 0.02734401 0.02530867 0.03700412 0.05145095 0.04288819
  0.04118742 0.04548525 0.05497077 0.03859011 0.04562376 0.09213512
  0.0516366  0.03842682]
 [0.03206364 0.04475589 0.04522266 0.0255414  0.02006412 0.02913006
  0.03510572 0.03813329 0.03825845 0.02371247 0.02718493 0.02682674
  0.02994187 0.02084342 0.01905829 0.02838031 0.02729485 0.021955
  0.02485935 0.02624952 0.02442193 0.03461937 0.05111311 0.03991523
  0.03705676 0.04222802 0.05688709 0.02859452 0.03025871 0.08644006
  0.0477003  0.02045269]
 [0.03262808 0.05915875 0.05672108 0.02802349 0.02191131 0.03189674
  0.04279895 0.04087184 0.0508326  0.02606259 0.02754888 0.02896595
  0.03222025 0.01966419 0.01866067 0.03611962 0.03549036 0.0284944
  0.02900175 0.03210346 0.02784467 0.03190494 0.06667947 0.04327305
  0.03785297 0.04121707 0.04700439 0.02907363 0.02895609 0.07609613
  0.03855387 0.01816896]
 [0.03273511 0.03969973 0.04204811 0.02425212 0.01933915 0.02505588
  0.03468079 0.03170996 0.03889116 0.02151325 0.02424597 0.02164213
  0.02238058 0.01814722 0.01873179 0.03031302 0.02955451 0.02127153
  0.02451052 0.0247101  0.02278419 0.03065547 0.04711629 0.04123343
  0.03546307 0.03555221 0.04607362 0.0257804  0.02775293 0.07246818
  0.03637687 0.02142451]
 [0.03312502 0.02392817 0.02622864 0.01767191 0.01423457 0.01794653
  0.02143751 0.02175104 0.0274689  0.0161953  0.01986089 0.01587812
  0.01704414 0.01170584 0.01423234 0.02290454 0.02396348 0.0182745
  0.02338052 0.0243183  0.0233502  0.02530354 0.03294282 0.04412848
  0.04264672 0.03420218 0.03071574 0.02512227 0.02163825 0.03934992
  0.02020983 0.01768593]
 [0.03273407 0.02971918 0.03165093 0.02501584 0.01916867 0.02587474
  0.02707662 0.02677239 0.02770643 0.02165812 0.02632015 0.02575881
  0.02374368 0.01731265 0.01666945 0.03109182 0.03138584 0.0295726
  0.03174675 0.03695173 0.0320247  0.03575632 0.03228838 0.0433494
  0.04506705 0.03454378 0.03873688 0.02779343 0.02635506 0.06094559
  0.08848511 0.01823755]
 [0.03349439 0.03680423 0.03947545 0.03906007 0.02900045 0.04194594
  0.03824165 0.04554985 0.04422182 0.04175688 0.03619504 0.05392109
  0.04862031 0.03167895 0.02366156 0.02533931 0.02820854 0.02736442
  0.02742607 0.02811729 0.02356087 0.03447794 0.02784665 0.02587782
  0.02774059 0.02868732 0.04062581 0.03012844 0.0306029  0.05396049
  0.10534646 0.03216703]
 [0.03362873 0.03000902 0.03192525 0.0299702  0.02351518 0.02990597
  0.03089912 0.03059819 0.0306219  0.02854953 0.03015609 0.03257658
  0.03088748 0.02147857 0.01953014 0.03065905 0.03052464 0.02928504
  0.032257   0.03203446 0.02777759 0.03375024 0.02628208 0.03132746
  0.03688687 0.02632255 0.03534227 0.02818754 0.02634723 0.03178097
  0.07661259 0.02840597]
 [0.03316858 0.02442441 0.02184632 0.01919344 0.01570934 0.01896004
  0.02269189 0.02078028 0.02226646 0.01788747 0.02586602 0.02007233
  0.02187744 0.01140267 0.01329227 0.03839703 0.03194398 0.03465516
  0.0372241  0.04130907 0.03739437 0.032862   0.02152005 0.03834305
  0.04820371 0.02602507 0.0213395  0.02412027 0.0185773  0.0159428
  0.04456482 0.01579358]
 [0.03277265 0.02599659 0.02126974 0.02011267 0.01549747 0.01912113
  0.02378482 0.02136886 0.02212562 0.01831604 0.02535875 0.01930285
  0.02203623 0.0113531  0.01350873 0.05499692 0.03301737 0.04823706
  0.0438862  0.05521544 0.0625542  0.03256121 0.02150897 0.04714818
  0.06596884 0.03935147 0.01893042 0.02865698 0.01662186 0.01248821
  0.03377665 0.01236856]
 [0.03391818 0.02570089 0.02380378 0.02264004 0.01805804 0.02307584
  0.02572576 0.02443441 0.02460388 0.02208469 0.03264092 0.02574714
  0.02578655 0.01359514 0.01538004 0.04595706 0.0351224  0.05657384
  0.04349947 0.06990699 0.04405119 0.02980832 0.02074745 0.03458167
  0.03881907 0.02780495 0.01977908 0.02475006 0.01737896 0.0125768
  0.02732864 0.01298532]
 [0.03399802 0.02181729 0.02080368 0.01841004 0.01441167 0.01968225
  0.02330423 0.02083137 0.02162115 0.01798204 0.03330117 0.0222899
  0.02234133 0.0107341  0.0129777  0.04607107 0.03780533 0.04555556
  0.0469351  0.05334767 0.04336413 0.03125082 0.01874351 0.03486915
  0.0399183  0.03090587 0.01858823 0.02298367 0.0157011  0.01010304
  0.02412954 0.01205615]
 [0.03295847 0.03238778 0.03047113 0.03081265 0.02689837 0.03283508
  0.03629329 0.03547649 0.03410491 0.03443087 0.03944318 0.03949939
  0.03651296 0.01988321 0.02107079 0.03531936 0.04279533 0.04266272
  0.04801597 0.04119328 0.04415967 0.03663525 0.03176778 0.03829008
  0.04365212 0.04683907 0.02931957 0.04266253 0.03113999 0.01720752
  0.02606587 0.02672919]
 [0.03414676 0.02543154 0.02635115 0.02529929 0.01896012 0.0267379
  0.02769268 0.02900206 0.02706952 0.02587949 0.03112554 0.03208555
  0.02781515 0.01704637 0.01676237 0.03134844 0.03149983 0.0300727
  0.036584   0.03106131 0.03472473 0.03414873 0.02231941 0.02737832
  0.02954221 0.02936549 0.02446035 0.03046459 0.02528632 0.01985931
  0.03006579 0.03155546]
 [0.03429453 0.03266152 0.03726898 0.03629256 0.02731051 0.03942223
  0.03763673 0.04413971 0.0363057  0.04053755 0.04127098 0.05192111
  0.04585485 0.02744618 0.02050758 0.02959591 0.03066064 0.03202726
  0.03035916 0.02998031 0.02755014 0.0371207  0.02694298 0.02730197
  0.02742489 0.0297613  0.02967546 0.03195858 0.02788132 0.02517132
  0.0338624  0.02351053]
 [0.034567   0.03851109 0.04069787 0.04147131 0.02979991 0.04363468
  0.0454246  0.05503668 0.03513699 0.04628609 0.04784779 0.05849295
  0.05483099 0.02873146 0.02093012 0.03277282 0.03163302 0.03477424
  0.03039636 0.0307401  0.02699671 0.03616198 0.02926631 0.02693503
  0.02362641 0.02702845 0.03107163 0.02667293 0.02635928 0.02303505
  0.03499239 0.01704266]
 [0.03452556 0.03380626 0.0345818  0.03530838 0.02717479 0.0374677
  0.03886883 0.04252519 0.03275542 0.03969449 0.04009217 0.04567691
  0.04695925 0.02534939 0.0212831  0.03704105 0.03259919 0.03539638
  0.03217489 0.03155304 0.03008038 0.03591304 0.02640023 0.02990409
  0.02905028 0.02562926 0.02628085 0.03012457 0.02475406 0.01980869
  0.03666041 0.01916845]
 [0.03454902 0.02582825 0.02522993 0.02117558 0.01702355 0.02401015
  0.02985628 0.02886718 0.02463541 0.02425372 0.02866326 0.02773378
  0.03149945 0.01342223 0.01493778 0.04042719 0.03253937 0.03312629
  0.0333491  0.03099152 0.03508425 0.03381188 0.02162712 0.03494161
  0.0375322  0.0248805  0.02291362 0.03055732 0.01919335 0.01341799
  0.0303597  0.01425371]
 [0.03443083 0.02775029 0.02565471 0.02124447 0.01707321 0.02373093
  0.03232606 0.02923504 0.02374416 0.02332212 0.02943786 0.02603892
  0.03103556 0.01301763 0.01545271 0.04975183 0.0357556  0.04005148
  0.04069974 0.03690097 0.04440913 0.03137505 0.02091083 0.03994016
  0.0400248  0.02624062 0.0240634  0.0305058  0.01735967 0.01097966
  0.02909486 0.01208007]
 [0.0346175  0.02574334 0.02424987 0.01993945 0.01797032 0.02363696
  0.02917714 0.02798021 0.02342045 0.02343279 0.03056996 0.02788301
  0.02967425 0.01355364 0.01522276 0.03961307 0.03877827 0.03493736
  0.04185149 0.03359688 0.04139098 0.03086643 0.02061269 0.03984667
  0.04163371 0.02755032 0.02877205 0.03481005 0.01736811 0.01235322
  0.03059414 0.01519642]
 [0.0347655  0.02261655 0.02222716 0.0152213  0.01569113 0.0209629
  0.02989154 0.02329811 0.02253762 0.01868225 0.03691649 0.02366796
  0.02688738 0.01111795 0.01260344 0.04042093 0.03968519 0.03225647
  0.04461474 0.03522196 0.03866054 0.03041012 0.01898996 0.03554227
  0.03675881 0.03018862 0.02362539 0.02701616 0.0142514  0.00937449
  0.02195669 0.01218008]
 [0.03323274 0.02682513 0.02717275 0.01656175 0.01712286 0.0241068
  0.03520963 0.0273201  0.02857876 0.02154142 0.02629116 0.02300269
  0.02889992 0.0119894  0.01427594 0.02795514 0.02959007 0.02538723
  0.03414221 0.03009134 0.03179987 0.0342818  0.029198   0.04216677
  0.03859086 0.04937653 0.02803291 0.03533294 0.02013309 0.01325641
  0.01875966 0.01620629]
 [0.0345939  0.02825532 0.02996379 0.02533472 0.02315931 0.03109667
  0.03470677 0.0350003  0.03056935 0.02981111 0.03569904 0.03689167
  0.03390094 0.01918005 0.01837414 0.02997235 0.03273915 0.02992922
  0.03512412 0.0288763  0.03481907 0.03363437 0.02399937 0.02645278
  0.02329677 0.02805327 0.02216078 0.03232177 0.02322298 0.01645746
  0.02018079 0.03212034]
 [0.0330697  0.03369207 0.03394129 0.05131702 0.05601303 0.04504688
  0.03331879 0.03115816 0.03551325 0.05030423 0.03636574 0.03736353
  0.03552096 0.06943157 0.0943867  0.02278249 0.02757703 0.02724832
  0.02442068 0.02370602 0.02396546 0.03284551 0.03927127 0.02067203
  0.01727828 0.03316223 0.03307007 0.04609098 0.05403747 0.02445754
  0.01010941 0.0930386 ]
 [0.03272333 0.03811438 0.03672302 0.06455029 0.15276341 0.05161524
  0.03564198 0.03345118 0.03624264 0.06738084 0.04844363 0.04869814
  0.03417748 0.0908744  0.12033847 0.03162429 0.04696701 0.04572584
  0.03289149 0.02891913 0.03489401 0.03058548 0.04638247 0.02220993
  0.0154792  0.0332845  0.04369191 0.04618436 0.05201993 0.02123709
  0.00783767 0.0916166 ]
 [0.03302763 0.0306414  0.02823936 0.04006393 0.06859408 0.02890185
  0.02765371 0.02694815 0.02587769 0.04092186 0.03418044 0.03284169
  0.0281131  0.02999944 0.0443202  0.02764487 0.05332104 0.0575163
  0.0470853  0.03563517 0.05999409 0.02957945 0.03596674 0.02921851
  0.02542929 0.03018484 0.03457574 0.05001143 0.03527149 0.01310033
  0.01159313 0.06776599]
 [0.03306283 0.03381065 0.03039923 0.03973128 0.05069824 0.03401505
  0.03417793 0.02975823 0.03427727 0.04057578 0.03364097 0.03147947
  0.03049675 0.0324432  0.03785808 0.02252766 0.03896451 0.038934
  0.03418152 0.03055214 0.03507272 0.03919367 0.04096692 0.02392078
  0.02234461 0.03254457 0.02803291 0.05581611 0.03854342 0.01071304
  0.00844589 0.07916561]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' explicitly', ' states', ' that', ' Fred', ' went', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03143061 0.04128136 0.04302783 ... 0.01612665 0.0325923  0.0294973 ]
 [0.03166912 0.09692841 0.07393314 ... 0.04290155 0.04729541 0.04664963]
 [0.03273749 0.04229144 0.04828354 ... 0.0145773  0.02337085 0.02475077]
 ...
 [0.0328722  0.04410245 0.04377189 ... 0.01414211 0.02530997 0.02926249]
 [0.03321345 0.03139441 0.03031732 ... 0.02424019 0.02850805 0.04073287]
 [0.03299379 0.03522712 0.03327306 ... 0.02187868 0.03254217 0.03057817]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Julie', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', ' for', ' Julie', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' office', ',', ' but', ' it', "'s", ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 44), x_tokens=44, y_tokens=55, max_supp_attn=0.0364, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 44)
DEBUG result.interpretability.attn_scores 2420 
 [[0.01652094 0.02513082 0.0267201  ... 0.00763634 0.03103142 0.03274747]
 [0.01684389 0.02282453 0.02586545 ... 0.01370246 0.01745988 0.02015096]
 [0.01732436 0.02523316 0.02985052 ... 0.0147123  0.03087812 0.02827816]
 ...
 [0.0174523  0.02661842 0.02278734 ... 0.00628517 0.05078584 0.0315477 ]
 [0.01777306 0.02253861 0.01785683 ... 0.0078521  0.02829705 0.02177054]
 [0.01789676 0.02232339 0.01790716 ... 0.00725205 0.02794863 0.04573451]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' previously', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', ' or', ' changed', ' locations', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.1429, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02629585 0.04109471 0.03681356 ... 0.02881264 0.03681415 0.04266305]
 [0.02679947 0.03756298 0.03583363 ... 0.02813778 0.02992183 0.02384943]
 [0.02753209 0.04106769 0.04106094 ... 0.02294952 0.03221448 0.02849977]
 ...
 [0.02775177 0.03517129 0.0293699  ... 0.02641839 0.0406592  0.03311755]
 [0.0283101  0.0270831  0.02138068 ... 0.02863855 0.04729997 0.02872896]
 [0.02813854 0.03159635 0.02388167 ... 0.02677086 0.03487846 0.03987102]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' moved', ' to', ' the', ' school', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' cinema', '.', ' Mary', ' is', ' in', ' the', ' cinema', ' (', 'sentence', ' ', '1', '),', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 26), x_tokens=26, y_tokens=54, max_supp_attn=0.1667, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 26)
DEBUG result.interpretability.attn_scores 1404 
 [[0.01694379 0.03068316 0.03564719 ... 0.01256972 0.01048542 0.01794685]
 [0.01671196 0.05455605 0.04562657 ... 0.018659   0.01656724 0.02184164]
 [0.01839622 0.04152149 0.0258384  ... 0.00547414 0.00413184 0.00916922]
 ...
 [0.01816563 0.0198689  0.02043438 ... 0.00590567 0.00426055 0.01194846]
 [0.01815397 0.0157637  0.01658147 ... 0.009302   0.00808603 0.01391967]
 [0.01820739 0.02042425 0.02020109 ... 0.00751292 0.00659604 0.01261813]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Mary', "'s", ' location', ' in', ' sentences', ' ', '4', ' and', ' ', '5', '.', ' Sentence', ' ', '1', ' (', 'from', ' the', ' previous', ' part', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' and', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(51, 32), x_tokens=32, y_tokens=51, max_supp_attn=0.0588, attn_on_target=0.0196)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (51, 32)
DEBUG result.interpretability.attn_scores 1632 
 [[0.01805513 0.02131196 0.02305513 ... 0.0084403  0.00701936 0.01009212]
 [0.01862917 0.0199043  0.02033098 ... 0.01102002 0.01062957 0.01401267]
 [0.01898569 0.01900819 0.02168845 ... 0.01849035 0.01209003 0.01662431]
 ...
 [0.01901    0.02293959 0.01984401 ... 0.00570031 0.00714463 0.00703477]
 [0.01936767 0.01804268 0.01568463 ... 0.00821329 0.01179732 0.01155224]
 [0.01931944 0.0196275  0.01643058 ... 0.00562258 0.01099438 0.01199045]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' office', ',', ' which', ' means', ' Julie', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.0357, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.03343168 0.04983919 0.04738591 ... 0.06728149 0.03938658 0.01443219]
 [0.03397952 0.04776715 0.04027603 ... 0.03505563 0.04733757 0.03369785]
 [0.03474845 0.0525603  0.05392898 ... 0.05265173 0.0326506  0.01350644]
 ...
 [0.03514453 0.04999522 0.04689708 ... 0.06390306 0.03352665 0.01640979]
 [0.03532087 0.03892146 0.034606   ... 0.04435974 0.03784807 0.03067878]
 [0.03543905 0.04175075 0.0367344  ... 0.07449014 0.02960146 0.01856987]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '1', ' (', 'from', ' the', ' previous', ' part', ')', ' stated', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' and', ' sentence', ' ', '10', ' updated', ' Mary', "'s", ' location', ' to', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 44), x_tokens=44, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 44)
DEBUG result.interpretability.attn_scores 2068 
 [[0.01978102 0.02698007 0.02371255 ... 0.01622916 0.088353   0.03397977]
 [0.02009953 0.02146211 0.01942057 ... 0.03013812 0.03744029 0.03157885]
 [0.02052333 0.02771328 0.02712353 ... 0.01168816 0.04617461 0.05124405]
 ...
 [0.02078657 0.02987133 0.02776214 ... 0.01882185 0.0357112  0.01227682]
 [0.02135352 0.02247247 0.02011861 ... 0.02309564 0.02067559 0.00926322]
 [0.02121694 0.02441006 0.02125366 ... 0.02185718 0.03162609 0.00972598]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', ' in', ' sentences', ' ', '13', ' and', ' ', '14', '.', ' Sentence', ' ', '11', ' (', 'from', ' the', ' previous', ' part', ')', ' stated', ' that', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' update', ' to', ' change', ' this', ' information', '.', ' Sentence', ' ', '14', ' is', ' about', ' Mary', "'s", ' location', ',', ' not', ' Fred', "'s", '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(64, 50), x_tokens=50, y_tokens=64, max_supp_attn=0.0, attn_on_target=0.0156)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (64, 50)
DEBUG result.interpretability.attn_scores 3200 
 [[0.01432828 0.02209474 0.021301   ... 0.00695797 0.00442439 0.02432786]
 [0.01467437 0.01453034 0.01559706 ... 0.00893248 0.00600422 0.01089418]
 [0.01492188 0.02290739 0.02511297 ... 0.01010406 0.00759431 0.02828849]
 ...
 [0.01569725 0.01840796 0.0133886  ... 0.00480857 0.00471598 0.02571102]
 [0.01567431 0.02419777 0.01983063 ... 0.00658632 0.00725227 0.02715631]
 [0.01566913 0.02280743 0.0192245  ... 0.00662408 0.0059512  0.04064472]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' school', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' moving', ' to', ' the', ' bedroom', ' and', ' Julie', ' going', ' back', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0541, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.02531972 0.04330695 0.045964   0.07556095 0.07505837 0.04478702
  0.03324471 0.02901022 0.03009203 0.04710978 0.03641079 0.022468
  0.0240411  0.1228385  0.12745528 0.03870977 0.02663157 0.01975222
  0.01857522 0.01879475 0.01827973 0.03866183 0.0588509  0.01225698
  0.00705252 0.02616227]
 [0.02613401 0.02732228 0.02736519 0.0564885  0.05353837 0.03859175
  0.0234318  0.02111836 0.0240818  0.04057805 0.03128817 0.02401057
  0.02378698 0.12513909 0.15261182 0.03713239 0.02881654 0.0234056
  0.02053353 0.01945459 0.01712598 0.03269379 0.03541536 0.00866412
  0.00612428 0.01696345]
 [0.02656446 0.03057789 0.03493283 0.05926022 0.05999593 0.04953877
  0.03136135 0.02975732 0.03206363 0.04827645 0.03588407 0.03878687
  0.03766727 0.09968464 0.09449186 0.03087803 0.02664164 0.02402651
  0.0200239  0.01971136 0.01640303 0.02957456 0.03272689 0.01161568
  0.00816364 0.01594995]
 [0.02568942 0.03562506 0.04187669 0.04511994 0.04833322 0.0466093
  0.03557058 0.03795172 0.03643388 0.04371502 0.03577424 0.04532828
  0.03968795 0.05764574 0.05384202 0.03856888 0.03315775 0.03024942
  0.02578892 0.02610146 0.0227281  0.03289621 0.04671825 0.02913225
  0.02163712 0.02579865]
 [0.02663137 0.03146922 0.03746833 0.03442654 0.0304681  0.04167606
  0.03602202 0.03906825 0.03491997 0.03487758 0.03081973 0.04222053
  0.03622258 0.02234891 0.01728255 0.02804998 0.02664342 0.02640132
  0.02447945 0.02494947 0.02109992 0.02693679 0.03427205 0.02447193
  0.02022499 0.02645148]
 [0.02695586 0.03012444 0.03365401 0.02906313 0.02397946 0.04117658
  0.03702303 0.03790541 0.03692565 0.03324793 0.03015853 0.0463016
  0.03825926 0.02004897 0.01485297 0.02634064 0.02668873 0.02491954
  0.02508269 0.02433767 0.02036336 0.02696872 0.03130624 0.02239343
  0.01874566 0.02468241]
 [0.02642774 0.04482213 0.03991234 0.03052522 0.02512695 0.04465798
  0.04326282 0.04882373 0.0424373  0.03817501 0.0365901  0.06086161
  0.05339977 0.02099413 0.01564756 0.03373105 0.03085491 0.02976244
  0.02839932 0.02688926 0.02243697 0.02873011 0.0353248  0.02372526
  0.02069317 0.02179118]
 [0.02705521 0.03662753 0.04023414 0.03168966 0.02306898 0.05391091
  0.04343323 0.04370313 0.04188647 0.03594428 0.03192696 0.06699894
  0.05195979 0.02057219 0.01459829 0.03117505 0.02869601 0.02807181
  0.02589313 0.02640322 0.02175971 0.02715197 0.0293796  0.01842336
  0.01641614 0.01759006]
 [0.02719651 0.04382781 0.05224368 0.03705016 0.0250881  0.07550941
  0.06605852 0.04699098 0.05709149 0.03839993 0.03098671 0.05631157
  0.04297731 0.02081497 0.01535406 0.02837565 0.02334849 0.02205493
  0.02153324 0.02321144 0.01910101 0.02765961 0.03511764 0.01717117
  0.01359188 0.01841456]
 [0.02670624 0.02184686 0.02210048 0.01840893 0.01468426 0.02129132
  0.02800771 0.02935084 0.02275414 0.02100783 0.0272627  0.02578024
  0.03448896 0.01037535 0.01020966 0.03241205 0.03211294 0.02938255
  0.03232814 0.02881506 0.02984853 0.0269676  0.01859346 0.03700048
  0.02601656 0.01989273]
 [0.02668426 0.01936106 0.01646746 0.01531343 0.01215616 0.01439844
  0.02314988 0.02356649 0.01721637 0.01512585 0.02092304 0.01751242
  0.02172677 0.00808256 0.00834278 0.03268252 0.03319181 0.03369465
  0.03675276 0.03505713 0.03828264 0.02463233 0.01601989 0.04658826
  0.03466057 0.0245581 ]
 [0.02724369 0.01967299 0.01689602 0.01663177 0.0141144  0.0168892
  0.02252715 0.02440724 0.01845204 0.0185364  0.02586074 0.02400959
  0.02447685 0.00914132 0.00892926 0.03249721 0.03296496 0.03010276
  0.0344623  0.02980548 0.029714   0.02302578 0.01329972 0.02687289
  0.02332885 0.01573643]
 [0.02720908 0.01691675 0.01467545 0.01245314 0.01206161 0.01277179
  0.01969452 0.0196715  0.01662921 0.0141065  0.02451704 0.01758517
  0.01968162 0.00710299 0.00756872 0.02959293 0.03563561 0.02840188
  0.03973112 0.03299027 0.03323429 0.02357891 0.01320237 0.02938888
  0.02239466 0.01709664]
 [0.02658549 0.02066064 0.0176845  0.01380343 0.0134487  0.01479969
  0.02311151 0.0220548  0.02099718 0.01511533 0.02581143 0.01716192
  0.02124207 0.00764698 0.00854336 0.03064435 0.03355251 0.02959494
  0.04474351 0.03574753 0.03471614 0.0257132  0.02161134 0.04060551
  0.03023236 0.033006  ]
 [0.02736782 0.02403554 0.02120676 0.01666081 0.01454698 0.01832355
  0.02382881 0.02554538 0.02262921 0.01871791 0.02533738 0.0225324
  0.02359216 0.00954379 0.00933244 0.02392711 0.02602654 0.02343705
  0.03686713 0.03295795 0.02689253 0.02529145 0.019906   0.02129002
  0.01730969 0.01803064]
 [0.02693942 0.02933388 0.02964067 0.02935497 0.02543649 0.03317153
  0.02792028 0.03095103 0.03028737 0.03527216 0.02803933 0.04153429
  0.03650023 0.02158031 0.0156736  0.02621315 0.02726621 0.02758978
  0.02406345 0.02360315 0.02016593 0.0295171  0.03381699 0.02949397
  0.01989174 0.01810252]
 [0.02674886 0.04682337 0.04572685 0.02444602 0.02035438 0.02877274
  0.03777066 0.03777266 0.03486545 0.02327145 0.02466161 0.02724908
  0.03093136 0.01547247 0.0139492  0.03225223 0.02695259 0.02493544
  0.02421772 0.02614644 0.02410803 0.02886436 0.05429238 0.03638434
  0.02795106 0.02757786]
 [0.02712416 0.06702241 0.0698992  0.02843155 0.02228283 0.03118774
  0.04502217 0.03981432 0.04169226 0.02461436 0.02417524 0.0259754
  0.02779163 0.01563476 0.01425797 0.04003245 0.02823698 0.02358583
  0.02144735 0.02465034 0.02009636 0.02896509 0.06304491 0.022962
  0.0176359  0.02203895]
 [0.02721849 0.03695501 0.04005798 0.02407288 0.01933121 0.02656503
  0.03629413 0.03500861 0.03197732 0.02194432 0.02190699 0.02427258
  0.02442038 0.01396904 0.01259217 0.03118452 0.02535133 0.02303736
  0.02157883 0.02428046 0.02187884 0.02952125 0.04446107 0.03039661
  0.02718159 0.03092151]
 [0.0278652  0.02896861 0.02914043 0.02151459 0.01690542 0.02550029
  0.0305593  0.03494583 0.02633847 0.02086052 0.02369671 0.02540812
  0.02667447 0.01211442 0.01025073 0.02315563 0.02100182 0.02199592
  0.01947724 0.02112624 0.02036669 0.02728926 0.02257975 0.02344817
  0.0208113  0.02124744]
 [0.02738454 0.02047392 0.01892138 0.01469055 0.01284128 0.01564216
  0.02235853 0.02250142 0.01882909 0.01488515 0.02323275 0.01527968
  0.0206849  0.00875183 0.00829169 0.02585304 0.02492962 0.02340242
  0.02278735 0.02428221 0.02826167 0.02485438 0.01995354 0.05537849
  0.03359632 0.02497669]
 [0.02726019 0.01674708 0.0144871  0.01232973 0.01046989 0.01145066
  0.01728925 0.01645775 0.01483477 0.01209542 0.01736713 0.01114896
  0.0158652  0.00714778 0.00711321 0.02420994 0.02529358 0.02550087
  0.02482218 0.02529271 0.03288744 0.02276781 0.01600177 0.06660839
  0.03872681 0.02668276]
 [0.02741518 0.0167945  0.01514061 0.01314861 0.011133   0.01268272
  0.01730352 0.01716368 0.0161488  0.01310425 0.01925659 0.01288177
  0.01687601 0.00759959 0.00720536 0.02852811 0.02145967 0.02761134
  0.02117992 0.02518179 0.0292524  0.02089005 0.0153039  0.06541704
  0.04066022 0.02147787]
 [0.02745193 0.01559421 0.01393653 0.0112161  0.00985211 0.01114098
  0.01650593 0.01570036 0.01504488 0.01163112 0.02458541 0.012197
  0.01609391 0.0067557  0.00689935 0.02770459 0.02830717 0.02599668
  0.0237834  0.02569927 0.03059176 0.02190468 0.01438699 0.0625266
  0.03038625 0.02019843]
 [0.02681055 0.02922941 0.0252224  0.03022467 0.03300786 0.03035028
  0.03326969 0.02946918 0.02841911 0.0357654  0.04547594 0.0348985
  0.03124571 0.02699097 0.02249106 0.02916238 0.03095916 0.0294716
  0.0263885  0.028274   0.02734361 0.0317949  0.02459356 0.03957566
  0.01825364 0.02158823]
 [0.02782485 0.01652629 0.01504605 0.01295696 0.01103198 0.01255202
  0.01581718 0.01605024 0.01670984 0.01328576 0.02008253 0.01314869
  0.01558191 0.00792222 0.00705737 0.01836222 0.02260664 0.01843265
  0.02152835 0.02352892 0.02501532 0.02244041 0.01516241 0.03489101
  0.02658228 0.0293389 ]
 [0.02759624 0.01959148 0.01820228 0.01403283 0.01180647 0.01392893
  0.0193448  0.02045565 0.0211346  0.0142959  0.01727075 0.014765
  0.01814376 0.00865121 0.00682698 0.01709184 0.02102581 0.02017594
  0.01972961 0.02372499 0.03046802 0.0266461  0.01750053 0.02305271
  0.0674961  0.05022314]
 [0.02724403 0.01693972 0.01525575 0.01318055 0.01088692 0.01223651
  0.01696093 0.01663681 0.01700854 0.01330943 0.0172192  0.01297271
  0.01601579 0.00791313 0.00643231 0.01756314 0.02137497 0.02714274
  0.02264366 0.03276275 0.04960189 0.0232946  0.01569218 0.02186357
  0.0969254  0.05679795]
 [0.02774861 0.01469547 0.01409056 0.01171847 0.01043881 0.01142319
  0.01498747 0.01526198 0.01609542 0.0124637  0.01731109 0.01303317
  0.01473486 0.00742627 0.0056793  0.01572579 0.01566112 0.01956633
  0.01888376 0.03461912 0.04917623 0.01902091 0.01300484 0.01721929
  0.08851006 0.05207423]
 [0.02807723 0.0140768  0.01345154 0.01103316 0.00978088 0.01085877
  0.01418363 0.01408371 0.01606816 0.01191785 0.01887444 0.01324209
  0.01396499 0.00747041 0.00565601 0.01625465 0.01728578 0.0195522
  0.02124749 0.0285941  0.04036832 0.02053024 0.01219943 0.01423317
  0.05168524 0.05288266]
 [0.02766374 0.01420053 0.01346527 0.01036237 0.00929649 0.01040507
  0.01459491 0.01386658 0.01591825 0.01131413 0.02248974 0.0121852
  0.01405817 0.00721075 0.00567354 0.01865399 0.02222609 0.02217297
  0.02612107 0.0320457  0.0382277  0.02181209 0.01460603 0.02084036
  0.04277896 0.073865  ]
 [0.02705135 0.02299751 0.02625567 0.0299793  0.02716032 0.02903747
  0.02896232 0.03046737 0.05550943 0.04268382 0.02767175 0.03314898
  0.03557977 0.02694034 0.02222311 0.01811408 0.02386171 0.0285291
  0.02766093 0.02693205 0.0231743  0.02768898 0.02510295 0.01508548
  0.0169488  0.03120057]
 [0.0283054  0.01839193 0.01848062 0.01605972 0.01248253 0.01599346
  0.0197427  0.02178725 0.0221931  0.01759596 0.02153156 0.01700118
  0.02141148 0.01083495 0.00793835 0.01688103 0.01906799 0.01897794
  0.024488   0.02457785 0.0214234  0.02476115 0.01500449 0.01203796
  0.01515519 0.03022301]
 [0.02676708 0.02914494 0.02814453 0.05002309 0.05465737 0.03747208
  0.02523129 0.02578    0.02991826 0.04796472 0.03269238 0.02710898
  0.03084477 0.0833884  0.09740026 0.02579416 0.02526722 0.02498598
  0.02083881 0.01977861 0.01742071 0.03166416 0.03285254 0.00912733
  0.00666535 0.01849236]
 [0.02658866 0.02943242 0.02707923 0.05365144 0.10804293 0.03404063
  0.02018789 0.0222565  0.02506079 0.05112405 0.03642087 0.02628657
  0.02364204 0.07944093 0.10114679 0.03057285 0.0365966  0.03808733
  0.02876525 0.02373678 0.02151274 0.0282726  0.03240597 0.00812777
  0.00604842 0.01619308]
 [0.02646963 0.02338205 0.02206922 0.03783855 0.05766598 0.024334
  0.01646846 0.02150323 0.02363205 0.04545909 0.0337447  0.02968385
  0.0273907  0.02756287 0.0295647  0.02252662 0.03894712 0.0620513
  0.0581077  0.0406983  0.03064773 0.0248191  0.02537237 0.01158305
  0.01083319 0.01659475]
 [0.02667377 0.02648133 0.02360425 0.03727811 0.04946517 0.02632194
  0.01949736 0.02314046 0.02770361 0.04220769 0.03274169 0.02870857
  0.02833751 0.02724154 0.02661424 0.01944597 0.03135748 0.04394059
  0.04504513 0.03523748 0.02602504 0.04219802 0.03091684 0.01014695
  0.00868411 0.01517747]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' do', ' not', ' mention', ' Julie', ' being', ' in', ' the', ' school', '.', ' Sentence', ' ', '4', ' states', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' and', ' sentence', ' ', '5', ' provides', ' alternative', ' locations', ' (', 'office', ' or', ' cinema', '),', ' but', ' school', ' is', ' not', ' mentioned', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 32), x_tokens=32, y_tokens=47, max_supp_attn=0.0851, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 32)
DEBUG result.interpretability.attn_scores 1504 
 [[0.01956859 0.03241419 0.0340619  ... 0.0101704  0.00827954 0.00918659]
 [0.02022182 0.0308653  0.03210736 ... 0.0121649  0.01005603 0.01022149]
 [0.02052476 0.03014072 0.03344562 ... 0.01892825 0.01420315 0.01205949]
 ...
 [0.02060212 0.03044307 0.02571122 ... 0.00649595 0.00475036 0.00742227]
 [0.02087483 0.02125689 0.01757493 ... 0.01177029 0.00606252 0.00939969]
 [0.02079784 0.0248257  0.02029733 ... 0.0087231  0.00531966 0.00883576]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Fred', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 38), x_tokens=38, y_tokens=27, max_supp_attn=0.0, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 38)
DEBUG result.interpretability.attn_scores 1026 
 [[0.03445416 0.04890321 0.05226714 ... 0.04054032 0.02641051 0.02405005]
 [0.03521785 0.04676944 0.04936231 ... 0.03788318 0.03555934 0.04122522]
 [0.03618577 0.04954334 0.0595317  ... 0.03168241 0.02249514 0.0168792 ]
 ...
 [0.0364221  0.05073215 0.04239171 ... 0.02890169 0.01899319 0.01648859]
 [0.03645699 0.04263718 0.03362272 ... 0.03963599 0.03297017 0.03088286]
 [0.0366971  0.0446814  0.03457063 ... 0.03105853 0.02357166 0.02431447]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' provides', ' alternative', ' locations', ' for', ' Fred', ' (', 'bed', 'room', ' or', ' office', '),', ' but', ' kitchen', ' is', ' not', ' mentioned', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' Fred', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0256, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02378519 0.03242102 0.03607602 ... 0.08579454 0.01775667 0.00920829]
 [0.02408115 0.02556538 0.02753601 ... 0.03348082 0.02905051 0.01372566]
 [0.02470645 0.0342616  0.03936452 ... 0.07186081 0.02790731 0.01486411]
 ...
 [0.02489625 0.03825504 0.03893256 ... 0.02338411 0.00961529 0.00745115]
 [0.02541428 0.02896911 0.02724165 ... 0.0133305  0.01010117 0.01002308]
 [0.0253332  0.03368517 0.03129828 ... 0.01312636 0.00970542 0.00817483]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Bill', "'s", ' location', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', ' moving', ' to', ' the', ' office', ' and', ' Mary', ' being', ' in', ' either', ' the', ' park', ' or', ' the', ' cinema', ',', ' but', ' do', ' not', ' mention', ' Bill', ' or', ' the', ' school', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 50), x_tokens=50, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 50)
DEBUG result.interpretability.attn_scores 2400 
 [[0.01925127 0.02276358 0.02782613 ... 0.02991846 0.03011437 0.01752313]
 [0.0195419  0.02403378 0.03088327 ... 0.01441736 0.03072725 0.02305856]
 [0.02007673 0.02413093 0.03158866 ... 0.03320755 0.01966904 0.01209933]
 ...
 [0.02044602 0.02763291 0.02386817 ... 0.04585713 0.02416859 0.01924278]
 [0.02081669 0.03041049 0.02778342 ... 0.0407781  0.02296224 0.01476076]
 [0.02088272 0.02642987 0.02530225 ... 0.04821664 0.02032768 0.01333088]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' moved', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.1818, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02813218 0.04606107 0.054979   0.07260676 0.07624871 0.07690781
  0.06249946 0.07037577 0.0535602  0.06271394 0.04665685 0.0583561
  0.06400379 0.09530302 0.06865717 0.03011345 0.03162343 0.03141846
  0.0286864  0.03216024 0.02630725 0.03859824 0.04786287 0.01940682
  0.01546792 0.02228947]
 [0.02841534 0.06270506 0.05709504 0.06933767 0.05881852 0.05979894
  0.05561702 0.0527077  0.04670816 0.04973839 0.03932802 0.0364697
  0.03843501 0.10442232 0.10163395 0.0344688  0.03125523 0.02563435
  0.02486003 0.02680417 0.02331858 0.03933827 0.0522616  0.01239904
  0.01101419 0.02035331]
 [0.03062869 0.06230093 0.0380239  0.05574061 0.03674574 0.03806917
  0.03508973 0.02509885 0.0232563  0.03454728 0.02687235 0.01779375
  0.01895811 0.02742578 0.03541876 0.02220344 0.01518876 0.01357709
  0.01706959 0.01823446 0.01647639 0.04553638 0.05655427 0.0056502
  0.00529299 0.01101368]
 [0.02865245 0.03370332 0.03290704 0.02509306 0.01840224 0.02846979
  0.03317164 0.03406782 0.03224142 0.02764344 0.03098921 0.03137501
  0.02960474 0.01302733 0.01157134 0.02898278 0.03437634 0.03272335
  0.04135605 0.03959916 0.03711551 0.03352869 0.03731243 0.08414362
  0.06639583 0.05423519]
 [0.02909064 0.04603386 0.04956664 0.06744489 0.06103789 0.04984203
  0.03834219 0.0328697  0.03570429 0.0473573  0.03528294 0.02759149
  0.02751995 0.09352012 0.09772685 0.03700985 0.02915795 0.0207484
  0.02224009 0.02433266 0.0232674  0.03989814 0.06781072 0.00859393
  0.00833799 0.02476631]
 [0.02966101 0.03001728 0.0298924  0.05080672 0.04701681 0.04319568
  0.02783633 0.0257802  0.03038663 0.04364894 0.03172876 0.0314333
  0.02979613 0.10663561 0.12564138 0.03690104 0.03315198 0.02520764
  0.02517991 0.02548444 0.02265635 0.0338192  0.03918904 0.00779088
  0.00677016 0.01593017]
 [0.03007894 0.03406424 0.03845247 0.05395619 0.0505526  0.0545284
  0.03711148 0.03497065 0.03898364 0.051311   0.03683894 0.04943794
  0.04448355 0.08418071 0.07928356 0.03128781 0.03036691 0.02514052
  0.02386014 0.02473664 0.02147736 0.03082838 0.03633637 0.01116464
  0.00999801 0.01558817]
 [0.0290144  0.04283599 0.04776511 0.04126683 0.04492413 0.048154
  0.04044358 0.04272698 0.0418463  0.04359869 0.03608529 0.0523825
  0.04450883 0.05033845 0.04581772 0.04071647 0.03820818 0.03212604
  0.03006866 0.0316269  0.02944315 0.03563174 0.05178919 0.02797993
  0.034211   0.03284194]
 [0.0302008  0.04340578 0.05047216 0.04686777 0.0441018  0.05616909
  0.04736093 0.04957564 0.05157153 0.04971622 0.0370799  0.05390259
  0.04980025 0.03784173 0.02533751 0.0288094  0.02960143 0.0267139
  0.02642976 0.0278107  0.02406216 0.03676594 0.0398046  0.0184743
  0.01680316 0.02221676]
 [0.02946599 0.05486803 0.05673041 0.0282172  0.02373126 0.03636906
  0.04588036 0.04362497 0.04468339 0.02978953 0.02940117 0.03874361
  0.03957009 0.01633139 0.01417649 0.04490118 0.03597471 0.03001008
  0.03157431 0.03342606 0.03208124 0.03459802 0.06884404 0.03845451
  0.04296356 0.03780154]
 [0.03015549 0.04095216 0.0486378  0.02414596 0.02151765 0.02824721
  0.04976346 0.03670611 0.04248261 0.02480712 0.02500234 0.02826999
  0.02914975 0.01301911 0.01270151 0.04435851 0.03395819 0.02796086
  0.03063639 0.03387997 0.03081776 0.02942023 0.0549568  0.02847872
  0.04234039 0.0344399 ]
 [0.03064061 0.01455609 0.0173154  0.01133698 0.01033211 0.01548329
  0.01717772 0.01720939 0.02157451 0.01386976 0.01382325 0.01491272
  0.01566963 0.00619306 0.00622581 0.01847621 0.01866403 0.01707665
  0.02091767 0.02255506 0.02265109 0.01769512 0.03157065 0.04383362
  0.07523464 0.05937911]
 [0.0301741  0.02508283 0.02704538 0.01686333 0.0151371  0.02140849
  0.02609608 0.02386684 0.024729   0.01856543 0.02275165 0.02197744
  0.02276779 0.00882853 0.00918605 0.0377421  0.02695938 0.03026499
  0.02888023 0.03174661 0.02839493 0.02877909 0.02964588 0.03718888
  0.06635181 0.04926206]
 [0.03033534 0.02472911 0.0249449  0.01844229 0.01572448 0.02488123
  0.02775669 0.02797918 0.02614303 0.02173431 0.02630968 0.02881817
  0.02992854 0.0098295  0.00882529 0.03897087 0.0304634  0.03381888
  0.02848674 0.03070037 0.02919845 0.02939855 0.0213     0.03668229
  0.0566513  0.03099794]
 [0.02988576 0.02170649 0.01893462 0.01505218 0.01174988 0.0168893
  0.02426746 0.02225966 0.02105252 0.01641491 0.02411796 0.02015281
  0.0240762  0.00720388 0.00696729 0.03920716 0.02921441 0.04440703
  0.03222255 0.03988171 0.04186092 0.02705117 0.01709974 0.04970373
  0.09663544 0.04711876]
 [0.03063273 0.01950095 0.01781136 0.01401502 0.01169575 0.01715922
  0.02292218 0.02184092 0.02079378 0.01646221 0.02661729 0.02265005
  0.02399194 0.00712174 0.00661115 0.03879254 0.02641531 0.05095186
  0.03399883 0.04434075 0.03792044 0.02277736 0.01350853 0.03380405
  0.06081545 0.04131283]
 [0.03061162 0.01779558 0.01590788 0.01143127 0.00977698 0.01375598
  0.02123539 0.01933092 0.01965504 0.01366579 0.03037655 0.01887701
  0.02080938 0.00587985 0.00618444 0.034607   0.02861969 0.04194548
  0.03723311 0.04081562 0.03842562 0.02450687 0.01468109 0.04138478
  0.04350487 0.0580255 ]
 [0.03017867 0.0199427  0.01828486 0.0124051  0.01100587 0.01619939
  0.0216249  0.02132779 0.02344735 0.01512903 0.02472933 0.01915208
  0.02155808 0.00645261 0.00643307 0.0256743  0.0300124  0.02734757
  0.03712136 0.03304365 0.03373526 0.02501686 0.01932058 0.07741561
  0.04813728 0.05924129]
 [0.03098741 0.02214264 0.02140924 0.0160823  0.01249735 0.0181241
  0.02350699 0.02371556 0.02349248 0.01763132 0.0255727  0.02149017
  0.02324204 0.0079787  0.00749605 0.02450434 0.0231255  0.02695642
  0.03282735 0.03186747 0.03233611 0.02710898 0.01684597 0.03025527
  0.02496379 0.04282456]
 [0.03120658 0.0232078  0.02717153 0.02363512 0.01766859 0.02655817
  0.02700603 0.03238682 0.02793013 0.02826569 0.02783107 0.0368155
  0.0332435  0.01283568 0.00924401 0.02073617 0.02336982 0.02623525
  0.0264859  0.02455451 0.02497085 0.02980506 0.01659154 0.02464324
  0.01947584 0.02268431]
 [0.03141462 0.02837993 0.03023629 0.02759518 0.01915316 0.03038946
  0.03427798 0.04178179 0.0304122  0.0326835  0.03608786 0.04403871
  0.04168136 0.01403979 0.00978831 0.02359294 0.02342081 0.02765801
  0.02579053 0.02440358 0.02401483 0.02992951 0.01661106 0.02250191
  0.01624688 0.01604642]
 [0.03130941 0.02660734 0.0269175  0.0250818  0.01903338 0.02804174
  0.03155359 0.03570767 0.03066492 0.03108428 0.03496508 0.04033574
  0.04075452 0.0134057  0.00984018 0.02785871 0.02573674 0.03080397
  0.02841895 0.0275202  0.02702488 0.03023924 0.01443968 0.02203739
  0.01857805 0.01468858]
 [0.03111915 0.0202428  0.01948847 0.01434573 0.0108953  0.01675736
  0.02179183 0.02396245 0.02370608 0.01824618 0.02384752 0.02390948
  0.02615377 0.00767479 0.00647255 0.03128973 0.02801915 0.03013993
  0.02977949 0.02882915 0.03261797 0.02793222 0.01282269 0.03357851
  0.03115764 0.02169467]
 [0.03128416 0.02000752 0.01816562 0.01424722 0.0101916  0.01526171
  0.0221497  0.02275464 0.02257787 0.0168258  0.02319641 0.02143385
  0.02504156 0.00708341 0.00595492 0.02865636 0.02731971 0.03142205
  0.03095892 0.03116846 0.03743489 0.02365525 0.01248302 0.03960476
  0.03289249 0.02465597]
 [0.03144476 0.02034443 0.01869787 0.01526467 0.01199866 0.01602213
  0.02120157 0.02359575 0.02257787 0.01899701 0.02575598 0.0238525
  0.02464434 0.00790587 0.00663256 0.02719706 0.02889755 0.029913
  0.03238884 0.02879283 0.03339345 0.02450317 0.01266977 0.03209602
  0.02011397 0.02019013]
 [0.0314615  0.0217273  0.02027043 0.01537866 0.01164162 0.01709678
  0.02424237 0.02608155 0.02568874 0.01899258 0.02896923 0.02458012
  0.02620673 0.00808383 0.00683983 0.02856596 0.02691558 0.03076202
  0.03040548 0.02980448 0.03311018 0.02450793 0.01393343 0.03442602
  0.02172515 0.02277646]
 [0.03157247 0.01738104 0.01722036 0.01140171 0.00984839 0.0134075
  0.02201005 0.02168965 0.02149027 0.01428656 0.03498687 0.02005588
  0.02196372 0.0066125  0.00553095 0.02619416 0.03050139 0.0288726
  0.03612306 0.03288875 0.03448128 0.02361294 0.01243097 0.03362969
  0.01846451 0.02914084]
 [0.03064477 0.01869748 0.01847668 0.01169583 0.00943262 0.01487294
  0.02009959 0.02159646 0.02483881 0.01517042 0.02496901 0.01867594
  0.02162789 0.00696678 0.00570923 0.02169951 0.02825218 0.02303375
  0.03688674 0.03127966 0.0350422  0.0250641  0.01708738 0.07465709
  0.03752226 0.04952035]
 [0.03149263 0.01997391 0.02060913 0.017225   0.01301908 0.01976478
  0.02109246 0.02322663 0.02605277 0.02095096 0.02373857 0.02370252
  0.02399916 0.01063936 0.00799541 0.01785056 0.02379653 0.02252914
  0.03091867 0.02802063 0.02921703 0.02517163 0.01435704 0.0228541
  0.01522543 0.0244928 ]
 [0.03024942 0.02932425 0.029628   0.04362964 0.04505542 0.03965244
  0.02628048 0.02665762 0.03206391 0.04494369 0.03335269 0.03248708
  0.03329767 0.07099129 0.08477146 0.02618015 0.02947311 0.02580655
  0.0259097  0.02554004 0.02386093 0.03245547 0.03369714 0.00888886
  0.0082108  0.01801175]
 [0.03006838 0.03062709 0.03000386 0.04828489 0.09120729 0.03853146
  0.02407434 0.02529369 0.03086048 0.0520914  0.03937929 0.03272482
  0.02785819 0.06847848 0.0889211  0.03199204 0.0412499  0.03519089
  0.03121736 0.02785552 0.029074   0.02941424 0.03299373 0.00769177
  0.00594697 0.0154643 ]
 [0.02974127 0.02754765 0.02637661 0.04018182 0.09249031 0.02747269
  0.02002867 0.02367562 0.02658228 0.0465976  0.03823985 0.0348815
  0.0268507  0.03198871 0.0418302  0.02721602 0.06438669 0.05651463
  0.04488638 0.03389699 0.04813308 0.02705627 0.03038117 0.01805271
  0.01290878 0.02174075]
 [0.0300487  0.03352726 0.03056203 0.04092064 0.05734777 0.03251863
  0.02648778 0.0255551  0.03224142 0.04251973 0.03511632 0.02871993
  0.02880309 0.03176037 0.03457396 0.02324343 0.04232369 0.0370887
  0.03618079 0.03239854 0.03607851 0.04635575 0.04280693 0.01253306
  0.00964154 0.01925418]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Julie', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 32), x_tokens=32, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 32)
DEBUG result.interpretability.attn_scores 928 
 [[0.03251587 0.05354788 0.052809   0.07657359 0.06460226 0.05666837
  0.04161983 0.04378026 0.05784203 0.05952851 0.03957113 0.03902334
  0.03774381 0.10588488 0.10624424 0.03516099 0.03210045 0.02486614
  0.02647407 0.02752827 0.02476603 0.03914696 0.06218942 0.01231086
  0.01561795 0.03319453 0.04493326 0.04450783 0.11131479 0.05786687
  0.00743702 0.03560374]
 [0.0334783  0.05318398 0.05091159 0.09125019 0.09209806 0.08596432
  0.04721204 0.04645236 0.05885968 0.08042293 0.05525796 0.06194763
  0.05434257 0.17475775 0.1505764  0.04109809 0.03421504 0.02993494
  0.02785857 0.02872623 0.02571238 0.04134151 0.04878314 0.01143842
  0.01335263 0.0276938  0.04352279 0.03484362 0.08258048 0.0642199
  0.010123   0.04225835]
 [0.03398032 0.04777767 0.05400646 0.07530478 0.06704152 0.06703756
  0.04540414 0.04745841 0.05555044 0.06458385 0.04156885 0.058619
  0.05146197 0.10609935 0.07714851 0.03263603 0.03189074 0.02617983
  0.02574376 0.02617552 0.02306591 0.0373224  0.04765739 0.0152437
  0.01738526 0.02708635 0.04076904 0.03068863 0.05801964 0.06954417
  0.01785056 0.0363224 ]
 [0.03276416 0.04252809 0.04482228 0.03631062 0.03298466 0.03768566
  0.03594718 0.03875461 0.03676242 0.03466827 0.03084052 0.03816078
  0.03721179 0.02718157 0.02757608 0.03652782 0.03409562 0.02731668
  0.02912619 0.02993897 0.02779562 0.03754871 0.05627512 0.03066952
  0.04326961 0.04055455 0.0482915  0.03346265 0.04367442 0.09775026
  0.03119747 0.0270879 ]
 [0.03398615 0.03241625 0.034392   0.02598951 0.02231831 0.0305783
  0.02975745 0.02851309 0.03188067 0.02751139 0.02495269 0.02684445
  0.02771103 0.01679221 0.01872511 0.02519315 0.02340906 0.0204633
  0.02569664 0.02656498 0.02568121 0.03098935 0.04098507 0.02277097
  0.0343095  0.04805258 0.04500042 0.02943558 0.03340753 0.0667658
  0.02829342 0.02353155]
 [0.03377393 0.04632565 0.0482483  0.02758479 0.02347711 0.03402007
  0.03920675 0.03762481 0.04043742 0.028383   0.02542895 0.03124897
  0.03269647 0.02033808 0.02017289 0.0355947  0.03045844 0.02308928
  0.02709021 0.0269574  0.02532511 0.03681894 0.06293306 0.02761315
  0.03733056 0.03670121 0.05752666 0.02499866 0.03523111 0.09542209
  0.02752261 0.01881124]
 [0.03392443 0.04154627 0.0418357  0.02235375 0.02105228 0.02679325
  0.0364049  0.03016997 0.03617273 0.02300323 0.02342911 0.02338907
  0.0247337  0.01564578 0.01853606 0.03587493 0.03268298 0.02344928
  0.02949768 0.02969248 0.02744298 0.03128806 0.05568554 0.02448056
  0.04058313 0.03842902 0.0467467  0.02238947 0.02885724 0.07283865
  0.01683072 0.0131642 ]
 [0.03452927 0.02192249 0.02152756 0.01349931 0.01405204 0.0172225
  0.01951336 0.01675677 0.01945982 0.01585119 0.01986985 0.01745936
  0.01812128 0.0100748  0.01165835 0.02365073 0.02179691 0.02370613
  0.02567218 0.03026631 0.02536529 0.0233457  0.02714945 0.03268615
  0.04770784 0.03566236 0.02266812 0.02158062 0.02130842 0.03091854
  0.01942579 0.0161094 ]
 [0.03401013 0.03148307 0.03384585 0.02043693 0.02029143 0.02669042
  0.03165344 0.0269662  0.03024595 0.02387242 0.02684927 0.02599632
  0.02681339 0.01536762 0.01708828 0.03989055 0.0373447  0.03321707
  0.03491427 0.03738403 0.0321145  0.03497089 0.03878493 0.03054246
  0.04829046 0.03720326 0.03613466 0.02282985 0.0285391  0.04937737
  0.02913011 0.0163433 ]
 [0.03444697 0.0319929  0.03324633 0.0215425  0.02100074 0.02708208
  0.03290403 0.02922351 0.0284943  0.02544374 0.02893551 0.03112943
  0.03319559 0.01640746 0.01559097 0.04527476 0.04022678 0.03913501
  0.03287467 0.03351212 0.03077394 0.03601677 0.03009838 0.03287815
  0.04837411 0.02693531 0.03269247 0.02341533 0.02422232 0.03809476
  0.03918888 0.0239577 ]
 [0.03400828 0.03174969 0.02818185 0.01934621 0.01781918 0.02287512
  0.03052351 0.02604724 0.02522735 0.02192582 0.0274899  0.02516674
  0.02948312 0.01304096 0.01355248 0.0497677  0.03799713 0.05354072
  0.03662587 0.04282757 0.04030957 0.03379624 0.02499348 0.04397917
  0.06575159 0.03143303 0.03265889 0.02717321 0.01904192 0.0181973
  0.02913802 0.02213035]
 [0.03508978 0.03037694 0.02804845 0.01985818 0.0187553  0.02413479
  0.03174728 0.02791038 0.02642664 0.02303955 0.03409421 0.02917862
  0.03148735 0.01375326 0.01378502 0.05325194 0.03722382 0.05894988
  0.0427927  0.06762668 0.04435479 0.03041902 0.02248827 0.04585534
  0.05816973 0.03762162 0.03183612 0.02457101 0.01770451 0.01580841
  0.03043325 0.0263473 ]
 [0.03507352 0.02605874 0.02390365 0.01539386 0.01464381 0.01933052
  0.02735586 0.0228068  0.0225924  0.0179479  0.03167502 0.02245643
  0.0263162  0.01064152 0.01141977 0.04731484 0.03774446 0.04175889
  0.04228711 0.04773079 0.03906531 0.03054696 0.02100611 0.06374742
  0.04594733 0.04329079 0.02298716 0.02647763 0.0156187  0.01402281
  0.02675575 0.02595338]
 [0.03386299 0.03854316 0.03783528 0.02542312 0.02461942 0.04399458
  0.0474476  0.04144504 0.04361727 0.03114794 0.0346358  0.03646864
  0.03728724 0.01620209 0.0163961  0.03848128 0.04088285 0.0364999
  0.04958836 0.04597675 0.04533095 0.03631051 0.03735206 0.06928417
  0.05335217 0.05814014 0.027101   0.0411757  0.03039233 0.02034722
  0.02617204 0.02437717]
 [0.03502718 0.02778098 0.02771574 0.02137432 0.01807692 0.0245824
  0.02893011 0.02781871 0.02556077 0.02305649 0.03187732 0.0286448
  0.02911748 0.0148243  0.01383394 0.03259185 0.02953731 0.02912792
  0.03747941 0.03582422 0.03420813 0.03446687 0.02236604 0.04274674
  0.03342827 0.03845401 0.0234741  0.03228278 0.02395545 0.02275259
  0.0677959  0.03716024]
 [0.03497084 0.02664243 0.03091576 0.0263704  0.02272657 0.03083235
  0.03032816 0.03450812 0.03153481 0.0306056  0.03153594 0.03965815
  0.03623289 0.01959979 0.01494952 0.0234362  0.02308576 0.02507737
  0.02720165 0.02643779 0.02600266 0.03563572 0.02337778 0.02766256
  0.02731609 0.03182641 0.02827638 0.03163749 0.03174951 0.03000514
  0.10561708 0.03650686]
 [0.03523392 0.0339205  0.03756848 0.03428746 0.02519676 0.03928406
  0.03883138 0.04572361 0.03224891 0.03760995 0.03963013 0.05224616
  0.0489857  0.02437398 0.01696687 0.02707858 0.02567803 0.02904652
  0.0285481  0.02682528 0.02691022 0.03701071 0.02590044 0.03113962
  0.02489028 0.02323302 0.03596675 0.02505085 0.0306351  0.02872829
  0.11425282 0.03897147]
 [0.03543343 0.03424478 0.03706941 0.03798752 0.03072891 0.04237954
  0.0400475  0.04560444 0.03574228 0.0426314  0.03999048 0.05225544
  0.05099573 0.0296538  0.02109338 0.02715881 0.02613022 0.02874055
  0.02899933 0.02655118 0.02729403 0.03369731 0.02240918 0.02342883
  0.02069716 0.02014905 0.03333053 0.0277186  0.03038615 0.02726754
  0.0837695  0.05186565]
 [0.03523983 0.02417437 0.02513093 0.02179725 0.01473247 0.02338776
  0.02789402 0.02962914 0.0246924  0.02254806 0.02903456 0.02728656
  0.03113526 0.01417829 0.01276426 0.03269592 0.02923657 0.03264584
  0.03090755 0.02888102 0.0329701  0.03205181 0.0179103  0.0395118
  0.03944804 0.0259823  0.02619427 0.03806248 0.02159382 0.01917923
  0.07004245 0.05231679]
 [0.03504084 0.02550568 0.02417516 0.02095386 0.01370976 0.02152624
  0.02859879 0.02813725 0.02470236 0.02065715 0.02788397 0.02343338
  0.03027823 0.01261203 0.0123922  0.03656736 0.03476408 0.03917782
  0.03782735 0.0365775  0.04386776 0.02998271 0.01892922 0.05698107
  0.0511919  0.03732062 0.02416254 0.04105606 0.02031509 0.0118781
  0.04158038 0.04900935]
 [0.03577732 0.02370238 0.02364156 0.02219546 0.01522321 0.02266341
  0.02726202 0.0285383  0.02414003 0.02326471 0.03030527 0.02649407
  0.02993388 0.01435507 0.01247133 0.02905354 0.02914191 0.02943108
  0.03174387 0.02768701 0.03390884 0.02961906 0.01724163 0.0416576
  0.02864182 0.02413713 0.02323902 0.03468643 0.019323   0.01331109
  0.03534668 0.07727622]
 [0.03558735 0.02798635 0.02779735 0.02447832 0.01683976 0.02546553
  0.03486321 0.03556688 0.02876302 0.02522826 0.03778201 0.0308316
  0.03521917 0.01577186 0.01463001 0.03593307 0.03647672 0.03812167
  0.03754918 0.03393116 0.03823742 0.03187745 0.01964514 0.05058247
  0.03319483 0.0307104  0.02478381 0.03428296 0.02053007 0.01312112
  0.02925529 0.05832719]
 [0.03573458 0.02261247 0.02249589 0.01838656 0.01288292 0.01984164
  0.03055223 0.02882017 0.0237892  0.01857739 0.04054891 0.0229717
  0.02963982 0.01223508 0.01098731 0.03296917 0.03840782 0.03147531
  0.04157946 0.03435316 0.03928839 0.03018497 0.01786407 0.06883948
  0.03386499 0.03819973 0.01919234 0.03239924 0.01806651 0.0119952
  0.02640789 0.0440118 ]
 [0.03410763 0.03916287 0.04204757 0.03401292 0.02620916 0.03243075
  0.04538882 0.04910384 0.04472201 0.0327701  0.03624578 0.03276283
  0.037738   0.02194984 0.0201741  0.03447554 0.04845286 0.03945993
  0.047913   0.04216795 0.04342506 0.03683634 0.03595617 0.04291191
  0.03742978 0.04871979 0.03851902 0.05638159 0.02864659 0.01566572
  0.02023744 0.0279674 ]
 [0.03544772 0.02537958 0.02650416 0.02630362 0.01743566 0.02811794
  0.03236395 0.03541563 0.02994489 0.02642914 0.03028841 0.03100267
  0.03102885 0.01865613 0.01569848 0.02404549 0.02631517 0.02561983
  0.03304683 0.03132327 0.03188588 0.03332235 0.02178263 0.03300591
  0.02567814 0.03044851 0.02103938 0.03852577 0.02870095 0.01902613
  0.03419112 0.0429984 ]
 [0.03442265 0.03722266 0.03671943 0.05414563 0.05211316 0.048817
  0.03636085 0.03818398 0.04412983 0.05355315 0.0392487  0.04168006
  0.03933017 0.07103055 0.0932414  0.02823844 0.03041766 0.03191882
  0.02980032 0.02958303 0.0295373  0.03754346 0.04022909 0.01362517
  0.01654392 0.03127873 0.03841827 0.04462366 0.05283925 0.02544421
  0.00958772 0.06093847]
 [0.03403519 0.04832352 0.04248857 0.08030581 0.16748214 0.06076947
  0.04048989 0.04218984 0.04686929 0.08248574 0.0648357  0.0589261
  0.04094555 0.10255348 0.13580988 0.03970451 0.05371386 0.05373511
  0.04081653 0.03617621 0.04487716 0.03692947 0.05093398 0.01307813
  0.01331762 0.03012686 0.0534296  0.04353288 0.05235556 0.02337453
  0.00585653 0.03489647]
 [0.03422472 0.03537972 0.02941541 0.04152929 0.06830548 0.02791833
  0.02751482 0.03061914 0.02969358 0.04210117 0.03934143 0.03334405
  0.02880795 0.0323158  0.04696679 0.03043142 0.05538427 0.05966076
  0.05146034 0.04211076 0.0677962  0.03403581 0.04177597 0.03156595
  0.02473758 0.03440834 0.04157501 0.05362093 0.03294237 0.01519384
  0.00973397 0.01980353]
 [0.0342726  0.03850893 0.03270018 0.04500429 0.04358091 0.03190601
  0.03387692 0.03623147 0.03989749 0.04115208 0.03685269 0.03137366
  0.03200582 0.0337027  0.03955031 0.02590244 0.04118868 0.04465434
  0.03888475 0.04066237 0.04268724 0.04694397 0.04729686 0.0197626
  0.02017776 0.03300654 0.03553018 0.05858859 0.03804802 0.01188331
  0.00682663 0.01595217]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Julie', "'s", ' location', ' since', ' the', ' previous', ' context', ' sentences', '.', ' The', ' previous', ' information', ' about', ' Julie', ' was', ' that', ' she', ' moved', ' to', ' the', ' park', ' (', 'sentence', ' ', '2', ').', ' There', ' is', ' no', ' information', ' that', ' suggests', ' she', ' left', ' the', ' park', ' or', ' went', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(55, 38), x_tokens=38, y_tokens=55, max_supp_attn=0.0, attn_on_target=0.0182)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (55, 38)
DEBUG result.interpretability.attn_scores 2090 
 [[0.01663041 0.02340209 0.02211068 ... 0.00557623 0.00792308 0.0135705 ]
 [0.01687774 0.04543238 0.03779738 ... 0.01277428 0.02360886 0.02142968]
 [0.01745091 0.02261587 0.02433776 ... 0.0043717  0.00730269 0.00975095]
 ...
 [0.0175705  0.02173669 0.02064673 ... 0.00426534 0.00711394 0.00973628]
 [0.01800789 0.01472764 0.01422131 ... 0.00781322 0.01393881 0.01180011]
 [0.01803676 0.01483122 0.01386547 ... 0.00631903 0.01051944 0.01092513]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '11', ' contrad', 'icts', ' sentence', ' ', '10', ',', ' as', ' it', ' is', ' not', ' possible', ' for', ' Bill', ' to', ' be', ' in', ' both', ' the', ' bedroom', ' and', ' the', ' park', ' at', ' the', ' same', ' time', '.', ' However', ',', ' since', ' sentence', ' ', '11', ' is', ' the', ' latest', ' information', ' about', ' Bill', "'s", ' location', ',', ' it', ' is', ' more', ' reliable', '.', ' Therefore', ',', ' it', ' is', ' likely', ' that', ' Bill', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(70, 44), x_tokens=44, y_tokens=70, max_supp_attn=0.0857, attn_on_target=0.0143)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (70, 44)
DEBUG result.interpretability.attn_scores 3080 
 [[0.0128352  0.01780296 0.01717731 ... 0.00962701 0.01062315 0.01976224]
 [0.01308022 0.01383794 0.01349561 ... 0.02745386 0.01469778 0.01403073]
 [0.01348676 0.01721794 0.01806789 ... 0.02075646 0.01718888 0.0213824 ]
 ...
 [0.0137077  0.01794998 0.01814987 ... 0.00641678 0.00639742 0.00877817]
 [0.01410984 0.01392723 0.01350118 ... 0.00612381 0.00609157 0.00670855]
 [0.01399272 0.01424745 0.0136906  ... 0.0057001  0.00625626 0.00850961]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '13', ',', ' Bill', ' travelled', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' he', ' is', ' now', ' in', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' that', ' suggests', ' he', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02258717 0.04114611 0.04164856 ... 0.01623371 0.01817929 0.03187466]
 [0.02314877 0.02496912 0.02768623 ... 0.01980168 0.02319174 0.02733607]
 [0.02358137 0.03849908 0.04292558 ... 0.01325067 0.01627845 0.02564281]
 ...
 [0.02376411 0.03638817 0.03487148 ... 0.0143872  0.01409198 0.03681504]
 [0.02426548 0.02676731 0.02379456 ... 0.0166672  0.01875561 0.02804945]
 [0.02420279 0.02860794 0.02534032 ... 0.01437469 0.01600546 0.03551127]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' office', ',', ' with', ' no', ' information', ' about', ' him', ' being', ' in', ' the', ' park', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 26), x_tokens=26, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 26)
DEBUG result.interpretability.attn_scores 754 
 [[0.03238208 0.0576026  0.06170363 0.09268656 0.08822151 0.06085343
  0.04535969 0.0387888  0.04324901 0.06097026 0.04693186 0.02968661
  0.03198863 0.13756074 0.13836065 0.04760315 0.03436427 0.02336983
  0.02049863 0.02248386 0.0224374  0.0473994  0.0742374  0.01592239
  0.01247046 0.03987526]
 [0.03340405 0.03610919 0.03646857 0.06895443 0.06274635 0.05256082
  0.03175275 0.0281142  0.03452775 0.05251975 0.04038884 0.03208894
  0.03185524 0.1402586  0.1649345  0.04519023 0.03693424 0.02781791
  0.02272153 0.02340752 0.02120201 0.04019285 0.04450182 0.01101818
  0.01079797 0.02599824]
 [0.0339549  0.04050564 0.04650534 0.07198256 0.07014889 0.06724658
  0.04271989 0.03959484 0.0458272  0.06191453 0.04638166 0.05139866
  0.05001486 0.1120464  0.10250663 0.03777632 0.03396968 0.02842406
  0.02209376 0.02367742 0.02021306 0.03632113 0.04122391 0.01541805
  0.01481616 0.02411852]
 [0.03289617 0.04710909 0.05505    0.0546512  0.0566904  0.06103389
  0.04821858 0.04975538 0.0506738  0.05481028 0.04571128 0.05763021
  0.05142495 0.06641631 0.05899619 0.04744434 0.04169523 0.03675675
  0.02885042 0.03195725 0.0289594  0.04052274 0.05964017 0.03797082
  0.03686212 0.03956408]
 [0.03309704 0.06467438 0.07558235 0.04369234 0.03515228 0.05362108
  0.0603864  0.0597007  0.05738889 0.04331998 0.04121993 0.04954742
  0.05190895 0.02996413 0.02211129 0.04551587 0.03809971 0.03511456
  0.02949578 0.03367276 0.03151201 0.03773576 0.07572439 0.04657792
  0.0418176  0.0496017 ]
 [0.0341692  0.08306315 0.09422874 0.03913954 0.02696535 0.0485431
  0.05865436 0.05096034 0.06029489 0.03650997 0.03344622 0.03941209
  0.03825652 0.02108413 0.01731186 0.05007894 0.03735323 0.03094335
  0.02707173 0.03289298 0.02752527 0.0362593  0.08111279 0.03330029
  0.03348211 0.0405849 ]
 [0.03417667 0.05098549 0.06503095 0.03483762 0.02399858 0.04554617
  0.05461053 0.05196789 0.05431408 0.0345513  0.03232121 0.04028788
  0.03606898 0.01909444 0.01573387 0.04488834 0.03611495 0.03126756
  0.02775317 0.03232009 0.02860868 0.03694686 0.05929221 0.04126569
  0.04653686 0.0528374 ]
 [0.03485094 0.0388821  0.04187166 0.03296845 0.02290589 0.04667298
  0.04609318 0.04915085 0.04359976 0.03529029 0.03490569 0.04539746
  0.03932362 0.01742369 0.01366019 0.03252476 0.0300623  0.03071129
  0.0265752  0.02891532 0.02579698 0.03500982 0.03277348 0.03199933
  0.03351265 0.03588727]
 [0.03432946 0.02937988 0.02810459 0.02209616 0.0169648  0.02751719
  0.03642235 0.0351712  0.02969261 0.02412843 0.03552828 0.02795548
  0.03280292 0.01175037 0.01081862 0.03894733 0.03592318 0.03500551
  0.03267928 0.03555893 0.03852754 0.03384682 0.02892462 0.06915852
  0.05384659 0.0431063 ]
 [0.03443955 0.0232672  0.01967971 0.01834545 0.01375623 0.01862114
  0.02812287 0.02667758 0.02203344 0.01858599 0.02453447 0.01900613
  0.02369326 0.00912935 0.00883045 0.03090525 0.02801692 0.03304291
  0.03562016 0.03973507 0.04854149 0.0302639  0.02220191 0.07853916
  0.05992036 0.0442204 ]
 [0.03482687 0.02423899 0.02042577 0.01852035 0.01508923 0.01981788
  0.02622501 0.02540134 0.02227766 0.01960895 0.02686267 0.02222354
  0.02432716 0.00939537 0.00913755 0.03414909 0.02897613 0.02930159
  0.03074275 0.03161173 0.04075883 0.02998234 0.02084345 0.08306611
  0.05800355 0.03277683]
 [0.03463974 0.02028941 0.01729435 0.01388806 0.0131532  0.01548096
  0.0238297  0.02157949 0.01990271 0.01548291 0.02887669 0.01820558
  0.02208119 0.00745352 0.00780308 0.03491297 0.03567651 0.03108285
  0.03956988 0.03728599 0.04792443 0.02876044 0.02136965 0.08889697
  0.05172319 0.03792158]
 [0.03399793 0.02516394 0.02037502 0.01569186 0.01481265 0.01752478
  0.02587037 0.02211822 0.02323157 0.01670259 0.02736364 0.01840225
  0.02230858 0.00813052 0.0088989  0.03485234 0.03305355 0.02990563
  0.03545735 0.03739784 0.0447519  0.03326317 0.02819746 0.09370961
  0.06588635 0.07820329]
 [0.0350503  0.02180367 0.0186738  0.01573779 0.01423079 0.01713677
  0.02185317 0.02119155 0.02033213 0.01708235 0.02635591 0.01911173
  0.02067872 0.00843278 0.00837291 0.02865018 0.02795249 0.02530749
  0.03063722 0.02958641 0.03786781 0.02982718 0.02233471 0.05469715
  0.0473722  0.04604615]
 [0.03563265 0.02324086 0.0236394  0.02068633 0.0173381  0.02594598
  0.02780212 0.03172358 0.0293894  0.02569537 0.02678014 0.03226977
  0.02974265 0.01212076 0.00966977 0.02272008 0.02792276 0.02716737
  0.02684534 0.02760519 0.02546807 0.03204636 0.0205452  0.0218979
  0.03844568 0.03359909]
 [0.03548146 0.03068925 0.02513761 0.02140361 0.0186167  0.02545758
  0.03252618 0.0365338  0.02929597 0.02395223 0.02805863 0.02874416
  0.03144238 0.012186   0.01008564 0.02404091 0.02917095 0.02790964
  0.02722913 0.03183595 0.03309591 0.03319507 0.0228325  0.02510414
  0.05591249 0.04074482]
 [0.03518211 0.03725367 0.03207647 0.02631151 0.02147313 0.03279482
  0.03913236 0.04973756 0.03966282 0.03261144 0.03732077 0.05029782
  0.04929204 0.01517089 0.01143689 0.0340352  0.03027275 0.03820281
  0.03413235 0.03807259 0.03059448 0.03279671 0.02448921 0.01873709
  0.03233238 0.02453565]
 [0.03576808 0.03154786 0.03327422 0.02964175 0.022055   0.04791258
  0.04048071 0.04791711 0.04457334 0.03976871 0.03382267 0.0761242
  0.06108467 0.01826088 0.0116593  0.02474672 0.02679427 0.02909616
  0.02592127 0.02783361 0.02314325 0.03205692 0.02120561 0.01336993
  0.02160582 0.01806957]
 [0.03498222 0.02291693 0.02268323 0.01796561 0.01447714 0.01992504
  0.02813376 0.03034179 0.02610806 0.02146498 0.03145972 0.02604879
  0.03458776 0.00995929 0.00895302 0.03290526 0.03175122 0.03973341
  0.0404236  0.04365864 0.04437654 0.03150653 0.01766495 0.02842098
  0.0355031  0.02521531]
 [0.03515198 0.02438729 0.02132612 0.0175045  0.01404489 0.01757667
  0.0282318  0.02905047 0.02418876 0.0188614  0.02814116 0.02304786
  0.02990272 0.00908151 0.00836263 0.03917608 0.03027046 0.04573745
  0.03871752 0.05224933 0.04894686 0.02843545 0.01714657 0.02965894
  0.04635901 0.026474  ]
 [0.03561728 0.02337355 0.01990505 0.01760167 0.01491996 0.01854783
  0.02476531 0.02774408 0.02483618 0.02149235 0.03063442 0.02703612
  0.02927517 0.00961789 0.0085964  0.03342307 0.03028037 0.03440231
  0.03624658 0.03601157 0.03887572 0.0270946  0.01544512 0.02008712
  0.0299018  0.01901243]
 [0.03527981 0.01953813 0.01738977 0.01370785 0.01250937 0.01486059
  0.02373771 0.02343696 0.02253334 0.01651613 0.03155528 0.01992417
  0.02352303 0.00767605 0.00738883 0.03117474 0.03575581 0.03322636
  0.0479564  0.04333623 0.04572663 0.02692887 0.01589746 0.02641168
  0.03177369 0.02615417]
 [0.03408773 0.02275302 0.01957009 0.0162837  0.0149653  0.01699691
  0.02335402 0.02257471 0.02561636 0.01897088 0.02746644 0.0201479
  0.02342521 0.00916487 0.00918355 0.03160913 0.03837916 0.03989953
  0.06087713 0.06043359 0.05500946 0.03062254 0.02320673 0.0288788
  0.03236831 0.04043431]
 [0.03547889 0.0236565  0.0217301  0.02039129 0.01605951 0.02162371
  0.02660749 0.02711213 0.02917632 0.02370077 0.03027969 0.02809605
  0.02930692 0.01260351 0.01078183 0.02451957 0.02880915 0.03192529
  0.04349345 0.04129883 0.03711363 0.03160162 0.01925775 0.01675709
  0.02411186 0.02463693]
 [0.03484964 0.03196057 0.0323688  0.03971196 0.03234421 0.04182284
  0.03849692 0.04000061 0.04118875 0.04557972 0.03777685 0.05858058
  0.05397708 0.0296568  0.01811059 0.02509706 0.0334977  0.0379158
  0.02936995 0.02798694 0.02511482 0.03806153 0.0272814  0.01846386
  0.02992066 0.02789529]
 [0.0343387  0.04011049 0.03619552 0.05947784 0.06359572 0.051337
  0.03450876 0.03101349 0.03597664 0.05511135 0.0411374  0.03284264
  0.03427398 0.09735318 0.11131299 0.03342403 0.032211   0.0261884
  0.02192735 0.02305833 0.02085793 0.0403486  0.04021767 0.01118665
  0.01056533 0.02560044]
 [0.03398355 0.03869574 0.03505563 0.06486098 0.12746651 0.0467384
  0.02996988 0.02953712 0.03540954 0.06510485 0.04718379 0.03768228
  0.03088216 0.0911355  0.11225648 0.03663644 0.04988627 0.04533841
  0.03337019 0.02810562 0.02842764 0.03486621 0.03875979 0.01017834
  0.01028464 0.02385666]
 [0.03388224 0.02908718 0.02690582 0.0418744  0.06926627 0.02996256
  0.02236999 0.02556173 0.02981718 0.04986998 0.03911615 0.03689294
  0.031356   0.03135075 0.03506961 0.02802457 0.05672771 0.06998777
  0.07918306 0.04238264 0.0436887  0.02979196 0.03305468 0.01625385
  0.0194977  0.02669723]
 [0.0340688  0.0377142  0.03174759 0.04938466 0.06603201 0.03632076
  0.02976412 0.02754257 0.03488177 0.04982208 0.03843854 0.03191074
  0.03119466 0.03652176 0.03965585 0.02502808 0.04007799 0.04521795
  0.04453974 0.03562772 0.03493352 0.05431519 0.05061738 0.01305348
  0.0143693  0.02633208]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' explicitly', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.1905, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.04504202 0.05743419 0.06189812 0.08386311 0.06975099 0.06541966
  0.05235682 0.05643199 0.06747538 0.06727321 0.04927963 0.04520042
  0.05384713 0.13256948 0.12044566 0.04137346 0.0295949  0.03295944
  0.02957922 0.03618991 0.03201482 0.04763551 0.06433699 0.0328654
  0.02123173 0.05451141 0.06208517 0.05891291 0.12431005 0.01800715
  0.02181773 0.08467193]
 [0.04613423 0.05762478 0.05316585 0.09418438 0.09199438 0.10811514
  0.06434266 0.06624763 0.07286534 0.09025812 0.07358929 0.07956509
  0.08733816 0.16743898 0.12106323 0.04591005 0.02890254 0.0398804
  0.03280342 0.03982658 0.03456336 0.05371783 0.05149001 0.02864239
  0.02483128 0.04659196 0.05350987 0.05278828 0.11405684 0.02447292
  0.03322962 0.0991736 ]
 [0.04713073 0.05353595 0.05903234 0.08428326 0.07002738 0.0792323
  0.05547528 0.05875633 0.06542219 0.07051205 0.05357591 0.06089717
  0.06454534 0.13802013 0.09239332 0.03973313 0.02785195 0.03155758
  0.02807836 0.03257762 0.02868226 0.04705213 0.04629314 0.02976117
  0.0233672  0.03992382 0.04791877 0.04325637 0.09516385 0.03023554
  0.03907069 0.08404923]
 [0.04542156 0.06650125 0.07042413 0.05319192 0.04026629 0.05385343
  0.05976971 0.06733444 0.06143152 0.04976226 0.0460222  0.05423773
  0.05724278 0.03820194 0.03355248 0.05378826 0.04124529 0.04146681
  0.03780145 0.04345106 0.03928072 0.05224016 0.0725073  0.06374434
  0.06011225 0.06022647 0.06678443 0.05485641 0.08446699 0.09683768
  0.07865749 0.05924901]
 [0.04627912 0.06951538 0.06823913 0.03505529 0.02513286 0.04043357
  0.05534197 0.05487979 0.05622993 0.03250482 0.037379   0.03891109
  0.04643011 0.0234861  0.0226147  0.04962775 0.03454363 0.033812
  0.03584109 0.04062904 0.037282   0.04887445 0.07038812 0.05746443
  0.05120808 0.05720732 0.07271854 0.04094815 0.06869186 0.12247272
  0.07484598 0.03512004]
 [0.04733792 0.08867658 0.08196945 0.03704352 0.02621298 0.04176695
  0.05755822 0.05295474 0.06382915 0.03321364 0.03602761 0.03881047
  0.04183391 0.0212243  0.02158751 0.05894799 0.03880176 0.03836763
  0.0391702  0.04774019 0.04082414 0.04570115 0.09634165 0.05924878
  0.05020433 0.0543048  0.0686024  0.03682404 0.04792643 0.12641853
  0.06032524 0.02833864]
 [0.04753586 0.0623189  0.06516865 0.0372611  0.02714607 0.03843868
  0.05839616 0.05499879 0.05631604 0.03428722 0.03711489 0.04045971
  0.04156175 0.02285141 0.02351179 0.05964237 0.04306869 0.03824807
  0.04240314 0.04615722 0.04114713 0.04913293 0.07550308 0.0763552
  0.06693245 0.0577405  0.08492977 0.04070719 0.04035361 0.09687585
  0.0684051  0.03333136]
 [0.04851593 0.03627004 0.03964488 0.02690732 0.0213201  0.02825061
  0.03652646 0.03757021 0.04664749 0.02720937 0.03006299 0.02732126
  0.03087117 0.01626346 0.01946722 0.04649982 0.03646099 0.03350529
  0.03988809 0.04398888 0.03650125 0.04107062 0.04859423 0.06389848
  0.05409304 0.04754335 0.04946233 0.03096638 0.02566527 0.0364772
  0.03184345 0.02246827]
 [0.04761901 0.04765771 0.05105839 0.03696349 0.02713039 0.04392205
  0.04860991 0.05110902 0.04413146 0.03701126 0.04108763 0.04637895
  0.04260715 0.02007544 0.02239427 0.05341283 0.04891767 0.04281756
  0.04612082 0.04822801 0.04480843 0.05378968 0.04781124 0.06758048
  0.06945182 0.04945949 0.04757576 0.03750186 0.03493827 0.06571258
  0.06478886 0.02612909]
 [0.04843342 0.05809772 0.06151353 0.05737094 0.03700633 0.06183816
  0.06134799 0.07208625 0.05624877 0.06298666 0.0608259  0.08523914
  0.07142566 0.0343579  0.02855969 0.05054482 0.0473832  0.05060406
  0.04714957 0.04910242 0.04468022 0.05214991 0.04383672 0.05198075
  0.05689159 0.04352782 0.04620371 0.04347393 0.03903634 0.06844001
  0.0854715  0.03905251]
 [0.04926323 0.04200182 0.04473133 0.03953693 0.0288084  0.0436981
  0.05064048 0.04790413 0.03981249 0.04013369 0.04912335 0.04980582
  0.04792318 0.02235135 0.0223704  0.04679824 0.04740669 0.04214608
  0.04553019 0.04590478 0.04264699 0.05110508 0.03383341 0.05171125
  0.05950734 0.03737454 0.03448986 0.03608035 0.03056758 0.04743093
  0.06656734 0.03390398]
 [0.04850709 0.03096004 0.02958518 0.02475404 0.01917946 0.02851074
  0.03638364 0.0329136  0.02972953 0.02695326 0.04021605 0.03348107
  0.03628641 0.01354903 0.01631179 0.04600053 0.05903124 0.04540296
  0.05464419 0.04986463 0.05010766 0.04835646 0.02700247 0.0521604
  0.0807158  0.03882913 0.02834994 0.03376432 0.02234171 0.03605639
  0.04822462 0.02501016]
 [0.04813445 0.03060533 0.02722029 0.02304841 0.01733875 0.02706712
  0.0363027  0.03201718 0.02828988 0.02549682 0.03634235 0.02915324
  0.03523083 0.01235658 0.01434603 0.04529332 0.06674062 0.0514003
  0.06585066 0.05829532 0.06699403 0.04445165 0.02318008 0.05694587
  0.1027718  0.04984605 0.02601746 0.03748538 0.01691831 0.03907055
  0.04701456 0.02120213]
 [0.04908926 0.03038121 0.02846709 0.02363112 0.01944802 0.0286365
  0.03537192 0.03351914 0.02892763 0.02782506 0.04567884 0.03862888
  0.03721735 0.01304    0.0147068  0.04748556 0.07393969 0.04859571
  0.07125378 0.05463182 0.05453081 0.04245872 0.02175028 0.05008003
  0.05381552 0.03775443 0.02673778 0.03659434 0.01586684 0.0337762
  0.04442356 0.02463178]
 [0.0489241  0.02837474 0.02699698 0.01953713 0.01727602 0.02498437
  0.03726918 0.03175275 0.0277786  0.02414127 0.05418998 0.03513493
  0.03769553 0.01090257 0.013266   0.06125062 0.0684683  0.05466671
  0.06806554 0.05834898 0.06034369 0.04124805 0.02241305 0.0531567
  0.05066632 0.05059917 0.02130104 0.04224137 0.01440209 0.0346139
  0.03925551 0.02642046]
 [0.04723317 0.03426357 0.03217803 0.02501663 0.0221395  0.03187346
  0.04638651 0.04166094 0.03887874 0.03023091 0.03908255 0.0345717
  0.04323541 0.01419014 0.01663619 0.05270177 0.04125997 0.04831499
  0.05869993 0.0585807  0.05764066 0.04526831 0.03263232 0.05218899
  0.04641532 0.06126285 0.02955048 0.06190328 0.0257737  0.03519911
  0.04602593 0.03732149]
 [0.04937759 0.03288534 0.03566721 0.03158903 0.02424093 0.03891931
  0.04180166 0.04655025 0.03817371 0.03814434 0.04416678 0.04566767
  0.04361439 0.01945486 0.01918827 0.03686704 0.03320706 0.040577
  0.04469184 0.04287544 0.0436258  0.04292461 0.02651523 0.03062885
  0.03177946 0.0394223  0.02991064 0.04209402 0.02714984 0.03285433
  0.0762827  0.05853374]
 [0.04778387 0.04014535 0.04221137 0.0690402  0.05874004 0.05857192
  0.04215874 0.04257322 0.05103911 0.07018869 0.05021724 0.05304185
  0.05175124 0.08653969 0.10784835 0.03483524 0.03317064 0.04230637
  0.03497069 0.03870826 0.03715462 0.04681409 0.04446226 0.02593933
  0.02074813 0.04447255 0.04785017 0.05801233 0.05667153 0.0163068
  0.02522822 0.12178047]
 [0.04739762 0.04738947 0.04220206 0.08045687 0.16842405 0.06742144
  0.04430833 0.04093904 0.04567337 0.08348811 0.0651904  0.06324612
  0.0454712  0.10850511 0.15212728 0.04773841 0.05368729 0.06971987
  0.04813849 0.04787678 0.05493598 0.04538103 0.05229428 0.02578723
  0.01869077 0.04388605 0.06688733 0.05574745 0.05062852 0.01122725
  0.01351904 0.06784388]
 [0.04724599 0.0403924  0.03795922 0.05664568 0.10777274 0.03920529
  0.03532669 0.03701755 0.03528902 0.0634549  0.05819794 0.05104217
  0.03959303 0.0373839  0.06268144 0.04716725 0.09117715 0.10595004
  0.07712319 0.06420644 0.09315735 0.04212805 0.04464631 0.03994561
  0.03274499 0.04146172 0.04946233 0.07450099 0.02962702 0.01479091
  0.01806723 0.03433497]
 [0.04759378 0.04496829 0.04066682 0.06061963 0.08064431 0.04984125
  0.044325   0.04078303 0.04581061 0.06492428 0.0526295  0.04920557
  0.04427826 0.04723762 0.05492751 0.03438152 0.05514073 0.06770111
  0.05219617 0.05281592 0.05907806 0.05849956 0.0541677  0.02991429
  0.02382088 0.04405433 0.03965219 0.08134069 0.03544325 0.01272357
  0.01693563 0.03743329]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Julie', ' went', ' back', ' to', ' the', ' park', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.03108088 0.04151713 0.04219762 ... 0.02145892 0.02573328 0.04229637]
 [0.03167826 0.0468533  0.0490161  ... 0.0273158  0.0294084  0.04553761]
 [0.03239778 0.04435334 0.04900349 ... 0.0177282  0.01968351 0.04182189]
 ...
 [0.0325804  0.04708271 0.04394324 ... 0.01680443 0.01765697 0.05173956]
 [0.03289298 0.03529632 0.03160722 ... 0.02696836 0.02616097 0.05057739]
 [0.03279987 0.04220536 0.03565194 ... 0.02135029 0.02418665 0.03985503]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Mary', ' went', ' to', ' the', ' kitchen', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.069, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03231339 0.04726502 0.04610258 ... 0.01512517 0.06384047 0.06862215]
 [0.03305551 0.04254421 0.04257971 ... 0.03249582 0.02731373 0.03069132]
 [0.03370772 0.05024458 0.0543254  ... 0.02840806 0.0643221  0.05268666]
 ...
 [0.03391874 0.04846538 0.04580779 ... 0.01148    0.11192925 0.05997369]
 [0.03443068 0.03527084 0.03116853 ... 0.0133154  0.08883334 0.03597661]
 [0.0340855  0.04018144 0.03544406 ... 0.01005531 0.08329877 0.06494893]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ' do', ' not', ' provide', ' any', ' information', ' about', ' Mary', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' to', ' a', ' previous', ' context', ' sentence', ' (', '10', ')', ' which', ' states', ' that', ' Mary', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 50), x_tokens=50, y_tokens=47, max_supp_attn=0.0851, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 50)
DEBUG result.interpretability.attn_scores 2350 
 [[0.01975948 0.0239177  0.02273756 ... 0.02479843 0.02544222 0.06714801]
 [0.02023258 0.01988371 0.01910995 ... 0.01721911 0.0185485  0.04223939]
 [0.02064696 0.02479272 0.02477123 ... 0.01982725 0.01564846 0.0519674 ]
 ...
 [0.02093343 0.02018012 0.02109697 ... 0.02762562 0.02076378 0.02472072]
 [0.02161398 0.01334141 0.01426681 ... 0.02840318 0.02906762 0.01445518]
 [0.02138091 0.01639685 0.01713848 ... 0.02187037 0.03002123 0.01854725]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' "', 'Bill', ' is', ' in', ' the', ' office', '".', ' This', ' contrad', 'icts', ' the', ' information', ' in', ' sentence', ' ', '1', ',', ' which', ' implies', ' that', ' Bill', ' was', ' in', ' the', ' park', ' at', ' some', ' point', '.', ' However', ',', ' sentence', ' ', '2', ' provides', ' the', ' most', ' up', '-to', '-date', ' information', ' about', ' Bill', "'s", ' location', ',', ' which', ' is', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(70, 26), x_tokens=26, y_tokens=70, max_supp_attn=0.1571, attn_on_target=0.0143)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (70, 26)
DEBUG result.interpretability.attn_scores 1820 
 [[0.01289887 0.02349116 0.02680139 ... 0.00993304 0.00670908 0.01417257]
 [0.01276498 0.04234466 0.03342036 ... 0.02036672 0.0146738  0.01961824]
 [0.01403861 0.03129816 0.01851144 ... 0.00497913 0.00289565 0.00666961]
 ...
 [0.01384882 0.0142893  0.01423018 ... 0.00522755 0.00288663 0.00898956]
 [0.01387777 0.01157056 0.01116535 ... 0.00799349 0.00623398 0.01361516]
 [0.01395409 0.01509282 0.01323174 ... 0.00686835 0.00483744 0.01006349]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' "', 'Fred', ' is', ' in', ' the', ' school', '",', ' but', ' sentence', ' ', '5', ' updates', ' the', ' information', ' by', ' saying', ' "', 'Fred', ' went', ' to', ' the', ' cinema', '".', ' This', ' implies', ' that', ' Fred', "'s", ' location', ' has', ' changed', ' from', ' the', ' school', ' to', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0962, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01769499 0.02914623 0.03122722 ... 0.04696664 0.00635709 0.01404922]
 [0.01815826 0.02880324 0.03158275 ... 0.05178679 0.00967966 0.01968541]
 [0.01851718 0.02645093 0.03202543 ... 0.05034127 0.01428351 0.02420716]
 ...
 [0.0185428  0.02824875 0.02836318 ... 0.01873075 0.00572619 0.00953403]
 [0.01898411 0.01959501 0.01849449 ... 0.00967278 0.00763411 0.00872384]
 [0.01893607 0.02311729 0.02145361 ... 0.00926729 0.00516137 0.00901132]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' bedroom', ' (', 'sentence', ' ', '8', ')', ' and', ' Julie', ' travelling', ' to', ' the', ' park', ' (', 'sentence', ' ', '7', ').\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 38), x_tokens=38, y_tokens=45, max_supp_attn=0.0444, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 38)
DEBUG result.interpretability.attn_scores 1710 
 [[0.02048126 0.03061547 0.02953148 ... 0.01783662 0.01985519 0.00978971]
 [0.02082041 0.03087204 0.02926851 ... 0.02440401 0.02397164 0.01689754]
 [0.02142225 0.0310852  0.03309451 ... 0.0268113  0.02521184 0.01267088]
 ...
 [0.02147382 0.03154441 0.02720582 ... 0.01252259 0.01384482 0.0091291 ]
 [0.02189714 0.02460895 0.0200011  ... 0.01418303 0.0142036  0.01291671]
 [0.02187348 0.02672866 0.02266369 ... 0.0137415  0.01582844 0.01332036]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', ' being', ' in', ' the', ' cinema', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Mary', ' travelling', ' to', ' the', ' office', ' (', 'sentence', ' ', '10', ')', ' and', ' then', ' moving', ' to', ' the', ' bedroom', ' (', 'sentence', ' ', '11', '),', ' but', ' do', ' not', ' mention', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 44), x_tokens=44, y_tokens=52, max_supp_attn=0.0192, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 44)
DEBUG result.interpretability.attn_scores 2288 
 [[0.01777838 0.02755596 0.02690227 ... 0.01741849 0.01463596 0.01891837]
 [0.01821627 0.02344861 0.02005344 ... 0.01707524 0.01928031 0.02377381]
 [0.01862544 0.02785167 0.0290407  ... 0.01556816 0.01254263 0.01788762]
 ...
 [0.01874526 0.02579548 0.02469195 ... 0.015384   0.01193433 0.02054863]
 [0.01902473 0.01962943 0.01743318 ... 0.01619704 0.0149237  0.01903573]
 [0.01895661 0.02180894 0.0187551  ... 0.01620206 0.0145201  0.01789186]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' park', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' either', ' in', ' the', ' school', ' or', ' the', ' bedroom', ' (', 'sentence', ' ', '14', '),', ' but', ' do', ' not', ' mention', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(45, 50), x_tokens=50, y_tokens=45, max_supp_attn=0.0, attn_on_target=0.0222)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (45, 50)
DEBUG result.interpretability.attn_scores 2250 
 [[0.02064277 0.03613074 0.03890732 ... 0.01260299 0.00884505 0.01601165]
 [0.02096113 0.03477969 0.03611901 ... 0.02144352 0.01908321 0.0180929 ]
 [0.02160168 0.03388816 0.03909218 ... 0.01918661 0.01533946 0.02517446]
 ...
 [0.02162825 0.039149   0.03391994 ... 0.00933387 0.0082558  0.01077362]
 [0.02212926 0.0276101  0.02273204 ... 0.01236624 0.01033595 0.01290141]
 [0.02196264 0.03282381 0.02626364 ... 0.00897237 0.00800944 0.01084676]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' "', 'Jul', 'ie', ' went', ' back', ' to', ' the', ' school', '",', ' which', ' implies', ' that', ' Julie', ' was', ' in', ' the', ' school', ' previously', ' and', ' now', ' she', ' has', ' returned', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 26), x_tokens=26, y_tokens=44, max_supp_attn=0.1364, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 26)
DEBUG result.interpretability.attn_scores 1144 
 [[0.0206504  0.04360321 0.0538764  ... 0.02275236 0.01302854 0.01998185]
 [0.02066742 0.07032692 0.05060589 ... 0.03536644 0.01930664 0.02600641]
 [0.0226057  0.05335534 0.03272482 ... 0.00499049 0.00372987 0.0097051 ]
 ...
 [0.02232558 0.02637294 0.02626641 ... 0.00621393 0.00430466 0.01329781]
 [0.02226575 0.02109225 0.02128389 ... 0.01585864 0.00967909 0.01639463]
 [0.02241504 0.02703251 0.02540821 ... 0.01114295 0.00702794 0.0154153 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '5', ' explicitly', ' states', ' "', 'Jul', 'ie', ' is', ' in', ' the', ' bedroom', '",', ' which', ' directly', ' answers', ' the', ' question', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 32), x_tokens=32, y_tokens=26, max_supp_attn=0.1154, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 32)
DEBUG result.interpretability.attn_scores 832 
 [[0.03592081 0.05098401 0.04795558 0.05726894 0.06582718 0.05999107
  0.04360957 0.0388088  0.05285358 0.05196397 0.0367104  0.03722427
  0.04227782 0.09967097 0.09983452 0.04047997 0.03102792 0.03143941
  0.03164978 0.03358356 0.030528   0.04001108 0.07244578 0.01432048
  0.02697249 0.0484225  0.0419112  0.04480668 0.12250687 0.04610556
  0.0147278  0.01395786]
 [0.03697946 0.04843464 0.04634361 0.07052027 0.0915198  0.08560937
  0.04793429 0.04252452 0.05562906 0.07319405 0.05375264 0.05774055
  0.0599626  0.14713745 0.13097274 0.04435839 0.03288974 0.03765571
  0.03404596 0.03451758 0.03160798 0.04145123 0.05106083 0.0136844
  0.02137706 0.04176624 0.04802749 0.03756313 0.09128742 0.06202512
  0.01716283 0.02265815]
 [0.03764084 0.0439258  0.04708738 0.05668269 0.06751972 0.0652612
  0.04605906 0.04085285 0.05113507 0.05565606 0.04091568 0.05207646
  0.05278525 0.10180924 0.07961098 0.03783348 0.02958369 0.03114302
  0.03049445 0.03070817 0.02755272 0.03911519 0.0475636  0.01618016
  0.02467974 0.03701383 0.0429597  0.03145137 0.06221467 0.08037002
  0.02412475 0.03232366]
 [0.03641554 0.04664273 0.04559127 0.03337348 0.03682506 0.04146422
  0.04320813 0.04314514 0.04186853 0.03360627 0.03434348 0.03992998
  0.04241141 0.028702   0.02771222 0.0408293  0.03259557 0.03254262
  0.03389297 0.03528307 0.03220987 0.0420781  0.05267992 0.03307557
  0.04594341 0.04385072 0.04127044 0.03503405 0.04528289 0.10405343
  0.04043445 0.05078295]
 [0.03750815 0.04606822 0.04690001 0.02554761 0.02448283 0.03300418
  0.045574   0.03522922 0.03969241 0.02478814 0.03004134 0.02845729
  0.03155474 0.01879095 0.01980696 0.04439345 0.03237827 0.02939677
  0.03475581 0.03581827 0.03218426 0.03469    0.05071582 0.03089201
  0.04472439 0.03917983 0.04051319 0.02650391 0.0311727  0.09403376
  0.04711681 0.04700291]
 [0.03848996 0.0201744  0.0204349  0.0133899  0.01318366 0.01843512
  0.02166633 0.01830831 0.0222188  0.01492024 0.02069158 0.01627635
  0.01946719 0.01012626 0.01097288 0.02578139 0.02098191 0.02178088
  0.02645919 0.02704671 0.02524933 0.0238611  0.02323013 0.02596256
  0.03427595 0.02982047 0.01855277 0.01852417 0.0176695  0.03714909
  0.02666678 0.02370991]
 [0.03758027 0.03824741 0.03895461 0.02450515 0.02205742 0.03414343
  0.0379932  0.03391792 0.03278354 0.02583792 0.03131113 0.03200428
  0.03158718 0.01718552 0.01936214 0.04158553 0.03935327 0.03386162
  0.04034127 0.04013843 0.03954007 0.04542096 0.04614232 0.04826696
  0.05585146 0.04384752 0.03535802 0.03202423 0.03484232 0.06687639
  0.06366173 0.05541956]
 [0.03851741 0.05441737 0.05531598 0.04090517 0.03185017 0.0513816
  0.05364544 0.05235836 0.04604917 0.04594674 0.04896615 0.06356256
  0.05501613 0.02829    0.02646996 0.0485663  0.04368447 0.04451504
  0.04378254 0.04274623 0.04070286 0.04515133 0.04736931 0.05477267
  0.04577509 0.03936526 0.03963943 0.03661173 0.03868723 0.05104857
  0.04683243 0.06321717]
 [0.03909046 0.03703001 0.03820655 0.02741507 0.02284263 0.03521906
  0.04235137 0.03525125 0.03251246 0.0284914  0.03820762 0.03365622
  0.03687334 0.01882778 0.0205197  0.0443392  0.03926606 0.03599958
  0.03997678 0.03825109 0.03840204 0.04280378 0.03621112 0.04733308
  0.05029324 0.03218789 0.03104749 0.03179044 0.03009096 0.05829418
  0.08464773 0.06662577]
 [0.03899643 0.02774899 0.0255497  0.0199239  0.0168208  0.02395973
  0.03203301 0.02424825 0.02464113 0.01905234 0.04073669 0.02443175
  0.02584874 0.01270069 0.0173841  0.04108998 0.04323657 0.03606025
  0.04239096 0.0408859  0.04247608 0.03629122 0.02534731 0.04414275
  0.06099151 0.02841377 0.0223973  0.02615013 0.02098997 0.034324
  0.09217262 0.04648997]
 [0.03801271 0.02558092 0.02430962 0.02072332 0.01526784 0.025025
  0.0290557  0.02687687 0.02821991 0.01993237 0.02957595 0.02171551
  0.02842121 0.01345334 0.01441501 0.03097975 0.02620447 0.03269775
  0.03431933 0.03747017 0.03786077 0.03588442 0.02395548 0.03367027
  0.05420366 0.03297596 0.02038766 0.02867147 0.02508469 0.02470652
  0.10802443 0.0289858 ]
 [0.03876405 0.02588869 0.02311245 0.01821418 0.01335621 0.02143267
  0.0367127  0.0312072  0.02448693 0.01760052 0.03552484 0.02167627
  0.03168833 0.0112092  0.01301891 0.04741045 0.05685841 0.04823286
  0.04788979 0.04319265 0.05336125 0.03222297 0.0187532  0.05297508
  0.06298127 0.02736034 0.01357235 0.03032579 0.01820197 0.01329314
  0.06703375 0.02955811]
 [0.03941026 0.02331709 0.02236296 0.01880683 0.014376   0.02231448
  0.02898694 0.0267988  0.02477045 0.01994577 0.03535848 0.02554294
  0.02952806 0.01228524 0.01325803 0.04192759 0.05865888 0.04378795
  0.0540231  0.0422329  0.04781195 0.03107073 0.01794895 0.07005313
  0.04403693 0.02528226 0.0149558  0.03537389 0.01911499 0.01517289
  0.05385605 0.03385867]
 [0.03908037 0.02090109 0.01939792 0.01621028 0.01212121 0.01884939
  0.02764324 0.02400801 0.0226391  0.01675623 0.03603654 0.0203172
  0.02660445 0.01057394 0.01167122 0.04061758 0.05631368 0.04016372
  0.05036809 0.04516233 0.04976616 0.03144448 0.01651591 0.08749197
  0.04355853 0.03264666 0.01268404 0.03475072 0.01743321 0.01104582
  0.04219759 0.02596505]
 [0.03817438 0.0273677  0.0237518  0.01988126 0.01517478 0.02442283
  0.0350828  0.02982382 0.02800852 0.01975591 0.03240825 0.02234337
  0.02925135 0.01311154 0.01399497 0.03359117 0.03467322 0.03391362
  0.04073951 0.04346926 0.04219007 0.0389845  0.03442011 0.17227763
  0.09556513 0.0525355  0.01692175 0.03282623 0.03108798 0.02082551
  0.04224193 0.02851077]
 [0.0395424  0.02360434 0.02289075 0.02079154 0.01499447 0.02340638
  0.02965785 0.02855055 0.02550411 0.02121443 0.03288627 0.02419248
  0.02717505 0.01462145 0.01430438 0.02991123 0.03208411 0.03020533
  0.03556692 0.03911564 0.03824751 0.03349262 0.01902638 0.04915946
  0.0303797  0.02730279 0.01580043 0.02944483 0.0225611  0.02004299
  0.02964647 0.06642869]
 [0.03909573 0.03285287 0.03648732 0.03584212 0.02477752 0.03881731
  0.03990187 0.04416416 0.03938402 0.03979996 0.04134316 0.04604007
  0.04345337 0.02676628 0.02145254 0.03107965 0.03047728 0.03522049
  0.0351113  0.03573593 0.03388917 0.04182971 0.03016337 0.03080294
  0.03371959 0.03443701 0.02828059 0.03449061 0.03402206 0.03725481
  0.03037042 0.0795704 ]
 [0.03949687 0.04036248 0.04561129 0.0494452  0.03082456 0.04857491
  0.04752542 0.05541341 0.04467386 0.05716596 0.04804171 0.05797312
  0.05714776 0.03462883 0.02292297 0.0300548  0.02775513 0.03296813
  0.03027283 0.03114559 0.02853623 0.04017333 0.03297529 0.02649069
  0.02718333 0.03140941 0.03157174 0.02880617 0.03438507 0.03357915
  0.02721433 0.09149294]
 [0.03987631 0.04724972 0.0557937  0.05569566 0.0323019  0.05388055
  0.05026112 0.06582582 0.0537862  0.06812161 0.04858711 0.08639117
  0.06643385 0.0378673  0.02631958 0.03627073 0.03325856 0.03752658
  0.03420233 0.03519301 0.0315542  0.04119135 0.03624056 0.02460582
  0.02677936 0.03495333 0.03812492 0.03612402 0.0326759  0.02879289
  0.02250428 0.04974445]
 [0.03985224 0.04975464 0.05932086 0.06784271 0.03598363 0.03916501
  0.04017321 0.05684684 0.0495036  0.05588165 0.03679463 0.04873525
  0.04039999 0.03433537 0.02868425 0.04150349 0.03599919 0.03536089
  0.03296262 0.03472343 0.03265467 0.04074119 0.03662796 0.01559805
  0.02228601 0.05150126 0.08242439 0.06088382 0.02939341 0.02765313
  0.01899344 0.0297691 ]
 [0.03893505 0.07676669 0.07897481 0.06905145 0.04056883 0.03524125
  0.04771684 0.06788187 0.05435821 0.04612989 0.03712524 0.04668036
  0.03879888 0.03292559 0.02876088 0.04700553 0.03860381 0.03619458
  0.0337456  0.03670211 0.03477279 0.04564368 0.04973612 0.0202252
  0.02447953 0.07107678 0.16251875 0.08465582 0.03017715 0.02465063
  0.01992658 0.02392722]
 [0.03989351 0.04045653 0.04725329 0.04559515 0.03151864 0.03246711
  0.038114   0.04607607 0.0436144  0.04030698 0.03470568 0.03991179
  0.03634473 0.02923369 0.02484743 0.03759662 0.03496221 0.0342932
  0.03306724 0.03532681 0.0322167  0.03937802 0.03384783 0.01588865
  0.02105105 0.03974571 0.06186198 0.05728721 0.02878935 0.02900188
  0.02149596 0.03698807]
 [0.03830544 0.03644353 0.03569921 0.04956032 0.04947362 0.0532399
  0.03752857 0.03726927 0.0474394  0.05238388 0.04092411 0.04265004
  0.04653537 0.07467698 0.08341784 0.03320743 0.031158   0.03938289
  0.03406846 0.03728491 0.03349219 0.03935413 0.04390622 0.01432498
  0.02531406 0.040513   0.0350959  0.04214212 0.053549   0.02969267
  0.01472973 0.01687754]
 [0.03790367 0.04406942 0.03600959 0.06262404 0.14796913 0.05200005
  0.03680376 0.03372772 0.04227639 0.0670227  0.05427488 0.04633007
  0.03698212 0.09825543 0.13922314 0.0467819  0.05441859 0.06199053
  0.04560611 0.04524853 0.04983873 0.03785114 0.05692017 0.01318057
  0.02087209 0.04096538 0.04520235 0.04230236 0.05602512 0.02196588
  0.01282007 0.01089921]
 [0.03820099 0.03409421 0.02691995 0.03882665 0.07729114 0.02882595
  0.0270541  0.02751751 0.03138585 0.04296046 0.04148635 0.03164345
  0.0295147  0.03448613 0.05136522 0.03320676 0.05987471 0.07409988
  0.05810898 0.05261134 0.06995282 0.03372094 0.04398981 0.02702871
  0.03061358 0.03597799 0.03154262 0.04554055 0.03275186 0.01533632
  0.01817309 0.01325668]
 [0.03831664 0.03761648 0.02976484 0.04135711 0.05107117 0.03386824
  0.03370751 0.03336736 0.04056535 0.04156448 0.03924999 0.03249718
  0.03393637 0.03832879 0.03969746 0.02959828 0.04370221 0.04956659
  0.04215809 0.0464064  0.04340154 0.04614281 0.05220656 0.01759628
  0.02609189 0.03744863 0.02737771 0.05591467 0.0400027  0.01270564
  0.01322398 0.0119794 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' "', 'Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' bedroom', '",', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' answer', '.', ' It', ' only', ' gives', ' two', ' possible', ' locations', ' for', ' Fred', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 38), x_tokens=38, y_tokens=41, max_supp_attn=0.0244, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 38)
DEBUG result.interpretability.attn_scores 1558 
 [[0.02238842 0.03605062 0.03384877 ... 0.04105933 0.025172   0.01603785]
 [0.02272329 0.03436006 0.02935476 ... 0.029842   0.02553242 0.02421422]
 [0.02339026 0.03592712 0.03687152 ... 0.03044796 0.02090252 0.01460944]
 ...
 [0.02352527 0.03211925 0.03024422 ... 0.0391716  0.02018991 0.01292975]
 [0.02400971 0.02728085 0.02333919 ... 0.03146914 0.02238747 0.01979865]
 [0.02420993 0.02483009 0.02186673 ... 0.03775716 0.02126192 0.01697727]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '11', ' only', ' mentions', ' two', ' possible', ' locations', ' for', ' Bill', ':', ' the', ' school', ' or', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0256, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02371843 0.0283273  0.03024214 ... 0.09561545 0.01547134 0.01972971]
 [0.02422547 0.02012002 0.02211923 ... 0.06305684 0.02537639 0.02524109]
 [0.02475564 0.02800264 0.03050034 ... 0.07718469 0.02884283 0.03591316]
 ...
 [0.02484329 0.03225646 0.02954708 ... 0.03482083 0.01359147 0.01876123]
 [0.02532863 0.02595881 0.02371669 ... 0.0172375  0.01524505 0.01713657]
 [0.02525545 0.03063315 0.02812697 ... 0.02273029 0.01373053 0.01727992]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Fred', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03352072 0.03542244 0.03857857 ... 0.02694734 0.02762135 0.03849322]
 [0.03408842 0.0313272  0.03931801 ... 0.03654735 0.04183882 0.04342825]
 [0.03492894 0.033565   0.04252935 ... 0.02319697 0.02154977 0.02696848]
 ...
 [0.03541255 0.03938879 0.03236109 ... 0.03913337 0.03896776 0.03605836]
 [0.03597568 0.04312693 0.03913993 ... 0.03132813 0.02969901 0.02643143]
 [0.03622454 0.03598665 0.03450392 ... 0.02652277 0.02686829 0.02621371]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' moved', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02797943 0.04925377 0.06110156 0.07568224 0.08307073 0.07565297
  0.06200685 0.07194113 0.05907858 0.06709173 0.04906283 0.06273616
  0.06986237 0.10337643 0.0678051  0.03231088 0.03377811 0.03406838
  0.03112751 0.03411905 0.02665282 0.04016868 0.04539385 0.02200485
  0.01482066 0.02495103]
 [0.02775758 0.08705536 0.06395542 0.05073116 0.03976797 0.05160699
  0.14470664 0.09162353 0.063082   0.04635473 0.06387088 0.04882972
  0.0817721  0.02355478 0.0225492  0.04206701 0.04367077 0.05824209
  0.04572972 0.05575632 0.04567861 0.04629054 0.04798039 0.04324249
  0.02943924 0.03403136]
 [0.03049144 0.06173727 0.03994266 0.05595856 0.04157446 0.03791699
  0.03159033 0.02348564 0.02388396 0.03591743 0.02927865 0.0175376
  0.01914821 0.03202233 0.0419422  0.02375174 0.01497126 0.01368591
  0.0173082  0.01763829 0.01557216 0.04465312 0.05534703 0.00969938
  0.00536847 0.01223089]
 [0.02872141 0.02991577 0.0294557  0.02341404 0.01674548 0.02445452
  0.02401823 0.02325003 0.0267158  0.02313049 0.0260121  0.02402326
  0.02224349 0.01336525 0.0131537  0.03114115 0.03034098 0.03300128
  0.03760598 0.04373208 0.04009872 0.03030219 0.04291152 0.06335052
  0.06943906 0.06279561]
 [0.02899421 0.0440947  0.04992372 0.06929222 0.06275437 0.05026307
  0.03433809 0.03094024 0.03624935 0.04745849 0.03575346 0.02714559
  0.02633942 0.10685202 0.11176258 0.03714671 0.02896269 0.02140998
  0.02243395 0.02404337 0.02185689 0.04000276 0.06531025 0.01692218
  0.00811364 0.02666481]
 [0.02958513 0.02852206 0.03054552 0.05351823 0.04718996 0.04591378
  0.02569172 0.02421041 0.03081938 0.04469154 0.03192986 0.03102232
  0.02868214 0.11646189 0.14053686 0.0367527  0.03247134 0.02574277
  0.02522043 0.02552641 0.02083364 0.03400254 0.03883269 0.01189574
  0.00653254 0.01714932]
 [0.0300199  0.03238287 0.03951918 0.05616252 0.05186734 0.05754391
  0.03390937 0.03334657 0.04028312 0.05231804 0.03711814 0.04871118
  0.04339654 0.09256526 0.08690398 0.03111949 0.02964323 0.02559518
  0.02434123 0.02538186 0.01980721 0.03086622 0.03685198 0.01647798
  0.00908662 0.01685845]
 [0.0290592  0.04093844 0.04923546 0.04254913 0.04474964 0.0505179
  0.03721101 0.0413884  0.04285545 0.04515119 0.03695561 0.05066919
  0.04263453 0.05479307 0.049399   0.04021137 0.03679584 0.03237734
  0.0296001  0.03219213 0.02771484 0.03445215 0.05300156 0.04269416
  0.02827634 0.03426073]
 [0.03022824 0.04325347 0.0535237  0.04961953 0.0447352  0.06027018
  0.04326238 0.04855596 0.0510262  0.05195063 0.03808954 0.05405216
  0.04857581 0.04340284 0.02815235 0.02881398 0.02854262 0.02675427
  0.02594704 0.02816982 0.02196652 0.03509333 0.0405196  0.02142887
  0.01442024 0.0239272 ]
 [0.02960931 0.05108265 0.05589535 0.0298026  0.02355168 0.03815969
  0.04179783 0.04208925 0.04508177 0.03161278 0.02948832 0.038652
  0.03767972 0.01842352 0.01522514 0.04257195 0.03426329 0.02995397
  0.03066712 0.03394662 0.03118849 0.03378354 0.06927921 0.04499048
  0.03629782 0.03838008]
 [0.03012183 0.03863716 0.04651136 0.0250385  0.0207301  0.02859145
  0.04334123 0.03427585 0.04137731 0.02518529 0.0241338  0.027585
  0.02653789 0.01424357 0.0134414  0.04206033 0.03208772 0.02739341
  0.03028935 0.03408605 0.03013727 0.02960704 0.05507833 0.05230208
  0.04123009 0.03839118]
 [0.03065534 0.01341858 0.01615522 0.01138286 0.00974926 0.01427752
  0.01511562 0.01548447 0.02119326 0.01355806 0.01279825 0.01431311
  0.01334278 0.00645361 0.00633076 0.01765289 0.01801362 0.0169792
  0.02091548 0.02334282 0.0230492  0.01652759 0.03182894 0.06401549
  0.06573892 0.06176531]
 [0.03023707 0.02403195 0.02579961 0.01666999 0.01447354 0.02109522
  0.02280401 0.02174906 0.02374737 0.01807438 0.02116623 0.02163894
  0.01998228 0.00940975 0.00976687 0.03558163 0.02589502 0.02533601
  0.02755811 0.0287133  0.02736878 0.02922054 0.03025378 0.05288829
  0.06431407 0.04815869]
 [0.03044136 0.02311225 0.02405485 0.01810942 0.01568709 0.02262521
  0.02435825 0.02639428 0.02500243 0.02113466 0.0243323  0.02800017
  0.02727745 0.01054962 0.00934507 0.03503285 0.03023571 0.03032674
  0.02878825 0.02906841 0.02964757 0.02938101 0.02173388 0.05116755
  0.05051083 0.02834251]
 [0.03001267 0.02026821 0.0177106  0.01487071 0.01217755 0.01617661
  0.02028688 0.02096808 0.01958157 0.01614357 0.02146026 0.01941637
  0.02171422 0.00744264 0.00731879 0.03463858 0.02873899 0.03684332
  0.03212614 0.03438311 0.04373348 0.02738398 0.01714653 0.05117512
  0.09303948 0.04351771]
 [0.03067126 0.01817077 0.01674441 0.014269   0.01232308 0.01659323
  0.01892581 0.02064875 0.01927198 0.01661833 0.02435835 0.02169133
  0.02226357 0.00729423 0.00716795 0.0357225  0.02607688 0.04291994
  0.03358147 0.0385346  0.03572829 0.02321399 0.01388573 0.0340905
  0.06844644 0.0352619 ]
 [0.03064532 0.01646079 0.01473224 0.01166696 0.01000904 0.01372742
  0.01738833 0.01799485 0.01736284 0.01364424 0.02813108 0.0176463
  0.01943647 0.0059372  0.00647725 0.03426943 0.0301021  0.03566423
  0.03709246 0.03451969 0.03846215 0.02456421 0.01431514 0.03536438
  0.04783513 0.05405609]
 [0.03039119 0.01740233 0.01646559 0.01318943 0.01170849 0.01656492
  0.01809991 0.02077792 0.02065603 0.01530441 0.01966136 0.0193594
  0.0199362  0.00707708 0.00704577 0.02219067 0.02328217 0.02590595
  0.03254864 0.03244708 0.03808336 0.02406522 0.01892949 0.05188705
  0.04840395 0.05560941]
 [0.0310597  0.01960573 0.01842428 0.01470608 0.01183237 0.01678941
  0.01852666 0.02000172 0.01939187 0.01596969 0.02111413 0.01974969
  0.0196503  0.00772183 0.00744006 0.0227734  0.02232091 0.02383695
  0.02980371 0.02702026 0.03059519 0.02584148 0.0159198  0.02560271
  0.02973581 0.03786401]
 [0.03132734 0.02340506 0.02644841 0.0229726  0.01768361 0.02721214
  0.02504322 0.03203337 0.02730311 0.02765438 0.02799089 0.03651522
  0.03133912 0.01351001 0.00983358 0.02162906 0.02283747 0.02522242
  0.0254593  0.02385272 0.02318584 0.02836949 0.01577227 0.01667262
  0.01865317 0.01972646]
 [0.03140433 0.02916027 0.03061391 0.02766531 0.02042581 0.03178895
  0.03215998 0.04180819 0.02981625 0.0329131  0.03750025 0.0446845
  0.04085179 0.0153141  0.01073542 0.02514039 0.02418337 0.02921684
  0.02605017 0.02517016 0.02334219 0.02899345 0.0174642  0.01519804
  0.01639567 0.01467577]
 [0.03130351 0.02700702 0.02706477 0.02498022 0.01954662 0.02849437
  0.0287657  0.03575768 0.02943533 0.0308583  0.03494209 0.03977507
  0.0388375  0.01429892 0.01070218 0.02889845 0.02568347 0.03086388
  0.02775805 0.0272331  0.0252047  0.02931598 0.01552178 0.01845243
  0.0173041  0.01362882]
 [0.03121706 0.01997944 0.0189784  0.01480806 0.01150282 0.01688042
  0.0206407  0.02448549 0.02260462 0.01794284 0.02368593 0.02295846
  0.02586213 0.00797304 0.00728349 0.03038173 0.02799131 0.03033634
  0.02951539 0.02783633 0.03148053 0.02736641 0.01368922 0.0287223
  0.02796573 0.01838726]
 [0.03132359 0.01927571 0.0175747  0.01447588 0.01058996 0.0151401
  0.02000796 0.02172993 0.02079716 0.01633559 0.02272569 0.02029911
  0.02388682 0.00726381 0.00694651 0.02954506 0.02673583 0.03145223
  0.02980214 0.02920328 0.03506127 0.02306407 0.01285236 0.03008328
  0.03263885 0.02139122]
 [0.03144799 0.01979259 0.01797099 0.01552777 0.01192017 0.01648099
  0.02011342 0.02313163 0.02161212 0.0184161  0.02456553 0.022504
  0.0240723  0.00824311 0.00763377 0.02785435 0.03080356 0.02985278
  0.03374036 0.02798088 0.03150532 0.02489359 0.01254474 0.0186039
  0.02076333 0.01808251]
 [0.03149985 0.02268597 0.02081609 0.01687542 0.01232308 0.01841344
  0.02459577 0.02673753 0.02659591 0.01958033 0.02950941 0.0241634
  0.02699746 0.00874614 0.00798337 0.03050576 0.03000055 0.03131424
  0.0330711  0.03023617 0.0328921  0.02596293 0.01315183 0.02032388
  0.02133309 0.01942496]
 [0.03150438 0.01747432 0.01631304 0.01147173 0.00951352 0.01329865
  0.01989462 0.0196202  0.02085787 0.01373496 0.0328504  0.01768101
  0.02152638 0.00653451 0.00584018 0.03145256 0.03450251 0.02981038
  0.0371819  0.03022251 0.03501138 0.02486406 0.01182842 0.02172879
  0.02202306 0.02917258]
 [0.03049923 0.02144028 0.01983061 0.01279752 0.0106537  0.01557695
  0.02200669 0.02336484 0.02727427 0.01595154 0.02598481 0.01988852
  0.02501743 0.00735444 0.00657055 0.02626442 0.0293507  0.02732542
  0.03612171 0.03585363 0.04675112 0.02832151 0.02002249 0.04712019
  0.04010928 0.05160659]
 [0.03160766 0.02000694 0.01925896 0.0162912  0.01239284 0.0185894
  0.01888048 0.02226214 0.02439843 0.01879107 0.02144165 0.02313135
  0.02253766 0.0096792  0.00778026 0.01794131 0.02250344 0.02091842
  0.02770964 0.02406442 0.02801387 0.02473786 0.01452483 0.0171384
  0.01697665 0.02261621]
 [0.03025385 0.02867252 0.02914358 0.04364327 0.04605098 0.0396654
  0.02391475 0.02588838 0.03186197 0.04526005 0.03231817 0.03401892
  0.03118081 0.07652368 0.08940548 0.02448362 0.02908517 0.02569197
  0.02601439 0.02526861 0.02232784 0.03212908 0.0339145  0.01261277
  0.00799459 0.01921455]
 [0.03002412 0.03058634 0.02990548 0.05000998 0.09668674 0.03990506
  0.02260591 0.0248084  0.03094383 0.05342633 0.03846669 0.03433652
  0.02588103 0.0762889  0.09642373 0.03063514 0.04104679 0.0348847
  0.03046403 0.0275     0.0259394  0.02940105 0.03305252 0.01056599
  0.00568726 0.01645429]
 [0.02981946 0.02720278 0.02578908 0.04036522 0.08750997 0.02730517
  0.01874546 0.02326079 0.02676588 0.04591021 0.03667771 0.03574184
  0.02469845 0.03301684 0.04306274 0.02637481 0.06296989 0.05269622
  0.0419767  0.03252732 0.04068279 0.02657776 0.02944015 0.01718157
  0.01178851 0.02197111]
 [0.03008604 0.03396666 0.0305955  0.04148267 0.05850275 0.03250793
  0.02524624 0.02598526 0.03307302 0.04191551 0.03662561 0.03152262
  0.02683561 0.03430634 0.03803476 0.02308401 0.04211264 0.03437715
  0.03245024 0.03042966 0.03042645 0.04658265 0.04170112 0.01439599
  0.00931747 0.01943143]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '1', ',', ' which', ' mentioned', ' Julie', ',', ' is', ' not', ' provided', ' in', ' this', ' task', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 32), x_tokens=32, y_tokens=38, max_supp_attn=0.1053, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 32)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02435242 0.02711202 0.02619481 ... 0.05243036 0.01301632 0.0513396 ]
 [0.02518553 0.02514628 0.02323104 ... 0.05967626 0.01974021 0.06573738]
 [0.02560796 0.02481994 0.02626003 ... 0.05715511 0.02816449 0.05262478]
 ...
 [0.02593434 0.02508904 0.01959999 ... 0.01162122 0.01418342 0.01885924]
 [0.02639318 0.02336934 0.02000711 ... 0.01055025 0.01261488 0.01863526]
 [0.02653448 0.02076629 0.01832392 ... 0.01151383 0.01247911 0.02229002]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '8', ',', ' Mary', ' travelled', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' information', ' suggesting', ' that', ' she', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 38), x_tokens=38, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 38)
DEBUG result.interpretability.attn_scores 1558 
 [[0.02256323 0.03839023 0.03684819 ... 0.01209947 0.01225014 0.04255881]
 [0.02297672 0.03865727 0.03008587 ... 0.03214012 0.04438483 0.03537261]
 [0.02353828 0.04207682 0.04237083 ... 0.0100491  0.00758255 0.03671326]
 ...
 [0.0237248  0.03429471 0.0305271  ... 0.01066114 0.00729544 0.04351211]
 [0.02426978 0.02687576 0.0229903  ... 0.01647585 0.01282948 0.02807825]
 [0.0241854  0.02622267 0.02294631 ... 0.01334402 0.0134848  0.03126765]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Fred', ' moved', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' he', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 44), x_tokens=44, y_tokens=29, max_supp_attn=0.0345, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 44)
DEBUG result.interpretability.attn_scores 1276 
 [[0.03248218 0.04182203 0.04555468 ... 0.01841689 0.01941743 0.03044791]
 [0.03271298 0.03654886 0.03714114 ... 0.03810908 0.0434414  0.04583764]
 [0.0339449  0.04248701 0.05011604 ... 0.02633656 0.02845968 0.03870016]
 ...
 [0.03405905 0.05067083 0.05076867 ... 0.01439978 0.01554516 0.02434059]
 [0.03417268 0.04038582 0.03715999 ... 0.01733112 0.01667984 0.01730134]
 [0.03424375 0.04446711 0.04213131 ... 0.01633547 0.01687417 0.02180951]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' current', ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '11', ',', ' which', ' mentioned', ' Bill', ',', ' is', ' not', ' provided', ' in', ' this', ' task', '.', ' \n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 50), x_tokens=50, y_tokens=39, max_supp_attn=0.1795, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 50)
DEBUG result.interpretability.attn_scores 1950 
 [[0.02395985 0.0280856  0.02773653 ... 0.01556808 0.01428175 0.01646449]
 [0.02453012 0.02181853 0.02171354 ... 0.0139717  0.0153312  0.01701024]
 [0.02496812 0.0281834  0.03083701 ... 0.01310317 0.01150808 0.01290098]
 ...
 [0.02565531 0.02684309 0.02272161 ... 0.01944373 0.01969081 0.02012811]
 [0.0259426  0.03026601 0.02514454 ... 0.01521734 0.01547362 0.01721368]
 [0.0257568  0.0247717  0.02198812 ... 0.0147269  0.01312029 0.01422014]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Julie', ' is', ' in', ' the', ' bedroom', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 26), x_tokens=26, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 26)
DEBUG result.interpretability.attn_scores 936 
 [[0.02582981 0.03945662 0.04804302 0.06908876 0.07829773 0.06609254
  0.04622878 0.05685226 0.04683303 0.0601503  0.04271907 0.05224353
  0.06033956 0.10073518 0.07078826 0.02839914 0.02644727 0.02780464
  0.02408331 0.02669169 0.02142292 0.03533486 0.03753449 0.02119073
  0.01565968 0.02254445]
 [0.02547642 0.07543898 0.05831646 0.05994787 0.05182743 0.05662762
  0.16233298 0.08867622 0.06468532 0.05810307 0.07531686 0.0526606
  0.07896274 0.0332854  0.02848795 0.03678448 0.03242806 0.04169049
  0.03195393 0.04014952 0.03323096 0.04352635 0.0370202  0.03277486
  0.0244499  0.02876437]
 [0.02800092 0.0540421  0.0351361  0.05390692 0.04094759 0.03460557
  0.02789956 0.02111589 0.02037835 0.03312143 0.02581275 0.01481797
  0.01700588 0.03224136 0.04192298 0.02229975 0.01200789 0.0114249
  0.01344347 0.01434782 0.01328481 0.04120664 0.04863661 0.0097733
  0.00561397 0.01196724]
 [0.02634524 0.02597167 0.02739837 0.02229664 0.01609339 0.02305795
  0.0228103  0.02002665 0.02288781 0.02247584 0.02316235 0.02124401
  0.02002064 0.01305887 0.01403714 0.02780863 0.02977825 0.03619017
  0.03809697 0.04191117 0.0369798  0.02914026 0.04327157 0.04891244
  0.05352199 0.05745121]
 [0.02664431 0.03860049 0.04367832 0.06713869 0.06202582 0.04561205
  0.02988448 0.0275302  0.03101641 0.04399494 0.03152464 0.02337378
  0.02366085 0.10590713 0.10990125 0.03426755 0.02311178 0.01805375
  0.01755299 0.01954801 0.01859203 0.03617715 0.05556532 0.01682865
  0.00860552 0.02616752]
 [0.02720342 0.02511625 0.02672376 0.05136533 0.04613663 0.04132387
  0.02236683 0.02143087 0.02610604 0.04059108 0.02784978 0.0261108
  0.02525957 0.11377797 0.13623719 0.03364995 0.02580182 0.02168868
  0.01974838 0.0207797  0.01771407 0.03095932 0.03349293 0.0119008
  0.0068226  0.01675969]
 [0.02763316 0.02793899 0.03359971 0.05317306 0.05060922 0.05102161
  0.02866385 0.02874269 0.03369317 0.04738788 0.03248852 0.0406394
  0.03762927 0.09007785 0.08490212 0.02810635 0.02354447 0.02153023
  0.01902238 0.02050807 0.01672472 0.02800542 0.03099315 0.01575256
  0.00971172 0.01611796]
 [0.02665591 0.03458839 0.04157811 0.03967317 0.04264654 0.04591308
  0.03255649 0.03658016 0.03689225 0.04155191 0.03337235 0.04521353
  0.03893591 0.05213358 0.04717078 0.03545325 0.0304933  0.02838208
  0.02426016 0.02614707 0.02371914 0.03168273 0.04378914 0.03284624
  0.03278897 0.03045214]
 [0.02777304 0.03414932 0.04136724 0.04518479 0.04151352 0.05349721
  0.03536146 0.03968355 0.04340663 0.04788876 0.03354868 0.04650257
  0.04299205 0.0414691  0.0270751  0.02569457 0.02325204 0.02354089
  0.021618   0.02338735 0.01892458 0.03222099 0.03402309 0.01990808
  0.01416465 0.02176927]
 [0.02708495 0.04670922 0.05421075 0.02901479 0.02363249 0.03703478
  0.03840404 0.03845632 0.04103126 0.02951557 0.02651159 0.03414047
  0.03383218 0.01826478 0.01576674 0.03910023 0.03077725 0.02646958
  0.02535158 0.02867548 0.02728601 0.03154856 0.06347883 0.042667
  0.0348538  0.03553484]
 [0.02760321 0.06148227 0.06157031 0.02710756 0.0222836  0.0312687
  0.03887153 0.03603449 0.04325721 0.0261704  0.02409378 0.02755166
  0.0279069  0.01553311 0.01472674 0.04470687 0.03067801 0.02597219
  0.02598692 0.03115168 0.02640724 0.02914153 0.06562573 0.03944404
  0.02586766 0.02672952]
 [0.0277532  0.03236956 0.03666562 0.02015584 0.01758347 0.02231309
  0.03013153 0.02718994 0.0313293  0.02049002 0.01946153 0.02121989
  0.02078543 0.01279607 0.01275508 0.03743483 0.02827776 0.02294073
  0.02384455 0.02733387 0.02606153 0.02749552 0.05040381 0.04864361
  0.04350693 0.03891038]
 [0.02792059 0.01358228 0.01483601 0.01098869 0.01014938 0.0126499
  0.01379238 0.01389362 0.01590602 0.0118903  0.01334829 0.01295839
  0.01279079 0.00644303 0.00701442 0.01767762 0.01845471 0.01801126
  0.02075886 0.02457918 0.0282767  0.01951724 0.03113212 0.05619523
  0.06460884 0.05529922]
 [0.02788019 0.02038231 0.0216898  0.01554117 0.01508055 0.01861425
  0.01968109 0.01951785 0.02008973 0.01679    0.0195935  0.0184456
  0.01779647 0.00949828 0.01018087 0.03004435 0.02895496 0.0233449
  0.02316104 0.02473675 0.02523135 0.0258425  0.02506348 0.04374841
  0.0584353  0.04819842]
 [0.02793298 0.02204839 0.02327127 0.01860103 0.01681568 0.02286514
  0.0242085  0.02688023 0.02281118 0.02162282 0.02545143 0.02744917
  0.0272701  0.01108401 0.00998974 0.02586374 0.03441072 0.02719558
  0.02371667 0.02436344 0.02743551 0.02700252 0.01884603 0.03193342
  0.05261071 0.02862695]
 [0.02753516 0.0181521  0.01614549 0.01351094 0.01148894 0.01426786
  0.01848019 0.01937564 0.01604394 0.01462403 0.02064501 0.01634871
  0.0196109  0.00704788 0.00740251 0.02487972 0.03441468 0.04004053
  0.02940081 0.03212411 0.05316234 0.02375193 0.01491116 0.0401989
  0.07382729 0.04204985]
 [0.02808934 0.01964127 0.01844512 0.01550524 0.01389502 0.01788303
  0.02252723 0.02482079 0.01880115 0.01810978 0.02936754 0.02429123
  0.02472082 0.00849476 0.0081049  0.02256078 0.03714309 0.02706415
  0.02680073 0.02546458 0.03322424 0.02390745 0.01471967 0.03561355
  0.05359378 0.03732039]
 [0.02806819 0.01627146 0.01493227 0.01156915 0.01102803 0.01379311
  0.0197094  0.01958211 0.01640408 0.01397302 0.03183187 0.01932853
  0.0202828  0.00639118 0.00673535 0.02414319 0.04019753 0.02866009
  0.03012073 0.02900161 0.03894937 0.02129853 0.01296889 0.03484502
  0.04085984 0.05252311]
 [0.02707536 0.01887182 0.01609965 0.01259602 0.01156129 0.01448159
  0.01893482 0.01781657 0.01919449 0.01446299 0.02229042 0.01481578
  0.01813913 0.00709615 0.00778433 0.02182843 0.03178075 0.03244358
  0.03925678 0.05876358 0.05533483 0.0244618  0.02677158 0.06847195
  0.0573964  0.07496934]
 [0.02839306 0.01816489 0.0169347  0.01404855 0.01222757 0.01671617
  0.01871608 0.01972432 0.01871176 0.01622633 0.03001878 0.02166601
  0.01920632 0.00802816 0.00767732 0.02131401 0.02956813 0.02396483
  0.02587078 0.02834615 0.030071   0.0231375  0.01273746 0.02253566
  0.02322257 0.03854525]
 [0.02872622 0.02010877 0.02228037 0.01864664 0.01584718 0.0233026
  0.02069157 0.02800529 0.02496434 0.0234121  0.02505766 0.03159527
  0.02582413 0.01137899 0.00883846 0.01817677 0.02063425 0.01957689
  0.02166858 0.01989246 0.01932934 0.02613872 0.01429346 0.01739517
  0.01729031 0.01879629]
 [0.02849855 0.0217713  0.02129482 0.01642016 0.01394986 0.02207753
  0.02206489 0.02742907 0.025267   0.01926305 0.02250895 0.02871684
  0.02591083 0.0099631  0.00842794 0.02052157 0.02159965 0.02216433
  0.02596062 0.02431443 0.02459978 0.02748485 0.01825733 0.02459595
  0.02307103 0.02027265]
 [0.02878405 0.02252654 0.02256075 0.01711671 0.01490202 0.02448492
  0.02504313 0.03154269 0.0280919  0.02138398 0.03001121 0.0408789
  0.03055836 0.01014247 0.00889657 0.02188802 0.02595504 0.02464306
  0.02739278 0.02366996 0.02341074 0.02386554 0.01697489 0.01753035
  0.01526337 0.01671652]
 [0.0288778  0.02148142 0.02189914 0.01786854 0.01485068 0.02614744
  0.02245089 0.02702877 0.02978659 0.02194492 0.02035293 0.03153772
  0.02845392 0.01101191 0.0086433  0.01781823 0.02027885 0.02088692
  0.02498129 0.02355224 0.02174286 0.02488613 0.02006282 0.01950103
  0.01862532 0.01898568]
 [0.02832681 0.0349074  0.02992184 0.02043502 0.01612256 0.0277181
  0.02864155 0.03757565 0.03504177 0.02559172 0.02624764 0.04012915
  0.03759108 0.01207442 0.00947759 0.02755204 0.0234664  0.02914036
  0.02911105 0.03038216 0.026998   0.02728726 0.02226005 0.02029462
  0.01920658 0.017667  ]
 [0.02900343 0.02300967 0.02521258 0.01935978 0.01486118 0.02768809
  0.02635211 0.03023223 0.03222581 0.02360864 0.02361238 0.03551884
  0.03149758 0.0115089  0.00860583 0.02156002 0.01895937 0.02099562
  0.02252732 0.02393792 0.02179574 0.0252566  0.01641847 0.01697977
  0.01569408 0.01253057]
 [0.02829994 0.01778976 0.01721127 0.01285308 0.01034192 0.01489995
  0.01884989 0.0215636  0.02122505 0.01599704 0.02388066 0.02106589
  0.0242636  0.00774748 0.00654489 0.02982765 0.02717449 0.03208948
  0.03035666 0.03072432 0.03327712 0.02456314 0.01154036 0.02469468
  0.03073312 0.0166095 ]
 [0.02830241 0.01968888 0.01899214 0.01413148 0.0106243  0.01468349
  0.02075247 0.02436571 0.02228119 0.01607347 0.02098469 0.01931866
  0.02372175 0.00779754 0.00668981 0.03710411 0.02756165 0.04288556
  0.03057478 0.035548   0.03934957 0.02339962 0.01262968 0.02765564
  0.03190761 0.01716666]
 [0.02870351 0.01918443 0.01785226 0.0134059  0.01086934 0.01461528
  0.01817224 0.02307316 0.02160179 0.01655525 0.0231894  0.02187702
  0.02381773 0.00779873 0.00635847 0.0332264  0.02812692 0.03213757
  0.0308706  0.02987969 0.0322298  0.02192682 0.011182   0.02384489
  0.02192047 0.01346034]
 [0.02857628 0.01611444 0.01591477 0.01058652 0.00934308 0.01221608
  0.01608868 0.01874464 0.01933114 0.01363864 0.02375518 0.01764269
  0.01854577 0.00668139 0.00555088 0.03167133 0.02887398 0.02667908
  0.03262125 0.02712866 0.03154106 0.02158901 0.01069069 0.0239907
  0.02115077 0.01827569]
 [0.0277428  0.01786649 0.01738851 0.01155395 0.00995568 0.01373764
  0.01800669 0.01996345 0.02195682 0.01409448 0.02346093 0.01774079
  0.01984106 0.00736372 0.00631091 0.03798791 0.0297719  0.03090001
  0.03629331 0.02939278 0.03300361 0.02317145 0.01554691 0.04124538
  0.03273414 0.03381887]
 [0.02875537 0.02089812 0.02073099 0.01482389 0.01194869 0.01752924
  0.01809418 0.02163734 0.02465145 0.01743283 0.0214239  0.02088009
  0.02066777 0.00960495 0.00762124 0.02633236 0.02243987 0.02586612
  0.03117694 0.02537297 0.0253728  0.02381296 0.01634187 0.01931953
  0.01668013 0.01647428]
 [0.02784026 0.02530453 0.02569466 0.04269157 0.0435917  0.03577697
  0.02140096 0.02346082 0.02911612 0.04537613 0.03010749 0.03060218
  0.03107648 0.06557503 0.08278105 0.0231146  0.02437992 0.02372799
  0.02231688 0.02119148 0.01886634 0.02963135 0.02762399 0.01187422
  0.00879645 0.01774848]
 [0.02761141 0.02708002 0.02584746 0.04730486 0.09252647 0.034983
  0.01899314 0.0215183  0.02620183 0.04801979 0.03427781 0.02784104
  0.02373    0.07298285 0.09335249 0.02885865 0.0334514  0.03230589
  0.02763235 0.02394433 0.02181453 0.02702833 0.02829586 0.00978051
  0.0062209  0.01589951]
 [0.02741859 0.02146011 0.02135976 0.03473787 0.0611005  0.02297428
  0.01431563 0.01927661 0.02239358 0.0404     0.03275573 0.02921667
  0.02342657 0.02708134 0.03265896 0.0229011  0.04420942 0.05326033
  0.06366586 0.03423112 0.02992257 0.02342687 0.02304188 0.01456255
  0.01143232 0.01786431]
 [0.02763406 0.02782958 0.02519654 0.03764985 0.05332101 0.02752621
  0.0185205  0.02065239 0.02638445 0.03806753 0.02996469 0.02441674
  0.02392507 0.02792336 0.03058097 0.01944176 0.03159445 0.03632754
  0.03880071 0.02882664 0.02471305 0.04117254 0.03385458 0.01255048
  0.00915114 0.0170125 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Mary', ' went', ' to', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02937094 0.04774926 0.04712881 ... 0.06515889 0.01028044 0.00929259]
 [0.03006402 0.05074588 0.04650061 ... 0.07178266 0.01515145 0.0144523 ]
 [0.03074806 0.04498758 0.04659846 ... 0.06826099 0.01928552 0.01854446]
 ...
 [0.03066666 0.03918134 0.03632187 ... 0.02456478 0.00766704 0.00679037]
 [0.03115542 0.03026341 0.0268564  ... 0.01290905 0.01114626 0.00943474]
 [0.03127252 0.03147325 0.02800076 ... 0.01122338 0.01011225 0.00914767]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' now', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.0303281  0.03797252 0.03754909 ... 0.03112771 0.02225574 0.02284997]
 [0.03104381 0.04267764 0.03818764 ... 0.03263792 0.02522843 0.02537106]
 [0.03157896 0.04063111 0.04536963 ... 0.02506512 0.01790422 0.0170656 ]
 ...
 [0.03175559 0.03621669 0.04002165 ... 0.02565341 0.0166166  0.01854178]
 [0.03195078 0.02946358 0.03060277 ... 0.0308247  0.02324119 0.02616117]
 [0.0319363  0.03343247 0.03399035 ... 0.02835308 0.0213152  0.02459966]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Mary', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 44), x_tokens=44, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 44)
DEBUG result.interpretability.attn_scores 1320 
 [[0.03124552 0.04195347 0.04242207 ... 0.03781498 0.01164767 0.0183208 ]
 [0.03181568 0.0386771  0.0398289  ... 0.04467101 0.02419161 0.03504529]
 [0.03271772 0.04479356 0.05099573 ... 0.05653997 0.01549147 0.02794526]
 ...
 [0.03290983 0.04692525 0.04121042 ... 0.0143118  0.00828447 0.01197089]
 [0.03328431 0.03500334 0.0276817  ... 0.01097924 0.01205269 0.01359545]
 [0.03303439 0.04207873 0.03228269 ... 0.00884199 0.00964486 0.01158099]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Julie', ' is', ' in', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02937169 0.04163153 0.04026037 ... 0.03640127 0.01920986 0.01524245]
 [0.02987704 0.0367041  0.03913869 ... 0.0384933  0.02789908 0.02049815]
 [0.03061883 0.04433477 0.04681916 ... 0.03029952 0.0188347  0.0133934 ]
 ...
 [0.03071757 0.03748911 0.03982882 ... 0.02778434 0.0171727  0.01506524]
 [0.03132311 0.02688749 0.02815828 ... 0.0261646  0.01994405 0.01951183]
 [0.0310247  0.03078636 0.03070474 ... 0.02613766 0.01895774 0.02031861]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 26), x_tokens=26, y_tokens=30, max_supp_attn=0.1, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 26)
DEBUG result.interpretability.attn_scores 780 
 [[0.03124273 0.0524494  0.05644075 0.0850444  0.07969984 0.0591125
  0.04039973 0.03580412 0.04200871 0.05758205 0.0402438  0.02966535
  0.03136727 0.1312162  0.12825574 0.03974167 0.03076593 0.02191594
  0.02486372 0.02428864 0.02447166 0.04542248 0.0686892  0.01453026
  0.01228643 0.0436712 ]
 [0.03224839 0.03314168 0.03346276 0.06335539 0.0564491  0.05041991
  0.02849951 0.02599251 0.03384359 0.04974204 0.03489503 0.03190884
  0.03121012 0.13311352 0.15334642 0.03843589 0.03347208 0.02576119
  0.02748946 0.02523401 0.02302364 0.03903681 0.04084776 0.00990665
  0.00983635 0.02860537]
 [0.03276219 0.037373   0.04447199 0.06560269 0.06195084 0.06494575
  0.03903248 0.03791055 0.04499982 0.05841041 0.04001724 0.05196471
  0.05048057 0.10594149 0.09392789 0.0325371  0.03060703 0.02648492
  0.02652444 0.02539243 0.02190812 0.03527468 0.03828247 0.01406735
  0.01349    0.02722858]
 [0.03168669 0.04829086 0.05747851 0.05244883 0.0517579  0.06141438
  0.04673863 0.04928756 0.04944998 0.0513645  0.03969833 0.056808
  0.05193264 0.06313251 0.05521761 0.04411859 0.03956866 0.03533782
  0.03297761 0.03364496 0.03038347 0.03970493 0.05912052 0.03765922
  0.03868479 0.04470435]
 [0.03291934 0.04966087 0.0609281  0.06078146 0.051182   0.07377145
  0.05499537 0.05718249 0.06159135 0.06148576 0.0420575  0.06043748
  0.05896544 0.0475265  0.03079919 0.03270327 0.03106877 0.02990359
  0.02920215 0.0310174  0.02523005 0.04000845 0.04390745 0.02022721
  0.02224238 0.03480873]
 [0.03233309 0.06023645 0.06562412 0.03714241 0.02724205 0.04696272
  0.05360423 0.05024526 0.05437404 0.0373689  0.0324115  0.04348662
  0.04533231 0.02261393 0.01871621 0.04987041 0.03914759 0.03382907
  0.03429878 0.03684861 0.03398453 0.03825373 0.07665554 0.0441982
  0.0478992  0.0427154 ]
 [0.03291915 0.07768635 0.07695382 0.03411608 0.02516107 0.03953125
  0.05264964 0.04461316 0.05592396 0.03260749 0.02891707 0.03316985
  0.0336843  0.01889832 0.01742773 0.05326485 0.03886735 0.030789
  0.03487834 0.03964266 0.03359354 0.03490856 0.08040639 0.03675425
  0.03601746 0.03935637]
 [0.03306507 0.04230323 0.04884756 0.0264204  0.0204592  0.0295328
  0.0410687  0.03502719 0.04411531 0.02702751 0.02446592 0.02674248
  0.026478   0.01617568 0.0155291  0.04589547 0.03559409 0.02725018
  0.03286701 0.03552936 0.03221975 0.03338983 0.06644619 0.05297333
  0.05782534 0.04535444]
 [0.03324678 0.01836174 0.01983768 0.01489812 0.01243389 0.01756629
  0.01912637 0.01893348 0.02335927 0.01658013 0.01673336 0.01659656
  0.01718348 0.0088221  0.00932125 0.02481017 0.02447568 0.0237803
  0.02998965 0.03454021 0.03492936 0.02493016 0.04435139 0.0675311
  0.09032087 0.05430989]
 [0.03330093 0.02670218 0.02861582 0.02105695 0.01662119 0.02630471
  0.02824104 0.02521943 0.02811779 0.02232481 0.02378748 0.02473298
  0.02344059 0.01213984 0.01256111 0.03971398 0.02765679 0.02654338
  0.02822995 0.03033934 0.0298464  0.03127316 0.03447338 0.05851692
  0.06958125 0.04591824]
 [0.03336405 0.02940627 0.02947659 0.02515303 0.01948337 0.02950879
  0.03445613 0.03401308 0.03162176 0.02769444 0.02888136 0.03506768
  0.03536267 0.01496349 0.01268103 0.03914527 0.03103087 0.0333912
  0.03115818 0.03230381 0.03227003 0.03415583 0.02618087 0.05100405
  0.046249   0.02910818]
 [0.03284215 0.02396216 0.02002959 0.01861694 0.01326309 0.01924088
  0.02823453 0.02698482 0.0222378  0.01889235 0.02377516 0.02288301
  0.02573499 0.009455   0.00912585 0.03737497 0.02646939 0.04389196
  0.03879426 0.04825178 0.05010946 0.03106714 0.0204627  0.08028591
  0.07096013 0.03554063]
 [0.0337178  0.02161652 0.02026248 0.01755698 0.01448688 0.02028818
  0.02639487 0.0256002  0.02260297 0.01953156 0.0279899  0.0264839
  0.02589466 0.0092619  0.00883933 0.03269888 0.0258032  0.03711792
  0.03227694 0.0471307  0.0422649  0.02614936 0.01683481 0.05841194
  0.04973029 0.02763395]
 [0.03369556 0.01953321 0.01690418 0.01379571 0.01190065 0.0157226
  0.02341167 0.02174632 0.0193749  0.01566862 0.03596749 0.02173899
  0.02268501 0.00742436 0.00777982 0.03353605 0.02962964 0.03684576
  0.03607397 0.04122172 0.04042383 0.02680686 0.01658049 0.06114959
  0.04747714 0.03528104]
 [0.03282087 0.03116078 0.02926792 0.02145218 0.01952603 0.02621307
  0.04027267 0.03977466 0.03535943 0.02369126 0.03145108 0.03134647
  0.03545319 0.01090702 0.01085131 0.03255657 0.03521615 0.04450037
  0.04302984 0.04646417 0.04398556 0.03255476 0.02607151 0.0471224
  0.04390673 0.0525783 ]
 [0.03428961 0.02362977 0.02203152 0.01898767 0.01541472 0.02077802
  0.02323139 0.0257284  0.02234654 0.02023762 0.02641138 0.02531595
  0.02427915 0.01024252 0.00942071 0.02443231 0.02378028 0.02787271
  0.02881449 0.02740415 0.02907502 0.02929989 0.01772593 0.02899981
  0.03476965 0.03083977]
 [0.03441097 0.02640572 0.0287537  0.02764857 0.02150702 0.03170922
  0.02890241 0.03604259 0.02893089 0.03136822 0.02885797 0.04004792
  0.03543433 0.01604787 0.01146071 0.02183253 0.0234357  0.02613979
  0.02569602 0.02465619 0.02409263 0.03141012 0.01745801 0.01713795
  0.02408723 0.02495178]
 [0.03452509 0.0319217  0.03271005 0.0316238  0.0226535  0.03501694
  0.03607425 0.04508753 0.02994037 0.03594374 0.03810256 0.04702901
  0.04352193 0.01776446 0.01242883 0.0253361  0.02416518 0.02820776
  0.02544937 0.02510726 0.02406766 0.03206781 0.01868953 0.0155949
  0.01805919 0.01986265]
 [0.03433964 0.0304924  0.02936014 0.03006246 0.02326006 0.03251215
  0.03323983 0.03986697 0.03009455 0.03499145 0.03518562 0.04289433
  0.04213272 0.01775003 0.01305464 0.02950051 0.02619123 0.03108535
  0.02843678 0.02828614 0.02647727 0.03309617 0.01640252 0.01961188
  0.01920346 0.01775618]
 [0.0341754  0.0244356  0.02189551 0.01881455 0.01462419 0.0206591
  0.02594418 0.02881432 0.02437524 0.02165951 0.02745429 0.02738662
  0.03014401 0.01059916 0.00915842 0.03255191 0.0282903  0.03300616
  0.03057143 0.02956622 0.03257824 0.03115194 0.01522731 0.03132766
  0.02938912 0.02129374]
 [0.03409799 0.02566637 0.0219011  0.01909057 0.0143549  0.01946452
  0.02955726 0.02999254 0.02462031 0.02076593 0.02888013 0.02455416
  0.03038288 0.00992916 0.00896278 0.03487693 0.02898187 0.03681754
  0.03584723 0.03399868 0.03827147 0.02701307 0.01494321 0.03256653
  0.03179954 0.02328268]
 [0.03428768 0.02411039 0.0206025  0.01861367 0.01525075 0.01933143
  0.02500372 0.02752457 0.02360109 0.02177692 0.02869174 0.0262406
  0.02819786 0.01029062 0.0093109  0.03090227 0.0329474  0.03388552
  0.03709429 0.03120693 0.03598057 0.02786121 0.01539104 0.02447185
  0.02393387 0.02195647]
 [0.03440314 0.02695552 0.02341955 0.02025178 0.01555603 0.02103548
  0.02996559 0.03127588 0.02842453 0.02306837 0.03322908 0.02713933
  0.03112086 0.01064727 0.00970799 0.03164784 0.03110181 0.03524347
  0.03683603 0.03498034 0.03828857 0.02903299 0.01600971 0.02568162
  0.02286563 0.02289441]
 [0.03449764 0.02024831 0.01790562 0.01361115 0.01166869 0.01519677
  0.02510906 0.023463   0.02197488 0.01561318 0.03895709 0.01994086
  0.02480718 0.00773703 0.00754833 0.02998394 0.03416296 0.0327461
  0.03846577 0.03304294 0.03665036 0.02716957 0.01425724 0.03645387
  0.02596812 0.0246498 ]
 [0.03273962 0.03138717 0.02650024 0.01786076 0.01628258 0.02237297
  0.05219136 0.04314905 0.03582847 0.02216011 0.06699132 0.03333338
  0.04378092 0.01010233 0.01084147 0.03446315 0.05818037 0.05558212
  0.05910609 0.05481405 0.05507747 0.03371743 0.02575376 0.04744492
  0.03943191 0.06013092]
 [0.03459007 0.02498989 0.02347265 0.02172983 0.01705311 0.02578433
  0.02743959 0.03096306 0.02950542 0.02412175 0.02794435 0.03055942
  0.02965496 0.01343931 0.01096542 0.02008472 0.02631814 0.02666273
  0.02998523 0.0263643  0.02845346 0.02958122 0.01543181 0.01772165
  0.0223492  0.02657328]
 [0.03307328 0.03283354 0.03165459 0.05189028 0.05344962 0.0450994
  0.02884376 0.02842073 0.03484334 0.05152267 0.03411192 0.03494604
  0.03429656 0.0890147  0.10289622 0.02580362 0.03060564 0.02608858
  0.02743858 0.0257064  0.02421578 0.03759585 0.03614366 0.01100244
  0.01222482 0.03107853]
 [0.03287834 0.0348396  0.03164062 0.05758527 0.10663527 0.04440447
  0.02639487 0.02682328 0.03365533 0.05834845 0.03924029 0.03546587
  0.02872714 0.08683632 0.10755179 0.03123159 0.04269935 0.03599019
  0.03240358 0.02814903 0.02892005 0.0343812  0.03609318 0.00947077
  0.0089657  0.02681725]
 [0.03266983 0.0312623  0.02756968 0.0463782  0.10457829 0.03029536
  0.02197817 0.02610918 0.02867933 0.05156507 0.03821954 0.03892051
  0.02839901 0.0389676  0.05000009 0.02693501 0.0651608  0.05608369
  0.04557538 0.03359829 0.04509903 0.02933689 0.03221355 0.0152825
  0.01627857 0.03112241]
 [0.03285686 0.03893705 0.03198064 0.04840991 0.06609414 0.0358046
  0.02899906 0.02840406 0.03419902 0.04688519 0.03643046 0.03319312
  0.0299152  0.03903975 0.04231216 0.02401441 0.04460579 0.03724573
  0.03562547 0.03126915 0.03410802 0.05434786 0.04894871 0.0128933
  0.01416666 0.02997546]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Fred', ' is', ' in', ' the', ' cinema', ',', ' which', ' explicitly', ' states', ' Fred', "'s", ' current', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.25, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03352204 0.04765064 0.05046885 0.06599698 0.05720321 0.04936256
  0.03632879 0.04011432 0.05671089 0.05131383 0.03501311 0.03320964
  0.03539848 0.10456421 0.10348192 0.03291367 0.02923861 0.02632328
  0.02357415 0.02819768 0.024898   0.03563692 0.05804388 0.02793009
  0.02255267 0.04496216 0.04829378 0.04292469 0.09834848 0.01511757
  0.0116838  0.03187893]
 [0.0343587  0.05179533 0.04854404 0.08509644 0.08525933 0.08959032
  0.05012165 0.0520819  0.06094405 0.07696969 0.0552241  0.06788217
  0.06916045 0.15072228 0.10762856 0.03497641 0.0294337  0.03352369
  0.02619537 0.031411   0.02684444 0.04113274 0.04483151 0.02383891
  0.02332984 0.03844253 0.04280316 0.03729518 0.09091023 0.02026349
  0.01988964 0.03740088]
 [0.03509158 0.04187818 0.04657231 0.06652292 0.05971466 0.05994658
  0.03768357 0.03966315 0.0505406  0.05391821 0.03723788 0.04650258
  0.04382652 0.11879946 0.08150454 0.0301408  0.02746919 0.02566278
  0.02224751 0.02517496 0.02207284 0.03566381 0.03953767 0.0235772
  0.02194966 0.03253359 0.04020546 0.0297611  0.0818716  0.03065369
  0.02277755 0.03614393]
 [0.03394241 0.04173077 0.04591    0.03835603 0.03227359 0.03797997
  0.03665785 0.03991932 0.04106464 0.03348788 0.0295273  0.03511084
  0.03545007 0.03088969 0.02914067 0.034144   0.03300896 0.02829419
  0.02789908 0.0300655  0.0272816  0.04016928 0.05080615 0.04118443
  0.04049206 0.04157459 0.05100957 0.03331474 0.07309861 0.09094382
  0.03828396 0.03256406]
 [0.03500586 0.03078646 0.03173396 0.0274751  0.02117709 0.0291339
  0.02852742 0.0276669  0.03364473 0.02472693 0.02503331 0.02509486
  0.02620021 0.01792731 0.01897527 0.02441492 0.02315986 0.02249701
  0.02429701 0.02787251 0.02587437 0.03304071 0.03507516 0.03987337
  0.04720122 0.04230742 0.04271461 0.03847538 0.05060581 0.06712231
  0.03475858 0.03218002]
 [0.03492726 0.04716137 0.0482598  0.03047576 0.02401436 0.03412803
  0.03713571 0.03817772 0.04663607 0.02758923 0.02514446 0.02992362
  0.03164873 0.02350678 0.02190013 0.03382741 0.03056166 0.02422482
  0.02569311 0.02759874 0.02375786 0.03813481 0.055904   0.03686832
  0.03642032 0.03642515 0.05590979 0.02554118 0.04701398 0.11162319
  0.0337172  0.02565704]
 [0.03517534 0.06117774 0.05301458 0.02881285 0.02315769 0.0300578
  0.03946894 0.03601744 0.04846078 0.02514422 0.02534453 0.02692981
  0.02969559 0.01820598 0.01970117 0.04283706 0.04059659 0.03415656
  0.03420786 0.04024556 0.03218107 0.0343296  0.07015032 0.04629819
  0.04772519 0.04248431 0.04734915 0.02575221 0.02419279 0.08641023
  0.02104691 0.02068928]
 [0.03536937 0.03550667 0.03401339 0.0241231  0.0196175  0.02296375
  0.02838564 0.02498088 0.03217891 0.02068196 0.02200482 0.02042945
  0.02090289 0.01543876 0.01842734 0.03194098 0.0306271  0.02485911
  0.02823647 0.03067845 0.02646586 0.03231408 0.0466703  0.04287424
  0.04553125 0.03325377 0.03760774 0.02153585 0.02195781 0.07367064
  0.02162028 0.01665971]
 [0.0354736  0.02223832 0.02345932 0.01960138 0.01603337 0.01960475
  0.02420227 0.0234381  0.02454063 0.01878005 0.02208861 0.02003741
  0.02229571 0.0120424  0.01510399 0.02264695 0.02703332 0.02638211
  0.02670373 0.03022902 0.02619059 0.0303997  0.02720872 0.03153966
  0.03827324 0.03482191 0.02215433 0.02432304 0.01892587 0.03316612
  0.02117423 0.02165713]
 [0.03565617 0.02653356 0.02848316 0.02362553 0.01925323 0.02574109
  0.02612592 0.0252447  0.02657073 0.02178494 0.0236191  0.02327897
  0.0221196  0.01487534 0.01717087 0.02896779 0.03275151 0.02691789
  0.03603676 0.03394971 0.03352594 0.03504957 0.03351286 0.04432159
  0.05059385 0.03410032 0.03061164 0.02635091 0.02812039 0.05242303
  0.03289359 0.02161478]
 [0.03578632 0.033421   0.03361877 0.03100824 0.02393016 0.03288725
  0.03514729 0.03394701 0.03070444 0.02974067 0.03204619 0.03487489
  0.03468695 0.02036597 0.02006552 0.0344917  0.03822831 0.03391347
  0.03943503 0.03501116 0.03308815 0.04127689 0.02886476 0.03807904
  0.04062378 0.02973424 0.03008029 0.02703851 0.02845706 0.04557
  0.0446911  0.03096579]
 [0.03565951 0.02730197 0.02416853 0.02222232 0.01669602 0.02364118
  0.02885824 0.02520838 0.02319588 0.02099021 0.02667495 0.02311018
  0.02540686 0.01296237 0.01488795 0.03937534 0.03666942 0.0401791
  0.05392499 0.04958093 0.0499138  0.03469317 0.02101631 0.05272803
  0.0537889  0.03192711 0.02380742 0.03078837 0.01525655 0.03163407
  0.02970978 0.03296221]
 [0.03617149 0.02917124 0.02670874 0.02321308 0.01914706 0.02609459
  0.03030228 0.02916953 0.02504438 0.02417753 0.03153659 0.03123767
  0.02955684 0.01437762 0.01550919 0.04060676 0.04642715 0.03638117
  0.05663246 0.03993814 0.04291041 0.03546922 0.02223775 0.03526295
  0.03812834 0.02910951 0.02835341 0.0335394  0.01784527 0.0288549
  0.04067665 0.04505938]
 [0.03648105 0.02368889 0.0225045  0.01757185 0.01573866 0.02040189
  0.02786753 0.02348589 0.0220176  0.01853891 0.03328939 0.02424635
  0.02609882 0.01079752 0.01253395 0.04683644 0.04560356 0.03712389
  0.05190603 0.04098652 0.04481212 0.03219784 0.01933281 0.03897704
  0.04096627 0.03506759 0.01934998 0.03691936 0.01275361 0.02133154
  0.03304813 0.04291187]
 [0.0350557  0.02860669 0.02517579 0.01958829 0.01707676 0.02330317
  0.03313787 0.02703602 0.03198217 0.02265097 0.02902112 0.02595425
  0.03157758 0.01220303 0.01465512 0.06646707 0.04785701 0.06980706
  0.06754937 0.09140372 0.06852903 0.03210618 0.03204334 0.08184544
  0.08392889 0.07003972 0.02427973 0.03746056 0.02016189 0.02247175
  0.03060275 0.02635876]
 [0.03636013 0.02727531 0.02763597 0.02464467 0.02069932 0.02984935
  0.02865519 0.02912557 0.02621401 0.02659738 0.03024893 0.03169686
  0.02887556 0.01675544 0.01673096 0.03049123 0.02830081 0.029061
  0.03576731 0.03180344 0.0351379  0.03289861 0.0246134  0.02825451
  0.03070055 0.03426738 0.02670032 0.0332365  0.02555703 0.02462067
  0.0815131  0.05090323]
 [0.0363573  0.02772224 0.03383678 0.0338976  0.02685347 0.03734057
  0.02995921 0.03580905 0.03391065 0.04020852 0.03179481 0.04450247
  0.03608333 0.02515445 0.01998492 0.02386963 0.02749204 0.02704404
  0.02626559 0.02536744 0.02537548 0.03605503 0.02592574 0.02315328
  0.02668881 0.03174179 0.03512811 0.03590988 0.03514726 0.02913341
  0.09881424 0.0449083 ]
 [0.03652406 0.03453283 0.04033424 0.04006695 0.03141142 0.04633593
  0.03770807 0.04416342 0.03580887 0.04760018 0.03571252 0.05398485
  0.04781108 0.02907286 0.02190349 0.02542801 0.02581214 0.02703766
  0.02498781 0.02530391 0.02381077 0.0363848  0.02913083 0.02167835
  0.02234923 0.02818716 0.04327548 0.02788025 0.03453571 0.03068363
  0.10842188 0.0483378 ]
 [0.03678092 0.04186093 0.04721529 0.04417185 0.0320521  0.04967522
  0.04272111 0.04997515 0.04112951 0.05311299 0.04185157 0.06439558
  0.05176717 0.03138131 0.02457483 0.03305504 0.03292747 0.03324942
  0.03107217 0.03112602 0.02937859 0.03765218 0.03540466 0.02638492
  0.02618241 0.03198045 0.04870705 0.03440188 0.03268905 0.03161055
  0.06242425 0.04004713]
 [0.03712084 0.03359663 0.03784371 0.03107153 0.02652947 0.03671102
  0.03918363 0.04018506 0.0323216  0.03809062 0.03743966 0.04240979
  0.04062999 0.02186884 0.01950752 0.03385361 0.0302042  0.03072857
  0.03019665 0.03031871 0.03155557 0.03833068 0.02776358 0.0311425
  0.02669467 0.02638458 0.03477388 0.03843151 0.02433577 0.02834547
  0.04598886 0.04733959]
 [0.03682783 0.03141687 0.03036659 0.02313888 0.02092448 0.02765368
  0.04811573 0.04596429 0.02803872 0.02811346 0.03649572 0.03145274
  0.04039696 0.01542294 0.01632184 0.04006419 0.0327441  0.03832939
  0.03965944 0.03809368 0.04400898 0.03873061 0.0253813  0.04218277
  0.032874   0.02650391 0.02231668 0.04151509 0.01814321 0.02292879
  0.02694918 0.04911717]
 [0.03639108 0.04442647 0.04220939 0.02811452 0.02378921 0.03219573
  0.06087763 0.06239581 0.03589751 0.03645712 0.07006898 0.04297788
  0.05869389 0.01844084 0.01989761 0.05664521 0.04821015 0.05149281
  0.04580869 0.04458387 0.04992514 0.03882508 0.03269099 0.05055577
  0.0429114  0.03811261 0.03436061 0.04996678 0.01997188 0.02455706
  0.03105319 0.05267799]
 [0.03657725 0.04244272 0.03912692 0.02652362 0.02254264 0.0294381
  0.05663475 0.0557257  0.03976097 0.03309785 0.0594479  0.03734418
  0.05242533 0.01719595 0.01810609 0.05200174 0.04291054 0.04707547
  0.03929763 0.0403773  0.04162475 0.03652255 0.02910432 0.04835173
  0.0374141  0.03711586 0.03140867 0.04518551 0.01850249 0.02268931
  0.03120071 0.06680828]
 [0.03743844 0.02729883 0.02985468 0.02284209 0.02154136 0.02743538
  0.03684514 0.0363692  0.02975533 0.02778634 0.05374662 0.03764365
  0.03763624 0.01713389 0.01662631 0.03264403 0.03265026 0.03066621
  0.03377736 0.0309924  0.03326327 0.03281156 0.02178705 0.02805718
  0.02634633 0.03123499 0.0248406  0.03660461 0.01980492 0.01839735
  0.03672717 0.05508104]
 [0.03563141 0.03421606 0.03469363 0.05306034 0.05002215 0.04544161
  0.03239397 0.03163378 0.04440058 0.05468987 0.03575698 0.03882429
  0.03545718 0.07135148 0.09112594 0.02801038 0.02912192 0.03223598
  0.02708463 0.02869103 0.02843119 0.03481248 0.03886825 0.02190327
  0.02202285 0.0368407  0.04144527 0.04307348 0.0451046  0.0112348
  0.01329547 0.0451575 ]
 [0.03520558 0.04101098 0.03705308 0.0674744  0.1512526  0.05214835
  0.03315188 0.03143879 0.03789734 0.06527305 0.04714586 0.04713328
  0.03367481 0.09503835 0.13118814 0.03927709 0.04908004 0.05616173
  0.03551923 0.03479813 0.04132491 0.03307451 0.04649608 0.0219133
  0.01997234 0.03550981 0.05127524 0.04104384 0.04176089 0.007885
  0.00794506 0.01509109]
 [0.03550252 0.03118164 0.02718891 0.03962831 0.07379671 0.02775508
  0.02403949 0.02379177 0.02584215 0.03884342 0.03511743 0.03074944
  0.02486076 0.02983342 0.0514835  0.03311618 0.0610659  0.06277745
  0.04943595 0.04133037 0.06696685 0.03040994 0.03534123 0.02806387
  0.02909937 0.03158737 0.0337407  0.04740128 0.0275402  0.00960761
  0.01043214 0.01517369]
 [0.03560619 0.03436974 0.03000508 0.0416753  0.04829232 0.03318301
  0.02976317 0.02727116 0.03478626 0.03963396 0.03236768 0.02906241
  0.0276624  0.03367151 0.04186267 0.02695636 0.04081453 0.04389411
  0.03658864 0.03487007 0.04085059 0.04187755 0.04225703 0.02315997
  0.02523838 0.03374935 0.02749734 0.05432896 0.02738708 0.00705002
  0.00866067 0.0146534 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' school', ',', ' which', ' means', ' Fred', ' is', ' in', ' the', ' school', '.', ' There', ' is', ' no', ' mention', ' of', ' the', ' bedroom', ' in', ' relation', ' to', ' Fred', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.0, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02100218 0.03378181 0.0326502  ... 0.01533906 0.02290076 0.03094293]
 [0.02144346 0.02646031 0.02591485 ... 0.01764921 0.01877783 0.02268299]
 [0.02194557 0.03454855 0.03555049 ... 0.0136374  0.01705575 0.0253205 ]
 ...
 [0.02198377 0.02979594 0.02747419 ... 0.01085457 0.01843359 0.03376811]
 [0.02243039 0.02505284 0.02164406 ... 0.01353856 0.01650584 0.03331233]
 [0.02245415 0.02471642 0.02125686 ... 0.01234826 0.01693041 0.02872434]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Fred', ' is', ' in', ' the', ' bedroom', ',', ' which', ' explicitly', ' states', ' Fred', "'s", ' current', ' location', '.', ' There', ' is', ' no', ' indication', ' that', ' Fred', ' is', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0769, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02396949 0.03029894 0.03498124 ... 0.00759395 0.02304827 0.0357782 ]
 [0.02444077 0.02250788 0.02645295 ... 0.01183095 0.01516287 0.0220816 ]
 [0.02494787 0.0330896  0.04176277 ... 0.0134631  0.02270464 0.03653382]
 ...
 [0.02506681 0.04009085 0.03663942 ... 0.00593674 0.04636476 0.04454816]
 [0.02567949 0.03158896 0.02609863 ... 0.00638319 0.03043491 0.02880104]
 [0.02547737 0.03325283 0.02748577 ... 0.00522387 0.03970072 0.03794961]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 50), x_tokens=50, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 50)
DEBUG result.interpretability.attn_scores 1550 
 [[0.03031434 0.04253906 0.04585728 ... 0.03219511 0.03577323 0.08900156]
 [0.03086129 0.04068118 0.04574126 ... 0.03668359 0.0380302  0.03851261]
 [0.03165223 0.04303496 0.05356529 ... 0.02618949 0.03360082 0.04635858]
 ...
 [0.03181065 0.04730121 0.03750812 ... 0.02598175 0.03448437 0.05041676]
 [0.03214133 0.0350933  0.0259634  ... 0.03329864 0.04373968 0.0363953 ]
 [0.03200198 0.04239432 0.02931772 ... 0.02971167 0.03446104 0.05589794]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' being', ' in', ' the', ' bedroom', ' and', ' Bill', ' being', ' in', ' the', ' office', '.', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02672249 0.05036331 0.05394999 0.0836266  0.08246958 0.05332526
  0.03884995 0.03327392 0.03622866 0.05302071 0.039565   0.02512566
  0.02717934 0.13054141 0.13227774 0.0419815  0.02875793 0.01989557
  0.01754095 0.01916596 0.01907001 0.0401881  0.06436792 0.01399576
  0.01096207 0.02891876]
 [0.02758164 0.03162435 0.03191703 0.06182335 0.05831708 0.04551744
  0.02727482 0.02421227 0.02907417 0.0455707  0.03423316 0.0269598
  0.02692244 0.13256374 0.15712619 0.04002406 0.03122846 0.02355947
  0.01949478 0.02002299 0.01802618 0.03428417 0.03805591 0.00959525
  0.00884541 0.01904248]
 [0.02805201 0.03528283 0.04059367 0.06398448 0.0647283  0.05796395
  0.03623195 0.03371893 0.03826434 0.05352314 0.03919433 0.04327569
  0.04268659 0.10561106 0.09760719 0.03324321 0.02821081 0.02387519
  0.01877023 0.02000492 0.01700879 0.03089914 0.03495546 0.01305564
  0.01156774 0.0180076 ]
 [0.02713008 0.0414301  0.04800783 0.04969639 0.05266313 0.0538286
  0.0407048  0.04206857 0.04207933 0.04759385 0.03891663 0.04959308
  0.04404416 0.06220568 0.05634324 0.04082464 0.03467432 0.03112885
  0.02427906 0.02672383 0.02382009 0.03469412 0.05234051 0.03149539
  0.02892442 0.03041452]
 [0.02734228 0.0558828  0.06488612 0.03912428 0.03173909 0.04747063
  0.05066214 0.04963023 0.0471637  0.03720827 0.03492862 0.04203787
  0.04338096 0.02689311 0.02044315 0.0383742  0.03119128 0.02944355
  0.02415702 0.02799289 0.02546779 0.03194314 0.06624224 0.04009593
  0.03712156 0.03814154]
 [0.02822776 0.07203677 0.08138443 0.03571223 0.02418295 0.04345668
  0.04980022 0.04240203 0.04969141 0.03167258 0.02791851 0.03353602
  0.03220224 0.01942284 0.01637165 0.04348924 0.03036275 0.02559304
  0.02196988 0.02724293 0.02256937 0.03086123 0.07079781 0.02825678
  0.02667967 0.03139381]
 [0.02823314 0.04346116 0.05456791 0.03117402 0.02153042 0.03987797
  0.04574845 0.04258834 0.04442511 0.02992674 0.02726651 0.03494454
  0.03048889 0.01773196 0.01501465 0.03911269 0.0299932  0.02616011
  0.02301629 0.02694611 0.02358437 0.031477   0.05096657 0.03601959
  0.03683524 0.03933346]
 [0.02878858 0.03348279 0.03646887 0.02908487 0.02036751 0.04061819
  0.03934694 0.04074777 0.03557537 0.03020703 0.02996986 0.03841813
  0.0327945  0.01615682 0.01300642 0.02798093 0.0255563  0.02595505
  0.02182744 0.02417397 0.021159   0.02937303 0.02827962 0.02798905
  0.02776583 0.02762589]
 [0.02839236 0.02529158 0.02456413 0.01957334 0.01509427 0.02382809
  0.03124756 0.02973755 0.0244846  0.02092173 0.0309889  0.02318107
  0.02747063 0.01114445 0.01034123 0.0323589  0.03019704 0.02893
  0.02604039 0.02943543 0.03146593 0.02807534 0.02514404 0.05856406
  0.04593712 0.03187077]
 [0.02850109 0.01951187 0.01675311 0.01637883 0.0123116  0.01621866
  0.02333638 0.02166086 0.01802475 0.01624629 0.02103638 0.01567272
  0.01890816 0.00867902 0.00837712 0.02590672 0.02384347 0.0278559
  0.02736052 0.03179373 0.03821317 0.02474351 0.01918183 0.06268112
  0.05259777 0.0324365 ]
 [0.02883565 0.02119769 0.01818694 0.01696271 0.01366002 0.0177741
  0.02295792 0.02224472 0.01864634 0.01746435 0.02387012 0.01908551
  0.02063119 0.00899884 0.00884407 0.02819424 0.02695247 0.02591057
  0.02435067 0.02638725 0.03171127 0.02474667 0.01822468 0.0654398
  0.04495529 0.02299963]
 [0.02869442 0.01782262 0.01553769 0.01274283 0.01182429 0.0138618
  0.02167388 0.01949394 0.01656518 0.01375351 0.02812617 0.01605929
  0.01916398 0.00716689 0.00771394 0.0279721  0.03403041 0.02742409
  0.02946758 0.03040857 0.0372804  0.02337866 0.0191376  0.07142106
  0.04027685 0.02484555]
 [0.02811129 0.02001599 0.01705053 0.01365623 0.01270893 0.01464643
  0.0207267  0.01770915 0.01854159 0.01412623 0.02265669 0.01535141
  0.01764196 0.00763189 0.00837608 0.02744379 0.03178488 0.02723386
  0.02929202 0.03266115 0.03745446 0.02512537 0.02351931 0.08627305
  0.0571545  0.04564226]
 [0.02901652 0.01931006 0.01675844 0.01486556 0.0133416  0.01568965
  0.01960901 0.01850305 0.01772429 0.01552618 0.02294164 0.01689492
  0.01762046 0.00839138 0.00841943 0.02200351 0.02583547 0.02183873
  0.02382015 0.02725738 0.02979608 0.02479887 0.01903704 0.04480518
  0.04228455 0.03399419]
 [0.02930756 0.02036896 0.01887766 0.01571338 0.01344128 0.01770106
  0.02280405 0.0239417  0.02109824 0.01683519 0.01951385 0.01880324
  0.01961436 0.00846124 0.00796078 0.02164494 0.0221723  0.01997694
  0.02024359 0.02215857 0.02743318 0.02682487 0.01766977 0.02379057
  0.0593465  0.04493706]
 [0.02895854 0.01861185 0.01568684 0.01434088 0.01226868 0.01494351
  0.02210952 0.0223895  0.01758646 0.0151311  0.01972153 0.01587577
  0.01951547 0.00725865 0.00736535 0.02623367 0.02264827 0.02340974
  0.02412699 0.02478614 0.04002105 0.02407273 0.01499883 0.02521494
  0.07766966 0.05831352]
 [0.02936983 0.02090055 0.01967314 0.01651321 0.01438961 0.01863966
  0.02505295 0.02671858 0.02319594 0.01819488 0.021727   0.01963497
  0.02226823 0.0082414  0.00799842 0.02328512 0.02231108 0.020446
  0.01988246 0.02078018 0.02755385 0.02411977 0.01718877 0.0248294
  0.05393894 0.05381211]
 [0.02877973 0.01763197 0.01519499 0.01235731 0.0112899  0.01410163
  0.0215855  0.02030327 0.01750652 0.01371325 0.0263658  0.01606376
  0.02059894 0.00649231 0.00662456 0.02996714 0.03351213 0.03074586
  0.03494292 0.03119151 0.04118688 0.02348755 0.01605896 0.03120546
  0.04653757 0.07054096]
 [0.02807392 0.02698685 0.02507018 0.03024782 0.02931913 0.03581566
  0.03211261 0.02978858 0.03316895 0.04184496 0.0347294  0.05120744
  0.04990546 0.02405101 0.01711581 0.02571932 0.03004416 0.03852717
  0.04322908 0.02739924 0.02864066 0.0320753  0.02387672 0.01954397
  0.02539298 0.03773968]
 [0.02949863 0.02093318 0.01835651 0.01580136 0.0132793  0.01800307
  0.02308165 0.02269448 0.02119059 0.01680686 0.02410677 0.01987874
  0.02038612 0.0087023  0.00829899 0.02178592 0.02491078 0.02167237
  0.02630796 0.02341272 0.02506788 0.02735718 0.01698098 0.01789382
  0.02163376 0.0356699 ]
 [0.02879607 0.02820634 0.02972501 0.02880013 0.02302143 0.03653812
  0.03454242 0.03958717 0.0384063  0.03468866 0.03124487 0.04769926
  0.04041645 0.01921602 0.01383105 0.02533455 0.02548098 0.0275456
  0.02586753 0.02579994 0.0223873  0.03324049 0.02428624 0.01692717
  0.01704979 0.01909515]
 [0.02918207 0.02685373 0.02568544 0.02496417 0.02472011 0.02893855
  0.02998951 0.03354805 0.03039316 0.02817941 0.03091163 0.03704029
  0.03605567 0.0159096  0.01271181 0.02358815 0.02534604 0.02679445
  0.02570507 0.0272244  0.02187954 0.02645215 0.02293653 0.01615977
  0.01533247 0.01854308]
 [0.02939088 0.02694047 0.02714235 0.02321735 0.0197196  0.03303639
  0.03151581 0.03475374 0.03797215 0.02923497 0.02749471 0.04582385
  0.03834624 0.01558087 0.01122608 0.02125305 0.02381366 0.02369545
  0.02352178 0.02363996 0.0207388  0.02708204 0.02532578 0.01479832
  0.01479287 0.01875864]
 [0.02897342 0.03823623 0.03329226 0.02643265 0.02204542 0.03600023
  0.03683083 0.04476712 0.04050538 0.03427419 0.03344473 0.05508768
  0.0478632  0.01728476 0.01253246 0.0271288  0.0252438  0.02776151
  0.02497666 0.02564046 0.02277066 0.02891453 0.02692871 0.01560643
  0.01538231 0.0178408 ]
 [0.02966456 0.02718781 0.02926334 0.02416434 0.01883219 0.03253403
  0.0351205  0.03644835 0.03522668 0.02903071 0.02911382 0.04010165
  0.03641468 0.01448512 0.01097716 0.02160365 0.02064248 0.02110891
  0.02049537 0.0218753  0.02004042 0.02811341 0.01989485 0.01294706
  0.01263969 0.01306726]
 [0.0287     0.01951445 0.01778742 0.01448645 0.01198765 0.01573899
  0.02402987 0.0234599  0.02201753 0.01711697 0.02506302 0.01943024
  0.02520157 0.0089961  0.00806123 0.0273743  0.02801978 0.03183371
  0.03416755 0.03681123 0.0408489  0.02634293 0.01657631 0.03028631
  0.02528286 0.01832069]
 [0.02921354 0.01909364 0.01686409 0.01503193 0.01161524 0.01463656
  0.0212372  0.02125026 0.02003837 0.01618814 0.0207297  0.01729599
  0.02162438 0.00872901 0.0075377  0.02730481 0.02286397 0.03312951
  0.02992918 0.03685686 0.03794461 0.0244767  0.01324142 0.02491329
  0.02167144 0.01550817]
 [0.02935043 0.01983392 0.01774924 0.01536146 0.01272692 0.01543995
  0.01977432 0.02301845 0.02117818 0.01859892 0.02345478 0.02217977
  0.024246   0.00915635 0.00755353 0.02819197 0.02613996 0.03081421
  0.03005238 0.03112961 0.0328424  0.02270754 0.01319538 0.01983144
  0.01793019 0.0129429 ]
 [0.02921935 0.01724808 0.01605973 0.01217175 0.01108639 0.01278405
  0.0189883  0.01987725 0.01945261 0.01478968 0.02564619 0.01727703
  0.01957243 0.00771476 0.00659393 0.02542854 0.02896883 0.02659337
  0.03502685 0.03330449 0.03481179 0.02245419 0.01389144 0.02395651
  0.01915138 0.01625727]
 [0.02790875 0.02186584 0.01994215 0.01524788 0.01376247 0.015663
  0.02073813 0.02116363 0.02550589 0.01806816 0.02356707 0.01775788
  0.0203614  0.00931935 0.00871481 0.02799802 0.03345444 0.04436025
  0.05873881 0.07305998 0.04929083 0.02670833 0.0293646  0.0349894
  0.02556686 0.03077736]
 [0.02960776 0.01995158 0.01930558 0.01682034 0.01359495 0.01750269
  0.01967659 0.02160509 0.02359563 0.01922807 0.02313965 0.02115449
  0.02208012 0.01142661 0.00864862 0.01934659 0.02227807 0.02348786
  0.03113189 0.03080297 0.02619928 0.02497642 0.01654905 0.01403462
  0.01360587 0.01476834]
 [0.02821556 0.03147664 0.03038466 0.05336918 0.05573792 0.04101989
  0.02670193 0.02633172 0.03125732 0.05214555 0.03452776 0.03204551
  0.03322445 0.08435695 0.10060747 0.02731905 0.03004256 0.02624691
  0.02164264 0.02078289 0.01915971 0.03303269 0.03400921 0.01028492
  0.0110664  0.02107714]
 [0.02809254 0.03329128 0.03062526 0.05601181 0.11013988 0.03978718
  0.02396749 0.02458608 0.02914033 0.05402855 0.03886592 0.02914815
  0.02489415 0.0871196  0.10720712 0.03354881 0.04025033 0.03608963
  0.02831838 0.02418255 0.02273756 0.02988739 0.03447689 0.00867302
  0.00830291 0.01863428]
 [0.02794331 0.02540322 0.02433773 0.03803492 0.06316807 0.02609316
  0.01832392 0.02190413 0.02531844 0.04340741 0.03266476 0.02980416
  0.02757597 0.03101655 0.03389134 0.02512892 0.04564685 0.06022702
  0.06998401 0.03741255 0.03415906 0.0258477  0.02925374 0.01334742
  0.01385973 0.02003543]
 [0.02812421 0.03274938 0.02834978 0.04250595 0.05891515 0.03100524
  0.02364621 0.02387169 0.02975641 0.04173314 0.03235446 0.02655426
  0.02869922 0.03334228 0.03427964 0.02190497 0.03359066 0.04072963
  0.04032201 0.03153125 0.02765877 0.04723777 0.04304522 0.01107854
  0.01193781 0.01869329]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' in', ' the', ' context', ' sentences', '.', ' The', ' sentences', ' only', ' talk', ' about', ' Julie', ' being', ' in', ' the', ' park', ' and', ' Bill', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 32), x_tokens=32, y_tokens=36, max_supp_attn=0.0556, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 32)
DEBUG result.interpretability.attn_scores 1152 
 [[0.02576713 0.03662029 0.03679708 ... 0.01066882 0.01028583 0.01790844]
 [0.02657794 0.03702501 0.03469052 ... 0.01341038 0.01126235 0.02216134]
 [0.02716837 0.0333072  0.03519661 ... 0.01614704 0.01177321 0.02731721]
 ...
 [0.02747368 0.02640386 0.02203191 ... 0.00936722 0.01040832 0.01232675]
 [0.02770794 0.03008108 0.02738641 ... 0.00989396 0.01047783 0.01389756]
 [0.02794233 0.02707761 0.02544961 ... 0.01043568 0.01014875 0.01584211]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' mention', ' Julie', ' moving', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(29, 38), x_tokens=38, y_tokens=29, max_supp_attn=0.0, attn_on_target=0.0345)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (29, 38)
DEBUG result.interpretability.attn_scores 1102 
 [[0.0322471  0.04841818 0.04797461 ... 0.03392546 0.03140647 0.03556835]
 [0.03284186 0.04197919 0.03865207 ... 0.03086132 0.02812306 0.03315603]
 [0.03374052 0.05628677 0.05651386 ... 0.02867585 0.0200312  0.02672439]
 ...
 [0.03390289 0.03991483 0.04117932 ... 0.02461366 0.0183895  0.02975075]
 [0.03442634 0.03170694 0.03084013 ... 0.02763652 0.02665197 0.03148446]
 [0.03435936 0.03429359 0.03219248 ... 0.02508935 0.02566486 0.02917204]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' explicitly', ' states', ' that', ' Mary', ' moved', ' to', ' the', ' cinema', ',', ' but', ' sentence', ' ', '11', ' creates', ' a', ' contradiction', ' by', ' saying', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' school', '.', ' However', ',', ' since', ' sentence', ' ', '10', ' is', ' a', ' more', ' specific', ' and', ' direct', ' statement', ',', ' it', ' takes', ' precedence', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 44), x_tokens=44, y_tokens=56, max_supp_attn=0.0179, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 44)
DEBUG result.interpretability.attn_scores 2464 
 [[0.01599182 0.01764396 0.02178093 ... 0.0148476  0.0084024  0.01171215]
 [0.01647769 0.01962529 0.02154283 ... 0.02698276 0.01563607 0.0151261 ]
 [0.01689237 0.01933852 0.02503338 ... 0.02066883 0.01302854 0.01193083]
 ...
 [0.017206   0.02227142 0.02169152 ... 0.00800227 0.00790282 0.0105382 ]
 [0.01767469 0.01659277 0.01578703 ... 0.00787891 0.00704075 0.0107166 ]
 [0.01738221 0.02080777 0.01932747 ... 0.00797015 0.00765202 0.01157116]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '13', ' states', ' that', ' Mary', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' park', ',', ' and', ' sentence', ' ', '14', ' mentions', ' Bill', ' going', ' to', ' the', ' office', ',', ' but', ' it', ' doesn', "'t", ' provide', ' any', ' information', ' about', ' Mary', "'s", ' location', '.', ' Therefore', ',', ' we', ' can', "'t", ' conclude', ' Mary', "'s", ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 50), x_tokens=50, y_tokens=56, max_supp_attn=0.0, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 50)
DEBUG result.interpretability.attn_scores 2800 
 [[0.01621413 0.02420308 0.02775234 ... 0.01262119 0.0086702  0.02383947]
 [0.0167196  0.01899624 0.0202435  ... 0.01200415 0.01829406 0.02236895]
 [0.01703136 0.02593275 0.03052205 ... 0.01197034 0.0075442  0.01602504]
 ...
 [0.01717783 0.0253804  0.02432657 ... 0.01095602 0.00835079 0.01927235]
 [0.0175819  0.01981311 0.01766947 ... 0.01543028 0.01705776 0.02195332]
 [0.01765422 0.02030789 0.01864038 ... 0.0135552  0.01266981 0.02005987]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' Fred', ' has', ' arrived', ' at', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 26), x_tokens=26, y_tokens=31, max_supp_attn=0.0968, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 26)
DEBUG result.interpretability.attn_scores 806 
 [[0.03021297 0.05130695 0.05503179 0.08653729 0.08194191 0.05917018
  0.04148961 0.03599074 0.04098488 0.05824798 0.04348907 0.03013609
  0.03125492 0.13383204 0.13267416 0.03599148 0.03150111 0.02176139
  0.02269018 0.02164812 0.02368174 0.0451602  0.06832522 0.00957164
  0.01051151 0.04319124]
 [0.03120289 0.03217675 0.03275609 0.06458406 0.05839365 0.05090788
  0.02908648 0.02618989 0.03308006 0.05047357 0.03735748 0.03258528
  0.03115629 0.13592432 0.15758824 0.03458066 0.03393782 0.02560164
  0.02489001 0.02233999 0.02218706 0.03828672 0.04105146 0.00730995
  0.0086465  0.0286938 ]
 [0.031682   0.03636576 0.04350872 0.06737363 0.06437106 0.06582332
  0.03995542 0.03809578 0.04380057 0.0590167  0.04296251 0.05311693
  0.04957517 0.10846499 0.0965752  0.02930587 0.03114791 0.02608632
  0.0239144  0.02245718 0.02104371 0.03455115 0.03861305 0.01090655
  0.0118549  0.02823968]
 [0.0305709  0.04777    0.05577591 0.05262198 0.05367625 0.0610273
  0.04666488 0.04933247 0.0473198  0.05168344 0.04267651 0.05790503
  0.05062383 0.06471217 0.05667114 0.04057536 0.03996219 0.0338044
  0.02984381 0.02985489 0.02885074 0.03880527 0.05596362 0.03235646
  0.03443309 0.04597244]
 [0.03179996 0.04830154 0.05914808 0.06199997 0.05432286 0.07424697
  0.0565125  0.05803081 0.05873119 0.06249814 0.04566345 0.06183773
  0.05900683 0.05015527 0.03207509 0.02845437 0.03089139 0.02850212
  0.02647264 0.02749372 0.02424522 0.03954278 0.04289006 0.01669416
  0.01994906 0.03671559]
 [0.03117844 0.06156401 0.06595593 0.03722267 0.02882644 0.04664137
  0.05443774 0.05045678 0.05174966 0.03711898 0.034853   0.04372366
  0.04452789 0.02316532 0.01926061 0.04581223 0.03958938 0.0326067
  0.03254796 0.03369498 0.03251133 0.03749484 0.07337157 0.03928373
  0.04572282 0.04461081]
 [0.03180085 0.07694916 0.07716593 0.03443146 0.02700428 0.0399135
  0.0539149  0.04602236 0.05426022 0.03321119 0.03164287 0.03417974
  0.03413372 0.019735   0.01811545 0.04904005 0.04063078 0.03072077
  0.03252203 0.03538884 0.03223795 0.0341627  0.07809714 0.02984164
  0.03331903 0.04022267]
 [0.03197511 0.04238871 0.04870671 0.02662989 0.02125256 0.0294075
  0.04103212 0.03533692 0.0422702  0.02707463 0.02588549 0.0269902
  0.02589679 0.0163538  0.01568672 0.04106157 0.03527249 0.02633506
  0.03070401 0.03201494 0.03083863 0.03250207 0.06330755 0.04326785
  0.05619172 0.04923065]
 [0.03218262 0.01873133 0.01993624 0.01515767 0.01284237 0.01758906
  0.01910815 0.01889533 0.02310893 0.01659572 0.01677899 0.01674892
  0.01651881 0.00863998 0.00924863 0.02162527 0.02332686 0.02104957
  0.02863688 0.03125654 0.03355028 0.02454837 0.04153263 0.0580166
  0.09085289 0.05677258]
 [0.03211317 0.02717005 0.02841838 0.02091761 0.01732023 0.02555031
  0.02916402 0.02567581 0.02658863 0.02197838 0.0251999  0.02497073
  0.0233101  0.0122436  0.01287747 0.04092652 0.02933731 0.02765673
  0.02682191 0.02829101 0.02849405 0.03107485 0.03272825 0.05471053
  0.06797644 0.04551475]
 [0.03220718 0.02830944 0.02839024 0.02366773 0.01920886 0.02803333
  0.03339662 0.03239859 0.0297221  0.02613966 0.02945111 0.03403987
  0.03354573 0.01419977 0.0122515  0.03922252 0.03088497 0.03295221
  0.02912544 0.0305877  0.03018147 0.03369571 0.02488098 0.04923265
  0.04536316 0.02882467]
 [0.03163427 0.02415944 0.01949793 0.01787819 0.01376729 0.01831241
  0.02670267 0.02532582 0.02208605 0.01833233 0.02385678 0.02258072
  0.02505537 0.00921112 0.00889144 0.04379302 0.02712322 0.04340322
  0.03794    0.04707288 0.04614485 0.03092075 0.0192811  0.08468357
  0.05585086 0.03109025]
 [0.03268291 0.02531357 0.02454801 0.0213335  0.01972255 0.02571924
  0.03269875 0.03076148 0.02682103 0.02306315 0.02638131 0.0295591
  0.02801782 0.01181981 0.0102927  0.03628812 0.02301861 0.0338228
  0.02584172 0.03494976 0.0292449  0.02713043 0.02054073 0.05816791
  0.03947707 0.02861156]
 [0.03267871 0.02018027 0.01753961 0.0149226  0.01307637 0.01643255
  0.02216324 0.02246569 0.02004028 0.01680806 0.02541506 0.0226446
  0.02375079 0.00800289 0.00777169 0.04253981 0.02633655 0.04042196
  0.03315499 0.04411144 0.03640112 0.02514529 0.01549959 0.06039148
  0.03654968 0.02201005]
 [0.03268803 0.01822754 0.01567203 0.01286289 0.01125559 0.01465989
  0.02029452 0.02034527 0.01868224 0.01505993 0.02673012 0.01935346
  0.02178206 0.00687185 0.00718589 0.03445452 0.02927238 0.03731913
  0.03826436 0.0416121  0.03553215 0.02542293 0.01628458 0.05619178
  0.03948459 0.02613358]
 [0.03165381 0.02872652 0.02817971 0.02091761 0.01920609 0.02925156
  0.0335384  0.03742017 0.03612342 0.0259125  0.02686109 0.03036944
  0.03273302 0.01092803 0.0108702  0.02780112 0.03654151 0.03648534
  0.05185325 0.04421072 0.04687028 0.03027603 0.02755672 0.04218706
  0.04686319 0.05476445]
 [0.03310244 0.02316227 0.02091177 0.01834504 0.01494422 0.01990964
  0.02347367 0.02463354 0.02202914 0.01956853 0.02619554 0.02380262
  0.02387688 0.00991556 0.0093422  0.02431929 0.02382526 0.02491461
  0.03054234 0.02809553 0.02925093 0.02973911 0.01748032 0.02966246
  0.03526645 0.02963708]
 [0.03318635 0.02689171 0.02859352 0.02710331 0.02147964 0.03135017
  0.0307968  0.03702147 0.02831346 0.03004579 0.0312553  0.04207271
  0.03702377 0.01656219 0.01127352 0.02188796 0.02400293 0.02650901
  0.02468817 0.023757   0.023573   0.03186579 0.01762832 0.01818963
  0.02550934 0.02446228]
 [0.03335416 0.03186372 0.03199744 0.03148574 0.02375042 0.03421869
  0.03671202 0.044125   0.02973    0.03466468 0.03916167 0.04743174
  0.04406599 0.01876955 0.01220588 0.02364597 0.02390304 0.02815221
  0.02465869 0.02442891 0.02348265 0.0320349  0.01892251 0.01597857
  0.01862573 0.01930465]
 [0.03315533 0.0298607  0.02881948 0.02913014 0.02352611 0.03191109
  0.03345754 0.03885216 0.03013631 0.03390748 0.03640059 0.04254883
  0.04263282 0.01769744 0.01238265 0.02725593 0.02610822 0.03132582
  0.02746655 0.02680901 0.02589048 0.03206695 0.01664643 0.02012537
  0.02056562 0.01769557]
 [0.03303085 0.02291514 0.02070578 0.017436   0.01380329 0.01909857
  0.02424686 0.02740137 0.02391522 0.0202105  0.02612738 0.02532042
  0.02945223 0.0097591  0.00843577 0.03207349 0.02891169 0.03280225
  0.03072587 0.02892198 0.0326696  0.02986265 0.01537702 0.03177739
  0.03291176 0.02025222]
 [0.03295541 0.02394874 0.02079925 0.01838284 0.01379637 0.01827018
  0.02734626 0.02819365 0.02408439 0.02013643 0.0272099  0.02294655
  0.02959205 0.00942231 0.00867242 0.03507159 0.02950036 0.03805894
  0.03587439 0.03330555 0.03771144 0.02649134 0.01458617 0.03246852
  0.03378271 0.02209229]
 [0.03344608 0.02281716 0.01987635 0.01743272 0.01315806 0.0185344
  0.02453154 0.02708857 0.02432785 0.01990268 0.02619153 0.02405884
  0.0297893  0.00915008 0.00774473 0.03334033 0.02691915 0.03602705
  0.03142746 0.0328414  0.03256152 0.02477784 0.01312833 0.0286579
  0.02463839 0.017461  ]
 [0.0336572  0.02213214 0.0196395  0.01732751 0.01286867 0.01838497
  0.02457696 0.0242092  0.02459662 0.01937265 0.02787144 0.02246236
  0.02651724 0.00935566 0.00807858 0.03058089 0.02697445 0.03213402
  0.03208379 0.03207481 0.03229919 0.02571689 0.01258914 0.02723467
  0.02083818 0.01648554]
 [0.0333552  0.02155464 0.01905145 0.01367659 0.01085128 0.01540274
  0.02687991 0.02523865 0.02394526 0.01603605 0.04334206 0.02072802
  0.02777188 0.00799939 0.00719133 0.03338048 0.0327976  0.03365764
  0.0403015  0.03611704 0.03629304 0.02746844 0.01377249 0.03506696
  0.02316718 0.01981598]
 [0.0316755  0.03419365 0.02932675 0.01983434 0.017251   0.02368994
  0.04101108 0.03624201 0.04120147 0.02425161 0.03368896 0.02544281
  0.03410251 0.01109291 0.01060452 0.03020099 0.04050912 0.0458814
  0.06365513 0.07131501 0.06100906 0.03338863 0.03461834 0.0433236
  0.04114126 0.05323976]
 [0.03350023 0.02218243 0.01986636 0.01708258 0.01301406 0.01800488
  0.02172901 0.02321566 0.02495866 0.0187422  0.02427508 0.02173876
  0.02398799 0.01002853 0.00796635 0.0202764  0.0243333  0.02308666
  0.03162777 0.02744203 0.03081153 0.02692215 0.01464093 0.02318912
  0.02863597 0.02539126]
 [0.03211374 0.03098881 0.03061264 0.04872941 0.05049023 0.04186266
  0.02849053 0.02909617 0.0331022  0.04950239 0.03546776 0.03608153
  0.03362812 0.07764198 0.09788832 0.02205325 0.03046791 0.02527652
  0.02563125 0.02310862 0.02429608 0.03555937 0.03563414 0.00846398
  0.0119445  0.03117607]
 [0.03174528 0.03436014 0.03187856 0.05831289 0.1117902  0.04486438
  0.02660076 0.02776289 0.03357807 0.06058541 0.04266448 0.037253
  0.02934112 0.08841845 0.10761932 0.02864197 0.04526911 0.03641895
  0.03074163 0.02544574 0.02918936 0.03338657 0.03752945 0.00730043
  0.00807286 0.02790428]
 [0.03164812 0.02889994 0.02638564 0.0421229  0.08583131 0.02825857
  0.02155953 0.02573734 0.02731587 0.0468555  0.0373067  0.03582128
  0.02780309 0.03376989 0.04246836 0.02438447 0.06357946 0.05258374
  0.04188159 0.03019724 0.04509787 0.02850366 0.03011119 0.01483407
  0.01815203 0.0332786 ]
 [0.03181039 0.03658774 0.03130414 0.04453931 0.05725688 0.03355272
  0.02842739 0.02843851 0.03339626 0.04300369 0.0376368  0.03154898
  0.02952588 0.03615687 0.04008991 0.02141463 0.04412388 0.03464179
  0.03347019 0.02915534 0.03384875 0.0534956  0.04741091 0.01091366
  0.01370143 0.03120468]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' bedroom', '.', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' kitchen', ',', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.1522, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02008669 0.03166018 0.03426182 ... 0.01237753 0.00919031 0.00611184]
 [0.02055543 0.03116815 0.03048533 ... 0.01999807 0.01932662 0.01057832]
 [0.02102488 0.02917167 0.03227371 ... 0.02492913 0.01675178 0.0093423 ]
 ...
 [0.0210647  0.02775227 0.0245983  ... 0.00669527 0.00651576 0.00474231]
 [0.02154189 0.02198556 0.0189423  ... 0.00690867 0.0077523  0.00662877]
 [0.02151315 0.02152593 0.01797402 ... 0.00586328 0.00696731 0.00621188]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' kitchen', '.', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Fred', ' went', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 38), x_tokens=38, y_tokens=44, max_supp_attn=0.1364, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 38)
DEBUG result.interpretability.attn_scores 1672 
 [[0.02110491 0.03373232 0.02951082 ... 0.01880887 0.01302107 0.02313174]
 [0.02129296 0.03225695 0.03280741 ... 0.04312246 0.04230418 0.05163943]
 [0.02201017 0.03451289 0.03524023 ... 0.01445246 0.00933831 0.01564801]
 ...
 [0.02254196 0.02705273 0.02229716 ... 0.01606035 0.01520025 0.01780086]
 [0.02273758 0.02889104 0.02584261 ... 0.014359   0.0121681  0.01491657]
 [0.02278758 0.02699555 0.0255692  ... 0.0156923  0.01268488 0.01604135]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Julie', ' is', ' in', ' the', ' park', ',', ' which', ' implies', ' that', ' Julie', ' is', ' not', ' in', ' the', ' school', '.', ' There', ' is', ' no', ' information', ' about', ' Julie', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 44), x_tokens=44, y_tokens=41, max_supp_attn=0.122, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 44)
DEBUG result.interpretability.attn_scores 1804 
 [[0.02267564 0.02870749 0.031787   ... 0.01308095 0.01629414 0.01064824]
 [0.02306959 0.02371733 0.02486952 ... 0.0134558  0.03969141 0.02090407]
 [0.02362847 0.03194616 0.0371261  ... 0.01861711 0.02764775 0.01345014]
 ...
 [0.02385963 0.03271481 0.03311941 ... 0.0062819  0.00779097 0.00712164]
 [0.02443508 0.0253716  0.02500039 ... 0.00710926 0.00658462 0.00813771]
 [0.02419705 0.02986959 0.02809726 ... 0.00680302 0.00715293 0.00820868]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Fred', ' journey', 'ed', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Fred', ' has', ' arrived', ' at', ' the', ' bedroom', ' and', ' is', ' still', ' there', ',', ' as', ' there', ' is', ' no', ' information', ' about', ' Fred', ' leaving', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 50), x_tokens=50, y_tokens=46, max_supp_attn=0.0217, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 50)
DEBUG result.interpretability.attn_scores 2300 
 [[0.02019764 0.02498296 0.03160173 ... 0.03592629 0.03039429 0.0108789 ]
 [0.02052526 0.01940085 0.02674245 ... 0.0173369  0.0240098  0.01972525]
 [0.02101794 0.0249798  0.03449792 ... 0.03286312 0.02201474 0.00891928]
 ...
 [0.02118311 0.02851971 0.02744749 ... 0.05254183 0.02375178 0.00907591]
 [0.02157225 0.02218796 0.01989027 ... 0.03868258 0.02220673 0.01526321]
 [0.02134614 0.02686102 0.02348554 ... 0.0743867  0.02647483 0.01106541]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(25, 26), x_tokens=26, y_tokens=25, max_supp_attn=0.0, attn_on_target=0.04)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (25, 26)
DEBUG result.interpretability.attn_scores 650 
 [[0.03740475 0.05685274 0.06904221 0.08765187 0.08941406 0.08787724
  0.07310287 0.08567312 0.06640909 0.07619665 0.05844008 0.07096805
  0.08367997 0.10040632 0.06194951 0.03849218 0.03557609 0.04196894
  0.03887532 0.04222637 0.03574808 0.04974129 0.04467323 0.02306508
  0.02817729 0.04225475]
 [0.03785272 0.06497558 0.06016723 0.0732329  0.0624413  0.06610163
  0.07033496 0.07232721 0.05837459 0.05819147 0.04940094 0.04630297
  0.05654576 0.10460769 0.10037025 0.04130313 0.03378076 0.03649687
  0.03643252 0.03837983 0.0321229  0.0498139  0.04874057 0.01941177
  0.02112352 0.03932752]
 [0.04081928 0.06839423 0.0405894  0.06028664 0.0431861  0.04150419
  0.03851779 0.02826888 0.0278541  0.04006554 0.03460166 0.02006041
  0.02463597 0.03022222 0.03705428 0.02861602 0.01652465 0.01868312
  0.02414798 0.02478209 0.0225558  0.05644793 0.05512228 0.00967276
  0.00985683 0.02099468]
 [0.03834433 0.04044435 0.05199126 0.03099877 0.02077303 0.03766878
  0.04146102 0.03806169 0.04980505 0.03421084 0.03393653 0.03724672
  0.03557923 0.01652785 0.0151521  0.04937028 0.04252024 0.04244299
  0.04386894 0.04475419 0.04406605 0.04304172 0.0682608  0.06962518
  0.0828386  0.06391213]
 [0.03882094 0.04908839 0.05117697 0.07505278 0.0652113  0.05456336
  0.04167718 0.03681775 0.04177232 0.05289524 0.04220405 0.0308435
  0.03342296 0.10037235 0.10019563 0.04447417 0.03141019 0.02872126
  0.03060478 0.03300331 0.03106541 0.04967797 0.06539629 0.01689692
  0.01472384 0.04660397]
 [0.03956838 0.03174578 0.03127824 0.05797014 0.04944818 0.04995424
  0.03127199 0.02886654 0.035682   0.04975741 0.03746495 0.03516958
  0.03636306 0.11218052 0.12999035 0.04452453 0.03578991 0.03506105
  0.03493774 0.03573518 0.03015773 0.04291864 0.03910799 0.01200313
  0.01208813 0.02991455]
 [0.04014548 0.03546122 0.04060102 0.06032556 0.05306127 0.06249392
  0.04052078 0.0390068  0.04632108 0.05784935 0.04340013 0.05507613
  0.05453929 0.08981411 0.08221716 0.03739611 0.03249364 0.03414521
  0.03315781 0.03474053 0.02818659 0.03841832 0.03706869 0.01635028
  0.01686517 0.02830803]
 [0.03883913 0.05045978 0.05973372 0.04999159 0.04840305 0.06006889
  0.04855913 0.05310049 0.05238315 0.053608   0.04622841 0.06257432
  0.05734925 0.05582484 0.04874015 0.05161969 0.04309773 0.04296789
  0.03937504 0.04182867 0.03694345 0.04330562 0.05426705 0.04031438
  0.03908724 0.04653723]
 [0.03920948 0.05923435 0.06874098 0.03947082 0.03048731 0.0502151
  0.05839512 0.06090442 0.05935816 0.0432084  0.0417898  0.05375485
  0.05615082 0.02678165 0.01913101 0.05110557 0.03954245 0.03970367
  0.03860928 0.04025789 0.03787227 0.03895717 0.06347202 0.04804416
  0.05414128 0.05555761]
 [0.04026122 0.07777671 0.08350011 0.03411235 0.02361036 0.04389054
  0.05691089 0.05208103 0.06137649 0.03473577 0.03337203 0.04290006
  0.04272898 0.0171272  0.01409384 0.05709248 0.0386894  0.03746848
  0.03945735 0.04365072 0.03742601 0.03794101 0.07100404 0.03607829
  0.04121776 0.04550705]
 [0.04017133 0.04608993 0.05259997 0.02749289 0.02082042 0.03246943
  0.04771975 0.04466172 0.04867316 0.03021938 0.0302491  0.03630861
  0.03477271 0.01552875 0.01403242 0.05609483 0.04262    0.03772273
  0.04186194 0.04338986 0.03940773 0.03793481 0.0570728  0.05511886
  0.0641731  0.04781868]
 [0.04040137 0.0261145  0.03017971 0.0183452  0.01540267 0.02324898
  0.03044102 0.03160607 0.04323266 0.02325445 0.02192032 0.02410043
  0.02456636 0.01088055 0.01103529 0.04245779 0.04069028 0.03423652
  0.04088746 0.04417725 0.03978918 0.03321266 0.05325803 0.08051883
  0.09893451 0.05306224]
 [0.04043692 0.03478625 0.03612019 0.02337518 0.01896586 0.03185819
  0.03677059 0.03560955 0.03547716 0.02697925 0.03018201 0.03656032
  0.03291454 0.01213584 0.01200548 0.04843253 0.03540405 0.03459029
  0.03549038 0.03721234 0.03646641 0.03680198 0.03608217 0.06091506
  0.0774475  0.05188601]
 [0.04106139 0.04475162 0.04690887 0.03961404 0.02837958 0.051757
  0.05075304 0.05683517 0.04742472 0.05092131 0.05086686 0.07879712
  0.06363043 0.02118558 0.01480973 0.03586326 0.03549327 0.0401739
  0.03825433 0.03916002 0.03437669 0.04025803 0.02599947 0.02725223
  0.02859656 0.02739719]
 [0.04151652 0.03299648 0.03308202 0.02601238 0.02125693 0.03091869
  0.03839411 0.03746831 0.03182897 0.03072418 0.03808779 0.03945906
  0.03888854 0.0131826  0.01176298 0.03722298 0.03238861 0.03273728
  0.03385009 0.0354343  0.03483719 0.03749979 0.0234813  0.04406934
  0.03655724 0.02511226]
 [0.0408686  0.02586329 0.02223613 0.01712779 0.01453962 0.01951305
  0.02849207 0.0276941  0.02459086 0.02059124 0.03346101 0.02692373
  0.03028313 0.00825737 0.00900126 0.03967581 0.03831294 0.03652148
  0.03545658 0.03697068 0.04576879 0.03394523 0.02115942 0.07544547
  0.05894216 0.03111119]
 [0.04044059 0.02466891 0.02010789 0.01623263 0.01288836 0.01817231
  0.03271779 0.03355777 0.02369205 0.01923951 0.03365209 0.02444251
  0.03205052 0.00731665 0.00766808 0.036723   0.04528947 0.0501508
  0.04275116 0.0431434  0.06342821 0.03126115 0.01875003 0.08280028
  0.06558745 0.03990857]
 [0.04119312 0.02376866 0.02036621 0.01599756 0.01370775 0.01941357
  0.02859294 0.02964436 0.0238757  0.02016694 0.04072937 0.03038041
  0.03183262 0.00767948 0.00751559 0.03541298 0.04231206 0.040368
  0.04237857 0.03903358 0.05245295 0.03018832 0.01591989 0.07143602
  0.04452512 0.02640392]
 [0.04102829 0.02115193 0.0180735  0.01306146 0.01191057 0.01642483
  0.02848247 0.02766979 0.02280031 0.0173377  0.05678745 0.02961185
  0.02985036 0.00658505 0.00685469 0.0361121  0.04989431 0.04405979
  0.04893385 0.04565682 0.05855711 0.02911637 0.01497527 0.07052043
  0.04126455 0.03361755]
 [0.03946925 0.02918806 0.02568278 0.02113963 0.02414789 0.02479198
  0.03445419 0.03366357 0.03837664 0.02728616 0.03670938 0.02940197
  0.03324592 0.01556509 0.02172047 0.03515657 0.06128482 0.0564567
  0.06975935 0.06395891 0.06004247 0.03811236 0.03749881 0.05664885
  0.06667612 0.08629661]
 [0.0417774  0.0248191  0.02480146 0.02157553 0.01575812 0.02366346
  0.02625493 0.02971014 0.02891183 0.02467326 0.03007844 0.03071428
  0.02967181 0.01116235 0.00967161 0.02372748 0.02724318 0.02949111
  0.03449974 0.03679064 0.03698665 0.03179557 0.01688265 0.02675152
  0.0338257  0.0349414 ]
 [0.04050676 0.03128001 0.02916341 0.04760348 0.04538612 0.04481237
  0.03043982 0.03044506 0.03506219 0.05104038 0.0391628  0.03896536
  0.03899901 0.07368543 0.08386307 0.03037237 0.03178779 0.03449241
  0.03365901 0.03289608 0.03020047 0.03932865 0.03249997 0.01244173
  0.01552054 0.03202281]
 [0.04018004 0.03261653 0.0282061  0.05202632 0.09433793 0.04210216
  0.02855812 0.02829891 0.03323633 0.05710639 0.04449848 0.03773595
  0.03285855 0.07294072 0.0930716  0.03650247 0.04420226 0.04872866
  0.04002322 0.03685465 0.03632532 0.03644444 0.0312215  0.01059135
  0.01104401 0.02750948]
 [0.03958838 0.03112356 0.02667405 0.04635493 0.10583069 0.03093969
  0.02525344 0.02783851 0.02947159 0.05259504 0.04704962 0.04298222
  0.03228354 0.0360989  0.04880416 0.03354406 0.0750696  0.07207462
  0.05789078 0.04417405 0.05329766 0.03387349 0.0290753  0.01857148
  0.01954542 0.03275697]
 [0.04009435 0.03634806 0.0289766  0.0449476  0.07063153 0.03557644
  0.03192404 0.03018912 0.03400976 0.04714619 0.04572665 0.03871962
  0.03315664 0.03393089 0.03928934 0.02870753 0.04858235 0.05053627
  0.0448368  0.04178866 0.04191888 0.05996353 0.03901046 0.01545653
  0.01724035 0.03123761]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' office', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '4', ' states', ' that', ' Fred', ' is', ' in', ' the', ' park', ',', ' and', ' sentence', ' ', '5', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(54, 32), x_tokens=32, y_tokens=54, max_supp_attn=0.1111, attn_on_target=0.0185)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (54, 32)
DEBUG result.interpretability.attn_scores 1728 
 [[0.0170032  0.02634966 0.02714796 ... 0.04280951 0.00827222 0.05632092]
 [0.01741907 0.02696848 0.02587278 ... 0.04966164 0.01362569 0.06375793]
 [0.01777479 0.02548051 0.02771125 ... 0.04727888 0.01920079 0.04925099]
 ...
 [0.01783582 0.02314239 0.02054766 ... 0.01494187 0.00583002 0.06881155]
 [0.01807693 0.01909159 0.01583738 ... 0.00941503 0.00807614 0.04384983]
 [0.01818645 0.01923204 0.01593442 ... 0.00823174 0.00701969 0.05905389]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' office', ',', ' which', ' means', ' Fred', ' is', ' definitely', ' in', ' the', ' office', ' because', ' the', ' two', ' options', ' are', ' the', ' same', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 38), x_tokens=38, y_tokens=38, max_supp_attn=0.0526, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 38)
DEBUG result.interpretability.attn_scores 1444 
 [[0.02414413 0.04298294 0.04017115 ... 0.01939856 0.0363613  0.03940905]
 [0.02435884 0.03778123 0.03657584 ... 0.03354041 0.04374721 0.0348254 ]
 [0.02517966 0.04340984 0.04760196 ... 0.01742279 0.03738196 0.02180099]
 ...
 [0.02536528 0.03871557 0.03575151 ... 0.01491097 0.04955054 0.03163429]
 [0.02566655 0.03114741 0.02627174 ... 0.02267103 0.04685523 0.03567626]
 [0.02567181 0.0336073  0.027016   ... 0.02075247 0.03805658 0.05823931]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' office', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '10', ' states', ' that', ' Bill', ' went', ' to', ' the', ' office', ',', ' and', ' sentence', ' ', '11', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' kitchen', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(56, 44), x_tokens=44, y_tokens=56, max_supp_attn=0.0714, attn_on_target=0.0179)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (56, 44)
DEBUG result.interpretability.attn_scores 2464 
 [[0.01653117 0.02226126 0.02214119 ... 0.01008541 0.00585717 0.00543074]
 [0.0169425  0.01626623 0.01845725 ... 0.01384846 0.00940564 0.01211407]
 [0.01726218 0.02253083 0.02549554 ... 0.01354772 0.00773452 0.00882665]
 ...
 [0.0176686  0.02175698 0.01891722 ... 0.00613992 0.00680805 0.00549506]
 [0.0177907  0.02767309 0.02740948 ... 0.00699137 0.00543054 0.00475831]
 [0.01792765 0.02306074 0.02280038 ... 0.00754573 0.00627751 0.00503897]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' Sentence', ' ', '13', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' cinema', ',', ' and', ' sentence', ' ', '14', ' states', ' that', ' Mary', ' went', ' back', ' to', ' the', ' school', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(57, 50), x_tokens=50, y_tokens=57, max_supp_attn=0.1228, attn_on_target=0.0175)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (57, 50)
DEBUG result.interpretability.attn_scores 2850 
 [[0.01628422 0.02507554 0.02421942 ... 0.03158989 0.02008211 0.01013609]
 [0.01653642 0.02377892 0.02170726 ... 0.01637868 0.0232613  0.01326047]
 [0.01694847 0.02760778 0.02788915 ... 0.02953487 0.01790709 0.00784972]
 ...
 [0.01747042 0.01861089 0.01874011 ... 0.02164662 0.01788209 0.0111492 ]
 [0.01763229 0.02062533 0.02106302 ... 0.02820765 0.01358484 0.00685412]
 [0.01734928 0.02095445 0.02108635 ... 0.05141362 0.01845849 0.00967332]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' travelled', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.0272526  0.04303122 0.05343237 0.0706101  0.08121179 0.07261948
  0.05666506 0.06399219 0.0535327  0.06371149 0.04502956 0.05849955
  0.0650221  0.09656664 0.06326441 0.02758163 0.03126007 0.03124118
  0.03010283 0.03062051 0.0245677  0.0384857  0.04037824 0.01579384
  0.0171304  0.03577093]
 [0.0276127  0.05154315 0.04976229 0.06609114 0.06025715 0.05713687
  0.04721189 0.04690261 0.04231466 0.0474708  0.03659687 0.03174834
  0.03463241 0.10447873 0.10192928 0.02833045 0.026347   0.02267775
  0.02427615 0.02343408 0.01966232 0.038971   0.04222504 0.01214892
  0.01109361 0.03152495]
 [0.02982153 0.05610797 0.03399388 0.04924804 0.03576618 0.03363748
  0.03059892 0.02131314 0.02149347 0.03224844 0.02633947 0.01580984
  0.01758257 0.02488525 0.03293482 0.01947816 0.01368471 0.01289535
  0.01745622 0.0167508  0.01507884 0.04232764 0.04857126 0.00711017
  0.00640206 0.01651416]
 [0.02815482 0.02403232 0.02509224 0.02697598 0.01929974 0.02648235
  0.02840073 0.02463406 0.02531208 0.02542267 0.0302949  0.02934249
  0.02652284 0.01342212 0.01279488 0.03330605 0.02752404 0.04067425
  0.03242202 0.03994797 0.03434779 0.02902131 0.02856321 0.06313701
  0.05595028 0.03524265]
 [0.02822064 0.04063092 0.04427307 0.06452768 0.05882208 0.04683641
  0.0342112  0.02915625 0.03360178 0.04433486 0.03304566 0.02493127
  0.02520116 0.09208786 0.09568709 0.03156964 0.02683746 0.02035573
  0.02275513 0.02302115 0.02140274 0.03857923 0.06024364 0.01269122
  0.00960381 0.03847741]
 [0.02879577 0.02570547 0.0268066  0.0493763  0.04361775 0.04206257
  0.02527912 0.022474   0.02835367 0.04150712 0.02907424 0.02830417
  0.02709847 0.10319939 0.12528655 0.03155117 0.03074335 0.02464307
  0.02561997 0.02448854 0.0204832  0.03256721 0.03539209 0.0088254
  0.00773811 0.02463096]
 [0.02920201 0.02920896 0.03510368 0.05199829 0.04775668 0.05323689
  0.03351642 0.03134325 0.03718827 0.04871353 0.03399912 0.04483824
  0.04114489 0.081323   0.07740297 0.02682697 0.0279017  0.02435112
  0.0246392  0.02422949 0.01935465 0.02944115 0.03339157 0.01184736
  0.01096026 0.0239476 ]
 [0.02815622 0.04096364 0.04816589 0.04104589 0.04230655 0.05008124
  0.03951726 0.04119934 0.04076202 0.04346708 0.03536365 0.04996584
  0.04317312 0.04975462 0.04534182 0.03932887 0.03623733 0.0317708
  0.03001993 0.03075889 0.02690956 0.0334266  0.04758032 0.03173064
  0.03214566 0.03871856]
 [0.02930798 0.04009549 0.04857566 0.0452867  0.04055568 0.05663378
  0.04397055 0.04642658 0.0486257  0.04851185 0.03520722 0.05013014
  0.04673411 0.0370817  0.02457733 0.02632838 0.02784724 0.02612375
  0.02694484 0.02785564 0.02206204 0.03424587 0.03774427 0.0174999
  0.0190007  0.0323949 ]
 [0.02866008 0.05410356 0.05666164 0.02967358 0.02354022 0.03868352
  0.04771138 0.04454383 0.04606533 0.03136646 0.02947504 0.03894051
  0.03965729 0.01732696 0.01495457 0.04405307 0.03541589 0.03062937
  0.03147863 0.03301617 0.0303142  0.03332254 0.06301268 0.03860089
  0.04239954 0.03782362]
 [0.02917386 0.06571208 0.06427576 0.02735267 0.02196008 0.03266037
  0.04702838 0.0404651  0.04793642 0.02741245 0.02567718 0.03058498
  0.03112108 0.01450321 0.0141031  0.04624807 0.03666167 0.02962209
  0.03318984 0.03614746 0.02987783 0.0305318  0.06799185 0.03152139
  0.03175252 0.03492463]
 [0.02933109 0.03652736 0.0408816  0.02117304 0.01772295 0.02435542
  0.03682547 0.03139602 0.03725479 0.02239325 0.02117252 0.02464678
  0.02362891 0.01229448 0.01245927 0.03967288 0.03196546 0.02509825
  0.0298021  0.03051534 0.02864777 0.02913201 0.05437251 0.04432518
  0.05081185 0.04097231]
 [0.02949854 0.01596474 0.01786227 0.01194612 0.01058445 0.0144886
  0.01776996 0.01774186 0.02158264 0.01443837 0.01419684 0.01555071
  0.01531844 0.00659879 0.00748154 0.02106888 0.02114736 0.01925308
  0.02498328 0.02619451 0.0287224  0.02270985 0.0369571  0.05661953
  0.07906288 0.05006617]
 [0.02943314 0.02424018 0.0255703  0.01642051 0.01505592 0.02079334
  0.02615054 0.02325876 0.02471056 0.01855571 0.02142144 0.02227294
  0.02151038 0.00916568 0.00998368 0.03881812 0.02497545 0.02383585
  0.02494535 0.02660966 0.02751447 0.02723093 0.0296933  0.05341393
  0.06308661 0.04055573]
 [0.02955367 0.02486008 0.02519856 0.01912216 0.01635596 0.02350315
  0.0283026  0.0286443  0.02536587 0.02248415 0.02626525 0.02967531
  0.03009398 0.01070626 0.00957319 0.03911793 0.02683098 0.02861132
  0.02659533 0.02787557 0.03077587 0.0283073  0.02219545 0.04559274
  0.04184661 0.02547595]
 [0.02907113 0.02117738 0.01725615 0.01434533 0.01142362 0.01494196
  0.02254512 0.02230784 0.01880573 0.01547232 0.02155618 0.01872911
  0.02244379 0.0068195  0.00690407 0.04212162 0.02413715 0.03754928
  0.03027189 0.03597642 0.04662342 0.02640147 0.01878305 0.07605035
  0.05569508 0.03042632]
 [0.02987277 0.01849578 0.01636055 0.01424272 0.01192466 0.01592376
  0.02015656 0.02038468 0.01853398 0.01621796 0.02537687 0.02076831
  0.02211196 0.00689398 0.00680119 0.03193938 0.02304989 0.04429626
  0.03162114 0.04580317 0.03850691 0.02146105 0.01489032 0.05462835
  0.0371404  0.0212661 ]
 [0.02981055 0.01669996 0.01502414 0.01124809 0.00945737 0.01321208
  0.01907808 0.01874218 0.01742576 0.01345271 0.03154753 0.01881367
  0.02000246 0.00570446 0.00621024 0.03315732 0.02701446 0.03561032
  0.03110149 0.03521533 0.03972306 0.02264421 0.0149072  0.0570605
  0.03915554 0.02586691]
 [0.0290764  0.02403305 0.02263749 0.01584265 0.01488518 0.02079147
  0.03080009 0.03140612 0.02886602 0.01995466 0.02911878 0.02591463
  0.03015493 0.00829052 0.00870761 0.02957903 0.03513289 0.03903693
  0.03641883 0.03914868 0.04314699 0.02577146 0.02123595 0.04680881
  0.04329158 0.04191849]
 [0.03030356 0.02054279 0.01945324 0.01556992 0.01273482 0.01741148
  0.02188665 0.02197216 0.02091884 0.01718516 0.02555501 0.02195039
  0.02165146 0.00813936 0.0075755  0.02189487 0.02245829 0.02311819
  0.02617214 0.02654932 0.02791511 0.02601564 0.01487576 0.02897367
  0.03424472 0.02634065]
 [0.03036257 0.02273816 0.02532817 0.02224371 0.01769282 0.02590134
  0.02653817 0.0312321  0.02601551 0.02644242 0.02808538 0.03628701
  0.03237956 0.01301356 0.00896627 0.01962363 0.02131398 0.02487725
  0.02470964 0.0239234  0.02227738 0.02840031 0.01538754 0.01714548
  0.02516452 0.02263609]
 [0.03053313 0.02649284 0.02739254 0.02589451 0.01928077 0.02863461
  0.03138693 0.03840047 0.02697512 0.03088641 0.03574275 0.04209112
  0.03987512 0.01419925 0.00968375 0.02126883 0.02196945 0.02645408
  0.02483969 0.02384867 0.02235296 0.02846816 0.01615199 0.01445589
  0.01798106 0.01720474]
 [0.03036867 0.02485053 0.02461728 0.02407451 0.01906205 0.02654336
  0.0286598  0.03336409 0.0272964  0.02920766 0.03247701 0.03688137
  0.03749587 0.01330218 0.0099648  0.02639176 0.02417281 0.02979733
  0.0275967  0.0261375  0.02488075 0.02827193 0.01414275 0.01688693
  0.01955593 0.01549833]
 [0.03023463 0.01955931 0.01832404 0.01506226 0.01148722 0.01656954
  0.02134888 0.02344288 0.0215883  0.01789813 0.02419733 0.02293617
  0.02579372 0.0076848  0.00700094 0.03101212 0.02560368 0.02960076
  0.02827512 0.02667055 0.03117904 0.0263996  0.01256143 0.02754452
  0.03084438 0.01783225]
 [0.03022952 0.02011752 0.01806793 0.0154133  0.01107434 0.01565625
  0.02396315 0.02423663 0.02127551 0.0171184  0.0245376  0.02062153
  0.02535466 0.00733101 0.00690511 0.033832   0.02613661 0.03162153
  0.02976471 0.02737961 0.03394778 0.02380305 0.01179581 0.02813941
  0.03127201 0.019561  ]
 [0.03030928 0.01933309 0.01728331 0.01518513 0.01220587 0.0158177
  0.02091022 0.02250768 0.02105613 0.01825319 0.02525926 0.0225659
  0.02403523 0.00788415 0.00721521 0.02706761 0.02883238 0.02991946
  0.03273955 0.02738182 0.03197874 0.02426114 0.01178417 0.02191938
  0.03073058 0.01967796]
 [0.03045983 0.02200294 0.01977609 0.01640836 0.01232751 0.01730823
  0.02460887 0.02528859 0.02574093 0.0194036  0.02917815 0.02363624
  0.02645625 0.00836993 0.00743943 0.02928039 0.0286421  0.03218371
  0.03347595 0.03069579 0.0340085  0.02510949 0.0125102  0.02292071
  0.02434088 0.01735915]
 [0.03051599 0.01768123 0.01642187 0.01111578 0.00955111 0.01263201
  0.02042446 0.01996142 0.02068814 0.01373108 0.0340642  0.0184724
  0.02150586 0.00626362 0.00575163 0.02774837 0.03097448 0.02816894
  0.03356211 0.02881878 0.03290397 0.02326146 0.0119076  0.03126722
  0.02547777 0.0202956 ]
 [0.02919993 0.02375615 0.02310314 0.01379717 0.01178852 0.01710455
  0.03284911 0.03317997 0.03147026 0.01875738 0.03355607 0.02495664
  0.0335421  0.00754898 0.00749377 0.02398254 0.04129952 0.03584567
  0.043132   0.04249087 0.04590309 0.02743141 0.02251043 0.04531995
  0.04126609 0.06681687]
 [0.03057177 0.02048035 0.0205576  0.01720495 0.01335638 0.02049205
  0.02163052 0.02550414 0.02514366 0.02046454 0.02339345 0.02494879
  0.023963   0.01019967 0.00826    0.01677615 0.02468823 0.0206756
  0.02649942 0.02560501 0.02721723 0.02464663 0.01366532 0.0175344
  0.02215848 0.02483794]
 [0.02946159 0.02607124 0.02618574 0.0407178  0.04250407 0.03662512
  0.0239602  0.02467111 0.02986526 0.04241609 0.02999916 0.03103257
  0.0293863  0.06659525 0.08017186 0.02143089 0.02790332 0.0244054
  0.02630652 0.02438559 0.02167405 0.03097068 0.03015792 0.00936414
  0.00967853 0.02722047]
 [0.02922215 0.02749027 0.02621523 0.04575385 0.08769526 0.03664859
  0.02227231 0.02302187 0.02889575 0.04959267 0.03542417 0.03138774
  0.02463005 0.06778313 0.08537527 0.02647945 0.03956004 0.03343215
  0.03161031 0.02685431 0.02580662 0.02831581 0.02985865 0.00799881
  0.00711449 0.02365126]
 [0.02895654 0.02481748 0.0229976  0.03701569 0.08285554 0.02501621
  0.01860017 0.0220384  0.0248988  0.04264617 0.03379701 0.03341667
  0.02420115 0.03000097 0.03807911 0.02280575 0.06004026 0.04932762
  0.04324146 0.03171428 0.04078964 0.02563015 0.02632573 0.01406477
  0.01463361 0.02791237]
 [0.02926534 0.0309328  0.0273421  0.03801615 0.0538797  0.02955822
  0.02522122 0.02484624 0.03043989 0.03886118 0.03397514 0.02934854
  0.02657476 0.03058094 0.03371971 0.02032801 0.04169079 0.03229653
  0.03343043 0.02993524 0.02944336 0.04443617 0.03823566 0.01105856
  0.01126949 0.02663699]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' in', ' the', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Julie', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 32), x_tokens=32, y_tokens=28, max_supp_attn=0.1071, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 32)
DEBUG result.interpretability.attn_scores 896 
 [[0.03340757 0.03523596 0.03608455 0.06602424 0.06114446 0.0453188
  0.03109159 0.03300684 0.0404253  0.05319256 0.04032105 0.03325459
  0.03435057 0.10364299 0.10323907 0.0321418  0.03233911 0.02832947
  0.0294729  0.03004949 0.02586447 0.03579588 0.03932763 0.02200368
  0.01733453 0.03596151 0.0368621  0.04835547 0.11568872 0.06748927
  0.01301173 0.01656225]
 [0.03442886 0.03261099 0.03063902 0.06836518 0.077557   0.06500422
  0.03229225 0.03521097 0.04128907 0.06428894 0.04922348 0.04974771
  0.0503519  0.13791643 0.10676725 0.03011947 0.0293219  0.0307614
  0.02926158 0.0307173  0.02556706 0.03827174 0.02764571 0.01834427
  0.01631706 0.02837235 0.03463804 0.0391262  0.08851518 0.07682349
  0.02066663 0.0292489 ]
 [0.03517503 0.03152824 0.03358309 0.06204518 0.06157962 0.05090832
  0.02918435 0.03264561 0.03804769 0.05029032 0.03945335 0.04070514
  0.03728759 0.11179775 0.08111553 0.02869288 0.02805633 0.02375434
  0.02523711 0.02580372 0.02162401 0.03480159 0.02669123 0.01861537
  0.01708718 0.02529037 0.03007982 0.03156162 0.05955666 0.07056568
  0.02710031 0.03296586]
 [0.03413776 0.03557672 0.03984268 0.04092357 0.03568157 0.03917145
  0.03295105 0.04068916 0.03933741 0.03780941 0.03417765 0.03959164
  0.03544626 0.03063054 0.03009136 0.03234315 0.03203479 0.02737943
  0.03057079 0.03160099 0.02950948 0.03739215 0.03861354 0.03555257
  0.03247233 0.04016059 0.04179466 0.04292259 0.03946516 0.06764191
  0.05448374 0.05719453]
 [0.03550334 0.03350466 0.03579904 0.03296727 0.02730005 0.03741955
  0.0344107  0.03907127 0.0390391  0.03278384 0.03240327 0.04318765
  0.03564832 0.021942   0.02196456 0.03121616 0.0338782  0.02883555
  0.03295011 0.03394409 0.03177144 0.03338674 0.03382103 0.03359532
  0.03599272 0.03934943 0.03540875 0.03192302 0.02838052 0.03527039
  0.0421263  0.05014941]
 [0.03610073 0.0348952  0.03663879 0.03675965 0.03014299 0.04682876
  0.03629028 0.04012282 0.04697782 0.03948216 0.03352179 0.05188853
  0.0407696  0.02820195 0.02334167 0.02976954 0.03163266 0.02675378
  0.03048997 0.03078926 0.02732805 0.03380195 0.03205462 0.02844816
  0.02932899 0.03441136 0.0358932  0.02809908 0.02989682 0.0337874
  0.03690893 0.04565484]
 [0.03522544 0.04739569 0.04565375 0.04133538 0.03293006 0.04897719
  0.04784936 0.05342719 0.04711733 0.04508051 0.03995499 0.06058638
  0.05789508 0.02974013 0.02576774 0.03821808 0.03697873 0.03413874
  0.03683145 0.03698185 0.03474744 0.03892706 0.03972678 0.03718132
  0.03873629 0.03970492 0.04249931 0.03871954 0.03221502 0.04255439
  0.04769158 0.05327539]
 [0.03627377 0.03911186 0.04164271 0.03706348 0.02744736 0.05409962
  0.04392928 0.04578927 0.04357912 0.03846975 0.03419121 0.06835972
  0.05535508 0.02626313 0.02214771 0.03567331 0.03662249 0.03184159
  0.03360514 0.03507437 0.03135418 0.03575083 0.03406856 0.03353863
  0.03693398 0.03588934 0.03712634 0.03319024 0.02804226 0.0349792
  0.04360671 0.05004988]
 [0.03549162 0.02955292 0.02842998 0.02451863 0.02090978 0.02493217
  0.03630537 0.03254765 0.02557191 0.02591769 0.03944996 0.02971225
  0.03967676 0.01512004 0.01778165 0.04888346 0.04195588 0.03838287
  0.04032381 0.04019904 0.05510444 0.0356544  0.02571082 0.05805483
  0.05639038 0.03618665 0.02820809 0.04105588 0.02368626 0.01985915
  0.05093131 0.04696434]
 [0.03573692 0.02708624 0.02513717 0.02131379 0.01691035 0.02115841
  0.03084391 0.02829399 0.02404324 0.02095415 0.02810712 0.02452045
  0.02802545 0.01291037 0.01500755 0.04460275 0.03550545 0.03535965
  0.03843281 0.03936332 0.05559083 0.03369212 0.02526112 0.06287784
  0.0685894  0.04396002 0.02635838 0.04667307 0.02141697 0.01795453
  0.0527681  0.0480281 ]
 [0.03603715 0.04075412 0.04446427 0.0237737  0.02225251 0.02906775
  0.03926994 0.0391432  0.04501874 0.02349703 0.02921717 0.02825933
  0.02795715 0.01563803 0.018069   0.04032985 0.03672272 0.02734111
  0.03528817 0.03437106 0.03636448 0.03424929 0.04743265 0.03813051
  0.04223128 0.04097822 0.04474539 0.03887695 0.02302421 0.04006414
  0.03958945 0.03689588]
 [0.03532302 0.05632148 0.05491669 0.02575225 0.02230839 0.03273286
  0.04696426 0.03645233 0.05249144 0.02436533 0.02893246 0.02736279
  0.02800838 0.01639527 0.0214237  0.0410947  0.03569022 0.02775205
  0.03787545 0.03595615 0.03737402 0.03671907 0.0688227  0.0405769
  0.03265283 0.04642259 0.05813377 0.03860278 0.0223291  0.03143625
  0.03218034 0.02904361]
 [0.03592538 0.0755284  0.07099147 0.02822498 0.02429456 0.03676426
  0.04825797 0.04106569 0.0532543  0.02682612 0.02558536 0.02884745
  0.02990805 0.0195608  0.02365212 0.04859952 0.03731445 0.02632434
  0.03137316 0.03333385 0.02781    0.03539554 0.0813742  0.03810216
  0.02952152 0.04507389 0.06588494 0.02674266 0.02547812 0.0549715
  0.03458337 0.02922713]
 [0.0358519  0.03973293 0.04556385 0.02557837 0.02232871 0.03093839
  0.0372659  0.03565792 0.04053215 0.02481955 0.02401943 0.02620847
  0.02481665 0.01866023 0.0218421  0.03827135 0.03457801 0.02599533
  0.03191284 0.03317841 0.02826974 0.03420765 0.05315048 0.04492094
  0.036458   0.04582364 0.0575172  0.02700765 0.02583843 0.05100746
  0.05255681 0.03774036]
 [0.03564166 0.02700489 0.02944658 0.0316092  0.02822794 0.03493283
  0.03174284 0.03379207 0.04102192 0.04046538 0.03340824 0.04361551
  0.03955865 0.02692784 0.02400445 0.03496906 0.03700953 0.03456222
  0.03588174 0.03440176 0.03372711 0.03671492 0.0322853  0.0430916
  0.04107877 0.03651844 0.03430773 0.04274025 0.03610877 0.05134844
  0.04529419 0.04078392]
 [0.03608841 0.04267887 0.04194897 0.02689802 0.02562205 0.03211006
  0.04172911 0.03921055 0.03527084 0.02792974 0.02953578 0.03036916
  0.03552167 0.02176594 0.02120886 0.03331522 0.02957912 0.02703456
  0.02903425 0.02956495 0.02785629 0.03722632 0.03734867 0.03273043
  0.03348714 0.03631593 0.0429177  0.0284349  0.02544506 0.03400822
  0.03609196 0.03838578]
 [0.03670652 0.05619946 0.05604887 0.02606706 0.02544595 0.03424506
  0.04426748 0.04084834 0.0419792  0.0285226  0.02685302 0.03027996
  0.03412858 0.02028983 0.0202104  0.04017737 0.03301295 0.02696784
  0.02906288 0.03035077 0.02587081 0.03480257 0.05481451 0.03280238
  0.02622976 0.03231074 0.04120011 0.02445026 0.02375515 0.04690811
  0.03142957 0.02987254]
 [0.03647344 0.03440274 0.03756449 0.02358884 0.02248957 0.02866786
  0.03692142 0.03632835 0.02986408 0.02436898 0.02549893 0.02776721
  0.02943277 0.0175475  0.01795084 0.03393199 0.03197622 0.02764502
  0.02985851 0.03089673 0.02806048 0.03698036 0.03745624 0.03804039
  0.03589645 0.03408173 0.0337352  0.02267013 0.02381784 0.03834896
  0.04107973 0.03723959]
 [0.03718683 0.02959799 0.03139479 0.0230123  0.02075569 0.02960766
  0.04056742 0.04162438 0.02631103 0.02500379 0.02683946 0.02997683
  0.03555725 0.01679816 0.0161478  0.0290086  0.02891736 0.02769589
  0.02758864 0.02848359 0.02690318 0.03576715 0.02520928 0.03201381
  0.03778968 0.03586349 0.02957335 0.02157411 0.0230683  0.02328032
  0.03353539 0.03957863]
 [0.03646231 0.0232686  0.021383   0.01680028 0.01703565 0.02034966
  0.03019895 0.02698835 0.01939933 0.01847876 0.02842065 0.02081332
  0.02900019 0.0129668  0.0139441  0.03325902 0.03544809 0.03042049
  0.03187075 0.03208266 0.03467641 0.03369309 0.02028977 0.04747708
  0.06680848 0.03956165 0.02240572 0.02352478 0.0192183  0.01853095
  0.04111072 0.03203429]
 [0.03617843 0.02026988 0.01872643 0.01596749 0.0146956  0.01740032
  0.02638447 0.02374491 0.01765694 0.01657069 0.02879179 0.01831115
  0.0238846  0.01171978 0.01256322 0.03422717 0.03961856 0.04144837
  0.03702341 0.03698856 0.04248642 0.03123428 0.01608757 0.04822277
  0.05295155 0.03442321 0.01901459 0.0258644  0.01889141 0.01472441
  0.05149192 0.03854908]
 [0.03614201 0.03514472 0.02883405 0.02083059 0.01754531 0.02167927
  0.04583778 0.04546477 0.02464284 0.02115116 0.04838797 0.02517434
  0.04063869 0.01391025 0.01545173 0.05033546 0.04886521 0.05448733
  0.04265682 0.04677062 0.04607562 0.03588355 0.02047509 0.05946191
  0.06561051 0.03382535 0.02450867 0.03048265 0.02062644 0.01570027
  0.05554299 0.0471323 ]
 [0.03698611 0.02366322 0.02343594 0.01891061 0.01674103 0.02142612
  0.03193268 0.03231346 0.02361284 0.02119129 0.05161644 0.02469507
  0.03235983 0.0140231  0.01396397 0.0376238  0.04435117 0.03915123
  0.04453266 0.04206813 0.04044767 0.03042506 0.01609988 0.04124555
  0.04412986 0.03043204 0.01786953 0.02806628 0.01929925 0.01571813
  0.04609989 0.04111362]
 [0.03546084 0.0278623  0.02886171 0.05127755 0.0495441  0.04283768
  0.03225328 0.03100782 0.03729967 0.05641403 0.04167006 0.0388735
  0.04066999 0.0748181  0.09509239 0.02906871 0.0313537  0.03938709
  0.03628924 0.03420603 0.03307395 0.03688904 0.02988775 0.01930292
  0.0162716  0.02864921 0.02869254 0.04044851 0.05650476 0.02730389
  0.01391674 0.01822632]
 [0.03489045 0.03246479 0.02869376 0.06740794 0.12242098 0.0472757
  0.02752228 0.02768326 0.03076496 0.06743927 0.05174863 0.04194413
  0.03432638 0.0832832  0.10840808 0.03677586 0.04493264 0.07321927
  0.05140204 0.04652979 0.04744726 0.03598096 0.03691063 0.02010094
  0.01645477 0.0298234  0.03820534 0.04425933 0.05695118 0.0238378
  0.01129467 0.01376442]
 [0.03525047 0.03103029 0.02726224 0.04473058 0.05540269 0.03278775
  0.02677171 0.02850981 0.03000656 0.04603637 0.04692034 0.04178462
  0.0349226  0.03197575 0.04054809 0.03822786 0.05375541 0.077912
  0.06393345 0.0567206  0.05650334 0.03358984 0.03214922 0.02984724
  0.02912843 0.03149851 0.03118084 0.04898449 0.03193601 0.01512276
  0.01650218 0.020196  ]
 [0.03580442 0.03123585 0.03003242 0.05509738 0.0637368  0.03908072
  0.02836966 0.03213591 0.03524413 0.05724037 0.04476803 0.04280514
  0.03459817 0.03547419 0.03616163 0.02590717 0.03196777 0.05127714
  0.04162797 0.04195108 0.04795203 0.03807863 0.03459602 0.025392
  0.02360385 0.03220518 0.03582714 0.05413599 0.03662821 0.01526511
  0.01452172 0.0201649 ]
 [0.03610962 0.02634096 0.02697968 0.04315653 0.03754921 0.03427754
  0.02859471 0.02722406 0.03020098 0.0414103  0.03698243 0.03135793
  0.02990378 0.03007982 0.0321334  0.02321675 0.02658124 0.03584194
  0.03561232 0.03762183 0.04063982 0.04468824 0.032689   0.02032842
  0.02051264 0.02690623 0.02541151 0.05150711 0.04421591 0.01549784
  0.01388293 0.01995805]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Julie', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' school', ',', ' which', ' means', ' Julie', ' is', ' definitely', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 38), x_tokens=38, y_tokens=33, max_supp_attn=0.0, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 38)
DEBUG result.interpretability.attn_scores 1254 
 [[0.0281559  0.04405121 0.0426783  ... 0.02171661 0.01670672 0.03932738]
 [0.02839498 0.03628321 0.03472501 ... 0.02639548 0.02716069 0.04225345]
 [0.02926521 0.04767953 0.05154752 ... 0.01793752 0.01615497 0.03650869]
 ...
 [0.0294734  0.03962491 0.04518611 ... 0.01722566 0.01659713 0.04362655]
 [0.02970982 0.03438437 0.03562271 ... 0.02223737 0.02365522 0.03646843]
 [0.02990933 0.03096613 0.0342678  ... 0.02140845 0.02004781 0.03542283]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' being', ' in', ' the', ' kitchen', ' in', ' the', ' context', ' sentences', '.', ' Bill', ' went', ' to', ' the', ' school', ' according', ' to', ' context', ' sentence', ' ', '10', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02752193 0.03191959 0.03554199 ... 0.0152867  0.01789165 0.03892418]
 [0.0278667  0.02458433 0.02682735 ... 0.01826487 0.02364001 0.01826117]
 [0.02867771 0.03456743 0.04013675 ... 0.0179321  0.02079128 0.03318998]
 ...
 [0.02886881 0.03597106 0.03200448 ... 0.00682636 0.00873668 0.07900827]
 [0.02937098 0.03187801 0.02620809 ... 0.00871114 0.00864746 0.05981567]
 [0.02939555 0.03349305 0.02634767 ... 0.00769881 0.0089188  0.04819941]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '14', ',', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' which', ' explicitly', ' states', ' her', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(26, 50), x_tokens=50, y_tokens=26, max_supp_attn=0.0385, attn_on_target=0.0385)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (26, 50)
DEBUG result.interpretability.attn_scores 1300 
 [[0.03611574 0.0467053  0.04825022 ... 0.02258132 0.02703764 0.04271671]
 [0.03672645 0.04425102 0.03891896 ... 0.02968557 0.03353689 0.03599469]
 [0.03763362 0.04711062 0.05124029 ... 0.01975637 0.02424812 0.0378407 ]
 ...
 [0.03792823 0.04293878 0.04458032 ... 0.01769134 0.02232581 0.04162762]
 [0.03819263 0.03399722 0.03423509 ... 0.03320343 0.03294189 0.03983144]
 [0.03812319 0.03950368 0.03937026 ... 0.01980206 0.02336405 0.03896301]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Julie', ' went', ' to', ' the', ' bedroom', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 26), x_tokens=26, y_tokens=33, max_supp_attn=0.0303, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 26)
DEBUG result.interpretability.attn_scores 858 
 [[0.02798603 0.050078   0.06146727 0.0758779  0.07925372 0.0745693
  0.06287826 0.07527941 0.06029547 0.06523196 0.04776682 0.06433367
  0.07302961 0.09336565 0.05895999 0.03456229 0.03185548 0.03277721
  0.03135587 0.03188374 0.02535609 0.03972682 0.04291892 0.02637169
  0.01606921 0.02503973]
 [0.02774836 0.07490967 0.06762919 0.07308641 0.06262915 0.07268722
  0.21064416 0.1277474  0.08485718 0.08028527 0.06349781 0.05965061
  0.08134517 0.06205007 0.04832941 0.03933796 0.03323746 0.03741327
  0.0335809  0.03593928 0.02780423 0.04597189 0.04473404 0.02784016
  0.01677977 0.02521695]
 [0.03052662 0.05953599 0.03776035 0.05344555 0.03934264 0.03647756
  0.02724959 0.02157881 0.02298227 0.03398961 0.02759297 0.01658469
  0.01865699 0.03137907 0.04184023 0.0259032  0.01426561 0.01288212
  0.01739581 0.01644656 0.01465635 0.04416436 0.05428277 0.01063337
  0.00603289 0.01250774]
 [0.02903618 0.02924356 0.03033632 0.02391546 0.01685553 0.02632124
  0.02416672 0.02190736 0.02570603 0.02282071 0.02531974 0.02385074
  0.02212504 0.01215841 0.01137861 0.03007299 0.02894175 0.03605155
  0.04051683 0.04234863 0.0339801  0.03146737 0.04005061 0.04283514
  0.07262679 0.05147481]
 [0.02903206 0.04270589 0.04697293 0.06596254 0.05911767 0.04779898
  0.02923386 0.02796378 0.03435883 0.04472376 0.03366887 0.0257405
  0.0254882  0.10282335 0.10947956 0.03975169 0.02719313 0.02005185
  0.02239765 0.02224722 0.02040967 0.03918571 0.0627095  0.01851185
  0.00860112 0.02695413]
 [0.02965835 0.02776345 0.02892226 0.05061141 0.04408627 0.04349611
  0.02200853 0.02196828 0.02939573 0.04177541 0.02990926 0.02916907
  0.02756082 0.11005642 0.13519496 0.0393492  0.03056985 0.024152
  0.02534606 0.0238002  0.01959799 0.0335789  0.0380659  0.01337959
  0.0069192  0.01744182]
 [0.03009395 0.0314574  0.037581   0.05329284 0.04839265 0.054699
  0.02905232 0.03028757 0.03825593 0.04889989 0.03503187 0.04589068
  0.04178642 0.08817082 0.08335362 0.03309063 0.02781575 0.02390036
  0.02428264 0.0234228  0.01852939 0.0303841  0.03558593 0.01825179
  0.00957884 0.01675953]
 [0.02903355 0.04213091 0.04970473 0.04167148 0.04334407 0.0492503
  0.03492454 0.03977528 0.04062435 0.0429961  0.03662185 0.04932234
  0.04302224 0.05385675 0.04908189 0.04433865 0.03755988 0.03243631
  0.0300897  0.02981998 0.02626415 0.03464824 0.05040552 0.03602334
  0.0345013  0.03229628]
 [0.0302885  0.04318215 0.05285586 0.04819689 0.04255141 0.05805552
  0.03805238 0.04552056 0.04953821 0.04961644 0.0365555  0.05140822
  0.04691666 0.04116628 0.02752654 0.03110903 0.02738869 0.02549984
  0.02606573 0.02606086 0.02043563 0.03463082 0.03844932 0.02360813
  0.01485958 0.02219588]
 [0.02958537 0.0551012  0.05772246 0.0295975  0.02335041 0.03812644
  0.04068903 0.04169219 0.04524952 0.03061501 0.02955658 0.03755393
  0.0383389  0.01819058 0.01561193 0.04869484 0.03714618 0.0304048
  0.03250217 0.03258084 0.0297806  0.03438708 0.06847069 0.04751273
  0.03637355 0.03506458]
 [0.03011679 0.04220752 0.04826244 0.0248854  0.0202504  0.02837968
  0.04000526 0.03351324 0.04171066 0.0245951  0.02398235 0.02713253
  0.02693835 0.01423011 0.01389538 0.04870176 0.03482359 0.02802714
  0.03212992 0.03313449 0.02882539 0.03044295 0.05617654 0.05133386
  0.03996955 0.03746726]
 [0.03048121 0.01661921 0.01912014 0.01215653 0.01030122 0.01528797
  0.01594883 0.01711074 0.02357111 0.01421639 0.01378834 0.01513839
  0.01492217 0.00683777 0.00739509 0.02233556 0.02151003 0.01931305
  0.02483705 0.02603333 0.02657658 0.02309668 0.04256867 0.06103232
  0.06407008 0.06596924]
 [0.03021004 0.02503071 0.02640468 0.01673243 0.01463114 0.02145557
  0.02249463 0.02180183 0.02418751 0.01797901 0.02122258 0.02205597
  0.02078548 0.00976008 0.01009392 0.03704347 0.02955992 0.0286103
  0.02863767 0.02923246 0.02762877 0.0290463  0.03123677 0.0463104
  0.06724313 0.04767772]
 [0.03048003 0.02272367 0.02354251 0.01812336 0.01589133 0.02230169
  0.02216209 0.02404729 0.02435431 0.02111853 0.02495891 0.02871205
  0.0270991  0.01097136 0.00954328 0.03148097 0.03212704 0.03243294
  0.02852784 0.02851207 0.03142632 0.02892425 0.02147175 0.03456007
  0.06562089 0.02973317]
 [0.02991309 0.018961   0.01633935 0.01363964 0.01141341 0.01488707
  0.01717129 0.01800827 0.01811344 0.01498958 0.02096884 0.01860088
  0.02056658 0.00719383 0.0073418  0.02912829 0.02904033 0.0456072
  0.03294992 0.04340989 0.05675675 0.02639123 0.01677296 0.03865947
  0.09495282 0.04803308]
 [0.03076155 0.01725027 0.01606534 0.01336448 0.01209396 0.01564646
  0.01696514 0.01883291 0.01805543 0.01581801 0.02439788 0.02216329
  0.02136348 0.00708476 0.00705449 0.02810435 0.02505688 0.03871048
  0.03251168 0.04870347 0.0489274  0.02183809 0.01418915 0.02666296
  0.06523366 0.03592828]
 [0.03068216 0.01562721 0.01399033 0.01105452 0.00980679 0.01290765
  0.01500971 0.01600977 0.01614822 0.01313023 0.02751615 0.01856511
  0.01828876 0.00593522 0.00642235 0.02650621 0.03029893 0.03677272
  0.03576897 0.0441271  0.04543781 0.02239748 0.01426227 0.03359959
  0.04612486 0.05786346]
 [0.02965516 0.02343292 0.02101829 0.01568132 0.01411093 0.01917067
  0.02430839 0.02488063 0.0253681  0.01828205 0.02740091 0.02174081
  0.02480531 0.00807329 0.00927217 0.02611208 0.03705555 0.03255144
  0.03990276 0.04145887 0.04811393 0.02689926 0.02612936 0.07734147
  0.04911839 0.06779737]
 [0.03115875 0.0217988  0.02064547 0.01596886 0.01294043 0.01803544
  0.01923191 0.02145914 0.02089232 0.01725537 0.02509044 0.02260674
  0.02201787 0.00874039 0.00834073 0.02377265 0.02559523 0.02642466
  0.0287702  0.0294066  0.0311303  0.0264445  0.01663839 0.02701664
  0.02434302 0.0343809 ]
 [0.03132185 0.02418008 0.0262519  0.02258231 0.01772891 0.02658626
  0.0227152  0.0312036  0.0253478  0.02644313 0.02879418 0.03705559
  0.03281533 0.01357513 0.0095304  0.02230243 0.02253205 0.02645841
  0.02512482 0.02403521 0.02291302 0.02874754 0.01612716 0.02119912
  0.01824505 0.01837174]
 [0.03149625 0.02789772 0.02887742 0.02616489 0.0195138  0.02940216
  0.02695861 0.0382881  0.02740149 0.03069431 0.03450809 0.04309182
  0.03996119 0.01492145 0.01034016 0.023214   0.0222961  0.02655291
  0.02482227 0.0233794  0.02163195 0.02910445 0.01742367 0.01927556
  0.01392111 0.01451029]
 [0.03132943 0.02635048 0.02579687 0.02450705 0.01965058 0.02691873
  0.02421338 0.03230239 0.02730432 0.02948778 0.0327342  0.03821078
  0.03742571 0.01425377 0.0104958  0.02694011 0.02437797 0.02983738
  0.02698077 0.02558713 0.02416066 0.02913265 0.01510347 0.0213829
  0.01734464 0.01306551]
 [0.03120879 0.01927851 0.01789374 0.01450227 0.0113596  0.01591147
  0.01737744 0.0213721  0.02089087 0.01702737 0.02355168 0.02223052
  0.02452143 0.00778764 0.00699543 0.02673641 0.02717914 0.03108097
  0.02815771 0.02694586 0.03186588 0.02664698 0.01300324 0.02880671
  0.03475789 0.01870518]
 [0.03136709 0.01881884 0.01651123 0.01379511 0.01011847 0.01424429
  0.01730872 0.01932573 0.01945357 0.01531954 0.02182319 0.01918988
  0.02244197 0.00690356 0.00652871 0.02772405 0.02575423 0.03445994
  0.02920422 0.02932879 0.03637931 0.02232575 0.01191011 0.03007233
  0.0324937  0.02167915]
 [0.03159465 0.01910554 0.01694217 0.01480081 0.01166231 0.01565417
  0.01748093 0.02093694 0.02033828 0.01753151 0.02521149 0.02236189
  0.02322177 0.00794806 0.00737511 0.02477728 0.02810035 0.0290112
  0.03101107 0.02610638 0.02935238 0.02400828 0.01171594 0.02753762
  0.01948241 0.01664061]
 [0.03155977 0.02138652 0.01915335 0.01583404 0.0118787  0.01713825
  0.02082425 0.02337713 0.02433545 0.01834153 0.02905607 0.02310817
  0.02505384 0.00837625 0.0077328  0.02778397 0.02910742 0.03160788
  0.03272763 0.03027413 0.03380464 0.02518539 0.0125725  0.02742753
  0.01928691 0.01884369]
 [0.03166488 0.01645888 0.0152732  0.01073946 0.00914531 0.01236895
  0.01716111 0.01752632 0.01920411 0.01292064 0.03279356 0.01770164
  0.02014818 0.00630801 0.0057154  0.02428058 0.0325929  0.02761198
  0.03354341 0.02909748 0.03291538 0.0232027  0.01119672 0.02774393
  0.02001767 0.03096575]
 [0.03020266 0.02423616 0.02346778 0.01361488 0.0116354  0.01782825
  0.02477243 0.02713153 0.02973511 0.01767879 0.03260151 0.02249942
  0.02798036 0.00789209 0.00754629 0.02674909 0.03741106 0.03334087
  0.04200371 0.04201199 0.04677945 0.02701748 0.02387368 0.05349235
  0.03313471 0.05796186]
 [0.03147652 0.02368092 0.02325023 0.01896397 0.01458966 0.02192778
  0.02083613 0.02881236 0.02648487 0.02182518 0.02664084 0.02687225
  0.02624178 0.01153863 0.00943603 0.01942567 0.02599272 0.02323769
  0.02751618 0.02570252 0.02660225 0.02647045 0.01490622 0.02001672
  0.01400429 0.02193239]
 [0.0302969  0.02875624 0.02836344 0.04297436 0.04447532 0.03846084
  0.02087854 0.02364367 0.03035876 0.04306125 0.03081832 0.03159047
  0.03017382 0.07285639 0.08852015 0.02653935 0.02721793 0.02362659
  0.02547383 0.0233053  0.02062273 0.03224475 0.03380338 0.01418751
  0.00833913 0.01943783]
 [0.03011489 0.02971587 0.02811102 0.04696417 0.0914654  0.03766676
  0.01934814 0.02240345 0.02933481 0.04975805 0.03638207 0.03229234
  0.02483039 0.07145582 0.09165528 0.03273194 0.03878954 0.03365289
  0.03062404 0.02565171 0.02418394 0.02901183 0.03250441 0.0119575
  0.00645489 0.01656413]
 [0.02984171 0.02683147 0.0243662  0.03813294 0.08946076 0.0256457
  0.01608032 0.0206704  0.02483582 0.04254295 0.03561967 0.03347776
  0.02389554 0.031547   0.04172011 0.02712132 0.05816079 0.0512637
  0.04179303 0.0306277  0.03821542 0.02640411 0.02925083 0.01972979
  0.01309871 0.02103558]
 [0.03007691 0.03354329 0.02940053 0.03915928 0.05695271 0.03069254
  0.0218482  0.02362191 0.03131019 0.03902956 0.0346175  0.03009729
  0.02623152 0.03259208 0.03629247 0.02427799 0.03944651 0.0342383
  0.03344784 0.02937801 0.0289355  0.04687166 0.04148968 0.01568588
  0.0104003  0.02048434]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '4', ',', ' Julie', ' is', ' in', ' the', ' school', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' kitchen', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.0292621  0.0468259  0.04716472 ... 0.05876641 0.00940116 0.00915453]
 [0.0299405  0.04656508 0.04381508 ... 0.06734563 0.0150593  0.01700406]
 [0.03058785 0.04309509 0.04625468 ... 0.06571501 0.02013629 0.01931134]
 ...
 [0.03051446 0.03903176 0.03730718 ... 0.01980394 0.00731675 0.00813324]
 [0.03078855 0.03130319 0.02881263 ... 0.01238702 0.01114655 0.0139402 ]
 [0.03102918 0.02958268 0.02779934 ... 0.01088224 0.00969078 0.01069353]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' states', ' that', ' Fred', ' went', ' to', ' the', ' office', ',', ' which', ' contrad', 'icts', ' sentence', ' ', '8', ',', ' which', ' suggests', ' that', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' cinema', '.', ' Since', ' Fred', ' is', ' in', ' the', ' office', ',', ' sentence', ' ', '8', ' is', ' no', ' longer', ' applicable', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 38), x_tokens=38, y_tokens=53, max_supp_attn=0.0, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 38)
DEBUG result.interpretability.attn_scores 2014 
 [[0.01708172 0.02979661 0.02766248 ... 0.02272808 0.01140035 0.03503599]
 [0.0175008  0.02584854 0.02388942 ... 0.02484708 0.01707876 0.02810403]
 [0.01792389 0.03112577 0.03218836 ... 0.01810748 0.01005781 0.02978255]
 ...
 [0.0180669  0.02409567 0.02312562 ... 0.01662942 0.00921718 0.03635738]
 [0.01852478 0.01825788 0.0162135  ... 0.01703437 0.01336955 0.02341724]
 [0.01850071 0.01889509 0.01715302 ... 0.01491467 0.01086145 0.02247798]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '10', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' her', ' being', ' in', ' the', ' school', '.', ' Previously', ',', ' sentence', ' ', '4', ' mentioned', ' Julie', ' being', ' in', ' the', ' school', ',', ' but', ' that', ' information', ' is', ' now', ' outdated', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 44), x_tokens=44, y_tokens=49, max_supp_attn=0.0204, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 44)
DEBUG result.interpretability.attn_scores 2156 
 [[0.01879868 0.02319796 0.02458495 ... 0.00875614 0.01119536 0.02550241]
 [0.01926361 0.01760886 0.01900875 ... 0.01493755 0.01636926 0.01520007]
 [0.01967366 0.02599867 0.02948927 ... 0.00935362 0.01499381 0.0295328 ]
 ...
 [0.01992502 0.02723576 0.02607773 ... 0.00398693 0.00487174 0.01319459]
 [0.02040758 0.02150743 0.01935276 ... 0.00595352 0.00584679 0.00865818]
 [0.02021637 0.02414796 0.02140565 ... 0.00498866 0.00537215 0.01143923]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' office', ' or', ' the', ' office', ',', ' which', ' is', ' a', ' redundant', ' and', ' affirmative', ' statement', '.', ' It', ' clearly', ' indicates', ' that', ' Fred', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(40, 50), x_tokens=50, y_tokens=40, max_supp_attn=0.05, attn_on_target=0.025)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (40, 50)
DEBUG result.interpretability.attn_scores 2000 
 [[0.02302828 0.03428274 0.03332637 ... 0.01740947 0.01017651 0.03487032]
 [0.02327011 0.02953933 0.0276635  ... 0.03204677 0.01743016 0.03938693]
 [0.02391072 0.03773829 0.04097999 ... 0.01670716 0.00770129 0.03210136]
 ...
 [0.02417652 0.0378     0.03864171 ... 0.01229568 0.00781706 0.03553087]
 [0.02445437 0.02962293 0.02740235 ... 0.01902231 0.0171457  0.03338103]
 [0.02444794 0.03071971 0.02881455 ... 0.01649541 0.01322946 0.02907647]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Fred', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' journey', 'ing', ' to', ' the', ' school', ' and', ' Bill', ' being', ' in', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 26), x_tokens=26, y_tokens=49, max_supp_attn=0.0612, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 26)
DEBUG result.interpretability.attn_scores 1274 
 [[0.01894062 0.03439848 0.03605894 ... 0.00785302 0.00645896 0.02259881]
 [0.01952581 0.02152043 0.02129172 ... 0.00601819 0.00532969 0.01508166]
 [0.01985893 0.02422454 0.02724052 ... 0.00848345 0.00694452 0.01433189]
 ...
 [0.01988036 0.02323297 0.02182695 ... 0.00514714 0.00490785 0.01375018]
 [0.01981514 0.01921634 0.01879242 ... 0.00840481 0.00853666 0.01431241]
 [0.0199956  0.02141325 0.02043203 ... 0.00770455 0.0074038  0.01265781]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' only', ' provide', ' information', ' about', ' Julie', "'s", ' movements', ',', ' but', ' there', ' is', ' no', ' new', ' information', ' about', ' Fred', '.', ' The', ' previous', ' information', ' about', ' Fred', ' journey', 'ing', ' to', ' the', ' school', ' (', 'sentence', ' ', '1', ')', ' is', ' still', ' valid', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0652, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02009835 0.02616476 0.02890484 ... 0.0090891  0.01098993 0.00651059]
 [0.02080733 0.02524277 0.02728712 ... 0.0103408  0.01291116 0.00821087]
 [0.02120527 0.02432167 0.02850148 ... 0.01498791 0.01890383 0.00901109]
 ...
 [0.02117946 0.02719118 0.02335156 ... 0.00621801 0.00604537 0.00566474]
 [0.02162224 0.01988486 0.0167434  ... 0.0119506  0.00921254 0.01169449]
 [0.02160421 0.02136469 0.01787589 ... 0.00949596 0.00776902 0.0083146 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '8', ' explicitly', ' states', ' that', ' Julie', ' moved', ' to', ' the', ' school', ',', ' which', ' means', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 38), x_tokens=38, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 38)
DEBUG result.interpretability.attn_scores 1064 
 [[0.03324608 0.04139582 0.05366145 ... 0.06986097 0.06694825 0.03532609]
 [0.03388869 0.03063099 0.03863152 ... 0.03631987 0.03955736 0.03376849]
 [0.03474523 0.04641222 0.06046182 ... 0.06596613 0.05179404 0.03029925]
 ...
 [0.03507906 0.04788024 0.04432223 ... 0.12253683 0.06802906 0.02637227]
 [0.03541335 0.03662674 0.03277931 ... 0.07668261 0.0482365  0.03386486]
 [0.03536935 0.04074558 0.03521744 ... 0.10456367 0.07599474 0.0255919 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' being', ' in', ' the', ' bedroom', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Bill', "'s", ' movements', ' and', ' Julie', "'s", ' previous', ' location', ' in', ' the', ' school', ' (', 'sentence', ' ', '8', '),', ' but', ' there', ' is', ' no', ' mention', ' of', ' Julie', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 44), x_tokens=44, y_tokens=52, max_supp_attn=0.0577, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 44)
DEBUG result.interpretability.attn_scores 2288 
 [[0.01781707 0.0250826  0.02524217 ... 0.02295497 0.08741196 0.00714512]
 [0.01824229 0.01904032 0.01822885 ... 0.0137531  0.04843254 0.00824869]
 [0.01861693 0.02475562 0.02585157 ... 0.0143008  0.06332762 0.01169453]
 ...
 [0.01866738 0.02623504 0.02662055 ... 0.02287951 0.02114967 0.00417076]
 [0.01907527 0.02172705 0.02089541 ... 0.02923276 0.01228993 0.00555583]
 [0.01906591 0.02413253 0.02361517 ... 0.02483866 0.01264484 0.00529634]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Mary', ' travelled', ' to', ' the', ' school', ',', ' which', ' means', ' she', ' is', ' now', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0714, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03347716 0.05267208 0.04651232 ... 0.02422571 0.04218786 0.04944943]
 [0.03393449 0.03589672 0.02883573 ... 0.03462993 0.02805636 0.02846308]
 [0.03497714 0.05124397 0.05014402 ... 0.03789996 0.05014749 0.04409854]
 ...
 [0.03513489 0.05258087 0.0520007  ... 0.01852472 0.08936744 0.06024611]
 [0.03566794 0.03730488 0.03449562 ... 0.01807662 0.10539003 0.03943463]
 [0.03509562 0.04664322 0.0427064  ... 0.01452477 0.04932186 0.09162195]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Bill', ' going', ' to', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' In', ' fact', ',', ' the', ' context', ' sentences', ' state', ' that', ' Bill', ' went', ' back', ' to', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(37, 26), x_tokens=26, y_tokens=37, max_supp_attn=0.0811, attn_on_target=0.027)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (37, 26)
DEBUG result.interpretability.attn_scores 962 
 [[0.02535548 0.03945681 0.04217905 0.07524607 0.07162596 0.04943409
  0.03451511 0.03084888 0.03099874 0.0497162  0.03669418 0.02577462
  0.02737418 0.12065609 0.12403709 0.03204423 0.02827582 0.0213826
  0.02030092 0.02090509 0.01831415 0.03823219 0.05194463 0.00824582
  0.00809402 0.02693914]
 [0.0261691  0.02459273 0.02491315 0.05639534 0.05124498 0.04268624
  0.02425228 0.02215577 0.02454662 0.04298833 0.03118571 0.02743181
  0.02703013 0.12395167 0.14905517 0.03054298 0.03018284 0.02501635
  0.02217695 0.02153828 0.01709576 0.03197993 0.03170939 0.00612481
  0.00685466 0.01761197]
 [0.02659855 0.02739309 0.03197588 0.05806733 0.05671842 0.05396467
  0.03246511 0.0312256  0.03267852 0.05011794 0.0358148  0.04377057
  0.04188409 0.09784733 0.09161162 0.02618163 0.02811184 0.02539925
  0.02155399 0.02187731 0.01632233 0.02893144 0.02942898 0.00892654
  0.00954897 0.01700417]
 [0.02572263 0.03268887 0.03826841 0.04321054 0.04552416 0.04712893
  0.03625121 0.03865129 0.03608452 0.04391458 0.03601721 0.04723269
  0.04148053 0.05592988 0.05135322 0.03541697 0.03477308 0.03222004
  0.02702153 0.027931   0.0228041  0.03188756 0.03897024 0.02337667
  0.0251771  0.03056831]
 [0.02665004 0.02936275 0.03443656 0.03280951 0.029136   0.04135969
  0.03605902 0.04037948 0.03498053 0.03537606 0.03143157 0.04474634
  0.03857443 0.02129719 0.01635762 0.02683276 0.02669273 0.02728126
  0.02448766 0.02561716 0.02140684 0.02639146 0.02885512 0.02111258
  0.0249057  0.03116886]
 [0.02697585 0.02778676 0.03138246 0.02746574 0.02274352 0.03978939
  0.03507612 0.03846506 0.03432464 0.03239365 0.03095243 0.04635691
  0.03690825 0.01799393 0.01378157 0.02388814 0.02581206 0.02507224
  0.02398858 0.02431171 0.02084256 0.02626402 0.02668488 0.02068215
  0.02439842 0.03052113]
 [0.02649803 0.04320618 0.0385103  0.03021958 0.02463604 0.0424878
  0.04288626 0.04895554 0.03807773 0.03689656 0.03769136 0.05822743
  0.05050283 0.0192369  0.01486001 0.03288125 0.02893701 0.0309524
  0.02777775 0.02724476 0.02333298 0.02836032 0.02933083 0.02133804
  0.02422404 0.0263844 ]
 [0.02727425 0.02928717 0.03338747 0.0280815  0.02103408 0.03844652
  0.03924842 0.03959733 0.03573626 0.03219835 0.03206968 0.04620916
  0.03898341 0.01670736 0.01286819 0.02755663 0.02569923 0.02684928
  0.0257461  0.02730359 0.02366478 0.02659843 0.02346306 0.01726762
  0.02046063 0.02020923]
 [0.02643866 0.02071652 0.01876589 0.01679816 0.01380914 0.01883544
  0.02707653 0.02618787 0.02111973 0.0189407  0.03046985 0.02506681
  0.02801145 0.00933094 0.00950373 0.04189379 0.03003064 0.03448117
  0.03283029 0.03238941 0.03820699 0.02570261 0.01761132 0.03497356
  0.03479962 0.02853351]
 [0.02669062 0.01727012 0.01494364 0.01521171 0.01163461 0.01475158
  0.021245   0.02122889 0.01690345 0.01543657 0.02098526 0.0185049
  0.02044652 0.00777835 0.00809394 0.03783235 0.02551541 0.03116537
  0.02835286 0.02936521 0.04210878 0.02444733 0.01447663 0.03968253
  0.04434669 0.0370247 ]
 [0.02708142 0.01705784 0.01528215 0.01514614 0.01271074 0.01571568
  0.02118917 0.02231327 0.01867726 0.01698776 0.02426381 0.02253496
  0.02258876 0.00808797 0.00798816 0.03770348 0.02514312 0.03564799
  0.03050303 0.0384484  0.03563676 0.02220184 0.01280063 0.03553905
  0.04181788 0.02358303]
 [0.02703818 0.01550223 0.01307431 0.01236806 0.01131672 0.01260408
  0.01802905 0.01716806 0.01541289 0.01375147 0.02671329 0.01831503
  0.01886797 0.00688026 0.00741082 0.04006097 0.028331   0.03780301
  0.03794096 0.04890601 0.04366564 0.02311504 0.01236598 0.03527417
  0.03621114 0.02154641]
 [0.02663723 0.01773148 0.01513345 0.0131335  0.01235574 0.0139252
  0.02008912 0.01879516 0.0184741  0.01440431 0.02564179 0.0174443
  0.01926937 0.00712706 0.00795766 0.0399511  0.02944911 0.03181637
  0.03481722 0.03134292 0.03398803 0.0248035  0.01882914 0.04014501
  0.04265744 0.04352283]
 [0.0271784  0.02598141 0.02179189 0.01625224 0.01402808 0.01767561
  0.02430353 0.0237435  0.02159801 0.01731279 0.02294759 0.02102776
  0.02217221 0.00887773 0.00914852 0.03339455 0.02491063 0.03424063
  0.03513295 0.03287745 0.03395929 0.02457086 0.02231735 0.02547048
  0.02629122 0.02375811]
 [0.02705288 0.03846179 0.04389557 0.0217813  0.01976993 0.03003595
  0.03735766 0.03548861 0.04108091 0.02305303 0.02077485 0.0278492
  0.02652919 0.01297973 0.01217548 0.02875733 0.02659601 0.02448467
  0.02523628 0.02811956 0.0234192  0.02705902 0.04995465 0.024237
  0.03075658 0.02861243]
 [0.02636237 0.06052624 0.06620756 0.02972925 0.02407323 0.03939432
  0.05327905 0.04223005 0.05623724 0.02683057 0.02286411 0.02891317
  0.02956511 0.01542593 0.01583882 0.03399086 0.03228174 0.0268825
  0.02703226 0.03178466 0.02509744 0.03164458 0.07317335 0.02429744
  0.02933175 0.04007192]
 [0.02716151 0.06737567 0.07204303 0.03089379 0.02286598 0.03517816
  0.05018849 0.03995063 0.04972476 0.02703981 0.02386586 0.02795144
  0.02946125 0.01551631 0.01495176 0.03443689 0.0297346  0.0243797
  0.02341884 0.02729732 0.01932392 0.02894773 0.06294407 0.0146409
  0.01576509 0.02024098]
 [0.02734255 0.0316564  0.03512385 0.0237013  0.0189214  0.02839225
  0.03459839 0.03187154 0.03530441 0.0237519  0.02112706 0.02600663
  0.02496795 0.01428873 0.01277152 0.02607744 0.02626898 0.02288398
  0.02352169 0.02609121 0.02138093 0.02752932 0.03925266 0.0227686
  0.02587017 0.02881745]
 [0.02720109 0.02366804 0.02336999 0.02779928 0.02481168 0.02981123
  0.02509607 0.02835875 0.02669423 0.03271728 0.02660923 0.0373418
  0.03379009 0.02002729 0.01452447 0.02133122 0.02458918 0.02614692
  0.02397605 0.02256933 0.02085924 0.02778388 0.02297033 0.02329258
  0.0220573  0.02350138]
 [0.02713877 0.02861353 0.02772536 0.02246691 0.02522358 0.02473426
  0.03022017 0.03298891 0.02997718 0.02446193 0.02739256 0.02821322
  0.03166949 0.0148913  0.01295429 0.0269778  0.0269618  0.02621035
  0.02555961 0.02588047 0.02499993 0.02775852 0.03127674 0.02866795
  0.02947379 0.02636988]
 [0.02823021 0.0203051  0.01944496 0.01951637 0.01627188 0.02244269
  0.02218855 0.02441924 0.0243098  0.02208911 0.02200759 0.02364668
  0.02425819 0.01282139 0.01008994 0.01576502 0.01719544 0.01822917
  0.01936939 0.01929051 0.01730567 0.02495067 0.01744908 0.01641097
  0.01808972 0.01871238]
 [0.02719774 0.02114502 0.01971083 0.01513188 0.01324386 0.01577911
  0.01992164 0.01936236 0.01884674 0.01530126 0.01936943 0.01688366
  0.01966968 0.00965274 0.00908284 0.02164226 0.0198272  0.02057678
  0.02214519 0.02278779 0.02967463 0.02541251 0.0258306  0.0425037
  0.040816   0.03633434]
 [0.02733288 0.03065482 0.02884572 0.01798408 0.01496568 0.01991281
  0.02855088 0.02647839 0.02675112 0.01785124 0.02102414 0.02051543
  0.02388601 0.01195215 0.01047639 0.02276738 0.02242053 0.02123646
  0.02286251 0.02456489 0.02683034 0.02718082 0.03159121 0.03309838
  0.03519404 0.03502437]
 [0.0277246  0.04398497 0.04193579 0.02230442 0.01706599 0.02423589
  0.03404379 0.03296762 0.03623776 0.02184639 0.02147012 0.02382476
  0.02744559 0.01290409 0.01130318 0.02671765 0.02503276 0.02172056
  0.02224805 0.02439996 0.02073888 0.02750865 0.03708742 0.01798343
  0.02013977 0.02162534]
 [0.02767335 0.02852481 0.02757529 0.02106719 0.01576721 0.02217448
  0.03039314 0.02990604 0.02721314 0.02014315 0.02117737 0.02388262
  0.02580753 0.01215407 0.01021072 0.0220374  0.02132876 0.02124817
  0.02136079 0.02424516 0.02330501 0.02821332 0.02595479 0.02411507
  0.03236847 0.03131855]
 [0.02809411 0.01998241 0.0191969  0.01739967 0.0142767  0.01823287
  0.02203388 0.02217919 0.02100132 0.01831297 0.01987144 0.01997952
  0.0224903  0.01049122 0.00856477 0.01989244 0.01967748 0.01883788
  0.01949639 0.02122    0.0217679  0.02616054 0.01646911 0.02718063
  0.02707751 0.0221261 ]
 [0.02735511 0.01540759 0.01380478 0.0120445  0.01005628 0.012267
  0.01528534 0.01604751 0.01631721 0.01317395 0.01692566 0.01413498
  0.01749931 0.00738155 0.00662093 0.02253388 0.02203863 0.02154195
  0.02297566 0.02600393 0.03533139 0.02401633 0.01501644 0.04950093
  0.04800674 0.03920465]
 [0.02706336 0.01536158 0.01341351 0.01231532 0.00975447 0.01215736
  0.0156203  0.0152015  0.01587375 0.01300517 0.01676785 0.01312437
  0.01651583 0.00736232 0.00632377 0.02434989 0.02064959 0.02431211
  0.02385531 0.0282353  0.04376085 0.02189655 0.01377158 0.06610741
  0.05565149 0.04131203]
 [0.0276342  0.0142371  0.01343406 0.01226401 0.01016637 0.01286504
  0.01479389 0.01553139 0.01620112 0.01347806 0.01763123 0.01409172
  0.01649635 0.00783604 0.00616117 0.01808254 0.01690901 0.02056054
  0.01955453 0.02927117 0.03461852 0.01923664 0.01159533 0.06175897
  0.05238459 0.02723805]
 [0.027928   0.0129424  0.0122397  0.01095836 0.00903581 0.01184838
  0.01419078 0.0146492  0.01525501 0.01226723 0.02145183 0.01411756
  0.01619016 0.00736552 0.00566377 0.01828    0.01895769 0.02111147
  0.02003125 0.02393652 0.03718413 0.0186865  0.01006955 0.04741133
  0.03906587 0.02524634]
 [0.02747555 0.01457885 0.0137849  0.01101395 0.00958996 0.01207128
  0.01725481 0.0165317  0.01641008 0.01267456 0.03965483 0.01552589
  0.01849794 0.00748283 0.00638404 0.02300634 0.0272228  0.02368527
  0.02343807 0.02639455 0.03787724 0.02060761 0.01206653 0.0557193
  0.03170519 0.03321319]
 [0.0270137  0.03278943 0.02669133 0.04681819 0.05566455 0.04534297
  0.02965184 0.02902385 0.02902874 0.0499645  0.04347314 0.03601268
  0.03569214 0.05310996 0.03719356 0.02015957 0.02728232 0.02436912
  0.02470724 0.02408746 0.02313102 0.03425173 0.02443552 0.01911495
  0.01369347 0.02094586]
 [0.02789663 0.01568427 0.01561449 0.01429233 0.01135259 0.01426046
  0.01613371 0.01793745 0.01836382 0.01605593 0.02198358 0.01522254
  0.01973352 0.00935658 0.00732644 0.02061543 0.02285575 0.02047973
  0.02225163 0.02352371 0.02624245 0.02169913 0.0130495  0.02982627
  0.02739075 0.02947607]
 [0.0268855  0.02454935 0.0247713  0.04456038 0.04641227 0.03463992
  0.02197714 0.02435752 0.02744996 0.04500404 0.03027202 0.02702791
  0.03022402 0.07945468 0.09501988 0.02177288 0.02879566 0.02539358
  0.02371757 0.02169646 0.01793771 0.0296253  0.02712454 0.00736013
  0.00840568 0.02014618]
 [0.02665186 0.02608788 0.02442183 0.05190681 0.104735   0.03643132
  0.02006533 0.02280385 0.02503651 0.05208344 0.03654552 0.02985748
  0.02635391 0.07847004 0.09770982 0.0250694  0.04073284 0.03724452
  0.03268629 0.02520532 0.02200142 0.02768963 0.02798983 0.00636565
  0.00671453 0.01710486]
 [0.02658261 0.02022361 0.01984445 0.03580424 0.05664544 0.02292928
  0.01507668 0.02055315 0.02187894 0.04088474 0.03389363 0.0293564
  0.024863   0.02820565 0.03274894 0.02138823 0.05116566 0.05295881
  0.07096265 0.03366351 0.03045371 0.02417336 0.02058376 0.01098751
  0.01179814 0.01805105]
 [0.02669301 0.02520525 0.02286018 0.03784112 0.05081205 0.0260581
  0.01939267 0.02144598 0.02519323 0.03757451 0.03096844 0.023877
  0.02429931 0.02916721 0.03187615 0.01816729 0.039611   0.03617778
  0.046962   0.02967289 0.02540948 0.04448101 0.03155516 0.00849178
  0.00845578 0.01693068]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '5', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 32), x_tokens=32, y_tokens=21, max_supp_attn=0.0476, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 32)
DEBUG result.interpretability.attn_scores 672 
 [[0.04491298 0.06076986 0.06197742 0.09258433 0.07262304 0.07164018
  0.05139267 0.05711532 0.0667466  0.0693785  0.05153291 0.05112287
  0.05479147 0.13094984 0.11904887 0.04494861 0.03584356 0.03370663
  0.03227697 0.03831115 0.03293552 0.05046153 0.06948894 0.02703896
  0.02510863 0.05259707 0.05325026 0.0592459  0.13684528 0.0230347
  0.02860869 0.01861345]
 [0.04623987 0.05661197 0.05630149 0.10268269 0.08894181 0.09917753
  0.0557737  0.05709926 0.0715422  0.09121089 0.06439216 0.07120693
  0.0717224  0.18287359 0.14670312 0.04774962 0.03574646 0.03890158
  0.03418424 0.04059164 0.0340997  0.05330708 0.05234373 0.02318354
  0.02363549 0.04711    0.05172211 0.04894601 0.1272227  0.02804191
  0.0332953  0.02333533]
 [0.0470749  0.054534   0.05975686 0.08724257 0.06853262 0.07744218
  0.05515807 0.05867063 0.06412198 0.07240549 0.05059969 0.0658294
  0.0631924  0.12183896 0.08552178 0.04058042 0.03282849 0.03197867
  0.03068206 0.03585451 0.0294589  0.04941402 0.05031783 0.02819482
  0.02831619 0.04416002 0.04764704 0.04178584 0.10599251 0.04283395
  0.05242803 0.03616276]
 [0.04545793 0.06499792 0.06553452 0.05387935 0.04232622 0.05437936
  0.05684378 0.06411286 0.05747354 0.05001675 0.04553364 0.05564726
  0.05564799 0.03801419 0.03496952 0.05163291 0.04184084 0.03810459
  0.03782869 0.04308861 0.03715025 0.05297831 0.06995912 0.05275748
  0.05358925 0.06055772 0.06234082 0.05040248 0.07510516 0.08020825
  0.11008654 0.08907192]
 [0.04622171 0.07065483 0.07096314 0.0387882  0.02831696 0.04689619
  0.05946524 0.06116554 0.05925274 0.03883951 0.04114119 0.04605279
  0.05066844 0.02683971 0.02589128 0.05396206 0.04257745 0.03716765
  0.04158439 0.04576577 0.04044212 0.04991219 0.07537533 0.05683106
  0.05277159 0.0601467  0.07205831 0.0419256  0.04389369 0.07660056
  0.11014407 0.11173695]
 [0.04745235 0.08643842 0.08516876 0.03994782 0.02657506 0.04487506
  0.05788699 0.0552361  0.06892642 0.03803002 0.03430226 0.04042453
  0.04314514 0.02327402 0.0236805  0.06002292 0.04341262 0.03571788
  0.03910162 0.04661557 0.03827111 0.04491457 0.0982871  0.0526299
  0.04756831 0.05707528 0.07464441 0.03697079 0.03438634 0.05497298
  0.12513408 0.11156334]
 [0.0474187  0.06355738 0.06620806 0.0357603  0.0262103  0.03923364
  0.05684602 0.05157672 0.05537326 0.03526406 0.03550913 0.03861046
  0.04047702 0.02257926 0.02520954 0.06234316 0.04862292 0.0376421
  0.04465655 0.04851553 0.04312671 0.04934107 0.07960921 0.07225146
  0.06368721 0.0617422  0.08110967 0.04073809 0.03806972 0.05783448
  0.08459175 0.09165027]
 [0.04834011 0.03268025 0.03669183 0.02261526 0.0192798  0.02784659
  0.03417074 0.03272299 0.0419173  0.02560824 0.02823048 0.02531411
  0.02763861 0.01496141 0.01906448 0.04158862 0.0368678  0.0296261
  0.03762652 0.04137018 0.03448069 0.0409617  0.04283192 0.05085273
  0.04577757 0.04407408 0.04576623 0.02790938 0.02340968 0.0300686
  0.03558996 0.03500701]
 [0.04765627 0.04040148 0.04183805 0.02784697 0.02295864 0.0370519
  0.04248284 0.04250187 0.0379082  0.03135638 0.0357898  0.03802846
  0.03801541 0.017276   0.02057644 0.04973653 0.04869228 0.03868399
  0.04734576 0.05012774 0.04632312 0.05129953 0.04660714 0.06814598
  0.07706255 0.05334998 0.05332863 0.03561803 0.03365168 0.06371619
  0.04565499 0.07455024]
 [0.04847575 0.0572299  0.0606514  0.05228488 0.03617985 0.0602873
  0.06139495 0.06816307 0.05588286 0.06055325 0.05925361 0.080722
  0.06961747 0.03395427 0.02885805 0.05151631 0.04827761 0.04909609
  0.04866577 0.05064004 0.04483011 0.05295135 0.04545015 0.05039218
  0.05822264 0.04962841 0.06202735 0.04405097 0.03919188 0.08413164
  0.05551042 0.0835648 ]
 [0.04908529 0.04041512 0.04465146 0.0340155  0.02849446 0.04125307
  0.04801678 0.04481743 0.03970214 0.03881051 0.04312458 0.04521666
  0.04644685 0.02200869 0.02187157 0.04708572 0.04218762 0.03890756
  0.04461697 0.04574157 0.04321776 0.048827   0.03656985 0.05407919
  0.05618187 0.04214043 0.05042906 0.04044012 0.03222702 0.06812578
  0.04769622 0.08398274]
 [0.04850108 0.03049896 0.03024239 0.02114158 0.0188058  0.02663869
  0.03512216 0.03206981 0.0294187  0.02513626 0.03658736 0.0306769
  0.03502815 0.01287194 0.01573534 0.04949443 0.04698252 0.04063295
  0.04890859 0.04673928 0.05022316 0.04548569 0.02773911 0.06652702
  0.0651153  0.04107552 0.03455978 0.04174804 0.02260732 0.05457456
  0.03150066 0.04579299]
 [0.0481898  0.03330987 0.03078788 0.02188782 0.0183123  0.02688301
  0.04473716 0.03987846 0.03163976 0.02542103 0.04075293 0.03095258
  0.04253502 0.0125886  0.01423045 0.05777128 0.04914125 0.0511739
  0.05789616 0.05841065 0.06707147 0.04453809 0.0257305  0.07483237
  0.07691389 0.04664667 0.02470515 0.04911478 0.01743806 0.06050016
  0.02646061 0.02958187]
 [0.04897457 0.03027479 0.02976355 0.02138854 0.02038384 0.02766037
  0.04078818 0.03728986 0.02991063 0.02611977 0.0495542  0.03776186
  0.04011564 0.01333899 0.01458399 0.04575997 0.06287844 0.0488418
  0.07146525 0.05662498 0.06048065 0.04365584 0.02108177 0.05084508
  0.06140768 0.03534371 0.02335332 0.04291621 0.01589599 0.04936308
  0.02458925 0.02680259]
 [0.04881064 0.02802333 0.02714659 0.01871765 0.01852296 0.02438178
  0.04169707 0.03528215 0.02832879 0.02233602 0.06118553 0.03515477
  0.04020951 0.01163507 0.01336547 0.05302519 0.07295155 0.05649258
  0.0721092  0.05851419 0.06387329 0.04363717 0.02043528 0.06075282
  0.0610743  0.04250848 0.01970926 0.05068815 0.01507419 0.04850378
  0.02591948 0.02115241]
 [0.04809649 0.0309551  0.02919701 0.0213268  0.01857173 0.03084498
  0.04370738 0.04200931 0.03799069 0.02575326 0.03659671 0.03432999
  0.0442504  0.0136495  0.01300132 0.03535081 0.04113927 0.04048703
  0.05192727 0.05151809 0.04406371 0.04165831 0.0232425  0.04651252
  0.05549261 0.04400869 0.02243251 0.04214798 0.02228032 0.04938333
  0.03559133 0.02767544]
 [0.04944311 0.02992002 0.03075104 0.02703631 0.02081492 0.03266793
  0.04025986 0.04343077 0.03290641 0.02991934 0.04076463 0.03816007
  0.04078678 0.01767708 0.01595395 0.03177341 0.03293215 0.03615819
  0.0393145  0.03873201 0.03984899 0.04137068 0.02287604 0.03672726
  0.03358478 0.0404291  0.02754594 0.04099124 0.02767358 0.04528438
  0.04282742 0.03136775]
 [0.04766317 0.04289075 0.04477774 0.0681169  0.05946424 0.06152253
  0.04412825 0.04518417 0.05570317 0.07257689 0.05160073 0.05919825
  0.05685415 0.08890808 0.101012   0.0383226  0.03629472 0.04573831
  0.03846409 0.04064811 0.03936988 0.04663795 0.0444879  0.02615994
  0.02371433 0.04643929 0.04878335 0.05821134 0.06088663 0.02486809
  0.03272402 0.02047085]
 [0.04717561 0.05414804 0.04811034 0.08945712 0.1907869  0.07331108
  0.0462281  0.04629243 0.05100773 0.09269539 0.07421084 0.06995898
  0.04960307 0.10815841 0.15012124 0.05338868 0.06205349 0.08147752
  0.0527873  0.05007396 0.05931294 0.045485   0.05517283 0.02736428
  0.02309489 0.04608246 0.06500529 0.05790282 0.05603356 0.01573068
  0.01556813 0.01213784]
 [0.04724291 0.04299796 0.03784069 0.05860373 0.0954861  0.04289492
  0.03690189 0.04093853 0.03835006 0.06452949 0.06355951 0.05474874
  0.0432085  0.03790551 0.05535152 0.04593486 0.08393209 0.11975276
  0.07399828 0.06034154 0.08788522 0.04298481 0.03942662 0.04086463
  0.03910341 0.04104563 0.04239646 0.0648705  0.03076491 0.02251557
  0.0179628  0.01353713]
 [0.04756674 0.04868996 0.04163985 0.06467563 0.07841244 0.05311166
  0.0469982  0.04444266 0.04589694 0.06403905 0.055778   0.05088236
  0.04604558 0.04869703 0.05524958 0.03801191 0.05479688 0.06971207
  0.05455979 0.05177491 0.06353474 0.06017811 0.05296717 0.03305683
  0.02857748 0.04383868 0.03718506 0.08337566 0.04134975 0.01970725
  0.01811623 0.01224233]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' going', ' to', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' In', ' fact', ',', ' the', ' context', ' sentence', ' ', '8', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 38), x_tokens=38, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 38)
DEBUG result.interpretability.attn_scores 1444 
 [[0.02457135 0.03350898 0.03444604 ... 0.03633328 0.01730302 0.01471448]
 [0.02499082 0.03732738 0.0345539  ... 0.02781204 0.02504918 0.02481864]
 [0.02564766 0.0346451  0.03685008 ... 0.02661328 0.01331496 0.01236168]
 ...
 [0.02575552 0.02832869 0.03203971 ... 0.02583575 0.01379027 0.01203144]
 [0.02637059 0.02198054 0.02467497 ... 0.01884384 0.01807709 0.01667858]
 [0.02621561 0.02399042 0.02771473 ... 0.02312375 0.01829347 0.01565214]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '10', ' states', ' that', ' Bill', ' is', ' in', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Bill', ' being', ' in', ' the', ' park', '.', ' \n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(33, 44), x_tokens=44, y_tokens=33, max_supp_attn=0.0, attn_on_target=0.0303)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (33, 44)
DEBUG result.interpretability.attn_scores 1452 
 [[0.02832775 0.03810379 0.0408969  ... 0.07240056 0.02427273 0.05773596]
 [0.0288687  0.02967877 0.03228813 ... 0.0578131  0.02520963 0.02583041]
 [0.02944776 0.04264812 0.04853725 ... 0.06415746 0.03173508 0.04769818]
 ...
 [0.02976232 0.04492443 0.03968782 ... 0.02053321 0.01273277 0.13202438]
 [0.03026637 0.03383236 0.02783763 ... 0.014334   0.01402485 0.07924767]
 [0.03019766 0.03771923 0.03070276 ... 0.01307986 0.01249085 0.09683763]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '13', ' states', ' that', ' Mary', ' is', ' in', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 50), x_tokens=50, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 50)
DEBUG result.interpretability.attn_scores 1600 
 [[0.02932795 0.04253238 0.0420122  ... 0.02360389 0.04297746 0.03955152]
 [0.02971028 0.03944252 0.03975548 ... 0.03657641 0.03571587 0.02743092]
 [0.0305049  0.0460101  0.04603814 ... 0.01973402 0.03868914 0.02299251]
 ...
 [0.03072025 0.03766226 0.03972627 ... 0.01494725 0.05377815 0.03409812]
 [0.03143829 0.02786101 0.02942497 ... 0.02004739 0.03879655 0.03810751]
 [0.03116189 0.03112518 0.03121976 ... 0.01860987 0.0442113  0.03931957]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' sentence', ' ', '1', ',', ' we', ' know', ' Bill', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', '.', ' From', ' sentence', ' ', '2', ',', ' we', ' know', ' Julie', ' is', ' in', ' the', ' cinema', '.', ' Since', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' it', "'s", ' possible', ' that', ' Bill', ' is', ' not', ' in', ' the', ' cinema', ',', ' which', ' means', ' he', ' could', ' be', ' in', ' the', ' park', '.', ' However', ',', ' we', ' can', "'t", ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(72, 26), x_tokens=26, y_tokens=72, max_supp_attn=0.0417, attn_on_target=0.0139)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (72, 26)
DEBUG result.interpretability.attn_scores 1872 
 [[0.01267405 0.0318733  0.03224048 ... 0.00325438 0.00521995 0.01512158]
 [0.01307945 0.01960227 0.01897338 ... 0.00271911 0.00418852 0.01000718]
 [0.01329622 0.02214052 0.02416593 ... 0.00393837 0.00614826 0.0096798 ]
 ...
 [0.01337045 0.01962347 0.01753238 ... 0.00247639 0.0033026  0.00926559]
 [0.01348618 0.01614888 0.01436175 ... 0.00723947 0.00710665 0.01003949]
 [0.01350909 0.01815298 0.01532994 ... 0.00477855 0.00548256 0.00901191]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' in', ' the', ' given', ' context', ' sentences', '.', ' Sentence', ' ', '1', ' mentioned', ' Bill', ',', ' but', ' it', "'s", ' not', ' provided', ' in', ' this', ' task', '.', ' Sent', 'ences', ' ', '4', ' and', ' ', '5', ' talk', ' about', ' Julie', ' and', ' Mary', ',', ' but', ' not', ' Bill', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0577, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01752507 0.02101771 0.02221255 ... 0.01108375 0.01314232 0.0141317 ]
 [0.01805034 0.01992836 0.0196369  ... 0.01665568 0.0184209  0.02094775]
 [0.01850693 0.01841941 0.01946165 ... 0.01966036 0.01467237 0.0208537 ]
 ...
 [0.01885106 0.02096885 0.01875106 ... 0.00890786 0.01636789 0.0080153 ]
 [0.01913732 0.02132458 0.02033726 ... 0.00809631 0.01750981 0.00749939]
 [0.01917449 0.01856145 0.01773538 ... 0.00838309 0.01391654 0.00868669]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' explicitly', ' states', ' that', ' Julie', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(19, 38), x_tokens=38, y_tokens=19, max_supp_attn=0.0, attn_on_target=0.0526)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (19, 38)
DEBUG result.interpretability.attn_scores 722 
 [[0.05002783 0.05893405 0.06613754 0.08016472 0.06622121 0.07046824
  0.0526244  0.05606676 0.05871834 0.06670909 0.04058269 0.05370706
  0.06116823 0.09907452 0.09616141 0.042027   0.0354237  0.03461946
  0.03782152 0.04070061 0.03422822 0.0500461  0.0811574  0.0195102
  0.02503702 0.05758483 0.06954113 0.06232376 0.13087867 0.02676904
  0.02703345 0.03916994 0.06628305 0.02595134 0.0294071  0.02623211
  0.03156475 0.05428104]
 [0.05043536 0.05189059 0.06097967 0.05000116 0.04592192 0.05253869
  0.05526147 0.06498504 0.04942773 0.04630512 0.03879254 0.04877325
  0.07315613 0.0546674  0.06696994 0.0436862  0.03931472 0.05607298
  0.05085263 0.05892054 0.05277839 0.04736135 0.05427904 0.03472086
  0.04631194 0.05886919 0.05835346 0.04166171 0.08850195 0.05082141
  0.03999333 0.05843955 0.05407186 0.04385209 0.04612933 0.05395858
  0.04638516 0.05374013]
 [0.05203475 0.06357877 0.0728246  0.1006809  0.09233523 0.10441159
  0.06177478 0.06340808 0.06837152 0.08495772 0.05186488 0.07367838
  0.07838082 0.15660764 0.10559795 0.04210461 0.03215756 0.03145111
  0.03376009 0.03654613 0.03045511 0.05343838 0.0616242  0.01638232
  0.02080437 0.04490205 0.0673036  0.04472786 0.11374426 0.04784236
  0.03035322 0.0528681  0.08284283 0.03642661 0.0388371  0.03256858
  0.03973926 0.09078594]
 [0.05063834 0.05671756 0.06748287 0.04443686 0.03931082 0.05237534
  0.05081159 0.05283285 0.05151657 0.04364891 0.03631957 0.04829725
  0.05162747 0.03652555 0.03006486 0.04713047 0.03536147 0.03268666
  0.03793816 0.04094465 0.03520102 0.05497233 0.07614844 0.03315692
  0.05032832 0.06286343 0.06499503 0.04485533 0.10169118 0.1244398
  0.03989048 0.13481851 0.09777739 0.07334048 0.06161258 0.0526486
  0.05197686 0.08236099]
 [0.05187447 0.06003292 0.06724312 0.03539051 0.03101657 0.04549212
  0.05451239 0.04971229 0.05470546 0.03673947 0.03385889 0.04073599
  0.04411739 0.02849159 0.0253512  0.05541416 0.03790766 0.03354649
  0.04258117 0.04569545 0.03698712 0.04868847 0.07662923 0.03020435
  0.04826547 0.05394343 0.06272198 0.03483867 0.06500548 0.1268416
  0.03496047 0.11675376 0.05363261 0.04966047 0.04153058 0.03911852
  0.04051673 0.04451337]
 [0.05249888 0.03353953 0.03636575 0.01991516 0.01817843 0.02622851
  0.02776579 0.02877852 0.03403538 0.02265375 0.02442528 0.0242799
  0.02707    0.01494317 0.01584162 0.0405041  0.03220077 0.02880299
  0.0375563  0.0409722  0.03447781 0.03745056 0.04628918 0.03637332
  0.05636715 0.05293852 0.03416679 0.0280363  0.02455566 0.05839921
  0.02897353 0.0612839  0.02347799 0.03054446 0.02840909 0.03021383
  0.02609605 0.02454004]
 [0.05196746 0.05737955 0.06142889 0.03513847 0.02705443 0.04849193
  0.05208696 0.05136259 0.05145889 0.03770425 0.03656564 0.04918503
  0.04823727 0.02481584 0.02239968 0.05612781 0.04262927 0.04309129
  0.04696215 0.04900763 0.0439404  0.05623575 0.06611303 0.06065866
  0.06470411 0.06022131 0.06655775 0.0371779  0.04810593 0.10206062
  0.05191047 0.09146796 0.09373628 0.07724055 0.06663094 0.05622276
  0.05570612 0.06504678]
 [0.05375704 0.06615976 0.06995706 0.05332811 0.03770958 0.0652854
  0.06130138 0.068489   0.06112855 0.06078085 0.05524216 0.08434122
  0.07088452 0.03684359 0.02851029 0.05328077 0.04660239 0.04686296
  0.04897529 0.05041476 0.04409015 0.05728111 0.05449976 0.06632426
  0.05726549 0.0543979  0.07092627 0.04657099 0.04737127 0.08533476
  0.06419292 0.071228   0.09900729 0.07767929 0.08068522 0.07167739
  0.07064953 0.08554667]
 [0.05447575 0.05078636 0.05232581 0.0368601  0.02800613 0.04612079
  0.05086171 0.04992899 0.04645308 0.03874292 0.04435059 0.04701846
  0.04812713 0.02520677 0.0229517  0.05285106 0.04378223 0.03990728
  0.044671   0.04616777 0.04332555 0.05489741 0.04413218 0.06308528
  0.0701179  0.051561   0.0549794  0.04288128 0.03930039 0.0770233
  0.0618024  0.06334792 0.07032417 0.08116975 0.07334762 0.06516626
  0.06438577 0.05736141]
 [0.0537261  0.0413388  0.03760634 0.02709253 0.01916402 0.03283452
  0.0403747  0.0397905  0.03823366 0.02789638 0.04254507 0.03531485
  0.03848312 0.01767472 0.01835259 0.057398   0.05632737 0.04600795
  0.0473488  0.04836015 0.05116395 0.05392383 0.03315267 0.07071231
  0.09361254 0.05244171 0.03494815 0.04141539 0.02689674 0.0494207
  0.0667927  0.04270567 0.04691206 0.07529149 0.06482206 0.06646008
  0.0586623  0.03723968]
 [0.05311523 0.04160949 0.03590024 0.02817049 0.01741029 0.0330449
  0.04486078 0.04525815 0.03992699 0.02847935 0.04109635 0.03353362
  0.0416496  0.01692102 0.01708557 0.0585442  0.05940423 0.05735549
  0.05148214 0.05279606 0.06164318 0.05064864 0.02774378 0.08169807
  0.1027694  0.05527014 0.02937207 0.03811842 0.01934997 0.0395743
  0.06182368 0.02897719 0.03476676 0.08248207 0.06678405 0.07320409
  0.06902868 0.03360882]
 [0.05430549 0.03593827 0.03409639 0.02657681 0.01815301 0.03212912
  0.03726425 0.0390337  0.03821307 0.02870104 0.0468205  0.03926265
  0.03895121 0.01678188 0.01642054 0.0539206  0.0586134  0.04871267
  0.05633605 0.04975744 0.05660994 0.04795761 0.02546003 0.09834944
  0.08672528 0.04748772 0.0318227  0.03943789 0.01929559 0.03967118
  0.09673449 0.03063083 0.03030835 0.06885413 0.07169752 0.07453025
  0.07249    0.03503532]
 [0.05408743 0.03579354 0.03322355 0.02494048 0.0169302  0.03078762
  0.042427   0.04067732 0.03949027 0.02722719 0.06739789 0.03918143
  0.0410163  0.01512704 0.01574397 0.06193548 0.06289422 0.04995786
  0.05945003 0.05202066 0.05776415 0.04921385 0.0254644  0.09315251
  0.06252956 0.05009598 0.03185822 0.03789965 0.01769611 0.02636335
  0.10185248 0.02450345 0.02055697 0.06016291 0.06196982 0.06883099
  0.06788222 0.02618673]
 [0.05189421 0.08126783 0.05842168 0.03761235 0.02605754 0.04880379
  0.1327222  0.0989745  0.07111132 0.04181378 0.13194449 0.05929253
  0.09057868 0.02045431 0.02240814 0.09726416 0.07714114 0.10334418
  0.08339525 0.09368167 0.07998516 0.06000131 0.05670703 0.14393109
  0.08065555 0.06647942 0.04901264 0.05444996 0.02474887 0.03271805
  0.08228497 0.03246035 0.02725556 0.05584158 0.05407651 0.06304117
  0.05593453 0.03049733]
 [0.05483702 0.03435162 0.03734798 0.03485541 0.02035012 0.03946528
  0.03954766 0.04467138 0.04638716 0.0374415  0.03710391 0.04371667
  0.04022812 0.02437853 0.0202316  0.03607358 0.03452744 0.03504336
  0.04640294 0.04272964 0.04259868 0.04931838 0.02517156 0.03483889
  0.02956198 0.03992548 0.04375622 0.04016998 0.02739308 0.03089247
  0.05924872 0.04743614 0.05415971 0.06213722 0.07377008 0.07934972
  0.08839975 0.0761117 ]
 [0.05292956 0.04880036 0.0515647  0.08370881 0.06462845 0.0743467
  0.04780416 0.05123256 0.06403315 0.08838164 0.05424866 0.06614546
  0.06317826 0.12146858 0.12471168 0.03847861 0.03864317 0.04275049
  0.04272177 0.04513653 0.03857477 0.05276002 0.04914333 0.01801742
  0.02074258 0.04539039 0.05998721 0.06484903 0.06187362 0.02398779
  0.03356305 0.04070229 0.05701485 0.03156558 0.0398748  0.03893092
  0.0418345  0.07467802]
 [0.05253849 0.06320087 0.05577991 0.11199563 0.21274437 0.08731863
  0.05102879 0.05301621 0.06744864 0.11307579 0.08043947 0.07883319
  0.04950386 0.15851758 0.18785289 0.05441561 0.06755014 0.07552505
  0.06090397 0.05730086 0.06400639 0.05277258 0.06398226 0.01780219
  0.01662401 0.04526337 0.07508169 0.07085041 0.06103368 0.01610825
  0.03308069 0.01891987 0.03028639 0.01899371 0.02726649 0.0250418
  0.03034802 0.04200265]
 [0.05216911 0.06123899 0.0518603  0.08779964 0.14158672 0.05146946
  0.04502229 0.04966561 0.05548001 0.09377618 0.07836636 0.07331193
  0.04599319 0.05925256 0.08931888 0.06368838 0.12752913 0.11812019
  0.09718528 0.07739237 0.11677625 0.0532154  0.06153897 0.05134792
  0.03954827 0.04938745 0.05252877 0.10954072 0.03839913 0.02434301
  0.05089255 0.02273862 0.03026443 0.02531459 0.03913764 0.04441023
  0.04958732 0.04580823]
 [0.05268748 0.0574412  0.0494536  0.08133186 0.0772209  0.05838733
  0.05194773 0.05211605 0.06386011 0.07496511 0.05803502 0.0613911
  0.04764871 0.0722477  0.07402544 0.04515515 0.07198999 0.07614163
  0.07365546 0.07145486 0.07539388 0.06981698 0.07076359 0.02973396
  0.0280291  0.05097669 0.04208694 0.12019472 0.04415842 0.01738887
  0.03461644 0.02154792 0.02732144 0.0234917  0.03401152 0.03839398
  0.03881244 0.04065514]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '7', ' (', 'from', ' a', ' previous', ' task', ')', ' stated', ' that', ' Julie', ' is', ' in', ' the', ' office', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' suggests', ' Julie', ' has', ' moved', ' or', ' changed', ' locations', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(39, 44), x_tokens=44, y_tokens=39, max_supp_attn=0.0, attn_on_target=0.0256)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (39, 44)
DEBUG result.interpretability.attn_scores 1716 
 [[0.02364    0.02746861 0.02557998 ... 0.02005706 0.01962247 0.02224134]
 [0.02412543 0.02387619 0.02142285 ... 0.02234075 0.02862491 0.02606101]
 [0.02472129 0.02629709 0.02602523 ... 0.01516631 0.01543001 0.01821959]
 ...
 [0.0249776  0.02967353 0.02646593 ... 0.01586075 0.01412655 0.02142229]
 [0.02543476 0.02504395 0.02240194 ... 0.01916754 0.02071011 0.01988524]
 [0.02533973 0.02669513 0.02218386 ... 0.01681175 0.01664159 0.01863447]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' Sentence', ' ', '14', ' explicitly', ' states', ' that', ' Fred', ' moved', ' to', ' the', ' cinema', ',', ' which', ' means', ' Fred', ' is', ' currently', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(28, 50), x_tokens=50, y_tokens=28, max_supp_attn=0.0, attn_on_target=0.0357)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (28, 50)
DEBUG result.interpretability.attn_scores 1400 
 [[0.03336123 0.04785372 0.04604837 ... 0.02966914 0.03005681 0.02066826]
 [0.03408797 0.03476159 0.03325427 ... 0.03515866 0.05665355 0.03112782]
 [0.03472507 0.04933831 0.05173434 ... 0.04537234 0.05137186 0.03303079]
 ...
 [0.03501085 0.05221869 0.04831912 ... 0.01803752 0.01895243 0.01750643]
 [0.03536273 0.04146305 0.03562364 ... 0.01909446 0.0167747  0.01920826]
 [0.03540076 0.04058895 0.03596361 ... 0.01567197 0.01591525 0.01671541]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' went', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02717359 0.04359012 0.05469918 0.07282609 0.07985047 0.07678962
  0.05410591 0.06600137 0.05313151 0.0622347  0.04470289 0.0603331
  0.06154576 0.09411506 0.06162515 0.02823697 0.03173297 0.03256088
  0.02872819 0.03106974 0.02419498 0.0379896  0.04070431 0.01732238
  0.02227772 0.03690039]
 [0.02707545 0.0770083  0.06108714 0.05714186 0.0423859  0.05734856
  0.1799191  0.10669594 0.06349168 0.05324995 0.06453843 0.05258017
  0.08074889 0.02718995 0.0226901  0.03872475 0.03794265 0.05110034
  0.03824977 0.04484387 0.03659787 0.04362959 0.03848532 0.02570978
  0.03435985 0.03978262]
 [0.02967669 0.05538159 0.03344605 0.0537098  0.03571157 0.03642222
  0.02828679 0.02186121 0.0209056  0.03289156 0.02459672 0.01645789
  0.01720941 0.0310981  0.04122952 0.01994251 0.01493338 0.01339625
  0.01641393 0.01700286 0.01406962 0.04316766 0.04942255 0.00757188
  0.00787208 0.01676703]
 [0.02800622 0.03285022 0.03701281 0.02474364 0.01843881 0.02703895
  0.02859177 0.02536074 0.02787278 0.02497286 0.02514384 0.02637148
  0.02385518 0.01398707 0.01338043 0.03489969 0.02861418 0.03044077
  0.02997458 0.03228302 0.03227014 0.03117151 0.05327706 0.06066995
  0.03418288 0.04235881]
 [0.02815124 0.04070183 0.04407526 0.06527368 0.06050161 0.0477957
  0.03082767 0.02905803 0.03258834 0.04546799 0.03263123 0.02597446
  0.02509406 0.10448826 0.10949012 0.0328357  0.02871202 0.02062948
  0.02162251 0.02291232 0.02013735 0.03798859 0.05794819 0.01272513
  0.01149238 0.036998  ]
 [0.02878725 0.02654996 0.02638663 0.04923589 0.04619709 0.04146016
  0.02240602 0.02272208 0.0275631  0.04176888 0.02925013 0.02927717
  0.02708779 0.11464494 0.13400525 0.03207939 0.03184986 0.02468607
  0.02419626 0.02377525 0.01944757 0.03239614 0.03398765 0.00841563
  0.01029535 0.02446329]
 [0.02922551 0.02975105 0.0338642  0.05201326 0.04891825 0.05193906
  0.02956681 0.0307766  0.0354769  0.04904571 0.03397734 0.0461908
  0.04046309 0.09059697 0.08481517 0.02727309 0.02912933 0.0244653
  0.02282767 0.02290228 0.01839286 0.02929511 0.0314713  0.01145033
  0.01202369 0.02340472]
 [0.02827629 0.03969314 0.04613426 0.04244705 0.04522333 0.04881225
  0.03466424 0.03962853 0.03953388 0.04327727 0.034856   0.05048608
  0.04124297 0.05494931 0.05018884 0.03743586 0.03682765 0.03065372
  0.0281778  0.02864423 0.02580457 0.03371047 0.04632386 0.02881747
  0.02237956 0.03899907]
 [0.02936087 0.03788733 0.04578643 0.04523518 0.04238143 0.05461332
  0.0376495  0.04347917 0.04741929 0.04740197 0.03415307 0.05105863
  0.04504444 0.04042417 0.02720648 0.02558762 0.02881118 0.02570392
  0.02523339 0.02568765 0.02074278 0.03464681 0.0339899  0.01634105
  0.01853222 0.03192476]
 [0.02870148 0.05067414 0.05425078 0.02853867 0.02430931 0.03755594
  0.04078028 0.04098117 0.04485934 0.02966129 0.02886586 0.03787985
  0.03751546 0.01777217 0.01582381 0.0423658  0.03532062 0.02978981
  0.02999138 0.03150781 0.02977903 0.03329742 0.06305073 0.03836523
  0.03306265 0.03862577]
 [0.02917412 0.0636205  0.06391892 0.02649395 0.02322152 0.03178727
  0.0401651  0.03772277 0.04489179 0.02606822 0.026101   0.02949869
  0.03026058 0.01483394 0.01502849 0.04528286 0.03667465 0.02915253
  0.03141649 0.03506469 0.02883798 0.03054031 0.06722062 0.03228081
  0.02530451 0.03555096]
 [0.02936687 0.03602671 0.04108922 0.0211274  0.01915655 0.02392072
  0.03191773 0.0302531  0.03703749 0.0221905  0.02220793 0.02420357
  0.02422064 0.01291788 0.01359634 0.03888762 0.03245464 0.02541361
  0.02853878 0.03040761 0.02809466 0.02864503 0.05591731 0.04555262
  0.02593225 0.04215039]
 [0.02950212 0.01611372 0.01746935 0.0120102  0.01110935 0.01512622
  0.01513369 0.01651832 0.01972908 0.01387412 0.01505795 0.01459985
  0.01515259 0.00690559 0.00828375 0.02166008 0.02188278 0.02027665
  0.02587899 0.028231   0.03109967 0.02229561 0.04082483 0.06181858
  0.03211104 0.05067835]
 [0.02947569 0.02326873 0.02475335 0.0165446  0.01536996 0.02112832
  0.02288091 0.02274323 0.02430264 0.01854302 0.02268827 0.02223296
  0.02201916 0.00981422 0.01085468 0.03809731 0.02614285 0.02407965
  0.02411938 0.02568131 0.02742073 0.02645657 0.029303   0.05486067
  0.03841505 0.03980372]
 [0.02964148 0.0240328  0.02469588 0.01948195 0.01640856 0.02499061
  0.02509066 0.0267303  0.0249788  0.02270958 0.02722686 0.02942061
  0.02869322 0.0116734  0.0104371  0.03744181 0.02726705 0.02795454
  0.02573745 0.02688667 0.03034677 0.02755223 0.02186883 0.0444941
  0.03148164 0.02500742]
 [0.02912144 0.01947226 0.01639032 0.0136906  0.01073818 0.01464701
  0.01948349 0.01934629 0.0185201  0.01464715 0.02138433 0.01766229
  0.02084772 0.0072527  0.00712716 0.04040357 0.02417124 0.03664208
  0.03062578 0.03704367 0.04992476 0.02583245 0.01802222 0.07821851
  0.05021003 0.02735805]
 [0.02984615 0.01777401 0.01653777 0.01351987 0.01166275 0.01609513
  0.01844746 0.01910304 0.01925306 0.01569228 0.02538869 0.02082641
  0.02158735 0.00757021 0.00709377 0.03039487 0.02319183 0.03647211
  0.0285897  0.04383826 0.04165187 0.02159698 0.01473598 0.0592792
  0.04214887 0.0190029 ]
 [0.02982202 0.0151233  0.01337857 0.01042255 0.00888457 0.01207754
  0.01499166 0.01501233 0.01681617 0.01219271 0.02775171 0.01653778
  0.01737473 0.00589619 0.0061206  0.03040676 0.02437316 0.03261597
  0.03183807 0.03995956 0.04019275 0.02179895 0.01463855 0.06235926
  0.05258905 0.02099209]
 [0.02914107 0.0219121  0.02115634 0.01675297 0.01639738 0.01925719
  0.02352919 0.02645745 0.0270979  0.0191514  0.02647472 0.02396087
  0.02558134 0.0089894  0.0091454  0.02450725 0.02846873 0.03192399
  0.03880627 0.03537066 0.03779766 0.02623521 0.02096998 0.03955832
  0.06381139 0.04500228]
 [0.03026915 0.01976397 0.01917598 0.01625961 0.01273153 0.01788147
  0.01932752 0.02142972 0.02204831 0.01752858 0.02523991 0.02209375
  0.02198436 0.00910259 0.00841396 0.02255049 0.02145661 0.02410192
  0.02883358 0.02670752 0.02794929 0.02626303 0.01457547 0.02780941
  0.03172539 0.02260271]
 [0.03043591 0.02080992 0.02364029 0.02265052 0.01725264 0.02487057
  0.02218034 0.0280491  0.02561304 0.02607799 0.02641849 0.03390049
  0.03051727 0.01374154 0.00972369 0.01871972 0.02204826 0.02411755
  0.02387906 0.02195216 0.02143795 0.02827919 0.01363831 0.01525189
  0.02437628 0.02132714]
 [0.03056982 0.02507804 0.02633597 0.02551394 0.01828229 0.02793735
  0.02760888 0.03574299 0.02732238 0.03002269 0.03507977 0.04031164
  0.03767752 0.01484323 0.01026437 0.02225543 0.02252828 0.02677649
  0.02441519 0.02342014 0.02206641 0.02860254 0.01426571 0.01413449
  0.02369763 0.01662984]
 [0.03043821 0.02382193 0.02385882 0.02424355 0.01860986 0.02595857
  0.02460445 0.03038106 0.02717363 0.02873058 0.03198218 0.03602302
  0.03532485 0.01421576 0.01049452 0.0276887  0.02454389 0.02882353
  0.02639222 0.0251867  0.02402717 0.02874045 0.01250573 0.01598181
  0.02325855 0.01492689]
 [0.030279   0.0194568  0.01855291 0.01528228 0.01173765 0.01675917
  0.01826098 0.02223453 0.0218982  0.01841325 0.02436593 0.02374783
  0.0252137  0.00875258 0.00737134 0.03145337 0.02597409 0.03030167
  0.02835243 0.0268185  0.03061598 0.02652873 0.01204222 0.02622523
  0.03276047 0.01639109]
 [0.03025942 0.01950319 0.01800697 0.01521641 0.01120773 0.01559972
  0.01965864 0.02252008 0.02125856 0.0175537  0.02455455 0.02141772
  0.02410753 0.00811351 0.00701097 0.03395983 0.02612906 0.0320541
  0.0300479  0.02765448 0.03438016 0.02322859 0.01179329 0.02677672
  0.03732654 0.01705525]
 [0.03029243 0.01863298 0.01719864 0.01500535 0.01218484 0.01558257
  0.01707507 0.02093054 0.02037549 0.01833929 0.02508409 0.02257249
  0.02265002 0.00869338 0.0072852  0.02743739 0.02881052 0.03113159
  0.03353658 0.02891056 0.03437299 0.02357268 0.01217964 0.02330317
  0.04280081 0.01686266]
 [0.03046053 0.02102501 0.01977183 0.01661316 0.01237937 0.01735653
  0.02053958 0.02383782 0.0251208  0.01931465 0.02884126 0.0238598
  0.02500813 0.00938005 0.00769432 0.02976315 0.02766038 0.03211623
  0.03263488 0.03218896 0.03437867 0.02448626 0.01263864 0.02433526
  0.03478724 0.01563063]
 [0.03059492 0.01541712 0.01542698 0.01086886 0.00930158 0.01246053
  0.01629695 0.01732208 0.01948701 0.01320435 0.03204896 0.01773734
  0.01898995 0.00698976 0.00573819 0.02681517 0.02774476 0.02821907
  0.03572541 0.03152525 0.03347561 0.02230758 0.0114137  0.03276682
  0.03742838 0.01542155]
 [0.02933154 0.01950179 0.02009697 0.0137027  0.01175777 0.01720314
  0.02124625 0.02384311 0.02842588 0.01749091 0.02364659 0.01929579
  0.02298177 0.00914264 0.00812726 0.02171239 0.03282204 0.02948738
  0.04656569 0.03762072 0.03821284 0.02688698 0.02204793 0.02998954
  0.06397834 0.08552754]
 [0.03063489 0.0196979  0.02022703 0.01784188 0.01348729 0.02104829
  0.01830368 0.02389176 0.02550891 0.0211677  0.02410116 0.02481606
  0.02488849 0.01195433 0.00887428 0.01740657 0.02244817 0.02177316
  0.02954486 0.02576427 0.02673125 0.02482378 0.01250573 0.01563757
  0.02268675 0.01995528]
 [0.02944004 0.02586321 0.02601612 0.04143477 0.04233783 0.03648128
  0.02093866 0.02371409 0.02936981 0.04346425 0.03062084 0.0297208
  0.03015725 0.07146829 0.08803119 0.02262728 0.02863519 0.02535735
  0.02497729 0.02383127 0.02068535 0.03057369 0.02897128 0.00917619
  0.01131124 0.02653098]
 [0.02923168 0.02695554 0.02630723 0.04656337 0.08832698 0.03681473
  0.01906786 0.02221127 0.0280594  0.0499206  0.0356714  0.03049852
  0.02557047 0.07203364 0.0937618  0.02748446 0.03969298 0.03401714
  0.02978467 0.02586626 0.02473938 0.02784119 0.02853762 0.00792016
  0.01020144 0.02296216]
 [0.02899473 0.02386762 0.02276996 0.03858749 0.08893739 0.02539171
  0.01555368 0.02073489 0.02379552 0.0438382  0.03369968 0.0321302
  0.02378883 0.03292129 0.04220648 0.02302577 0.0599397  0.05041929
  0.04133826 0.0306787  0.04069348 0.0253862  0.02492247 0.01348808
  0.01912071 0.02697815]
 [0.02924207 0.02917325 0.0264819  0.03900692 0.05459869 0.0298485
  0.02089945 0.02270516 0.02907364 0.03989211 0.03164829 0.02632186
  0.02559548 0.03352786 0.03686028 0.02063677 0.04106539 0.03334586
  0.03300554 0.02876207 0.02942995 0.04423281 0.03580001 0.01139266
  0.01605803 0.02542755]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Bill', ' travelled', ' to', ' the', ' cinema', ',', ' which', ' means', ' Bill', ' is', ' currently', ' in', ' the', ' cinema', '.', ' Context', ' sentence', ' ', '5', ' is', ' contradictory', ' to', ' sentence', ' ', '4', ',', ' so', ' it', ' can', ' be', ' ignored', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.1739, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02001757 0.03293099 0.03447933 ... 0.04536654 0.00752806 0.02249672]
 [0.0206919  0.03042003 0.03104269 ... 0.05060289 0.01013466 0.02657303]
 [0.0209902  0.02957318 0.03405961 ... 0.05214481 0.01643132 0.02645688]
 ...
 [0.02107105 0.03033228 0.02511209 ... 0.01498554 0.00551217 0.01029274]
 [0.02149741 0.0234951  0.01819207 ... 0.00789875 0.00714426 0.01086978]
 [0.02151358 0.02421085 0.01856796 ... 0.00829106 0.0074053  0.01348312]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Bill', ' is', ' in', ' the', ' cinema', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '7', ' states', ' that', ' Bill', ' went', ' to', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(38, 38), x_tokens=38, y_tokens=38, max_supp_attn=0.0, attn_on_target=0.0263)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (38, 38)
DEBUG result.interpretability.attn_scores 1444 
 [[0.02444246 0.02918193 0.02874288 ... 0.01655027 0.01582482 0.02369622]
 [0.0249833  0.02810064 0.03145103 ... 0.02741822 0.02613328 0.03630619]
 [0.02554973 0.03081394 0.03558795 ... 0.01327946 0.01202993 0.01489003]
 ...
 [0.02572247 0.0278164  0.02530781 ... 0.01321486 0.01350274 0.01492336]
 [0.02618066 0.02091885 0.01889989 ... 0.01760885 0.02230522 0.02103649]
 [0.02620193 0.02284813 0.01963383 ... 0.01434352 0.01545758 0.01765175]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '10', ',', ' Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' school', ',', ' but', ' it', ' doesn', "'t", ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Mary', ' might', ' be', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 44), x_tokens=44, y_tokens=47, max_supp_attn=0.0213, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 44)
DEBUG result.interpretability.attn_scores 2068 
 [[0.01954732 0.0259403  0.02460136 ... 0.01081571 0.00824714 0.01547509]
 [0.01987736 0.0197078  0.01942342 ... 0.0199149  0.01344679 0.02457595]
 [0.0204096  0.0280151  0.02890636 ... 0.01403854 0.01136122 0.02278759]
 ...
 [0.0206112  0.02832419 0.02879168 ... 0.00700706 0.00638144 0.00836073]
 [0.02102197 0.0228771  0.02220956 ... 0.00811493 0.00835602 0.00949325]
 [0.02111023 0.02289094 0.02281453 ... 0.00733541 0.00827991 0.00941343]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Mary', ' is', ' in', ' the', ' kitchen', '.', ' The', ' possible', ' locations', ' for', ' Mary', ' are', ' the', ' office', ' or', ' the', ' bedroom', ',', ' according', ' to', ' context', ' sentence', ' ', '14', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 50), x_tokens=50, y_tokens=42, max_supp_attn=0.0476, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 50)
DEBUG result.interpretability.attn_scores 2100 
 [[0.02216381 0.03166458 0.03041309 ... 0.03312257 0.01478331 0.02145517]
 [0.02265878 0.02359489 0.02538572 ... 0.02472868 0.01680437 0.01660971]
 [0.02302836 0.03179203 0.03360257 ... 0.0274426  0.01291414 0.01658837]
 ...
 [0.02324751 0.03172476 0.02943233 ... 0.02510688 0.0132017  0.02005577]
 [0.02374514 0.02286031 0.02078773 ... 0.02086629 0.01601863 0.01711114]
 [0.02364078 0.02773859 0.02486688 ... 0.0238088  0.01539692 0.01859057]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Bill', ' went', ' back', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Bill', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0857, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02636632 0.04312401 0.05523906 0.07207768 0.07533495 0.07615129
  0.0569392  0.06630836 0.05208873 0.05998972 0.04058371 0.05772398
  0.05905711 0.09580533 0.06119699 0.02707142 0.02990452 0.0309223
  0.02861471 0.03172504 0.02354478 0.03672062 0.04166291 0.01411384
  0.02503845 0.03616016]
 [0.02632336 0.06935321 0.04997063 0.04369489 0.03100872 0.04405064
  0.14002101 0.08094316 0.05111062 0.03819612 0.05051239 0.03912027
  0.06544115 0.0185322  0.01794688 0.03937665 0.03815168 0.05389932
  0.04095282 0.04886683 0.04142895 0.04035131 0.03926025 0.0321832
  0.04329108 0.04396415]
 [0.02881206 0.05484954 0.03341915 0.05331034 0.03539234 0.03631991
  0.02813371 0.02163196 0.0206614  0.03301224 0.02285792 0.01635216
  0.01673587 0.03177803 0.04083836 0.01921213 0.01455689 0.01316627
  0.01698087 0.01766705 0.01401351 0.04139065 0.05073986 0.0051302
  0.00644732 0.016406  ]
 [0.02722017 0.02694378 0.03002149 0.02525981 0.01950116 0.02524069
  0.02536712 0.02352989 0.02407019 0.02435585 0.02453365 0.02611128
  0.02274198 0.01622265 0.01624394 0.03426571 0.02841941 0.03040298
  0.03022072 0.03093688 0.03086034 0.02813461 0.04154789 0.05963283
  0.03180858 0.03818794]
 [0.02734382 0.04020143 0.04339634 0.06494347 0.05964463 0.04719826
  0.03056659 0.0282222  0.03186456 0.04482481 0.02971497 0.02565193
  0.02429035 0.10254876 0.10763751 0.03197025 0.02801863 0.02035688
  0.0221236  0.02339902 0.02008094 0.03678249 0.05823421 0.008209
  0.00918993 0.03629799]
 [0.02795947 0.02621193 0.02581844 0.04847247 0.04555789 0.04042168
  0.02227977 0.02197259 0.02696069 0.04079843 0.02685322 0.02882871
  0.02604497 0.11249752 0.13219316 0.03129779 0.03086703 0.02417307
  0.02486206 0.0243036  0.01947387 0.0316666  0.03385801 0.00591845
  0.00879409 0.02368196]
 [0.02835515 0.02951805 0.03314568 0.05134224 0.04889416 0.05093903
  0.02966399 0.03009464 0.0346195  0.04792161 0.03137103 0.04519394
  0.03870104 0.08864876 0.08361483 0.02656725 0.02823938 0.02376294
  0.02355434 0.02356135 0.01846058 0.02881142 0.03160372 0.00907374
  0.01245875 0.02239808]
 [0.02743708 0.03935003 0.04515173 0.04123644 0.04496744 0.0470315
  0.03523782 0.03906725 0.03861038 0.04187581 0.03218211 0.04870646
  0.04028082 0.05332579 0.04908109 0.03737395 0.03570502 0.03028029
  0.02900697 0.02961962 0.02573644 0.0330991  0.04682246 0.02636833
  0.02340954 0.0365705 ]
 [0.02845989 0.03889253 0.04630401 0.04526375 0.04324909 0.05434627
  0.03849376 0.04397577 0.04754368 0.04725308 0.03271336 0.05014452
  0.04469773 0.04036431 0.02722951 0.02551578 0.02787931 0.0254162
  0.02581712 0.02644728 0.02052565 0.03417413 0.03471602 0.01343462
  0.01900425 0.03037388]
 [0.02783451 0.04997812 0.05348067 0.02828365 0.02427547 0.03665438
  0.04059206 0.04041345 0.04347439 0.02912397 0.02723034 0.03673798
  0.03704483 0.01760393 0.01573834 0.0425131  0.03472597 0.02953449
  0.03050422 0.03187481 0.02935062 0.0321979  0.06279799 0.03550006
  0.03282645 0.03669133]
 [0.02833868 0.06239543 0.06354927 0.02641067 0.02281315 0.03148193
  0.04001107 0.03687764 0.04422791 0.02594568 0.02436094 0.02869204
  0.02947778 0.01456842 0.0147418  0.04482092 0.03562931 0.02849469
  0.03174913 0.03517669 0.02814309 0.02897378 0.06753889 0.02617832
  0.0255898  0.03387938]
 [0.02849209 0.03487875 0.0405471  0.02096053 0.01855866 0.02397576
  0.03173548 0.02941135 0.03614117 0.02180603 0.02065204 0.02353289
  0.02338687 0.01262699 0.01325433 0.03853917 0.03147393 0.0246623
  0.02874194 0.03033291 0.02719925 0.02752377 0.05492985 0.03777646
  0.02602334 0.03949322]
 [0.02863484 0.01612701 0.01773823 0.01195333 0.01080344 0.0156121
  0.01603676 0.01694679 0.01982149 0.01361375 0.01466073 0.01475426
  0.01496764 0.00695313 0.00828259 0.02340493 0.02278973 0.02019252
  0.02549507 0.02692827 0.02818729 0.0213209  0.03777311 0.05433086
  0.03077185 0.04752629]
 [0.02854956 0.02272129 0.02452006 0.01635042 0.01494868 0.02117872
  0.02300081 0.02212964 0.02463766 0.01820231 0.02101276 0.02141741
  0.02103447 0.00967524 0.01045522 0.03533606 0.02399016 0.02251827
  0.02369424 0.02570503 0.02676417 0.02607064 0.02954381 0.05218458
  0.03707074 0.0407985 ]
 [0.02869802 0.02382771 0.02467365 0.01917463 0.01625097 0.02445331
  0.02537663 0.02620801 0.02541643 0.02230467 0.02587271 0.02912999
  0.02839842 0.01170272 0.01009939 0.03660057 0.02574023 0.02752126
  0.02613124 0.0274355  0.0304451  0.0275971  0.02180678 0.04455121
  0.03064619 0.02457627]
 [0.02819181 0.01898946 0.01606301 0.01355032 0.01065666 0.01468828
  0.01977599 0.01903441 0.01886331 0.01447428 0.02078868 0.01749844
  0.02095072 0.00717822 0.00682511 0.04035027 0.02392814 0.03618109
  0.03003805 0.03674755 0.04869219 0.02496222 0.0172407  0.08130354
  0.04456028 0.02705593]
 [0.02889873 0.01800053 0.01718532 0.01445332 0.01251738 0.01762651
  0.01940855 0.02006854 0.02052584 0.01667601 0.0237335  0.0213366
  0.02193795 0.00802215 0.00719846 0.02501278 0.0197613  0.0297957
  0.0260246  0.03891856 0.04333346 0.02147017 0.01498353 0.06725368
  0.03544025 0.01926956]
 [0.02943961 0.01452578 0.01334863 0.01124192 0.00919987 0.01332861
  0.01551802 0.01625737 0.0172845  0.01318556 0.0227978  0.01705395
  0.01848316 0.00627959 0.00596324 0.02230918 0.01847372 0.02513339
  0.02407489 0.02690969 0.03771555 0.02030152 0.01204606 0.04976445
  0.03603087 0.02066043]
 [0.02908725 0.01618714 0.01490398 0.01138795 0.00955524 0.01336746
  0.01873074 0.01748323 0.01820946 0.0129314  0.03518378 0.01838563
  0.01903697 0.00636734 0.00687132 0.02706676 0.0227856  0.02659065
  0.02667186 0.02800449 0.03606541 0.02285521 0.01427792 0.05302741
  0.0400741  0.0228852 ]
 [0.02814309 0.02331631 0.02278939 0.01708996 0.0161991  0.02127821
  0.02795389 0.02812736 0.02826839 0.01943854 0.02925696 0.02370403
  0.02583035 0.0098781  0.01038208 0.02393777 0.03296604 0.03009857
  0.03569236 0.03232682 0.03363952 0.02792314 0.02195974 0.03682746
  0.0695736  0.06924403]
 [0.02940076 0.01969505 0.01936476 0.0162218  0.01241364 0.01767957
  0.02015381 0.02184409 0.021694   0.01715117 0.02575137 0.02182328
  0.02206253 0.00918803 0.00809252 0.02259262 0.02193092 0.0254081
  0.0264781  0.0247589  0.02584228 0.02636608 0.01426642 0.02583258
  0.02836383 0.0227952 ]
 [0.02956184 0.02098875 0.0234412  0.02309744 0.01741419 0.02535344
  0.02279504 0.02916454 0.02648625 0.02680759 0.02563004 0.03448464
  0.03028704 0.0146613  0.00953926 0.01784413 0.02080778 0.02259003
  0.02328403 0.02181121 0.02012695 0.02835083 0.01447287 0.01516438
  0.02523166 0.02195564]
 [0.02974139 0.02539023 0.02734232 0.02612664 0.01843505 0.02814007
  0.02648672 0.03593836 0.02811556 0.0311641  0.03156232 0.04078353
  0.03710765 0.01538328 0.0100418  0.0204179  0.02072413 0.02375098
  0.02350735 0.02207958 0.02008515 0.02800171 0.01502781 0.01304723
  0.02286055 0.01663886]
 [0.02968005 0.0236031  0.0235888  0.02314299 0.01732259 0.02571634
  0.02322905 0.02948783 0.02777667 0.02797752 0.02783264 0.03546453
  0.03433962 0.01384359 0.00958941 0.02444684 0.0218673  0.02554082
  0.02579969 0.02456377 0.02212797 0.02750298 0.01303978 0.0157769
  0.02155758 0.01458465]
 [0.0294545  0.01871234 0.01835933 0.01455782 0.01099327 0.0165255
  0.01822929 0.02256104 0.02258574 0.01800203 0.02265023 0.02362143
  0.0249185  0.0085954  0.00696329 0.03085585 0.02458592 0.0270764
  0.02680596 0.02554051 0.02825795 0.02527272 0.01186836 0.02645654
  0.03033988 0.01740415]
 [0.02943902 0.01947736 0.01870696 0.0154568  0.01105286 0.01631895
  0.02144719 0.0246915  0.02219502 0.01762494 0.02356516 0.02205443
  0.02490908 0.00853215 0.0069484  0.03270355 0.02602555 0.03003452
  0.02933007 0.02670418 0.03224377 0.02290758 0.01151182 0.02534202
  0.03405167 0.01769869]
 [0.02947138 0.01879942 0.01776446 0.01542732 0.01209359 0.01625451
  0.01873938 0.0220144  0.0209551  0.01836116 0.02443199 0.02246624
  0.02262158 0.00912649 0.007297   0.0260442  0.02780329 0.02875551
  0.03127556 0.0265566  0.03050523 0.023268   0.01201846 0.0220012
  0.03924629 0.01715871]
 [0.02960324 0.02097493 0.01996338 0.01649109 0.01205055 0.01764356
  0.02220628 0.02424888 0.02517855 0.01920511 0.02973574 0.02312228
  0.02493944 0.00951398 0.00759852 0.02799795 0.02679753 0.02942029
  0.03120956 0.029671   0.0315528  0.02448036 0.01271602 0.02399393
  0.03282488 0.01588678]
 [0.02958162 0.01668748 0.01652827 0.01182337 0.00982121 0.01347168
  0.0188855  0.01882024 0.01999825 0.01443422 0.03755363 0.01797323
  0.0210261  0.00740729 0.00614083 0.02791101 0.02909469 0.02859462
  0.0321076  0.02822421 0.03150018 0.02303198 0.01225711 0.02992912
  0.03558477 0.01767478]
 [0.02836232 0.02163699 0.02057998 0.01392813 0.01187286 0.01666952
  0.02739711 0.02782752 0.02673476 0.01773544 0.03983822 0.02226717
  0.0305205  0.00830592 0.00762129 0.02710755 0.03698656 0.03761829
  0.04187831 0.03924596 0.04107115 0.027867   0.02073772 0.04019986
  0.0661744  0.05100473]
 [0.02962908 0.01976554 0.02040766 0.01840159 0.01396645 0.02062916
  0.01938348 0.02614886 0.02405026 0.02230329 0.02469871 0.02429054
  0.0258     0.01275292 0.00986028 0.01719008 0.02400861 0.02400987
  0.02651717 0.02376194 0.02352403 0.02448609 0.0135585  0.01501465
  0.02426405 0.02264353]
 [0.02859164 0.02508754 0.0259945  0.04138247 0.04262002 0.03635687
  0.02032585 0.02325963 0.02864183 0.04394909 0.02852567 0.02906997
  0.02939403 0.07099868 0.08763186 0.02223389 0.02737739 0.02501571
  0.02545231 0.02412706 0.02031938 0.02986288 0.02867775 0.0068115
  0.0096109  0.02603448]
 [0.02839071 0.02632388 0.02586863 0.04619488 0.08677409 0.03643361
  0.01863304 0.02138516 0.02765308 0.04999213 0.03348837 0.02981099
  0.02462641 0.0710283  0.09351715 0.0267423  0.03771973 0.03367401
  0.03081043 0.02644564 0.02434128 0.02747581 0.02762767 0.0061493
  0.00880705 0.02249185]
 [0.0281016  0.024572   0.02381056 0.04114801 0.09721112 0.02688272
  0.01621227 0.02120566 0.02451008 0.04753485 0.03530183 0.03448226
  0.02380878 0.03580106 0.04585871 0.02315762 0.05990161 0.05131391
  0.04150663 0.03084833 0.03732707 0.02528941 0.02450387 0.0123231
  0.018921   0.02562603]
 [0.02840541 0.02889331 0.02701342 0.04014185 0.05662951 0.0305799
  0.02103307 0.02269872 0.02902457 0.04182747 0.03256142 0.02820893
  0.02509857 0.03428245 0.03750561 0.02021208 0.04036297 0.03409378
  0.03308641 0.02877407 0.02751406 0.04350929 0.03437213 0.00919543
  0.01411201 0.02428111]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' current', ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' Context', ' sentence', ' ', '2', ' mentioned', ' Julie', "'s", ' possible', ' locations', ',', ' but', ' it', ' is', ' not', ' relevant', ' to', ' the', ' current', ' situation', '.', ' Context', ' sentences', ' ', '4', ' and', ' ', '5', ' only', ' provide', ' information', ' about', ' Bill', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(58, 32), x_tokens=32, y_tokens=58, max_supp_attn=0.0345, attn_on_target=0.0172)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (58, 32)
DEBUG result.interpretability.attn_scores 1856 
 [[0.01575359 0.02086322 0.02282093 ... 0.03886021 0.00996559 0.00740658]
 [0.0163297  0.01786434 0.01891672 ... 0.04548977 0.01447057 0.00983472]
 [0.01657459 0.01817794 0.02141073 ... 0.04350932 0.02005774 0.01224036]
 ...
 [0.01681294 0.01875205 0.01634798 ... 0.00829627 0.00864987 0.0089703 ]
 [0.01706755 0.01918769 0.01822626 ... 0.00839557 0.00855053 0.00902449]
 [0.01723304 0.01657323 0.0159355  ... 0.00875617 0.00878836 0.0091942 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 38), x_tokens=38, y_tokens=31, max_supp_attn=0.0, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 38)
DEBUG result.interpretability.attn_scores 1178 
 [[0.03029261 0.04168717 0.04679093 ... 0.02147446 0.01758623 0.02634018]
 [0.03045995 0.0344434  0.03995124 ... 0.02457642 0.02982355 0.03698873]
 [0.03163493 0.04525701 0.05274718 ... 0.01587519 0.01430305 0.01875659]
 ...
 [0.03182761 0.04256732 0.04222592 ... 0.01697287 0.01365244 0.01731784]
 [0.03197067 0.03381499 0.03169422 ... 0.02082242 0.02673935 0.0257732 ]
 [0.03198495 0.0398379  0.03527145 ... 0.01968728 0.0193103  0.0243195 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Mary', ' is', ' in', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' that', ' suggests', ' Mary', ' has', ' moved', ' from', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02739213 0.03121035 0.03139446 ... 0.02100048 0.02390694 0.01200879]
 [0.02788749 0.02799573 0.0284557  ... 0.03068037 0.0543904  0.02512634]
 [0.02852431 0.03367624 0.03489606 ... 0.0299626  0.03007405 0.01573055]
 ...
 [0.0287462  0.03748336 0.03540354 ... 0.00934497 0.0119057  0.00921545]
 [0.0291418  0.03131091 0.02825732 ... 0.01187463 0.01045161 0.01220288]
 [0.02918607 0.03262739 0.02869867 ... 0.00908541 0.01082486 0.01048191]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', "'s", ' current', ' location', ' being', ' the', ' cinema', '.', ' Context', ' sentence', ' ', '14', ' only', ' mentions', ' the', ' bedroom', ' as', ' a', ' possible', ' location', ' for', ' Julie', ',', ' and', ' there', ' is', ' no', ' mention', ' of', ' the', ' cinema', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 50), x_tokens=50, y_tokens=44, max_supp_attn=0.0227, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 50)
DEBUG result.interpretability.attn_scores 2200 
 [[0.02099122 0.02875476 0.0281968  ... 0.02604277 0.04344868 0.03063954]
 [0.02121774 0.02693862 0.02317724 ... 0.01144016 0.02092329 0.02684586]
 [0.02187789 0.03235739 0.03285513 ... 0.02542396 0.04023559 0.02363071]
 ...
 [0.02211086 0.03093728 0.02943739 ... 0.0286942  0.05918555 0.02847194]
 [0.02258269 0.02336215 0.02178138 ... 0.01123073 0.03192045 0.02509172]
 [0.02238703 0.02616401 0.02402228 ... 0.01051028 0.06440039 0.02716058]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Mary', ' moved', ' to', ' the', ' school', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02712761 0.04540917 0.05721802 0.06884167 0.07545729 0.07200094
  0.05457683 0.06685213 0.05341074 0.0609313  0.04514362 0.05986208
  0.06512176 0.08670767 0.05345215 0.02908851 0.03016603 0.0322846
  0.02877956 0.03168515 0.02693234 0.03900975 0.04125483 0.02032009
  0.02171513 0.03680522]
 [0.026948   0.06885536 0.05999615 0.0619756  0.05332816 0.06415009
  0.18935113 0.11705205 0.07445959 0.06714926 0.06130237 0.05646416
  0.08518023 0.04056853 0.03092079 0.03532292 0.03318305 0.0425358
  0.03463339 0.04020315 0.0342654  0.04509138 0.04044564 0.02491574
  0.02535759 0.03692504]
 [0.02962515 0.05444964 0.03448067 0.0527714  0.03992613 0.03475342
  0.02651193 0.02017524 0.02118107 0.03311761 0.02656009 0.01576206
  0.01722806 0.0315868  0.04135068 0.02075997 0.01339529 0.01283991
  0.01583663 0.01611482 0.01521776 0.04259955 0.04974508 0.00735126
  0.00703505 0.0182394 ]
 [0.02807956 0.03293805 0.0373398  0.02479813 0.01713879 0.02862366
  0.02701045 0.02503685 0.02915535 0.02479001 0.02550501 0.02666575
  0.02396432 0.01323711 0.0132447  0.03488304 0.02897406 0.03213495
  0.03275496 0.03416704 0.03148451 0.031045   0.04978985 0.05513111
  0.06008629 0.04480449]
 [0.02817225 0.03895291 0.04309708 0.06515346 0.06006004 0.04575805
  0.02858719 0.02638865 0.03203603 0.04373377 0.03238492 0.02451478
  0.02359913 0.10392109 0.10909183 0.03208732 0.0258607  0.02009496
  0.02054039 0.02196493 0.02141866 0.03789366 0.05798239 0.01259828
  0.0102444  0.03903573]
 [0.02876385 0.02519824 0.02635027 0.05039515 0.04514502 0.04171608
  0.02136763 0.02066792 0.02713206 0.04090705 0.02881632 0.02778859
  0.02559757 0.11268795 0.13545923 0.03166937 0.02888939 0.02403134
  0.02307978 0.02333498 0.02042551 0.0324303  0.03484908 0.00897485
  0.00835429 0.02551491]
 [0.02920321 0.02830086 0.03401864 0.05285442 0.04923716 0.05244983
  0.02798126 0.02829624 0.03551368 0.04830951 0.03364675 0.04386945
  0.03891449 0.08971611 0.08519454 0.02674998 0.02634868 0.0238641
  0.02225321 0.02304611 0.01929088 0.02923769 0.03275003 0.01218785
  0.01108438 0.02391382]
 [0.02829161 0.03830686 0.04529244 0.04167409 0.04368574 0.04971433
  0.03276315 0.03754204 0.03879768 0.04328161 0.03516251 0.04928954
  0.04094892 0.05461809 0.05014891 0.03638822 0.03398458 0.03021745
  0.02727663 0.02884583 0.02593671 0.03306634 0.04612894 0.03072994
  0.02904683 0.03874306]
 [0.02938932 0.03739839 0.04631024 0.04657629 0.04235331 0.05589293
  0.03548371 0.04092562 0.04566349 0.04816249 0.03492543 0.04950481
  0.04328078 0.04174835 0.0273995  0.02529303 0.02587805 0.02499551
  0.0238038  0.02566567 0.02133862 0.03299824 0.03492239 0.01635755
  0.01778882 0.03150817]
 [0.0287292  0.05156879 0.05548093 0.03036992 0.02436318 0.03950944
  0.04016557 0.04105999 0.04500642 0.03124376 0.0292388  0.03860994
  0.03735851 0.01884128 0.01611541 0.04240938 0.03353041 0.02941229
  0.02897308 0.03116093 0.02926117 0.03251316 0.06130081 0.03734453
  0.03919384 0.03760267]
 [0.02919344 0.06532845 0.06450012 0.02803995 0.0228959  0.03239936
  0.03955061 0.0369262  0.04597734 0.02695374 0.02555445 0.0298184
  0.02877729 0.0157151  0.01524634 0.04600985 0.03409947 0.0284021
  0.02946363 0.03366931 0.02905081 0.03000556 0.06605741 0.03088393
  0.03033403 0.03529984]
 [0.02933627 0.03621966 0.04048546 0.02168425 0.01848608 0.02435503
  0.03136351 0.02910142 0.03629628 0.02214498 0.02111167 0.02444126
  0.02231412 0.01332071 0.01358918 0.03978629 0.03105073 0.02499963
  0.0282582  0.03019769 0.02820783 0.02903943 0.05280161 0.04396686
  0.04796139 0.04153895]
 [0.02955199 0.01604224 0.01744884 0.01211258 0.010992   0.01431966
  0.01514838 0.01637839 0.02044387 0.01390199 0.014334   0.0153968
  0.01463686 0.00703656 0.00808532 0.02187073 0.02137795 0.02051999
  0.02571063 0.02845201 0.03010136 0.0227582  0.03498955 0.05849324
  0.08109663 0.04775327]
 [0.02950047 0.02309749 0.02428617 0.0165956  0.01549096 0.02082625
  0.02168904 0.02111784 0.02361569 0.0181282  0.02105885 0.02213971
  0.02059936 0.0099873  0.01088328 0.03690448 0.02543675 0.02312778
  0.02351641 0.0248479  0.02590785 0.02680993 0.02785689 0.05187644
  0.06394852 0.04477144]
 [0.0296065  0.02372644 0.02431617 0.01895551 0.01640629 0.02385382
  0.02435713 0.02708084 0.02451181 0.02218937 0.02572861 0.02968489
  0.02939228 0.01139908 0.01023425 0.0355657  0.02805166 0.02749667
  0.02552962 0.02610313 0.0284762  0.02808117 0.02132411 0.0468604
  0.04053422 0.02603208]
 [0.02915128 0.02002624 0.01688107 0.01420847 0.01144452 0.01521706
  0.02056081 0.02299489 0.01839654 0.01554421 0.02137684 0.01920586
  0.02337262 0.00733563 0.00735245 0.03830673 0.02956107 0.03534998
  0.03271356 0.03417535 0.04297167 0.0256977  0.01664698 0.07404599
  0.05951221 0.02989537]
 [0.02984067 0.01850951 0.01636954 0.01431599 0.0121016  0.01637888
  0.01858885 0.02059259 0.01869169 0.01637502 0.02639941 0.0217268
  0.02291429 0.00744102 0.00729744 0.03736121 0.02530151 0.039824
  0.02921426 0.03507209 0.03697212 0.0221012  0.01433751 0.05135966
  0.04276134 0.02216673]
 [0.029727   0.01612282 0.01402268 0.01090677 0.0091739  0.01327208
  0.01733926 0.01784827 0.01694619 0.01305314 0.03239391 0.0175966
  0.02023312 0.00595858 0.00644812 0.03331556 0.03054331 0.03444828
  0.03455829 0.03422678 0.03678907 0.02268558 0.01514725 0.05901445
  0.04065083 0.02534   ]
 [0.02911081 0.02433969 0.02267884 0.01534896 0.01330147 0.0199998
  0.02449488 0.02735059 0.02819512 0.01788964 0.02262069 0.02305668
  0.02550548 0.00806154 0.00827519 0.03037929 0.02865183 0.03664265
  0.03993794 0.04389245 0.04202878 0.02661772 0.02310364 0.04492398
  0.04670046 0.04716103]
 [0.03027375 0.02037352 0.01921893 0.01594778 0.0128558  0.0180364
  0.01844946 0.02092138 0.02078709 0.01716007 0.02421847 0.02222617
  0.02117624 0.00883691 0.00806824 0.02347907 0.02192307 0.02352624
  0.02777728 0.02655566 0.02695623 0.02584564 0.01461563 0.02739717
  0.0321921  0.02606101]
 [0.03048117 0.02164209 0.02437693 0.02254438 0.01772958 0.02590382
  0.02177596 0.02896502 0.02509676 0.02626162 0.02699718 0.0355514
  0.03043807 0.01372871 0.00959698 0.01909532 0.02114339 0.02344767
  0.02272739 0.02188804 0.02184031 0.02715865 0.01446118 0.01547132
  0.02154341 0.0220779 ]
 [0.03056927 0.02574375 0.02676879 0.02617815 0.0190483  0.02885308
  0.02656031 0.03600294 0.02586067 0.03038797 0.03475801 0.04074974
  0.03733945 0.01486379 0.01030523 0.02157395 0.02160892 0.02584781
  0.02295365 0.02242006 0.02231098 0.0279745  0.01560221 0.01419127
  0.01652661 0.01698469]
 [0.03043635 0.02392895 0.0238324  0.02370256 0.01871919 0.02617562
  0.02423496 0.03128894 0.02593278 0.02852383 0.0321456  0.03613017
  0.03567762 0.01401424 0.01051107 0.02502486 0.02370893 0.02870553
  0.02522682 0.02451643 0.02425726 0.02816085 0.01372699 0.01722827
  0.01804383 0.01548758]
 [0.03033471 0.01863716 0.01745784 0.01452421 0.01115198 0.01626924
  0.01851096 0.02248288 0.02060279 0.01730155 0.0234398  0.02231322
  0.02497518 0.00809334 0.00736842 0.02786905 0.02694556 0.02870965
  0.02716639 0.02567295 0.03002876 0.02666686 0.01215227 0.02770403
  0.02771863 0.01738961]
 [0.03042235 0.01818934 0.01616853 0.01400024 0.01006181 0.01433993
  0.01826416 0.02008363 0.01924592 0.01539302 0.02202067 0.01920233
  0.02275446 0.00722672 0.00671607 0.02887735 0.02749247 0.03151798
  0.02940682 0.02899078 0.03536248 0.02250895 0.01136435 0.03013783
  0.03073768 0.01861333]
 [0.03055659 0.01858439 0.01645355 0.01460859 0.0114171  0.01544279
  0.01753523 0.02069032 0.02006592 0.01747076 0.02398476 0.02178915
  0.02311223 0.00819813 0.00731496 0.02621894 0.02922328 0.02866587
  0.03042402 0.0268279  0.03006009 0.02398717 0.01139681 0.02128996
  0.02096228 0.01610185]
 [0.03057568 0.02105237 0.0185874  0.01559938 0.01167421 0.01684232
  0.02094126 0.02335626 0.02406308 0.01834735 0.02831293 0.02273671
  0.02551289 0.00857315 0.00748354 0.02784712 0.02797357 0.03036898
  0.03104936 0.02930978 0.03286332 0.02460694 0.01189542 0.0232247
  0.02180931 0.01671543]
 [0.03062774 0.01574204 0.01417419 0.01039641 0.00882422 0.01198956
  0.01671775 0.017265   0.0189254  0.01279516 0.03248156 0.0165267
  0.02020666 0.00627886 0.00540559 0.0264975  0.03326593 0.02826816
  0.03518989 0.03034628 0.0329021  0.022306   0.01091164 0.03110216
  0.02289276 0.01693304]
 [0.0289509  0.02458641 0.02178855 0.01366136 0.01270725 0.01682574
  0.02688336 0.02648739 0.03017434 0.01743193 0.03337146 0.02250496
  0.02804799 0.00790376 0.0080048  0.0291139  0.04694006 0.04701844
  0.0701694  0.06107443 0.05419883 0.02745956 0.02578077 0.045253
  0.041198   0.05148296]
 [0.03063721 0.01962264 0.01926243 0.01656702 0.01298036 0.0187228
  0.01781565 0.02249713 0.02447575 0.01930577 0.02333531 0.02379779
  0.02280526 0.01044945 0.00840495 0.01812603 0.02347078 0.02120243
  0.02856245 0.02596181 0.02711012 0.02455344 0.01300007 0.01767636
  0.01920096 0.02082388]
 [0.02943023 0.02528666 0.02545998 0.04114196 0.04325036 0.03541311
  0.01977366 0.02212457 0.02816975 0.04128293 0.02935003 0.02987016
  0.02724353 0.07284709 0.08801512 0.02138216 0.02658174 0.02401039
  0.023941   0.02334329 0.02177236 0.0307191  0.02935605 0.00941478
  0.01036133 0.02784184]
 [0.02922489 0.02683049 0.02549823 0.04616119 0.08927643 0.03598803
  0.01872824 0.02102521 0.027502   0.0485356  0.03481644 0.03051187
  0.02319797 0.07299957 0.09237375 0.02634864 0.03661235 0.03255586
  0.02831789 0.02555501 0.02532053 0.02816521 0.02915516 0.00793201
  0.00758991 0.02422577]
 [0.02894546 0.02482601 0.02314387 0.03829482 0.08676925 0.02505065
  0.01587649 0.02053355 0.02397894 0.04352433 0.03496251 0.03300105
  0.02326148 0.03320405 0.0441808  0.02397064 0.05934414 0.04995585
  0.0395379  0.03096402 0.03923797 0.02556738 0.02648139 0.01362132
  0.01423541 0.02833491]
 [0.0291856  0.03016344 0.02723532 0.03909371 0.05254653 0.02895627
  0.02104129 0.02288801 0.02968822 0.03847146 0.03254111 0.02769037
  0.02531178 0.03289378 0.03646125 0.02042395 0.03948128 0.03297715
  0.03071575 0.02974828 0.02970143 0.04463816 0.03866612 0.01101969
  0.01158157 0.02787489]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', "'s", ' current', ' location', ' in', ' the', ' provided', ' context', ' sentences', '.', ' However', ',', ' we', ' can', ' look', ' back', ' at', ' the', ' previous', ' context', ' sentences', '.', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Bill', ' went', ' to', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' information', ' about', ' him', ' moving', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(59, 32), x_tokens=32, y_tokens=59, max_supp_attn=0.0508, attn_on_target=0.0169)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (59, 32)
DEBUG result.interpretability.attn_scores 1888 
 [[0.0155653  0.02043356 0.02175257 ... 0.02321239 0.00649786 0.00703469]
 [0.01603462 0.01984272 0.01891287 ... 0.03111556 0.00996671 0.0123667 ]
 [0.0163903  0.01818665 0.01988833 ... 0.03490827 0.01256969 0.01282689]
 ...
 [0.01645243 0.0202497  0.0163553  ... 0.00990167 0.00435997 0.00537751]
 [0.01685193 0.01642327 0.01237604 ... 0.00762017 0.00738494 0.00932419]
 [0.01684463 0.01707366 0.01281982 ... 0.00661616 0.00609473 0.00802353]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '7', ',', ' Bill', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' kitchen', ',', ' but', ' we', ' don', "'t", ' have', ' specific', ' information', ' about', ' his', ' exact', ' location', '.', ' Therefore', ',', ' we', ' can', "'t", ' be', ' certain', ' about', ' his', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 38), x_tokens=38, y_tokens=47, max_supp_attn=0.0, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 38)
DEBUG result.interpretability.attn_scores 1786 
 [[0.01963086 0.0262644  0.03096106 ... 0.0159839  0.01241534 0.02795416]
 [0.01980388 0.01995428 0.02582054 ... 0.01910701 0.01743316 0.0329357 ]
 [0.02049795 0.02680075 0.03434481 ... 0.01474641 0.01289511 0.02666872]
 ...
 [0.02054764 0.0284978  0.02753296 ... 0.01471656 0.01091502 0.02978579]
 [0.02097182 0.02192367 0.02002447 ... 0.02187295 0.01841543 0.02431774]
 [0.02109751 0.02171793 0.02010884 ... 0.01910887 0.01308295 0.02298853]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' we', ' don', "'t", ' have', ' specific', ' information', ' about', ' her', ' exact', ' location', '.', ' Therefore', ',', ' we', ' can', "'t", ' be', ' certain', ' about', ' her', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 44), x_tokens=44, y_tokens=47, max_supp_attn=0.0638, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 44)
DEBUG result.interpretability.attn_scores 2068 
 [[0.01976127 0.02735321 0.02643103 ... 0.01350762 0.02270064 0.0207052 ]
 [0.02002841 0.02456947 0.02519559 ... 0.01965261 0.02454829 0.03731138]
 [0.02056486 0.02788515 0.0299103  ... 0.01778993 0.03879882 0.02822848]
 ...
 [0.02080309 0.0276645  0.02760942 ... 0.00847047 0.01379123 0.01036169]
 [0.02120644 0.01981182 0.01857007 ... 0.00988785 0.0109406  0.00869299]
 [0.02109921 0.02325512 0.02136932 ... 0.00891457 0.01201144 0.00964552]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' new', ' information', ' about', ' Julie', "'s", ' location', ' in', ' the', ' provided', ' context', ' sentences', '.', ' We', ' can', ' look', ' back', ' at', ' the', ' previous', ' context', ' sentences', '.', ' According', ' to', ' context', ' sentence', ' ', '11', ',', ' Julie', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' bedroom', ',', ' but', ' we', ' don', "'t", ' have', ' specific', ' information', ' about', ' her', ' exact', ' location', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(61, 50), x_tokens=50, y_tokens=61, max_supp_attn=0.1148, attn_on_target=0.0164)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (61, 50)
DEBUG result.interpretability.attn_scores 3050 
 [[0.01516487 0.02076444 0.02070758 ... 0.03145271 0.01859906 0.01207065]
 [0.01544824 0.02122108 0.02014397 ... 0.0120142  0.0187357  0.01599626]
 [0.01585043 0.02039186 0.02270226 ... 0.02701427 0.01354518 0.01034627]
 ...
 [0.01621698 0.01934683 0.01728592 ... 0.04321882 0.01328262 0.00908231]
 [0.01650229 0.0159391  0.01277503 ... 0.02511782 0.01084633 0.01154007]
 [0.01643104 0.01795307 0.01403775 ... 0.03501426 0.01303434 0.00971264]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' "', 'Bill', ' is', ' in', ' the', ' kitchen', '",', ' which', ' explicitly', ' states', ' Bill', "'s", ' location', ' as', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02643112 0.04101218 0.04988743 0.06933069 0.07839306 0.06914974
  0.050605   0.05579665 0.05032188 0.06015819 0.03828484 0.05155108
  0.05856621 0.09553508 0.06367071 0.02834718 0.02859607 0.03124296
  0.02847771 0.03122973 0.0247623  0.03650071 0.03906379 0.01901734
  0.01377961 0.02424109]
 [0.0267883  0.05066644 0.04656195 0.06493015 0.05735528 0.05328496
  0.04075094 0.03823913 0.03929569 0.04422697 0.03076592 0.02756945
  0.03049236 0.0980725  0.10027781 0.02987003 0.02446701 0.02290386
  0.0236201  0.02450173 0.02078113 0.03817113 0.04124947 0.01488386
  0.00902851 0.02055645]
 [0.02892194 0.05303709 0.03184721 0.04549465 0.03337123 0.03111279
  0.02775517 0.01915477 0.02025301 0.02931706 0.02218741 0.01428703
  0.01630587 0.02328258 0.03118051 0.02078781 0.01300865 0.01349319
  0.01731724 0.01801858 0.01609766 0.04061829 0.04742461 0.00880782
  0.00534718 0.01086129]
 [0.0270143  0.03536437 0.03467207 0.02227439 0.01596784 0.02571378
  0.02908356 0.0242374  0.03106135 0.02327197 0.02232797 0.02382508
  0.02354974 0.01147013 0.01130707 0.03623601 0.03045493 0.0309038
  0.03253102 0.03318316 0.0303237  0.03302488 0.05216083 0.05350098
  0.06675632 0.05921802]
 [0.02736981 0.03854695 0.04160648 0.06025284 0.05526759 0.04347131
  0.03112174 0.02632455 0.03164366 0.04059598 0.02794875 0.02253156
  0.02341397 0.08686401 0.09027015 0.03376346 0.02552922 0.02128614
  0.02245139 0.02465581 0.02281453 0.03741897 0.05924866 0.01650904
  0.00855948 0.02561178]
 [0.02789514 0.02460605 0.02547306 0.04667033 0.04136733 0.03932706
  0.02321736 0.02041727 0.02679692 0.03817269 0.02459645 0.02556132
  0.02524694 0.09929423 0.12157784 0.03400259 0.02928285 0.02580746
  0.02534622 0.02631362 0.02190207 0.03156674 0.03511069 0.01150952
  0.00681013 0.01642355]
 [0.02830171 0.02764993 0.03280282 0.04854684 0.04505254 0.04983171
  0.03062416 0.02819736 0.03501243 0.04488333 0.02867388 0.04042399
  0.03818705 0.07877357 0.07480465 0.02850078 0.02640758 0.0253467
  0.02421686 0.02586095 0.02052864 0.02842049 0.03275566 0.01548523
  0.00960049 0.01663194]
 [0.02733898 0.03952352 0.04676883 0.04044534 0.04179503 0.04768536
  0.03705115 0.03864737 0.0401631  0.04195859 0.03045376 0.04572443
  0.04079438 0.04960466 0.04490823 0.03732286 0.03329058 0.03162523
  0.02861517 0.03116762 0.02680112 0.03309237 0.04906927 0.03204773
  0.02442468 0.03338977]
 [0.02843733 0.03756759 0.04581837 0.04446372 0.04007469 0.05372148
  0.04092252 0.0430319  0.04691007 0.04644022 0.03045861 0.04682022
  0.04440517 0.03733259 0.02453191 0.0267436  0.02591517 0.02681274
  0.02587128 0.02873346 0.02252685 0.03232907 0.03442419 0.01971671
  0.01497888 0.02368142]
 [0.02776113 0.05098728 0.05289856 0.02831148 0.02296879 0.03660193
  0.04241616 0.04015379 0.04421774 0.02971219 0.02523337 0.03553934
  0.03655773 0.01699662 0.01441057 0.04256834 0.03310457 0.02992252
  0.02975801 0.03249519 0.03027768 0.03198443 0.06173099 0.04205865
  0.03609323 0.03730407]
 [0.02824476 0.06367421 0.06163007 0.02631308 0.02139561 0.03079821
  0.0431115  0.0366878  0.04570108 0.02559811 0.02227175 0.02788528
  0.0288832  0.01423099 0.01367289 0.04814455 0.03384707 0.02944102
  0.03093805 0.03626289 0.03070074 0.02929256 0.06640469 0.03970961
  0.02814735 0.0286164 ]
 [0.02842925 0.03312751 0.03658623 0.02012618 0.01755266 0.02294005
  0.03288268 0.02782382 0.03440592 0.02105346 0.01838529 0.0226914
  0.02209227 0.0122726  0.01222857 0.03918455 0.02953974 0.02515557
  0.02770791 0.02984961 0.02776469 0.02795858 0.04870897 0.04681466
  0.04542129 0.04085432]
 [0.02864312 0.01324456 0.01450713 0.01077408 0.00984346 0.01302831
  0.01459054 0.01420176 0.01788344 0.01254439 0.01168554 0.01357463
  0.01315013 0.00624669 0.00668024 0.0182482  0.01765643 0.01750048
  0.02165841 0.02305234 0.02468581 0.01951636 0.02661461 0.05194188
  0.0680005  0.06147797]
 [0.02852326 0.01976036 0.02047783 0.01462741 0.01380287 0.01840965
  0.02185556 0.02020702 0.02066857 0.01644055 0.01813324 0.01974457
  0.01944569 0.00840411 0.00910048 0.03189443 0.02538375 0.02506407
  0.02747072 0.02837096 0.02884773 0.02625998 0.02489494 0.04787485
  0.06688885 0.04665688]
 [0.02875366 0.02192435 0.02314735 0.01901017 0.0170805  0.02409496
  0.02695508 0.0284321  0.02440044 0.02307112 0.02314909 0.02984727
  0.02971589 0.01134382 0.00995909 0.03116261 0.02882014 0.02927388
  0.02830844 0.02799891 0.0291811  0.02783605 0.02045709 0.04174461
  0.04096261 0.02568961]
 [0.02912451 0.02065146 0.01972248 0.01511368 0.01565024 0.01764266
  0.02719709 0.02300961 0.02059595 0.01712973 0.02827932 0.02335436
  0.02328455 0.00840941 0.0095449  0.03123245 0.02714296 0.02594166
  0.02599419 0.02895681 0.02985563 0.02528553 0.0209839  0.04620587
  0.05798684 0.02467743]
 [0.02846094 0.01597039 0.01366784 0.01168568 0.01028281 0.01350106
  0.02349911 0.02319842 0.01707789 0.01338716 0.02028053 0.0164171
  0.02160644 0.00577009 0.00615621 0.03787376 0.0298251  0.03524375
  0.03306362 0.03711748 0.04880033 0.02009391 0.01479966 0.05913083
  0.0942575  0.03924463]
 [0.02907328 0.01595568 0.01509095 0.0116971  0.01210266 0.01479735
  0.02089562 0.0190272  0.01690306 0.01410128 0.02089321 0.019532
  0.01997607 0.00618353 0.00645652 0.02375128 0.03029647 0.02713522
  0.03405498 0.03075556 0.04028021 0.01952438 0.01379889 0.04815549
  0.07011648 0.03436494]
 [0.02899363 0.01411604 0.01221234 0.0094689  0.00907911 0.01170463
  0.01832103 0.01715846 0.0154399  0.01159791 0.025467   0.01660769
  0.01859709 0.00510562 0.00538205 0.02707105 0.03466384 0.03297414
  0.03644308 0.0324707  0.03865497 0.02086738 0.01215138 0.04355391
  0.04266898 0.05270695]
 [0.02847119 0.01805733 0.01629024 0.01158157 0.01040667 0.01457821
  0.01897755 0.01851995 0.02107067 0.0131338  0.01865189 0.01587881
  0.01785987 0.00613789 0.00609494 0.02513319 0.02212192 0.02526618
  0.02987284 0.03043905 0.03951159 0.02351961 0.01877208 0.06090598
  0.06195046 0.06095572]
 [0.02957667 0.01675571 0.01536408 0.01287786 0.01133406 0.0154212
  0.01801219 0.01820459 0.01722986 0.01408815 0.01924712 0.01752003
  0.01835206 0.00700616 0.00681266 0.01895522 0.02176321 0.02630603
  0.02646534 0.025296   0.02586091 0.02170848 0.0127123  0.02384091
  0.02546076 0.03398431]
 [0.02921116 0.02477768 0.02776048 0.02953159 0.02217691 0.02917674
  0.02702371 0.03303709 0.02907773 0.03407831 0.02732055 0.03875806
  0.03178541 0.01692391 0.0127387  0.02012381 0.02290248 0.02530929
  0.02628314 0.0252536  0.02380551 0.03016692 0.01784063 0.01717018
  0.01798693 0.01915897]
 [0.02949289 0.027989   0.03153285 0.03137129 0.02233465 0.03382996
  0.03039388 0.04000274 0.03267648 0.03826458 0.02781981 0.04704927
  0.03872697 0.01727897 0.01167732 0.01992618 0.02226583 0.02518404
  0.02366108 0.02248381 0.02028394 0.0279802  0.01769913 0.01388158
  0.01256007 0.01512389]
 [0.02938795 0.03164025 0.03589492 0.03293674 0.02264907 0.03811913
  0.03482062 0.04387696 0.03558398 0.04090578 0.03133013 0.05737717
  0.04557943 0.01733629 0.01208406 0.02315636 0.02435683 0.02858702
  0.0260012  0.02578033 0.02179106 0.02864456 0.01819582 0.0144269
  0.0116368  0.01344913]
 [0.02968949 0.02422285 0.02512556 0.02093493 0.01576987 0.02269351
  0.02934815 0.03173479 0.02603978 0.02438253 0.02628229 0.02924252
  0.03050084 0.01089376 0.00924016 0.0257605  0.0224961  0.02464683
  0.02498828 0.02509475 0.02432029 0.02761083 0.01400802 0.01852214
  0.01430367 0.01158809]
 [0.02936094 0.02167075 0.01935511 0.01550091 0.01162837 0.01624916
  0.03071988 0.03085502 0.02329366 0.01783073 0.02703166 0.02156374
  0.02896488 0.00766798 0.00736572 0.03027238 0.02519217 0.02794693
  0.02791276 0.0276179  0.03337347 0.02722819 0.0128629  0.02961924
  0.02533043 0.01726604]
 [0.0290379  0.02971655 0.02697052 0.01933647 0.01454817 0.02006382
  0.0389313  0.04358303 0.02900646 0.02447967 0.05075174 0.02991043
  0.04090257 0.00991722 0.00916195 0.03415366 0.03234258 0.03729253
  0.03463448 0.03435366 0.03609562 0.02828781 0.01547537 0.02805346
  0.02128794 0.01945752]
 [0.02959889 0.02219616 0.02265777 0.01729109 0.01330212 0.0187578
  0.02943213 0.0322951  0.02819419 0.02109153 0.04346937 0.02816651
  0.0325046  0.0093297  0.00777165 0.02676207 0.03044657 0.02956465
  0.03212132 0.02973495 0.03067231 0.02453468 0.01329139 0.01992311
  0.01633423 0.01807407]
 [0.02992127 0.01808115 0.0165862  0.01252617 0.01135947 0.0151782
  0.02114667 0.0220135  0.02156959 0.01607824 0.03830907 0.02217453
  0.02256536 0.00775025 0.00648574 0.02201688 0.02651467 0.02402748
  0.02826963 0.02656803 0.0279857  0.02550519 0.01121369 0.01964915
  0.01375223 0.02476334]
 [0.0288388  0.02387818 0.02087539 0.01409924 0.01394791 0.01742793
  0.03539677 0.03102445 0.0259564  0.01790424 0.08004703 0.03041521
  0.03169419 0.00842746 0.00826001 0.03170541 0.04184272 0.04154789
  0.03989477 0.03551282 0.03971635 0.02702263 0.01601753 0.0292896
  0.01698479 0.04523941]
 [0.02958933 0.01988856 0.01986088 0.01849343 0.01414376 0.01900699
  0.02181222 0.02580506 0.02450803 0.02086574 0.02536618 0.02687572
  0.02615176 0.0131016  0.01040372 0.01840484 0.02288762 0.0243764
  0.02669445 0.02449934 0.02456871 0.02461347 0.01233154 0.01524209
  0.01540219 0.02327996]
 [0.02854164 0.02546212 0.02482003 0.0396607  0.03987885 0.03663551
  0.02240281 0.02313004 0.02881818 0.04123003 0.02669042 0.02830987
  0.0286562  0.06778374 0.0782524  0.02302478 0.02509344 0.02449352
  0.0249651  0.02515865 0.02212071 0.03020787 0.02886451 0.01140372
  0.00839684 0.01804813]
 [0.02835586 0.02602606 0.02451892 0.04218727 0.08119217 0.03350832
  0.02007837 0.02053872 0.0268803  0.04458009 0.02951438 0.02702512
  0.02302573 0.06440458 0.08335409 0.02824343 0.03651064 0.03626285
  0.03065449 0.02865522 0.02598275 0.02726243 0.02841953 0.00964231
  0.00631673 0.01624749]
 [0.02805246 0.02357274 0.02171541 0.03564106 0.08335821 0.02403752
  0.01674251 0.01961507 0.0232829  0.04044633 0.029907   0.03016859
  0.02294193 0.03052121 0.04133128 0.02419159 0.05696434 0.05476577
  0.04049477 0.03205386 0.03905028 0.02426981 0.02556439 0.01654431
  0.01255569 0.02223121]
 [0.02836739 0.02867904 0.02529268 0.03649298 0.05356632 0.028499
  0.02190523 0.02181754 0.02805971 0.03697943 0.02878537 0.02607654
  0.02551743 0.03032643 0.03284513 0.02146422 0.03906681 0.03734824
  0.03324205 0.03050295 0.02927384 0.04167546 0.03567899 0.01321674
  0.00991126 0.01892421]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '5', ',', ' "', 'Jul', 'ie', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' school', '",', ' which', ' provides', ' two', ' possible', ' locations', ' for', ' Julie', ',', ' but', ' it', ' does', ' not', ' specify', ' her', ' exact', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Julie', ' might', ' be', ' in', ' the', ' school', ',', ' but', ' we', ' are', ' not', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(63, 32), x_tokens=32, y_tokens=63, max_supp_attn=0.1429, attn_on_target=0.0159)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (63, 32)
DEBUG result.interpretability.attn_scores 2016 
 [[0.01447603 0.02382492 0.02620371 ... 0.00842877 0.00599915 0.03486306]
 [0.01495357 0.02201398 0.02329884 ... 0.01173549 0.0098705  0.04340602]
 [0.01518676 0.02162587 0.02508041 ... 0.0203614  0.01408425 0.03410017]
 ...
 [0.0152472  0.02205113 0.02093759 ... 0.00576582 0.0042546  0.05138073]
 [0.01551196 0.01775612 0.01596275 ... 0.00614449 0.00503787 0.02733483]
 [0.01556481 0.01844745 0.0167234  ... 0.00520956 0.00475566 0.02526676]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' "', 'Jul', 'ie', ' went', ' back', ' to', ' the', ' park', '",', ' which', ' explicitly', ' states', ' that', ' Julie', ' returned', ' to', ' the', ' park', ',', ' implying', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(42, 38), x_tokens=38, y_tokens=42, max_supp_attn=0.0, attn_on_target=0.0238)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (42, 38)
DEBUG result.interpretability.attn_scores 1596 
 [[0.02208138 0.03136937 0.03197925 ... 0.01444089 0.01658554 0.02056647]
 [0.02253005 0.02729088 0.02840555 ... 0.01963181 0.01833219 0.0320967 ]
 [0.02312242 0.03419373 0.0378933  ... 0.01056286 0.01266584 0.01372271]
 ...
 [0.02323605 0.03164284 0.03041765 ... 0.01124919 0.01331482 0.01277914]
 [0.02336916 0.02534573 0.02284998 ... 0.01818974 0.01651994 0.01611018]
 [0.0234372  0.02891404 0.0252535  ... 0.01517291 0.01463038 0.01802586]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Julie', ' is', ' in', ' the', ' school', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '10', ' states', ' that', ' Julie', ' went', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' kitchen', ',', ' not', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 44), x_tokens=44, y_tokens=53, max_supp_attn=0.0189, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 44)
DEBUG result.interpretability.attn_scores 2332 
 [[0.01734969 0.02296608 0.02041424 ... 0.02485137 0.01045733 0.01166506]
 [0.01780593 0.01676287 0.01682513 ... 0.03978122 0.01810748 0.014689  ]
 [0.01814265 0.02352149 0.02325364 ... 0.04426692 0.01673128 0.01664502]
 ...
 [0.01828416 0.02219363 0.0215689  ... 0.0098521  0.00857903 0.00913289]
 [0.01857937 0.01716043 0.01694839 ... 0.0076014  0.01095715 0.01195147]
 [0.01860842 0.01675991 0.01685571 ... 0.00645822 0.00841471 0.00987778]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' in', ' the', ' context', ' sentences', ' that', ' suggests', ' Bill', ' is', ' in', ' the', ' bedroom', '.', ' In', ' fact', ',', ' context', ' sentence', ' ', '13', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' kitchen', ' or', ' the', ' office', ',', ' which', ' implies', ' that', ' he', ' is', ' not', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 50), x_tokens=50, y_tokens=52, max_supp_attn=0.0, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 50)
DEBUG result.interpretability.attn_scores 2600 
 [[0.01776486 0.02871072 0.02958533 ... 0.01180797 0.02975238 0.04913451]
 [0.01821605 0.02118295 0.02318116 ... 0.01138559 0.0175497  0.02473471]
 [0.0185676  0.02922465 0.03147623 ... 0.01495577 0.03325272 0.04361521]
 ...
 [0.01870305 0.03111651 0.02598239 ... 0.01329236 0.02820618 0.11542641]
 [0.01904851 0.02324727 0.01936422 ... 0.01689796 0.02734752 0.08275938]
 [0.01899868 0.02491149 0.01934186 ... 0.01175109 0.02123679 0.08738112]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '2', ',', ' Bill', ' journey', 'ed', ' to', ' the', ' cinema', ',', ' which', ' implies', ' that', ' Bill', ' is', ' now', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.1471, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02733391 0.042613   0.05125423 0.07074751 0.0776657  0.07527932
  0.05685757 0.06407051 0.04998604 0.06305529 0.04549075 0.05839575
  0.06241973 0.09450973 0.06839205 0.02345532 0.03189027 0.0330795
  0.02956862 0.03366635 0.02661439 0.037566   0.04636593 0.01926312
  0.01190338 0.02257991]
 [0.02766697 0.05522288 0.05153666 0.07117403 0.06311072 0.06160549
  0.04636567 0.04387249 0.04104838 0.0501491  0.0373788  0.03341247
  0.03416849 0.10838738 0.10344425 0.02467065 0.02737968 0.02378765
  0.02348536 0.02578754 0.02176271 0.03840285 0.0488501  0.01045312
  0.00831628 0.02076913]
 [0.02985194 0.06011273 0.03545904 0.05131465 0.03327983 0.03574041
  0.03302464 0.02376026 0.02181772 0.03299674 0.02534549 0.01737841
  0.01796146 0.02600217 0.03345629 0.01646787 0.01475545 0.01385273
  0.01743241 0.01883827 0.01632669 0.04319267 0.05671266 0.00587838
  0.00491717 0.01119355]
 [0.02852502 0.02387502 0.02243346 0.02395537 0.01898432 0.02425482
  0.02676496 0.02283869 0.02335629 0.02566802 0.02533302 0.02492967
  0.02257083 0.01370987 0.01728529 0.01749816 0.02657273 0.0259956
  0.02984806 0.02961276 0.03168282 0.02748032 0.03472527 0.06828436
  0.02882347 0.04722453]
 [0.02826237 0.04468942 0.04779885 0.06562513 0.05988179 0.04775845
  0.03672482 0.03168344 0.03401866 0.04563317 0.03324429 0.02707572
  0.02665823 0.09129281 0.09557924 0.02863019 0.02896875 0.02144223
  0.02270159 0.02497694 0.02352217 0.03881009 0.06844305 0.00915996
  0.00743008 0.02673078]
 [0.02884595 0.02860287 0.02825675 0.04886009 0.04594619 0.04091956
  0.02656348 0.02459373 0.0288518  0.04165677 0.02993121 0.03053254
  0.02859058 0.10577281 0.12486021 0.02860247 0.03279069 0.02586105
  0.02561232 0.02601413 0.02277697 0.03293419 0.03887752 0.00773024
  0.00599571 0.01732988]
 [0.02925331 0.03228566 0.03637092 0.05238783 0.05014538 0.05205974
  0.03525041 0.03370857 0.037026   0.04926837 0.03510027 0.04796264
  0.0422667  0.08311079 0.07835587 0.02434398 0.02989841 0.02520585
  0.02417652 0.02512145 0.02156315 0.02981155 0.03568624 0.01062154
  0.00821372 0.0169347 ]
 [0.02809608 0.04265559 0.04732179 0.0411428  0.04471532 0.04673212
  0.04091193 0.04278284 0.04091313 0.04249375 0.035812   0.05069527
  0.04363466 0.04924234 0.04542692 0.03571349 0.03737742 0.03127604
  0.02905052 0.03047986 0.02912407 0.03492426 0.05078135 0.02374341
  0.02945836 0.03607632]
 [0.02929519 0.04271872 0.04994977 0.04547131 0.0432464  0.05436081
  0.04580948 0.04933236 0.04963266 0.04804643 0.03629687 0.05233744
  0.04912891 0.03735711 0.02503678 0.02373256 0.02937188 0.02680582
  0.02644238 0.02846377 0.02427597 0.03572601 0.0395195  0.01855115
  0.01406306 0.02400601]
 [0.02851478 0.05387282 0.05547158 0.02813253 0.02419889 0.03570082
  0.04690401 0.04466307 0.04468976 0.02945487 0.02999478 0.03788676
  0.03973696 0.0160494  0.01421476 0.04079961 0.03611602 0.02958999
  0.0300068  0.03171984 0.03202318 0.0335046  0.06816658 0.03681806
  0.03742229 0.03877579]
 [0.02925167 0.04229279 0.04914224 0.02439565 0.02170556 0.02807312
  0.04855891 0.03706215 0.04232373 0.02495352 0.02529937 0.02794978
  0.02927987 0.01287814 0.01292211 0.03837067 0.03374074 0.02754208
  0.02958516 0.0324222  0.03035938 0.02873079 0.05784842 0.02776658
  0.0345722  0.0362825 ]
 [0.02957933 0.01660679 0.01917437 0.01187931 0.01065929 0.01627677
  0.01817457 0.01814158 0.02210566 0.01416313 0.01481291 0.0151432
  0.01589007 0.00627982 0.00672483 0.01964922 0.01954511 0.01759044
  0.02116107 0.0223584  0.02312413 0.0196202  0.03524098 0.03209272
  0.06029233 0.06409622]
 [0.0293096  0.02598491 0.02792297 0.01713515 0.01533458 0.02200125
  0.02806517 0.02494265 0.02508973 0.01836263 0.02318413 0.02197415
  0.02249778 0.00872827 0.00918399 0.03513129 0.02528924 0.02555184
  0.02598381 0.02799453 0.02757634 0.02804058 0.02874411 0.03662915
  0.05723755 0.05013686]
 [0.02943953 0.02509273 0.02526269 0.01845324 0.01584904 0.02499315
  0.02901383 0.02774677 0.0264916  0.02138832 0.0273124  0.02815779
  0.02825949 0.00975253 0.00875436 0.03934443 0.02733005 0.02865692
  0.02604775 0.02685862 0.0274359  0.02887813 0.02123909 0.03149036
  0.05781954 0.03355439]
 [0.02875518 0.02219487 0.01854574 0.01412886 0.01121211 0.01601747
  0.02435239 0.02219301 0.02148761 0.01536611 0.02379115 0.01934294
  0.02264506 0.00676665 0.00655656 0.05416608 0.02694901 0.03935694
  0.03326752 0.03744638 0.04296938 0.02700355 0.01576965 0.04335672
  0.10909759 0.04561897]
 [0.02992841 0.02330382 0.02289975 0.01779557 0.01607694 0.02403115
  0.02979353 0.02745813 0.02566996 0.02054258 0.02620056 0.02593551
  0.02648738 0.00913808 0.00781362 0.03661096 0.02173413 0.03385378
  0.02671962 0.0384229  0.0290997  0.02354355 0.01782584 0.0282139
  0.06984349 0.02621962]
 [0.02981268 0.01918749 0.01711373 0.01264842 0.01049457 0.01529795
  0.0214508  0.020227   0.0209321  0.01464432 0.0253567  0.02048768
  0.02173426 0.00634803 0.00598563 0.04575591 0.02408392 0.03942672
  0.03246998 0.04304564 0.03285974 0.0225449  0.01313595 0.03214886
  0.06961017 0.03574986]
 [0.0296079  0.01800781 0.01602626 0.01101113 0.00906514 0.01339375
  0.02020621 0.01882552 0.01998249 0.01314679 0.0255175  0.01811551
  0.0201495  0.00551299 0.00556885 0.04369727 0.02623486 0.0371306
  0.03577425 0.03873335 0.03371099 0.02326471 0.01295851 0.04502925
  0.05287137 0.04801537]
 [0.02906754 0.02507828 0.02350684 0.01544695 0.01462381 0.01860754
  0.0275688  0.02599521 0.02619494 0.01768604 0.02830333 0.02256009
  0.02477772 0.00781787 0.00819165 0.02939313 0.02899696 0.02791857
  0.03293407 0.0293154  0.03430571 0.02649011 0.02088686 0.07738751
  0.03189386 0.0524421 ]
 [0.03016625 0.02245576 0.02153234 0.01651051 0.01284124 0.01860952
  0.02419498 0.02406397 0.02434807 0.01792081 0.02640124 0.02257494
  0.02375381 0.00818698 0.00768137 0.02597302 0.02311008 0.02783918
  0.03179314 0.02721367 0.02910114 0.02736776 0.0150672  0.03320923
  0.02323693 0.03391712]
 [0.03031447 0.02246564 0.02499186 0.02216811 0.01666022 0.02525344
  0.02633891 0.03127539 0.02726234 0.02608797 0.02763398 0.03551331
  0.03210299 0.01253653 0.00856504 0.01902275 0.02194691 0.02484441
  0.02551256 0.02450473 0.02345446 0.02945457 0.01540613 0.02658993
  0.01772671 0.02260091]
 [0.03043756 0.02839751 0.03014677 0.02728774 0.01960709 0.03064934
  0.03380329 0.04121907 0.03049653 0.03199644 0.03583817 0.04487792
  0.04218893 0.01460982 0.00944934 0.02245963 0.02331267 0.02835397
  0.02604334 0.02649942 0.02365114 0.02957161 0.0164967  0.02385747
  0.01637886 0.01517069]
 [0.03038569 0.02572707 0.02611411 0.02420853 0.0185195  0.02726948
  0.02979878 0.03455479 0.02982322 0.02961381 0.0333652  0.03902374
  0.03919732 0.01311248 0.00921747 0.02707229 0.02479909 0.0297705
  0.0278848  0.02786132 0.02608307 0.02879637 0.01440263 0.02139054
  0.0189167  0.01378993]
 [0.0301714  0.01988723 0.01935244 0.0142981  0.01087929 0.01648263
  0.02102474 0.02388545 0.02318469 0.01785665 0.02367523 0.02346451
  0.02535036 0.00755383 0.00624951 0.0322779  0.0260214  0.02919303
  0.02901359 0.02767993 0.03150512 0.02644209 0.01289704 0.03137363
  0.03347068 0.02078345]
 [0.03010527 0.02089882 0.01977484 0.01499979 0.01071457 0.01591751
  0.02340373 0.02470965 0.02299128 0.01754314 0.02526447 0.02203488
  0.02517951 0.00734479 0.00619644 0.03763115 0.02710027 0.03369709
  0.03161512 0.03025208 0.03753981 0.0240847  0.01237634 0.03679979
  0.0355111  0.02112184]
 [0.03025393 0.01991994 0.01903026 0.01488422 0.01166791 0.0161293
  0.02090301 0.02388198 0.02263209 0.01831451 0.02525076 0.02365702
  0.02400478 0.00793999 0.00645252 0.03027771 0.02961356 0.03015117
  0.03427617 0.02872009 0.03458552 0.02405079 0.01215903 0.03593234
  0.02551673 0.02015583]
 [0.03039072 0.02256148 0.02173609 0.01584596 0.01178975 0.01802559
  0.02526327 0.02685997 0.02774077 0.01895027 0.02854888 0.0252643
  0.02659107 0.00856709 0.00689604 0.0333991  0.02792319 0.0321786
  0.0322418  0.03144865 0.03321944 0.02509885 0.01352938 0.03286706
  0.0264179  0.01930867]
 [0.03046273 0.01760545 0.01746573 0.0110015  0.00908093 0.01314335
  0.02107826 0.01991285 0.02140472 0.01386712 0.030269   0.01842754
  0.02127592 0.00648885 0.00506279 0.03508122 0.02989092 0.03036929
  0.03852072 0.03244183 0.03413159 0.02353288 0.0111522  0.03700251
  0.02489095 0.0263356 ]
 [0.0295249  0.02131106 0.02014009 0.01201827 0.00923437 0.01479814
  0.02120734 0.02191016 0.02410376 0.01551047 0.02587024 0.01782029
  0.02337559 0.00686841 0.00556906 0.02594293 0.02556626 0.02371202
  0.03321737 0.0284822  0.03593047 0.0252646  0.01696921 0.07641269
  0.02976367 0.05227076]
 [0.03047901 0.02126923 0.02167149 0.016699   0.01211016 0.01900045
  0.02033423 0.02446505 0.02546346 0.02012117 0.02372758 0.0214244
  0.02422629 0.00968102 0.00743454 0.0186574  0.02292925 0.02334222
  0.03011428 0.02503463 0.02834125 0.02504291 0.01435345 0.03109472
  0.01481245 0.02402654]
 [0.02943397 0.02721631 0.02826834 0.04134643 0.04208096 0.03693993
  0.02414041 0.02561731 0.03062596 0.04393296 0.03133596 0.03099186
  0.03219961 0.06660315 0.08108249 0.02018887 0.02996401 0.02695249
  0.02681553 0.02624904 0.02453822 0.03087251 0.03331571 0.01010873
  0.00718874 0.01958358]
 [0.02924316 0.02895579 0.02887543 0.04765207 0.08929977 0.03766341
  0.02253483 0.02445926 0.02987848 0.05149061 0.03730401 0.03220895
  0.02765151 0.06785735 0.0880215  0.02498528 0.04237069 0.03639058
  0.03223132 0.02861839 0.02948879 0.02851237 0.03229692 0.00734174
  0.00577562 0.01671229]
 [0.02895849 0.02582671 0.02558488 0.03957293 0.08826971 0.02669347
  0.01898156 0.02368027 0.02646978 0.04674721 0.03781506 0.03517738
  0.02644379 0.03281997 0.04118736 0.02249638 0.07078403 0.05399983
  0.04304142 0.03250011 0.04397468 0.02635396 0.02787551 0.01802141
  0.01156339 0.02092377]
 [0.02927502 0.0311037  0.02986765 0.03980132 0.05104907 0.03032075
  0.02463153 0.02560687 0.03195657 0.04137097 0.03399466 0.02726565
  0.02760084 0.03117301 0.03318125 0.01850116 0.04564232 0.03528117
  0.03541102 0.03121552 0.03334197 0.04508498 0.03992489 0.01337984
  0.00904788 0.01956258]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Julie', ' going', ' to', ' the', ' park', '.', ' According', ' to', ' sentence', ' ', '5', ',', ' Julie', ' went', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 32), x_tokens=32, y_tokens=30, max_supp_attn=0.1667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 32)
DEBUG result.interpretability.attn_scores 960 
 [[0.03122673 0.04779273 0.04778862 0.07597198 0.06766778 0.0506007
  0.03753569 0.03847489 0.04838873 0.05886646 0.03872336 0.03409387
  0.0374314  0.10771129 0.10974604 0.03405724 0.0277313  0.02420734
  0.02067232 0.02087644 0.02072854 0.03589572 0.05273438 0.0115137
  0.01943673 0.03826739 0.04611477 0.0536837  0.11892221 0.06424114
  0.01087087 0.01441908]
 [0.03199117 0.04782771 0.04600315 0.08642866 0.09205663 0.07740565
  0.04384814 0.04480593 0.05021593 0.07602537 0.05115202 0.0551431
  0.05638961 0.14168642 0.1172578  0.03459102 0.02703692 0.02769427
  0.02055481 0.02283726 0.02184485 0.03978496 0.04000638 0.01170328
  0.02094372 0.03304132 0.04545726 0.0445794  0.08960702 0.07299706
  0.01826706 0.02663529]
 [0.03266583 0.04387042 0.04805198 0.07332738 0.06857655 0.05945748
  0.03854954 0.04004553 0.04662367 0.05779428 0.03836138 0.04539987
  0.04162134 0.11425275 0.08671085 0.03208466 0.02556013 0.02150066
  0.01789644 0.01934354 0.01822903 0.03594889 0.0377099  0.0124414
  0.02094372 0.02989838 0.03846384 0.03679328 0.06211518 0.07215496
  0.02367244 0.03210664]
 [0.03171739 0.04424882 0.04950612 0.04094152 0.03621437 0.04213537
  0.04099492 0.04665967 0.04340034 0.0379235  0.03344474 0.04174075
  0.03841958 0.03029828 0.02952363 0.03246633 0.0310066  0.02543453
  0.022889   0.02428711 0.02384088 0.03740096 0.04657137 0.0284096
  0.03443369 0.04330716 0.04662283 0.04144713 0.04152488 0.08089993
  0.04804301 0.0538626 ]
 [0.03320357 0.04239975 0.04511254 0.03306083 0.02762813 0.0449801
  0.04293583 0.04847657 0.04632075 0.03541635 0.03578357 0.05211819
  0.04254606 0.0227457  0.0220283  0.03310225 0.03299836 0.02609082
  0.0256383  0.02676171 0.02632577 0.03352206 0.0434457  0.03244661
  0.03264319 0.03770712 0.03936043 0.03141411 0.02874438 0.03293084
  0.03541742 0.04665376]
 [0.03370017 0.0447083  0.04708208 0.03581166 0.03061189 0.05189747
  0.04517811 0.04928322 0.05433829 0.04233991 0.03398596 0.05719922
  0.04799312 0.0276048  0.02281692 0.03109013 0.03000602 0.02426769
  0.0233543  0.02330177 0.02287887 0.03365789 0.04199463 0.0286431
  0.02970078 0.03647856 0.04088464 0.03021733 0.03004318 0.03253515
  0.03299282 0.04348578]
 [0.03297939 0.06656481 0.0582126  0.04076448 0.03513845 0.05610781
  0.05646977 0.06644393 0.05905289 0.04895336 0.04443952 0.07364437
  0.06502938 0.03090326 0.02647246 0.03966251 0.03570942 0.03141174
  0.02998546 0.02912651 0.02814099 0.03785735 0.05118416 0.03746778
  0.03439515 0.04005352 0.04892409 0.03718668 0.03113039 0.03500772
  0.03918757 0.04893096]
 [0.03385912 0.0509821  0.05367742 0.03682524 0.02878091 0.06128595
  0.05456654 0.05816995 0.05442955 0.04160418 0.0359505  0.07445221
  0.06241388 0.0271336  0.02306688 0.03818308 0.03406928 0.02726636
  0.02529523 0.02594388 0.02563065 0.03500387 0.04410544 0.03399116
  0.032851   0.03848475 0.04390317 0.03479156 0.02800143 0.03270218
  0.0371859  0.04663999]
 [0.0332591  0.0332832  0.03546872 0.0228343  0.02162411 0.02833251
  0.04228231 0.04182946 0.03287599 0.02809148 0.04236779 0.03426677
  0.04590042 0.01598972 0.01813454 0.04115897 0.04715832 0.03647875
  0.03648375 0.03356756 0.03822673 0.03549201 0.02688543 0.04122599
  0.0338942  0.03232038 0.03123132 0.03507223 0.01936839 0.01647288
  0.03519292 0.03511629]
 [0.03328713 0.02881873 0.02624827 0.01918497 0.01800824 0.02149675
  0.03266458 0.03173082 0.02505651 0.02115374 0.03109888 0.02457644
  0.02835346 0.01278888 0.01505285 0.04329466 0.04475624 0.04528498
  0.0365924  0.0412574  0.051977   0.03289179 0.02328028 0.05206988
  0.05360893 0.03319522 0.02728631 0.03375089 0.01726881 0.01203179
  0.03969161 0.03581295]
 [0.03416013 0.02351479 0.02315874 0.01769559 0.01849432 0.02116396
  0.02627187 0.02572749 0.02347009 0.02174556 0.03189841 0.02693661
  0.02571681 0.01266596 0.01356775 0.03553503 0.03401889 0.03506397
  0.03448142 0.04682666 0.0469298  0.02798193 0.01841783 0.03563677
  0.03908953 0.02728872 0.02441721 0.02536165 0.01573562 0.01048184
  0.03615465 0.03471152]
 [0.03392507 0.02195032 0.02124442 0.01502443 0.01712253 0.01839446
  0.02636686 0.02229535 0.021439   0.01907829 0.03783949 0.02358751
  0.02288222 0.01102818 0.01288124 0.04048406 0.04453752 0.0372155
  0.04709774 0.053187   0.04885871 0.02874324 0.01880808 0.04440569
  0.03533375 0.02698766 0.02425284 0.02443293 0.01436505 0.00929626
  0.03181672 0.02523097]
 [0.03330689 0.02557849 0.0240536  0.01674619 0.01863842 0.01935715
  0.02944939 0.02398039 0.0238565  0.02024978 0.04112896 0.02445422
  0.02360748 0.01163557 0.01505696 0.04117545 0.04477618 0.03639339
  0.0513203  0.04475886 0.04518984 0.03246539 0.0260238  0.05464737
  0.03390521 0.03469514 0.0328153  0.02990671 0.01757191 0.01175242
  0.03037124 0.02190604]
 [0.03396672 0.03021944 0.02925993 0.01979135 0.01982001 0.02490635
  0.03215683 0.02863996 0.02953227 0.02347646 0.02925558 0.02821693
  0.02820085 0.01523772 0.01547004 0.0320259  0.03412853 0.02943475
  0.03984716 0.04781833 0.03921094 0.0330251  0.02997955 0.03229188
  0.02922047 0.03254449 0.03544531 0.02654975 0.02193129 0.02343873
  0.03187032 0.0361241 ]
 [0.03321172 0.03291593 0.03469988 0.0315471  0.02927083 0.03515935
  0.03508375 0.03495161 0.03892069 0.0384606  0.03211806 0.04661312
  0.04276364 0.02588387 0.02150667 0.03256682 0.03419941 0.03439355
  0.02915464 0.02667444 0.02692074 0.03713711 0.03651479 0.02962935
  0.03387493 0.03716979 0.03696952 0.03556418 0.03426411 0.05259212
  0.03472654 0.04027649]
 [0.03399871 0.03139757 0.03540076 0.03027902 0.02781065 0.03548577
  0.03456781 0.03568263 0.03705078 0.03362263 0.02796404 0.03091022
  0.03279724 0.02439674 0.0214122  0.02629047 0.02206    0.02041538
  0.02086304 0.02120442 0.0204584  0.03271463 0.02935856 0.01878756
  0.02213968 0.03114719 0.04049611 0.02751474 0.03513224 0.06660634
  0.03873712 0.04438344]
 [0.03306875 0.04259372 0.04280884 0.02416214 0.02007747 0.02689294
  0.03567503 0.03247155 0.03260802 0.0213625  0.02362903 0.02163126
  0.02631062 0.01745396 0.01827008 0.03491887 0.02670358 0.02116355
  0.02043317 0.0220497  0.02309975 0.03603307 0.05552296 0.03222776
  0.03700865 0.0396161  0.0440526  0.02942895 0.0307766  0.08406547
  0.04867451 0.03953577]
 [0.0332315  0.0335996  0.03325706 0.02076731 0.0171744  0.02181425
  0.03061557 0.02446903 0.02807012 0.01779533 0.02036592 0.01561496
  0.01960491 0.01406512 0.01596586 0.0312417  0.02376438 0.01937631
  0.02003459 0.02271198 0.02318582 0.0290333  0.04607746 0.03076755
  0.04082773 0.04005621 0.0350269  0.02559896 0.02667746 0.06502855
  0.03630238 0.02797353]
 [0.03366475 0.01817905 0.01859524 0.01410823 0.0125537  0.01504224
  0.01862125 0.01671278 0.01848558 0.01265738 0.01819402 0.01182021
  0.01548448 0.0094121  0.01150058 0.02292138 0.02069673 0.0204045
  0.02179424 0.02551385 0.02660079 0.02159857 0.02703955 0.03238876
  0.03666734 0.03124034 0.0201584  0.02388264 0.02093014 0.02782166
  0.02494413 0.01753887]
 [0.03379033 0.02419368 0.02551766 0.019393   0.01550672 0.02096377
  0.02519577 0.02212277 0.02186425 0.01741631 0.02207743 0.01691689
  0.01992675 0.01377348 0.01487799 0.0298051  0.02853254 0.02317317
  0.02286892 0.02668077 0.0269137  0.03238223 0.0265186  0.0252076
  0.03952029 0.03074487 0.02818291 0.02269454 0.02435948 0.03700408
  0.05289511 0.03626178]
 [0.03413459 0.02483441 0.02680898 0.0212409  0.01751447 0.02302304
  0.02831596 0.0264779  0.02357494 0.02044841 0.02665141 0.02176764
  0.02637257 0.0153498  0.01456466 0.03188586 0.03001764 0.02749798
  0.02314055 0.02581367 0.02793311 0.03415536 0.01982744 0.02651935
  0.03967168 0.02572265 0.02643455 0.02319595 0.02005419 0.02557924
  0.06406652 0.05601314]
 [0.03364533 0.022157   0.0209584  0.0186295  0.01251335 0.01846331
  0.02403122 0.02140338 0.01959433 0.01648398 0.02394884 0.0156552
  0.02157522 0.01243578 0.01266531 0.03478213 0.03442588 0.03687513
  0.0293495  0.04243065 0.04652107 0.03080265 0.01680903 0.03589257
  0.05148401 0.02295638 0.02347579 0.02223175 0.01640033 0.01265665
  0.05399299 0.04451699]
 [0.03446655 0.01939533 0.0197308  0.01773321 0.01241345 0.01834983
  0.023209   0.0215682  0.01918267 0.01656911 0.02512441 0.01619774
  0.02156767 0.01215016 0.0118497  0.03139162 0.02645495 0.02955545
  0.0252663  0.04270796 0.04398962 0.02631061 0.01465044 0.03149521
  0.04003226 0.0210501  0.02141363 0.01853421 0.01536585 0.01045972
  0.04478124 0.03769914]
 [0.03400588 0.01828239 0.01764658 0.01557327 0.01080148 0.0157818
  0.02250962 0.01986764 0.01797296 0.01473688 0.02784631 0.01463497
  0.02029694 0.01081728 0.01080292 0.0369936  0.03971621 0.03314841
  0.04090708 0.04906125 0.04004573 0.02895845 0.01528405 0.04461061
  0.03988362 0.02291588 0.01785714 0.02014804 0.01584244 0.00997778
  0.04003343 0.0264866 ]
 [0.03260757 0.02255448 0.02267308 0.02040216 0.0145211  0.01978558
  0.0250156  0.02429064 0.02414194 0.01921814 0.02221273 0.01689901
  0.02321916 0.01305401 0.01334889 0.02925209 0.03421602 0.0345795
  0.03811054 0.04381153 0.04486014 0.03148861 0.0391132  0.14609618
  0.0661892  0.06697502 0.0262104  0.05253029 0.03078681 0.01647835
  0.03694257 0.02040809]
 [0.03468903 0.02063864 0.02026885 0.01969398 0.01304747 0.01918374
  0.02525473 0.02461058 0.02143318 0.01884318 0.02900606 0.01929047
  0.02300461 0.01383133 0.01263186 0.02769138 0.03106031 0.02536711
  0.0343332  0.03383853 0.02994646 0.03093319 0.01594739 0.02794889
  0.02369484 0.02207615 0.01725941 0.02058244 0.0186632  0.01182649
  0.02867807 0.04353121]
 [0.03336444 0.03256138 0.03473103 0.05458944 0.0524435  0.0422106
  0.0337243  0.03484302 0.0371401  0.05726122 0.03993934 0.03927551
  0.03762934 0.07430135 0.09526881 0.02836026 0.02765876 0.03297007
  0.03068932 0.02400629 0.02661595 0.03559482 0.03253921 0.01204132
  0.0174398  0.02942451 0.03245667 0.04120982 0.05115328 0.0250558
  0.01263428 0.01946018]
 [0.0326084  0.04094657 0.03710128 0.0737545  0.13556229 0.0513428
  0.03483316 0.03507571 0.03806826 0.07453161 0.05364021 0.0443081
  0.03648402 0.0902043  0.11677313 0.0371847  0.04303083 0.06603149
  0.05455675 0.03591407 0.03987141 0.03577703 0.04606124 0.01168446
  0.01888898 0.03448318 0.04569636 0.04751693 0.05512384 0.02310418
  0.00950866 0.01259415]
 [0.03303824 0.03227679 0.02776755 0.04249287 0.06418641 0.0292085
  0.02608515 0.02965603 0.03061577 0.04516121 0.04376828 0.03844159
  0.03431879 0.0368988  0.04400615 0.03073922 0.04856147 0.08704823
  0.08641405 0.05350934 0.05021484 0.03234871 0.03735569 0.02047081
  0.02244658 0.03154815 0.03278542 0.04797814 0.03034526 0.01315673
  0.01191733 0.01693859]
 [0.03322588 0.03171396 0.02716579 0.04122479 0.04422038 0.02977082
  0.02799166 0.02923331 0.03227598 0.04271284 0.03808374 0.03419299
  0.03213845 0.03428968 0.036769   0.02506365 0.03540764 0.06025546
  0.06997552 0.04417751 0.04480979 0.04506049 0.04023351 0.0173378
  0.01983033 0.02860368 0.02634489 0.05620102 0.03779516 0.01164406
  0.01043056 0.01474606]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' about', ' Bill', ' going', ' to', ' the', ' park', '.', ' According', ' to', ' sentence', ' ', '4', ',', ' Bill', ' is', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 38), x_tokens=38, y_tokens=30, max_supp_attn=0.0667, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 38)
DEBUG result.interpretability.attn_scores 1140 
 [[0.0312871  0.04596297 0.04050868 ... 0.01822485 0.00855003 0.02285452]
 [0.03186264 0.03994921 0.03901597 ... 0.02469575 0.01746994 0.03141029]
 [0.03261959 0.04766231 0.04925455 ... 0.0141422  0.00595507 0.01352864]
 ...
 [0.03295565 0.03854349 0.0427784  ... 0.01243093 0.00564247 0.01357012]
 [0.03356463 0.02703898 0.02986751 ... 0.01365771 0.0114572  0.01899456]
 [0.03344927 0.03019359 0.03278501 ... 0.01163802 0.00706511 0.01650109]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '10', ',', ' Mary', ' is', ' in', ' the', ' park', ',', ' and', ' there', ' is', ' no', ' information', ' about', ' Mary', ' being', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 44), x_tokens=44, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 44)
DEBUG result.interpretability.attn_scores 1364 
 [[0.03015727 0.04207775 0.04494254 ... 0.03574228 0.01855239 0.04344227]
 [0.0307757  0.03064617 0.03326879 ... 0.03376327 0.03400704 0.0256523 ]
 [0.03131271 0.04534616 0.05199239 ... 0.05287169 0.03744243 0.04994181]
 ...
 [0.03146064 0.04840088 0.0420563  ... 0.01253464 0.01066241 0.05731642]
 [0.0321895  0.03756765 0.02980827 ... 0.01026739 0.0087966  0.02162036]
 [0.03202047 0.04116448 0.03164093 ... 0.00896963 0.00905819 0.02425136]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' sentence', ' ', '14', ',', ' Mary', ' went', ' back', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Mary', ' is', ' now', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(30, 50), x_tokens=50, y_tokens=30, max_supp_attn=0.0333, attn_on_target=0.0333)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (30, 50)
DEBUG result.interpretability.attn_scores 1500 
 [[0.03135446 0.0433181  0.04211432 ... 0.02301302 0.01845187 0.03376396]
 [0.03157079 0.04181418 0.04100493 ... 0.03313385 0.02817812 0.03083231]
 [0.03273365 0.04774115 0.04918162 ... 0.02100797 0.01428466 0.03538208]
 ...
 [0.03282324 0.04544772 0.04647495 ... 0.01792827 0.01546441 0.06279254]
 [0.03306581 0.03327524 0.03282014 ... 0.02441944 0.02264791 0.05639145]
 [0.03292961 0.04088588 0.03918496 ... 0.02219802 0.02148052 0.05108735]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '2', ',', ' Julie', ' journey', 'ed', ' to', ' the', ' park', ',', ' which', ' implies', ' that', ' she', ' is', ' currently', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02722978 0.04466347 0.05474291 0.07514081 0.08037978 0.07474874
  0.05967277 0.0678541  0.0543048  0.06516173 0.04688411 0.06013684
  0.06799041 0.10175262 0.06577506 0.02834484 0.02969989 0.03004535
  0.02788577 0.02894635 0.02421922 0.03911382 0.04006612 0.02347629
  0.01328945 0.02541034]
 [0.02954187 0.05816853 0.03682949 0.05729316 0.04238659 0.03805439
  0.0328839  0.02372512 0.02311851 0.03571554 0.02812761 0.01640372
  0.01923357 0.03417572 0.04347552 0.02182072 0.01351161 0.01195677
  0.01515737 0.01508435 0.0142624  0.04273975 0.05032723 0.01058745
  0.0049247  0.01336811]
 [0.02789062 0.03413754 0.03473848 0.02500751 0.01839157 0.02739335
  0.0305118  0.02513776 0.02908565 0.02505106 0.02521409 0.02423508
  0.02373091 0.0128568  0.01222088 0.02954687 0.02836496 0.0305096
  0.03601988 0.04404245 0.0365794  0.03332751 0.04995487 0.05330148
  0.06175114 0.05198784]
 [0.02816495 0.04139738 0.04555716 0.06827304 0.06121331 0.04898012
  0.03546962 0.03030043 0.03439472 0.04632588 0.03413907 0.02541143
  0.02592587 0.10551249 0.11120108 0.03354581 0.02568621 0.01872418
  0.01987789 0.02067919 0.02008694 0.0383889  0.05965508 0.01818729
  0.00662949 0.02812812]
 [0.02874012 0.02681909 0.0278888  0.05234608 0.04563278 0.04448222
  0.0264593  0.02352001 0.02901237 0.04302807 0.03043678 0.02872493
  0.027951   0.11381337 0.13768041 0.03315198 0.02872416 0.02248072
  0.02242794 0.02204252 0.01927263 0.03304562 0.03632241 0.01296015
  0.00578343 0.01827776]
 [0.029163   0.03052589 0.03658284 0.05546508 0.05051485 0.05642428
  0.03522142 0.03281282 0.03834742 0.05072979 0.03577012 0.04579294
  0.04255553 0.0910833  0.08486926 0.02803466 0.02623463 0.02246679
  0.02164313 0.02183251 0.01822666 0.02992976 0.03405389 0.01780881
  0.00843953 0.01747041]
 [0.02815293 0.04185711 0.04956381 0.04365024 0.04496027 0.05183255
  0.04149039 0.04388331 0.04201132 0.04520954 0.03710256 0.05115775
  0.04478052 0.05537281 0.04968589 0.0373847  0.03514712 0.03035845
  0.02746845 0.0280466  0.02556664 0.0342245  0.04756184 0.03670724
  0.03032231 0.03029683]
 [0.02933392 0.04043833 0.04952858 0.04923564 0.04380258 0.0595256
  0.04574939 0.04832981 0.04967391 0.05119067 0.03744281 0.05166616
  0.04879266 0.04261515 0.0280114  0.02689162 0.02652691 0.02437536
  0.02388625 0.02481619 0.02049308 0.03417524 0.03650622 0.02281858
  0.0128295  0.02300604]
 [0.02863772 0.05529672 0.05842042 0.0312227  0.02488743 0.04029741
  0.04914276 0.04574789 0.04688216 0.03236359 0.03058668 0.03891691
  0.04000938 0.01914158 0.01610879 0.0438815  0.03544502 0.02949507
  0.02952247 0.03095195 0.02891158 0.03368364 0.06517162 0.04593126
  0.03417824 0.03198251]
 [0.02911907 0.07061408 0.06780478 0.02898569 0.0231573  0.03409576
  0.04891694 0.04188197 0.04887648 0.0282962  0.02679517 0.03055765
  0.03157036 0.01594903 0.01523449 0.04811205 0.03538194 0.02775855
  0.02954575 0.03283224 0.02769319 0.03101867 0.06959245 0.04202437
  0.0240433  0.02617235]
 [0.02934286 0.03803462 0.04205504 0.02203671 0.01841019 0.02541009
  0.03847034 0.03220558 0.0375428  0.02269987 0.02214471 0.02471001
  0.02403936 0.01329215 0.01319828 0.04067287 0.03232415 0.02470483
  0.0273725  0.02856109 0.02656482 0.02940498 0.052055   0.04850425
  0.04068606 0.03743779]
 [0.02947674 0.01622846 0.0172367  0.01215396 0.01092999 0.01448731
  0.01764428 0.016801   0.01971899 0.01373112 0.01504351 0.01524442
  0.01506431 0.00693213 0.00767995 0.02040062 0.02176936 0.0211792
  0.0267507  0.02938399 0.03045459 0.02337219 0.03383332 0.05528626
  0.05988131 0.0563775 ]
 [0.02924575 0.02345938 0.02442913 0.01672772 0.0154828  0.02093885
  0.02623246 0.02376568 0.02434269 0.01860468 0.02236361 0.02233113
  0.02190217 0.0097395  0.01031663 0.03753145 0.03168008 0.0291043
  0.02903108 0.02984611 0.02766034 0.02831898 0.02773215 0.04758177
  0.06311834 0.04645764]
 [0.0294117  0.02299432 0.0241144  0.0190089  0.01677429 0.02362535
  0.02715506 0.02771504 0.02565595 0.02279351 0.02617297 0.02970462
  0.02923563 0.01127486 0.00998076 0.03353033 0.03399253 0.03185013
  0.02829983 0.02804856 0.02932563 0.0284146  0.02101672 0.0376
  0.06022639 0.02796744]
 [0.02881105 0.02019938 0.01702207 0.01463747 0.01198413 0.01569624
  0.02212706 0.02161717 0.01958105 0.01608231 0.0221578  0.01910104
  0.02228109 0.00733941 0.00740386 0.03557755 0.03086811 0.04384521
  0.03345584 0.04107738 0.04911348 0.02703285 0.01663799 0.04265517
  0.10792477 0.04220106]
 [0.03001028 0.0207984  0.02028553 0.01722072 0.01598311 0.02121046
  0.02670749 0.02585393 0.02218314 0.01981904 0.02463947 0.02517762
  0.02479951 0.00910708 0.00823846 0.03421548 0.02103526 0.03127756
  0.02477959 0.03280678 0.02627891 0.02247452 0.01636702 0.03194698
  0.07216177 0.02540147]
 [0.02982497 0.0174364  0.01568785 0.01302027 0.01106496 0.01533178
  0.02049853 0.02038532 0.01861407 0.01522786 0.02529855 0.02146348
  0.02181437 0.00676372 0.00675331 0.03920709 0.02625714 0.04111784
  0.03206414 0.04062505 0.03353738 0.02206177 0.01288064 0.02930006
  0.06223781 0.034374  ]
 [0.02963804 0.01672168 0.01497269 0.01157547 0.009884   0.01383742
  0.01951592 0.01930063 0.01834538 0.01408372 0.02717706 0.01996017
  0.02031141 0.0061528  0.00648173 0.03212885 0.03059004 0.03989921
  0.03756481 0.03959214 0.03490943 0.02315359 0.01385066 0.0301888
  0.04428036 0.05201248]
 [0.02874437 0.02485608 0.02046813 0.016239   0.01556308 0.01853582
  0.03178126 0.026905   0.02657264 0.01854908 0.02972297 0.0219171
  0.0241572  0.00876071 0.00988624 0.02468871 0.02945559 0.0328772
  0.04406362 0.04104164 0.05305984 0.02759321 0.0251814  0.06138204
  0.03314487 0.06347016]
 [0.03017042 0.02193251 0.02068115 0.01632164 0.01338267 0.01874324
  0.02292251 0.02295565 0.02290012 0.01792434 0.02607779 0.02235122
  0.0228021  0.00879057 0.00832869 0.02452576 0.02383365 0.02541602
  0.03167849 0.03005367 0.02870309 0.02626278 0.01635101 0.02483229
  0.0206431  0.03621937]
 [0.03029257 0.02335358 0.02623345 0.02348008 0.01856377 0.02649555
  0.02712454 0.03376887 0.02743905 0.02755149 0.02950645 0.03794514
  0.03423781 0.0136415  0.0096424  0.02262215 0.02376702 0.02703343
  0.0252719  0.02316599 0.02285245 0.02822541 0.01531221 0.01916079
  0.01805029 0.01864299]
 [0.03044758 0.0278474  0.0294865  0.02834878 0.02092801 0.03082851
  0.03326332 0.04144625 0.02871495 0.0327162  0.03671116 0.04442114
  0.0420426  0.0159341  0.01076438 0.0230271  0.02304951 0.0271595
  0.02419319 0.02368587 0.02193756 0.02902029 0.01669135 0.01788555
  0.01578755 0.01432825]
 [0.03027911 0.02554721 0.02592672 0.02551191 0.02010774 0.02803732
  0.03037041 0.03552684 0.02864598 0.03072201 0.03436392 0.03908252
  0.04015725 0.01474331 0.01085484 0.02633872 0.02507767 0.03030482
  0.02594493 0.02511872 0.02414767 0.02913797 0.01450406 0.02102183
  0.0186645  0.01302505]
 [0.03017626 0.01977161 0.01882719 0.01555792 0.01185382 0.01712443
  0.02224404 0.02442507 0.02250068 0.01851543 0.0241981  0.02384114
  0.02659822 0.00842629 0.00744581 0.02805182 0.02890154 0.03064265
  0.02846332 0.02722174 0.031334   0.02724376 0.01205944 0.02566558
  0.02940803 0.01741028]
 [0.0302662  0.02007987 0.01774684 0.01505922 0.01086484 0.01524882
  0.02235796 0.02221978 0.02114863 0.01674948 0.02317854 0.02059218
  0.02466319 0.00760814 0.0068282  0.02967983 0.02788168 0.03523331
  0.03088529 0.03206759 0.03865375 0.02339152 0.01175172 0.02987059
  0.02868035 0.0203819 ]
 [0.03048581 0.01989872 0.01779489 0.01563201 0.01249258 0.01613773
  0.02080267 0.02311209 0.02190871 0.01903336 0.02526762 0.02378086
  0.02465279 0.00856065 0.00739325 0.02643059 0.03013224 0.03028357
  0.03205157 0.02766575 0.03003585 0.02408958 0.01157977 0.02022149
  0.01814594 0.01689225]
 [0.03047286 0.02256426 0.02032478 0.01698989 0.01274855 0.01786914
  0.02500267 0.02653417 0.02661287 0.02012337 0.02995615 0.02474715
  0.02704183 0.00890403 0.0076892  0.02852857 0.02928561 0.03171465
  0.03237341 0.03064404 0.0325782  0.02493354 0.01275613 0.02200056
  0.01874045 0.0188224 ]
 [0.03060826 0.01655119 0.01562379 0.01116654 0.0096001  0.01266208
  0.01935927 0.01959846 0.02041297 0.01399447 0.03026309 0.01864561
  0.02069495 0.00658934 0.0056063  0.02494957 0.03178491 0.02817683
  0.03726067 0.03221788 0.03196974 0.02264181 0.01175942 0.02092621
  0.01811452 0.03016277]
 [0.0292599  0.02266169 0.02132424 0.01365432 0.01225523 0.01609921
  0.026087   0.02806385 0.02813303 0.01683434 0.02962185 0.02183733
  0.02519922 0.00798974 0.0078189  0.02340763 0.0279566  0.02828863
  0.04097095 0.03692323 0.05011575 0.02637807 0.0235402  0.05612678
  0.02563368 0.0573475 ]
 [0.03052237 0.0216859  0.02173027 0.0188365  0.01466951 0.02212901
  0.02319206 0.02886346 0.02771492 0.02241457 0.02628242 0.02775439
  0.02640529 0.01185413 0.00919533 0.01825598 0.02363672 0.02356492
  0.03107812 0.02714635 0.02893533 0.02579478 0.014191   0.01606389
  0.01220169 0.02237958]
 [0.02937673 0.02725903 0.02689495 0.04319856 0.04489511 0.03864107
  0.0246965  0.02515166 0.03026959 0.04398493 0.03164074 0.03121158
  0.0308957  0.07363833 0.09014081 0.02268573 0.02677625 0.02305504
  0.02359422 0.02221484 0.02079218 0.03169107 0.03126953 0.01336012
  0.00617375 0.02069193]
 [0.02918574 0.02850047 0.02714081 0.04762841 0.09107357 0.03802377
  0.02290725 0.02361735 0.02913594 0.05049862 0.03694076 0.03078842
  0.0253598  0.07437824 0.09446791 0.02794859 0.03670503 0.03093625
  0.02749686 0.02406428 0.02358319 0.02863936 0.03033982 0.01108285
  0.00527143 0.01776466]
 [0.0288703  0.02537443 0.02374601 0.03870031 0.08835213 0.0257775
  0.01860349 0.02207492 0.02510133 0.04367183 0.035299   0.0325298
  0.02517727 0.03302494 0.04226534 0.02387495 0.0595822  0.05059661
  0.04026811 0.02950148 0.03867633 0.02613723 0.0280132  0.01874696
  0.01108392 0.02211292]
 [0.02910612 0.03232524 0.02858955 0.04067373 0.05680943 0.03127494
  0.02541565 0.02489904 0.0310972  0.04060227 0.03347285 0.0278585
  0.02792674 0.03428142 0.03735651 0.02100526 0.03893456 0.0335675
  0.03165194 0.0280515  0.02946873 0.04493878 0.0411144  0.01478624
  0.00754799 0.02201829]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Mary', ' being', ' in', ' the', ' school', ' in', ' the', ' context', ' sentences', '.', ' The', ' options', ' provided', ' are', ' office', ',', ' bedroom', ',', ' and', ' cinema', ',', ' but', ' school', ' is', ' not', ' one', ' of', ' them', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 32), x_tokens=32, y_tokens=41, max_supp_attn=0.0732, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 32)
DEBUG result.interpretability.attn_scores 1312 
 [[0.02250089 0.03313118 0.03495413 ... 0.0117023  0.00981834 0.06756047]
 [0.02317342 0.03124091 0.03114015 ... 0.01554309 0.0172766  0.07789139]
 [0.02354699 0.0301413  0.03345961 ... 0.0247933  0.02301578 0.05605097]
 ...
 [0.02353518 0.0319275  0.02573332 ... 0.00817765 0.00940676 0.09042727]
 [0.02368484 0.02479663 0.01969427 ... 0.00963246 0.0149588  0.05026061]
 [0.02388813 0.02572567 0.01997548 ... 0.00852208 0.01276658 0.06971783]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Bill', ' is', ' in', ' the', ' cinema', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' him', ' being', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 38), x_tokens=38, y_tokens=32, max_supp_attn=0.0938, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 38)
DEBUG result.interpretability.attn_scores 1216 
 [[0.02913312 0.04528885 0.04217271 ... 0.01880902 0.02554175 0.02752041]
 [0.02963684 0.03611461 0.03588866 ... 0.02643791 0.02402094 0.03379621]
 [0.03034807 0.04524447 0.04632495 ... 0.01417301 0.02057475 0.02104607]
 ...
 [0.0305054  0.04175019 0.03401815 ... 0.013379   0.02117268 0.01768482]
 [0.03107061 0.03404965 0.02632231 ... 0.02175921 0.02553362 0.02148326]
 [0.03110226 0.0341473  0.0262184  ... 0.01654614 0.02008569 0.01925721]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' mention', ' of', ' Fred', ' being', ' in', ' the', ' cinema', ' in', ' the', ' context', ' sentences', '.', ' The', ' information', ' provided', ' is', ' about', ' Julie', ' traveling', ' to', ' the', ' cinema', ' and', ' Bill', "'s", ' possible', ' locations', ',', ' but', ' it', ' does', ' not', ' mention', ' Fred', "'s", ' location', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(48, 44), x_tokens=44, y_tokens=48, max_supp_attn=0.0, attn_on_target=0.0208)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (48, 44)
DEBUG result.interpretability.attn_scores 2112 
 [[0.01915356 0.02191821 0.02344275 ... 0.02386225 0.01028053 0.00641128]
 [0.01953945 0.02168519 0.02516777 ... 0.02345407 0.02550266 0.01396751]
 [0.02007434 0.02221812 0.02542679 ... 0.0369902  0.01590522 0.01040051]
 ...
 [0.02054148 0.02362705 0.02142389 ... 0.01052439 0.00758228 0.00910531]
 [0.02073554 0.02743741 0.02738035 ... 0.01172723 0.01060822 0.0110655 ]
 [0.02085593 0.02304341 0.02361036 ... 0.01244468 0.01109797 0.01038938]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ',', ' Bill', ' went', ' to', ' the', ' kitchen', ' and', ' then', ' travelled', ' to', ' the', ' bedroom', ',', ' but', ' there', ' is', ' no', ' mention', ' of', ' him', ' being', ' in', ' the', ' school', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(41, 50), x_tokens=50, y_tokens=41, max_supp_attn=0.0, attn_on_target=0.0244)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (41, 50)
DEBUG result.interpretability.attn_scores 2050 
 [[0.02262643 0.02841362 0.03395353 ... 0.03477511 0.02413763 0.01841019]
 [0.02292809 0.03276287 0.03639011 ... 0.02410012 0.03089004 0.02586406]
 [0.02360692 0.03341315 0.04111205 ... 0.03277625 0.02140146 0.01459231]
 ...
 [0.02383578 0.03053305 0.03100908 ... 0.03378373 0.019666   0.01394019]
 [0.0243576  0.02326356 0.02264066 ... 0.02030043 0.01957989 0.01983827]
 [0.02408068 0.02710303 0.02494655 ... 0.02926991 0.0178961  0.0174562 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '2', ',', ' "', 'Fred', ' travelled', ' to', ' the', ' school', '",', ' we', ' can', ' infer', ' that', ' Fred', ' has', ' moved', ' to', ' the', ' school', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 26), x_tokens=26, y_tokens=35, max_supp_attn=0.0286, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 26)
DEBUG result.interpretability.attn_scores 910 
 [[0.02650266 0.04233338 0.05161104 0.0668107  0.0793134  0.06757753
  0.05205586 0.06221564 0.05216551 0.05876753 0.04587658 0.0526339
  0.0598962  0.093867   0.06454754 0.02875103 0.0304656  0.02872202
  0.02478858 0.02541667 0.02487548 0.0368103  0.03987642 0.02070812
  0.01450927 0.02385328]
 [0.02629442 0.08096466 0.06204924 0.05429426 0.04474816 0.05424954
  0.15939513 0.09569222 0.06299678 0.04868374 0.06640684 0.0446426
  0.07014341 0.02642618 0.02413972 0.03883728 0.03840264 0.04886653
  0.03502432 0.0391489  0.03892044 0.04271888 0.04036886 0.03362267
  0.02464603 0.02810387]
 [0.02882457 0.05554896 0.03632154 0.05078502 0.04031027 0.03410308
  0.0279238  0.02080007 0.02161247 0.03181227 0.02777707 0.01401257
  0.01585783 0.03085779 0.04169177 0.02257492 0.01407789 0.01164136
  0.01351178 0.01309653 0.01484692 0.04109234 0.05112074 0.00964961
  0.00646577 0.01142918]
 [0.02707806 0.02239571 0.02234205 0.01849696 0.01359231 0.02087688
  0.01880278 0.01766953 0.0229361  0.0198282  0.02036588 0.0169858
  0.01691489 0.00974311 0.01007454 0.02278285 0.02522236 0.02468814
  0.05094879 0.04487471 0.03611102 0.03012822 0.04655035 0.05291193
  0.05789344 0.07356373]
 [0.02741411 0.03963868 0.04502149 0.06217377 0.06000553 0.04502371
  0.03008238 0.02723948 0.03268465 0.04200567 0.03378692 0.02187347
  0.02185266 0.10057528 0.10938991 0.03462238 0.026882   0.01821118
  0.01756189 0.01787551 0.02082241 0.0366761  0.05954995 0.0166755
  0.00898797 0.02490801]
 [0.02798868 0.02572122 0.0276532  0.04821879 0.04499735 0.04070992
  0.02246273 0.02128603 0.02766759 0.03928532 0.03009007 0.02488982
  0.02355941 0.10841543 0.134923   0.03407483 0.03007693 0.02184568
  0.01971004 0.01895886 0.01988343 0.03124739 0.03563413 0.01177177
  0.00712894 0.01609366]
 [0.02840247 0.02938814 0.03566101 0.05116352 0.04975013 0.05175824
  0.02988685 0.0294805  0.03615477 0.04650746 0.03531999 0.03938243
  0.03600375 0.08581772 0.08377119 0.02869409 0.02719412 0.02156406
  0.01900364 0.01874738 0.01869236 0.02854112 0.03327167 0.01542965
  0.00927906 0.0159296 ]
 [0.02737115 0.03690882 0.04355504 0.03932864 0.04325527 0.04780163
  0.03394907 0.03863228 0.03903075 0.04087791 0.03548787 0.04410957
  0.0389278  0.05273117 0.0491308  0.03659664 0.03458065 0.02841954
  0.0248648  0.025232   0.02643072 0.03335414 0.04620207 0.03436984
  0.0281767  0.03465217]
 [0.02768535 0.04454013 0.0513266  0.03033444 0.0271733  0.03931962
  0.03959791 0.04131545 0.04401803 0.03089316 0.02962607 0.03515871
  0.03492352 0.0212353  0.01780248 0.03951426 0.03327905 0.02784553
  0.02755958 0.02892972 0.02928881 0.03377387 0.06670479 0.04197029
  0.03347227 0.04036655]
 [0.02853436 0.06095666 0.06247511 0.02609683 0.02207505 0.03270206
  0.0395023  0.03692936 0.04503309 0.02601898 0.02549437 0.02681517
  0.02696613 0.01556136 0.01473906 0.04424686 0.03451316 0.02590884
  0.02619772 0.02840039 0.02778164 0.02863199 0.06565533 0.03662362
  0.0232309  0.02509362]
 [0.02849584 0.03123809 0.03670949 0.019332   0.01659508 0.02270919
  0.02975593 0.0273959  0.03387294 0.02036831 0.02006393 0.01998864
  0.01979646 0.01229036 0.01218562 0.03601522 0.03115264 0.02438128
  0.0287804  0.02908633 0.02887025 0.02782292 0.05266727 0.04810245
  0.04088427 0.04209423]
 [0.02870402 0.01277526 0.01400635 0.01015831 0.00913064 0.0125047
  0.01306005 0.01345967 0.01731407 0.01144529 0.01256415 0.01176096
  0.01159677 0.00593775 0.00647935 0.01684528 0.01878219 0.01799383
  0.02634405 0.02824587 0.02802682 0.01780643 0.02823306 0.05565232
  0.0617944  0.0646799 ]
 [0.02857713 0.02187993 0.02270235 0.01591381 0.01468763 0.0198259
  0.02109144 0.02004403 0.02150149 0.01679487 0.02030293 0.01870854
  0.01783294 0.00939871 0.01016484 0.03017422 0.02518893 0.02487656
  0.02598046 0.027642   0.02587605 0.0278399  0.02620101 0.04184078
  0.05848947 0.05199762]
 [0.0287657  0.02564796 0.02928558 0.02262012 0.01989914 0.02938747
  0.02895486 0.031587   0.02988175 0.02593314 0.02589542 0.03469166
  0.03203326 0.01538042 0.01189494 0.03014613 0.02980418 0.03051033
  0.02835729 0.02751554 0.02638565 0.03053647 0.02214382 0.02812733
  0.03777386 0.0279728 ]
 [0.02901544 0.02122713 0.0202127  0.01488367 0.01588828 0.01753194
  0.02402181 0.02162599 0.02037275 0.01629438 0.02987556 0.02062194
  0.02008414 0.00889647 0.01024446 0.0305033  0.02938052 0.02852216
  0.02792929 0.03095027 0.02812027 0.02651555 0.02231797 0.03714855
  0.06645201 0.03051066]
 [0.02859036 0.01632276 0.01357574 0.01192983 0.01072886 0.01296367
  0.01551839 0.01558285 0.01563044 0.01290714 0.01791414 0.01296106
  0.01567538 0.00620775 0.0068719  0.02470519 0.02215458 0.03426966
  0.03871694 0.04846689 0.03687783 0.02216171 0.01552178 0.03731791
  0.09020399 0.04200098]
 [0.02900341 0.01656014 0.01446541 0.01232654 0.01103243 0.01414056
  0.01611962 0.01667989 0.01654669 0.01393586 0.02215777 0.0158948
  0.01756168 0.00647775 0.00681563 0.03289619 0.02369831 0.04222774
  0.03367143 0.05362359 0.0337382  0.01975036 0.01252272 0.03304716
  0.05665855 0.03004619]
 [0.02900427 0.01395776 0.01245852 0.00953268 0.00857109 0.01163587
  0.0141738  0.01476215 0.01498757 0.01144132 0.02060022 0.01336109
  0.01559912 0.00525401 0.0057254  0.02988151 0.02610561 0.03553915
  0.0395065  0.0457738  0.03376644 0.02023331 0.01235838 0.04135953
  0.04422758 0.03847788]
 [0.02868337 0.02881668 0.02630843 0.03560089 0.04815983 0.03806147
  0.02698318 0.02732082 0.02831857 0.04182079 0.03754555 0.03460126
  0.02961119 0.03056862 0.02862898 0.02164134 0.03079741 0.02631428
  0.0242387  0.02299704 0.02641029 0.03280991 0.02481825 0.02203731
  0.01670134 0.02216342]
 [0.02967237 0.01682902 0.01524999 0.0118674  0.01084667 0.01401734
  0.01605158 0.0164244  0.01703391 0.0132188  0.02041252 0.0151576
  0.01620246 0.00683681 0.00703448 0.02228847 0.02329684 0.02256605
  0.03111891 0.02776512 0.02649682 0.02204142 0.01288888 0.02832121
  0.02400538 0.03005895]
 [0.02917738 0.02831261 0.02852312 0.0275679  0.02144414 0.03027148
  0.02903841 0.03430875 0.02833346 0.03005329 0.03234712 0.04147143
  0.03414255 0.01837522 0.01253013 0.02364921 0.02246046 0.02419152
  0.02278105 0.02245348 0.02384365 0.03055344 0.01829884 0.02037285
  0.01859382 0.02159251]
 [0.02935842 0.03277007 0.03799105 0.04500871 0.03180941 0.04455848
  0.03274659 0.04141035 0.03919451 0.04630409 0.03039669 0.05950875
  0.04921459 0.03061428 0.01711458 0.01843728 0.0205993  0.02052169
  0.01819288 0.0171791  0.01831196 0.03048748 0.02075991 0.01247506
  0.00901518 0.01541719]
 [0.02916529 0.03493726 0.04107487 0.04976009 0.03230666 0.04406915
  0.03575277 0.04704366 0.03742155 0.04981809 0.03579798 0.07749619
  0.05874357 0.03071912 0.01664597 0.0220093  0.02280976 0.02426117
  0.02014742 0.01908114 0.01944024 0.03019515 0.01974965 0.01405064
  0.01023958 0.01446186]
 [0.02925274 0.02561132 0.02738693 0.0319785  0.02593753 0.03519782
  0.03118838 0.03976791 0.03506663 0.04204529 0.03549369 0.07593866
  0.06544601 0.02996436 0.01587311 0.02307381 0.02441191 0.02477327
  0.0223718  0.01988057 0.02131548 0.02819932 0.01576685 0.0136736
  0.01195763 0.01320657]
 [0.02905077 0.01863501 0.01795218 0.01451038 0.01176868 0.01706315
  0.02000698 0.0238962  0.02166796 0.01804544 0.02254132 0.02186412
  0.02529607 0.00915294 0.00790319 0.02939189 0.02725817 0.03002347
  0.03006073 0.02693764 0.03057333 0.02762389 0.01285486 0.02682074
  0.03243903 0.0230343 ]
 [0.02902281 0.01876835 0.01722844 0.01401222 0.01044796 0.01489509
  0.02036014 0.02215365 0.02041742 0.01585727 0.02155153 0.01770482
  0.02243477 0.00780125 0.00709052 0.03381673 0.02600969 0.03387062
  0.03421519 0.03235481 0.03713623 0.02379763 0.01186075 0.03490167
  0.03418965 0.02533421]
 [0.02953169 0.01876542 0.01712493 0.0135921  0.01057482 0.01534156
  0.01855729 0.02202539 0.02157864 0.0165334  0.02147342 0.01955588
  0.02364146 0.00787735 0.00628097 0.03167818 0.02409791 0.03111362
  0.02826354 0.0307434  0.03110847 0.02219518 0.01101886 0.02805721
  0.0250645  0.01868387]
 [0.02931819 0.02077069 0.01866407 0.01448827 0.01130994 0.01618807
  0.02193816 0.02426328 0.02348016 0.01715274 0.02598635 0.02000994
  0.02549204 0.00854474 0.00683253 0.03565002 0.03053777 0.05035876
  0.03920242 0.04176996 0.03753767 0.02331113 0.01263401 0.02713953
  0.02553472 0.01803774]
 [0.02940364 0.01680338 0.01575329 0.01083986 0.00887805 0.0129217
  0.0181068  0.01965193 0.02060013 0.01385135 0.02685023 0.01606417
  0.02129662 0.00688415 0.0057741  0.03099994 0.03123637 0.03559601
  0.04227546 0.03679166 0.03600316 0.02329868 0.01163182 0.03235976
  0.02381622 0.02402745]
 [0.0285779  0.01862988 0.01768038 0.01099204 0.00939682 0.01376374
  0.01834626 0.0205352  0.02338137 0.0141762  0.02119712 0.01526514
  0.02047511 0.00701944 0.00622247 0.02425446 0.02990166 0.02416897
  0.03295809 0.02937696 0.03974794 0.02430904 0.0177101  0.06323438
  0.03852603 0.05225448]
 [0.0295647  0.01892514 0.01792927 0.01317978 0.01048194 0.01499332
  0.01773986 0.02062384 0.02217819 0.01547695 0.02488581 0.01785081
  0.020283   0.00866762 0.00679806 0.0262109  0.02796239 0.02607101
  0.03610695 0.02852016 0.03029599 0.02360895 0.01191322 0.02611801
  0.01951017 0.02572083]
 [0.02868624 0.02483032 0.02600818 0.03512615 0.03733921 0.03146176
  0.02146527 0.02440301 0.02847557 0.03684228 0.02942322 0.02657152
  0.02614558 0.05901952 0.07947409 0.02312423 0.02790741 0.02239109
  0.02185046 0.02017999 0.02276165 0.02922036 0.02894751 0.01316993
  0.00960943 0.01873445]
 [0.02843939 0.02759315 0.02692314 0.04398767 0.08659662 0.03529336
  0.01974684 0.02206397 0.02848234 0.04673591 0.03570238 0.02704013
  0.02218668 0.07004217 0.09013467 0.02829603 0.03914278 0.03046626
  0.02455664 0.0212135  0.02529193 0.02730101 0.02999179 0.01014179
  0.00676044 0.01590937]
 [0.02831689 0.02171435 0.02090326 0.02962427 0.05764726 0.02094742
  0.01486289 0.01932761 0.02223503 0.03462638 0.02848589 0.02383363
  0.020673   0.02483775 0.03350345 0.02306855 0.05317319 0.0471647
  0.03559335 0.02615161 0.04352457 0.02343805 0.02490359 0.01690138
  0.01307519 0.02133125]
 [0.0285262  0.02928191 0.02586596 0.03346388 0.04330058 0.02613361
  0.02075378 0.02238203 0.02772714 0.03364125 0.03030342 0.02157319
  0.0234899  0.02800109 0.03156652 0.02054749 0.03743565 0.03011398
  0.0276089  0.02461892 0.03088582 0.04196834 0.03735077 0.01389584
  0.01068728 0.01825766]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '4', ',', ' "', 'Jul', 'ie', ' travelled', ' to', ' the', ' office', '",', ' we', ' can', ' infer', ' that', ' Julie', ' has', ' moved', ' to', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(32, 32), x_tokens=32, y_tokens=32, max_supp_attn=0.0, attn_on_target=0.0312)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (32, 32)
DEBUG result.interpretability.attn_scores 1024 
 [[0.02957226 0.04317524 0.04183932 ... 0.05647513 0.01129724 0.01118519]
 [0.03019355 0.0448143  0.04231576 ... 0.06169872 0.01507746 0.01730609]
 [0.03084453 0.03859679 0.04340884 ... 0.06207407 0.02211984 0.02579073]
 ...
 [0.03087419 0.0362114  0.03398399 ... 0.02221027 0.00919505 0.00671799]
 [0.03100982 0.02714348 0.02359328 ... 0.01336309 0.01211773 0.00889474]
 [0.03117295 0.03125404 0.02717499 ... 0.01123438 0.00738504 0.00602503]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '7', ',', ' "', 'Mary', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' bedroom', '",', ' we', ' can', ' infer', ' that', ' Mary', ' is', ' in', ' one', ' of', ' these', ' two', ' locations', ',', ' but', ' we', ' don', "'t", ' have', ' enough', ' information', ' to', ' determine', ' which', ' one', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(49, 38), x_tokens=38, y_tokens=49, max_supp_attn=0.0, attn_on_target=0.0204)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (49, 38)
DEBUG result.interpretability.attn_scores 1862 
 [[0.01865622 0.02746288 0.02629944 ... 0.02061598 0.01559484 0.02387793]
 [0.0189542  0.02188209 0.02340422 ... 0.02113749 0.02295183 0.02574077]
 [0.01952923 0.0278942  0.02964042 ... 0.01612492 0.01376874 0.01911905]
 ...
 [0.01965808 0.02466517 0.02266651 ... 0.0189299  0.01236322 0.02231084]
 [0.02008531 0.01967768 0.01701074 ... 0.01979025 0.01683835 0.01748187]
 [0.02023748 0.01872429 0.01645551 ... 0.0199523  0.01427194 0.01913249]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '11', ',', ' "', 'Bill', ' is', ' in', ' the', ' kitchen', '",', ' we', ' can', ' infer', ' that', ' Bill', "'s", ' location', ' is', ' explicitly', ' stated', ' as', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 44), x_tokens=44, y_tokens=34, max_supp_attn=0.1176, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 44)
DEBUG result.interpretability.attn_scores 1496 
 [[0.02761154 0.03468739 0.03769867 ... 0.01222908 0.01512892 0.04023388]
 [0.02797312 0.03451504 0.03673184 ... 0.01560691 0.01342143 0.02071507]
 [0.02876971 0.03372917 0.03800021 ... 0.0173843  0.02525276 0.03939674]
 ...
 [0.02889539 0.0374245  0.03582403 ... 0.0097201  0.00798524 0.06531867]
 [0.02912734 0.03167515 0.02893811 ... 0.01175616 0.00758956 0.04222493]
 [0.02931122 0.03397584 0.03181947 ... 0.00992799 0.00756446 0.02646917]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' From', ' context', ' sentence', ' ', '13', ',', ' "', 'Jul', 'ie', ' is', ' in', ' the', ' cinema', '",', ' we', ' can', ' infer', ' that', ' Julie', "'s", ' location', ' is', ' explicitly', ' stated', ' as', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(35, 50), x_tokens=50, y_tokens=35, max_supp_attn=0.0, attn_on_target=0.0286)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (35, 50)
DEBUG result.interpretability.attn_scores 1750 
 [[0.02701035 0.03391501 0.03978356 ... 0.01069382 0.0176963  0.02441843]
 [0.02720937 0.05417163 0.05680203 ... 0.02496625 0.03008682 0.03429619]
 [0.02811449 0.03395812 0.04362224 ... 0.00956095 0.01426803 0.0202489 ]
 ...
 [0.02826712 0.03870663 0.03386302 ... 0.01146427 0.01399488 0.0189962 ]
 [0.02852809 0.02938616 0.02481356 ... 0.01991276 0.01942686 0.02044626]
 [0.02833435 0.03437692 0.02870319 ... 0.01300035 0.01658121 0.02299012]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|end_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' explicitly', ' states', ' that', ' "', 'Bill', ' is', ' in', ' the', ' office', '".', ' This', ' contrad', 'icts', ' the', ' information', ' in', ' sentence', ' ', '1', ',', ' which', ' implies', ' that', ' Bill', ' was', ' in', ' the', ' kitchen', ' previously', ',', ' but', ' sentence', ' ', '2', ' provides', ' the', ' current', ' location', ' of', ' Bill', ',', ' which', ' is', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(62, 26), x_tokens=26, y_tokens=62, max_supp_attn=0.1935, attn_on_target=0.0161)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (62, 26)
DEBUG result.interpretability.attn_scores 1612 
 [[0.01458433 0.02808784 0.03227931 ... 0.00911153 0.00799906 0.01574291]
 [0.01452332 0.04313799 0.03221498 ... 0.02463088 0.01936806 0.02409197]
 [0.01588405 0.03618834 0.02144155 ... 0.00369144 0.00311998 0.00711179]
 ...
 [0.0156833  0.01592864 0.01680177 ... 0.00425306 0.00317998 0.00964594]
 [0.01575491 0.01218685 0.01300969 ... 0.00759423 0.00657343 0.01411183]
 [0.01578975 0.01615554 0.01626045 ... 0.00622901 0.00531266 0.01035638]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' "', 'Jul', 'ie', ' moved', ' to', ' the', ' kitchen', '",', ' which', ' implies', ' that', ' Julie', ' is', ' currently', ' in', ' the', ' kitchen', '.', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', ' being', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(44, 32), x_tokens=32, y_tokens=44, max_supp_attn=0.0227, attn_on_target=0.0227)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (44, 32)
DEBUG result.interpretability.attn_scores 1408 
 [[0.0210782  0.03228746 0.03608332 ... 0.05829304 0.01517482 0.01244932]
 [0.02166    0.03179717 0.03394945 ... 0.06295609 0.02309039 0.01875674]
 [0.02212875 0.03053465 0.03529131 ... 0.05521387 0.02494328 0.02015451]
 ...
 [0.02209232 0.03085184 0.03002749 ... 0.02034571 0.01150576 0.00935055]
 [0.02244766 0.02441383 0.02241725 ... 0.0096657  0.00971044 0.0092883 ]
 [0.02251388 0.02391214 0.02216559 ... 0.00974721 0.00979293 0.00925576]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' given', ' context', ' sentences', '.', ' The', ' context', ' sentences', ' only', ' mention', ' Fred', ' and', ' Mary', ',', ' but', ' not', ' Julie', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 38), x_tokens=38, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 38)
DEBUG result.interpretability.attn_scores 1368 
 [[0.02577706 0.03203349 0.02672956 ... 0.00985612 0.05485127 0.03208831]
 [0.0261683  0.02488916 0.02398046 ... 0.01629714 0.02654522 0.02220063]
 [0.02699027 0.0290593  0.0290913  ... 0.01340417 0.03938803 0.02171641]
 ...
 [0.02742755 0.02874038 0.02472528 ... 0.01638643 0.04804008 0.02997674]
 [0.02790011 0.02891071 0.02665762 ... 0.01561005 0.05870588 0.02825745]
 [0.02799622 0.02536392 0.02489129 ... 0.01590701 0.11364038 0.02908341]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '* 41 cont *', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' "', 'Jul', 'ie', ' went', ' to', ' the', ' cinema', '",', ' but', ' it', ' does', ' not', ' provide', ' direct', ' information', ' about', ' Bill', "'s", ' location', '.', ' However', ',', ' sentence', ' ', '10', ' mentions', ' that', ' Bill', ' is', ' either', ' in', ' the', ' cinema', ' or', ' the', ' bedroom', ',', ' and', ' since', ' Julie', ' is', ' in', ' the', ' cinema', ',', ' it', ' is', ' possible', ' that', ' Bill', ' is', ' also', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(70, 44), x_tokens=44, y_tokens=70, max_supp_attn=0.1286, attn_on_target=0.0143)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (70, 44)
DEBUG result.interpretability.attn_scores 3080 
 [[0.01297586 0.02093056 0.02016752 ... 0.02213601 0.02310748 0.07622774]
 [0.01340381 0.01591189 0.01457552 ... 0.01537815 0.01474299 0.03802159]
 [0.01361199 0.02191945 0.02292645 ... 0.01930995 0.01501546 0.05971067]
 ...
 [0.01375029 0.02027515 0.01777506 ... 0.02309609 0.01867707 0.02520248]
 [0.01416267 0.01767281 0.01406945 ... 0.02050983 0.0155504  0.00940171]
 [0.01412369 0.01785401 0.01442282 ... 0.01665885 0.02219279 0.01579658]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '* 48 cont *', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '14', ' states', ' that', ' "', 'Mary', ' journey', 'ed', ' to', ' the', ' school', '",', ' which', ' implies', ' that', ' Mary', ' has', ' moved', ' to', ' the', ' school', ' and', ' is', ' currently', ' there', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 50), x_tokens=50, y_tokens=36, max_supp_attn=0.1389, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 50)
DEBUG result.interpretability.attn_scores 1800 
 [[0.02585715 0.03485815 0.03828478 ... 0.00918517 0.01272677 0.0544646 ]
 [0.02629586 0.02988067 0.03241818 ... 0.01649473 0.02913641 0.01960753]
 [0.02695176 0.03981308 0.04768374 ... 0.01364296 0.02322888 0.04733423]
 ...
 [0.027131   0.04280362 0.03856506 ... 0.00591706 0.01087427 0.09767739]
 [0.02738486 0.03444543 0.02925596 ... 0.0091489  0.01231311 0.06468704]
 [0.02737768 0.03966423 0.03285679 ... 0.0075437  0.01236568 0.0855605 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '* 24 cont *', '25 wrap', '26 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '2', ' states', ' that', ' Bill', ' is', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' can', ' only', ' conclude', ' that', ' Bill', ' might', ' be', ' in', ' the', ' park', ',', ' but', ' we', ' cannot', ' be', ' certain', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(53, 26), x_tokens=26, y_tokens=53, max_supp_attn=0.0943, attn_on_target=0.0189)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (53, 26)
DEBUG result.interpretability.attn_scores 1378 
 [[0.01737377 0.0349368  0.03583432 ... 0.0179815  0.00315437 0.02142977]
 [0.01792905 0.02151035 0.02107712 ... 0.0128979  0.00289098 0.01436332]
 [0.01822675 0.02451477 0.02764727 ... 0.01708293 0.00389411 0.01417375]
 ...
 [0.01833096 0.02049363 0.02071318 ... 0.01106559 0.00278189 0.01261131]
 [0.01835048 0.01699286 0.01699883 ... 0.0153501  0.00742302 0.01530329]
 [0.01846365 0.01842505 0.01810352 ... 0.01410193 0.00531921 0.01473136]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' bedroom', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' park', '.', ' The', ' previous', ' information', ' about', ' Bill', ' being', ' either', ' in', ' the', ' park', ' or', ' the', ' cinema', ' (', 'sentence', ' ', '2', ')', ' is', ' no', ' longer', ' relevant', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 32), x_tokens=32, y_tokens=52, max_supp_attn=0.0192, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 32)
DEBUG result.interpretability.attn_scores 1664 
 [[0.01781251 0.0261207  0.0302043  ... 0.00687915 0.00673381 0.0116252 ]
 [0.01829989 0.02645704 0.02819068 ... 0.0086032  0.00812657 0.01967949]
 [0.01870542 0.0236016  0.02899526 ... 0.01292758 0.00823064 0.01895796]
 ...
 [0.01878063 0.02588456 0.02472119 ... 0.00402283 0.00678723 0.00898752]
 [0.01899427 0.02010484 0.01840059 ... 0.00465891 0.01017079 0.00939642]
 [0.01899662 0.02161403 0.01939571 ... 0.0035931  0.00804054 0.00807738]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '* 35 cont *', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '7', ' explicitly', ' states', ' that', ' Bill', ' is', ' in', ' the', ' cinema', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(21, 38), x_tokens=38, y_tokens=21, max_supp_attn=0.0, attn_on_target=0.0476)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (21, 38)
DEBUG result.interpretability.attn_scores 798 
 [[0.04541782 0.05979652 0.06661058 0.08395412 0.06509475 0.06942598
  0.05437404 0.05912124 0.06776087 0.06773786 0.04591263 0.0576793
  0.05505968 0.10129529 0.1075694  0.04090907 0.03612579 0.04006962
  0.03549111 0.04273516 0.03244642 0.04900948 0.07489408 0.03168311
  0.01339172 0.04672109 0.05658655 0.05524381 0.12254184 0.01732994
  0.02154173 0.02800184 0.01946067 0.0348899  0.02662614 0.06562895
  0.06612718 0.06300062]
 [0.04552479 0.05005757 0.05104218 0.04827131 0.03591353 0.04654218
  0.04286755 0.04996328 0.04993267 0.04365811 0.03719054 0.04397225
  0.05322816 0.0420822  0.06049346 0.03960095 0.03415156 0.04040855
  0.04012538 0.0473369  0.0369237  0.04373438 0.05954529 0.04304503
  0.02573171 0.05082002 0.04800054 0.0387041  0.08224925 0.03700397
  0.02893411 0.02737837 0.02676528 0.03886642 0.03759941 0.03566568
  0.04168304 0.05474954]
 [0.04721377 0.063821   0.06979888 0.09722254 0.08285311 0.10028411
  0.06544098 0.06609108 0.07309078 0.0827854  0.05633283 0.08111673
  0.07631412 0.15578473 0.10695735 0.04258309 0.03429588 0.03602483
  0.03410026 0.03792425 0.02947706 0.05203959 0.06146389 0.03062974
  0.01394805 0.03607868 0.05624852 0.03947318 0.10946069 0.02993209
  0.02538996 0.05238083 0.0283214  0.05972438 0.03523821 0.06550686
  0.05842249 0.04577851]
 [0.04591656 0.05333176 0.05849737 0.04776631 0.03797106 0.05003741
  0.04736654 0.05279406 0.05071885 0.04448324 0.04030821 0.05095626
  0.04922867 0.03547988 0.03202436 0.04266469 0.03434013 0.03645046
  0.03688197 0.04064933 0.03291467 0.05301521 0.06817899 0.05132724
  0.02524426 0.04640359 0.0613528  0.04313372 0.08665518 0.07800492
  0.0380042  0.05951206 0.05166322 0.06957836 0.0446402  0.04077564
  0.04220754 0.06983375]
 [0.0464887  0.05775722 0.05511687 0.03185412 0.02481914 0.03808915
  0.04384709 0.04457332 0.04513897 0.03101597 0.03511322 0.03659058
  0.03983304 0.02389878 0.02117365 0.04085496 0.03004052 0.03105258
  0.03473834 0.03742967 0.031536   0.04898588 0.07183156 0.0472971
  0.03136656 0.04060254 0.06243451 0.0302146  0.06528453 0.09117378
  0.03729747 0.047939   0.05697234 0.04496189 0.03344001 0.02112108
  0.03381724 0.07583113]
 [0.04746159 0.07979347 0.07324043 0.04049179 0.02893421 0.04593118
  0.05812895 0.05287057 0.06324939 0.03666662 0.03799932 0.0438178
  0.04769553 0.02570817 0.02218255 0.05198387 0.03798744 0.03808992
  0.03995474 0.04491483 0.03404845 0.04520603 0.08880028 0.04734213
  0.02812394 0.03779035 0.06277253 0.02872968 0.05107379 0.10828885
  0.03450619 0.04415235 0.03610201 0.04106059 0.03098676 0.0215949
  0.03707526 0.09228322]
 [0.04747572 0.05042902 0.04894152 0.03425035 0.02512659 0.03620802
  0.04701491 0.04071734 0.04672343 0.03005455 0.0343984  0.03322285
  0.03654457 0.02247628 0.02085536 0.04515553 0.03446809 0.03275116
  0.0376964  0.03971099 0.03239767 0.04221468 0.05458228 0.05376367
  0.0257582  0.0356442  0.05655275 0.02741633 0.03165925 0.09224186
  0.03321855 0.03738922 0.02121817 0.03026188 0.02834084 0.02098512
  0.03652121 0.05836174]
 [0.04776608 0.02749489 0.02656011 0.02253321 0.01624215 0.02385323
  0.02780394 0.02524368 0.03049179 0.02103708 0.02748851 0.02302379
  0.0267966  0.01389224 0.01407949 0.02904493 0.02650289 0.02796019
  0.03323277 0.03740817 0.03151672 0.03284788 0.03067946 0.05175181
  0.0270828  0.03512616 0.03025386 0.02556905 0.01918642 0.04514742
  0.03042098 0.01915517 0.01224759 0.01938158 0.02521755 0.01586822
  0.02979393 0.03716276]
 [0.0472249  0.04382159 0.04628235 0.03543197 0.02497418 0.03833692
  0.04361791 0.04189938 0.04281671 0.03342506 0.0382678  0.03967072
  0.0392712  0.02235802 0.01998311 0.04728219 0.03800476 0.04497356
  0.04304473 0.04691856 0.04028649 0.05025734 0.04511419 0.06179983
  0.05597501 0.0419227  0.05036676 0.03296407 0.03802901 0.09369379
  0.05060376 0.0994674  0.15319555 0.05856546 0.04582616 0.02624215
  0.03463084 0.04966304]
 [0.04846094 0.05912495 0.06043071 0.05366449 0.03512257 0.05685949
  0.06428249 0.06352808 0.05343622 0.05524674 0.05980623 0.0730853
  0.06409027 0.03455407 0.02623366 0.05373691 0.04695227 0.05200959
  0.05015099 0.05203833 0.04483633 0.05267511 0.04722464 0.06209735
  0.06859581 0.04153596 0.05161748 0.04384807 0.04223437 0.07649875
  0.06111038 0.12444167 0.16447285 0.10781369 0.07341561 0.03938126
  0.04030554 0.05102621]
 [0.04928306 0.04351163 0.04631852 0.04021454 0.02901567 0.04304454
  0.05085145 0.04609582 0.04135723 0.03948827 0.04612406 0.04689261
  0.04753047 0.02578589 0.02105664 0.04605738 0.03817505 0.03801898
  0.04131979 0.04254163 0.03880804 0.04714463 0.03547052 0.05684015
  0.05180251 0.03478956 0.03985397 0.04219159 0.03391181 0.07460178
  0.0578074  0.07497217 0.05814401 0.07093234 0.06003404 0.03046831
  0.0366152  0.03638492]
 [0.0484889  0.03420318 0.03181516 0.02588002 0.01987371 0.02794744
  0.03755228 0.03520114 0.03092721 0.0262678  0.04096933 0.03245237
  0.03757935 0.01638417 0.01531259 0.05820239 0.04259493 0.04349568
  0.04515682 0.04525302 0.04877054 0.04638605 0.02696353 0.06823745
  0.07369023 0.04048795 0.02910455 0.04867259 0.02497265 0.05574481
  0.06049383 0.04155101 0.0343262  0.04624575 0.06380811 0.02007634
  0.03259547 0.02965665]
 [0.04814168 0.03570867 0.03161617 0.02668537 0.01913794 0.02835638
  0.04371209 0.04103867 0.03233428 0.02628622 0.04070086 0.03042321
  0.04021712 0.01583679 0.01454098 0.06707751 0.04076213 0.04877927
  0.04725314 0.04921161 0.05743826 0.04451235 0.02355893 0.06824227
  0.09079878 0.03909857 0.02616367 0.04351974 0.01754329 0.04082223
  0.05191237 0.03390374 0.0283214  0.03616101 0.06714334 0.01573571
  0.03091186 0.02744833]
 [0.04890949 0.03154643 0.02987278 0.02483703 0.01942174 0.02811583
  0.03556807 0.03540006 0.0303668  0.02659196 0.04252984 0.03572069
  0.03633507 0.0163622  0.01440352 0.05409336 0.0470504  0.04806069
  0.05551079 0.04837102 0.05488839 0.04288519 0.02129824 0.05378779
  0.10879216 0.04414524 0.02910455 0.0453537  0.01808384 0.03883209
  0.07847882 0.0446226  0.04693994 0.04729248 0.07512818 0.0198259
  0.02970711 0.02592238]
 [0.04876737 0.03009997 0.02902031 0.02103804 0.01751136 0.02639828
  0.03896508 0.03520879 0.02991122 0.02365981 0.05315476 0.03447621
  0.03710322 0.01459843 0.01343963 0.07187625 0.05524651 0.05919012
  0.0679711  0.05735555 0.06486563 0.04384521 0.02030636 0.06516579
  0.11861011 0.07341545 0.02626508 0.05207726 0.01569297 0.02458262
  0.10176116 0.03211961 0.03352068 0.04357477 0.07194922 0.01525288
  0.03107655 0.02477674]
 [0.04725837 0.03129305 0.02937079 0.02127898 0.01728012 0.0281471
  0.0395145  0.03574435 0.03738197 0.0268756  0.03834834 0.03128245
  0.03629698 0.0153874  0.0137882  0.04748232 0.04206289 0.0476009
  0.05868394 0.05414567 0.05409248 0.04527304 0.02505942 0.05933286
  0.09807349 0.12371982 0.0296116  0.06284295 0.02204455 0.02131996
  0.08574328 0.0317427  0.03430789 0.03277095 0.05224186 0.01917033
  0.03668054 0.03323129]
 [0.04944722 0.03413922 0.0367898  0.03151745 0.02451958 0.04105276
  0.04531327 0.04533074 0.03961553 0.03676977 0.04527165 0.04431489
  0.0455339  0.0261677  0.01919187 0.03684728 0.03491739 0.04001182
  0.04715133 0.04318478 0.04217536 0.046912   0.02271547 0.02894756
  0.03791804 0.0446967  0.03076091 0.03690119 0.02506908 0.02255493
  0.07717441 0.07987543 0.07967339 0.07749571 0.07516029 0.03645791
  0.03443751 0.02679569]
 [0.04802897 0.04661117 0.05066909 0.07533955 0.05956069 0.0721779
  0.05460637 0.05638991 0.06588613 0.08428831 0.05866186 0.06702977
  0.06673438 0.11451346 0.11080963 0.03588187 0.04178773 0.04329469
  0.03992463 0.04336267 0.03691803 0.05104458 0.04458205 0.02402648
  0.01683304 0.04048318 0.05026536 0.05356367 0.0581753  0.01513884
  0.03155762 0.04000993 0.03291654 0.05164383 0.04126216 0.12857251
  0.06525897 0.04155593]
 [0.0476472  0.05966368 0.05741878 0.10014027 0.19712628 0.08872313
  0.05716511 0.05897205 0.06063281 0.1074103  0.08362334 0.07477182
  0.05851003 0.15274711 0.19082063 0.05198044 0.08222756 0.07133239
  0.05655464 0.05423755 0.06429534 0.04960201 0.06080686 0.02496566
  0.01804902 0.04382057 0.07727411 0.05890584 0.0602339  0.01122949
  0.02498102 0.02677603 0.02123648 0.02777831 0.0265769  0.13816738
  0.08178718 0.04859565]
 [0.04736076 0.05360728 0.04990027 0.07071871 0.13921319 0.05042951
  0.04557071 0.05237709 0.04580823 0.08271172 0.075804   0.06296257
  0.05046343 0.05706413 0.08620673 0.05455459 0.1380465  0.10900193
  0.08824313 0.06934079 0.11953407 0.0483925  0.05499677 0.03875114
  0.04269191 0.0492874  0.06706554 0.09194386 0.03728734 0.0151903
  0.03918488 0.03097128 0.03829889 0.03471778 0.0486155  0.10700259
  0.05696712 0.04899788]
 [0.04771613 0.05418782 0.05068718 0.06690981 0.08028843 0.0600396
  0.05643673 0.06143942 0.06241886 0.07353954 0.06199431 0.05653778
  0.0556342  0.06762312 0.06887718 0.04213044 0.08425951 0.07142303
  0.06681398 0.06592955 0.07183041 0.06401677 0.06192726 0.03096585
  0.02752257 0.0534102  0.05834432 0.09873101 0.03861088 0.01066763
  0.02987782 0.02363751 0.02189554 0.02628281 0.03674955 0.11650035
  0.1433782  0.05894394]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' kitchen', ',', ' which', ' means', ' Bill', ' is', ' not', ' in', ' the', ' bedroom', '.', ' The', ' previous', ' information', ' about', ' Bill', ' being', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' park', ' (', 'sentence', ' ', '10', ')', ' is', ' no', ' longer', ' relevant', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 44), x_tokens=44, y_tokens=52, max_supp_attn=0.0, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 44)
DEBUG result.interpretability.attn_scores 2288 
 [[0.01790938 0.02706126 0.02555837 ... 0.01822321 0.07872756 0.03522183]
 [0.01828219 0.01760641 0.01634287 ... 0.01271924 0.03403391 0.04317534]
 [0.01867235 0.02720525 0.02727331 ... 0.01470882 0.04578539 0.04479852]
 ...
 [0.01882904 0.02795452 0.02785764 ... 0.02747251 0.03129158 0.00943899]
 [0.01926461 0.02138811 0.0203399  ... 0.02968917 0.01830605 0.00639741]
 [0.01917918 0.02254129 0.02064065 ... 0.02830448 0.02536234 0.00539313]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '11', ' (', 'from', ' previous', ' questions', ')', ' states', ' that', ' Bill', ' moved', ' to', ' the', ' kitchen', ',', ' and', ' there', ' is', ' no', ' new', ' information', ' that', ' contrad', 'icts', ' this', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 50), x_tokens=50, y_tokens=36, max_supp_attn=0.0, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 50)
DEBUG result.interpretability.attn_scores 1800 
 [[0.02576392 0.03135304 0.02852269 ... 0.01669127 0.01590662 0.03412112]
 [0.02613848 0.0283939  0.02943773 ... 0.0222983  0.02763055 0.01992661]
 [0.02700918 0.03147727 0.03182327 ... 0.0232954  0.02076459 0.03530025]
 ...
 [0.02724552 0.03312162 0.02768366 ... 0.00902914 0.00997131 0.07312569]
 [0.02750998 0.02430805 0.01925387 ... 0.01086024 0.00986052 0.05786913]
 [0.02743749 0.02689449 0.02104303 ... 0.00978731 0.00991328 0.03952605]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' park', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(47, 26), x_tokens=26, y_tokens=47, max_supp_attn=0.0426, attn_on_target=0.0213)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (47, 26)
DEBUG result.interpretability.attn_scores 1222 
 [[0.01955726 0.03397959 0.03735208 ... 0.01022553 0.01446411 0.0235419 ]
 [0.01997173 0.03855622 0.03935595 ... 0.00419634 0.00816511 0.02811388]
 [0.02039798 0.02396058 0.02378581 ... 0.0039801  0.00713936 0.02022575]
 ...
 [0.02078691 0.02390782 0.02338218 ... 0.00367264 0.00623188 0.01919226]
 [0.02081458 0.01948056 0.01933479 ... 0.010931   0.0135952  0.01998745]
 [0.0210798  0.01959434 0.01925484 ... 0.00831579 0.01102962 0.01802442]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '4', ' states', ' that', ' Fred', ' is', ' either', ' in', ' the', ' bedroom', ' or', ' the', ' office', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' definitive', ' location', '.', ' Therefore', ',', ' we', ' cannot', ' conclude', ' that', ' Fred', ' is', ' definitely', ' in', ' the', ' bedroom', '.\n\n', 'Answer', ':', ' maybe']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(46, 32), x_tokens=32, y_tokens=46, max_supp_attn=0.0435, attn_on_target=0.0217)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (46, 32)
DEBUG result.interpretability.attn_scores 1472 
 [[0.02023363 0.03129756 0.03577613 ... 0.00578709 0.0083157  0.00853143]
 [0.02086924 0.0295296  0.03297801 ... 0.00735015 0.01041039 0.01030089]
 [0.02121929 0.02695537 0.03391907 ... 0.01358154 0.01492239 0.01485763]
 ...
 [0.02127715 0.02866596 0.02883043 ... 0.00409251 0.00499048 0.00488374]
 [0.02157944 0.02183507 0.02037233 ... 0.00707187 0.00634353 0.00719321]
 [0.0216107  0.02407761 0.02261794 ... 0.00501746 0.00525026 0.0062567 ]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '* 30 cont *', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentences', ' ', '7', ' and', ' ', '8', ' provide', ' information', ' about', ' Mary', "'s", ' location', ',', ' but', ' they', ' do', ' not', ' mention', ' Bill', "'s", ' location', '.', ' However', ',', ' we', ' can', ' refer', ' back', ' to', ' context', ' sentence', ' ', '2', ',', ' which', ' states', ' that', ' Bill', ' went', ' to', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(52, 38), x_tokens=38, y_tokens=52, max_supp_attn=0.0962, attn_on_target=0.0192)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (52, 38)
DEBUG result.interpretability.attn_scores 1976 
 [[0.01774033 0.02494713 0.02615519 ... 0.02383834 0.01308332 0.00980474]
 [0.01796294 0.02477986 0.02898738 ... 0.01807683 0.01287558 0.01372433]
 [0.018627   0.02474733 0.0257444  ... 0.01641865 0.01018584 0.0087985 ]
 ...
 [0.01884748 0.02117709 0.01915356 ... 0.0181416  0.00874691 0.00779994]
 [0.01913208 0.01633281 0.01413257 ... 0.0149081  0.01106329 0.01128257]
 [0.0191088  0.01871917 0.01586879 ... 0.02111864 0.00990183 0.00944394]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '8', ' states', ' that', ' Mary', ' journey', 'ed', ' to', ' the', ' school', ',', ' but', ' it', ' does', ' not', ' provide', ' a', ' current', ' location', '.', ' However', ',', ' we', ' can', ' infer', ' that', ' Mary', ' is', ' likely', ' to', ' be', ' in', ' the', ' school', ' since', ' she', ' journey', 'ed', ' there', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(50, 44), x_tokens=44, y_tokens=50, max_supp_attn=0.0, attn_on_target=0.02)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (50, 44)
DEBUG result.interpretability.attn_scores 2200 
 [[0.01838667 0.02616056 0.02726941 ... 0.03809896 0.09524295 0.010216  ]
 [0.01863781 0.02345285 0.02451152 ... 0.02277704 0.05660861 0.02688626]
 [0.01917077 0.02924443 0.03138511 ... 0.02767642 0.07856265 0.01932124]
 ...
 [0.01944005 0.02630446 0.02861809 ... 0.03446859 0.03401368 0.00716978]
 [0.02004241 0.02172346 0.0215298  ... 0.02669935 0.01486438 0.00762451]
 [0.01982963 0.02183076 0.02246737 ... 0.03689869 0.02212803 0.00673705]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques', '45 ans', '46 wrap', '* 47 cont *', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' The', ' context', ' sentence', ' ', '1', ' stated', ' that', ' Fred', ' is', ' either', ' in', ' the', ' school', ' or', ' the', ' park', ',', ' but', ' later', ' context', ' sentences', ' updated', ' Fred', "'s", ' location', '.', ' The', ' latest', ' information', ' is', ' that', ' Fred', ' moved', ' to', ' the', ' school', ' (', 'sentence', ' ', '10', ')', ' and', ' then', ' went', ' to', ' the', ' bedroom', ' (', 'sentence', ' ', '13', ').', ' There', ' is', ' no', ' current', ' information', ' suggesting', ' that', ' Fred', ' is', ' in', ' the', ' park', '.\n\n', 'Answer', ':', ' no']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(72, 50), x_tokens=50, y_tokens=72, max_supp_attn=0.0278, attn_on_target=0.0139)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (72, 50)
DEBUG result.interpretability.attn_scores 3600 
 [[0.0126801  0.01760138 0.01985835 ... 0.01578585 0.03334974 0.02521436]
 [0.01288221 0.01342452 0.01473789 ... 0.01174021 0.0128238  0.01589334]
 [0.01322814 0.01973879 0.02322857 ... 0.02264321 0.02936404 0.02446845]
 ...
 [0.01347101 0.02362621 0.02251712 ... 0.01284699 0.06653698 0.02598494]
 [0.01386933 0.01846191 0.01585573 ... 0.01215016 0.04076847 0.01603411]
 [0.01366593 0.01889385 0.01683996 ... 0.00960396 0.06054154 0.02734602]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '* 23 cont *', '24 cont', '25 wrap', '26 ques']
self.y_tokens True ['<|start_header_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '1', ',', ' Fred', ' travelled', ' to', ' the', ' kitchen', ',', ' which', ' implies', ' that', ' Fred', ' is', ' currently', ' in', ' the', ' kitchen', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(34, 26), x_tokens=26, y_tokens=34, max_supp_attn=0.0882, attn_on_target=0.0294)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (34, 26)
DEBUG result.interpretability.attn_scores 884 
 [[0.02721596 0.04354205 0.05347333 0.07223881 0.07658678 0.07594351
  0.0614208  0.06967303 0.0547934  0.06245355 0.0438819  0.05958793
  0.06270823 0.09159196 0.06215812 0.02809783 0.03037587 0.02963529
  0.02798143 0.02977842 0.02533028 0.03761024 0.04168621 0.0162996
  0.01671637 0.03716901]
 [0.02764801 0.05358171 0.04957688 0.07094254 0.06123628 0.05979188
  0.04349332 0.04156737 0.04114949 0.04872832 0.03523324 0.03134208
  0.03152495 0.10484115 0.1025464  0.02859954 0.02599128 0.02075651
  0.02149532 0.02188109 0.02001091 0.0381685  0.04361056 0.01258092
  0.00877152 0.03076848]
 [0.02983025 0.05726979 0.03380807 0.05196817 0.0337235  0.03500151
  0.03112514 0.02228346 0.0214677  0.03232102 0.0241574  0.01644906
  0.01677277 0.02537449 0.03334122 0.01931701 0.01394276 0.01206938
  0.01599568 0.01611293 0.01533627 0.04248523 0.04888046 0.00752099
  0.00600278 0.0160911 ]
 [0.02809654 0.02693129 0.02803613 0.02435331 0.01857435 0.02619058
  0.03127878 0.02657622 0.02495185 0.02496695 0.02733294 0.02909106
  0.0269969  0.01340606 0.01225162 0.03555615 0.02956803 0.04352967
  0.03486963 0.04257876 0.03374907 0.0301139  0.03373895 0.06540514
  0.03926558 0.03633124]
 [0.02824124 0.04200487 0.04539965 0.06538592 0.05940298 0.04719755
  0.03438954 0.03013173 0.03370748 0.04555408 0.0322305  0.02577437
  0.02501015 0.09167039 0.09584962 0.03296647 0.02700347 0.01853206
  0.02098006 0.02163833 0.02184834 0.03773627 0.05970611 0.01288305
  0.0075307  0.03789011]
 [0.02882773 0.02699483 0.02698576 0.0488345  0.04551644 0.04049924
  0.02468093 0.02332286 0.02838369 0.04176713 0.02876893 0.02919304
  0.02681351 0.10480086 0.12384873 0.03273516 0.0306055  0.02236007
  0.02351181 0.02248827 0.02113432 0.03178786 0.03446639 0.00837411
  0.00710871 0.02483258]
 [0.0292509  0.03055366 0.03481151 0.05160877 0.04834314 0.05126289
  0.03307581 0.03194684 0.03656805 0.04902191 0.03342482 0.04615509
  0.04027867 0.08224468 0.07755866 0.02757743 0.02784554 0.02227501
  0.02223742 0.02176503 0.01991809 0.02895474 0.03192383 0.01178021
  0.0093614  0.02389408]
 [0.0282044  0.04084314 0.04631159 0.0404861  0.04407138 0.04750124
  0.0392633  0.0412828  0.03973829 0.0421827  0.03363614 0.05045622
  0.04217045 0.05038044 0.0460386  0.03772474 0.03628916 0.0297731
  0.0285723  0.02905062 0.02774053 0.03399587 0.04768587 0.03166825
  0.02133808 0.04036363]
 [0.02932035 0.03956806 0.04700688 0.04445704 0.04168076 0.05348431
  0.04279901 0.04563709 0.04843878 0.04724332 0.03351472 0.05000553
  0.04491806 0.03640921 0.02486801 0.02607328 0.02741219 0.02370199
  0.02482025 0.02487845 0.02268004 0.03468752 0.03636867 0.01723838
  0.01593261 0.03463186]
 [0.02865977 0.05059906 0.05414281 0.02781677 0.02373271 0.03626454
  0.04530493 0.04238702 0.04358019 0.02930989 0.02764348 0.03746063
  0.03855609 0.01657411 0.01479238 0.04288271 0.03536619 0.02914826
  0.03068893 0.03190556 0.03097585 0.03322198 0.06515148 0.03975112
  0.03506957 0.04113246]
 [0.02916515 0.06318384 0.06395824 0.02588246 0.02253573 0.03125689
  0.04453672 0.03882273 0.04565739 0.02617963 0.02515093 0.02939885
  0.03060144 0.01370691 0.01383519 0.0460889  0.03635152 0.02770801
  0.03173699 0.03466572 0.0310206  0.03021168 0.06912684 0.03242671
  0.02511499 0.03661491]
 [0.02934316 0.03513775 0.04044267 0.02021949 0.0180515  0.0231754
  0.03464431 0.03020974 0.03659774 0.0217374  0.02083477 0.02356916
  0.02395128 0.01159774 0.01212899 0.03819573 0.03184988 0.02454468
  0.02936998 0.03186197 0.0300215  0.0283495  0.05740409 0.04564224
  0.02699519 0.04299621]
 [0.02951945 0.01557755 0.01684577 0.01139323 0.01041796 0.01474385
  0.01648928 0.01661178 0.0193608  0.01351106 0.01406341 0.0143269
  0.01516809 0.00621093 0.00723431 0.02062721 0.02173972 0.01998273
  0.02685576 0.02993199 0.03041331 0.02115085 0.03942951 0.0591435
  0.03476597 0.05362066]
 [0.02946802 0.0233869  0.02477397 0.01618125 0.01497339 0.02062852
  0.02495418 0.02314707 0.02441028 0.01829227 0.02143018 0.02171631
  0.02207369 0.00921942 0.01014378 0.03592242 0.02603445 0.02448761
  0.0253295  0.02691132 0.02710739 0.02713953 0.03023072 0.05297246
  0.03910222 0.04228571]
 [0.02952301 0.02470603 0.0245323  0.0187213  0.01582997 0.02477429
  0.02864936 0.02818147 0.02557685 0.02227495 0.02615612 0.03007367
  0.03044643 0.01102076 0.00970527 0.03510581 0.02757082 0.0302185
  0.02788028 0.03027359 0.02993862 0.0291737  0.02198249 0.04761912
  0.03573783 0.02638814]
 [0.0290361  0.02129593 0.01757313 0.01417962 0.01109989 0.0156275
  0.02471593 0.02256364 0.02030537 0.0155407  0.02211666 0.01914711
  0.02324718 0.00720803 0.00690268 0.03780734 0.02474338 0.04672243
  0.0365401  0.04905089 0.0464825  0.02635428 0.01725063 0.0771113
  0.04920861 0.02738762]
 [0.02985957 0.0194389  0.01714453 0.01377041 0.01149035 0.01637302
  0.02188717 0.02036067 0.02039304 0.01586975 0.02638378 0.02090592
  0.02262496 0.00720964 0.00664894 0.03375014 0.02385814 0.04696289
  0.0319473  0.0526093  0.0373845  0.02209924 0.01381909 0.05330929
  0.04115815 0.01917902]
 [0.02978805 0.0169992  0.01494916 0.01082653 0.00930664 0.01308914
  0.02003763 0.01797971 0.01847846 0.01303166 0.03007767 0.01761183
  0.01993738 0.00582573 0.00601841 0.03191856 0.02712724 0.03722168
  0.03251063 0.03797477 0.03627103 0.02328046 0.01477779 0.0570075
  0.05314721 0.02225699]
 [0.02910027 0.02316452 0.02175895 0.01534668 0.01466858 0.02136647
  0.03328682 0.032672   0.02834692 0.0187901  0.02998661 0.02392458
  0.02881991 0.00834105 0.00848046 0.02448383 0.0331643  0.02951039
  0.03746497 0.03159944 0.03497624 0.02782349 0.02203014 0.0389555
  0.07536641 0.06152637]
 [0.0302956  0.02014215 0.0192875  0.01558359 0.01227017 0.01752819
  0.02165865 0.02205822 0.02158223 0.01712781 0.02548249 0.02191723
  0.02235424 0.00841357 0.00766682 0.02241405 0.02196423 0.02529585
  0.02655431 0.02375432 0.02684353 0.0264656  0.01458024 0.02639447
  0.03253184 0.02334198]
 [0.03041448 0.02231254 0.02523463 0.02269897 0.01743299 0.02614328
  0.02694082 0.03151943 0.02661192 0.02668881 0.0276645  0.03682856
  0.03332831 0.01337383 0.00909359 0.01964911 0.02082731 0.02376156
  0.02311672 0.02179088 0.02191066 0.02857348 0.01430599 0.01610418
  0.02648863 0.02248831]
 [0.03053063 0.02665476 0.02819803 0.02622571 0.01884689 0.02920955
  0.03234747 0.03842498 0.02832571 0.03105444 0.03494488 0.04245123
  0.04015423 0.01450147 0.0096454  0.02266282 0.02169079 0.02533784
  0.02352984 0.02256987 0.02250734 0.02870285 0.01486901 0.01399141
  0.02483283 0.01734112]
 [0.03039655 0.02493202 0.02502346 0.02393737 0.01854542 0.0266816
  0.02918905 0.03344661 0.02858023 0.02909856 0.03212659 0.03823255
  0.03849387 0.0137832  0.00972495 0.02641497 0.02373086 0.0282704
  0.02662191 0.02554239 0.02502001 0.02897112 0.01300101 0.01803459
  0.02517109 0.01584123]
 [0.03020289 0.02022879 0.01918114 0.01494554 0.01146922 0.01699365
  0.02175881 0.02432271 0.02296656 0.01858444 0.02396594 0.02474719
  0.02721523 0.00834105 0.00675582 0.03098814 0.02620331 0.03035273
  0.02903198 0.0277491  0.031368   0.02701451 0.01251353 0.02969719
  0.03604473 0.01744716]
 [0.03018393 0.02092265 0.01943454 0.01558762 0.01138133 0.016426
  0.02426279 0.02526433 0.02290435 0.01855608 0.02493845 0.02256151
  0.02673273 0.00803805 0.00677488 0.03274671 0.02664305 0.03360219
  0.03354967 0.03147476 0.03593855 0.02345028 0.01232354 0.02862397
  0.04044864 0.01786472]
 [0.03028191 0.01966995 0.01821054 0.01484055 0.01217673 0.01604945
  0.02113841 0.02382828 0.02184807 0.01866529 0.02576268 0.02386595
  0.02472196 0.00830398 0.00686561 0.02791347 0.02962176 0.02969379
  0.03327076 0.02718652 0.0323681  0.0237     0.01214691 0.02260915
  0.04938681 0.01820605]
 [0.03043351 0.02192842 0.02045127 0.01607491 0.01217784 0.01746953
  0.02483165 0.02621254 0.02624003 0.01943261 0.03000996 0.02455543
  0.02657991 0.00880575 0.00724177 0.03054542 0.02911166 0.03148541
  0.0340449  0.03185893 0.03425028 0.02498736 0.01267157 0.02355809
  0.0376007  0.01655969]
 [0.0305067  0.01712339 0.01655404 0.01105806 0.00950799 0.01310901
  0.02128622 0.02010796 0.02079038 0.01382735 0.0349227  0.01839352
  0.02157918 0.00681854 0.00559605 0.02859929 0.03065603 0.02933094
  0.03473993 0.02979058 0.03213638 0.02360004 0.01161062 0.03267121
  0.04055094 0.01690169]
 [0.02914738 0.0223342  0.02109026 0.01298565 0.0109219  0.01710245
  0.03297662 0.03052178 0.02876547 0.01771926 0.04649822 0.0241481
  0.03357611 0.00803966 0.00703215 0.0293537  0.04609357 0.04478079
  0.0516745  0.04357061 0.04466562 0.02810914 0.01957531 0.0435951
  0.06345985 0.04779346]
 [0.03054606 0.02040713 0.02073518 0.01718408 0.01317236 0.02045066
  0.02148848 0.02506985 0.02511305 0.02089349 0.0250692  0.02522536
  0.02551666 0.01115936 0.00844504 0.01782244 0.02397232 0.0227003
  0.02650073 0.02285268 0.02592332 0.02506809 0.01337693 0.01622149
  0.02721794 0.02369259]
 [0.02949585 0.02611974 0.02678476 0.04111741 0.04169744 0.0361406
  0.0232398  0.02470837 0.0304623  0.04341665 0.03013138 0.02984588
  0.03001306 0.06398259 0.07966381 0.02269084 0.02708471 0.0230147
  0.02423989 0.02264893 0.02254579 0.03008431 0.02923891 0.0089566
  0.00826249 0.02769913]
 [0.02923953 0.02754067 0.02701627 0.04638194 0.08699028 0.03651715
  0.02116758 0.02296797 0.02915999 0.05071682 0.03540603 0.03069596
  0.02570879 0.06649898 0.08613979 0.02796705 0.0379285  0.0317937
  0.02911611 0.02475833 0.02693866 0.02772755 0.02909714 0.00769957
  0.00770478 0.02378339]
 [0.02892338 0.02509087 0.02395511 0.03858273 0.0895233  0.02604867
  0.01804223 0.02214831 0.02482883 0.0453229  0.03483981 0.03329325
  0.02509857 0.03193193 0.04169781 0.02410355 0.05858759 0.04963489
  0.04088453 0.02964208 0.04328928 0.02557972 0.02579227 0.01332006
  0.02009562 0.028802  ]
 [0.02930373 0.02981359 0.0273119  0.03818295 0.05264382 0.02995791
  0.02363849 0.02404143 0.02991507 0.04011902 0.03221299 0.0270489
  0.026307   0.0303745  0.03330518 0.02069825 0.03904496 0.03180447
  0.03233587 0.0278535  0.03195506 0.04362115 0.03562728 0.01083359
  0.01250923 0.02687727]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '* 29 cont *', '30 cont', '31 wrap', '32 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '4', ',', ' Mary', ' journey', 'ed', ' to', ' the', ' office', ',', ' which', ' implies', ' that', ' Mary', ' is', ' currently', ' in', ' the', ' office', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(31, 32), x_tokens=32, y_tokens=31, max_supp_attn=0.0323, attn_on_target=0.0323)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (31, 32)
DEBUG result.interpretability.attn_scores 992 
 [[0.0304934  0.04957623 0.04834603 0.07081147 0.06284453 0.05445803
  0.0366278  0.03726534 0.04943254 0.0558139  0.03561977 0.03495456
  0.03365651 0.10196885 0.10343459 0.03054934 0.02841346 0.02384306
  0.02492894 0.02694511 0.02415941 0.03533581 0.06333146 0.0192241
  0.0090896  0.03523336 0.0414721  0.0409895  0.10692283 0.03383495
  0.00653637 0.0320043 ]
 [0.03131534 0.04738299 0.04645492 0.08373463 0.08562547 0.07944407
  0.0412486  0.03932012 0.05186417 0.07543263 0.04937133 0.05496027
  0.04955717 0.16672747 0.14679806 0.03525336 0.03124011 0.02959374
  0.02702514 0.02826133 0.02543531 0.03664388 0.04924156 0.01598476
  0.00961118 0.03156637 0.04777206 0.03304776 0.0791466  0.0425524
  0.00964392 0.03884916]
 [0.03181965 0.04387772 0.04969293 0.07034668 0.06411259 0.0641426
  0.04075713 0.04047927 0.04895835 0.06187303 0.03864534 0.05305543
  0.04714044 0.10265792 0.0770345  0.02830812 0.02852611 0.02535506
  0.02478307 0.02531705 0.02258793 0.03435199 0.04554617 0.01873515
  0.01171205 0.03050352 0.04362485 0.0287138  0.05484724 0.06205449
  0.01650587 0.03331063]
 [0.03060835 0.04131217 0.04403683 0.03487865 0.03285712 0.03750676
  0.03520324 0.0374516  0.0345012  0.03407598 0.02995343 0.03806281
  0.03633802 0.02658786 0.02702345 0.03249383 0.03161432 0.0256671
  0.02781818 0.0281905  0.02640597 0.03657354 0.04910323 0.03714154
  0.02729565 0.04085059 0.04837357 0.03330779 0.03971797 0.09765026
  0.03104171 0.02495405]
 [0.0318876  0.03058824 0.03357471 0.02462205 0.0225217  0.02997626
  0.02857879 0.02733029 0.02986044 0.02615445 0.02402793 0.02641097
  0.02596918 0.01691006 0.01814108 0.02142379 0.02065021 0.01879549
  0.02442147 0.025018   0.02398549 0.03008861 0.03449359 0.02664849
  0.0198178  0.03821684 0.03925604 0.02867804 0.03080325 0.06961092
  0.02659719 0.02059979]
 [0.03168597 0.04896979 0.05213112 0.0278205  0.02496538 0.036249
  0.04056123 0.03945089 0.04298941 0.02953451 0.02548869 0.03285611
  0.03372582 0.02145109 0.02008943 0.03066135 0.02629509 0.02071662
  0.02450457 0.02475043 0.02312413 0.03531142 0.0583417  0.03194013
  0.02331329 0.03728272 0.05375544 0.02300935 0.03072359 0.09736709
  0.0247499  0.01699648]
 [0.03187566 0.06633522 0.05862866 0.02623685 0.02498146 0.0348455
  0.04590204 0.03891193 0.05043711 0.02912502 0.02641933 0.03094738
  0.03252456 0.01750701 0.01869891 0.04106374 0.03927916 0.0314151
  0.03508193 0.03864156 0.0322994  0.03208115 0.077783   0.04315716
  0.03089634 0.05181851 0.05641472 0.02490962 0.02589605 0.07271725
  0.01467884 0.01279907]
 [0.03214462 0.03780852 0.03695487 0.02021131 0.02036941 0.02471642
  0.03095535 0.02599083 0.03239095 0.02174024 0.02151676 0.02208276
  0.02239029 0.01438344 0.01601471 0.02958594 0.02724292 0.02069653
  0.02609065 0.02571251 0.02427559 0.02755949 0.04275091 0.03246894
  0.0190623  0.03370573 0.04530273 0.01906818 0.02200274 0.06344461
  0.0156614  0.01135647]
 [0.03193874 0.02209169 0.02238745 0.01542442 0.01562874 0.0186346
  0.023061   0.02133637 0.02064409 0.01789978 0.02362936 0.02271025
  0.02175057 0.01078205 0.01198465 0.03865008 0.02390286 0.02992788
  0.02605263 0.03016385 0.02691537 0.02676899 0.02237588 0.0439182
  0.03137203 0.02463339 0.02652948 0.02840346 0.02779907 0.02968603
  0.03161124 0.0239031 ]
 [0.03204005 0.02646515 0.02939187 0.01863245 0.01869942 0.02374286
  0.02831073 0.02415599 0.02659955 0.0214603  0.02482506 0.02397009
  0.02392384 0.01371646 0.01490195 0.03358399 0.03482489 0.02839311
  0.03274526 0.03263791 0.02974006 0.0305361  0.03229118 0.04285498
  0.02527425 0.03002621 0.03501385 0.02212195 0.02472109 0.04688496
  0.02679726 0.01461911]
 [0.0321185  0.02960949 0.03108769 0.02150986 0.02102856 0.02706433
  0.03418423 0.02992007 0.02689395 0.02450259 0.02973549 0.03173539
  0.03242327 0.01624554 0.01516231 0.04109617 0.03429465 0.03111846
  0.0300187  0.02925391 0.02804552 0.03404878 0.02629457 0.04624611
  0.0284776  0.02506399 0.02759003 0.0266232  0.02450788 0.03934053
  0.03900283 0.02265119]
 [0.03170349 0.02748292 0.02405743 0.0183186  0.01575132 0.02069685
  0.02890701 0.02537261 0.02245545 0.01914677 0.02726163 0.02248357
  0.02737835 0.01189735 0.0123749  0.05006549 0.04285099 0.04507931
  0.04105756 0.04122481 0.04249277 0.03183211 0.02090563 0.06106691
  0.0424405  0.02847808 0.02100514 0.02981275 0.01864947 0.01724913
  0.02546672 0.02126006]
 [0.03251731 0.02909248 0.03096133 0.02553727 0.02336775 0.03394336
  0.03604526 0.0396748  0.03615075 0.02953683 0.03122178 0.03516469
  0.03476359 0.0190817  0.01618114 0.03603253 0.02514656 0.03237265
  0.03111145 0.03660821 0.03225815 0.02851994 0.0257541  0.04202678
  0.02907081 0.03719728 0.02595964 0.0262486  0.02930321 0.0257113
  0.0370954  0.02330215]
 [0.03281439 0.02455156 0.02315423 0.01805026 0.01453752 0.02096793
  0.02654936 0.02346248 0.02212509 0.01893392 0.0299122  0.02400608
  0.02596029 0.01151289 0.01166051 0.0520596  0.0307772  0.04299144
  0.03410854 0.04734848 0.03828014 0.02731712 0.01832182 0.06565137
  0.04227709 0.02266718 0.01992877 0.02515511 0.01824297 0.01535316
  0.02883479 0.03026514]
 [0.03278656 0.02118935 0.02081368 0.01591078 0.01239327 0.0186448
  0.02358167 0.02092225 0.0203834  0.01680548 0.02966874 0.0201137
  0.02340851 0.01001927 0.0107507  0.04318902 0.0335035  0.0350096
  0.03491749 0.0372978  0.03368597 0.02738978 0.01628145 0.05198543
  0.04977172 0.02344979 0.01913732 0.02542182 0.01430515 0.01219792
  0.02442464 0.02438054]
 [0.03165083 0.03820034 0.03422662 0.02907832 0.02478653 0.03448115
  0.04320242 0.04159286 0.03933973 0.03298399 0.03808578 0.03881094
  0.04547361 0.01744437 0.0164154  0.04398638 0.05555926 0.05354059
  0.0560174  0.04981467 0.04790568 0.0337389  0.03266368 0.04909303
  0.09730938 0.06722236 0.02971112 0.04273339 0.0264355  0.01760739
  0.02230977 0.02237277]
 [0.03282136 0.02401178 0.02525355 0.02102111 0.01503188 0.02393233
  0.0279447  0.02793662 0.02356339 0.02155747 0.03232913 0.02797434
  0.02849608 0.01461558 0.0135068  0.03168862 0.02804054 0.02776702
  0.0340272  0.02937589 0.0318285  0.03364545 0.01901248 0.02856019
  0.03467948 0.02348852 0.02328453 0.02642984 0.02312499 0.02098745
  0.07247484 0.03237634]
 [0.03271041 0.02264934 0.02738733 0.02419799 0.01863511 0.02719404
  0.02716627 0.03106337 0.02577477 0.02607116 0.0291936  0.03219068
  0.03132153 0.01744928 0.01394692 0.02129262 0.02164659 0.02506511
  0.02577502 0.02498652 0.02460281 0.0341525  0.01962904 0.02434227
  0.02647075 0.02439758 0.02496241 0.03109657 0.03092449 0.02710658
  0.10336681 0.03479489]
 [0.03292363 0.0298241  0.03397821 0.03359687 0.02245136 0.03696751
  0.03682027 0.04309282 0.02970537 0.03399269 0.03666232 0.04526483
  0.04457444 0.02457836 0.01678593 0.02291188 0.02158962 0.02594767
  0.02536657 0.02501899 0.02436702 0.03532194 0.02293809 0.02130018
  0.02711657 0.02024531 0.02975861 0.02432833 0.03102992 0.02777761
  0.11540914 0.03890553]
 [0.03309203 0.02884373 0.03339091 0.03675459 0.02705739 0.03949031
  0.03648174 0.04268464 0.0324314  0.03949888 0.03756941 0.04567051
  0.0461311  0.02859491 0.02008131 0.02271439 0.02320882 0.02693067
  0.02670421 0.02582662 0.02513214 0.03320643 0.01983061 0.0178496
  0.0230413  0.0184158  0.02581717 0.02687051 0.02981748 0.02521618
  0.07831742 0.04944145]
 [0.03283912 0.02334845 0.0241206  0.02331393 0.01480279 0.02369185
  0.02970779 0.03306068 0.0249455  0.02367666 0.03062883 0.0289472
  0.03239839 0.0148723  0.01272398 0.0305744  0.02969859 0.03078833
  0.03039179 0.0286499  0.03113006 0.03436893 0.01736339 0.02706328
  0.03968933 0.02078186 0.01996043 0.03301018 0.02259373 0.01803215
  0.05591068 0.04684546]
 [0.03268479 0.0222185  0.02126312 0.02124632 0.01303232 0.01992296
  0.02626582 0.02735209 0.02265546 0.02060429 0.02517062 0.02210027
  0.02738723 0.0131146  0.01198755 0.03376772 0.03368931 0.0387762
  0.03896313 0.03858254 0.0421683  0.02882263 0.01712329 0.03923302
  0.04723546 0.02767041 0.01891571 0.03951777 0.01881903 0.01116734
  0.03555006 0.05521625]
 [0.03333293 0.02141697 0.02083953 0.02067131 0.01423407 0.0200381
  0.02522275 0.02686267 0.02180372 0.02091431 0.02722628 0.02471529
  0.02670131 0.01381719 0.01178402 0.02715164 0.02778093 0.02807906
  0.03027244 0.02807836 0.03298546 0.02758105 0.01606111 0.02722906
  0.04721978 0.02005279 0.01908983 0.03671071 0.01887966 0.01259693
  0.03235752 0.0829854 ]
 [0.03308183 0.02669114 0.026319   0.02448549 0.01721633 0.02366125
  0.03300025 0.03573763 0.02888734 0.02511567 0.03640316 0.03102715
  0.0331323  0.01610429 0.0144224  0.03573039 0.03615081 0.03676869
  0.03641162 0.03422465 0.03639311 0.03055613 0.01808666 0.02924639
  0.05177074 0.02338942 0.02138504 0.03830245 0.01946597 0.01240171
  0.02749198 0.06418703]
 [0.03337251 0.02067884 0.01986023 0.01650015 0.01303835 0.01696439
  0.02702192 0.02658923 0.02204193 0.01676615 0.04079721 0.02204482
  0.02565998 0.01184576 0.01072634 0.03234497 0.03667587 0.0295482
  0.03720377 0.03258184 0.03618688 0.02895023 0.01613719 0.0376053
  0.06610636 0.02739359 0.01815592 0.03236403 0.01571909 0.01091634
  0.02392139 0.04181622]
 [0.03226128 0.02820478 0.02792436 0.02376674 0.01931637 0.02441765
  0.03312054 0.03460622 0.03833741 0.02468305 0.02609145 0.02443803
  0.02834681 0.01551347 0.01429715 0.02359575 0.0274598  0.02501958
  0.03445069 0.03216474 0.03527877 0.03307857 0.02950482 0.02988153
  0.05021271 0.07626279 0.03431737 0.04246668 0.02358185 0.01621726
  0.01803893 0.02450603]
 [0.03324121 0.02275502 0.02344572 0.02343372 0.01709173 0.02274599
  0.02567985 0.0287193  0.02582646 0.0240422  0.0264586  0.02561421
  0.02637967 0.01705622 0.01448677 0.02005508 0.02458201 0.02387721
  0.02915582 0.02741041 0.02846348 0.03104316 0.01963793 0.0163289
  0.0257824  0.02655972 0.02320538 0.02635892 0.02371013 0.01666262
  0.02789949 0.03587329]
 [0.03222086 0.03356349 0.03335932 0.04971849 0.04647022 0.04511013
  0.03282326 0.03416039 0.04008135 0.04860263 0.0360576  0.03877591
  0.03713056 0.06463088 0.08436399 0.02399565 0.02798616 0.03137894
  0.02816297 0.02960706 0.02849579 0.03494197 0.03788861 0.01658422
  0.01103825 0.03426962 0.04128215 0.0420448  0.04838494 0.01913738
  0.00889642 0.05533193]
 [0.03189361 0.04286483 0.03863346 0.07500419 0.15844972 0.05657421
  0.0367017  0.03523831 0.04169045 0.07443318 0.05545979 0.05360315
  0.03720875 0.10018535 0.1362538  0.03521455 0.04893612 0.05102618
  0.03688904 0.03529396 0.04088072 0.03397484 0.04886016 0.0163401
  0.01046742 0.03258137 0.05429363 0.04154473 0.05030026 0.01631509
  0.00525371 0.03184621]
 [0.03195717 0.03260426 0.02764579 0.04054482 0.0718516  0.02730772
  0.02636721 0.02745711 0.02866036 0.0419119  0.0383901  0.03288238
  0.02757559 0.03252179 0.04835379 0.02797945 0.05727946 0.05974393
  0.04828242 0.04117858 0.06042879 0.0306963  0.03863263 0.02348539
  0.02732028 0.03177598 0.03552038 0.04876334 0.03330781 0.01266215
  0.00800162 0.01737392]
 [0.0321668  0.03579087 0.03067846 0.04462014 0.04685004 0.03246699
  0.03200014 0.03280111 0.03856889 0.04311031 0.03617933 0.03242611
  0.03117226 0.0362067  0.0396129  0.02298017 0.0411541  0.04476727
  0.03726035 0.03983383 0.0400613  0.0415622  0.04381408 0.01680735
  0.01505755 0.03479933 0.02920459 0.05194683 0.03631609 0.0095408
  0.00615219 0.01487596]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' According', ' to', ' context', ' sentence', ' ', '8', ',', ' Julie', ' is', ' in', ' the', ' park', ',', ' which', ' directly', ' states', ' her', ' current', ' location', '.\n\n', 'Answer', ':', ' yes']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(27, 38), x_tokens=38, y_tokens=27, max_supp_attn=0.0, attn_on_target=0.037)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (27, 38)
DEBUG result.interpretability.attn_scores 1026 
 [[0.0346556  0.04657249 0.04124673 ... 0.02605158 0.02795389 0.0315651 ]
 [0.03578133 0.05442559 0.04834675 ... 0.03110988 0.03666326 0.04208215]
 [0.0362941  0.04760114 0.04622682 ... 0.02235181 0.0257728  0.02341887]
 ...
 [0.03654315 0.03844463 0.04096057 ... 0.021022   0.02263708 0.02226483]
 [0.03697732 0.03002483 0.02961483 ... 0.02674222 0.03006006 0.02784499]
 [0.03690553 0.03258014 0.03354518 ... 0.02174616 0.02552451 0.02605467]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '* 36 cont *', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '42 cont', '43 wrap', '44 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Julie', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '10', ' and', ' ', '11', ',', ' which', ' only', ' mention', ' Fred', ' and', ' Mary', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 44), x_tokens=44, y_tokens=36, max_supp_attn=0.0833, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 44)
DEBUG result.interpretability.attn_scores 1584 
 [[0.02566913 0.03043354 0.03026339 ... 0.03556456 0.01604909 0.01607494]
 [0.02614768 0.02969521 0.03300767 ... 0.04360704 0.02420897 0.02325081]
 [0.02690287 0.02882087 0.03145293 ... 0.05591273 0.02115742 0.02530334]
 ...
 [0.02733995 0.03061748 0.02379431 ... 0.01392774 0.01793519 0.01660543]
 [0.02770626 0.03452157 0.02821663 ... 0.01193525 0.01690421 0.01769489]
 [0.0279428  0.03001127 0.02510128 ... 0.01254608 0.01678525 0.01803313]]
Version: before
DEBUG: checking if InterpretabilityResult is empty...
self.x_tokens True ['1 sys', '2 sys', '3 sys', '4 sys', '5 sys', '6 sys', '7 sys', '8 sys', '9 sys', '10 sys', '11 sys', '12 sys', '13 sys', '14 sys', '15 sys', '16 ex', '17 ex', '18 ex', '19 ex', '20 ex', '21 ex', '22 wrap', '23 cont', '24 cont', '25 wrap', '26 ques', '27 ans', '28 wrap', '29 cont', '30 cont', '31 wrap', '32 ques', '33 ans', '34 wrap', '35 cont', '36 cont', '37 wrap', '38 ques', '39 ans', '40 wrap', '41 cont', '* 42 cont *', '43 wrap', '44 ques', '45 ans', '46 wrap', '47 cont', '48 cont', '49 wrap', '50 ques']
self.y_tokens True ['\n\n', 'Reason', 'ing', ':', ' There', ' is', ' no', ' information', ' provided', ' about', ' Mary', "'s", ' location', ' in', ' the', ' context', ' sentences', ' ', '13', ' and', ' ', '14', ',', ' which', ' only', ' mention', ' Bill', ' and', ' Julie', "'s", ' locations', '.\n\n', 'Answer', ':', ' not', ' mentioned']
self.attn_scores.shape != () True
DEBUG InterpretabilityResult(attn_scores=(36, 50), x_tokens=50, y_tokens=36, max_supp_attn=0.0278, attn_on_target=0.0278)
ATTN raw type: <class 'numpy.ndarray'>
ATTN raw shape: (36, 50)
DEBUG result.interpretability.attn_scores 1800 
 [[0.02597485 0.03766    0.03365241 ... 0.02184438 0.01876563 0.04396057]
 [0.02643029 0.03656017 0.03361164 ... 0.03086615 0.02556519 0.03283449]
 [0.02713338 0.04054067 0.03861821 ... 0.01996111 0.01629416 0.03325872]
 ...
 [0.02759873 0.02826528 0.02316519 ... 0.02854828 0.04563824 0.04494967]
 [0.02729674 0.03418131 0.02607763 ... 0.02141931 0.03031371 0.0423035 ]
 [0.02773857 0.03058566 0.02478825 ... 0.01673021 0.01847644 0.03163914]]
______________________________

==> The run for TEST data is finished successfully <==

The features before applying the setting:
<Features: {'there_before': 0, 'verbs_before': 0, 'pronouns_before': 0, 'not_mentioned_before': 296, 'context_sents_hall_before': 0}>


Metrics for split test:
+----------------------------+--------+
|           Metric           | Before |
+----------------------------+--------+
|    Exact-match accuracy    |  0.81  |
|    Soft-match accuracy     |  0.81  |
| Max attention distribution |  0.07  |
+----------------------------+--------+

- RUN RESULTS -


[before] Exact-match accuracy score for prompt init_prompt_reasoning: 0.81 
[before] Soft-match accuracy score for prompt init_prompt_reasoning: 0.81 
[before] Max attention distribution for prompt init_prompt_reasoning: 0.07 


Metrics for prompt init_prompt_reasoning:
+----------------------------+--------+
|           Metric           | Before |
+----------------------------+--------+
|    Exact-match accuracy    |  0.81  |
|    Soft-match accuracy     |  0.81  |
| Max attention distribution |  0.07  |
+----------------------------+--------+
Processed 20 tasks in total with 100 samples in each
Total samples processed 2000

