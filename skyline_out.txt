Activating the project environment: venv
The project environment 'venv' activated successfully.
Checking for data directory: /home/hd/hd_hd/hd_ea226/tasks_1-20_v1-2
Data directory '/home/hd/hd_hd/hd_ea226/tasks_1-20_v1-2' exists.
Running the script with config: CONFIG_PATH=/home/hd/hd_hd/hd_ea226/research-project/settings/skyline/config, CONFIG_NAME=skyline_test_1_5
Torch version:  2.6.0+cu124
CUDA version:  12.4
CUDA available:  True
Device: cuda
Config data for the run:
model:
  name: meta-llama/Meta-Llama-3-70B-Instruct
  max_new_tokens: 12
  temperature: 0.1
  to_continue: false
  mode: eval
  interpretability:
    use: true
    aggregate: true
setting:
  name: Skyline
data:
  path: /home/hd/hd_hd/hd_ea226/tasks_1-20_v1-2/en-valid/
  baseline_results: ''
  splits:
    train: false
    valid: false
    test: true
  task_ids:
  - 3
  - 4
  - 5
  samples_per_task: 100
  to_enumerate:
    context: true
    question: false
  wrapper:
    context: '*TASK*

      Here are the context sentences:

      {context}

      '
    question: 'Now, answer the following question:

      {question}

      '
    reasoning: ''
    answer: ''
init_prompt:
  paths:
  - /home/hd/hd_hd/hd_ea226/research-project/inference/prompts/init_prompt_direct_answer.txt
  examples:
    add: true
    enumerated: true
    handpicked: true
    not_mentioned: true
    number: 1
    wrapper: '*EXAMPLE*

      {example}

      *END OF EXAMPLE*

      '
logging:
  print_to_file: true
results:
  headers:
  - id_
  - task_id
  - sample_id
  - part_id
  - task
  - answer_lies_in_self
  - golden_answer
  - silver_reasoning
  - model_output_before
  - model_answer_before
  - model_reasoning_before
  - answer_correct_before
  - reasoning_correct_before
  - exact_match_accuracy_before
  - soft_match_accuracy_before
  - max_supp_attn_before
  - attn_on_target_before
  - verbs_before
  - there_before
  - pronouns_before
  - not_mentioned_before
  - context_sents_hall_before


Running the script...
File /home/hd/hd_hd/hd_ea226/tasks_1-20_v1-2/en-valid/qa5_test.txt is read.
File /home/hd/hd_hd/hd_ea226/tasks_1-20_v1-2/en-valid/qa3_test.txt is read.
File /home/hd/hd_hd/hd_ea226/tasks_1-20_v1-2/en-valid/qa4_test.txt is read.
Results will be saved to: /pfs/work9/workspace/scratch/hd_nc326-research-project/skyline/test/da/21-06-2025/03-59-37
The model meta-llama/Meta-Llama-3-70B-Instruct is being loaded in mode 'eval'...

False

===================================BUG REPORT===================================
================================================================================
The following directories listed in your path were found to be non-existent: {PosixPath('/home/hd/hd_hd/hd_ea226/.vscode-server/extensions/ms-python.debugpy-2025.8.0-linux-x64/.noConfigDebugAdapterEndpoints/endpoint-87a084d767b927cd.txt')}
The following directories listed in your path were found to be non-existent: {PosixPath('/lsdf')}
The following directories listed in your path were found to be non-existent: {PosixPath('/etc/lmod/?.lua;;')}
The following directories listed in your path were found to be non-existent: {PosixPath('/run/user/954847/vscode-git-3261119487.sock')}
The following directories listed in your path were found to be non-existent: {PosixPath('module use --append /etc/modulefiles'), PosixPath('module use --append /usr/share/Modules/modulefiles'), PosixPath('module use --append /usr/share/modulefiles')}
The following directories listed in your path were found to be non-existent: {PosixPath('/run/user/954847/vscode-ipc-95dab5d3-e461-489a-85d1-9f53359d69d6.sock')}
The following directories listed in your path were found to be non-existent: {PosixPath('() {  ( alias;\n eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot $@\n}')}
The following directories listed in your path were found to be non-existent: {PosixPath('() {  eval $(/opt/bwhpc/common/admin/modules/module-wrapper/modulecmd bash $*)\n}')}
The following directories listed in your path were found to be non-existent: {PosixPath('() {  if [ "$1" = "load" -o "$1" = "unload" ]; then\n eval "module $@";\n else\n /usr/bin/scl "$@";\n fi\n}')}
The following directories listed in your path were found to be non-existent: {PosixPath('() {  eval "$(/usr/bin/tclsh \'/usr/share/Modules/libexec/modulecmd.tcl\' bash "$@")";\n _mlstatus=$?;\n return $_mlstatus\n}')}
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}
DEBUG: Possible options found for libcudart.so: set()
CUDA SETUP: PyTorch settings found: CUDA_VERSION=124, Highest Compute Capability: 9.0.
CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
CUDA SETUP: Loading binary /pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...
libcudart.so.11.0: cannot open shared object file: No such file or directory
CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.
CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable
CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null
CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a
CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc
CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.
CUDA SETUP: Solution 2a): Download CUDA install script: wget https://raw.githubusercontent.com/TimDettmers/bitsandbytes/main/cuda_install.sh
CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.
CUDA SETUP: Solution 2b): For example, "bash cuda_install.sh 113 ~/local/" will download CUDA 11.3 and install into the folder ~/local
Error: Python script 'running_script.py' failed.

============================= JOB FEEDBACK =============================

NodeName=uc2n906
Job ID: 521259
Cluster: uc3
User/Group: hd_ea226/hd_hd
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 2
CPU Utilized: 00:00:16
CPU Efficiency: 3.42% of 00:07:48 core-walltime
Job Wall-clock time: 00:03:54
Memory Utilized: 730.69 MB
Memory Efficiency: 0.56% of 128.00 GB (128.00 GB/node)
