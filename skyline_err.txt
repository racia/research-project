Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:02<01:24,  2.92s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:05<01:15,  2.70s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:08<01:13,  2.73s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:10<01:10,  2.71s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:13<01:07,  2.70s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:16<01:04,  2.69s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:18<01:01,  2.68s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:22<01:01,  2.81s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:24<01:00,  2.86s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:29<01:05,  3.29s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [00:32<01:00,  3.17s/it]Loading checkpoint shards:  40%|████      | 12/30 [00:34<00:54,  3.05s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [00:37<00:51,  3.06s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [00:40<00:47,  2.99s/it]Loading checkpoint shards:  50%|█████     | 15/30 [00:43<00:43,  2.90s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [00:46<00:39,  2.84s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [00:48<00:36,  2.79s/it]Loading checkpoint shards:  60%|██████    | 18/30 [00:51<00:33,  2.81s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [00:54<00:30,  2.82s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [00:57<00:27,  2.77s/it]Loading checkpoint shards:  70%|███████   | 21/30 [00:59<00:24,  2.75s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [01:02<00:21,  2.73s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [01:05<00:19,  2.77s/it]Loading checkpoint shards:  80%|████████  | 24/30 [01:08<00:16,  2.79s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [01:11<00:13,  2.76s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [01:13<00:10,  2.73s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [01:16<00:08,  2.72s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [01:19<00:05,  2.76s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [01:25<00:03,  3.77s/it]Loading checkpoint shards: 100%|██████████| 30/30 [01:26<00:00,  3.08s/it]Loading checkpoint shards: 100%|██████████| 30/30 [01:26<00:00,  2.90s/it]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
