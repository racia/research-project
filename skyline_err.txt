/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:107: UserWarning: 

================================================================================
WARNING: Manual override via BNB_CUDA_VERSION env variable detected!
BNB_CUDA_VERSION=XXX can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.
If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=
If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH
For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64
Loading CUDA version: BNB_CUDA_VERSION=118
================================================================================


  warn((f'\n\n{"="*80}\n'
/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes


  warn(msg)
/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: /home/hd/hd_hd/hd_ea226/miniconda3 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
Error executing job with overrides: []
Traceback (most recent call last):
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/utils/import_utils.py", line 1863, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/usr/lib64/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/integrations/bitsandbytes.py", line 21, in <module>
    import bitsandbytes as bnb
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/optim/__init__.py", line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/bitsandbytes/cextension.py", line 20, in <module>
    raise RuntimeError('''
RuntimeError: 
        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/pfs/data6/home/hd/hd_hd/hd_ea226/research-project/running_script.py", line 117, in run_setting
    model = Model(
  File "/pfs/data6/home/hd/hd_hd/hd_ea226/research-project/settings/Model.py", line 50, in __init__
    self.model, self.tokenizer = self.load()
  File "/pfs/data6/home/hd/hd_hd/hd_ea226/research-project/settings/Model.py", line 97, in load
    model = AutoModelForCausalLM.from_pretrained(self.name, **model_kwargs)
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/modeling_utils.py", line 262, in _wrapper
    return func(*args, **kwargs)
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in from_pretrained
    hf_quantizer.validate_environment(
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/quantizers/quantizer_bnb_4bit.py", line 79, in validate_environment
    from ..integrations import validate_bnb_backend_availability
  File "<frozen importlib._bootstrap>", line 1055, in _handle_fromlist
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/utils/import_utils.py", line 1851, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/pfs/data5/home/hd/hd_hd/hd_ea226/research-project/venv/lib64/python3.9/site-packages/transformers/utils/import_utils.py", line 1865, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):

        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
