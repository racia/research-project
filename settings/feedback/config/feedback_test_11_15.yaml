defaults:
  # running this script will pull the prompt in this file over the prompt in baseline_config file
  - feedback_config
  - _self_

teacher:
  max_new_tokens: 150

student:
  max_new_tokens: 150

data:
  path: "${oc.env:HOME}/tasks_1-20_v1-2/en-valid/"
  baseline_results: "${oc.env:HOME}/../../../../pfs/work9/workspace/scratch/hd_nc326-research-project/results/baseline/test/reasoning/06-05-2025/21-56-44/init_prompt_reasoning/test_init_prompt_reasoning_results.csv"
  task_ids: [ 11, 12, 13, 14, 15 ]
  samples_per_task: 100
  splits:
    train: False
    valid: False
    test: True

init_prompt:
  paths:
    - "${oc.env:HOME}/research-project/inference/prompts/init_prompt_reasoning.txt"

logging:
  # if to print the results to a log file, otherwise will print to console
  print_to_file: True

hydra:
  run:
    # the run directory with logs, plots, and csv results will be created here
    # use more folders if needed for distinguishing between different experiments
    dir: "${oc.env:HOME}/../../../../pfs/work9/workspace/scratch/hd_nc326-research-project/results/feedback/test/reasoning/${now:%d-%m-%Y}/${now:%H-%M-%S}"
